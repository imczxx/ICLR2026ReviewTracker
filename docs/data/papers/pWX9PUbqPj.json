{"id": "pWX9PUbqPj", "number": 2673, "cdate": 1757191993556, "mdate": 1759898133864, "content": {"title": "Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion", "abstract": "Understanding how neural populations in higher visual areas encode object-centered visual information remains a central challenge in computational neuroscience. Prior works have investigated representational alignment between artificial neural networks and the visual cortex. Nevertheless, these findings are indirect and offer limited insights to the structure of neural populations themselves. Similarly, decoding-based methods have quantified semantic features from neural populations but have not uncovered their underlying organizations. This leaves open a scientific question: ``how feature-specific visual information is distributed across neural populations in higher visual areas, and whether it is organized into structured, semantically meaningful subspaces\" To tackle this problem, we present MIG-Vis, a method that leverages the generative power of diffusion models to visualize and validate the visual-semantic attributes encoded in neural latent subspaces. Our method first uses a variational autoencoder to infer a **group-wise disentangled** neural latent subspace from neural populations. Subsequently, we propose a **mutual information** (MI)–guided diffusion synthesis procedure to visualize the specific visual-semantic features encoded by each latent group. We validate MIG-Vis on multi-session neural spiking datasets from the inferior temporal (IT) cortex of two macaques. The synthesized results demonstrate that our method identifies neural latent groups with clear semantic selectivity to diverse visual features, including object pose, inter-category transformations, and intra-class content. These findings provide direct, interpretable evidence of structured semantic representation in the higher visual cortex and advance our understanding of its encoding principles.", "tldr": "We propose MIG-Vis, a method that uses mutual information-guided diffusion to synthesize images, thereby uncovering neural latent groups that exhibit clear semantic selectivity for pose, inter-category variation, and intra-category content.", "keywords": ["Neural Latent Discovery", "Selectivity", "Visual Cortex", "Diffusion Models"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/64685bb0984169d2cae2a90a621bb25a764e7dbe.pdf", "supplementary_material": "/attachment/496bb87f78ae02b9146fb8ff825d0b3661755c14.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents MIG-Vis, a computational method for interpreting mixed selectivity in neural population dynamics. The approach combines a semi-supervised variational autoencoder that decomposes neural latent representations with a diffusion model for stimulus generation. The method replaces variance-based optimization with mutual information maximization using InfoNCE estimation to generate visual stimuli that selectively activate specific latent factors. Experimental validation is conducted on neural recordings from macaque IT cortex during visual decision-making tasks, with reported improvements in disentanglement metrics and demonstration of generated stimuli showing selectivity to targeted neural factors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed mutual information maximization approach offers a new perspective for stimulus generation in neural interpretation tasks, demonstrating improved disentangled visual stimulus reconstruction effects.\n2. The paper is well-structured with relevant background coverage, providing sufficient implementation detail for reproducibility."}, "weaknesses": {"value": "1. The paper reports poor reconstruction R² values alongside high MIG disentanglement scores, creating a concerning contradiction. If the VAE cannot adequately explain neural variance, the validity of downstream stimulus generation becomes questionable.\n2. The entire evaluation relies solely on a single real-world dataset (macaque IT cortex) with no additional validations such as synthetic data. This provides insufficient evidence for method generalizability or robustness.\n3. The lack of controlled synthetic datasets with known underlying factors prevents proper validation of whether the method recovers true latent structure versus dataset-specific artifacts.\n4. The approach bears high similarity to the authors' prior BeNeDiff method, which represents a natural and important baseline for comparison. Additional comparison would help substantiate the claimed effectiveness of MI guidance over variance-based approaches."}, "questions": {"value": "1. Given the suboptimal reconstruction performance of VAE, how can you demonstrate that the learned representations capture meaningful neural dynamics rather than statistical artifacts?\n2. Can you provide ablation studies isolating the contribution of MI guidance versus VAE architecture choices to determine which components actually drive the reported improvements?\n\nSuggestions: \n1. The authors should include at least one synthetic dataset with known ground truth factors to provide reliable evidence for method effectiveness and generalization capabilities.\n 2. The authors should provide explicit quantitative comparison with their prior BeNeDiff method to clearly demonstrate the specific advantages of MI guidance over variance-based approaches."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jxwAtRMVuD", "forum": "pWX9PUbqPj", "replyto": "pWX9PUbqPj", "signatures": ["ICLR.cc/2026/Conference/Submission2673/Reviewer_4PLU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2673/Reviewer_4PLU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761744364397, "cdate": 1761744364397, "tmdate": 1762916328157, "mdate": 1762916328157, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the enduring question of how information is represented in higher-level visual cortex, a challenge compounded by the mixed selectivity of neurons to multiple latent variables. The authors propose MIG-Vis, which combines a group-wise disentangled variational autoencoder (VAE) with a mutual-information-guided diffusion model to visualize and interpret the semantic content encoded by neural latent groups. Using macaque IT recordings and controlled object stimuli, the method aims to reveal how different latent groups in neural activation space correspond to features such as pose, category, or intra-category content."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important problem—understanding how visual cortex encodes semantically meaningful subspaces—using a technically interesting and timely approach. The combination of a group-wise disentangled VAE and mutual information-guided diffusion is conceptually elegant."}, "weaknesses": {"value": "- While the idea is strong, the paper remains largely qualitative, and it is unclear what new insights about neural coding are gained beyond demonstrating that the model can recover known, supervised factors. Two of the latent groups are trained with supervised labels, presumably corresponding to pose and category. For these, the generated images vary sensibly along the provided latent axes, which serves as a good sanity check for the method. However, it is not at all clear how much variance these axes explain in the overall neural space. Given that a considerable fraction of IT variance is already known to relate to category and pose, these results may simply reflect that expected structure. It would be useful to quantify how much of the explained variance these supervised groups account for, and whether the learned representations capture any additional structure beyond the labeled variables.\n\n\n- The most interesting aspect of the approach lies in the unsupervised latent groups, yet these are only very briefly discussed and remain largely qualitative. It is unclear what these groups encode, how stable they are across datasets or neurons, and what fraction of neural variance they capture. A more detailed analysis of these unsupervised dimensions would greatly strengthen the paper and help assess whether the model uncovers genuinely new aspects of neural representation.\n\n\n- Methodologically, the two-step diffusion process—first inverting and then guiding image synthesis—should be motivated more clearly. Is this procedure intended to constrain the generation to remain on the natural image manifold, for instance analogous to preserving phase information in Fourier space? Does the choice of starting image determine the outcome in the second stage?\n\n\n- Finally, the introduction would benefit from clearer framing, as it currently shifts rapidly between topics without defining a specific gap in knowledge or central research question."}, "questions": {"value": "- Can the authors clarify what the supervised latent groups represent—are these indeed pose and category—and how the corresponding labels were generated? How much of the total neural variance do these supervised groups explain, and do they capture any structure beyond what would be expected from the labeled variables? For the unsupervised groups, what features do they encode, how consistent are they across neurons or datasets, and what proportion of variance do they account for?\n\n-  In terms of methodology, what is the motivation for the two-step diffusion process (inversion followed by guided synthesis)? Is this intended to constrain image generation to remain on the natural image manifold, and does the choice of starting image influence the final outcome?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Hf9dr2UxJN", "forum": "pWX9PUbqPj", "replyto": "pWX9PUbqPj", "signatures": ["ICLR.cc/2026/Conference/Submission2673/Reviewer_bCGZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2673/Reviewer_bCGZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960055226, "cdate": 1761960055226, "tmdate": 1762916327904, "mdate": 1762916327904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method to visualize how neural populations in the primate brain encode visual information. The approach first processes neural spiking data from macaques through a group-wise disentangled variational autoencoder to identify distinct, low-dimensional latent subspaces. It then employs a diffusion model guided by an objective that maximizes the mutual information between a synthesized image and a target neural subspace, thereby generating images intended to represent the specific visual features encoded by that group of neurons. The resulting images suggest the higher visual cortex organizes information into specialized groups selective for features like object pose, inter-category transformations, and intra-category content details. However, the work's novelty lies more in its combination of existing machine learning techniques than in a fundamental conceptual breakthrough, updating the classic optimal stimulus paradigm with modern tools. Furthermore, the claim of providing direct evidence is questionable, as the visualizations are interpretations generated by a multi-stage modeling pipeline. A significant limitation that tempers the paper's broader conclusions is its reliance on a highly constrained stimulus set consisting of grayscale, segmented objects from only eight categories. This limited visual diversity means the uncovered semantic selectivity is defined by this artificial environment, and claims about the general encoding principles of the higher visual cortex may be overstated, as the findings are not shown to generalize to the complexity of natural vision."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work presents several strengths in its approach to investigating neural representations. It successfully integrates multiple machine learning models, a variational autoencoder and a diffusion model, into a cohesive pipeline for interpreting high-dimensional electrophysiology data.\n1. A key contribution is the use of a mutual information-based guidance objective for the diffusion model. The authors support the efficacy of this choice through an ablation study that compares it to a simpler activation-based guidance, showing the MI approach yields more semantically consistent results for complex transformations.\n2. The method produces clear and intuitive visualizations of the abstract information encoded in the identified neural subspaces. This translates complex neural activity patterns into understandable images, making the model's findings accessible.\n3. The study includes a comparative analysis against several baseline methods for neural guidance. This demonstrates that the proposed approach generates higher-quality and more structurally coherent images, strengthening the claims about its effectiveness."}, "weaknesses": {"value": "The study has several limitations that should be considered when interpreting its conclusions, with the primary concerns relating to the novelty of the approach and the characteristics of the dataset used.\n1. The work's main contribution is the novel integration and application of existing machine learning methods to a specific neuroscience problem. The core components: variational autoencoders for disentanglement, diffusion models for generation, and mutual information for guidance. Are all established techniques. As such, the paper represents an advancement in methodology rather than the introduction of a fundamentally new theoretical concept for understanding neural computation.\n2. The conclusions are based on neural responses to a highly controlled and simplified visual environment. The dataset consists of grayscale, segmented objects from only eight categories presented on a uniform background. This lack of complexity raises significant questions about the generalizability of the findings. The \"semantic\" features discovered by the model are defined entirely by the limited variations present in the dataset and may not reflect how the visual cortex represents the much richer and more complex information found in natural scenes, which include color, texture, and cluttered backgrounds.\n3. The claim of providing \"direct\" evidence of neural representation is not strong. The final visualizations are the output of a multi-stage pipeline involving two separate deep learning models. The results are therefore an interpretation of the neural data as filtered through the specific architectures and biases of these models. Different modeling choices could potentially lead to different visual interpretations of the same underlying neural activity.\n4. The primary support for the semantic meaning of the latent groups comes from the visual inspection of the synthesized images. While the images are interpretable, the evaluation of their semantic content is largely qualitative and subjective. The study lacks quantitative metrics to formally validate that the generated images accurately capture the intended semantic transformations."}, "questions": {"value": "1. The choice of the VAE architecture, particularly the number of latent groups (four) and the dimensionality of each group (six), is important to the findings. Could you elaborate on the selection process for these hyperparameters? How sensitive are the discovered semantic selectivities to changes in this architecture, for example, if you used more or fewer groups? How would you apply this to natural RGB images?\n\n2. The \"latent groups\" are a powerful modeling abstraction. Do you have any hypotheses about how these computationally-defined groups might map onto the known anatomical or functional organization of the IT cortex? For instance, could a single latent group correspond to a specific neural sub-population or a known processing stream?\n\n3. Your results show that manipulating a single latent group can produce large, coherent changes in the image, such as transforming a face into a pear. Does this imply that the neural code for these distinct objects is adjacent or connected in this latent space, or is this transformation an artifact of the generative model's ability to interpolate between any two points?\n\n4. Have you considered applying your method to a more diverse dataset to test the robustness of these specific semantic axes? Would you expect to find similar, cleanly separated latent groups, or would you anticipate a more entangled representation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rwJSaWyuWg", "forum": "pWX9PUbqPj", "replyto": "pWX9PUbqPj", "signatures": ["ICLR.cc/2026/Conference/Submission2673/Reviewer_NyBK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2673/Reviewer_NyBK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988671586, "cdate": 1761988671586, "tmdate": 1762916327703, "mdate": 1762916327703, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MIG-Vis, a two-stage pipeline to uncover semantically selective latent groups in macaque IT cortex. First, a group-wise (weakly supervised) VAE learns a structured neural latent space. Then, the authors visualize each group’s semantics by editing real images with a deterministic DDIM sampler guided by a surrogate of mutual information (via InfoNCE), so edits stay on-manifold while moving the image toward the target group. Qualitatively, different groups control pose (intra-class), inter-category transitions, and fine intra-class details; ablations suggest stronger, more controllable edits than activation-guided baselines, while disentanglement improves with little loss in neural reconstruction."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper combines a group-wise neural latent space (VAE) with explicit, InfoNCE-guided deterministic DDIM editing, yielding a clean ‘unconditional denoising score + semantic term’ decomposition for controllable edits—going beyond regression guidance and offering a clear, reproducible, and extensible recipe.\n2. On macaque IT data, the approach consistently maps different latent groups to pose, inter-category transitions, and fine intra-category details while preserving structure, providing a practical tool for population-level neural interpretation with promising implications for closed-loop neuroscience and interpretable generative modeling."}, "weaknesses": {"value": "1. In Eqs.~(5)--(6) the authors train an InfoNCE scorer and use $-\\nabla_y L_{\\mathrm{InfoNCE}}$ to approximate $\\nabla_y \\mathrm{PMI}(z_g,y)$. By standard contrastive–learning results, however, the InfoNCE optimum estimates $\\log \\frac{p(z\\mid y)}{q(z)}$; this coincides with PMI only when the negative–sample distribution satisfies $q(z)\\approx p(z)$ and is independent of the current $y$. Therefore, the reliability of the gradient’s direction and magnitude hinges on this assumption. Please (i) specify how negatives are sampled in your implementation and (ii) systematically quantify the impact of different $q(z)$ strategies and batch sizes $B$.\n2. The implementation guides sampling with the pointwise mutual information (PMI) gradient for a specific target group $z_g$, yet the main text repeatedly refers to an \"MI gradient,'' which can be misread as maximizing the expected mutual information over $p(z\\mid y)$. The two have different statistical meanings: PMI means make the current image look more like this group,whereas MI concerns the overall dependence between $Z$ and $Y$. Using \"MI'' instead of \"PMI\" overstates the correspondence between the target and the evidence. Please state explicitly in the main text.\n3. The paper fixes the editing start at an intermediate diffusion step $t'$ and employs deterministic DDIM. However, it provides no evidence for why such a $t'$ should generally exist, how $t'$ ought to be selected, or whether the choice is robust across different noise schedules, datasets. Therefore, the observed effects may depend on carefully chosen settings or hyperparameters, rather than the method itself.\n4. The number of groups $G$ in the group-wise VAE is a key hyperparameter.  If $G$ is too large, semantic factors tend to fragment across multiple groups;  if $G$ is too small, heterogeneous semantics are merged into the same group.  The authors should provide experiments justifying their choice of $G$ together with metrics such as reconstruction and controllability of the resulting visualizations.\n5. While this is a minor issue, it was unclear if the dataset from Majaj et al., 2015 is publicly available but I must specify that MIG-Vis code has been provided on a link. The model is there but I might have missed the data."}, "questions": {"value": "1. In equation (4), the conditional variable $z$ in $\\log p_\\gamma(y_t \\mid z)\\,$ is undefined. The authors need replace $z$ by $z_g$ or explicitly define $z$, and ensure consistent notation throughout.\n2. The paper states that negative samples are drawn from $q_\\phi(z_g \\mid \\hat{x})$ with $\\hat{x}$ unrelated to $y$, but how independence from the current $y$ is guaranteed. The authors need to clarify whether negative samples are drawn cross-image or provide the exact procedure.\n3. The quantity in Eq.~(2) is commonly referred to as Total Correlation. Please rename accordingly or explain the difference between your usage and the standard definition."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XdiGpsBbmN", "forum": "pWX9PUbqPj", "replyto": "pWX9PUbqPj", "signatures": ["ICLR.cc/2026/Conference/Submission2673/Reviewer_X5v2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2673/Reviewer_X5v2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762209099512, "cdate": 1762209099512, "tmdate": 1762916327435, "mdate": 1762916327435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}