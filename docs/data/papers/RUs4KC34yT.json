{"id": "RUs4KC34yT", "number": 20605, "cdate": 1758308175110, "mdate": 1763695361901, "content": {"title": "Verifiable Natural Language to Linear Temporal Logic Translation: A Benchmark Dataset and Evaluation Suite", "abstract": "Empirical evaluation of state-of-the-art natural language (NL) to temporal logic (TL) translation systems reveals near-perfect performance on existing benchmarks. However, current studies only measure the accuracy of the translation of NL logic into formal TL, ignoring a system’s capacity to ground atomic propositions into new scenarios or environments. This is a critical feature, necessary for the verification of resulting formulas in a concrete state space. In this paper, we introduce the Verifiable Linear Temporal Logic Benchmark (VLTL-Bench), a unifying benchmark for automated NL-to-LTL translation. The dataset consists of three unique state spaces and thousands of diverse natural language specifications and their corresponding formal temporal logic specifications. Moreover, the benchmark contains sample traces to verify the temporal logic expressions. While the benchmark directly supports end-to-end evaluation, we observe that many frameworks decompose the process into i) lifting,  ii) grounding, iii) translation, and iv) verification. The benchmark provides ground truths after each of these steps to enable researchers to improve and evaluate different substeps of the overall problem.  \n Using the benchmark, we evaluate several state‑of‑the‑art NL-to-TL translation models and frameworks, including nl2spec, NL2TL, NL2LTL, Lang2LTL, sequence-to-sequence translation, and various LLM prompting techniques. Our evaluation confirms that existing work is capable of reliably performing lifting and translation with high accuracy, while it exposes their struggles to ground the translation into a state space, which stems from the lack of existing datasets.", "tldr": "We present VLTL-Bench, a benchmark unifying lifting, grounding, translation, and verification for NL-to-LTL. While prior models excel at lifting and translation, our evaluation reveals grounding into concrete state spaces remains a major challenge.", "keywords": ["Benchmark", "Temporal Logic", "Linear Temporal Logic", "Verification", "Natural Language"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4a913f4403c564683ee70b528d9dcbc566738867.pdf", "supplementary_material": "/attachment/c7037d92610176cde6a01262809a58fb7d50de65.zip"}, "replies": [{"content": {"summary": {"value": "The main argument of this paper is that while current NL-to-TL systems excel at translating abstract formulas, they fail badly at the crucial step of connecting those formulas to real-world environments (so called \"grounding\"). To address this, the authors  introduce VLTL-Bench, a new benchmark designed specifically to address this gap and enable end-to-end evaluation of NL->TL translation including verification. This benchmark includes multiple distinct state spaces (environments), Thousands of diverse NL specifications with corresponding formal TL specs,  sample traces for verifying the grounded formulas within each state space and it supports the evaluation of the full process: \"Lifting\", \"Grounding\", \"Translation\", and \"Verification\"\nThe authors show that existing systems perform very well on \"lifting\" and \"translation\", confirming prior benchmark results, but they struggle significantly with the critical step of \"grounding\" atomic propositions into a provided state space."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-- The paper addresses the major limitation in existing NL-to-TL research: the lack of evaluation for \"grounding\". Previous benchmarks ignored this essential step needed for real-world verification.\n\n-- The work enables end-to-end evaluation, providing not just formulas, but \"sample traces\" that allow researchers to verify if the final grounded TL formula behaves correctly in a specific state space/scenario. \n\n-- The paper considers NL-to-TL process as a pipeline of different stages (lifting, grounding, translation) and for each stage it provides the ground truth data.\n\n-- The paper provides a rich & diverse dataset, with \"thousands of diverse NL specifications\" providing corresponding formal TL specs for each NL spec.\n\n--The paper exposes the specific weakness of existing SOTA models: high accuracy on abstract translation but poor performance on grounding.\n\n-- Broad Evaluation Scope (`nl2spec`, `NL2TL`, `NL2LTL`, `Lang2LTL`) including sequence-to-sequence models and Various LLM prompting techniques."}, "weaknesses": {"value": "-- Scope Limited to LTL: The benchmark specifically targets Linear Temporal Logic (LTL), as indicated by \"VLTL-Bench\" and references to LTL. This does not evaluate translation  capabilities for other important temporal logics like Computation Tree Logic (CTL) or Signal Temporal Logic (STL).\n\n-- Limited State Space Diversity & Scale:While it includes three distinct state spaces, this is still a small number compared to the vast diversity of real-world systems NL-to-TL might  be applied to. Generalizability beyond these state spaces is not proven.\n\n-- Sample Trace Limitations: While including traces for verification is crucial, their representativeness are very important. The paper does not provide details how these traces were generated or if they comprehensively cover potential system behaviors (e.g., are corner cases included?)"}, "questions": {"value": "The benchmark includes only three distinct state spaces. How do you justify that this small number sufficiently captures the complexity and variability  required to evaluate grounding generalization in real-world scenarios? What steps were taken to ensure these environments are not biased or overlapping?\n\nHow were the sample traces for verification generated? Can you demonstrate statistically that they cover corner cases, violations, and  satisfactions of the LTL formulas? How do you address concerns about trace completeness impacting verification reliability?\n\nVLTL-Bench focuses exclusively on Linear Temporal Logic (LTL). Many practical applications require richer logics like CTL*, Signal Temporal Logic (STL), or Metric Temporal Logic (MTL). Does your approach fundamentally limit the benchmark's applicability? Is extending it to other TLs feasible?\n\nYou attribute poor grounding performance primarily to a 'lack of existing datasets'. However, could the failure also stem from fundamental architectural limitations in current NL-to-TL systems (e.g., LLMs lacking state-space reasoning)? How did you disentangle data scarcity from model capability?\n\nGiven the identified grounding bottleneck, what concrete architectural changes, training paradigms (e.g., using VLTL-Bench for fine-tuning), or hybrid approaches do you propose as most promising to address this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wra4TE2l8g", "forum": "RUs4KC34yT", "replyto": "RUs4KC34yT", "signatures": ["ICLR.cc/2026/Conference/Submission20605/Reviewer_HCJe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20605/Reviewer_HCJe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773392396, "cdate": 1761773392396, "tmdate": 1762934010830, "mdate": 1762934010830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies an interesting and important problem in the area of natural language to formal language (here is temporal logic). Most previous studies focus on lifted translation, while neglecting the action grounding process. This work finds most models actually fails in Atomic proposition grounds. Hence, they create a new dataset and test the performance of all the SoTA methods. Overall, I think this paper is a good contribution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The great detection of the flaws in current approaches and the solid dataset creation and benchmark testing. The writing and related work articulation are clear. The motivation is great."}, "weaknesses": {"value": "The main question I am doubting is the semantic and expression diversity of the created dataset. The initial 43 expressions seem too limited. Meanwhile, I remember in the referenced work NL2TL, they utilized LLM to help synthesize the initial pairs to then do human annotation. That increases the diversity. In this study, it seems the authors do not utilize LLM for synthesizing. I wonder if the authors can explain what's the reason and possible benefits."}, "questions": {"value": "As I said above, the dataset semantic diversity remains one question."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DP2QnHAidd", "forum": "RUs4KC34yT", "replyto": "RUs4KC34yT", "signatures": ["ICLR.cc/2026/Conference/Submission20605/Reviewer_LzLP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20605/Reviewer_LzLP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761863774041, "cdate": 1761863774041, "tmdate": 1762934010216, "mdate": 1762934010216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to all reviewers"}, "comment": {"value": "We thank all reviewers for their insights and constructive feedback. We appreciate that the motivation and purpose of our paper is clear. We identify four key components of current NL-to-LTL translation systems: Lifting, Grounding, Translation, and Verification. Crucially, we note the widespread omission of grounding and verification components in current NL-to-LTL systems, as well as the inability of current benchmarks and datasets to independently measure the performance of each. In response, we propose VLTL-Bench to measure the capabilities of each component separately. Below, we list some strengths highlighted by multiple reviewers:\n- [n43H, HCJe, LzLP, yG7A] Identifying the major gap in current NL-to-LTL systems: they omit grounding and verification.\n- [n43H, HCJe, LzLP, yG7A] VLTL-Bench is the first benchmark that enables isolated evaluation of lifting, grounding, translation, and verification components.\n- [LzLP, yG7A, HCJe] Clear motivation and strong writing/presentation quality.\nTo improve our submission, we strengthened the experimental results with additional grounding evaluations using a stronger reasoning model (GPT-4o) and chain-of-thought prompting.\n\nWe now address several concerns raised by multiple reviewers:\n\n>Q1: [HCJe, yG7A] Lack of inclusion of other TL formalisms (CTL, STL):\n\nWe focus on LTL because our primary goal is to provide the first benchmark that enables independent evaluation of all NL-to-TL components, especially grounding and verification, which no existing dataset supports even for LTL. While our framework is not inherently limited to LTL, extending it to CTL, STL, etc. would require substantially different dataset design choices, so we leave these richer logics to future work.\n\n>Q2: [n43H, LzLP] Limitations of templated data and of 43 templates for diversity:\n\nWe intentionally use 43 hand-crafted templates because they reliably generate coherent NL–LTL–trace tuples while guaranteeing logical correctness, syntactic validity, and full control over grounded predicate–argument structures—properties that algorithmic LTL generation and LLM-based synthesis cannot consistently ensure. Template count is not the primary source of diversity: VLTL-Bench derives combinatorial richness from domain variation, hierarchical types, multi-argument predicates, trace variability, and grounded predicates. Empirically, this diversity is sufficient to expose severe grounding failures across current systems. We also note that prior NL–LTL benchmarks use fewer templates and less linguistic diversity (Table 2), whereas VLTL-Bench has significantly more numerous and varied predicates and arguments. While additional templates expand logical coverage, the central challenge posed by VLTL-Bench is the grounding of atomic propositions. Empirically, we observe that this design already exposes severe grounding failures across all baselines, suggesting that the available combinations of APs and traces leave substantial room for future systems to improve rather than saturating the benchmark.\n\n>Q3: [HCJe, LzLP] Small number of domains/state spaces:\n\nWe have extended the initial three domains of VLTL-Bench with an additional Kitchen Assistant domain. The domains serve as a proof of concept for our data-generation protocol and demonstrate that grounding can be evaluated independently of lifting and translation. Our goal is to establish the framework and provide initial domains rather than enumerate all possible environments; the benchmark is designed to make future domain extensions straightforward. Adding a new domain requires specifying a scenario configuration file and defining synonyms for canonical actions and arguments; our data-generation code handles English morphology (tense, gerunds, part of speech) to ensure fluent text. Complexity metrics for Kitchen Assistant are provided in Table 1 and Table 2, and the scenario configuration file is included in Appendix 8.\n\n>Q4: [n43H, yG7A] Grounding evaluations are too simple and do not employ reasoning models or CoT:\n\nOur updated grounding evaluation with GPT-4o and few-shot chain-of-thought addresses this concern (Table 5, Section 4.3). This experiment shows that even powerful LLMs cannot fully solve grounding. GPT-4o performs better than other models, achieving 94% accuracy on Search and Rescue, but its accuracy in Traffic Light and Warehouse is notably lower (82% and 62%, respectively), indicating substantial remaining headroom.\n\n>Q5: [n43H, HCJe] How are positive and negative traces chosen for each spec?\n\nThe positive and negative trace examples are hand-made, not generated, as stated on line 204 in Section 3.2. They provide a partial correctness metric without revealing the ground-truth LTL: if a proposed LTL expression is not satisfied by the positive trace, or is satisfied by the negative trace, it is known to be incorrect. We provide these traces to encourage future NL–LTL systems to consider scenarios in which they have access to labeled traces."}}, "id": "5VREmjupZd", "forum": "RUs4KC34yT", "replyto": "RUs4KC34yT", "signatures": ["ICLR.cc/2026/Conference/Submission20605/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20605/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20605/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763694701781, "cdate": 1763694701781, "tmdate": 1763698869250, "mdate": 1763698869250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces VLTL-Bench, a benchmark that evaluates natural-language-to-LTL systems end-to-end. The proposed benchmark covers lifting, translation, grounding, and verification across warehouse, traffic-light, and search-and-rescue scenarios. It shows that while models handle lifted translation well, they struggle to ground atomic propositions in concrete state spaces, leading to large drops in end-to-end and trace-verification accuracy."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. VLTL-Bench measures all four aspects and supplies ground truth for each, plus example traces to check whether formulas actually hold. \n2. The scenario configs and templated generation make the benchmark easy to extend."}, "weaknesses": {"value": "1. All LLMs used for evaluation all extremely small & non-reasoning LLMs. The task is considered as a reasoning task, so including results for reasoning LLMs will make the evaluation more comprehensive. \n2. The benchmark centers on discrete-time LTL. Related logics are discussed in L680 but not supported, limiting applicability to systems needing other temporal formalisms."}, "questions": {"value": "1. I understand that you have provided few-shot examples in A.7, but what's the prompt used for few-shot? \n2. Why Actions is limited to a maximum of two targets (as stated in L197)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xCOCqW3ae0", "forum": "RUs4KC34yT", "replyto": "RUs4KC34yT", "signatures": ["ICLR.cc/2026/Conference/Submission20605/Reviewer_yG7A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20605/Reviewer_yG7A"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978315909, "cdate": 1761978315909, "tmdate": 1762934009212, "mdate": 1762934009212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces VLTL-Bench, a benchmark dataset for evaluating natural language to Linear Temporal Logic (LTL) translation systems. The key contribution is providing ground truth annotations for intermediate translation steps (lifting, grounding, translation, verification) and including verification traces. The authors evaluate several state-of-the-art systems and reveal that grounding (mapping abstract propositions to concrete state spaces) is a significant bottleneck. While the paper addresses an important problem and provides a useful modular evaluation framework, it suffers from limited template diversity (43 templates), insufficient domain coverage (3 scenarios), and, critically, lacks analysis of whether LLMs exploit semantic knowledge versus compositional reasoning. The absence of obfuscated scenario variants (similar to PlanBench [1] for PDDL) is a major weakness that prevents proper isolation of the grounding problem.\n\n[1] Valmeekam et al., PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change. NeurIPS 2023."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "A) The paper correctly identifies a critical gap in existing benchmarks that they focus on lifted translation while ignoring grounding, which is essential for executable specifications. The observation that current datasets achieve >90% accuracy but cannot produce verifiable formulas is valuable.\n\nB) The design allowing isolated assessment of lifting, grounding, translation, and verification is well-motivated and technically sound. The metrics are clearly defined and appropriate."}, "weaknesses": {"value": "A) Limited Template Diversity and Generalization\n\nThis is my biggest concern with this work. The benchmark is built from only 43 linguistic and logical templates (36 from nl2spec + 7 new). While thousands of examples are generated through instantiation with different actions/arguments, this approach has some limitations. 43 templates cannot capture the rich diversity of natural language specifications in real-world applications. Human stakeholders express requirements in countless syntactic structures, with varying referring expressions, negations, conditionals, and quantifiers. The high translation accuracy (99.9% for NL2TL in Table 4) likely reflects template memorization rather than robust understanding. Additionally, Table 8 shows a significant imbalance. E.g., \"next\" appears ~10 times more than \"until\" across domains. This distribution may not reflect real-world specifications and could bias evaluation toward overrepresented operators. Finally, Models trained and evaluated on template-instantiated data may learn to recognize surface patterns rather than develop compositional understanding. \n\nB) Missing Analysis on Semantic Knowledge vs. Compositional Reasoning\n\nThe paper does not adequately address whether LLMs leverage pre-training knowledge for grounding, which is crucial for understanding the grounding bottleneck. It's well known that modern LLMs are trained on massive corpora, potentially including robotics documentation, LTL tutorials, warehouse management systems, and traffic control specifications. Additionally, GPT-4 models may have encountered the nl2spec benchmark (36 templates) during pre-training, artificially inflating performance on lifting and translation while grounding remains poor because it requires scenario-specific knowledge. Can they exploit this semantic knowledge for this benchmark? A possible solution would be to follow PlanBench's approach for PDDL planning. SImilar to it, the paper must include obfuscated versions where semantically meaningful names are replaced with arbitrary symbols. E.g., replace search(apple) with act_3(obj_17) then ask queries like \"perform procedure Z on target Q\" instead of \"look for the red fruit\". This would isolate compositional reasoning from semantic shortcuts, and test pure grounding ability based solely on scenario configuration. It might also mitigate data contamination concerns (nl2spec templates are publicly available). This is a major gap that significantly weakens the paper's contributions.\n\nC) Weak Grounding Baselines\n\nGiven that grounding is identified as the critical bottleneck (Table 5 shows 5.0%-68.6% AP-Dict accuracy), the baseline approaches are surprisingly simplistic. The baselines use a basic few-shot prompting without even the basic additions like chain-of-thought reasoning, structured output constraints like JSON, iterative refinement with verification feedback using provided traces, and self-consistency or ensemble methods. THis might inflate the efficacy of this benchmark."}, "questions": {"value": "1. Why 43 templates? Can you provide empirical or theoretical justification that 43 templates provide adequate coverage of natural language and logical diversity? What would performance look like with 10 templates vs 100 templates?\n2. Will you add obfuscated variants (replacing meaningful names with symbols like \"act_3(obj_17)\") to isolate compositional reasoning from semantic knowledge? This is standard practice in planning benchmarks (PlanBench) and seems essential here.\n3. Have you verified that the nl2spec templates and your scenarios don't appear in GPT-4's training data? Can you test on models with verifiable training cutoffs before your dataset creation?\n4. Why didn't you explore chain-of-thought prompting, iterative refinement with trace verification, or fine-tuned models for grounding given it's the identified bottleneck?\n5. How were the positive and negative traces chosen for each specification? Are they minimal, typical, or adversarial examples?\n6. Current scenarios have flat type systems. Can your framework handle hierarchical types (e.g., \"animal -> dog -> poodle\")?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J6AvwLi7Bp", "forum": "RUs4KC34yT", "replyto": "RUs4KC34yT", "signatures": ["ICLR.cc/2026/Conference/Submission20605/Reviewer_n43H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20605/Reviewer_n43H"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762083979814, "cdate": 1762083979814, "tmdate": 1762934008818, "mdate": 1762934008818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}