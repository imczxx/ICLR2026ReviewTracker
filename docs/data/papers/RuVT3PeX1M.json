{"id": "RuVT3PeX1M", "number": 22895, "cdate": 1758336808818, "mdate": 1763711846279, "content": {"title": "Ensemble Prediction of Task Affinity for Efficient Multi-Task Learning", "abstract": "A fundamental problem in multi-task learning (MTL) is identifying groups of tasks that should be learned together. Since training MTL models for all possible combinations of tasks is prohibitively expensive for large task sets, a crucial component of efficient and effective task grouping is predicting whether a group of tasks would benefit from learning together, measured as per-task performance gain over single-task learning. In this paper, we propose ETAP (Ensemble Task Affinity Predictor), a scalable framework that integrates principled and data-driven estimators to predict MTL performance gains. First, we consider the gradient-based updates of shared parameters in an MTL model to measure the affinity between a pair of tasks as the similarity between the parameter updates based on these tasks. This linear estimator, which we call affinity score, naturally extends to estimating affinity within a group of tasks. Second, to refine these estimates, we train predictors that apply non-linear transformations and correct residual errors, capturing complex and non-linear task relationships. We train these predictors on a limited number of task groups for which we obtain ground-truth gain values via multi-task learning for each group. We demonstrate on benchmark datasets that ETAP improves MTL gain prediction and enables more effective task grouping, outperforming state-of-the-art baselines across diverse application domains.", "tldr": "We introduce an ensemble approach for predicting performance gains from multi-task learning, bridging the gap between white-box and data-driven approaches for task grouping.", "keywords": ["Machine Learning", "Multi-Task Learning", "Task Affinity", "AutoML"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1a5f427835a6f65f04454735fb46f99752ded0c2.pdf", "supplementary_material": "/attachment/0e2d8fc7f333a81b091aa6f58ac88887feb5ee18.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes ETAP (Ensemble Task Affinity Predictor), a framework for predicting multi-task learning (MTL) gains to enable efficient task grouping. The approach combines white-box gradient-based affinity scoring with data-driven ensemble prediction."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The two-stage ensemble design that uses gradient-based affinity scores as foundation and refining with data-driven models is reasonable, it combines white-box gradient-based affinity scoring with data-driven ensemble prediction.\n2. ETAP achieves impressive runtime reduction while maintaining or improving correlation with ground-truth gains. This is a meaningful practical contribution."}, "weaknesses": {"value": "1. The gradient-based affinity score (Equation 5) is quite similar to existing work (TAG), just removing the auxiliary forward/backward passes. The B-spline transformation and ridge regression are standard techniques. The main novelty seems to be in combining these pieces, which feels somewhat incremental. Can you clarify what is fundamentally new here beyond engineering different existing methods together?\n2. While you claim ETAP is \"scalable,\" all experiments use relatively small task sets (n=7-10). What happens when n=50 or n=100? The affinity score computation still requires training one MTL model with all tasks, and the pairwise scores grow as O(n²). The paper doesn't really demonstrate scalability to large task pools that appear in real applications.\n3. Section 3.2.3 uses branch-and-bound from prior work. So the contribution is really just the gain prediction, not the actual grouping algorithm. This should be made more clear in the contribution claims."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xhfj93iMdN", "forum": "RuVT3PeX1M", "replyto": "RuVT3PeX1M", "signatures": ["ICLR.cc/2026/Conference/Submission22895/Reviewer_66hX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22895/Reviewer_66hX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761489146581, "cdate": 1761489146581, "tmdate": 1762942429256, "mdate": 1762942429256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\n\nThis paper addresses a central challenge in multi-task learning (MTL): identifying groups of tasks that mutually improve each other’s performance when trained together. Existing methods typically fall into two categories — white-box and black-box approaches.\n\nThe paper introduces a hybrid method that integrates both. The proposed two-step framework first estimates pairwise task affinities by training a single MTL model on all tasks within a group, inferring affinities for all possible combinations. In the second step, a non-linear mapping from task affinity to performance gain is constructed and refined using residual predictions.\n\nThe method is evaluated against several state-of-the-art task grouping algorithms, with ablation studies highlighting the contribution of each component. Results demonstrate the benefits of applying non-linear mappings and residual predictions. Overall, the paper presents a robust and well-conceived methodology that successfully combines the strengths of existing approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strengths\n\nTackles an important challenge in the MTL literature — the high computational overhead of existing task-grouping algorithms. Through comprehensive ablation studies, the paper provides valuable insights into the role of gradient similarities (e.g., via comparison of affine vs. non-linear mappings).\n\nDesign choices (e.g., use of B-splines and regression techniques) are justified through ablation analyses and comparative experiments.\n\nThe paper is clearly structured and effectively relates its contributions to prior work, ensuring coherence and contextual grounding.\n\nThe experimental evaluation goes beyond measuring performance gains, also analyzing the correlation between predicted affinities and ground-truth transfer gains."}, "weaknesses": {"value": "Weaknesses\n\nWhile computational efficiency is claimed as a key advantage, it would be valuable to include results for the complete approach (including hyperparameter tuning in the second stage) or to explicitly state that the additional cost is negligible. Comparing against an additional data-driven baseline would strengthen the evaluation.\n\nThe performance gains over naive MTL are relatively modest; a discussion of their practical significance would help contextualize their value.\n\nSome design choices lack clear theoretical justification (e.g., why averaging gradient similarities yields effective affinity estimates, or why B-splines are particularly suitable).\n\nThe proposed method introduces several additional hyperparameters (for the B-spline expansion, regression method, and residual prediction), which may complicate tuning and reproducibility."}, "questions": {"value": "Questions for the Authors\n\nWhat is the rationale for time-averaging the cosine similarity over the \nK\nK training steps in Equation (6)? How stable is this measure across training, and how much variability is typically observed?\n\nSince TAG’s affinity scores are on a different scale than observed gains, how does your method correct for this discrepancy?\n\nYou mention that GRAD-TAE performs well for groups — could you include these results in Table 3 for completeness?\n\nCould you provide additional details on the computational requirements of the different methods, particularly in terms of the number of backward passes and the extent of hyperparameter tuning involved?\n\nRecommendation\n\nAlthough some design choices could be better motivated and the performance gains over naive MTL are modest, the paper provides valuable insights into the problem of task grouping. The authors conduct detailed and well-structured experiments, including informative ablation studies that clarify the role of different components within the proposed framework.\n\nAdditional Feedback\n\nFigure 1 is somewhat difficult to interpret, as it presents too many elements at once. Consider splitting it into two complementary figures: one conceptual illustration to convey the overall idea, and another outlining the algorithmic steps in more detail.\n\nSection 4 could be improved for clarity and consistency. Ensure that all discussed results appear in the corresponding tables or figures, and avoid repetition of statements like “TAG achieves higher correlation but incurs significant computational overhead.”\n\nThe term “training cost” could be replaced with “computational cost” for improved clarity.\n\nIn Section 3.1.3, explicitly explain the difference with TAG and refer to the appendix where both affinity measures are compared.\n\nThe discussion of limitations could be expanded. As shown in the appendix, the method performs comparably to naive MTL in some cases, indicating room for improvement and further exploration in future work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2DBbcx4Naz", "forum": "RuVT3PeX1M", "replyto": "RuVT3PeX1M", "signatures": ["ICLR.cc/2026/Conference/Submission22895/Reviewer_LwS8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22895/Reviewer_LwS8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923419984, "cdate": 1761923419984, "tmdate": 1762942428848, "mdate": 1762942428848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Proposed ETAP builds a scalable predictor by computing a gradient-alignment affinity score for pairs and groups in shared parameters, then refining it with learned nonlinear transformations and residual corrections. Across benchmarks, ETAP improves MTL gain prediction and enables more effective task grouping, outperforming used baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "It combines gradient-based affinity with learned non-linear relationship modeling to efficiently and accurately capture task relationships. And it includes thorough component-wise ablations that clarify each contribution and improve interpretability."}, "weaknesses": {"value": "Dividing learning tasks into groups based on similarity is a long-standing area [1]. The paper introduces new measures of task affinity for MTL, but I am not fully convinced that the proposed methods are superior to prior work. The baselines used are relatively dated, and a comparison of computational cost and predictive performance with stronger recent baselines, such as [2], would strengthen the claims. Efficient group-wise tracking of task affinity is also not new, as [3] tracks inter-task affinity in a group-wise manner during multi-task optimization. Finally, I am not convinced that the proposed methods clearly improve over other inter-task affinity tracking approaches, including [4].\n\n[1] Which tasks should be learned together in multi-task learning?\n\n[2] Task Grouping for Automated Multi-Task Machine Learning via Task Affinity Prediction\n\n[3] Selective Task Group Updates for Multi-Task Optimization\n\n[4] Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity"}, "questions": {"value": "It would help to clarify the concrete differences from prior work, especially how your methods distinctively improve on gradient-based affinity and group-wise tracking approaches. Practical guidance on when to prefer your method over more recent baselines would make the contribution clearer."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l5IbmixKZv", "forum": "RuVT3PeX1M", "replyto": "RuVT3PeX1M", "signatures": ["ICLR.cc/2026/Conference/Submission22895/Reviewer_Y2PA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22895/Reviewer_Y2PA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988216160, "cdate": 1761988216160, "tmdate": 1762942428628, "mdate": 1762942428628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}