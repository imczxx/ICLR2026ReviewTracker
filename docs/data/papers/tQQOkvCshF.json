{"id": "tQQOkvCshF", "number": 24560, "cdate": 1758357984611, "mdate": 1759896760553, "content": {"title": "Learning Argumentative Summarization with Iterative Rejection Sampling", "abstract": "Summarization is a fundamental task for evaluating language understanding in both humans and machines, and serves as a crucial tool for information processing in our data-rich world. While large language models (LLMs) have shown significant progress in summarization, they still struggle with domain-specific tasks such as zero-shot medical documentation, legal text, and argumentative summarization. To improve argumentative text understanding and summarization, we propose an iterative fine-tuning framework that trains LLMs on high-quality argument-summary pairs generated by the model itself. These pairs are filtered using similarity scores calculated by comparing reconstructed arguments from summaries with the original arguments, using rejection sampling, without external supervision. Our experiments demonstrate that this method improves argument summarization performance, achieving gains up to 11.88% in BERT F1 similarity scores between reconstructed and original arguments, over the vanilla model without such fine-tuning on a dataset of 200 r/ChangeMyView posts.", "tldr": "", "keywords": ["summarization", "language understanding", "large language models", "LLMs", "domain-specific tasks", "fine-tuning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aae50d0deca6601c9c3f96705beab892658ba32c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a technique to improve argumentation in summarization by iterative fine-tuning of the model on its own outputs after rejection sampling. Under the technique, the model generates summaries to the input argumentative texts and then reconstructs original texts from summaries. The reconstructed texts close enough to the original ones in terms of BERTScore are added as new training examples along with the summaries. \n\nThe technique is evaluated on r/ChangeMyMind dataset with medium-sized models (LLama-3.2@1B,3B, Gemma 3@1B,4B) and compared to baselines DeepSeek V3.1, gpt 4o-mini and Claude Sonnet 4. The authors track average BERT-F1 score across test set and observe that the technique improves BERT F1 between reconstructed and original arguments by 11.88%."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strength of the paper is in a simple yet effective rejection-sampling based technique that results in notable data augmentation and paves the way towards self-learning from seed data."}, "weaknesses": {"value": "The main weakness of the paper is evaluation - measuring BERT F1 is too indirect of a way to assess argumentativeness of the summaries, the main output of the model. Ideally, a set of automatic, LLMaaJ and human metrics would be needed to assess the final downstream impact of the generated data on the faithfulness of model summaries."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Bp7c0OApuz", "forum": "tQQOkvCshF", "replyto": "tQQOkvCshF", "signatures": ["ICLR.cc/2026/Conference/Submission24560/Reviewer_eGrs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24560/Reviewer_eGrs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761467801105, "cdate": 1761467801105, "tmdate": 1762943122028, "mdate": 1762943122028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an iterative rejection-sampling framework designed to improve argumentative summarization in LLMs. The proposed method forms a self-supervised loop in which the model repeatedly generates candidate summaries, reconstructs the original argument from each one, and measures semantic consistency using BERTScore F1. Most consistent pairs are retained for iterative fine-tuning.\nThrough this process, the model gradually learns to produce summaries that are both faithful and informative, without relying on any human-labeled data."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper introduces a clean and logically consistent training scheme that couples summarization and reconstruction within a single self-improving cycle."}, "weaknesses": {"value": "- The experimental analysis is somewhat limited, focusing only on before-and-after fine-tuning results without conducting detailed ablation or thorough studies. The paper lacks comparisons with strong baselines or alternative self-training methods, which makes it difficult to assess external validity and performance competitiveness.\n-  The novelty of the work is also ambiguous, as the framework mainly applies a known idea of self-filtered iterative training to the summarization setting rather than introducing a new algorithmic mechanism.\n- The paper could have incorporated domain-specific knowledge of argumentative texts, but instead it merely applies an existing well-known technique."}, "questions": {"value": "- Is there any comparison results with exiting argumentative summarization datasets or models, and what is the superior of your method?\n- How is the “18-sentence reconstruction” prompt determined, empirically or arbitrarily?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ThReMoukIr", "forum": "tQQOkvCshF", "replyto": "tQQOkvCshF", "signatures": ["ICLR.cc/2026/Conference/Submission24560/Reviewer_g1V8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24560/Reviewer_g1V8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894474931, "cdate": 1761894474931, "tmdate": 1762943121792, "mdate": 1762943121792, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a strategy to enhance the capabilities of Large Language Models (LLMs) for summarizing argumentative texts, by rejection sampling. The core idea is to expand generated summaries back to argumentative texts, which forms additional training pairs to fine-tune LLMs (with rejection based on similarity between the expanded texts and the original input argumentative texts). Experimental results on Reddit’s r/ChangeMyView dataset show that the proposed strategy helps enhance LLMs output quality (measured in BERT score) iteratively."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "S1. This paper studies a practical problem -- enhancing LLMs' capabilities for summarizing argumentative texts.\n\nS2. The proposed strategy is validated on a real dataset (Reddit’s r/ChangeMyView dataset)\n\nS3. The paper is easy to follow."}, "weaknesses": {"value": "W1. While the rejection sampling strategy is simple and intuitive, its actual effectiveness is questionable. The generated summary-expanded text pairs (selected based on similarity with original input argumentative texts) may be too similar to the original training pairs, offering limited additional training signals which might not generalize beyond the input training dataset. \n\nThis is reflected by the performance results in Table 1. The BERT scores of the LLMs tests either drops or do not change much as more training iterations are run, except for one LLM meta-llama/Llama-3.2-3B-Instruct. \n\nThere are no theoretical analysis or cross-dataset results to verify the generalizability of the proposed strategy. \n\nW2. There is no comparison with baseline methods designed for text summarization (e.g., those mentioned in Section 2.1) or strategies designed to exploit or strengthen LLMs for text summarization, e.g.,\n\nFang et al. Multi-LLM Text Summarization, arXiv:2412.15487\n\nOr methods mentioned in:\n\nZhang et al. A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods, arXiv:2403.02901\n\nW3. The choice of hyperparameter values needs clarification, e.g., why \"Expand the following summaries to one argumentative paragraph with 18 sentences\", and why sampled from the model’s distribution with temperature $T = 1.5$ and minimum probability threshold $p_{min} = 0.1$?\n\nW4. While the paper is easy to follow overall due to its simple idea, it could use a full proofread to polish the writing. For example, the introduction section has been written in a way that is unnecessarily complex while not containing much information beyond that argumentative text summarization with LLM is a challenging problem that necessitates further study. The first three paragraphs can be simplified substantially (or just cut)."}, "questions": {"value": "Please refer to the Weaknesses points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "56Sctekv3y", "forum": "tQQOkvCshF", "replyto": "tQQOkvCshF", "signatures": ["ICLR.cc/2026/Conference/Submission24560/Reviewer_CNVL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24560/Reviewer_CNVL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001213634, "cdate": 1762001213634, "tmdate": 1762943121541, "mdate": 1762943121541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}