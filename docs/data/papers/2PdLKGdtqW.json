{"id": "2PdLKGdtqW", "number": 5136, "cdate": 1757853444544, "mdate": 1763396813748, "content": {"title": "From Gradient Volume to Shapley Fairness: Towards Fair Multi-Task Learning", "abstract": "Multi-task learning often suffers from gradient conflicts, leading to unfair optimization and degraded overall performance. To address this, we present SVFair, a Shapley value-based framework for fair gradient aggregation. We propose two scalable geometric conflict metrics: VolDet, a gram determinant volume metric, and VolDetPro, its sign-aware extension distinguishing antagonistic gradients. By integrating these metrics into Shapley value computation, SVFair quantifies each task’s deviation from the overall gradient and rebalances updates toward fairness. In parallel, our Shapley value computation admits controllable complexity. Extensive experiments show that SVFair achieves state-of-the-art results across diverse supervised and reinforcement learning benchmarks, and further improves existing methods when integrated as a fairness-enhancing module.", "tldr": "We introduce SVFair, a fairness-driven  method using Shapley values to quantify and mitigate gradient conflicts in multi-task learning, achieving state-of-the-art performance through the novel Volume Determinant (VolDet and VolDetPro) metric.", "keywords": ["Multi-task Learning", "Shapley Value", "Fair Optimization"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4508d2bb5d6570b65654f52575cde1f9379544ec.pdf", "supplementary_material": "/attachment/c75408e8916c7eb495c3344fa300018cc3c8cef0.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces SVFair, a gradient-based multi-task learning (MTL) method that aims to balance training across tasks in a fairness-aware manner. The authors define two gradient conflict metrics: VolDet, the volume of the parallelotope formed by task gradients (computed via the Gram determinant), and VolDetPro, a signed extension that penalizes negative cosine relations between gradients. These metrics quantify the degree of conflict or synergy among tasks. Using these as importance weights, the paper constructs a single-pass Shapley value approximation that determines each task’s contribution to the joint update. The resulting algorithm adaptively reweights task gradients to seek a Pareto-stationary point near the center of the trade-off front, improving fairness across tasks. Experiments on standard MTL benchmarks show small but consistent improvements in balance metrics compared to simple averaging and prior multi-gradient methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Geometric intuition. The gradient volume concept (Gram determinant of task gradients) provides a tangible geometric measure of task conflict. It’s an appealing visualization tool and a natural extension of cosine-similarity-based conflict measures.\n\nUnified perspective on fairness in MTL. By linking gradient aggregation to task-level “fairness,” the paper situates multi-task balance as a fairness problem, offering conceptual coherence with broader fairness research.\n\nImplementation simplicity. SVFair requires only first-order gradient information and scales linearly in the number of tasks. It’s easy to implement atop existing MTL optimizers and could serve as a practical baseline.\n\nReadable and self-contained. The paper is decently written, with useful algorithm boxes and schematic figures clarifying how VolDet and VolDetPro differ. It’s easy for readers familiar with gradient manipulation to reproduce."}, "weaknesses": {"value": "Lack of originality and differentiation. The key ingredients (gradient alignment metrics and Shapley weighting) are not new. Prior works such as PCGrad (Yu et al., NeurIPS 2020), IMTL-G (Liu et al., 2021), GradVac (Wang et al., 2022), and ParetoMTL (Navon et al., 2022) already addressed gradient conflict and Pareto fairness using similar geometric or cooperative-game ideas. VolDet and VolDetPro are essentially new metrics, not fundamentally new algorithms. Suggestion: The paper should clearly articulate what these new metrics provide beyond previous gradient-conflict measures and why the Shapley approximation adds value.\n\nWeak theoretical grounding. The claim that minimizing VolDetPro “drives the solution toward a front-center Pareto point” is heuristic, no theorem or guarantee is offered. Similarly, the Shapley-value approximation is described qualitatively but without convergence or unbiasedness analysis. Suggestion: Include theoretical propositions linking VolDet/VolDetPro to Pareto-stationarity or fairness guarantees.\n\nEmpirical evaluation is thin. Experiments are small-scale and mostly incremental. Improvements over baselines are minor (often <2%), and no statistical tests are reported. There are few ablations on the role of VolDet vs. VolDetPro or on Shapley-weight computation overhead. Suggestion: Expand experiments to more diverse MTL setups (e.g., computer vision or NLP) and provide detailed comparisons to ParetoMTL, PCGrad, MGDA, and IMTL-G.\n\n“Fairness” interpretation feels overstated. While the method balances gradients, calling it “fairness-aware” is somewhat misleading; the fairness concept here refers only to task balance, not fairness in the social or demographic sense. Suggestion: Use more neutral terminology like “balanced multi-task optimization” to avoid confusion.\n\nUnclear benefit of signed volume (VolDetPro). The proposed “signed” determinant variant is underexplained—why should penalizing negative cosine relations via determinant sign improve convergence? Empirical evidence is insufficient. Suggestion: Provide analytical insight or controlled experiments illustrating when VolDetPro outperforms VolDet.\n\nRelation to prior Shapley gradient methods. Shapley-based gradient allocation (e.g., Ghorbani & Zou, 2019; Yoon et al., 2022) has already been applied to task weighting and feature attribution. The “single-pass approximation” presented here is not clearly compared to these prior formulations. Suggestion: Include a subsection detailing differences in computational complexity and approximation bias.\n\nPositioning in literature. The related work section underplays existing geometric and cooperative-game perspectives on MTL optimization. Without a clearer comparison, readers may perceive SVFair as an incremental tweak rather than a conceptual advance."}, "questions": {"value": "Can you theoretically connect VolDetPro minimization to convergence to a Pareto stationary solution?\n\nHow does your Shapley approximation differ in complexity or quality from prior Shapley-MTL approaches (e.g., Yoon et al. 2022)?\n\nDid you test the sensitivity of the method to task scaling or normalization (since determinant magnitudes can vary drastically)?\n\nWould your framework work for a large number of tasks (the Gram determinant computation scales poorly)?\n\nCan you clarify whether “fairness” here has any formal definition (e.g., equal loss, equal gradient norm) or is purely heuristic?\n\nPlease provide statistical significance or confidence intervals for performance differences.\n\nWould you consider integrating ParetoMTL’s convex combination layer with VolDet weighting to strengthen the theoretical link?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uT4gZVHdJo", "forum": "2PdLKGdtqW", "replyto": "2PdLKGdtqW", "signatures": ["ICLR.cc/2026/Conference/Submission5136/Reviewer_j3fR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5136/Reviewer_j3fR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760777930496, "cdate": 1760777930496, "tmdate": 1762917904109, "mdate": 1762917904109, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to questions about the effectiveness, convergence, and cost–performance trade-off of MC Shapley estimation (Part 1/2)"}, "comment": {"value": "Dear all reviewers,\n\nWe sincerely appreciate your meticulous reviews. It has come to our attention that, quite remarkably, several of you have independently pointed out the following common concerns. We truly value these insights as they will undoubtedly contribute significantly to enhancing the quality of our work. The concerns are as follows:\n\n(i) the computational cost of Shapley values,\n\n(ii) the effectiveness and convergence of the Monte Carlo (MC) approximation under different task scales\n\n(iii) whether increasing the number of sampled subsets actually improves downstream performance. \n\nWe will address these comments together in this response. \n\n### 1. **Analysis of the Convergence of Monte Carlo Estimation for Shapley Values**\n\nFor any task subset $S$, the VolDet utility satisfies $$0 \\le v(S) = \\det(\\mathcal{M}_S) \\le 1.$$ \n\nHence each marginal contribution in the permutation-based MC estimator,  $\\Delta_i(S) = v(S \\cup \\{i\\}) - v(S),$ is bounded in an interval of width $B \\le 2$.  Together with uniform sampling over permutations, this yields an **unbiased** and **bounded** MC estimator of the Shapley values.\nIn Appendix G we derive the following Hoeffding-style concentration bound:\n$$\n\\Pr\\Bigl( \\bigl\\| \\widehat{\\boldsymbol{\\phi}} - \\boldsymbol{\\phi} \\bigr\\|_\\infty > \\varepsilon\n\\Bigr)\\le 2N \\exp\\Bigl(- \\frac{2K \\varepsilon^2}{B^2} \\Bigr).\n$$\n\nThis inequality shows that the deviation $\\bigl\\|\\widehat{\\boldsymbol{\\phi}} - \\boldsymbol{\\phi}\\bigr\\|_\\infty$ \nshrinks at rate $\\mathcal{O}(1/\\sqrt{K})$ as the number of MC samples $K$ increases. More detail is provided in Appendix G.\n\n\n\n### 2. **Empirical results validate the effectiveness and convergence of MC Shapley Value**\n\nWe report an experiment to empirically validate the effectiveness and convergence of MC Shapley. We collect gradient Gram matrices from Office-31 ($N = 3$) and from CelebA ($N = 40$). For CelebA, we randomly sample task subsets of size  $N_{\\text{sub}} \\in \\{10, 15, 20\\}$  and extract the corresponding VolDet submatrices.\n\nFor each matrix, we compute both exact Shapley values and their MC approximation using our permutation-based estimator, for MC samples  $K \\in \\{100, 250, 500, 1000, 2000\\}.$  We then measure the MSE between exact and MC Shapley values and average over 10 matrices.\n\n**Table 1.** Results on Office-31 and CelebA\n\n| Sample Size $K$ | Office-31 ($N=3$) | CelebA ($N=10$) | CelebA ($N=15$) | CelebA ($N=20$) |\n|---|---|---|---|---|\n| $$100$$  | $$9.18\\times10^{-5}$$ | $$1.96\\times10^{-5}$$ | $$5.95\\times10^{-6}$$ | $$3.19\\times10^{-6}$$ |\n| $$250$$  | $$1.05\\times10^{-4}$$ | $$2.13\\times10^{-5}$$ | $$3.07\\times10^{-6}$$ | $$1.48\\times10^{-6}$$ |\n| $$500$$  | $$5.84\\times10^{-5}$$ | $$1.38\\times10^{-5}$$ | $$2.49\\times10^{-6}$$ | $$1.77\\times10^{-6}$$ |\n| $$1000$$ | $$0.671\\times10^{-5}$$ | $$1.28\\times10^{-5}$$ | $$2.26\\times10^{-6}$$ | $$1.33\\times10^{-6}$$ |\n| $$2000$$ | $$5.36\\times10^{-5}$$ | $$1.25\\times10^{-5}$$ | $$1.87\\times10^{-6}$$ | $$1.28\\times10^{-6}$$ |\n\nWe make two observations from the Table 1:  \nA. For all large-task settings ($N_{\\text{sub}}\\ge 10$), the MSE rapidly decreases as $K$ grows and essentially plateaus once $K \\ge 1000$. This confirms that the choice $K=1000$ in the CelebA experiments is well justified: increasing to $K=2000$ provides almost no benefit while nearly doubling the Shapley-related computation.\n\nB. For the small-task case (Office-31, $N=3$), exact Shapley is cheap so MC is unnecessary. The slight non-monotonic rebound at $K=2000$ is typical Monte Carlo noise at the $10^{-5}$ level rather than a systematic issue, and it has no impact on our method\nbecause we never rely on MC in such small-$N$ settings.\n\nOverall, these results directly support the **effectiveness** and **convergence** of the MC Shapley estimator."}}, "id": "lxS4xvljs3", "forum": "2PdLKGdtqW", "replyto": "2PdLKGdtqW", "signatures": ["ICLR.cc/2026/Conference/Submission5136/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5136/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5136/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763383514979, "cdate": 1763383514979, "tmdate": 1763383576792, "mdate": 1763383576792, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to questions about the effectiveness, convergence, and cost–performance trade-off of MC Shapley estimation (Part 1/2)"}, "comment": {"value": "Dear all reviewers,\n\nWe sincerely appreciate your meticulous reviews. It has come to our attention that, quite remarkably, several of you have independently pointed out the following common concerns. We truly value these insights as they will undoubtedly contribute significantly to enhancing the quality of our work. The concerns are as follows:\n\n(i) the computational cost of Shapley values,\n\n(ii) the effectiveness and convergence of the Monte Carlo (MC) approximation under different task scales\n\n(iii) whether increasing the number of sampled subsets actually improves downstream performance. \n\nWe will address these comments together in this response.  We highlight all revised text in the main paper in orange. For the appendix, we mark the section titles in orange to indicate which appendix sections have been updated.\n\n### 1. **Analysis of the Convergence of Monte Carlo Estimation for Shapley Values**\n\nFor any task subset $S$, the VolDet utility satisfies $$0 \\le v(S) = \\det(\\mathcal{M}_S) \\le 1.$$ \n\nHence each marginal contribution in the permutation-based MC estimator,  $\\Delta_i(S) = v(S \\cup \\{i\\}) - v(S),$ is bounded in an interval of width $B \\le 2$.  Together with uniform sampling over permutations, this yields an **unbiased** and **bounded** MC estimator of the Shapley values.\nIn Appendix G we derive the following Hoeffding-style concentration bound:\n$$\n\\Pr\\Bigl( \\bigl\\| \\widehat{\\boldsymbol{\\phi}} - \\boldsymbol{\\phi} \\bigr\\|_\\infty > \\varepsilon\n\\Bigr)\\le 2N \\exp\\Bigl(- \\frac{2K \\varepsilon^2}{B^2} \\Bigr).\n$$\n\nThis inequality shows that the deviation $\\bigl\\|\\widehat{\\boldsymbol{\\phi}} - \\boldsymbol{\\phi}\\bigr\\|_\\infty$ \nshrinks at rate $\\mathcal{O}(1/\\sqrt{K})$ as the number of MC samples $K$ increases. More detail is provided in Appendix G.\n\n\n\n### 2. **Empirical results validate the effectiveness and convergence of MC Shapley Value**\n\nWe report an experiment to empirically validate the effectiveness and convergence of MC Shapley. We collect gradient Gram matrices from Office-31 ($N = 3$) and from CelebA ($N = 40$). For CelebA, we randomly sample task subsets of size  $N_{\\text{sub}} \\in \\{10, 15, 20\\}$  and extract the corresponding VolDet submatrices.\n\nFor each matrix, we compute both exact Shapley values and their MC approximation using our permutation-based estimator, for MC samples  $K \\in \\{100, 250, 500, 1000, 2000\\}.$  We then measure the MSE between exact and MC Shapley values and average over 10 matrices.\n\n**Table 1.** Results on Office-31 and CelebA\n\n| Sample Size $K$ | Office-31 ($N=3$) | CelebA ($N=10$) | CelebA ($N=15$) | CelebA ($N=20$) |\n|---|---|---|---|---|\n| $$100$$  | $$9.18\\times10^{-5}$$ | $$1.96\\times10^{-5}$$ | $$5.95\\times10^{-6}$$ | $$3.19\\times10^{-6}$$ |\n| $$250$$  | $$1.05\\times10^{-4}$$ | $$2.13\\times10^{-5}$$ | $$3.07\\times10^{-6}$$ | $$1.48\\times10^{-6}$$ |\n| $$500$$  | $$5.84\\times10^{-5}$$ | $$1.38\\times10^{-5}$$ | $$2.49\\times10^{-6}$$ | $$1.77\\times10^{-6}$$ |\n| $$1000$$ | $$0.671\\times10^{-5}$$ | $$1.28\\times10^{-5}$$ | $$2.26\\times10^{-6}$$ | $$1.33\\times10^{-6}$$ |\n| $$2000$$ | $$5.36\\times10^{-5}$$ | $$1.25\\times10^{-5}$$ | $$1.87\\times10^{-6}$$ | $$1.28\\times10^{-6}$$ |\n\nWe make two observations from the Table 1:  \nA. For all large-task settings ($N_{\\text{sub}}\\ge 10$), the MSE rapidly decreases as $K$ grows and essentially plateaus once $K \\ge 1000$. This confirms that the choice $K=1000$ in the CelebA experiments is well justified: increasing to $K=2000$ provides almost no benefit while nearly doubling the Shapley-related computation.\n\nB. For the small-task case (Office-31, $N=3$), exact Shapley is cheap so MC is unnecessary. The slight non-monotonic rebound at $K=2000$ is typical Monte Carlo noise at the $10^{-5}$ level rather than a systematic issue, and it has no impact on our method\nbecause we never rely on MC in such small-$N$ settings.\n\nOverall, these results directly support the **effectiveness** and **convergence** of the MC Shapley estimator."}}, "id": "lxS4xvljs3", "forum": "2PdLKGdtqW", "replyto": "2PdLKGdtqW", "signatures": ["ICLR.cc/2026/Conference/Submission5136/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5136/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5136/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763383514979, "cdate": 1763383514979, "tmdate": 1763396469349, "mdate": 1763396469349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the common issue of gradient conflicts in multi-task learning, which can lead to unfair optimization among tasks. The authors propose SVFair, a Shapley value–based framework designed to quantify and mitigate such unfairness. Specifically, they introduce two geometric conflict metrics: (1) VolDet, a Gram-determinant-based volume metric that measures the geometric diversity of task gradients, and (2) VolDetPro, a sign-aware extension that distinguishes antagonistic gradients. By integrating these metrics into Shapley value computation, SVFair evaluates each task’s deviation from the aggregated gradient and rebalances the updates to improve fairness. Extensive experiments across both supervised and reinforcement learning benchmarks demonstrate that SVFair achieves state-of-the-art performance and can serve as a fairness-enhancing plug-in module for existing multi-task optimization methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a novel approach that combines Shapley-value-based fairness reasoning with gradient conflict measurement in multi-task learning. \n\n2. The method is well-motivated and theoretically solid. The analysis is detailed and convincing, providing clear justification for the proposed metrics and their role in achieving fair optimization.\n\n3. The experimental evaluation is extensive, covering both supervised and reinforcement learning settings. Results demonstrate strong performance improvements and fairness benefits over several competitive baselines.\n\n4. The authors have released code, which greatly improves the reproducibility and credibility of the work."}, "weaknesses": {"value": "1. The core contribution of the proposed SVFair framework lies in computing Shapley values based on the newly defined VolDet and VolDetPro conflict metrics. However, once these weights are obtained, the subsequent problem formulation and solution procedure (Sec. 4.3) largely follow prior works such as FairGrad and PIVRG, and the corresponding convergence analysis also remains very similar. This overlap somewhat weakens the theoretical novelty of the paper.\n\n2. Although the authors conducted an ablation study on the temperature coefficient $\\tau$ in Table 4, they did not provide further theoretical analysis or practical guidance for tuning this parameter. In particular, the optimal $\\tau$ varies across tasks and does not show a consistent trend (for example, in the Cityscapes experiment, performance first drops and then improves as $\\tau$ increases). I believe the authors should include a more thorough investigation and discussion to clarify the role of $\\tau$ and how it should be selected.\n\n3. The overall presentation could be improved. For instance, the abstract is overly concise and does not sufficiently describe the problem background or the core motivation behind introducing Shapley-value-based fairness reasoning. A slightly more detailed introduction would help readers better understand the context and significance of the proposed approach."}, "questions": {"value": "1. The computational cost of Shapley value estimation grows exponentially with the number of tasks, as also acknowledged by the authors. To address this, the paper employs Monte Carlo subset sampling to approximate the Shapley values. However, increasing the number of sampled subsets should, in principle, improve the estimation accuracy. Would this lead to better downstream performance (e.g., in terms of fairness or overall task accuracy)? I encourage the authors to include an ablation study on the number of sampled subsets to clarify the trade-off between computational cost and performance.\n\n2. Referring to Weakness 2, while the authors conducted ablation experiments on the temperature coefficient $\\tau$, they did not provide further theoretical insights or practical guidance on how to choose this parameter. Could the authors elaborate on how $\\tau$ influences the optimization dynamics, and whether any general guidance or heuristic can be derived from the observed trends?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5vAzINZEa5", "forum": "2PdLKGdtqW", "replyto": "2PdLKGdtqW", "signatures": ["ICLR.cc/2026/Conference/Submission5136/Reviewer_gTqY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5136/Reviewer_gTqY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761736368882, "cdate": 1761736368882, "tmdate": 1762917903810, "mdate": 1762917903810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes two novel geometric gradient conflict measures, VolDet and VolDetPro, which quantify the squared volume of a subset of normalized task gradients. It then uses Shapley values to attribute each task's contribution to gradient conflict, and this information is incorporated into an existing fairness-based MTL optimization framework. Experiments on a suite of MTL benchmarks demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduced VolDet and VolDetPro metrics are novel, and they can capture the geometric misalignment across task gradients.\n2. The Shapley values further leverage the VolDet/VolDetPro and lead to the overall per-task weights quantifying contribution to the misalignment. This angular-driven measure is also novel.\n3. Theoretical analysis and extensive empirical studies are provided, which can demonstrate the effectiveness of the proposed SVFair framework."}, "weaknesses": {"value": "1. Line 240-241 states that higher $\\phi_i$ values indicate task $i$ is more misaligned with others and should be assigned a lower influence. It may be a typo. It seems that such tasks should actually be assigned higher influence, as mentioned in Eq. (7) and Line 2093–2094.\n2. The volume metric is built on the normalized task gradients. It ignores the magnitude information. Although the term $g_i^\\top d$ in Eq. (7) considers magnitude information, it may lead to a suboptimal solution. For example, consider two approximately aligned task gradients, but with very different magnitudes. They have similar Shapley value weights, and Eq. (7) reduces to $\\arg\\min \\sum_i \\frac{1}{g_i^\\top d}$, which corresponds to the minimum potential delay (MPD) fairness in FairGrad [1].  This MPD fairness criterion may not be suitable for this case, thus leading to suboptimal solutions. \n3. The calculation of the Shapley value introduces additional cost at each training step. Though Table 5 shows that the cost can be mitigated by Monte Carlo subset sampling, an ablation study is still needed to demonstrate the necessity of using Shapley value weights. The VolDet and Shapley value are two independent and separable concepts. It would be informative to compare them with other simpler weighting strategies, such as $\\phi_i^\\prime=\\sum_{i, j\\neq i} M_{ij}$, where a larger value indicates better alignment. You do not necessarily need to use this example; what I want to express is that it would be better to provide ablation studies to show that the Shapley value provides sufficient benefit compared to its additional cost."}, "questions": {"value": "See the discussion in weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Zc5fszTqHj", "forum": "2PdLKGdtqW", "replyto": "2PdLKGdtqW", "signatures": ["ICLR.cc/2026/Conference/Submission5136/Reviewer_Mspw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5136/Reviewer_Mspw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761767463198, "cdate": 1761767463198, "tmdate": 1762917903445, "mdate": 1762917903445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SVFair, a Shapley value-based framework for fair multi-task learning (MTL) that systematically quantifies and mitigates gradient conflicts among tasks. The authors introduce two utility functions, named as VolDet and VolDetPro, to compute Shapley values in a single training pass. These values are then used to guide gradient aggregation, promoting balanced optimization across tasks. Extensive experiments on supervised and reinforcement learning benchmarks demonstrate that SVFair achieves state-of-the-art performance and improves existing MTL methods when integrated as a fairness module."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "++ The paper integrates Shapley values into MTL optimization for quantifying gradient deviation and conflict at a subset level. The proposed VolDet and VolDetPro metrics offer ageometric perspective on gradient interactions.\n\n++ The method is well-motivated and theoretically grounded, with convergence guarantees to Pareto stationary points under reasonable assumptions.\n\n++ SVFair demonstrates strong empirical performance across diverse benchmarks (e.g., NYU-v2, CelebA, MT10) and can be easily integrated into existing MTL methods, enhancing their fairness and performance. The framework is scalable and supports Monte Carlo sampling for large-task settings."}, "weaknesses": {"value": "-- Although the complexity is dominated by the training cost, the exact Shapley value computation can be prohibitive for very large N (number of tasks). While Monte Carlo sampling is proposed, its effectiveness and convergence properties are not thoroughly analyzed or empirically validated across different task scales."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JznIKJd95F", "forum": "2PdLKGdtqW", "replyto": "2PdLKGdtqW", "signatures": ["ICLR.cc/2026/Conference/Submission5136/Reviewer_563x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5136/Reviewer_563x"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991567630, "cdate": 1761991567630, "tmdate": 1762917903025, "mdate": 1762917903025, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}