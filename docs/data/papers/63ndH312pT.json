{"id": "63ndH312pT", "number": 22387, "cdate": 1758330425240, "mdate": 1759896868967, "content": {"title": "LARO: Learning-Accelerated Two-Stage Adaptive Robust Optimization with Relaxation Guarantees", "abstract": "Two-stage Adaptive Robust Optimization (ARO) with discrete and polyhedral uncertainty sets incorporates \"wait-and-see\" decisions to reduce conservatism but remains intractable due to its multi-level structure and mixed-integer recourse. This paper introduces LARO, a learning-accelerated two-phase decomposition framework that scales ARO efficiently without embedding neural networks (NNs) into optimization models. The framework operates in two phases: a Relaxed Master Problem (RMP) that identifies candidate here-and-now decisions through a penalized selection mechanism, where pre-computed severity scores bias scenario choice toward adversarial cases, and a verification phase that ensures restricted worst-case consistency. By decoupling the NN from the RMP, we eliminate solver-compatible embeddings, reduce computational overhead, and enable the use of more expressive neural architectures for recourse evaluation in the adversarial step.  \n\nWe establish finite convergence, with the number of iterations bounded by the size of the discrete uncertainty set, and show that the penalized RMP preserves valid lower bound while improving iteration efficiency by prioritizing impactful scenarios. Experiments on robust knapsack and unit commitment problems in power grids demonstrate the scalability of the framework, achieving runtime speedups of up to 10^3 times for knapsack instances and 10^2 times for a 24-bus power network compared to classical column-and-constraint generation. The solve spped is achieved while maintaining optimality gaps typically below 7% for knapsack instances and 2% on the UC problems. This work delivers a severity-aware, learning-accelerated CCG that is both scalable and certifiable, advancing robust decision-making under uncertainty.", "tldr": "", "keywords": ["Adaptive Robust Optimization", "Two-Phase Decomposition", "Machine Learning", "Uncertainty Sets", "Accelerated Column-and-Constraint Generation"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5d355a72ec3fc9d4fa638b936291e4e4957c5697.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors study two-stage robust optimization problems which are computationally very demanding. They study the column-and-constraint algorithm which can be used to solve the latter problems exactly, however, it suffers from poor runtimes since iteratively an expensive master and adversarial problem has to be solved. Based on the idea in Dumouchelle et al. (2023) the authors of this paper use trained neural networks to approximate the value of the second-stage problem. However, they do not embed the neural network into the master and adversarial problem, but only use forward passes in their algorithm."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The problems tackled in this work are very relevant in the robust optimization literature.\n\nThe idea of avoiding the embedding of neural network MIP formulations into the optimization problems solved during the CCG is innovative and has high potential (however, I have to say not in the way the authors did this)."}, "weaknesses": {"value": "The paper has several fundamental weaknesses, both methodological and in terms of presentation.\n\n1. I think the whole convergence analysis is flawed. The authors claim to have a lower bound (LB) and and upper bound (UB) and that the gap between both is closed after finite time. However, I think this is not true. Even if we do not use a NN-approximation but solve the adversarial problem and Problem P_2 exactly, then the lower bound which their algorithm provides will never hit the optimal value over time in general (maybe in some artificial special cases). The reason is that the LB is the optimal value of a single scenario problem, but this is usually strictly smaller than the optimal value of the problem. This is clearly the case since the solution x calculated by the master problem must not be feasible for all the other (non-selected) scenarios. Since there is not rigorous proof presented for the convergence, I cannot believe that it is true. Furthermore, when using neural network approximations in all the subproblems, this is even more unclear why the convergence should be true. \n2. Due to the issues discussed in Point 1, I think there are situations where your algorithm does not return even a feasible solution of the robust problem. Imagine you added all scenarios from \\hat \\Sigma to the master problem. Now your master problem can only return solutions x which are optimal for one of the single-scenario problems. However there may be situations where all these optimal solutions are not feasible for the robust problem.\n3. The authors mention the works from Bertsimas and Kim and Dumouchelle et al. and state that they discretize the scenarios. This is not true. In Dumouchelle et al. the authors find solutions for the problem with full convex uncertainty sets \\Sigma. Using only a finite number of scenarios as in this paper is definitely a limitation.\n4. The authors should obviously compare their algorithm to the one of Dumouchelle et al.. However, there is no comparison to any other method given in the experiments."}, "questions": {"value": "1. How can you prove that your algorithm converges?\n2. If it converges, does it always return a feasible solution x for the 2RO problem?\n3. If it always returns a feasible solution for the 2RO problem, how far from optimal is it? Can you provide an approximation guarantee for certain special cases similar as in [1]?\n4. How good does your algorithm perform compared to other state-of-the-art methods?\n\n\n[1] Dumouchelle, J., Julien, E., Kurtz, J., & Khalil, E. B. (2023). Deep Learning for Two-Stage Robust Integer Optimization. arXiv preprint arXiv:2310.04345."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "e6vLiSzlHG", "forum": "63ndH312pT", "replyto": "63ndH312pT", "signatures": ["ICLR.cc/2026/Conference/Submission22387/Reviewer_8DUc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22387/Reviewer_8DUc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760626496680, "cdate": 1760626496680, "tmdate": 1762942195780, "mdate": 1762942195780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an accelerated approach for adjustable robust optimization (ARO).  The approach relies on using a learning model to predict the value of a decision-scenario pair ($x$, $\\xi$), then optimizing over the model to find worst-case scenarios for first-stage decisions found throughout the solving process.  To find first-stage solutions, the authors introduce a relaxed master problem and an iterative solution refinement procedure.  Computationally, the approach yields solutions significantly faster than standard column-and-constraint generation (CCG), with only minor reductions in solution quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Methodological Motivation**: Overall, this paper provides a new learning-based framework for adjustable robust optimization with discrete uncertainty sets.  \n- **Computational Results**: The authors present relatively strong computational results, with the ML variant of the method obtaining quite strong performance in terms of computing time, with somewhat limited sacrifices to solution quality."}, "weaknesses": {"value": "- **Discrete Uncertainty Sets**: The paper assumes discrete uncertainty sets in all experiments and theoretical claims, yet never discusses how these are constructed or how discretization affects robustness quality. As a result, the reported “finite termination” and “certified lower bound” guarantees hold only for the sampled scenario sets, not for any underlying continuous uncertainty region (which is actually studied in the robust knapsack and unit commitment problems benchmarked on).  This omission is important since the tractability and robustness of ARO hinge critically on how the uncertainty set is discretized, with trade-offs between actual robustness and computational complexity.  The paper doesn't explicitly mention this, which is a significant issue that needs to be addressed in a discussion. If applicable, the robustness of the results should be reported and compared to the true underlying budgeted sets.  I believe that the solutions to the knapsack problem from [1,2] are publicly available, so evaluating the actual robustness of the solutions from the discretized CCG, accelerated CCG, and ML-accelerated CCG should be possible.  Beyond this, the authors discuss related ML-based approaches [1,3] that utilize discretized uncertainty sets; however, this is not the case, as both use continuous uncertainty sets.  The authors also later state that they use the discretized uncertainty sets from [1], but [1] does not have discretized sets.  There is some level of inconsistency/misreporting happening here, so this is a significant concern.  \n- **Lower bounds**: The paper repeatedly emphasizes its “certified lower bounds” as if they provide assurance about the quality or robustness of the final solution. In reality, these bounds only guarantee that the relaxed single-scenario subproblem ($\\mathcal{P}_1$) underestimates the actual worst-case cost, a property that is mathematically valid but trivial. They do not imply that the returned decision is robust, feasible under all uncertainties, or near-optimal for the original problem. This framing risks misleading readers into interpreting an internal consistency check as a guarantee of solution quality.\n- **Methodological Issues with Algorithm 1**:  In my view, Algorithm 1 may be problematic since it cuts off scenarios from the scenario set somewhat arbitrarily. The reason for this is that the relaxation is a pure minimization problem that determines the decisions and scenarios. \nThe scenarios identified may, in fact, be the worst-case scenarios for the true minimizer, but they are the best-case scenarios for the decision found in phase 1, which would lead us to discard that particular scenario immediately.  For example, consider the uncertainty set \n$\\{[1,0], [0,1], [0.5,0.5]\\}$ and the (single-stage) robust optimization problem with an objective of $(1 + 3\\xi_1)x_1 + (1.5 + \\xi_2)x_2$\nand constraints $x_1 + x_2 \\ge 1$, with $x$ binary.  For this problem, the optimal solution will be $x^* = [0,1]$ with the worst-case uncertainty $\\xi^* = [0,1]$ and an objective of $2.5$.  Now, we can consider what happens in Algorithm 1 (note that I am assuming $|\\Xi_t|$ decreases as well within the scope of Algorithm 1).\n  - **Iteration 1**: If we consider the relaxed master problem (phase 1), then the pure minimization problem over both $x$ and $(\\xi$ returns $x' = [1,0]$ and $\\xi' = [0,1]$ (objective of $1$).  In phase 2, we would realize the $\\xi = [1,0]$ is the worst scenario for $x'$ (objective of $4$), so we add a cut to ensure $\\xi' = [0,1]$ is not selected again and resolve phase 1.\n  - **Iteration 2**: In this iteration the remaining scenarios are $\\{[1,0], [0.5,0.5]\\}$, so solving the minimization problem yields $x'' = [0,1]$ and $\\xi'' = [1,0]$ (objective of $1.5$), and in phase 2, we would realize $\\xi = [0.5,0.5]$ is the worst case for $x''$ \n    (objective of $2$), so we cut off $\\xi'' = [1,0]$.\n  - **Iteration 3**: In the last iteration, we have a single remaining scenario $\\{[0.5,0.5]\\}$, so solving the relaxed master problem yields \n    $x''' = [1,0]$ and $\\xi''' = [0.5,0.5]$ (objective of $2.5$), at which point the best- and worst-case coincide, so we would terminate.\n    \n  Algorithm 1 does not explicitly state that the size of $\\Xi_t$ decreases in phase 2.  However, if it did not, the $\\xi = [1,0]$ would be worse (objective of $4$), and we would cut off this scenario, making $P_1$ infeasible (all $z_k = 0$), but we require $\\sum z_k = 1$).  Used on its own, I see major issues with Algorithm 1 that lead me to be quite skeptical of its reasonableness as a relaxation.  \n\n- **ML-based solution quality**: Compared to [1], both the computing time and solution quality trade-offs are not clear.  For example, on the most difficult knapsack instances, [1] reports solutions that are better than branch-and-price [2], which are likely better than the CCG with a discretized uncertainty set (although this needs to be compared), which are about $2-5\\%$ better than the ML-augmented CCG from this work.  [1] takes a few seconds, whereas this approach takes about 0.5 seconds.  For that reason, there is no clear trade-off, as both are pretty efficient, and the solution quality of the proposed method may be significantly worse (although it is not directly compared).  Another issue I can see with larger instances in this context is that the dimension of the knapsack (and therefore uncertainty) increases; I believe this would make discretizations weaker."}, "questions": {"value": "- $xi$ should be $\\xi$ on line 299.  \n- Do the authors have any insight into how the discretization of the uncertainty sets affects the robustness of the solution? How does the number of scenarios affect this?\n- Why does the author not compare to [1,2] for the knapsack problem?\n- Can the authors provide clarity on the usefulness of the lower bound in this case?\n- If scenarios are removed with cuts, can they be added back in within Algorithm 2?  If so, could this lead to termination issues?\n- Is the robustness of the solution for each method evaluated on the same discrete scenario set?\n- Given that this work takes notable inspiration from [1], is there a reason the capital budgeting benchmark was not evaluated on? In addition, it appears [1] has been extended in [4] with evaluation on more complex facility location problems in [4], have the authors considered exploring these benchmarks?\n\nI am happy to discuss during the rebuttal phase.\n\n\n## References\n- [1] Justin Dumouchelle, Esther Julien, Jannis Kurtz, and Elias Boutros Khalil. Neur2RO: Neural two-stage\nrobust optimization. In The Twelfth International Conference on Learning Representations.\n- [2] Ayse N Arslan and Boris Detienne. Decomposition-based approaches for a class of two-stage robust\nbinary optimization problems. INFORMS journal on computing, 34(2):857–871, 2022.\n- [3] Dimitris Bertsimas and Cheol Woo Kim. A machine learning approach to two-stage adaptive robust\noptimization. European Journal of Operational Research, 319(1):16–30, 2024.\n- [4] Justin Dumouchelle, Esther Julien, Jannis Kurtz, and Elias B Khalil. Deep learning for two-stage robust\ninteger optimization. arXiv preprint arXiv:2310.04345, 2023."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "a9IMWd8f0q", "forum": "63ndH312pT", "replyto": "63ndH312pT", "signatures": ["ICLR.cc/2026/Conference/Submission22387/Reviewer_Pm2R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22387/Reviewer_Pm2R"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882622710, "cdate": 1761882622710, "tmdate": 1762942195579, "mdate": 1762942195579, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes a learning-assisted column-and-constraint generation algorithm for two-stage adaptive robust optimization with finite uncertainty sets. Unlike previous neural network-based approaches that identify worst-case uncertainty realizations by solving a mixed-integer program, the proposed solution algorithm only requires a (relatively computationally inexpensive) single forward pass in which it predicts the recourse value of all elements of the uncertainty set. In Proposition 1, the authors show that the solution to the main problem of the proposed algorithm necessarily underestimates (or equals) the true problem objective. The proposed algorithm is experimentally evaluated against two benchmark approaches -- an accelerated-CCG algorithm that does not leverage a predictive model and a classical CCG approach -- with respect to optimality gap and runtime for the knapsack problem and the unit commitment problem. Experimental results demonstrate substantial reductions in solution time -- up to two orders of magnitude in some cases. However, this came at a cost to solution quality, which resulted in median optimality gaps of 7\\% (resp. 2\\%) and maximum optimality gaps of 13\\% (resp. 8.5\\%) for the knapsack and unit commitment problems respectively."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Proposes a two-phase learning-augmented framework that decouples prediction from optimization, removing the need for MILP-embedded neural networks.\n\nProvides a lower-bound guarantee (Proposition 1) and a transparent decomposition algorithm that is easy to reproduce.\n\nRuntime improvements compared to classical CCG, supported by systematic experiments on two benchmark problems."}, "weaknesses": {"value": "The paper focuses on a specific subclass of adaptive robust optimization problems with a finite uncertainty set, rather than the more general continuous setting. The practical motivation for this framework is not clear, as such an assumption is uncommon in the ARO literature; robust optimization typically aims to ensure robustness of decisions that generalizes beyond a finite sample of observations. Is this a common assumption? If so, the authors should cite related works. If not, perhaps the authors can empirically demonstrate that the approach performs well as an approximation to more standard formulations with continuous uncertainty sets. \n\n It is not obvious that the reported speed-ups justify the relatively high optimality gaps observed, particularly in the unit commitment case. While the reductions in runtime are substantial, the benefit of solving the unit commitment problem in 2 seconds rather than 3 minutes does not have clear utility if it comes at a cost of up to 8.5\\% suboptimality, especially given that such problems are typically solved on a relatively infrequent (e.g., daily or hourly) basis. Clarifying the practical implications of this tradeoff would strengthen the contribution.\n\nProposition 1 appears to offer limited insight as the result is fairly intuitive: considering only a subset of the uncertainty set provides a lower bound on the optimal value of $\\mathcal{P}$. Results that \\textit{tighten upper bounds} are generally of greater practical relevance as they offer guarantees of solution quality and feasibility under uncertainty. This work would benefit from focusing more on such results or on demonstrating how Proposition 1 provides additional value in practice.\n\nHave the authors compared runtimes to those obtained by simply solving the full single-level reformulation of the problem (i.e., with variables and constraints defined for all $\\xi\\in\\hat{\\Xi}$)? It is not immediately clear to the reviewer that CCG would necessarily achieve a lower runtime than this baseline, so such a comparison could more clearly highlight the advantages of the proposed approach."}, "questions": {"value": "Revisions needed though not necessarily sufficient for an ``accept'' recommendation:\n\nThe work would benefit from additional justification of the proposed formulation and the class of accelerated CCG algorithms. One possible way to do this would be through an out-of-sample evaluation comparing (1) ML-accelerated CCG with a finite uncertainty set, (2) accelerated CCG or the single-level extensive formulation using the same uncertainty set, and (3) a traditional CCG formulation with continuous uncertainty. Ideally, runtime improvements should be demonstrated with minimal losses in optimality (e.g., all cases achieving a $<1\\%$ optimality gap).\n\nProposition 1 could be removed or replaced with a result that provides a stronger analytical contribution, such as a guarantee on bounded suboptimality/infeasibility of the ML-accelerated approach as an approximation of the original problem."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wHMYYSluLh", "forum": "63ndH312pT", "replyto": "63ndH312pT", "signatures": ["ICLR.cc/2026/Conference/Submission22387/Reviewer_buEc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22387/Reviewer_buEc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903319986, "cdate": 1761903319986, "tmdate": 1762942195371, "mdate": 1762942195371, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission presents LARO, a learning-based method integrated within column-and-constraint generation (CCG) approaches to solving adaptive robust optimization (ARO) problems. Specifically, the paper:\n* Presents a two-phase decomposition of master problem solving within CCG, which (1) aims to select a worst-case realization of uncertainty via a one-hot \"severity-weighted\" selection model (where the severity is calculated using a neural network), and (2) uses an exact verification step to verify the choice and potentially rectify it if needed via a cutting-plane.\n* Within the adversarial problem, uses a neural network approximation for the value function.\n* Trains both neural networks on the same data, using supervised learning with supervised instances generated offline.\n* Presents results on two-stage robust knapsack and a version of unit commitment (with a linearized second-stage and polyhedral demand uncertainty)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The overall method is reasonably sound and well-motivated, aiming to avoid some of the computational complexity associated with prior methods to integrate ML into CCG. The method is generally clear and well-described.\n* The method provides certifiable lower bounds.\n* The method is tested on reasonably large-scale knapsack problems, with median optimality gaps within 3% for sizes greater than 30, orders-of-magnitude faster solution times than exact or non-ML-accelerated CCG, and all gaps being non-negative (i.e., lower bound is preserved).\n* The results for linearized unit commitment are quite impressive, with median optimality gaps of 2% for the 24-bus system (competitive with non-ML-accelerated CCG), and with a two orders-of-magnitude speedup over the traditional solver."}, "weaknesses": {"value": "Major/medium:\n* Data generation can be expensive given the supervised nature of the method, and the time to generate data and train the algorithm is not reported. While this is offline time rather than online time, seeing this would be helpful in evaluating the time tradeoffs at hand.\n* The results on smaller knapsack problems are not good, with median optimality gaps of 7% (and maxes substantially higher) despite the fact that accelerated CCG does well on these instances.\n\nMinor:\n* Introduction: While ARO is described as an extension of RO to \"mitigate excessive conservatism,\" it seems that these are instead related but different frameworks that apply in different settings. Notably, it would be incorrect to partition a set of \"here-and-now\" variables (in RO) into two sets of \"here-and-now\" and \"wait-and-see\" variables (in ARO) unless the problem setting actually warrants this. The introduction could be slightly updated accordingly.\n* Introduction (and abstract): In the writing, the contributions are framed not with respect to ARO methods (or ML for ARO methods) more generally, but with respect to a specific subclass of ML for ARO methods. This makes it difficult to interpret the contributions for someone who is not already very immersed in this specific subclass of methods. More context on the what the method is actually doing could be provided ahead of the listing of contributions.\n* The abbreviation AP should be defined before it is used.\n* The submission should use \\citep{} in many places where \\cite{} is currently used."}, "questions": {"value": "* What is the effect of using the ML approximation _only_ in Phase 1 or _only_ in Phase 2? This could be an interesting ablation to see to better understand the \"weak points\" in the performance of the method.\n* What is the computational time associated with data generation and training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xVq6qoHRWS", "forum": "63ndH312pT", "replyto": "63ndH312pT", "signatures": ["ICLR.cc/2026/Conference/Submission22387/Reviewer_YuAr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22387/Reviewer_YuAr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762114607363, "cdate": 1762114607363, "tmdate": 1762942195077, "mdate": 1762942195077, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}