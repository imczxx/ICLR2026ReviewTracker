{"id": "Dru5mm9anE", "number": 10629, "cdate": 1758178012766, "mdate": 1759897639384, "content": {"title": "Scaling Agents via Continual Pre-training", "abstract": "Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.", "tldr": "The first work to introduce agentic continual pre-training to agent training pipeline, providing strong agentic foundamental models.", "keywords": ["Continual Pre-training", "Deep Research Agent", "Agentic Training", "Data Synthesis"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/767e7d08609a5b6233165e441773c43e923eb881.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Agentic Continued Pre-Training for having better base pre-trained models for capabilities requiring tool calls and multi-hop reasoning like DeepResearch. The authors develop a model named AgentFounder-30B using this continued pre-training setup by generating synthetic pre-training data using FAS (First-order Action Synthesis) and HAS (Higher-order Action Synthesis); and further apply SFT on top of the base model with agentic capabilities. They achieve SoTA scores (across open models/deepresearch agents) on various agentic benchmarks like BrowseComp, HLE, GAIA etc."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles an important problem of building better base models for agentic capabilities where standard pre-training data is not easily available for multi-hop reasoning, long trajectories, etc.\n- The paper's synthetic data generation pipeline is interesting and captures various insights like collecting discarded rejection sampling and historical tool use data, correlation of quality of first-step reasoning with final task completion rates.\n- The empirical results are impressive."}, "weaknesses": {"value": "I feel there are quite a lot of points to address before this paper is ready for publication.\n\n- The entire paper reads more like a high-level blog rather than a technical white paper with concrete methodology, steps/details, and experiments.\n- The paper tries to present that they are the first to do agentic CPT, but a lot of mid-training/pre-training works do this step before post-training for example: https://arxiv.org/abs/2507.20534\n- Lines 65-67 \"Consequently, both SFT and RL training depend on limited deterministic\nsupervisory signals that lock models into replicating specific behavioral patterns rather than develop\nflexible decision-making capabilities\". The authors don't show any evidence for this and neither do they cite any works highlighting this phenomenon. SFT does mimic specific patterns, but I've not seen this case happening with RL.\n- A lot of key technical details are missing (at least in the main paper), like where are the questions sourced from, how many parallel steps are generated for the HAS strategy, what models are used for the rejection sampling, number of tokens for SFT and what's the source of the SFT data, etc.\n- How is the model performance affected on non-agentic benchmarks by adding the agentic CPT data? There's no analysis on that.\n- What's the effect of the model used for rejection sampling? Can weaker models help as well to eliminate the \"distillation\" effect of using more capable models to get the rejection sampling data?\n- The effect of HAS strategy is minimal on top of FAS, and the evaluation gains seem to be just noise.\n- Since I don't know the source of the questions used to generate the synthetic data, how did the authors ensure no contamination with the evaluation sets like HLE.\n\nAlthough not a weakness, there are a few typos here and there: AgentFoudner instead of AgentFounder in various places, line 224: high-orider instead of high-order."}, "questions": {"value": "I have asked most of my questions in the weaknesses sections above. I am willing to increase my score if the authors are able to address the issues."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d09lQmo3tZ", "forum": "Dru5mm9anE", "replyto": "Dru5mm9anE", "signatures": ["ICLR.cc/2026/Conference/Submission10629/Reviewer_UZu1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10629/Reviewer_UZu1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931542119, "cdate": 1761931542119, "tmdate": 1762921886261, "mdate": 1762921886261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Agentic Continual Pre-Training as an intermediate training state between pre-training and post-training for building deep research agents. The authors propose a two-stage training pipeline: stage 1 involves standard next-token prediction training on synthetic data, while stage 2 focuses on long-context training. To support the training pipeline, authors propose two key data synthesis methods: First-order Action Synthesis (FAS) for generating planning and reasoning data and Higher-order Action Synthesis (HAS) for transforming wasted trajectories into multi-step multi-choice decision problems. \n\nThe trained model achieves strong performance across 10 benchmarks, including BrowseComp, HLE, GAIA, etc. However, the paper does not provide details of some of the claims and doesn't provide enough details about the generated data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Strong Empirical Performance: The proposed model achieves state-of-the-art results on multiple challenging benchmarks and beats stronger and larger commercial models on most datasets.\n- Scalable Data Synthesis: The FAS approach for generating diverse question-answer pairs from entity-anchored knowledge without requiring expensive API calls or human supervision is practical and cost-effective.\n- Model Size and Data Scaling: The Authors show that their method scales with the model size and data volume effectively.\n- Adaptability to different SFT data: Table 3 shows that the authors' model consistently improves performance across different post-training dataset setups, suggesting the CPT does provide a better foundation."}, "weaknesses": {"value": "- Unverified Claims: The Authors claim that general-purpose foundation models create \"inherent optimization conflicts\", but this is not verified in this work, and no supporting evidence in the form of a citation is provided. Similarly, authors also claim that \"the quality of first-step reasoning exhibits strong positive correlation with final task completion rates\". Although this statement may seem intuitive, no experimental validation is provided to support it.\n- Unclear distinction from domain adaptation: While the authors claim that the trained model provides a better foundation model for post-training, the paper doesn't verify this claim outside the domain of web-search-based benchmarks. This is understandable because the data was collected using web-search-specific tools; however, the authors should not claim it as a foundation model.\n- Limited Transparency on data composition: While the work mentions using 200B and 100B tokens for Stage 1 and 2, respectively, the actual composition of the FAS/HAS data or the data sources is never discussed in the work. How did the authors verify that there was no potential test-data leakage during the training data collection?\n- Zero Supervisory Signal: In section 2.2, the authors claim that the data is collected using a zero supervisory signal. However, in section 2.2.2, the authors employ rejection sampling using an LLM-as-a-judge. This is a type of supervision. Authors should clarify this claim.\n- Limited Error Analysis: The paper does not provide details error analysis showing what types of tasks/questions benefit most from Agentic CPT versus post-training alone, making it difficult to understand the method's limitations."}, "questions": {"value": "- GLM 4.5 Comparison: Please add some details on how your strategy differs from the GLM 4.5 strategy. What is the difference between the agentic data sizes used for GLM 4.5 and the AgentFounder model?\n- FAS vs Trajectory Collection: What is the performance comparison between FAS-generated data and actual collected trajectories (e.g., from rollouts)? Is FAS primarily a cost-saving measure or does it provide qualitative benefits?\n- HAS Design Choices: In HAS data construction, you generate N alternatives. What is the value of N here? Please add details about the dataset construction to the paper.\n- In the first stage, is there any general-purpose reasoning corpus added to the data mix? If not, does the model suffer from forgetting? Some evaluations on general-purpose language reasoning benchmarks like MMLU would be appreciated and would make the claims stronger.\n- Can authors please provide error analysis of the trained model on the evaluation datasets? What type of errors are still prevalent after Agentic CPT? What type of errors are targeted in this training paradigm? This would add significant depth to the work.\n- It is not clear to me which data is used for what stage. Some clarification on this would be appreciated.\n- In Table 4, what happens if you skip Stage 1 training? \n- Evaluation Protocol: The Agentic CPT data is collected using the same set of tools as used in the evaluation. However, I am not sure if the other models were trained to use the same set of tools. This gives an inherent advantage to the AgentFounder model. If my understanding is correct, how does it affect the tool use for AgentFounder vs other models? Are the majority of the errors in baseline models because of incorrect tool use?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6a0JRD6YQr", "forum": "Dru5mm9anE", "replyto": "Dru5mm9anE", "signatures": ["ICLR.cc/2026/Conference/Submission10629/Reviewer_cMZ8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10629/Reviewer_cMZ8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762155238989, "cdate": 1762155238989, "tmdate": 1762921885714, "mdate": 1762921885714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Agentic Continual Pre-Training, an intermediate training stage between pre-training and post-training to bridge the optimization conflict between pre-training and agent post-training. To test the effectiveness of the proposed method, the authors further synthesized large-scale data for model training. The resulting model, AgentFounder-30B, achieves state-of-the-art results on 10 benchmarks, including 39.9% on BrowseComp-en, 31.5% on HLE, and 72.8% on GAIA. Ablations show consistent improvements, and scaling analyses indicate steady gains with larger models and data. Key contributions include:\n\n(1) First-order Action Synthesis (FAS): reformulates static knowledge into complex questions and synthesizes planning/reasoning behaviors without API costs.\n\n(2) Higher-order Action Synthesis (HAS): reuses suboptimal trajectories by expanding each step into contrastive multi-choice decision processes.\n\n(3) Two-stage CPT strategy: progressive training with 32K and 128K contexts (200B + 100B tokens) to enhance long-horizon reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The data synthesis pipeline is scalable and efficient.  FAS enables large-scale agentic data generation through knowledge-to-question transformation without costly API calls, while HAS reuses suboptimal trajectories by converting them into step-level decision processes. Together, they improve data efficiency and coverage. The addition of reject sampling with knowledge alignment verification further enhances data quality.\n\n(2) The experiment results are promising. AgentFounder-30B achieves SOTA across ten benchmarks, outperforming all open-source agents and even surpassing some commercial systems. It is the first open-source model to exceed 30% on HLE (31.5%), with consistent gains across all SFT configurations, demonstrating strong robustness."}, "weaknesses": {"value": "(1) Limited Theoretical Evidence for “Optimization Conflict” \nThe claimed conflict between capability learning and alignment is intuitively appealing but empirically unsupported. It would be great if the authors could provide more evidence for this claim, like gradient interference analyses (e.g., cosine similarity between CPT and SFT objectives), visualize loss landscapes, and probe capability retention during SFT with vs. without CPT.\n\n(2) Lack of analysis regarding the influence of the model on data synthesis.  It would be great if the authors could provide more details on the models used in data synthesis. Ideally, it would be great if the authors could further provide an oblation study regarding model performance against the quality of the model for data synthesis."}, "questions": {"value": "The paper's core contribution relies heavily on the synthetic FAS and HAS data synthesis. Could you specify the data release plan, like whether the whole CPT stage training data will be released? If it's not, it's possible to release a sample subset for community inspection."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9CUDWY382X", "forum": "Dru5mm9anE", "replyto": "Dru5mm9anE", "signatures": ["ICLR.cc/2026/Conference/Submission10629/Reviewer_pAr1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10629/Reviewer_pAr1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762607246516, "cdate": 1762607246516, "tmdate": 1762921885210, "mdate": 1762921885210, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}