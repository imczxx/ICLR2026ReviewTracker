{"id": "oh9ChF7Pv0", "number": 10593, "cdate": 1758176748894, "mdate": 1759897641688, "content": {"title": "EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via Equality Graph", "abstract": "Symbolic regression seeks to uncover physical laws from experimental data by searching for closed-form expressions, which is an important task in AI-driven scientific discovery. Yet the exponential growth of the search space of expression renders the task computationally challenging.\nA promising yet underexplored direction for reducing the effective search space and accelerating training lies in *symbolic equivalence*: many expressions, although syntactically different, define the same function—for example, $\\log(x_1^2x_2^3)$, $\\log(x_1^2)+\\log(x_2^3)$, and $2\\log(x_1)+3\\log(x_2)$.\nExisting algorithms treat such variants as distinct outputs, leading to redundant exploration and slow learning.\nWe introduce EGG-SR, a unified framework that integrates equality graphs (e-graphs) into diverse symbolic regression algorithms, including Monte Carlo Tree Search (MCTS), deep reinforcement learning (DRL), and large language models (LLMs).\nEGG-SR compactly represents equivalent expressions through the proposed EGG module, enabling more efficient learning by:\n(1) pruning redundant subtree exploration in EGG-MCTS,\n(2) aggregating rewards across equivalence classes in EGG-DRL, and\n(3) enriching feedback prompts in EGG-LLM.\nTheoretically, we establish that embedding e-graphs tightens the regret bound of MCTS and reduces the variance of the DRL gradient estimator.\nEmpirically, EGG-SR consistently enhances multiple baselines across challenging benchmarks, discovering equations with lower normalized mean squared error than state-of-the-art methods.", "tldr": "We introduce EGG-SR, a unified framework that integrates equality graphs (e-graphs) into diverse symbolic regression algorithms.", "keywords": ["Symbolic Regression", "symbolic equivalence", "Monte Carlo Tree Search", "Deep Reinforcement Learning", "Large Language Model"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ae0a4a1bad4b87b70281222d96a35833d54a6463.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces EGG-SR, a framework designed to improve the efficiency and effectiveness of Symbolic Regression (SR). The core problem addressed is that existing SR algorithms inefficiently explore the search space by treating syntactically different but semantically equivalent expressions as distinct candidates. EGG-SR integrates equality graphs (e-graphs) to compactly represent and manage these symbolic equivalences within a grammar-based SR setting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Originality**: While e-graphs and their application to SR are not entirely new (as noted in the related works ), this paper's contribution is a novel and highly general framework. Applying the equivalence concept systematically to MCTS (search pruning), DRL (variance reduction), and LLMs (prompt enrichment) is a creative and powerful combination of ideas. The DRL variance reduction and LLM feedback mechanisms are particularly original.\n\n- **Quality**: The paper is technically strong. The theoretical claims are well-supported by proofs in the appendix that build on established literature (e.g., Rao-Blackwellization for DRL variance ). The empirical evaluation is thorough and convincing. The authors test their claims across all three proposed algorithm variants and find consistent improvements. Crucially, they include practical analyses of memory and time overhead (Figures 4 and 5), which demonstrate the method's feasibility.\n\n- **Clarity**: The paper is exceptionally well-written. The problem is motivated with a clear, simple example ($log(x_{1}^{2}x_{2}^{3})$) 16 that is carried through the text. The methodology is explained clearly, with helpful diagrams for the e-graph construction (Figure 1) 17, the MCTS process (Figure 2) 18, and the LLM pipeline (Figure 8)19. The distinction between the baseline algorithms and their EGG-enhanced counterparts is sharp and easy to grasp.\n\n- **Significance**: This work addresses a fundamental and widely recognized source of inefficiency in symbolic regression. Because the EGG-SR framework is shown to be effective across diverse SR methods (search, DRL, LLM) and practical (low overhead), it has the potential for broad impact. It provides a \"drop-in\" enhancement that could benefit a wide range of existing and future SR systems."}, "weaknesses": {"value": "- The process of building the e-graph, \"equality saturation\", involves iteratively applying all rules. While the storage is efficient (Figure 4), the construction time could become a bottleneck for very complex expressions or a very large set of rewrite rules. Figure 5  shows the overhead is negligible for one dataset, but it does not analyze how this construction time scales with expression complexity or the number of rules.\n- The claim for EGG-MCTS is that it \"prunes redundant subtree exploration\". However, Figure 3 (Left)  shows that EGG-MCTS explores a larger search tree (more nodes) than standard MCTS. The paper states this indicates exploration of a \"larger and more diverse search space\", but this seems to contradict the \"pruning\" claim and is confusing. A clearer explanation is needed.\n\n- The related work section (Section 4) is incomplete and overlooks several significant, recent advancements in symbolic regression. While the paper covers the main paradigms, it omits highly relevant work on generative and transformer-based SR models [2, 3, 4].\nA more critical omission is the lack of any discussion or comparison with DySymNet [1]. This method is highly relevant to the present work, as DySymNet also employs a policy gradient approach (similar to EGG-DRL) to dynamically construct symbolic networks and has demonstrated strong performance, particularly on high-dimensional problems. The paper would be significantly strengthened by:\n\n    - Including this and other recent works [2, 3, 4] to provide a more comprehensive and up-to-date overview of the field.\n\n    - Providing at least a detailed conceptual comparison, and ideally an empirical one, between EGG-DRL and DySymNet. This is necessary to properly contextualize the DRL-based contribution of EGG-SR.\n\n[1] Li W, Li W, Yu L, et al. A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical Expressions from Data, ICML 2024\n\n[2] Holt S, Qian Z, van der Schaar M. Deep generative symbolic regression, ICLR 2023\n\n[3] Li W, Li W, Sun L, et al. Transformer-based model for symbolic regression via joint supervised learning, ICLR 2023\n\n[4] Shojaee P, Meidani K, Barati Farimani A, et al. Transformer-based planning for symbolic regression, NeurIPS 2023"}, "questions": {"value": "1. The framework's success depends on the manually curated set of rewrite rules. (a) How was the rule set for the trigonometric benchmarks in Table 1  selected? Was it designed specifically for those problems? (b) How does EGG-SR's performance degrade if key rewrite rules are omitted from the set?\n\n2. Regarding the time-efficiency in Figure 5, how does the \"EGG construction\" time scale with (a) the complexity (e.g., length or depth) of the initial expression and (b) the total number of rewrite rules in the system?\n\n3. For the EGG-LLM method, how are the equivalent expressions for the feedback prompt selected from the e-graph? Do you use cost-based extraction, random sampling, or some other heuristic? How many equivalent expressions are added, and how are they formatted in the prompt to effectively guide the LLM?\n\n4. Could you please clarify the result in Figure 3 (Left)? Why does EGG-MCTS, which is designed to avoid redundant exploration, result in a larger total search tree than standard MCTS? Does merging equivalent nodes (and sharing their visit counts/rewards) encourage a deeper, more focused search down promising paths, thus leading to a larger total node count even as redundant branches are eliminated?\n\nI am willing to raise my score if the authors can satisfactorily address all the concerns outlined in the weaknesses and questions above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PKSUjdeLFC", "forum": "oh9ChF7Pv0", "replyto": "oh9ChF7Pv0", "signatures": ["ICLR.cc/2026/Conference/Submission10593/Reviewer_b8v3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10593/Reviewer_b8v3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757089101, "cdate": 1761757089101, "tmdate": 1762921861782, "mdate": 1762921861782, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Important Clarifications on E-graphs and Symbolic Regression in Prior Work"}, "comment": {"value": "Dear Authors,\n\nAs one of the authors of a closely cited related work [1] and a researcher actively involved in the field of e-graphs and SR, I would like to provide feedback on your paper. I believe a few points concerning the foundational mechanisms of our work could be clarified, especially regarding the scope and novelty of the *eggp* algorithm [1].\n\nA misunderstood point about our work comes from this sentence:\n\"Prior research (de Franca & Kronberger, 2025) has primarily used rewrite rules to simplify expressions, typically rewriting a\nlonger expression into a shorter one.\"\n\nThis understates the contribution and primary mechanism of our work. The simplification process in *eggp* is a side-effect of a novel search strategy. We exploit e-graphs for enhanced, non-redundant search space exploration by\n- Inserting every visited expression into the e-graph.\n- Running equality saturation to compute and store some equivalent forms.\n- Exploiting this equivalence information to force the production of novel expressions \n\nFor example, when proposing a new expression like $(x + 3y)^2$, the e-graph is queried to check if it or any equivalent form (e.g., $x^2 + 6xy + 9y^2$) has been visited. If found, the proposal is \"repaired\" using existing equivalent forms to create a novel expression.  This efficient process significantly improves exploration capabilities and is precisely what led *eggp* to achieve SotA results across many benchmarks. This is better explained at a blog post https://symreg.at/blog/2025/equality-saturation-and-symbolic-regression/\n\nRegarding the statement:\n\"our approach employs e-graphs not only for simplified variants but also to generate a richer set of equivalent variants, enabling easy integration into many symbolic regression algorithms.\"\n\nI would politely argue that our *eggp* algorithm is already using this strategy, as detailed above, by using eqsat to generate a rich set of equivalent forms for novelty generation.\nThe \"integration into many symbolic regression algorithms\" is supported by another of work, presented at the same conference, called rEGGression [2] (https://github.com/folivetti/reggression):\n\n- *rEGGression* is a dedicated Python library that enables the user to create, manipulate, and query e-graphs.\n- Like EGG-SR, it facilitates the creation of an e-graph from an expression, running equality saturation, and retrieving all equivalent forms.\n- Crucially, *rEGGression* offers functionality beyond the scope of EGG-SR, including:\n  * Importing e-graphs and equations generated by other SR algorithms.\n   * Advanced querying for top-N expressions with filtering by size, complexity, and number of adjustable parameters.\n   * Querying expressions by pattern matching (e.g., returning top expressions following the pattern $\"v^x\"$).\n    * Displaying statistics on the quality of the building blocks.\n\nThis demonstrates a clear existing solution for flexible integration and advanced model exploration within the SR community.\n\nSome of these features are explained in this blog post:\nhttps://github.com/folivetti/reggression/blob/main/tutorials/blog/post.md\n\nSpecific Technical Corrections:\n\n- Conditional Rewrite Rules: equivalence rules such as $log(a \\cdot b) = log(a) + log(b)$ are only valid under specific domain constraints (in this case, $a, b > 0$). It is important to note that conditional rules are already supported in the original *egg* library (not to be confused with eggp) and fully implemented in *rEGGression*.\n- The statement: \"Most existing e-graph implementations are either in Haskell (Willsey et al., 2021) or provided as Python wrappers (Shanabrook, 2024)\" is inaccurate.\n  * The widely used *egg* library is written in Rust.\n  * Implementations also exist in Haskell (*hegg* and *srtree*) and Julia (*Metatheory.jl*).\n   * Furthermore, I would argue that many of these libraries are more flexible and general-purpose than libraries specifically constrained for SR, such as the proposed on.\n- Space Complexity: while e-graphs are excellent at compacting equivalence relationships, it is vital to acknowledge that they still suffer from the risk of exponential growth in memory usage. Depending on the starting expression and the set of equivalence rules (particularly common simplification rules like $a + 0 \\Rightarrow a$ or $a(b + c) \\Rightarrow ab + ac$), the e-graph can quickly \"explode.\" It is possible this behavior was not observed in your experiments due to the omission of some of these \"problematic\" rules.\n\nI hope these clarifications help to improve the accuracy and depth of your paper.\n\nBest regards\n\n[1] Fabrıcio Olivetti de Franca and Gabriel Kronberger. Improving genetic programming for symbolic\nregression with equality graphs. In GECCO. ACM, 2025.\n[2] de França, Fabrício Olivetti, and Gabriel Kronberger. \"rEGGression: an Interactive and Agnostic Tool for the Exploration of Symbolic Regression Models.\" Proceedings of the Genetic and Evolutionary Computation Conference. 2025."}}, "id": "bnNBhKZ0pg", "forum": "oh9ChF7Pv0", "replyto": "oh9ChF7Pv0", "signatures": ["~Fabricio_Olivetti_de_Franca1"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "~Fabricio_Olivetti_de_Franca1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10593/-/Public_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763380399617, "cdate": 1763380399617, "tmdate": 1763380399617, "mdate": 1763380399617, "parentInvitations": "ICLR.cc/2026/Conference/-/Public_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Important Clarifications on E-graphs and Symbolic Regression in Prior Work"}, "comment": {"value": "Dear Authors,\n\nAs one of the authors of a closely cited related work [1] and a researcher actively involved in the field of e-graphs and SR, I would like to provide feedback on your paper. I believe a few points concerning the foundational mechanisms of our work could be clarified, especially regarding the scope and novelty of the *eggp* algorithm [1].\n\nA misunderstood point about our work comes from this sentence:\n\"Prior research (de Franca & Kronberger, 2025) has primarily used rewrite rules to simplify expressions, typically rewriting a\nlonger expression into a shorter one.\"\n\nThis understates the contribution and primary mechanism of our work. The simplification process in *eggp* is a side-effect of a novel search strategy. We exploit e-graphs for enhanced, non-redundant search space exploration by\n- Inserting every visited expression into the e-graph.\n- Running equality saturation to compute and store some equivalent forms.\n- Exploiting this equivalence information to force the production of novel expressions \n\nFor example, when proposing a new expression like $(x + 3y)^2$, the e-graph is queried to check if it or any equivalent form (e.g., $x^2 + 6xy + 9y^2$) has been visited. If found, the proposal is \"repaired\" using existing equivalent forms to create a novel expression.  This efficient process significantly improves exploration capabilities and is precisely what led *eggp* to achieve SotA results across many benchmarks. This is better explained at a blog post https://symreg.at/blog/2025/equality-saturation-and-symbolic-regression/\n\nRegarding the statement:\n\"our approach employs e-graphs not only for simplified variants but also to generate a richer set of equivalent variants, enabling easy integration into many symbolic regression algorithms.\"\n\nI would politely argue that our *eggp* algorithm is already using this strategy, as detailed above, by using eqsat to generate a rich set of equivalent forms for novelty generation.\nThe \"integration into many symbolic regression algorithms\" is supported by another of work, presented at the same conference, called rEGGression [2] (https://github.com/folivetti/reggression):\n\n- *rEGGression* is a dedicated Python library that enables the user to create, manipulate, and query e-graphs.\n- Like EGG-SR, it facilitates the creation of an e-graph from an expression, running equality saturation, and retrieving all equivalent forms.\n- Crucially, *rEGGression* offers functionality beyond the scope of EGG-SR, including:\n  * Importing e-graphs and equations generated by other SR algorithms.\n   * Advanced querying for top-N expressions with filtering by size, complexity, and number of adjustable parameters.\n   * Querying expressions by pattern matching (e.g., returning top expressions following the pattern $\"v^x\"$).\n    * Displaying statistics on the quality of the building blocks.\n\nThis demonstrates a clear existing solution for flexible integration and advanced model exploration within the SR community.\n\nSome of these features are explained in this blog post:\nhttps://github.com/folivetti/reggression/blob/main/tutorials/blog/post.md\n\nSpecific Technical Corrections:\n\n- Conditional Rewrite Rules: equivalence rules such as $log(a \\cdot b) = log(a) + log(b)$ are only valid under specific domain constraints (in this case, $a, b > 0$). It is important to note that conditional rules are already supported in the original *egg* library (not to be confused with eggp) and fully implemented in *rEGGression*.\n- The statement: \"Most existing e-graph implementations are either in Haskell (Willsey et al., 2021) or provided as Python wrappers (Shanabrook, 2024)\" is inaccurate.\n  * The widely used *egg* library is written in Rust.\n  * Implementations also exist in Haskell (*hegg* and *srtree*) and Julia (*Metatheory.jl*).\n   * Furthermore, I would argue that many of these libraries are more flexible and general-purpose than libraries specifically constrained for SR, such as the proposed on.\n- Space Complexity: while e-graphs are excellent at compacting equivalence relationships, it is vital to acknowledge that they still suffer from the risk of exponential growth in memory usage. Depending on the starting expression and the set of equivalence rules (particularly common simplification rules like $a + 0 \\Rightarrow a$ or $a(b + c) \\Rightarrow ab + ac$), the e-graph can quickly \"explode.\" It is possible this behavior was not observed in your experiments due to the omission of some of these \"problematic\" rules.\n\nI hope these clarifications help to improve the accuracy and depth of your paper.\n\nBest regards\n\n[1] Fabrıcio Olivetti de Franca and Gabriel Kronberger. Improving genetic programming for symbolic\nregression with equality graphs. In GECCO. ACM, 2025.\n\n[2] de França, Fabrício Olivetti, and Gabriel Kronberger. \"rEGGression: an Interactive and Agnostic Tool for the Exploration of Symbolic Regression Models.\" Proceedings of the Genetic and Evolutionary Computation Conference. 2025."}}, "id": "bnNBhKZ0pg", "forum": "oh9ChF7Pv0", "replyto": "oh9ChF7Pv0", "signatures": ["~Fabricio_Olivetti_de_Franca1"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "~Fabricio_Olivetti_de_Franca1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10593/-/Public_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763380399617, "cdate": 1763380399617, "tmdate": 1763392370936, "mdate": 1763392370936, "parentInvitations": "ICLR.cc/2026/Conference/-/Public_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents EGG-SR, a unified framework that addresses the underexplored problem of symbolic equivalence in symbolic regression (SR). The core idea is to integrate equality graphs (e-graphs) to compactly represent equivalent expressions, thereby reducing redundant search. The authors demonstrate the versatility of EGG-SR by embedding it into three distinct SR paradigms: Monte Carlo Tree Search (MCTS), Deep Reinforcement Learning (DRL), and Large Language Models (LLMs). Theoretical analysis shows tighter regret bounds for MCTS and lower gradient variance for DRL. Empirically, the EGG module consistently enhances baseline performance across various benchmarks, leading to the discovery of expressions with lower normalized mean squared error."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "**Novel and Important Problem Formulation**:​​ The paper successfully identifies and tackles the fundamental issue of symbolic equivalence, a significant source of inefficiency in SR that has been largely overlooked. This focus is timely and valuable.\n\n​**High Methodological Innovation**:​​ The primary strength is the proposal of a unified, plug-and-play framework (EGG-SR) rather than a single algorithm. Its applicability across diverse paradigms (MCTS, DRL, LLM) demonstrates remarkable generality and conceptual elegance.\n\n**​Strong Theoretical and Empirical Validation**:​​ The work is supported by non-trivial theoretical guarantees, which substantiate the method's benefits. The experiments are comprehensive, convincingly showing performance improvements across multiple baselines and datasets. The inclusion of efficiency analyses (time/space) and rich e-graph visualizations strengthens the empirical contribution."}, "weaknesses": {"value": "**Dependence on Manually Defined Rewrite Rules**:​​ The effectiveness of EGG-SR currently relies on a pre-defined set of rewrite rules. The framework's power and generality could be further amplified by exploring methods to learn or automatically discover these rules from data, as noted by the authors in the conclusion.\n\n**Writings**: There is a significant distance between Figure 1 and the corresponding explanatory text (Section 3.1). To improve the reader's flow, I suggest moving the figure closer to its initial description or adding a cross-reference (e.g., \"as illustrated in Figure 1\") when it is first mentioned in the text. Plus, there appears to be an error in the reported minimum value for the second column under the \"noisy setting\" in Table 1."}, "questions": {"value": "Concerns and questions are described in \"Weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "su2ia5Mh1m", "forum": "oh9ChF7Pv0", "replyto": "oh9ChF7Pv0", "signatures": ["ICLR.cc/2026/Conference/Submission10593/Reviewer_A6nL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10593/Reviewer_A6nL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811770570, "cdate": 1761811770570, "tmdate": 1762921861295, "mdate": 1762921861295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Equality Graph (e-graph) into the symbolic regression (SR) framework to enable uniform rewards and loss assigned to the mathematical equivalent expressions, enabling a more efficient and robust SR search. The paper provides both theoretical analyses and experiments on several backend learning/search methods to support the claim."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. **Significance**: The paper focuses on an important and fundamental problem in symbolic regression (SR), and the introduced e-graph is reasonable for equivalence-aware SR frameworks.\n\n2. **Multiple Backends:** The paper conducts e-graphs on several learning/search methods (MCTS, DRL, and LLM) to show a universal advantage of capturing expression equivalences in SR methods."}, "weaknesses": {"value": "1. **Novelty:** Though the e-graph is new in SR, similar ideas of using graph-based representations to capture expression equality have already been studied for SR. For example, Expression DAGs [1] include the same idea of sharing sub-expressions in DAGs for expression equality. The paper lacks a sufficient literature review on this topic to differentiate its novelty and contribution.\n\n2. **Potentially Biased UCT Search**: The proposed EGG back-propagation in MCTS might lead to biased UCT selections, see Question 2.\n\n3. **Experimental Soundness:** The whole experimental section can be regarded as an ablation study, which only focuses on implementing typical baselines with or without EGG on datasets with abundant equivalencies. However, benchmarkings on widely adopted general datasets (e.g., SRBench [2]) with relevant prevailing baselines (e.g., SPL [3] for MCTS and uDSR [4] for DRL) are missing, which cannot support the claim \"EGG-SR ... discovering equations with lower normalized mean squared error than *state-of-the-art* methods\" in the abstract. Especially, the *state-of-the-art* methods could include many transformer-based methods, such as TPSR[5], RAG-SR[6], and also DGSR [7], an E2E transformer model to encode expression equivalences.\n\n4. **Clarity:** There are some confusing definitions and notations, see Question 1.\n\n[1] Kahlmeyer, Paul, et al. \"Scaling up unbiased search-based symbolic regression.\" Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence. 2024.\n\n[2] La Cava, William, et al. \"Contemporary symbolic regression methods and their relative performance.\" Advances in neural information processing systems 2021.DB1 (2021): 1.\n\n[3] Sun, Fangzheng, et al. \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search.\" The Eleventh International Conference on Learning Representations.\n\n[4] Landajuela, Mikel, et al. \"A unified framework for deep symbolic regression.\" Advances in Neural Information Processing Systems 35 (2022): 33985-33998.\n\n[5] Shojaee, Parshin, et al. \"Transformer-based planning for symbolic regression.\" Advances in Neural Information Processing Systems 36 (2023): 45907-45919.\n\n[6] Zhang, Hengzhe, et al. \"RAG-SR: Retrieval-augmented generation for neural symbolic regression.\" The Thirteenth International Conference on Learning Representations. 2025.\n\n[7] Holt, Samuel, Zhaozhi Qian, and Mihaela van der Schaar. \"Deep Generative Symbolic Regression.\" The Eleventh International Conference on Learning Representations."}, "questions": {"value": "1. **Clarity** \n- In line 42, \"A promising yet underexplored direction for reducing the *effective* search space\", do you mean reducing the ineffective or redundant search space?\n- *Inconsistences*: In line 83, coefficients are denoted as $\\boldsymbol{c}$, then in line 93 they are denoted as $const$, and in line 213 $c$ is referred to constant to balance exploration and exploitation.\n- *Confusions*: In Fig.1 and lines 133, 134, 252, and 253, notations explaining the substitution rule for recursively constructing a closed-form expression all use a single notation $A$ for a place-holder subexpression, making it hard to distinguish their hierarchy structure and correspondence in the figure. Using a subscription to distinguish placeholders might be better for clarity.\n- *Missing Critical Definitions*: There are no formal definitions of states and actions in the Markov Decision Process (MDP) for both MCTS and DRL in the main context. There is also no clear definition of what a node $s$ represents in line 211 (I assume it should be the candidate expression $\\phi$ inferred from the example in line 252) and what a sequence $\\tau$ represents in line 272 (Is it the same as $\\phi$ for node $s$? How EGG is represented as a state here?).\n2. **EGG-based Backpropagation**: I have two major concerns about the EGG-based backpropagation based on my understanding, both of which arise from the backpropagation to all the equivalent sub-expressions in MCTS:\n\n- The EGG-based backpropagation seems to backpropagate the increasing visit counts to all the equivalent sub-expression generation paths (even if they are not explored at this stage). Does it mean that the visit counts are dependent on the number of equivalents a sub-expression has, so that visit counts of an expression with more equivalents will grow faster, leading to potentially under-explored UCT search?\n- Even if the above case is fine for the terminal nodes that are equivalent, the non-terminal nodes on the intermediate paths might not be equivalent. For example, two equivalent subexpression, their paths $sin^2(A_1)+cos^2(A_2) \\rightarrow sin^2(x)+cos^2(x)=1$ and $\\frac{B_1}{B_2} \\rightarrow \\frac{y}{y} = 1$  can have distinct intermediate expressions $sin^2(A_1)+cos^2(A_2)$ and $\\frac{B_1}{B_2}$ if the placeholders $A_i$ and $B_i$ are not further sampled to be the same variables respectively. In such a case, would the synchronization of the equivalent terminals' backpropagation regarding the visit counts also affect these non-equivalent intermediate nodes (i.e., more number of visits if they have equivalent terminals), so that they might have biased UCT selections?\n\nI'm happy to change my score if the above concerns and questions are properly addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "43FaRtzgLb", "forum": "oh9ChF7Pv0", "replyto": "oh9ChF7Pv0", "signatures": ["ICLR.cc/2026/Conference/Submission10593/Reviewer_Yckw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10593/Reviewer_Yckw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987263209, "cdate": 1761987263209, "tmdate": 1762921860846, "mdate": 1762921860846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}