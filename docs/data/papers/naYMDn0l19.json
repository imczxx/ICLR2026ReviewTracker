{"id": "naYMDn0l19", "number": 14031, "cdate": 1758227302930, "mdate": 1759897394886, "content": {"title": "Bidding for Influence: Auction-Driven Diffusion Image Generation", "abstract": "Motivated by online auctions for banner ads, we propose auctions that fractionally allocate the creation of a banner to bidders according to their preferences. Our mechanism elicits bids and textual prompts from the advertisers, and composes them into a score function that drives a reverse diffusion process that generates the banner. Then, it implements Monte Carlo sampling to calculate approximate VCG-based payments to incentivize high-welfare images. Extensive experiments on a diverse 20-prompt dataset with up to 3 agents demonstrate key economic properties. Our mechanism achieves: (1) bid monotonicity; (2) efficiency improvement of up to 20.7% higher welfare than a single-winner VCG baseline; and (3) approximate incentive compatibility, with average regret as low as 7% when deviating from truthful bidding. These benefits are achieved while preserving high image quality. Our study establishes a principled and scalable bridge between auction theory and controllable image diffusion, laying a foundation for economically aligned, multi-stakeholder image generation in advertising and beyond.", "tldr": "", "keywords": ["Diffusion Models", "Online Advertising"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/920c2c8ee112c3c3cb2ce2468c73f0f4b1c5a5fd.pdf", "supplementary_material": "/attachment/25fe92e922860807c4a8d924ff82e043fce40fa9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a Vickrey-Clarke-Groves (VCG)-based bidding mechanism for diffusion-based image generation. The framework allows multiple agents to bid for fractional influence over the generated image via classifier-free guidance. Experiments show higher social welfare than a winner-takes-all baseline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The idea of combining auction theory with diffusion image generation is conceptually novel and potentially impactful for applications such as multi-stakeholder content generation or advertising. \n* The paper is well written, and the empirical results demonstrate consistent welfare improvement and approximate incentive compatibility."}, "weaknesses": {"value": "* The framework mainly integrates existing methods (VCG and classifier-free guidance) and lacks a clear novel algorithmic contribution in either modeling or mechanism design.\n* Since the proposed approach relies on Monte Carlo estimation for counterfactual reruns, the computational cost grows roughly as $O(nk)$ . It remains unclear how scalable this framework is in practice. The experiments are limited to at most three agents and $k=20$ , which raises concerns about the feasibility of extending the mechanism to larger, real-world settings.\n* The baseline comparison is limited, only a single-winner VCG. \n* Since the proposed framework relies heavily on classifier-free guidance, the authors should include ablation studies varying the guidance scale to assess its effect on image quality, welfare, and alignment.\n* The experiments are conducted using only a single diffusion model (FLUX.1-schnell). Evaluating the framework on additional backbones (e.g., SDXL, Stable Diffusion) would help demonstrate robustness and model-agnostic applicability."}, "questions": {"value": "* How sensitive are the results to the choice of alignment metric? The proposed framework assumes that each agentâ€™s semantic component can be cleanly separated in the embedding space (both text and image), e.g., bags vs. shoes. However, when prompts become semantically similar or compositional, such as a bag vs. a red bag, the distinction in embedding space may be weak. In such cases, how does the proposed value function ensure reliable welfare estimation?\n* Why is only joint conditioning considered, rather than an additive form such as $w_1 * s_t(x|c, c_1)  + w_2 * s_t(x|c, c_2)$ \n* The authors mention using a guidance scale of 10, but its interpretation is unclear. Since the proposed method composes multiple conditional scores weighted by bids, does this guidance scale apply globally to the composed score, or do the individual bid-based weights sum to 10? \n* Is it possible to compare the proposed framework with other allocation or pricing mechanisms, e.g., Shapley value?\n* How accurate is the Monte Carlo estimation with respect to the number of samples $k$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hsGXhPaXLw", "forum": "naYMDn0l19", "replyto": "naYMDn0l19", "signatures": ["ICLR.cc/2026/Conference/Submission14031/Reviewer_oLUd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14031/Reviewer_oLUd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14031/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761363331854, "cdate": 1761363331854, "tmdate": 1762924521149, "mdate": 1762924521149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for ad image generation. Leveraging the VCG mechanism from ad auctions and diffusion models, this method allows multiple advertisers to bid to influence the generation of a image. Experiments show that this approach maintains image quality while achieving higher social welfare and economic rationality compared to traditional methods."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The integration of auctions with diffusion models is a novel idea. Traditional internet ad slots display content from a single advertiser. This paper's method of merging multiple ads into one generated image has significant potential for a new type of advertising."}, "weaknesses": {"value": "My major concerns of the paper are its theoretic depth and computational complexity. I understand that the diffusion process is difficult to analyze. But maybe it is possible to provide some structural results about the distribution of the final image? Furhtermore, the VCG-based mechanism also suffers from computational issues, and the issues are magnified when combined with the diffusion process. The experiments only involves 3 agents, which is insufficient."}, "questions": {"value": "Please see my comments above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fN7vVH2kaZ", "forum": "naYMDn0l19", "replyto": "naYMDn0l19", "signatures": ["ICLR.cc/2026/Conference/Submission14031/Reviewer_UtxX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14031/Reviewer_UtxX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14031/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008000146, "cdate": 1762008000146, "tmdate": 1762924520708, "mdate": 1762924520708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to apply the Vickrey-Clarke-Groves (VCG) mechanism to the setting where multiple agents bid to influence the generation outcome of a vision diffusion model. An allocation rule is implemented based on classifier-free guidance in diffusion models, while a payment rule is implemented based on Monte Carlo sampling. Empirically, the implemented mechanism achieves welfare improvement over the winner-takes-all baseline, incentive compatibility, and bid monotonicity, all while maintaining image aesthetic quality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- To my knowledge, this paper is the first to propose applying a bidding mechanism to the setting of vision diffusion models. It is an original idea to use score composition to implement multi-bidder influence.\n- As noted by the authors, the real-world implication in online advertising can be significant.\n- The exposition is well written. As a person without a strong economics background, I can understand the exposition."}, "weaknesses": {"value": "- The authors argue that their method can improve total welfare compared to the single-winner baseline. However, the agent prompts tested in this paper (Table 3) all bid for different objects in the generated image. For example, in the first setting, agent 1 bids for showing their brand on a mug, agent 2 bids for showing their brand on a laptop, and agent 3 bids for showing their brand on a newspaper. It is unclear whether the proposed method would collapse to the single-winner baseline when all agents bid for the same object in a generated image.\n- In Section 4.4, it seems more reasonable to visualize regret vs. truthfulness deviation in one scatter plot instead of two plots--in order to assess incentive compatibility.\n- In Section 4.5, the LAION aesthetic predictor can also be used to assess image aesthetic quality. Also, the baseline quality should be from images generated from the base prompt $c$.\n- Lines 415-431 contain two very similar paragraphs. Please trim down to one paragraph."}, "questions": {"value": "- Does your method still outperform the single-winner baseline in terms of total welfare, when all agents bid for the same object in a generated image?\n- Does your framework result in higher regret when the truthfulness deviation is higher?\n- In terms of image quality, does your framework produces similarly quality images compared to images generated with only the base prompt?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "r59D5qOkys", "forum": "naYMDn0l19", "replyto": "naYMDn0l19", "signatures": ["ICLR.cc/2026/Conference/Submission14031/Reviewer_guFR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14031/Reviewer_guFR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14031/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762209324323, "cdate": 1762209324323, "tmdate": 1762924519373, "mdate": 1762924519373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper  introduces the auction mechanism designed for diffusion-based image generation, enabling multiple agents to bid for and share influence over a single generated image. Motivated by the limitations of traditional winner-take-all online ad auctions, this work allows fractional allocation of image content creation according to agents' bids and preferences.\nKey contributions include:\nA generative auction framework where agent bids dynamically control the composition of a diffusion model's score function.\nAn allocation and pricing mechanism inspired by Vickrey-Clarke-Groves (VCG) auctions.\nExperiments on a dataset of 20 prompts with up to 3 agents, demonstrating bid monotonicity, welfare improvement.\nPreservation of image quality when blending multiple agents' inputs, validated via CLIP alignment scores."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "It pioneers the task of a generative auction specifically for diffusion-based image generation, bridging auction theory and controllable image synthesis in a new domain. While it builds on known diffusion and VCG auction concepts, their combination to enable multi-agent fractional influence over a continuous visual output is creative.\nThe problem is timely and important, responding to the technological and economic shift caused by generative AI in advertising and content creation. The results demonstrate meaningful incentives for adopting multi-agent auctions in visual media, potentially impacting online ad platforms and extending to dynamic media applications."}, "weaknesses": {"value": "The paper exhibits several weaknesses and areas for improvement:\nThe core auction mechanism primarily adapts existing concepts from classifier-free guidance in diffusion models and classical VCG auction theory without substantial original algorithmic contributions. \nThe evaluation compares against only a single-winner VCG baseline, which is a minimal comparative standard. Metrics rely heavily on CLIP-based alignment scores as proxies for semantic accuracy and image quality, which cannot fully capture compositional quality. There is no use of stronger quantitative metrics like FID, human preference score.\nExperimental validation uses just 20 base prompts with up to 3 agents, limiting claims about generalizability. The dataset represents a narrow range of scenarios without stress tests on complex or larger-scale settings.\nNo Human Validation: Given the intended application in advertising, a lack of human studies or user feedback evaluation reduces the practical impact and reliability of semantic alignment and image quality claims."}, "questions": {"value": "Could the authors please provide a detailed explanation of the single-winner VCG baseline used in the experiments? Specifically, how is the baseline implemented in terms of image generation sampling, prompt conditioning, and image selection? Additionally, how does this baseline relate theoretically and practically to classical single-winner VCG auctions that allocate a discrete good to one highest bidder? Lastly, what hypotheses or advantages is this baseline intended to demonstrate with respect to the multi-agent generative auction, and why is it considered a strong or relevant comparator in this context?\nIs it feasible to add standard image quality metrics (e.g., FID, IS,Pickscore) to complement CLIP alignment?\n\n\nCan we try a simpler baseline or alternative approach where the bidding mechanism only changes the prompt given to the diffusion model according to the bid weights, without modifying the internal diffusion score composition or guidance.\nHuman-Centric Validation: Are there plans to conduct human studies or ad platform experiments to validate semantic fidelity and economic incentives in real-world contexts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wSe0OAD4uU", "forum": "naYMDn0l19", "replyto": "naYMDn0l19", "signatures": ["ICLR.cc/2026/Conference/Submission14031/Reviewer_sy7L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14031/Reviewer_sy7L"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14031/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762872323356, "cdate": 1762872323356, "tmdate": 1762924518819, "mdate": 1762924518819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}