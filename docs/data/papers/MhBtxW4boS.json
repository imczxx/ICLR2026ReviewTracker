{"id": "MhBtxW4boS", "number": 8858, "cdate": 1758100137532, "mdate": 1759897759139, "content": {"title": "Shortcuts in Material Design: Efficient Generative Modeling of Amorphous Materials", "abstract": "Amorphous materials, such as glasses, are solids that lack long-range atomic order but possess complex short- and medium-range order. Inverse design of amorphous materials with probabilistic generative models aims to generate the atomic positions and elements of amorphous materials given desired properties. It has emerged as a promising approach for facilitating the application of amorphous materials in domains such as energy storage and thermal management. In this paper, we introduce MDShortcut, an inference- and training-efficient probabilistic generative model for amorphous materials. MDShortcut enables accurate inference of diverse short- and medium-range structures in amorphous materials with only a few sampling steps, mitigating the need for an excessive number of sampling steps that hinders inference efficiency. MDShortcut can be trained once with all relevant properties and perform inference conditioned on arbitrary combinations of desired properties, mitigating the need for training one model for each combination. Experiments on two amorphous materials datasets with diverse structures and properties demonstrate that MDShortcut achieves its design goals.", "tldr": "", "keywords": ["amorphous materials", "inverse design", "generative model"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4150be587243f3239684dc33c86139f53dfdabe1.pdf", "supplementary_material": "/attachment/7004575fe837414e9bb147fa5a8c85c6b6478b7e.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a generative model for the generation of disordered, or amorphous, materials. Their approach is based on diffusion/flow-matching and incorporates techniques from multiple previous works. Most prominently, they use a distillation technique for one-step diffusion [1] to reduce the number of inference steps required. Additionally, they use a technique for training models conditioned on multiple variables, but enabling sampling with only a subset of them [2].\n\nThey benchmark their models with and without distillation, showing how the distillation enables generation with fewer steps, and how the conditioning techniques allows training a single model for multiple conditional tasks.\n\nPlease see more details under “strengths/weaknesses/questions”, but to summarize the reasons for my rating: while the application seems interesting and somewhat novel, and the proposed improved design seems to improve over the proposed baseline designs, I think the main problem is that the empirical evaluation is lacking comparison with other methods, and that some claimed disadvantages of previous models are not well motivated/explained, nor shown empirically. This means that the developed method is not evaluated and tested enough for a method development paper at a conference like ICLR. \n\n[1] Kevin Frans, Danijar Hafner, Sergey Levine, and Pieter Abbeel. One step diffusion via shortcut models. In International Conference on Learning Representations, 2025\n[2] Seyedmorteza Sadat, Manuel Kansy, Otmar Hilliges, and Romann M. Weber. No training, no problem: Rethinking classifier-free guidance for diffusion models. In International Conference on Learning Representations, 2025."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The use of diffusion/flow-matching for generating amorphous materials seems like a rather new and under-explored research direction application, although this is not my area of expertise."}, "weaknesses": {"value": "The main weakness is the lack of comparison with other methods. First off, it is claimed (line 440), that amorphous materials have specific characteristics “which makes generative models for molecules and crystals not directly applicable”. I am not an expert on amorphous materials so I will refrain on weighing in on whether that is true or not, but **with a claim like that I would like to see an explanation how the method developed in this paper is specifically designed to handle these characteristics.** To me, the method seems like a somewhat straight-forward use of diffusion/flow-matching, placing it in the same category as models like CDVAE [1], DiffCSP [2], and FlowMM [3] (and I think these and/or similar methods should be mentioned as part of the related work).  **Therefore, I think that either the authors would have to clarify how their method particularly handles “the lack of long-range atomic order” and “large simulation cells”, and/or demonstrate that these baselines indeed fail at these tasks** by running the same experiments. **But even if there is an explanation why the developed method better handles this, this should still be backed up by some experiments to show that previous methods indeed fail.** It seems like a fixed cell is used (see also \"Questions\"), and a simple baseline would be to use a model for crystal generation, and just remove the cell-update part in training and generation and use the same procedure that you use for initializing the fixed cell. I also have some further questions about the evaluation, see “Questions”\n\nAs I interpret that the motivation of this paper is that previous methods are not applicable in this task, I expect something to **make it clear that the paper addresses these shortcomings of previous work**, but as I do not find that in the paper, I therefore do not think that the contribution is clear enough for this venue. \n\n[1] Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi S. Jaakkola. Crystal diffusion variational autoencoder for periodic material generation. ICLR 2022\n[2]  Crystal Structure Prediction by Joint Equivariant Diffusion, Rui Jiao, Wenbing Huang, Peijia Lin, Jiaqi Han, Pin Chen, Yutong Lu, Yang Liu, NeurIPS 2023\n[3] Miller, B.K., Chen, R.T.Q., Sriram, A. &amp; Wood, B.M.. (2024). FlowMM: Generating Materials with Riemannian Flow Matching. ICML 2025"}, "questions": {"value": "In Figure 3, I don’t understand what you mean by “the distribution of the target properties is designed to fall outside the distribution of training “ (line 352). Do you mean that you condition on values outside of the training data? Then I don’t think a histogram is the correct way to present the results if you want to convey that the model generates according to the target: it should be a plot showing target value on one axis, and generated value on the other axis (training data of course don’t have a target value, but could perhaps be presented separately in a histogram). If just presenting a histogram, it is not possible to determine if the model generates outside of the training values because you conditioned on it, or if it is because it just generates randomly.\n\nLine 356: what does it mean that you linearly interpolate value? That you choose which values to condition evenly spaced between these values?\n\nTable 2: Where is MDShortcut (Target)? (also minor detail, I would prefer the “Cell format text” in tables to be put in caption for easier reading”)\n\nAs I am not particularly knowledgeable about the specific use-case: is the unit cell always kept fixed? Is this standard procedure in this application? Is this cell the same in all experiments? \n\nExperiments: Do I interpret it correctly that the data used is from the paper Finkler et al (2025), or did you generate this yourselves?\n\nLine 470: what do you mean with the loss for 25 % of samples?\n\nLine 70: You say that there is a lack of trained classifiers. However, as you have data with properties that you use for training a conditional model, shouldn’t you be able to train a classifier using this data? The claim of “poor availability” on line 70 seems like unjustified in this case (as there seems to exist data to train such models)\n\nAs you use “ghost atoms” to enable a fixed number of atoms, how is this number chosen?\n\nMinor question: When you use RMSD as a metric, I interpret this as you have a grid of distances/angles and compute RDF/ADF, for each of the values on the grid, and compute RMSD between these values calculated on the generated and reference structures. Is this the best choice, or could something like total variation distance between discrete distributions have been used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9UctGdQ1KC", "forum": "MhBtxW4boS", "replyto": "MhBtxW4boS", "signatures": ["ICLR.cc/2026/Conference/Submission8858/Reviewer_Z8v2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8858/Reviewer_Z8v2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761308734298, "cdate": 1761308734298, "tmdate": 1762920623385, "mdate": 1762920623385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes learning shortcuts as an efficient training and inference procedure within diffusion models for inverse design of amorphous materials (generating materials conditioned on properties) and demonstrates generalization when conditioned on different properties. The results show improved efficiency with similar performance when compared to proposed baselines."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper adapts existing ideas in diffusion models to build MDShortcut model for amorphous materials.  \n- The method is extremely efficient in training and inference while retaining its accuracy in materials generation and supports this with large number of experiments.\n- The method shows generalization to different target properties combination than it was trained with for inverse design."}, "weaknesses": {"value": "My main concerns can be categorized into the following:\n- lack of proper contextualization with related work\n- insufficient background for amorphous materials inverse design problem\n- missing crucial details regarding experiment and motivation for some design choices\n\nThese weakenesses are supported in the questions below. I am willing to increase the score if the questions are adequately answered during the discussion period."}, "questions": {"value": "- If amorphous materials \"lack long-range atomic order but possess complex short- and medium-range order\", how is designing local cell structures useful for downstream applications of amorphous materials? Does generating these local structures capture enough information to  predict properties? Essentially, shouldn't the task ask to design the entire material rather than one cell?\n- The paper suggests that \"lack of large-scale datasets and unique atomic ordering characteristics\" as the main challenges for using existing crystal generation approaches [1,2,3,4]. However,\n  - It is not mentioned how MDShortcut and baselines defined within the paper are trained (i.e., which datasets, its description, and if these datasets are used in previous works or not)?\n  - I don't identify differences in the representation of amorphous materials (in section 2.1) and crystals. What needs to be learned differently than crystals as defined in above references? Am I missing something? \n  - If one crucial difference is the number of atoms within the cell, then I am not sure which component in MDShortcut or baselines allow this to happen. The underlying architecture is inspired from EGNN which is also used in many works for crystals and molecule design.\n  - From my understanding, there is nothing that could hinder using existing crystal generation methods for this task? Or, am I missing something here too?\n- Regarding related work, the authors do not appropriately discuss the existing works (mentioned in the paper) on amorphous materials and in which aspects they differ. The methods proposed in these works are not considered in baselines also. This work should:\n  - contrast the methodological differences across MDShortcut and these existing works\n  - compare the performance of these methods with MDShortcut results\n- Can MDShortcut be used for crystal generation task? What are the challenges in using this method to such a task? Please note that I am not asking for experimental results and comparison to existing works rather from conceptual lens.\n- Can you point out the crucial novelty/novelties of MDShortcut? I feel the proposed learning shortcuts is a direct adaptation of self-consistency loss which has been explored in other domains. Also, how is *material differential equation* different for amorphous and crystals (which already drives most of the crystal generation works)?\n- Regarding experimental setup:\n  - what properties are entailed within the \"All\" training setting?\n  - in the \"target\" setting, predicting and conditioning on the same target properties is not ideal (because of information leakage) and could be better to train on subset of All - {target properties} and predict the target properties. Was this setup considered?\n  - why is the RMSD of RDF and ADF of generated samples compared with training samples and not test samples (which is preferred and common in crystal generation)?\n  - why are the invalid generation (e.g., charge imbalanced samples) not removed? \n  - what percentages of generated samples are invalid?\n\n\n1. Crystal Diffusion Variational Autoencoder for Periodic Material Generation. Xie et al. ICLR 2022.\n2. Crystal Structure Prediction by Joint Equivariant Diffusion. Jiao et al. NeurIPS 2023.\n3. Space Group Constrained Crystal Generation. Jiao et al. ICLR 2024\n4. SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models. Levy et al. ICLR 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IQEKqCYLi9", "forum": "MhBtxW4boS", "replyto": "MhBtxW4boS", "signatures": ["ICLR.cc/2026/Conference/Submission8858/Reviewer_ZfcL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8858/Reviewer_ZfcL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761549402124, "cdate": 1761549402124, "tmdate": 1762920623055, "mdate": 1762920623055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents MDShortcut, an innovative probabilistic generative model aimed at accelerating and improving the inverse design of amorphous materials—such as glasses, which are structurally complex and lack long-range atomic order. The work addresses two long-standing challenges in generative modeling for materials science: slow inference due to many sampling steps and the need to train separate models for different property combinations. MDShortcut introduces an elegant solution through two key innovations. First, it learns “shortcuts” in the generative process, allowing it to produce accurate material structures in only a few sampling steps. This dramatically reduces inference time—by as much as 99% compared to existing Material ODE and SDE models—while maintaining high structural fidelity. Second, it employs a flexible material denoiser trained once on all relevant properties, which can condition generation on any arbitrary subset of target properties. This “train once, use flexibly” paradigm eliminates the need for multiple specialized models and introduces a practical mechanism using “null properties” to handle missing conditions. The model’s effectiveness is demonstrated on datasets of amorphous silicon (a-Si) and amorphous silica (a-SiO₂), where it matches or surpasses existing methods in accuracy while being significantly faster and more adaptable. These results showcase MDShortcut’s potential to make inverse material design more scalable and efficient, marking a meaningful advancement in the intersection of machine learning and computational materials science."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "MDShortcut represents a major advancement in inverse material design by offering exceptional computational efficiency and flexibility compared to traditional diffusion models. It generates high-quality amorphous material structures in just a few sampling steps, drastically reducing inference time while maintaining structural accuracy. This efficiency enables high-throughput material discovery under the same computational budget that conventional models would require for far fewer samples. Despite its speed, MDShortcut preserves or surpasses the structural and inverse design accuracy of slower baselines, accurately reproducing key structural features and target properties with minimal computation. Its flexible denoiser architecture allows a single trained model to handle multiple material properties and adapt to various inference conditions without retraining, even when some conditioning properties are absent. Altogether, MDShortcut combines diffusion-level structural fidelity with orders-of-magnitude faster generation, making it a powerful and practical tool for rapid, large-scale amorphous material design."}, "weaknesses": {"value": "Despite its remarkable efficiency, MDShortcut has several limitations related to training complexity, structural validity, and extreme-case performance. While inference is extremely fast, training the model introduces additional computational overhead due to the shortcut mechanism, though this is mitigated by applying the shortcut loss to only a subset of training batches. Structurally, MDShortcut can sometimes generate multi-element samples that are not charge balanced, reducing their physical realism and limiting direct real-world usability—a challenge that remains difficult to solve due to the non-differentiable nature of charge balance constraints. The model also inherits diffusion models’ difficulty in generating annealed, low-energy structures, as these states cannot be achieved simply by increasing sampling steps, and existing refinement methods remain computationally slow. Finally, although MDShortcut performs well structurally even with a single sampling step, its inverse design accuracy declines in such cases because its property embeddings depend on multi-step randomization. These challenges highlight areas for future work to further improve MDShortcut’s physical consistency, training efficiency, and robustness."}, "questions": {"value": "1. [Abstract] The abstract needs to be updated, at the moment it looks vague, kindly answer the question as to what is your work precisely focusing on. Using sentences like \n\n> MDShortcut can be trained once with all\nrelevant properties and perform inference conditioned on arbitrary combinations\nof desired properties, mitigating the need for training one model for each combi-\nnation. Experiments on two amorphous materials datasets with diverse structures\nand properties demonstrate that MDShortcut achieves its design goals.\n\nCan raise questions like : What relevant properties? Which arbitrary combinations? Which design goals?\n\n2. [Line 48] What is the definition of \"Shortcut\" in your paper? Does it refers to Inverse design? Or some efficient methodology which you have implemented within inverse design? Be specific\n\n3. [Line 55] Why is the field under-developed? Is there a particular reason, I see you mentioned unique atomic ordering, but that's not reasoning; that's a fact about amorphous material and not a reason why it is under-developed.\n\n4. [Line 63] : Add a reference to the section/ plot where you've shown this comparison between earlier model (which you can call baseline models) and your own model. And what is SDE, ODE? Where have you defined these abbreviations? \n\n5. [Line 65] : Conditioning on a variety of properties, which properties? And why is training efficient hindered by conditioning? It should usually become more efficient since you are now generating on a smaller and focussed subset on which you are conditioning on.\n\n6. Have you read about implicit diffusion models (DDIM, https://arxiv.org/abs/2010.02502); how is your method different from just applying implicit diffusion model as an application?\n\n7. [Line 95] : Again vague, what experiments? define the experiment in short and add the reference section/ plot.\n\n8. [Line 108] : What is ghost atom? Why give it such a peculiar name? If I read it write it's just another way of either conditioning or parameterizing. Be a bit nitty about these things when you're writing in such high standard journals.\n\n9. [Line 117 - 157] is just writing DDPM/ DDIM equations with some changed notations. Cut short all this, your work doesn't not derive anything new.\n\n10. [Section 3] : before evaluation, tell us the training dataset and the training details please.\n\n11 [Section 4] : Since the paper is about diffusion models for material generation, rather than focussing on papers covering fundamentals of diffusion models; you should primarily include papers in the field of material generation. I can mention a few previous submissions which I have seen previously highly similar to your work (a) Sinha, Anshuman, Shuyi Jia, and Victor Fung. \"Representation-space diffusion models for generating periodic materials.\" arXiv preprint arXiv:2408.07213 (2024). ; (b) Luo, Youzhi, Chengkai Liu, and Shuiwang Ji. \"Towards symmetry-aware generation of periodic materials.\" Advances in Neural Information Processing Systems 36 (2023): 53308-53329. Kindly review these works which have high similarity to your work and have been well cited previously.\n\n12. Do you have any experimental result which we can compare with?\n\nI feel the paper is written by a new author in the field, and as a reviewer I wish to encourage such authors. But have to maintain strict standards of ICLR platform; kindly address each of the above 12 questions and the corresponding changes meticulously so that we can make this paper and your article better."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "I did not find any concerns related to Ethics"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "agXxwFYkUE", "forum": "MhBtxW4boS", "replyto": "MhBtxW4boS", "signatures": ["ICLR.cc/2026/Conference/Submission8858/Reviewer_tJ51"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8858/Reviewer_tJ51"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948408387, "cdate": 1761948408387, "tmdate": 1762920622489, "mdate": 1762920622489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of inefficient and inflexible generative modeling for amorphous materials. To address this, the authors propose MDShortcut, a shortcut-aware denoising framework built upon a Material Differential Equation that learns step-size-dependent dynamics, enabling few-step (as few as 1–5) generation while maintaining structural accuracy. They also introduce a flexible conditional denoiser that uses null-property embeddings, allowing a single model to perform inverse design under any subset of target properties without retraining or external classifiers. Experiments on two amorphous material datasets, silicon (a-Si) and silica (a-SiO₂), show that MDShortcut achieves up to 99% reduction in inference time compared to Material SDE/ODE baselines while preserving or improving structural metrics (RDF/ADF) and inverse design accuracy for shear modulus and ring-size distribution."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Experimental results show that the proposed method effectively reduces the number of sampling steps needed to generate structurally accurate amorphous material samples. \n\n2. The proposed method achieves better accuracy in inverse design tasks compared to the baseline methods."}, "weaknesses": {"value": "1. The scope of the inverse design experiments is limited. The paper claimed the proposed method can be used for inference conditioned on arbitrary subsets of desired properties. However, the authors only conduct experiments on one dataset with two properties. \n\n2. Missing comparison to published baselines (e.g., [1]). The authors only compare against two self-proposed baselines.\n\n3. Insufficient evidence for training efficiency. Although the authors claim training efficiency as one contribution, they do not provide experimental results (e.g., training time of the model compared to the baselines) related to the statement.\n\n4. In the experiments, the authors may also consider evaluating the physical properties (e.g., energetic stability) and other DFT-level validations.\n\n[1] Zeni, Claudio, et al. \"A generative model for inorganic materials design.\" Nature 639.8055 (2025): 624-632."}, "questions": {"value": "The authors conduct experiments with sampling steps up to 250. In some materials generation frameworks, the number of steps can go up to 1000 (e.g., FlowMM). How does MDShortcut perform with more inference steps compared to baseline methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Pj410QWHkU", "forum": "MhBtxW4boS", "replyto": "MhBtxW4boS", "signatures": ["ICLR.cc/2026/Conference/Submission8858/Reviewer_F3RS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8858/Reviewer_F3RS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762028948030, "cdate": 1762028948030, "tmdate": 1762920622115, "mdate": 1762920622115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}