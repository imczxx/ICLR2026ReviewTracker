{"id": "n9Ps1SFOlE", "number": 18254, "cdate": 1758285681131, "mdate": 1759897116312, "content": {"title": "GradCFG: Gradient Inversion of Classifier-Free Guidance Diffusion Models", "abstract": "Gradient inversion attacks, as a means of privacy theft, have been extensively studied and applied in classifier models, yet research on gradient inversion for diffusion models, particularly classifier-free guidance (CFG) diffusion models, remains relatively underdeveloped. CFG models such as Stable Diffusion present significant challenges for such attacks due to their complex training mechanisms, including the high-dimensional search space caused by multimodal variables, the non-uniqueness of the noise $\\epsilon$ solution space, and the difficulty in optimizing discrete time steps $t$. To address these challenges, this paper proposes a novel joint inversion framework featuring two core algorithmic innovations: the **GradCFG** algorithm, which integrates a four-variable co-optimization mechanism for simultaneous reconstruction of image latent variables $\\mathbf{x}_0$, text embeddings $C_0$, noise $\\epsilon$, and reparameterized continuous time steps $t$, alongside a periodic restart strategy for $\\epsilon$ to enhance solution stability and generalization; and the **Inv-Sam** algorithm, a model-difference-based generation optimization method that leverages the generative capability disparities between pre-fine-tuning and post-fine-tuning models to restore high-resolution details through a reverse-forward diffusion editing process. Systematic experiments in CFG model fine-tuning scenarios demonstrate that the proposed method effectively achieves high-quality image-text joint reconstruction for various textual conditions ranging from concise descriptions to complex semantic combinations.", "tldr": "", "keywords": ["Gradient Inversion Attack", "Diffusion Models", "Classifier-Free Guidance", "AI Safety", "Dataset Reconstruction"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b0e68650bd8934a95b14ced5a83ec74f0ac7fe3.pdf", "supplementary_material": "/attachment/df7c9e430c9750b4811bd0af328d7ea754d4baae.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates gradient inversion attacks on Classifier-Free Guided (CFG) diffusion models, aiming to expose potential privacy risks when model gradients are shared. The authors propose GradCFG, a framework that jointly optimizes four variables—the image latent, text embedding, noise, and diffusion timestep—to reconstruct both image and text data from gradients. The method introduces a continuous-time reparameterization to make the discrete timestep differentiable and a periodic noise reset to enhance optimization stability. Building upon this, the authors design Inv-Sam, an inverse–sampling refinement algorithm that leverages the difference between the fine-tuned and original models’ noise predictions to enhance reconstructed details. The approach effectively recovers private sample information and demonstrates a new privacy vulnerability in diffusion models, though the theoretical justification of Inv-Sam remains largely empirical."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper tackles a novel and underexplored problem—gradient inversion attacks on Classifier-Free Guided (CFG) diffusion models—highlighting a significant and realistic privacy risk in generative model training.\n2.\tThe follow-up Inv-Sam refinement strategy is conceptually creative, leveraging the difference between fine-tuned and base models to recover lost high-frequency details.\n3.\tExperiments on realistic datasets show clear improvements in reconstruction quality, and the analysis provides meaningful insights into multi-modal gradient inversion."}, "weaknesses": {"value": "1.\tThe Inv-Sam refinement relies on an empirical assumption that the difference between the fine-tuned and base models encodes training-sample-specific details. While this idea is intuitively appealing, it lacks solid theoretical justification or causal evidence linking parameter shifts to concrete data features. The claim that Inv-Sam restores “fine-grained details” therefore appears somewhat overstated without stronger empirical validation. It is more plausible that the observed signal primarily reflects semantic adaptation—changes in concept alignment or attention—rather than genuine pixel-level detail recovery. \n2.\tThe optimization process in GradCFG is extremely sensitive to the intrinsic stochasticity of diffusion models. Diffusion processes involve random noise sampling and discrete timesteps, both of which can drastically change the gradient landscape. Even though GradCFG introduces noise resetting and timestep reparameterization, the optimization objective remains non-convex, noisy, and highly multimodal. This means convergence may depend heavily on initialization and random seeds, making the reconstructed results unstable or inconsistent across runs.\n3.\tThe computational cost of jointly optimizing four high-dimensional variables (latent image, text embedding, noise, and timestep) is considerable, limiting the approach’s practical scalability to larger CFG models or federated learning settings."}, "questions": {"value": "Please see the weakness. \n\nGiven the inherently stochastic nature of diffusion processes—where random noise sampling and discrete timesteps play a central role—the reliability of any gradient-based inversion remains questionable. As a result, the reproducibility and stability of the proposed inversion process are uncertain, raising concerns about its robustness in practice."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5FE7kRF6NO", "forum": "n9Ps1SFOlE", "replyto": "n9Ps1SFOlE", "signatures": ["ICLR.cc/2026/Conference/Submission18254/Reviewer_aUCK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18254/Reviewer_aUCK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760518252537, "cdate": 1760518252537, "tmdate": 1762927981642, "mdate": 1762927981642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper adapts the gradient inversion attack, which is commonly used in classifier models, to the domain of diffusion generation models. To demonstrate the feasibility of this attack on Classifier-Free Guidance (CFG) models, the authors propose GradCFG, complemented by the Inv-Sam strategy. GradCFG is designed around a Quadruple Collaborative Optimization Algorithm, which enables the reconstruction of multiple high-dimensional variables: the image latent variable $x_0$, text embeddings $C_0$, noise $\\epsilon$, and reparameterized continuous time steps $t$. The Inv-Sam strategy further enhances the quality of the reconstructed image latent variable by leveraging the differences between the pre-finetuning and post-finetuning versions of the model."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The evaluation includes detailed experiments that sufficiently demonstrate the effectiveness and efficacy of the proposed GradCFG method.\n2. The proposed method successfully recovers both the training image data and the paired text prompt simultaneously, addressing a significant challenge in prior gradient inversion attacks.\n3. The implementation details of the method are clearly explained and effectively supported by corresponding pseudocode, contributing to the reproducibility of the work."}, "weaknesses": {"value": "1. The paper claims to present a gradient inversion attack specifically applicable to general Classifier-Free Guidance (CFG) diffusion models. However, the experimental validation is exclusively performed on personalized generation tasks. This limited scope suggests the claim might be overly broad.\n2. The clarity and focus of the writing in certain sections are weak (e.g., the content described around Line 80 is overly broad and lacks necessary specificity).\n3. The paper fundamentally emphasizes a gradient attack methodology. However, the Inv-Sam module utilizes the output and knowledge derived from the finetuned model. The authors should provide a robust justification for the consistency and validity of incorporating this model-specific information within the definition of a gradient inversion attack.\n4. The experiment presented in Section 5.4 intended to demonstrate the non-uniqueness of the noise $\\epsilon$ is not convincing. The large discrepancy observed between $\\hat{\\epsilon}$ and $\\epsilon$ could potentially be attributed to the model's inherent prediction accuracy limitations or the intrinsic stochasticity of $\\epsilon$ itself, rather than solely being definitive proof of its non-uniqueness."}, "questions": {"value": "1. Since the Inv-Sam module relies on priors from the fine-tuned model, it is important to clarify how much the model overfits to the training data. Please provide visualizations of the fine-tuned model to support this analysis.\n2. The current experimental setting focuses on attacking models fine-tuned using a single image. In practical personalization tasks, multiple images are typically used for fine-tuning. Would the proposed GradCFG method remain effective under these more complex multi-image fine-tuning conditions?\n3. The ablation study is incomplete. Specifically, ablation studies are missing for key hyperparameters within the optimization process, such as the switching time step ($S_{\\text{switch}}$) and the reset time step ($S_{\\text{reset}}$).\n4. The function of the $L_{\\text{mix}}$ loss appears limited to suppressing uncorrelated noise in the reconstructed $x_0$, rather than achieving the stated goal of “feature disentanglement and prevention of feature mixing.” The authors should provide further ablation studies or visual analyses to substantiate the claimed disentanglement effect. \n5. It is mentioned in the supplementary materials that the continuous time step $t$ is restricted to the range [400, 600] during optimization. What is the fundamental justification of this specific constraint?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "m6zzPhHkZ0", "forum": "n9Ps1SFOlE", "replyto": "n9Ps1SFOlE", "signatures": ["ICLR.cc/2026/Conference/Submission18254/Reviewer_xW4i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18254/Reviewer_xW4i"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743432093, "cdate": 1761743432093, "tmdate": 1762927981227, "mdate": 1762927981227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GradCFG and Inv-Sam to address gradient inversion in classifier-free guidance diffusion models, aiming for joint image-text reconstruction. Experiments on DREAMBOOTH-like fine-tuning evaluate performance under generic/specific prompts, using metrics like SSIM and cosine similarity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "It is the first work to empirically demonstrate joint image-text gradient inversion for CFG models, filling a gap in diffusion model privacy research."}, "weaknesses": {"value": "1. The experiments lack direct comparisons with existing diffusion model gradient inversion methods (e.g., Huang et al. 2025a) or state-of-the-art gradient inversion techniques (e.g., GradInversion), making it hard to gauge relative performance.\n2. Only validates on TinySD and 512×512 DREAMBOOTH data; no tests on other CFG models (e.g., full Stable Diffusion) or higher resolutions."}, "questions": {"value": "1. Why not compare with Huang et al. (2025a, GIDM) or other diffusion-based gradient inversion methods to highlight GradCFG/Inv-Sam’s advantages?\n2. Is there a systematic rationale for choosing the Inv-Sam guidance scale ω_sam (e.g., hyperparameter sensitivity analysis)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "AKOdogzdTl", "forum": "n9Ps1SFOlE", "replyto": "n9Ps1SFOlE", "signatures": ["ICLR.cc/2026/Conference/Submission18254/Reviewer_sgw7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18254/Reviewer_sgw7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761784839983, "cdate": 1761784839983, "tmdate": 1762927980802, "mdate": 1762927980802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents the first gradient inversion attack targeting Classifier-Free Guidance (CFG) diffusion models. Unlike traditional settings that only reconstruct images, this method jointly recovers image latents, text embeddings, noise, and timesteps from shared gradients during fine-tuning. The proposed GradCFG framework performs a four-variable collaborative optimization, including a continuous reparameterization of the discrete timestep and a periodic noise reset to handle the non-uniqueness of noise solutions. To further enhance visual quality, Inv-Sam leverages the generative capability gap between pre- and post-fine-tuned models through a reverse-forward diffusion process to recover high-resolution details. Experiments on 512×512 DreamBooth-style fine-tuning show that the method successfully reconstructs both training images and their prompts with strong fidelity, revealing a severe privacy risk in CFG-based diffusion training."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper solves an important problem of the gradient inversion attack in classifier-free guidance diffusion models, which may actually violate the user's privacy, especially in a federated learning scenario. As a pioneering work in this field, I tend to believe it will shed light on future research.\n\n2. The proposed function reparameterization strategy is an elegant solution, well done. By transforming the noise scheduler into a differentiable integral form, the authors eliminate the non-differentiability barrier that has prevented prior gradient-based attacks on CFG diffusion models. This design not only enables seamless optimization of $t$ alongside other latent variables, but also retains compatibility with standard diffusion scheduling. The idea is conceptually simple, mathematically well-motivated, and practically impactful—an insightful contribution that clearly advances the feasibility of gradient inversion in diffusion-based systems.\n\n3. The four-variable joint optimization framework is well designed and technically ambitious. Prior attacks typically focus only on image reconstruction, while this work simultaneously recovers image latents, text embeddings, sampled noise, and timesteps—representing a significant expansion of attack surface and adversarial capability in multimodal diffusion training. The periodic noise reset mechanism is also a thoughtful addition, effectively addressing solution multiplicity and improving convergence stability."}, "weaknesses": {"value": "1. **Small batch size**: The authors mainly conduct experiments with a small batch size of 5, and the images within each batch appear to focus on the same object category. While this setup is reasonable for controlled evaluation, it deviates from real-world scenarios where a batch may contain more diverse and semantically unrelated samples, making inversion substantially more challenging. Although I expect the current method may not yet fully address the inversion of highly heterogeneous batches, the proposed approaches are technically solid and represent a meaningful step forward. Despite these limitations, I still believe the contributions are significant.\n\n2. **Lack of demonstrations of generalization**：All the experiments were conducted on TinySD. I suggest that more model types be examined, so as to show the generalizability of the proposed method.\n\n3. **Missing Comparison with Other Gradient Inversion Methods**: Although there is no direct baseline for CFG inversion, comparing against existing inversion methods for GAN-based reconstruction attacks would strengthen the empirical claim."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4wqVpRRIU3", "forum": "n9Ps1SFOlE", "replyto": "n9Ps1SFOlE", "signatures": ["ICLR.cc/2026/Conference/Submission18254/Reviewer_TnL3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18254/Reviewer_TnL3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966047835, "cdate": 1761966047835, "tmdate": 1762927980272, "mdate": 1762927980272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}