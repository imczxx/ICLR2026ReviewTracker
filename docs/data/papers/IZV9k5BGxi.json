{"id": "IZV9k5BGxi", "number": 8470, "cdate": 1758085185915, "mdate": 1759897782233, "content": {"title": "Global and Local Topology-Aware Graph Generation via Dual Conditioning Diffusion", "abstract": "Graph generation plays an important role in various domains such as molecular design, protein prediction, and drug discovery. However, generating graph-structured data poses challenges due to the complex dependencies inherent in graphs, spanning from intricate local substructures to broad global topologies.  Although recent advances in graph-generative models have made notable progress, most existing methods still leverage the node-level generative paradigms and struggle with graphs that exhibit pronounced sparsity and complicated multiscale relationships. To address these challenges, we propose a unified latent diffusion model that jointly learns local and global topological information, enabling effective and efficient graph generation. Besides, our approach introduces a dual conditioning mechanism designed to promote dynamic interaction between local and global information, equipping the generative model with global and local awareness to better capture the coupled dependencies within graphs. Our method can largely promote the joint modeling of global and local information and substantially improve the quality of the generated graphs. Extensive experiments consistently demonstrate the effectiveness of our proposed method.", "tldr": "", "keywords": ["generative model; AI for science; conditioning method"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/612d232b1dc3991c31425b5e134ac8b248145544.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes DualDiff, a latent diffusion model designed for graph generation that jointly captures both local and global topological information through a two-branch diffusion process and a dual conditioning mechanism.\n\nThe model encodes input graphs via a pretrained graph autoencoder, extracts global representations via graph clustering (spectral or K-means), and performs parallel diffusion on node-level and cluster-level latent variables, alternately conditioning one on the other. Experiments are conducted on generic graph datasets (Ego-small, SBM, etc.) and molecular datasets (ZINC250k, QM9, MOSES)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The motivation—capturing multi-scale (global and local) structural information in graph generation—is both timely and important.\n\n- The paper is very well-written and full of details.\n\n- The authors conduct comprehensive experiments, comparing with many recent diffusion-based and autoregressive graph generators."}, "weaknesses": {"value": "1. The paper defines “global information” simply as the cluster centroids obtained from node embeddings via K-means or spectral clustering. This is a very coarse, heuristic, and outdated approximation of global structure. It is not truly “topology-aware” as claimed. The authors do not justify why a fixed, non-learned clustering is preferable.\n\n2. The statement that “existing methods still leverage node-level generative paradigms” is too absolute. Many recent approaches already incorporate hierarchical or subgraph-level generation.\n\n3. Although the authors emphasize that the encoder takes 3D coordinate information as input for molecular graphs, the model ultimately generates only 2D molecular structures (bond graphs) rather than full 3D geometries.\n\n4. The authors claim Eq. (7) “implies that modeling the joint distribution of global and local information can be decomposed as two complementary processes” . In fact, Eq. (7) is merely a standard conditional-probability identity—any joint distribution can be written that way. Therefore, it provides no theoretical evidence that the proposed alternation scheme meaningfully models $p(Z_l​,Z_g​)$.\n\n5. On ZINC250k (Table 2), the reported Validity = 92%, which is much lower than baselines such as GruM (99%), GraphArm (100%), and GDSS (97%).  This indicates a serious failure in generating chemically valid molecules and undermines the claim that DualDiff captures local chemical constraints (e.g., valence, functional groups).\n\n6. Protein datasets, which contain larger graphs (100 < |V| < 500) are also widely used in generic graph generation. Moreover, related baselines such as GruM have reported results on these datasets. The authors are encouraged to include experiments on protein graphs to more comprehensively demonstrate the effectiveness and scalability of their proposed approach.\n\n7. The paper does not provide a code release or supplementary implementation details.  \nGiven the model complexity and multi-stage training (autoencoder + dual diffusion), reproducibility is questionable. Code should be provided for verification."}, "questions": {"value": "1. Why do the authors believe that a fixed, non-learnable clustering method (K-means or spectral) can define “global topology” more effectively than end-to-end hierarchical pooling approaches in modern GNNs?\n\n2. How sensitive are the results to the choice of clustering algorithm and the number of clusters $K$?\n\n3. Why not train the clustering jointly with the autoencoder or in the diffusion process to obtain adaptive global representations?\n\n4. The model’s validity on ZINC250k is only 92%. Does this reflect an inherent inability to capture local chemical rules? Have the authors examined failure cases?\n\n5. Can the framework be extended to explicitly generate 3D molecular structures rather than only 2D topologies?\n\n6. Is there any theoretical basis to justify Eq. (8) as a valid probabilistic factorization of $p(Z_l, Z_g)$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XusEKTghDS", "forum": "IZV9k5BGxi", "replyto": "IZV9k5BGxi", "signatures": ["ICLR.cc/2026/Conference/Submission8470/Reviewer_Cc24"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8470/Reviewer_Cc24"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761515671615, "cdate": 1761515671615, "tmdate": 1762920349999, "mdate": 1762920349999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a latent graph diffusion model that concurrently denoises node-level and cluster-level representations, coupled with a bidirectional conditioning mechanism to exchange global and local topological cues during generation. Extensive experiments on eight generic and molecular graph benchmarks demonstrate competitive or state-of-the-art performance in both unconditional and property-conditional generation while requiring fewer diffusion steps than prior diffusion counterparts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written and easy to follow.\n2. Using global & local latent features in graph diffusion models with learnable cross-conditioning is a reasonable design for the task.\n3. The empirical results across diverse datasets show the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The paper uses different global feature extraction methods in different tasks, but how to choose the method is unclear, which may lead to difficulty in generalization to new tasks.\n2. In ablation study, what if there is only local-to-global condition?\n3. At the beginning of sampling process, the number of nodes and clusters should be pre-determined, how to decide these numbers? What about the generalization ability of these numbers?"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "01L41rf1kv", "forum": "IZV9k5BGxi", "replyto": "IZV9k5BGxi", "signatures": ["ICLR.cc/2026/Conference/Submission8470/Reviewer_rfZi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8470/Reviewer_rfZi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924462162, "cdate": 1761924462162, "tmdate": 1762920349550, "mdate": 1762920349550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DualDiff, a dual-branch latent diffusion model that learns both global and local graph structures. The key idea is to run two diffusion processes, one at the node level and one at the cluster level, and let them interact through a dual conditioning mechanism. This design helps the model capture both fine-grained details and overall topology. Experiments on multiple benchmarks show clear gains over prior graph diffusion models, proving that the method effectively models multi-scale dependencies in graphs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Good motivation and clear design idea\nThe paper starts from a real problem that most graph diffusion models only handle node-level stuff. Splitting the process into local and global branches makes sense and is well explained.\n2. Thoughtful architectural design\nAlternating between the two diffusion branches is clever. It’s like doing local updates and then global aggregation, which keeps the training stable and avoids conflicts between the two processes.\n3. Strong and broad experiments\nThey test on both synthetic graphs and real molecular datasets, and the gains are consistent. It shows the method isn’t overfitted to one type of data."}, "weaknesses": {"value": "1. too dependent on clustering\nThe global branch comes from clustering nodes, so if the clustering is poor, the “global info” might be misleading. They don’t analyze this sensitivity much.\n2 . Efficiency claim not fully convincing\nThey say the model is efficient in the latent space, but with two diffusion networks and alternating steps, it’s unclear how much heavier it actually is.\n3. No solid theoretical grounding for stability\nThe alternating process is explained intuitively (like server-client updates), but there’s no formal guarantee or analysis of convergence."}, "questions": {"value": "1. The paper mentions that the alternating scheme improves stability, but is there any quantitative or theoretical evidence to support this? What happens if the two processes are trained simultaneously, rather than alternately?\n2. How sensitive is the model to the choice of clustering algorithm or the number of clusters K? Did you try other global extraction methods besides K-means or spectral clustering?\n3. Computation and scalability: Since you have two denoising networks and alternating updates, how much additional compute or memory does this introduce compared to a standard latent diffusion model, such as Latent Graph Diffusion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "w9WRkU31FX", "forum": "IZV9k5BGxi", "replyto": "IZV9k5BGxi", "signatures": ["ICLR.cc/2026/Conference/Submission8470/Reviewer_o5es"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8470/Reviewer_o5es"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992570318, "cdate": 1761992570318, "tmdate": 1762920348840, "mdate": 1762920348840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}