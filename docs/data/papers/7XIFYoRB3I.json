{"id": "7XIFYoRB3I", "number": 15604, "cdate": 1758253058853, "mdate": 1763335221248, "content": {"title": "Why Sacrifice Majority Nodes?: Improving Imbalanced Node Classification via Class-Balanced Graph Generation", "abstract": "Class imbalance is prevalent in real-world data, often leading to a deterioration in a classifier’s generalization performance, especially on minority classes. Since graph-structured data is no exception, many efforts have been made to tackle imbalanced node classification by focusing on minority classes, leading to improved overall performance in imbalanced node classification. However, we find that these methods boost minority recall at the expense of degrading majority recall, a trade-off that has been overlooked. To address this issue, we propose Class Balancing Graph Generation (CBGG), a novel framework that prevents imbalanced node classifiers from sacrificing prediction power on majority classes. CBGG trains classifiers on high-quality synthetic graphs with class-balanced nodes, thereby tightening their generalization bounds across all classes. Extensive experimental results demonstrate that CBGG not only overcomes the majority-sacrifice pitfall of prior work but also significantly outperforms state-of-the-art imbalanced node classification methods across seven benchmark datasets.", "tldr": "We propose a graph-generation approach for imbalanced node classification that overcomes a key limitation of existing methods.", "keywords": ["imbalanced learning", "imbalanced node classification"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/58870179d8c4974c438d432a052de1ccf28335fb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper focuses on the problem of class-imbalanced node classification and considers the trade-off between the majority and minority classes in existing oversampling methods.\nTo avoid sacrificing predictive power for the majority classes, this paper proposes Class-Balanced Graph Generation (CBGG). First, CBGG trains a novel diffusion-based graph generator, conditioned on the soft labels of an initial classifier, to synthesize  class-balanced graphs. Then, CBGG retrains the classifier based on the class-balanced graphs, thereby improving class-imbalanced node classification.\nExtensive experimental results demonstrate the effectiveness of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-organized and easy-to-follow.\n2. The experimental results show the proposed method can achieve state-ot-the-art performance."}, "weaknesses": {"value": "1. The novelty of the proposed method seems limited. The diffusion-based graph generator follows the previous method GraphMaker, including in the forward process and reverse process. CBGG generates graphs conditioned on the soft labels, which is also discusses in GraphMarker, \"To generate graph data with node labels, one naïve way is to simply generate node labels as extra node attributes\" (See Section 2.4 'Conditional generation given node labels' in GraphMarker).  Could you show some difference of the proposed graph generator compared with that in GraphMaker?\n2. As shown in Figure 1b, CGBB generates a large amount of training data, such as tens of thousands of training nodes, while other baselines that also use oversampling only have dozens of training nodes. Is this a fair comparison?\n3. The diffusion-based graph generator is conditioned on soft labels of an initial classifier, however, is the soft labels are reliable for graph generation? In particular, the classifier may under-perform on minority nodes, could the unreliable soft labels impact the graph generation?\n4. Due to the training cost of CGBB, the datasets used in the experiments are relatively small and cannot be well applied to real-world scenarios. In order to verify the practicality of CGBB, it should be extended to large datasets, such as the OGBN dataset."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U3byPdoLWJ", "forum": "7XIFYoRB3I", "replyto": "7XIFYoRB3I", "signatures": ["ICLR.cc/2026/Conference/Submission15604/Reviewer_bcCo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15604/Reviewer_bcCo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761685744681, "cdate": 1761685744681, "tmdate": 1762925874828, "mdate": 1762925874828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "UDihdZQbc5", "forum": "7XIFYoRB3I", "replyto": "7XIFYoRB3I", "signatures": ["ICLR.cc/2026/Conference/Submission15604/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15604/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763335220485, "cdate": 1763335220485, "tmdate": 1763335220485, "mdate": 1763335220485, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the class imbalance problem on graph data. In specific, it studies the imbalance problem for node classification tasks. Its core idea can be summarized as\n\n1. a generative model (a diffusion model in this paper) is trained on the given graph, conditioned on the node label matrix\n2. adjust the node label matrix so the labels are balanced; feed the balanced node label matrix to the generative model to generate \"label-balance\" synthetic graphs\n3. train a node classifier on both the original graph and the synthetic graphs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The overall method is easy to understand. The presentation of this paper is good.\n\nS2. The core idea is intuitive and reasonable, which generates the balanced class distribution, which improves the classifier's performance.\n\nS3. Looks like the proposed method gains good performance compared to baseline methods (Table 2)"}, "weaknesses": {"value": "W1. The novelty of this paper is not significant. Fundamentally, the key idea, as mentioned above, is to generate a balanced class distribution, which has been widely used in many literatures (on node classification problem) such as using mixup, SMOTE.\n\nW2. It is concerning why the proposed method can work: the method applies a diffusion model trained on the given graph. However, for the node classification tasks, the input graph usually only includes 1 graph. In other words, the # of training sample for the diffusion model is only 1. In that case, the model will tend to over-memorize the given data sample.\n\nW3. The contribution of this paper, to be frank, is limited. In detail\n\nW3.1 a lot of the section 3.3 is established model design. The main uniqueness is that the diffusion model is conditioned on the \"node label matrix\", different from the typical setting which conditions on the \"graph label\".\n\nW3.2 The socalled \"Original-Synthetic Balanced Loss (OSBL)\" is nothing new. It is very common to train the classifier on both the original nodes and synthetic nodes for the imbalanced classification problem.\n\nW3.3 The theoretical analysis (section 3.5) is not a unique contribution of this paper, which applies to most \"rebalancing\" based method, e.g., SMOTE.\n\nW4. I think the model architecture is not talked. I suggest to introduce it"}, "questions": {"value": "Q1. The paper mentioned that the conditioning is based on \"concatenating soft-label label vectors\". If I understand correctly, it concatenates the label vectors from all the nodes which would be pretty long. How the model architecture is designed to handle it?\n\nQ2. Above Eq. 9, the paper mentioned that it first sampled class c_i and then\"independently sampling soft label vectors\" based on c_i. It is a bit vague how define the label of the \"soft label vectors\"? Is it by its largest logit?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TboDP7iZwx", "forum": "7XIFYoRB3I", "replyto": "7XIFYoRB3I", "signatures": ["ICLR.cc/2026/Conference/Submission15604/Reviewer_zwKq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15604/Reviewer_zwKq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761781725240, "cdate": 1761781725240, "tmdate": 1762925874390, "mdate": 1762925874390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CBGG, a class-balanced graph generation framework that tackles the performance trade-off in imbalanced node classification where boosting minority recall typically compromises majority recall. Through a conditional diffusion model, CBGG produces high-quality synthetic graphs with balanced class distributions, providing diverse training samples for all classes. Comprehensive evaluations across seven benchmarks show CBGG substantially outperforms state-of-the-art methods while effectively alleviating the trade-off, simultaneously enhancing performance for both majority and minority classes. This work establishes graph-level generation as a new paradigm for class imbalance, supported by theoretical generalization bounds, offering significant implications and a solid benchmark for future studies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper systematically uncovers the long-overlooked \"performance trade-off\" in imbalanced graph learning, shifting the research focus from partially optimizing minority classes to holistically enhancing all categories.\n2. Paper pioneers a graph-level generation paradigm using conditional diffusion models to create class-balanced synthetic graphs, fundamentally redefining the solution landscape beyond conventional node-level oversampling.\n3. The method innovatively integrates soft-label conditioning with supervised contrastive learning, achieving deep synergy between the graph generation process and node classification objectives.\n4. The study establishes a comprehensive framework of argumentation integrating methodology, theoretical analysis, and experimental validation, demonstrating performance superiority across benchmark datasets while providing rigorous explanations through generalization theory."}, "weaknesses": {"value": "1. The survey of related work is somewhat inadequate, particularly lacking further elaboration on whether existing studies have attempted to address the inherent minority-majority trade-off problem.\n2. It is suggested to roughly categorize the experimental results by type (e.g., comparative experiments, analytical experiments) to enhance the structural clarity. Although experiments have been conducted under various scenarios, there remains a lack of additional analytical experiments to validate the model's superiority."}, "questions": {"value": "1. The paper mentions that existing methods have not sufficiently explored the inherent minority–majority trade-off. Are there any methods that have attempted to address this issue? If so, please summarize such methods and compare them with the method proposed in this paper to further argue the motivation of this chapter.\n2. In line 192, there is a lack of explanation for the function γ_Z(t).\n3. In the paragraph corresponding to line 450 in Section 4.2, two metrics are used to evaluate whether the generator can capture real graph properties. These two metrics are mainly used to measure the differences in node attributes, but there is a lack of metrics to measure the semantic differences in edges.\n4. The core innovation of this paper is graph-level generation. Can experiments be designed to isolate the effect of generation itself? For example, comparing it with a simple method of “sampling nodes from the original graph to form a new graph” to prove that the high-quality data generated by the diffusion model is the key to performance improvement, rather than simple data augmentation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LkO8pqe5uP", "forum": "7XIFYoRB3I", "replyto": "7XIFYoRB3I", "signatures": ["ICLR.cc/2026/Conference/Submission15604/Reviewer_gEJA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15604/Reviewer_gEJA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986365474, "cdate": 1761986365474, "tmdate": 1762925873900, "mdate": 1762925873900, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical issue of class imbalance in graph-structured data for node classification. The authors identify a key limitation in existing methods: while they improve minority-class recall, they often do so at the expense of majority-class performance. To mitigate this trade-off, the proposed framework, Class Balancing Graph Generation (CBGG), leverages diffusion-based graph generation to create class-balanced synthetic graphs. By training classifiers on these graphs, CBGG aims to tighten generalization bounds across all classes. The authors support their claims with theoretical analysis and extensive experiments on five benchmark datasets, demonstrating state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper highlights an underexplored but important trade-off in imbalanced node classification—improving minority recall at the cost of majority recall—which motivates the proposed method.\n\n2. CBGG introduces a graph-level generation paradigm for class imbalance, combining diffusion-based generation with supervised contrastive learning to produce high-quality synthetic graphs.\n\n3. The authors provide a theoretical analysis of generalization bounds and empirically validate CBGG on seven benchmarks, showing consistent improvements over existing methods."}, "weaknesses": {"value": "1. The experimental evaluation, while extensive, does not include large-scale real-world graphs (e.g., with millions of nodes), raising questions about scalability and applicability to truly massive datasets.\n\n2. The use of diffusion-based graph generation and multiple training stages (initial classifier, generator, and final classifier) may introduce significant computational overhead, which is not thoroughly discussed or evaluated."}, "questions": {"value": "1. How does CBGG ensure the quality and diversity of synthetic graphs, especially when the initial classifier is trained on imbalanced data?\n\n2. Could the performance gains be attributed solely to the increased quantity of synthetic data, rather than the graph generation process itself?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PCUxV39CBE", "forum": "7XIFYoRB3I", "replyto": "7XIFYoRB3I", "signatures": ["ICLR.cc/2026/Conference/Submission15604/Reviewer_iUpF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15604/Reviewer_iUpF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762083474969, "cdate": 1762083474969, "tmdate": 1762925873595, "mdate": 1762925873595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}