{"id": "PcjvI4OlED", "number": 18147, "cdate": 1758284361787, "mdate": 1759897126444, "content": {"title": "Multi-Integration of Labels across Categories for Component Identification (MILCCI)", "abstract": "Many fields collect large-scale temporal data through repeated measurements (`trials’), where each trial is labeled with a set of metadata experimental variables. These metadata often include labels spanning several categories. For example, a trial in a neuroscience study is linked to a value from category (a): task difficulty, and category (b): animal choice. A critical challenge in time-series analysis is thus to understand how these labels are encoded within the multi-trial observations, and disentangle the distinct effect of each label entry across categories. Here, we present MILCCI, a novel data-driven method that i) identifies the interpretable components underlying the data, ii) captures cross-trial variability, and iii) integrates label information to understand each category's representation within the data.  MILCCI extends a sparse per-trial decomposition that leverages label similarities within each category to enable subtle, label-driven cross-trial adjustments in component compositions and to distinguish the contribution of each category.  MILCCI also learns each component’s corresponding temporal trace, which evolves over time within each trial and varies flexibly across trials. We demonstrate MILCCI’s performance through both synthetic and real-world examples, including voting patterns, online page view trends, and neuronal recordings.", "tldr": "We present a novel data-driven method that identifies core components in multi-trial, multi-label temporal data while disentangling how each label dimension is encoded within the observed dynamics.", "keywords": ["multi-trial data", "multi-label analysis", "component identification", "matrix factorization", "tensor factorization", "dictionary learning", "data-driven models", "interpretability", "neural ensembles"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/45722f092f9a185de9e9b843f321fbc9e6615988.pdf", "supplementary_material": "/attachment/0c2ca5797bc40b14ae0ff550ed8f3e5cf9110865.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies a matrix factorization problem specialized to tensor data commonly generated in many fields, including neuroscience. In the neuroscience application, the generative model for one trial has a loading matrix that is formed from a tensor of shape cells x components x category options (layers) x categories. (e.g., If category is 'task', layers can be easy, medium, hard. If it is 'choice', layers can be correct, incorrect.) The loading matrix for a given trial (e.g., with metadata task=easy, choice=correct) is formed by concatenating the layer matrices corresponding to that trial (e.g., layer 'easy' under task, and layer 'correct' under choice) The aim of the matrix factorization is to infer this loading matrix and the temporal trace matrix that it multiplies.\n\nMatrix decomposition is performed by iteratively solving for the loading and temporal trace matrices. (in a loop: solve for the loading matrix when the trace matrix is constant, solve for the trace matrix when the loading matrix is constant) This iterative method uses multiple heuristic objective function components:\n- data fidelity (L2)\n- sparsity (L1; has a hyperparameter)\n- temporal smoothness (L2 between consecutive time points of the trace matrix, has a hyperparameter)\n- de-correlation of temporal trace components, has a hyperparameter)\n- consistency between the cell x component matrices corresponding to different options of given category (L2, has a hypermarameter. This has one more hyperparameter for categories with ordinal labels, the st. dev. of the Gaussian kernel.)\n\nThe method is applied to a synthetic dataset, a large-scale neuroscience dataset, a US states-level voting dataset, and a wikipedia pageview counts dataset. On the synthetic dataset, the method is quantitatively compared against baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Analyzing data in relation to underlying complex metadata structure is a prominent problem.\n- This paper takes advantage of prior knowledge on the structure of metadata, unlike other more generalist approaches. I think this is the paper's most prominent contribution.\n- This paper offers a linear decomposition which improves interpretability.\n- The paper demonstrates its method across three real-world datasets."}, "weaknesses": {"value": "- Similar methods exist to analyze neuroscience data. In particular, not even citing the Pellegrino et al, \"Dimensionality reduction beyond neural subspaces with slice tensor component analysis,\" Nature Neuroscience, 2024 paper is a big miss. I believe this paper should be added as a baseline, too.\n\n- The method has multiple hyperparameters. Neither their sensitivity is properly discussed nor is it clear whether similar effort was spent to tune the competing models.\n\n- The approach does not have a dynamics model. The only temporal processing comes from a penalty component to ensure temporal smoothness of the trace matrices. Therefore, it is not clear why the focus is on temporal data. Conversely, temporal smoothness could be added in a similar manner to some of the other tensor decomposition methods studied here.\n\n- With such large datasets, probabilistic models (e.g., variational) that are optimized with gradient descent have shown remarkable performance across many applications. Here, the focus has been on matrix decomposition, which is readily interpretable. However, I consider a lack of any emphasis on noise modeling or analysis as a weakness.\n\n- The consistency heuristic that enforces the cell x component matrices corresponding to different options of a given category is not clear to me.\n\n- I find the wikipedia study anecdotal. There is a full page of text that describes seemingly cherry-picked results. Out of how many pages and components are the displayed results shown/discussed is not clear."}, "questions": {"value": "- The SliceTCA method of Pellegrino seems relevant. Could the authors compare against that?\n\n- Could you please add details on the tuning of hyperparameters; the procedure and sensitivity of the results to the hyperparameters. Was hyperparameter tuning performed for the baselines?\n\n- Could you please explain the intuition behind the consistency heuristic? What is the effective assumption and does it apply to all datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QfJnBLj8jA", "forum": "PcjvI4OlED", "replyto": "PcjvI4OlED", "signatures": ["ICLR.cc/2026/Conference/Submission18147/Reviewer_RtNp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18147/Reviewer_RtNp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18147/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761593013533, "cdate": 1761593013533, "tmdate": 1762927905403, "mdate": 1762927905403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of disentangling the effects of multi-category labels in high-dimensional temporal multi-trial data by proposing MILCCI, a data-driven method for component identification. MILCCI extends sparse per-trial decomposition to: (1) identify interpretable underlying components of the data, (2) capture cross-trial variability via label similarity within each category, and (3) integrate label information to distinguish the contribution of each category. It models components using category-specific sparse tensors, allowing subtle label-driven adjustments in component compositions while maintaining consistency across trials. Additionally, MILCCI learns flexible temporal traces for each component that evolve within and across trials."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1.MILCCI breaks new ground by modeling components as category-specific tensors, allowing subtle adjustments to label changes while avoiding the rigidity of fixed-component methods. This design uniquely enables disentangling multi-category label effects, a capability lacking in SiBBlInGS and tensor factorization.\n\n2.The method is rigorously tested across synthetic and real-world data with varying characteristics. It outperforms baselines in synthetic component recovery and produces interpretable results in real domains.\n\n3.The paper provides comprehensive details, including model equation, initialization steps, label similarity calculations, and code/environment specifications. This transparency ensures other researchers can replicate experiments and adapt MILCCI to new datasets.\n\n4.MILCCI addresses unmet needs in multiple fields: it identifies decision-critical neural ensembles for neuroscience, uncovers actionable voting trends for political science, and reveals user/spider behavior differences for web analytics—demonstrating broad real-world utility."}, "weaknesses": {"value": "1.The iterative training process may become computationally expensive for large datasets with many categories or trials (e.g., >10,000 trials). The paper does not report runtime comparisons with baselines or discuss optimizations (e.g., mini-batch training) for scaling.\n\n2.While MILCCI uses sparsity (γ₂) and label consistency (γ₁) hyperparameters, there is no systematic analysis of how these parameters affect performance. For example, how does varying γ₁ impact component consistency across labels? This makes it difficult for users to tune MILCCI for new datasets.\n\n3.The method assumes linear relationships between components and data, which may limit performance on non-linear systems. The paper acknowledges this but does not explore even simple extensions or discuss scenarios where linearity might fail.\n\n4. For the Wikipedia dataset, PARAFAC and Tucker failed to converge, but the paper does not explore alternative implementations or explain why convergence failed. Additionally, SiBBlInGS comparisons are qualitative only—quantitative metrics would strengthen the case for MILCCI’s superiority."}, "questions": {"value": "1.For large datasets (e.g., 100,000 trials or 10+ label categories), how does MILCCI’s runtime compare to baselines like SiBBlInGS or SVD? Have you explored optimizations such as mini-batch training for component updates or parallelization of trace calculations?\n\n2.The paper uses γ₁ (label consistency) and γ₂ (sparsity) hyperparameters, but no sensitivity analysis is provided. Can you show how varying these parameters affects component interpretability and downstream performance on synthetic or real data?\n\n3.MILCCI assumes linear decomposition—have you tested scenarios where non-linear relationships exist? Would a kernelized version of MILCCI improve performance, and how would you adapt the label consistency constraint for non-linear spaces?\n\n4. For the Wikipedia dataset, PARAFAC and Tucker failed to converge with MILCCI’s component dimension. Did you test lower dimensions or alternative initialization strategies to enable convergence? If not, why is MILCCI more robust to high-dimensional, noisy data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ZnRX25x8Az", "forum": "PcjvI4OlED", "replyto": "PcjvI4OlED", "signatures": ["ICLR.cc/2026/Conference/Submission18147/Reviewer_fmKt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18147/Reviewer_fmKt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18147/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761621728590, "cdate": 1761621728590, "tmdate": 1762927904955, "mdate": 1762927904955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the Authors propose a model to decompose the variability in time series to attribute it to multidimensional labels of the data. They test the model on a synthetic dataset to show that it faitfully reconstructs the way the data was generated, to the US elections data to show that the model finds interpretable patterns, and to IBL neural data to assign roles to clusters of individual units in the brain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Strainghtforward model\n\nThe model proposed here is straightforward, attributing components of the time series segment to labels in a multi-hot label vector. The optimization is done in a kind of E-M algorithm, an alernation between optimizing the time series \"templates\" that correcpond to different labels and the \"projection matrices\" that determine the membersips of the templates in the labels.\n\n- Comparison to baselines\n\nThe work compares the proposed algorithm to multiple beaselines including classical baselines (e.g. PARAFAC) and more recent baselines.\n\n-- Principled buildup:\n\nThe work builds its way through a progression of datasets starting from the ones offering higher control of the input data and making way to real-world datasetss.\nThe work starts from **synthetic data**, enabling the Authors to show that the model faithfully reproduces the components used, manually, in the genaration of the synthetic data.\nSecond the work moves on to the case of **inherently interpretable data** (with the example of the US election data) which has been thoroughly analyzed semantically, allowing to show that the model finds known pattern in this simpler real-world data.\nFinally, the work moves on to **novel data yet to be interpreted** (the IBL's biological data) where the model can make novel predictions abouth the biology of the brain.\n\n- Finally, the model scientifically corroborates that Tucker is not the most reliable source when it comes to the interpretation of the US elections."}, "weaknesses": {"value": "- No alternatives for the design choice\n\nWhile the model puts forward a quite reasonable and quite principled architecture, the alternative design choices are not explored in the text. For the E-M-like algorithm that alternates between optimizing A and Phi, is lasso for MSE the best algorithm choice or could other alternatives (e.g. MSE -> entropy) would be better?\n\n- No range description for the US election interpretability\n\nWhile the readouts of the model on the US electios dataset are linked to known facts about the political events that took place in certain states in certain years, the significance of the effect is unclear from the proposed analysis. Notoriously, spurious correlations are often picked up on in election data, leading to widespread conspiracy theories. What would be a good baseline and the analysis to show that the model's interpretability capacities are significant?\n\n- No thoroughly developed impact area\n\nWhile the analysis of the IBL data is interesting and promising, this part of the work -- that could be its culmination and goal -- seems underdeveloped. While it is shown that certatin cells respond to certain labels, it is unclear form the text 1) which parts of it are already known and 2) what do we learn from this finding. For example, it would be interesting to analyze what brain regions these units belong to and to derive new knowledge about the neural circuitry related to decision-making in the brain. Overall, the lack of a defined goal / application domain and a corresponding result leaves me with the impression that the work is a bit unfinished\n\n- Text is a bit heavy\n\nThe text seems to be a bit heavy, oftentimes obscuring othwerwise strainghtforward concepts. At the same time, some straightforward good propoerties of the model get lost in the wording. For example, I would highlight that limiting the number of components substantiates the need of separating Phi and A: the A tensor cannot be defined as a unit projection matrix from all labels that apply to their corresponsing templates in the time series domain because, under a limited number of components, it is forced to learn synergies between the labels (e.g. grouping states in the US election data.)"}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PFa9CCVQXz", "forum": "PcjvI4OlED", "replyto": "PcjvI4OlED", "signatures": ["ICLR.cc/2026/Conference/Submission18147/Reviewer_1E2a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18147/Reviewer_1E2a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18147/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762205120057, "cdate": 1762205120057, "tmdate": 1762927904195, "mdate": 1762927904195, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MILCCI, a flexible model that exposes interpretable sparse components underlying multiway data and reveals how they capture diverse label categories. This paper performs linear decomposition for each trial with respect to tuple containing the set of each category’s value in that trial."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The setting is practical although challenging because we do not have ground-truth labels to justify the performance rigorously."}, "weaknesses": {"value": "- The writing of the paper is not good with confusing mathematical notions and formulas, making the paper hard to read.\n-  It is unclear how to use and interpret $A$ and $\\Phi$.\n-  The experiments have no ground-truth. Therefore, it is hard to justify the performance of the proposed approach."}, "questions": {"value": "- After finishing learning, how to use two tensors $A$ and $Q$.\n- What are the meaning of Q and A?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I8jIH4MEmZ", "forum": "PcjvI4OlED", "replyto": "PcjvI4OlED", "signatures": ["ICLR.cc/2026/Conference/Submission18147/Reviewer_iLs4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18147/Reviewer_iLs4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18147/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762370578115, "cdate": 1762370578115, "tmdate": 1762927903503, "mdate": 1762927903503, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}