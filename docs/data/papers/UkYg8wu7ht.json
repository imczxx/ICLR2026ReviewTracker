{"id": "UkYg8wu7ht", "number": 12543, "cdate": 1758208478425, "mdate": 1759897502734, "content": {"title": "CTODS: Polynomial-Time Construction of Hypergraphs via Constrained Overlapping Densest Subgraphs for Enhanced Neural Network Performance", "abstract": "The fundamental challenge of constructing meaningful hyperedges from graph structures has limited the effectiveness of hypergraph neural networks in capturing complex relational patterns. We present CTODS (Constrained Top-$K$ Overlapping Densest Subgraphs), a theoretically grounded polynomial-time algorithm that transforms graphs into hypergraphs by systematically identifying overlapping dense subgraphs as hyperedges. The algorithm achieves computational efficiency with $O(K \\cdot m \\log n)$ time complexity and $O(n + m)$ space requirements while ensuring connectivity-enforced subgraph discovery through a principled distance function that controls overlap. Our adaptive parameter optimization framework enables robust performance across diverse network topologies, from citation networks to geometric structures. Extensive empirical validation across eight benchmark datasets demonstrates the method's superiority, achieving consistent improvements of 1-3\\% over existing approaches on seven datasets. The framework effectively models higher-order interactions that remain inaccessible to traditional pairwise representations, establishing a principled foundation for hypergraph-based machine learning applications across multiple domains.", "tldr": "We propose a novel framework for hypergraph generation using top-ùêæ densest overlapping subgraphs and demonstrate its efficiency in enhancing the performance of hypergraph neural networks for  different graph structures and application domains.", "keywords": ["hypergraphs", "hypergraph neural networks", "hyperedge generation", "overlapping densest subgraphs", "node classification", "graph representation learning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/38a8c4d0985d608b76b6a56af0300731e4b1afd6.pdf", "supplementary_material": "/attachment/ccef55acb2f4d76f4ef3dccf5a360ecfa17ed7a5.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a hypergraph construction approach from a graph through constrained top-K densest subgraphs. The method introduces the diversity consideration (i.e., different subgraphs contain only some overlapping nodes) while maximizing the subgraph density, extending the traditional top-K densest subgraphs. The algorithm starts with subgraph candidate generations where multiple heuristics are added to expand the search space while still enjoying polynomial computational cost. Then iterative subgraph selections are performed to get the top-K subgraphs guided by the objective function mentioned above. Experiments have been conducted to show that it can boost the performance of HGNN on hypergraphs constructed from real-world graph data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n1. The paper considers diversity perspective in the top-K densest subgraph search and define a normalized cut-like distance metric to quantify the overlaps of two subgraphs. The constrained TODS  problem naturally extends the original TODS problem and may be of interest.\n2. The experiments show performance improvement over HGNN and over classic GNNs on graph data. It might be due to the hypergraph construction helps extract higher-order structural relationship among entities."}, "weaknesses": {"value": "Weaknesses:\n1. The experimental study can be enhanced by incorporating more advanced hypergraph models such as AllSetTransformer and ED-HNN. Then the performance landscape in the tables of experimental results can be changed. The experimental method may also need some clarification: in practice, some network data is more naturally modeled as hypergraphs, such as co-authorship networks. Then why not directly constructing a hypergraph, instead of first constructing a graph and then transforming it into a hypergraph in an indirect way? The graph representation of the raw data can already incur information loss compared to the hypergraph representation.\n2. The paper presentation should be enhanced. The different strategies/heuristics in Algo. 2 deserve more discussions, at least high-level explanations. The motivations of constructing hypergraphs from graphs should be elaborated.\n\nComments:\n- About the experimental method, you may consider using some hypergraph data and then transforming them into graphs for GNN applications.\n- Why does the distance function be defined to within [0,2], instead of [0,1]? \n- Is the distance function inspired by the definition of normalized cut?\n- The superscript 2 (not square) in the distance function is quite misleading."}, "questions": {"value": "Please see the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "myZSYIf8zX", "forum": "UkYg8wu7ht", "replyto": "UkYg8wu7ht", "signatures": ["ICLR.cc/2026/Conference/Submission12543/Reviewer_TfJP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12543/Reviewer_TfJP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761531455432, "cdate": 1761531455432, "tmdate": 1762923406083, "mdate": 1762923406083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CTODS (Constrained Top-K Overlapping Densest Subgraphs), a polynomial-time algorithm for constructing hypergraphs from graphs by identifying overlapping densest subgraphs as hyperedges. Unlike *k*-nearest neighbor or *k*-hop methods, CTODS enforces connectivity, applies size constraints, and regulates overlap via a distance-based diversity function. The algorithm runs in O(K m \\log n) time and O(n+m) space, making it scalable. Experiments on eight benchmark datasets (citation, political, social, and geometric networks) show consistent 1‚Äì3\\% improvements over existing hypergraph and graph neural network baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Principled hyperedge construction.** Offers a theoretically grounded formulation that captures higher-order interactions.  \n2. **Polynomial-time scalability.**  Achieves O(K m \\log n) complexity, making it practical for large-scale networks.  \n3. **Controlled overlap mechanism.** The distance-based metric effectively constrains redundancy among hyperedges, aligning with real-world overlapping community structures.  \n4. **Robust empirical validation.** Consistent gains across diverse domains (citation, political, and geometric) support the general effectiveness of the approach."}, "weaknesses": {"value": "1. **Limited novelty.** While CTODS presents a well-engineered and efficient algorithm, the contribution is primarily algorithmic, with limited empirical evaluation (tested only on a single architecture), and does not provide deeper theoretical or representational insights into hypergraph learning.  \n\n2. **Evaluation tied only to HGNN.** Since CTODS is a general-purpose hypergraph construction method, it should be validated across multiple architectures such as UniGNN [1], AllSet [2], and ED-HNN [3], rather than relying solely on HGNN, to confirm its generality.  \n\n3. **Ablation study missing.** The paper lacks an ablation analysis showing the contribution of each candidate generation strategy (density, diversity, high-degree expansion, random sampling). This is essential to understand which components drive the observed improvements.  \n\n4. **Hyperedge size constraints.** The current formulation fixes \\(\\alpha\\) and \\(\\beta\\) as static bounds. Exploring adaptive or learnable bounds could make the method more flexible and data-driven.  \n\n5. **Experimental reporting.** Results are presented as single numbers without standard deviations. For scientific rigor, they should be averaged over multiple runs (e.g., 10) and reported as mean ¬± standard deviation, following standard practice [2, 3].  \n\n6. **Minor.** The authors should explicitly mention that their hypergraph construction produces *undirected* hypergraphs. Clarifying this assumption is important for reproducibility and for understanding potential extensions to directed or attributed hyperedges.  \n\n\n\n[1] Huang, Jing, and Jie Yang. \"UniGNN: a Unified Framework for Graph and Hypergraph Neural Networks.\" Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence Organization, 2021.\n\n[2] Chien, Eli, et al. \"You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks.\" International Conference on Learning Representations.\n\n[3] Wang, Peihao, et al. \"Equivariant Hypergraph Diffusion Neural Operators.\" The Eleventh International Conference on Learning Representations."}, "questions": {"value": "1. How sensitive is CTODS to the trade-off parameter $\\lambda$? A systematic sensitivity analysis would clarify its robustness.  \n\n2. Which candidate generation strategies contribute most to performance? An ablation study would help clarify this.  \n\n3. How does CTODS perform on tasks beyond node classification (e.g., link prediction, community detection)?  \n\n4. Could the hyperedge size constraints $\\alpha$, $\\beta$ be learned adaptively rather than fixed?  \n\n5. Please report results with mean ¬± standard deviation over multiple runs (‚â•10) to ensure statistical robustness.  \n\n6. Since CTODS is architecture-agnostic, have you tested it with other hypergraph neural networks, such as UniGNN [1], AllSet [2], or ED-HNN [3]? This would support the claim of general-purpose applicability.  \n\n\n[1] Huang, Jing, and Jie Yang. \"UniGNN: a Unified Framework for Graph and Hypergraph Neural Networks.\" Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence Organization, 2021.\n\n[2] Chien, Eli, et al. \"You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks.\" International Conference on Learning Representations.\n\n[3] Wang, Peihao, et al. \"Equivariant Hypergraph Diffusion Neural Operators.\" The Eleventh International Conference on Learning Representations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "r6mmGrdF9g", "forum": "UkYg8wu7ht", "replyto": "UkYg8wu7ht", "signatures": ["ICLR.cc/2026/Conference/Submission12543/Reviewer_ujaT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12543/Reviewer_ujaT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890299312, "cdate": 1761890299312, "tmdate": 1762923405301, "mdate": 1762923405301, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CTODS (Constrained Top-K Overlapping Densest Subgraphs) as a method to construct a hypergraph from a graph with meaningful hyperedges.They start by finding top k dense subgraphs (even overlapping ones) and turn each subgraph into a hyperedge. The subgraphs should be dense with many edges per node, and sufficiently different from each other. Density is measured on a subgraph formed by a chosen set of nodes where only edges among them count. To avoid near duplicate groups, CTODS adds a diversity penalty that discourages heavy groups overlap. Each group must also respect size limits and be connected. After creating the hypergraph with the algorithm proposed, they pass it through a hypergraph neural network and train on eight different datasets. The accuracy of their model is outperforming the baselines on ‚Öû of all datasets used."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-The novelty here is in the creation of a hypergraph from a graph by finding the top k densest subgraphs and turning them into hyperedges with overlap control with a  distance based diversity term and size and connectivity constraints.\n- Evaluating on 8 different datasets show that the approach can be applied in different domains. The hyperparameter table is helpful for reproducibility, and shows the trade off between runtime and accuracy, with fine grained hypergraphs being more accurate with higher runtime.\n- Well written definitions and the pipeline of hypergraph construction is understandable\n- The comparison with the baselines show that their model in the fine grained configuration has consistent performance gains on ‚Öû datasets"}, "weaknesses": {"value": "- There are already many hypergraph creation model proposed using community detection. Using denstiy to define community adn hyperesge is a limited controbution. \n-The distance chosen for overlap control is not well motivated and not compared to other standard distance measures\n-Data split information is not specified (train/val/test), and the number of seeds is missing\n-No mean+/- std is reported\n-Only Accuracy/F1 are reported, other metrics like ROC-AUC/PR-AUC are missing which are important for datasets with class imbalance\n-References to the appendix are missing which make the appendix confusing\n- Include sensitivity plots for the hyperparameters to make it easier to see the impact"}, "questions": {"value": "1. Why did you choose that distance function instead of another one? Can you report results of other standard distances like jaccard or cosine? \n2. How many seeds did you choose? Provide the mean and standard deviation for the results for each dataset\n3. How were train/val/test splits done?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V9QQc0ZMJe", "forum": "UkYg8wu7ht", "replyto": "UkYg8wu7ht", "signatures": ["ICLR.cc/2026/Conference/Submission12543/Reviewer_bWRM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12543/Reviewer_bWRM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949912606, "cdate": 1761949912606, "tmdate": 1762923404539, "mdate": 1762923404539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework to construct hypergraphs from graphs for downstream learning tasks. The main idea is based on the extraction of top-K densest subgraphs while also taking into account the distance between those subgraphs (to minimise overlap). Experimental results on common graph machine learning benchmarks are presented to demonstrate the effectiveness of the proposed algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- A new method of constructing hypergraphs from graphs that respect both dense connection and minimal overlap is welcome and have a broad appeal beyond machine learning tasks.\n- The main idea is intuitive and easy to follow."}, "weaknesses": {"value": "**Main motivation.** The authors need to explain more clearly why constructing a hypergraph would be beneficial for graph machine learning tasks. If the task does not come with inherent hypergraph structure (eg co-authorship network), it is unclear why turning a pairwise graph into a hypergraph would necessarily be helpful (even though it might be a generally useful technique in network science). Along this line, recent studies such as [1] have demonstrated that hypergraph neural networks are not necessarily better than classical graph neural networks with for example clique expansion. To better justify their approach, the authors need to show convincingly hypergraph construction is indeed required for a certain type of tasks. \n\n**Technical aspects.** Several technical aspects of the paper should be clarified and improved:\n- In Eq.(5), why use product of cardinality of the two sets but not the size of the union set, as the commonly used Jaccard index?\n- Why do the authors propose a two phase algorithm? How are the ‚Äúadditional densest subgraphs that are distinct‚Äù in phase 2 differ from those in phase 1? This lacks proper justification and needs to be explained more clearly (ideally via an illustration of the overall algorithm).\n- Related to the point above, it is confusing to see the objective function in Eq.(6) and then another optimisation with a different objective function in 4.3.\n- In Eq.(6), the $L_i$ and $L_j$ should be $\\mathcal{L}_i$ and $\\mathcal{L}_j$ as defined before.\n- The optimisation problem at the beginning of 4.3 should be defined using a sum over all indices $i$, if multiple $\\mathcal{L}_i$ are being optimised together.\n- Multiple functions in Algorithms 1 and 2 are not explained, making it difficult to understand how they work.\n- The authors mentioned in 4.2 that existing iterative approaches are suboptimal, however it looks like the proposed method is iterative as well. Can the authors clarify on this point and how their method addresses the limitation of previous iterative approaches? \n\n**Experiments** The experimental results should be clarified and strengthened: \n- The authors cited three papers in Introduction and also mentioned ‚Äúour HGNN‚Äù a couple of times but it is unclear which HGNN method is being used. \n- The authors mentioned ‚Äúgraph-to-hypergraph conversion approaches‚Äù in 5.1, however star expansion and clique expansion are methods for hypergraph-to-graph conversion. Also, in order to apply the proposed method, my understanding is that we need to start with a graph dataset. However, hypergraph datasets such as Cora-CA are included which presumably already contains defined hyperedges. These aspects need be to clarified. \n- Only three hypergraph neural network baselines are included in the experiments. The authors should either include more baselines (some of those can be found in [1]) or discuss why they are not suitable to compare against. \n- There are no ablation studies to demonstrate that minimising overlap using the proposed loss function would indeed contribute to the learning performance.\n\n[1] Tang et al., ‚ÄúTraining-Free Message Passing for Learning on Hypergraphs,‚Äù ICLR, 2025."}, "questions": {"value": "See weaknesses above for the specific points I would like the authors to address."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qVfMR1MtXm", "forum": "UkYg8wu7ht", "replyto": "UkYg8wu7ht", "signatures": ["ICLR.cc/2026/Conference/Submission12543/Reviewer_uC1n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12543/Reviewer_uC1n"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762088912272, "cdate": 1762088912272, "tmdate": 1762923403807, "mdate": 1762923403807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}