{"id": "dDvLeDjBOa", "number": 6442, "cdate": 1757984144357, "mdate": 1759897914446, "content": {"title": "Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation", "abstract": "Recent advances in video generation models have achieved remarkable visual realism. However, these models typically lack accurate physical alignment, failing to replicate real-world dynamics in object motion. This limitation arises primarily from their reliance on learned statistical correlations rather than capturing mechanisms adhering to physical laws. To address this issue, we introduce a novel framework that integrates symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for physics-grounded video forecasting. Our approach extracts motion trajectories from input videos, uses a retrieval-based pre-training mechanism to enhance symbolic regression, and discovers equations of motion to forecast physically accurate future trajectories. These trajectories then guide video generation without requiring fine-tuning of existing models. We evaluate our framework on scenarios from classical mechanics, including spring-mass, pendulums, and projectile motions. In these settings, our method successfully recovers ground-truth analytical equations and improves the physical alignment of generated videos compared to baseline methods. This work provides a first step toward integrating equation discovery with video generation.", "tldr": "We propose a framework combining physical equation learning and trajectory-guided video models to improve physical realism in video generation by forecasting dynamics with derived equations of motion.", "keywords": ["equation learning", "video understanding", "video forecasting"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dc64e8ee9c2500724ce0a1baaa49b141cc903847.pdf", "supplementary_material": "/attachment/a4cc7cd8b23a7139de1d8f3f9a998ffb9704690b.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses the lack of physical realism in modern video generators by discovering explicit equations of motion from a short input video and then using the predicted future trajectory to control a trajectory-guided I2V model. The pipeline is: (i) extract object tracks from a short clip (CoTracker) → (ii) perform symbolic regression to recover a closed-form motion law, using a retrieval-based pre-training (ReSR) that initializes the SR population from a curated equation bank of physics laws → (iii) extrapolate the future trajectory with the discovered equation and drive an I2V model to synthesize future frames without generator fine-tuning. Experiments on classical mechanics scenes (spring–mass, pendulum, projectile) show that the method recovers ground-truth analytical equations and improves physical alignment of generated videos over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear pipeline; inference-only control ensures the improvements stem from the motion law rather than re-training the generator. The paper reports successful recovery of ground-truth equations and improved global motion consistency.\n2. The overview and per-module descriptions are easy to follow; classical-mechanics scope and assumptions are explicit."}, "weaknesses": {"value": "1. Experiments are limited to controlled lab videos of simple systems (single-object classical mechanics). It’s unclear how the method handles multi-object scenes, contacts/collisions, or non-rigid effects beyond the chosen examples.\n2. Tracking noise/occlusions can corrupt trajectories; sensitivity of SR to noisy, short observations is not analyzed. (Method description assumes clean tracks.)\n3. The attached showcase videos are not convincing to me. The quality of the video is low and some objects are distorted, shape changed."}, "questions": {"value": "1. Can authors provide more convincing demos? Demos now can not support ReSR's contribution.\n2. Please see the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EJ5x3h9Zc1", "forum": "dDvLeDjBOa", "replyto": "dDvLeDjBOa", "signatures": ["ICLR.cc/2026/Conference/Submission6442/Reviewer_uc2J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6442/Reviewer_uc2J"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6442/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761566750067, "cdate": 1761566750067, "tmdate": 1762918835750, "mdate": 1762918835750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Existing video generation models are based on statistical fitting and lack accurate physical alignment. This work introduces a novel retrieval-based pre-training method for symbolic regression, named ReSR, which motion-consistent equations from input videos. The authors then derive future trajectories from the recovered equations. These equations are subsequently used to forward with trajectory-guided image-to-video (I2V) models, enabling physically aligned video forecasting without the need to fine-tune the I2V models. Experimental results demonstrate that in classical mechanics tasks, such as spring-mass systems, pendulum swings, and projectile motion, ReSR can recover the analytical equations and generate videos with superior physical alignment compared to baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- A better symbolic regression method.\n\nThe authors analyze the drawbacks of previous symbolic regression methods, such as PySR and LaSR, including large search spaces and slow convergence, and propose ReSR. This method is based on a carefully designed, pre-defined equation bank rather than random candidate equations, which improves convergence speed and achieves superior results, significantly outperforming the baselines.\n\n- It demonstrates the performance of trajectory-guided video generation with physical alignment.\n\nWith the more physics-consistent trajectories generated by ReSR, trajectory-guided video generation can produce videos that better match real-world dynamics, providing a new approach for physically aligned video generation."}, "weaknesses": {"value": "- The ability to generate physically-aligned videos without ground truth should be proven.\n\nIn this work, input videos are necessary to obtain analytical equations and predict future changes. This method cannot generate motion-consistent trajectories based solely on the initial frame, which limits its application scope.\n\n- The method's extensibility has yet to be demonstrated.\n\nIn the introduction, the authors mention that \"insights into object motion in classical mechanics can be easily extended into other types of motion.\" However, the experiments presented in the paper are still limited to simple laboratory settings and lack examples of applications in more general scenarios.\n\n- bad writing.\n\nIn this paper, the authors exhibit several instances of improper writing, including but not limited to:\n\n1、Inconsistent use of tenses.  In Sec.. 4.2, the phrase \"Evaluations were conducted on ten videos per system across all physical systems.\" should use \"are\" instead of \"were.\" The sentence \"Inter-annotator agreement was measured...\" mixes present and past tenses. There are other similar problems in this paper.\n\n2、Incorrect singular/plural usage. In the introduction, \"a handful of video clip\" should be corrected to \"clips.\"\n\n3、Incorrect caption format. For the table type, the caption should be placed above the table, but in this paper, the caption is placed below the table."}, "questions": {"value": "- Can the ablation study be expanded?\n\nThe paper compares the equation prediction performance of several methods, including PySR, KAN, and LaSR, but in Section 4.2, the authors only compare LaSR with Kling as the base model. Additionally, the authors do not explain how $Manual_{Kling}$ and $GT_{Kling}$ are generated, even in the supplementary materials."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TiJfNwuZMw", "forum": "dDvLeDjBOa", "replyto": "dDvLeDjBOa", "signatures": ["ICLR.cc/2026/Conference/Submission6442/Reviewer_nLVP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6442/Reviewer_nLVP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6442/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816249695, "cdate": 1761816249695, "tmdate": 1762918834770, "mdate": 1762918834770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a neuro-symbolic framework that integrates symbolic regression with trajectory-guided image-to-video models to achieve physics-grounded video generation. The method extracts motion trajectories from input videos using CoTracker, discovers governing equations through a novel retrieval-based symbolic regression approach (ReSR) initialized with a curated physics equation bank, and uses the discovered equations to forecast future trajectories that guide video generation models without fine-tuning. The framework is evaluated on classical mechanics systems including spring-mass oscillators, pendulums, and projectile motion, demonstrating improved equation recovery and physical alignment compared to baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Novel neuro-symbolic integration for video generation. The paper presents an innovative approach combining interpretable symbolic equation discovery with data-driven video generation models, bridging two typically separate domains. The ReSR method with retrieval-based pre-training from a physics equation bank is a well-motivated contribution that significantly improves convergence speed (44.3 iterations vs 61.4 for PySR) and equation accuracy (TED 0.80 vs 0.47) as shown in Table 1.\n2. Comprehensive evaluation framework with meaningful metrics. The paper employs multiple complementary evaluation metrics including symbolic similarity (TED), trajectory error (MSE), convergence speed (ITB), and video quality measures (FVD, FID, smoothness, trajectory error), alongside human evaluation studies with substantial inter-annotator agreement (Fleiss' Kappa 0.73). The ablation studies systematically analyze the impact of initialization weight w and training/test split proportions."}, "weaknesses": {"value": "1. Equation bank construction relies heavily on manual curation. Section 3.3 describes constructing the equation bank by manually adapting 106 Feynman equations through time-variable substitution where \"time-dependent variables (e.g., velocity, acceleration, momentum) with the time variable t\" and \"variables that are independent of time (e.g., mass, density) are replaced with constant values (e.g., 10).\" \n\n2. The trajectory extraction pipeline uses heuristic selection. The paper extracts trajectories by sampling a uniform 10×10 grid and selecting \"top-k trajectories with the highest motion magnitude\" based on \"temporal variance\" (Section 3.2), motivated by the observation that \"target objects in physics-driven videos typically exhibit the most motion.\" However, this heuristic may fail when background elements move more than objects of interest (e.g., camera motion, wind effects on curtains), or when the physical system involves multiple interacting objects with different motion scales. \n\n3. Limited scope to idealized classical mechanics scenarios restricts practical applicability. The paper acknowledges in Section 4.1 that evaluation is limited to \"classical physics systems\" in \"controlled laboratory environment\" because it enables \"direct evaluation against ground-truth equations.\" While this is reasonable for proof-of-concept, the scenarios tested (spring-mass, pendulums, projectile motion) represent highly simplified physics with analytical solutions."}, "questions": {"value": "1. Your equation bank construction (Section 3.3) involves manually replacing time-dependent variables with \"t\" and time-independent variables with constants like \"10\". Can you provide evidence that this substitution process preserves the mathematical structure relevant for trajectory fitting? \n\n\n2. Your trajectory extraction selects the \"top-5 trajectories with the highest temporal variance\" from a 10×10 grid (Section 3.2), but Table 2 shows substantially degraded performance on real initial frames versus synthetic ones (e.g., Kling: FVD 1064 vs 641, TraEr 404 vs 325). Can you quantify how often your heuristic correctly identifies the object of interest in your real-world test cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rVXhQK4wBM", "forum": "dDvLeDjBOa", "replyto": "dDvLeDjBOa", "signatures": ["ICLR.cc/2026/Conference/Submission6442/Reviewer_Jxx2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6442/Reviewer_Jxx2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6442/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940540856, "cdate": 1761940540856, "tmdate": 1762918834301, "mdate": 1762918834301, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a neuro symbolic framework for generating physics grounded videos. The method operates at inferenc time by first extracting an object 2D motion trajectory from a short input video using a tracking model (CoTracker3). It then feeds this trajectory into a novel symbolic regression method, ReSR. It  enhances standard SR by initializing its search using candidate equations retrieved from a prebuilt equation bank of known physical laws. The retrieval is based on trajectory shape similarity using normalized dynamic time warping. The discovered symbolic equation is then used to forecast a physically consistent future trajectory. Finally, this forecasted trajectory is passed to an existing trajectory guided I2V model to synthesize the output video. The framework is evaluated on videos of classical mechanics systems, where it reports accurate equation recovery and improved physical alignment in the generated videos compared to baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The core concept of connecting video analysis, symbolic equation discovery, and generative video models into a single pipeline is a novel approach to address the lack of physical realism in video generation.\n2. An intermediant representation of the system is an explicit symbolic equation. This more explainable than black-box neural network predictors and provides genuine insight into the system's dynamics."}, "weaknesses": {"value": "1. the method is exclusively evaluated on simple, 2D classical mechanics problems (springs, pendulums) in controlled, static-background lab settings. There is no evidence it can scale to complex, real-world 3D scenarios involving camera motion, occlusions, or non-trivial dynamics.\n2. the ReSR method's success is predicated on the assumption that an equation similar to the true governing law already exists in its curated bank. This approach will not generalize to discovering novel physics or complex dynamics not represented in the bank.\n3. the method operates entirely in 2D space . It does not model 3D motion, camera projection, or perspective, which are fundamental to any real-world video application.\n4. the method of isolating the object of interest by selecting trajectories with the highest motion magnitude will fail in any video with camera motion or multiple dynamic background elements.\n5. the retrieval step requires comparing the input trajectory to every equation in the bank via N-DTW. While parallelizable, this comparison is computationally inefficient and will not scale to a truly large, general-purpose bank of physical equations.\n6. The framework is not scalable and couldn't fit into the scaling law."}, "questions": {"value": "1. I understand that this is a pioneering work that use symbolic regression to represent physical effects. But it is still worth investigating that if this works in a in-the-wild enviroment where more noises are there in the video. Otherwise, if this work only applies to simple toy/lab env, then, physical engine might be a better choice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vcYvF0rA7b", "forum": "dDvLeDjBOa", "replyto": "dDvLeDjBOa", "signatures": ["ICLR.cc/2026/Conference/Submission6442/Reviewer_sRn7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6442/Reviewer_sRn7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6442/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762006110200, "cdate": 1762006110200, "tmdate": 1762918833377, "mdate": 1762918833377, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}