{"id": "0FJYicpOj0", "number": 22272, "cdate": 1758328790343, "mdate": 1759896875746, "content": {"title": "Gaussian certified unlearning in high dimensions: A hypothesis testing approach", "abstract": "Machine unlearning seeks to efficiently remove the influence of selected data while preserving generalization. Significant progress has been made in low dimensions $(p \\ll n)$, but high dimensions pose serious theoretical challenges as standard optimization assumptions of $\\Omega(1)$ strong convexity and $O(1)$ smoothness of the per-example loss $f$ rarely hold simultaneously in proportional regimes $(p\\sim n)$.\nIn this work, we introduce $\\varepsilon$-Gaussian certifiability, a canonical and robust notion well-suited to high-dimensional regimes, that optimally captures a broad class of noise adding mechanisms. Then we theoretically analyze the performance of a widely used unlearning algorithm based on one step of the Newton method in the high-dimensional setting described above. Our analysis shows that a single Newton step, followed by a well-calibrated Gaussian noise, is sufficient to achieve both privacy and accuracy in this setting. This result stands in sharp contrast to the only prior work that analyzes machine unlearning in high dimensions \\citet{zou2025certified}, which relaxes some of the standard optimization assumptions for high-dimensional applicability, but operates under the notion of $\\varepsilon$-certifiability. That work concludes %that a single Newton step is insufficient even for removing a single data point, and\nthat at least two steps are required to ensure both privacy and accuracy. Our result leads us to conclude that the discrepancy in the number of steps arises because of the sub optimality of the notion of $\\varepsilon$-certifiability and its incompatibility with noise adding mechanisms, which $\\varepsilon$-Gaussian certifiability is able to overcome optimally.", "tldr": "We introduce the canonical dimension free notion of certifiability suitable to high dimensions and show its utility via a Newton based unlearning algorithm", "keywords": ["Machine unlearning in high dimensions", "Proportional asymptotics", "High dimensional statistical theory", "Privacy–accuracy tradeoff", "Hypothesis testing", "Gaussian noise calibration", "Newton method"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2aa1ed1036190b875838c897c261f703465c440f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces ε-Gaussian certifiability (GPAR)—a new theoretical notion for analyzing machine unlearning in high-dimensional regimes (p ~ n). It reformulates unlearning guarantees via hypothesis testing and Gaussian trade-off functions, showing that a single Newton step with Gaussian noise suffices to ensure both privacy and accuracy. This contrasts with prior work (notably Zou et al., 2025), which required at least two steps under ε-certifiability. The authors also provide proofs of convergence, theoretical bounds for Generalization Error Divergence (GED), and simulation results validating the high-dimensional behavior."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Introducing ε-Gaussian certifiability as a canonical high-dimensional analogue to ε-certifiability is a meaningful contribution, bridging DP-inspired hypothesis testing with unlearning theory.\n\n2.  The paper convincingly argues that existing assumptions—especially Ω(1) strong convexity and O(1) smoothness—fail in proportional regimes, motivating a new approach.\n\n3. The contrast with Allouah et al. (2025), Sekhari et al. (2021), and Zou et al. (2025) is detailed—highlighting where previous frameworks break down."}, "weaknesses": {"value": "1. Experiments are confined to synthetic logistic/ridge regression under controlled Gaussian features. There are no tests on real or non-linear models, limiting practical validation.\n\n2.  While the framework is theoretically extendable, the assumptions (convexity, separability, sub-Gaussian features) exclude modern deep models. Discussion on extending to non-convex objectives (e.g., neural networks) remains speculative.\n\n3. Although one-step Newton is theoretically efficient, computational overhead in large-scale settings (Hessian computation, inversion) is not discussed."}, "questions": {"value": "1. How sensitive is the ε-GPAR bound to mis-specification of noise variance? Could small deviations in σ break certifiability guarantees?\n\n2. The theorems assume a single batch of deletions of size m. What happens if deletions arrive sequentially? Is the GED bound sub-additive, or does error accumulate over multiple unlearning rounds?\n\n3. The constants C₁(n), C₂(n) are said to be polylog(n), but they are never specified. How large are they empirically, and do they affect practical implementability?\n\n4. The framework assumes exact access to the Hessian—what happens when it is estimated or approximated in large-scale models? For large $p$, forming and inverting $p \\times p$ Hessians is infeasible. Can similar theoretical results be shown for quasi-Newton or stochastic approximations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "E6PSSs8Dys", "forum": "0FJYicpOj0", "replyto": "0FJYicpOj0", "signatures": ["ICLR.cc/2026/Conference/Submission22272/Reviewer_WvFT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22272/Reviewer_WvFT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976566730, "cdate": 1761976566730, "tmdate": 1762942144726, "mdate": 1762942144726, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ε-Gaussian certifiability, a novel and robust framework tailored for high-dimensional machine unlearning. The authors demonstrate that a single noisy Newton step suffices to achieve both privacy and statistical accuracy under this new notion, contrasting with prior work that required at least two steps. Theoretical results are supported by convincing simulations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a novel, high-dimensional–friendly notion of certified unlearning (ε-Gaussian certifiability) that tightly captures Gaussian noise mechanisms and subsumes prior privacy definitions.\n2. The theoretical analysis is rigorous. The authors theoretically prove that a single Gaussian-Newton step simultaneously achieves (φ,ε)-GPAR privacy and vanishing generalization error in the proportional p∼n regime under relaxed assumptions."}, "weaknesses": {"value": "1. Some writing issues:\n   - In the Abstract, the notation $ p \\ll n $ should be clarified by specifying what $ p $ and $ n $ represent, respectively.\n   - In the Introduction section, the reviewers suggests first discussing the shortcomings or failures of existing works before presenting the performance and contributions of the proposed method.\n   -  Using boldface followed by a colon for the first sentence of every paragraph throughout the paper harms the logical flow and readability, making it less reader-friendly.\n2. Some typos:\n   - $\\mathcal D$ shoud be $\\mathcal D_{\\backslash {\\mathcal M}}$ on Line 188.\n   - The symbols $\\epsilon$ and $\\delta$ are not defined in Eq.(8).\n   - $ p\\uparrow \\infty $ on Line 254.\n   - The symbol $ r $ is reused in Eq.(16). Earlier in the text, it denotes the regularization term.\n3. The paper lacks discussion on online unlearning (i.e., handling continuous unlearning requests).\n4. The reviewers suggets that using a table to compare the results of this work with those of existing methods would be clearer and more effective."}, "questions": {"value": "Could you provide experiments with larger values of $p$ (e.g., 10K or 100K)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ixlMa7rDu2", "forum": "0FJYicpOj0", "replyto": "0FJYicpOj0", "signatures": ["ICLR.cc/2026/Conference/Submission22272/Reviewer_qmUk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22272/Reviewer_qmUk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984191639, "cdate": 1761984191639, "tmdate": 1762942144397, "mdate": 1762942144397, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of certified machine unlearning in high-dimensional settings where the number of parameters p is comparable to the sample size n. It introduces a new privacy notion called (phi, epsilon)-Gaussian certifiability, which is argued to be the canonical and optimal framework for high dimensions. The main theoretical result shows that a single step of Newton's method, followed by calibrated Gaussian noise, is sufficient to achieve both this strong privacy guarantee and maintain model accuracy. This finding directly contrasts with the prior state-of-the-art analysis by Zou et al. (2025), which concluded that at least two Newton steps were necessary."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper's primary strength is its novel and theoretically sound analysis of unlearning in the challenging high-dimensional proportional regime (p ~ n). The introduction of varepsilon-Gaussian certifiability is well-motivated, leveraging a hypothesis testing perspective and properties of high-dimensional data to create a more natural and tighter privacy notion than previous frameworks like varepsilon-certifiability. The core result—that only one noisy Newton step is needed—is both surprising and significant, as it suggests prior analyses were suboptimal due to an incompatible privacy definition, not a fundamental algorithmic limitation. The theoretical claims are strongly supported by comprehensive experiments showing the clear superiority of the Gaussian mechanism over the Laplace mechanism from Zou et al. (2025)."}, "weaknesses": {"value": "The analysis relies on specific technical assumptions, such as the data features being sub-Gaussian and the loss functions being convex. While common in high-dimensional statistics, the practical implications for highly non-convex models (like large neural networks) remain an open and important question. Furthermore, the requirement for Hessian computation in the Newton step, though theoretically elegant, could be a scalability bottleneck for extremely large-scale models. The paper could also benefit from a more detailed discussion on the potential trade-offs or limitations of the Gaussian certifiability notion itself, beyond its superiority over prior work."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9EXvZ0MfIy", "forum": "0FJYicpOj0", "replyto": "0FJYicpOj0", "signatures": ["ICLR.cc/2026/Conference/Submission22272/Reviewer_xe5g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22272/Reviewer_xe5g"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762187307077, "cdate": 1762187307077, "tmdate": 1762942144004, "mdate": 1762942144004, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **$(\\phi, \\epsilon)$-Gaussian certifiability**, a new privacy-certification framework for high-dimensional settings ($p \\approx n$). It shows that a single Newton step with Gaussian noise can achieve certified unlearning while maintaining model accuracy. The work improves upon prior high-dimensional unlearning methods by reducing the number of required Newton steps and provides empirical validation on synthetic linear models, demonstrating the advantages of Gaussian noise for generalization and unlearning metrics."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "-**Problem Significance:** This is a timely work in the important field of machine unlearning, addressing key limitations of existing methods. It does so by introducing a canonical privacy notion tailored to high-dimensional settings, bridging differential-privacy hypothesis testing and machine unlearning.\n\n-**Novelty and Theoretical Elegance:** The paper introduces $(\\phi, \\epsilon)$-Gaussian certifiability and proves that a single Newton step suffices for certified unlearning. This provides a rigorous, theoretically sound approach that balances privacy guarantees and model accuracy.\n\n-**Support for Multiple Deletions:** The method can handle multiple deletion requests simultaneously, as long as the total deletion size remains within the theoretical bound. This feature is valuable for practical batch-deletion scenarios."}, "weaknesses": {"value": "-**On deletion size**. From what I understand, the certified unlearning guarantees hold only for relatively small deletion sets ($m = o(n^{1/4-\\alpha})$), which limits applicability when larger batches of records need to be removed. This is a clear theoretical limitation of the method.\n\n-**On noise-scale calibration**. While the paper provides a theoretical formula for Gaussian noise, it involves unspecified constants and poly-logarithmic factors, making practical calibration challenging. Implementing the noise correctly in real-world scenarios may be difficult.\n\n-**On model scope and empirical validation**. Experiments are restricted to linear ridge-regularized ERM models with Gaussian/sub-Gaussian features on synthetic datasets. Non-convex models, deeper architectures, and real-world datasets are not evaluated. Even though this is outside the scope and assumptions of the paper, I think it would be interesting to see a simple extension, such as a two-layer fully connected network on MNIST, with results compared against the frequently cited papers by Sekhari et al. and Guo et al.\n\n-**On scalability of Newton method**. The method requires inversion of the Hessian ($O(p^3)$), which may be difficult to compute in high-dimensional settings, as often encountered in deep neural networks. This can be computationally and memory intensive, and may also be numerically unstable."}, "questions": {"value": "I would appreciate it if you could also answer the following questions:\n\nQ1. **On the high-dimensional regime**. From what I understand, your theoretical framework is developed under the assumption that the number of features $p$ and the number of samples $n$ grow proportionally ($p \\sim n$), which allows the use of Random Matrix Theory results. While the framework is elegant in this setting, it is unclear how well it could extend to ultra high-dimensional regimes where $p \\gg n$, such as in modern neural networks. Do you think the current framework could provide a solid base for such settings, or would substantial modifications be needed?\n\nQ2. **On the deletion set structure**. Does you framework for more sophisticated/structured unlearning scenarios such as class or concept unlearning? \n\nQ3. **On the choice of $\\phi$ (tolerance):** How sensitive are the certified unlearning bounds to the tolerance parameter $\\phi_n$? Is there a principled way to choose $\\phi_n$ in practice, and how might different choices affect empirical performance or computational stability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5BoXXnyC4r", "forum": "0FJYicpOj0", "replyto": "0FJYicpOj0", "signatures": ["ICLR.cc/2026/Conference/Submission22272/Reviewer_3wiW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22272/Reviewer_3wiW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762402635742, "cdate": 1762402635742, "tmdate": 1762942143566, "mdate": 1762942143566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}