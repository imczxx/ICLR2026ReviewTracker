{"id": "Anv4gdNFaL", "number": 6489, "cdate": 1757986827103, "mdate": 1759897911678, "content": {"title": "One-Shot Exemplars for Class Grounding in Self-Supervised Learning", "abstract": "Self-Supervised Learning (SSL) has recently achieved remarkable progress by leveraging large-scale unlabeled data. However, SSL pretrains models without relying on human annotation, so it usually does not specify the class space. This inevitably weakens the effectiveness of the learned representation in most downstream tasks that have the intrinsic class structure. In this work, we introduce the new easy setting of One-Shot Exemplar Self-Supervised Learning (OSESSL), requiring only one instance annotation for each class. By introducing this extremely sparse supervision, OSESSL provides the minimum class information to guide the exploration of unlabeled data, achieving significant performance boosts with neglectable annotation cost (i.e., a complexity of $\\mathcal{O}(1)$ w.r.t. the sample size). In this OSESSL setting, we propose a simple yet effective framework that leverages the single-labeled exemplar to build the class-specific prototype for learning reliable representations from the huge unlabeled data. To this end, we also build a novel consistency regularization, which extends the sparse exemplar supervision into the decision boundaries, thus improving the robustness of the learned representation. Extensive experiments on real-world datasets clearly validate the reliability of this simple and practical setting. The proposed approach successfully outperforms the state-of-the-art methods, achieving gains of approximately 3\\% and 6\\% $k$-NN accuracy on CIFAR-100 and ImageNet-100, respectively.", "tldr": "We introduce a new one-shot exemplar self-supervised learning setting that enhances representation learning with just a single annotation per class.", "keywords": ["Self-supervised learning", "One-shot exemplar", "Representation learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e3599c3b82f3cbf8516e25c6414949d8d76fc212.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper focuses on one-shot exemplar self-supervised learning, a new problem to self-supervised learning that uses one labeled example per class. To address this issue, the paper incorporates a prototype learning algorithm and an interpolation consistency module. Extensive experimental results validate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-written.\n\nThe problem of self-supervised learning with one-shot exemplars is interesting and novel to the literature. Utilizing the available supervision information for self-supervised learning is a critical research problem. Therefore, it will create new opportunities in the field.\n\nThe proposed overall algorithm is simple yet effective. The different components of the algorithm are effective and reasonable. The design of the algorithms for exemplar-guided prototype construction, exemplar-guided prototype learning, and exemplar-guided interpolation consistency is coherent and interesting.\n\nExtensive experiments validate the effectiveness of the proposed method."}, "weaknesses": {"value": "Is the proposed approach sensitive to the choice of the selected example for each class? Since one exemplar is very few, will it cause big variations on the algorithm performance?\n\nSince there are different losses for the proposed methods, it would be beneficial to conduct ablation studies to confirm the effectiveness of each component, although the experimental results are already very comprehensive."}, "questions": {"value": "I have no major questions on this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JZ56LW4wqu", "forum": "Anv4gdNFaL", "replyto": "Anv4gdNFaL", "signatures": ["ICLR.cc/2026/Conference/Submission6489/Reviewer_Bjyr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6489/Reviewer_Bjyr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760590797925, "cdate": 1760590797925, "tmdate": 1762918863988, "mdate": 1762918863988, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on one-shot exemplar self-supervised learning, a new problem to self-supervised learning that uses one labeled example per class. To address this issue, the paper incorporates a prototype learning algorithm and an interpolation consistency module. Extensive experimental results validate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-written.\n\nThe problem of self-supervised learning with one-shot exemplars is interesting and novel to the literature. Utilizing the available supervision information for self-supervised learning is a critical research problem. Therefore, it will create new opportunities in the field.\n\nThe proposed overall algorithm is simple yet effective. The different components of the algorithm are effective and reasonable. The design of the algorithms for exemplar-guided prototype construction, exemplar-guided prototype learning, and exemplar-guided interpolation consistency is coherent and interesting.\n\nExtensive experiments validate the effectiveness of the proposed method."}, "weaknesses": {"value": "Is the proposed approach sensitive to the choice of the selected example for each class? Since one exemplar is very few, will it cause big variations on the algorithm performance?\n\nSince there are different losses for the proposed methods, it would be beneficial to conduct ablation studies to confirm the effectiveness of each component, although the experimental results are already very comprehensive.\n\n=============After the rebuttal========\n\nThe supplementary experiments show the robustness w.r.t. the hyperparameters and the effectiveness of each component of the method. My concerns have been addressed adequately. Therefore, I am satisfied with the rebuttal and will lean towards acceptance on this paper."}, "questions": {"value": "I have no major questions on this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JZ56LW4wqu", "forum": "Anv4gdNFaL", "replyto": "Anv4gdNFaL", "signatures": ["ICLR.cc/2026/Conference/Submission6489/Reviewer_Bjyr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6489/Reviewer_Bjyr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760590797925, "cdate": 1760590797925, "tmdate": 1763740294743, "mdate": 1763740294743, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel and practical learning setting called One-Shot Exemplar Self-Supervised Learning (OSESSL). The core motivation is derived from that self-supervised learning (SSL) fails to specify the class space, which inevitably weakens the effectiveness of the learned representations for downstream tasks with intrinsic class structures. Instead of relying on self-generated signals, the authors propose using a single annotated instance per class to provide minimal yet crucial supervision, guiding the model toward meaningful semantic structures while retaining the scalability of SSL. The central mechanism to tackle the new setting is the \"Exemplar-Guided Prototype Construction,\" where each single-labeled exemplar is used to build a robust class prototype. This is achieved not by using the exemplar in isolation, but by enriching it with its most discriminative neighbors from the vast pool of unlabeled data. These prototypes then provide semantic guidance for a clustering-based SSL objective. The framework is further enhanced with a prototype dispersion loss to prevent collapse and an \"Exemplar-Guided Interpolation Consistency\" loss, which regularizes the model on mixed samples to improve decision boundary robustness. Extensive experimental results on standard benchmarks demonstrates that the proposed method significantly outperforms a wide array of state-of-the-art SSL methods across multiple evaluation protocols and demonstrates strong performance on both CNN and Vision Transformer backbones."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction of the OSESSL setting is a significant contribution in itself. The authors provide a very lucid argument for its necessity. Unlike traditional SSL that lacks explicit semantic grounding, OSESSL leverages a single labeled exemplar per class to guide representation learning in a scalable manner. The OSESSL setting offers semantic grounding with a truly negligible annotation cost (a complexity of $\\mathcal{O}(1)$ with respect to dataset size, as the authors rightly point out). This is an extremely practical scenario for many real-world applications where identifying and labeling one canonical example of each class is far more feasible than labeling thousands of instances.\n\n2. The proposed method is simple yet effective, combining exemplar-guided prototype alignment, prototype dispersion, and interpolation consistency to jointly promote discriminative and stable representation learning. The design is also supported by theoretical reasoning. The method is evaluated across diverse datasets, and significant performance makes the empirical evidence convincing. Ablation studies further confirm the complementary effects of the proposed components and the stability of key hyperparameters.\n\n3. The paper is clearly written and well-structured, making it easy to follow. The authors effectively present the motivation, identify the limitations of prior work, and justify their proposed approach. Figures and tables are well-designed to illustrate key results, and the appendices provide useful supplementary details that enhance the overall clarity and completeness of the work."}, "weaknesses": {"value": "1. The neighbor selection mechanism is key to the method's success, as it relies on a meaningful feature space to identify semantically similar instances. However, in the early stages of training, the encoder is not yet powerful, and the feature space is likely to be poorly structured. I concern that the initial neighbor selections could be noisy or incorrect, reinforcing incorrect associations early on. \n\n2. Lack of ablation studies of exemplar-guided prototype construction. It would be helpful to analyze how the choice of exemplars influences performance and to evaluate the sensitivity or benefit of the discriminative-neighbor weighting parameter. Such studies would clarify the robustness and generality of the proposed mechanism."}, "questions": {"value": "Have the authors evaluated the robustness of OSESSL under exemplar noise, or considered mechanisms to mitigate its effects? If such analysis has not been conducted, what challenges or design choices would be most critical for extending the method to noisy one-shot supervision?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mlcdopCNwc", "forum": "Anv4gdNFaL", "replyto": "Anv4gdNFaL", "signatures": ["ICLR.cc/2026/Conference/Submission6489/Reviewer_Ubdk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6489/Reviewer_Ubdk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854498463, "cdate": 1761854498463, "tmdate": 1762918863625, "mdate": 1762918863625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addressed self-supervised learning, but with a new paradigm called One-Shot Exemplar Self-Supervised Learning (OSESSL). In OSESSL, the challenge is to use the sparse supervision to guide representation learning. First, the authors build class-specific prototypes and use the prototypes to guide representation learning. Moreover, the authors proposed an interpolation consistency loss to provide the regularization and improve the decision boundaries. The authors have conducted extensive experiments to validate the effectiveness of the  proposed method in various settings, such as SSL, semi-supervised learning and transfer learning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well motivated\n\nConsidering representation learning in a semantically grounded manner is likely to encourage the model to learn more informative representations.\n\n2. The presentation is clear\n\n3. The paper is easy to follow"}, "weaknesses": {"value": "1. The proposed OSESSL setting seems unnecessary\n\n2. The proposed exemplar-guided alignment seems similar to PAWS\n\n3. The ablation study is missing\n\n4. The semi-supervised learning setting is strange\n\nPlease see the Question section below for details."}, "questions": {"value": "1. The proposed OSESSL setting seems unnecessary\n\nWhile the authors claim this OSESSL as one of their contributions, I am not convinced that OSESSL brings new insights to the community. Its entire definition is covered by semi-supervised learning; the one-exemplar assumption is still under the few-shot semi-supervised learning paradigm. Having one or 3 samples does not change the nature of sparse supervision. \n\n2. The proposed exemplar-guided alignment seems similar to PAWS\n\nI would love to see a direct comparison between the proposed exemplar-guided alignment with PAWS. The major difference is that PAWS uses labeled data as anchors, and here the authors use the reconstructed exemplars. Under such sparse supervision, I am not sure how much more information the reconstructed exemplar gathers, as it has to stay close to the labeled data to avoid the loss of semantic meaning. Therefore, I find these two methods very similar.\n\n3. The ablation study is missing\n\nWhile the ablation study is promised in line 312 in the experiment section, there is no ablation study provided in this section, making it hard to validate the effectiveness of the proposed method.\n\n4. The semi-supervised learning setting is strange\n\nI find the semi-supervised learning setting in line 425 very strange. It is more like a transfer learning rather than semi-supervised learning, if the model is first trained in SSL on ImageNet-1k, and then fine-tuned on labeled data. In general, semi-supervised learning provides both labeled and unlabeled data at the same time. I hope the authors could elaborate on the reason for setting up the experiments in this way."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concern."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5s0l20lzcD", "forum": "Anv4gdNFaL", "replyto": "Anv4gdNFaL", "signatures": ["ICLR.cc/2026/Conference/Submission6489/Reviewer_dQe4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6489/Reviewer_dQe4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998373333, "cdate": 1761998373333, "tmdate": 1762918863240, "mdate": 1762918863240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new setting called One-Shot Exemplar Self-Supervised Learning (OSESSL), where self-supervised learning is augmented with just one labeled example per class to ground the representations in the true class space. The authors argue that this minimal supervision—essentially O(1) annotation cost relative to dataset size—can significantly boost downstream performance without losing SSL's scalability. They propose a framework that builds class-specific prototypes from the exemplar plus selected unlabeled neighbors, enforces alignment across views, adds dispersion to prevent collapse, and includes an interpolation consistency regularization for robustness near decision boundaries. Experiments on CIFAR-10/100, ImageNet-100/1K show consistent gains over SSL baselines like ReSA, DINO, etc., with notable improvements in k-NN (e.g., +6% on ImageNet-100) and linear classification. Transfer to semi-supervised, detection, and fine-grained tasks also looks strong"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The OSESSL idea is clever and addresses a real gap in SSL—lack of class grounding—while keeping annotations negligible. It's a nice middle ground between pure SSL and semi-supervised learning, especially since class count grows slower than data volume in big datasets like LAION. This could inspire more work on \"minimal supervision\" hybrids.\n2.The prototype construction (using discriminative scores for neighbors) and interpolation consistency are straightforward extensions to clustering-based SSL. The math derivations (e.g., gradient analysis of alignment loss) provide good intuition on why it works. No overly complex bells and whistles, which makes it reproducible.\n3"}, "weaknesses": {"value": "1.The method relies on one high-quality exemplar per class, but real-world data often has noise or ambiguity. The conclusion mentions extending to noisy scenarios, but no experiments here—would be good to test robustness with mislabeled or atypical exemplars.\n2. While gains over pure SSL are clear, the semi-sup baselines (PAWS, Suave) use 1% labels (~12k on ImageNet), which is 12x more than yours (1k classes = 1k labels). Claiming superiority feels a bit stretched without ablating how performance scales with more exemplars. Also, some citations are to 2025 papers (ReSA, SOP)—fine for anon review, but ensure they're public.\n3. Mostly image classification-focused; more on non-vision (e.g., if applicable) or diverse domains (medical, satellite) would strengthen generality. Detection results are good, but only on COCO—VOC or others? Also, no analysis on failure cases, like classes with high intra-variance.\n4. Appendix shows stability, but temperatures τs/τt fixed at 0.1/0.04—why these? And α=0.75 in discriminative score; a sweep there might reveal more."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "imTutVbpIz", "forum": "Anv4gdNFaL", "replyto": "Anv4gdNFaL", "signatures": ["ICLR.cc/2026/Conference/Submission6489/Reviewer_P5Pb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6489/Reviewer_P5Pb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762095449881, "cdate": 1762095449881, "tmdate": 1762918862886, "mdate": 1762918862886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces One-Shot Exemplar Self-Supervised Learning (OSESSL), a novel setting that leverages only one annotated instance per class to provide semantic grounding while maintaining the scalability of self-supervised learning. The authors propose a framework that constructs exemplar-guided prototypes augmented with discriminative neighbors from unlabeled data, and introduces exemplar-guided interpolation consistency to smooth decision boundaries. Extensive experiments on CIFAR and ImageNet benchmarks demonstrate state-of-the-art performance, with significant improvements in k-NN accuracy (e.g., +3% on CIFAR-100, +6% on ImageNet-100) over strong baselines."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "**Originality**: The OSESSL setting is novel and fills an important gap between fully unsupervised SSL and semi-supervised learning. The exemplar-guided prototype construction and interpolation consistency mechanism are creative and well-motivated.\n\n**Quality**: Experimental evaluation is extensive and convincing, covering linear evaluation, k-NN classification, semi-supervised learning, and transfer learning. The method consistently outperforms strong baselines across all settings.\n\n**Clarity**: The paper is exceptionally clear in both writing and technical exposition. The gradient analysis provides valuable theoretical insight.\n\n**Significance**: The work addresses the important problem of incorporating minimal supervision to guide SSL toward semantically meaningful representations, with practical implications for real-world applications where annotations are scarce."}, "weaknesses": {"value": "1.\tThe method assumes clean exemplars are available, but real-world scenarios often involve noisy annotations. The paper briefly mentions this limitation but provides no experiments on noisy exemplars.\n\n2.\tThe paper could benefit from more analysis on how the method performs with different qualities of exemplars (e.g., easy vs. hard examples)."}, "questions": {"value": "1.\tHow sensitive is the method to the quality of the single exemplar per class? Have you experimented with different strategies for selecting the exemplar (e.g., cluster centers vs. random samples)?\n\n2.\tFor the neighbor selection in prototype construction, did you consider using more sophisticated metrics beyond cosine similarity, such as incorporating density estimation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SXOPqQAJtk", "forum": "Anv4gdNFaL", "replyto": "Anv4gdNFaL", "signatures": ["ICLR.cc/2026/Conference/Submission6489/Reviewer_Jd4w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6489/Reviewer_Jd4w"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission6489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762097970464, "cdate": 1762097970464, "tmdate": 1762918862455, "mdate": 1762918862455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}