{"id": "MGSIggp1mV", "number": 21275, "cdate": 1758315706192, "mdate": 1759896931233, "content": {"title": "Hybrid Quantum-Classical Recurrent Neural Networks", "abstract": "We present a new hybrid quantum-classical recurrent neural network (RNN) architecture in which the recurrent core is realized as a parametrized quantum circuit (PQC) controlled by a nonlinear classical feedforward network. The hidden state is the quantum state of the PQC, residing in an exponentially large Hilbert space $\\mathbb{C}^{2^n}$ and manipulable using only $n$ qubits. The PQC is unitary by construction, making the hidden-state evolution inherently norm preserving without external constraints. To evolve the recurrence, classical embeddings of the current input are combined with mid-circuit readouts from the previous timestep’s quantum state and processed by a feedforward network. The resulting outputs parameterize the PQC, which then evolves unitarily to produce the updated hidden state. This enables per-timestep readouts while avoiding attempts to emulate nonlinearities with inherently linear quantum dynamics. We evaluate the model in simulation with up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory, and language modeling, adopting projective measurements as a limiting case to obtain mid-circuit readouts while maintaining a coherent quantum memory across timesteps. We also devise a soft attention mechanism over readouts in a sequence-to-sequence model and show that the network is effective for machine translation. To our knowledge, this is the first model (RNN or otherwise) grounded in quantum operations to achieve superior or competitive performance against strong classical baselines across a broad class of sequence-learning tasks.", "tldr": "A hybrid quantum–classical RNN with a unitary PQC core and nonlinear classical control and feedback, achieving superior or competitive performance to strong classical baselines on six sequence tasks, with simulations up to 14 qubits.", "keywords": ["quantum computing", "variational quantum models", "parametrized quantum circuits", "hybrid-quantum classical neural networks", "recurrent neural netwroks"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/779222b0043a372fff7a0f601e882db5597bd22e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a hybrid-classical quantum recurrent neural network. In the proposed architecture, the hidden state is the quantum state of a parametric quantum circuit (PQC). The parameters of the PQC, in turn, are controlled by a classical neural network that processes both the prior hidden state (or rather, a measurement taken from it) and the new input.\nThe paper provides an empirical study with extensive experiments on various datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Designing algorithms and architectures that allow to integrate quantum computing into machine learning is an important task. Thereby, the paper contributes to a relevant research area. \n- The experiments are carried out and described (mostly) very thoroughly, providing important experimental insights on the performance of QRNN architectures in comparison to classical architectures. \n- In the experimental study, the proposed architecture appears to perform well in comparison to classical architectures.  \n- Overall, the paper is well-written and clearly presented."}, "weaknesses": {"value": "- Important experimental details on baselines are missing: the precise choices for number of hidden layers, activation functions, etc. for the classical baseline models (RNNs, LSTMs) are not reported. While Dropout is applied for the QRNNs, it is not stated whether it is also used for the classical baseline models. Moreover, it remains unclear how exactly the network sizes / total number of parameters were chosen for the different experiments. This makes it impossible to reproduce experimental results and undermines the main claims of the paper. \n\n- Claimed outperformance not supported by experiments:  the paper states that QRNNs outperform standard LSTMs/RNNs on four of six tasks. However, this is not fully supported by the experiments: only in two of the experiments QRNNs appear to really obtain a significant improvement (Table 2). For the remaining experiments, this does not seem to be the case. For the first task (reported in Table 1), the difference between the RNN performance and the best QRNN is very minor, while the RNN uses fewer parameters (only 5K instead of 5.2K). For the task in Section 4.3, no table is provided, but the text states that LSTMs and QRNNs perform equally well. For the remaining two tasks LSTMs outperform QRNNs. This would mean that only in 2/6 tasks QRNNs outperform classical methods. \nMoreover, to allow for a full comparison of the considered architectures, it would be crucial to also report runtimes. \n\n- Only classical baselines used: several other recurrent quantum neural networks architectures have been proposed (Ubale et al. 2025, Yu et al. 2024a, etc. as discussed in Section 2), but the paper does not compare performance to any of them. This would be important for justifying why yet another QRNN architecture should be considered. In particular, this is important because in comparison to these works the novelty of the architecture is incremental (adding non-linearity to the circuits from Li et al. 2023 and Siemaszko et al. 2023)\n\n- No code is available with the paper, which limits reproducibility of the experimental results. \n\n- Missing details on the methodology: the model architecture is never spellt out in full detail, which makes it not possible to reproduce the results. Figure 1(a) is stated as an example, but the paper does not state how exactly the unitary operator U looks like in general and which gates are used exactly. As for measurement, lines 260-262 state that \"measurement outcomes are combined to form $z_t$, but does not state how exactly these measurements are combined. \n\n- Impact of measurement noise: Related to this point, it appears that the measurement operation in (3) would be prone to noise. This needs to be thoroughly addressed in the paper, as it may have a major impact on the performance. How is this addressed in the current implementation? If it is currently neglected, it would be highly important to assess its impact on the performance. \n\n- The discussion on norm preservation is misleading: only the norms of the quantum states are preserved, but this does not have any impact on or relation to the norms of the inputs."}, "questions": {"value": "- Can you provide full experimental details regarding the baselines (use of dropout, activation functions, etc., see first point above)? \n- How sensitive are the baselines with respect to choices of activation functions? \n- According to which procedure did you select network sizes / hyperparameters / activation functions for the classical baselines?\n- Can you add a table with results also for Section 4.3? \n- What happens in Table 1 if you increase the number of RNN parameters to 5.2K? \n- Can you provide insights on the use of alternative, previously proposed QRNN architectures?\n- Can you provide code for your implementation? \n- Can you write out in detail the model architecture: how exactly is U defined and how does the measurement operator look like. \n- Can you assess the impact of measurement noise on the results? \n- The paper states \"To preserve coherence across timesteps, we simulate mid-circuit measurements, allowing recurrent structure without collapsing the full quantum state, retaining the quantum memory throughout the sequence.\" It appears that this would create problems on real quantum hardware  - can you comment on this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FwDJiZoUJJ", "forum": "MGSIggp1mV", "replyto": "MGSIggp1mV", "signatures": ["ICLR.cc/2026/Conference/Submission21275/Reviewer_FAnR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21275/Reviewer_FAnR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826334020, "cdate": 1761826334020, "tmdate": 1762941665729, "mdate": 1762941665729, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a hybrid quantum-classical RNN architecture in which the recurrent core is implemented as a PQC. At each timestep, mid-circuit measurements from the previous quantum state are combined with classical embeddings of the current input through a feedforward network, which outputs the next set of PQC parameters. The quantum state acts as the hidden state, evolving unitarily in a high-dimensional Hilbert space. The authors argue that this design offers a principled way to integrate unitary evolutions into recurrent architectures while preserving state norm and enabling per-timestep readouts.\nThe model is evaluated in simulation (up to 14 qubits) on standard benchmarks including sentiment analysis, MNIST, permuted MNIST, copying memory, and machine translation. The authors report modest accuracy improvements over classical RNN baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Novel architectural concept: The idea of embedding quantum circuits within RNN recurrence steps is original and conceptually interesting, especially for sequence modeling.\nComprehensive benchmarking: The authors evaluate the model across diverse tasks, including language modeling and translation, showing its general applicability.\nMathematical consistency: The recurrent evolution is unitary by construction, automatically ensuring norm preservation—an elegant contrast to the ad-hoc regularization required in classical RNNs.\nPractical transparency: The paper reports training times, qubit counts, and parameter sizes for both classical and hybrid models, which is commendable.\n\nThe work presents an interesting blueprint for integrating parametrized quantum circuits into recurrent models, but the evidence for impact is limited. The modest performance improvements could stem from added representational capacity rather than genuine quantum effects. The unclear separation between encoding and learning blocks, combined with incomplete training details, makes replication and interpretation difficult.\nGiven that all experiments rely on classical simulation and incur high computational costs, the results do not substantiate the paper’s implicit suggestion that such architectures are practical or advantageous in the near term."}, "weaknesses": {"value": "Ambiguity in circuit design: The paper does not clearly distinguish between data-encoding and trainable parts of the PQC. From Figure 1A, the first layer of RY gates seems to correspond to data encoding, but this is not explicitly stated. Without this separation, it is difficult to evaluate what portion of the model’s expressivity truly arises from quantum effects. \n\nModest empirical gains: Across tasks, improvements are small (e.g., +2\\% accuracy in classification, BLEU 29.2 --> 31.9 for German–English translation). These gains do not convincingly justify the significant simulation cost or architectural complexity, especially when comparable improvements could be achieved by scaling classical models.\n\nLimited discussion of simulation cost: Although the authors mention that training takes between 4–60 minutes per epoch (depending on task and qubit count), no wall-clock comparisons are provided against classical baselines. Given that all results are obtained on simulators rather than real quantum hardware, the practical feasibility and scalability of the method remain unclear.\n\nMeasurement and training details missing: The paper reports “24 measurements for 8 qubits” but does not specify whether this is per timestep or per sample, nor how parameter gradients were obtained. If the parameter-shift rule was used, the number of measurements would change, significantly impacting the total computational cost. Clarification is needed to assess efficiency and scalability.\n\nUnclear goal between physics and simulation: It remains ambiguous whether the main objective is to demonstrate a computationally advantageous quantum model or to motivate unitary evolution as a conceptual analogue for classical nonlinearities. Without a clear experimental focus, the narrative risks oscillating between hardware-motivated and purely simulated reasoning.\n\nRelated work gap: Although several hybrid sequence models are cited, the omission of Quantum Deep Equilibrium Models is notable, as it directly addresses the encoding overhead and representational collapse issues that also affect this architecture.\n\nWhile conceptually creative, the paper does not provide compelling empirical or theoretical evidence that hybrid quantum-classical RNNs outperform, generalize better, or offer unique interpretability compared to classical counterparts. The design lacks clarity regarding the role of data encoding and omits key implementation details needed to evaluate its feasibility on hardware. The work’s contribution lies more in architectural exploration than in demonstrated quantum advantage."}, "questions": {"value": "In this type of architecture, reading and feeding back to the QCP could have a great cost; is it the case for this QML model too? \n\nAre canonical initialization schemes (e.g., amplitude or angle encoding) used for classical input embeddings?\n\nIs the reported “24 measurements for 8 qubits” the number of observables per timestep or per sample? For training, how was gradient estimation done (e.g., via parameter-shift rule)?\n\nHow do the runtime costs per epoch compare quantitatively against the classical RNN baseline (e.g., same hardware and dataset)?\n\nWill replacing the PQC with an orthogonal matrix RNN test whether unitarity alone explains observed gains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tAzSsfl1V8", "forum": "MGSIggp1mV", "replyto": "MGSIggp1mV", "signatures": ["ICLR.cc/2026/Conference/Submission21275/Reviewer_vQW1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21275/Reviewer_vQW1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761827803309, "cdate": 1761827803309, "tmdate": 1762941665470, "mdate": 1762941665470, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Addressing some common concerns"}, "comment": {"value": "We thank the reviewers for their feedback, and we first address some common concerns.\n\n**Measurement- and Feedback-driven nonlinear classical control and Universality**\n\nConcurrent to our work, a theoretical paper submitted under the same conference (https://openreview.net/forum?id=248ysaRatx) on feedback-driven quantum recurrent network shows that recurrent quantum neural networks equipped with measurement-based feedback form a universal function approximator, showing that: “1) RQNNs are able to approximate regular state-space systems without the curse of dimensionality, using quantum circuits with qubit number only growing logarithmically in the reciprocal of the prescribed approximation accuracy. 2) ... we prove that RQNNs can uniformly approximate the arbitrary fading memory, causal, and time-invariant filters. In particular, RQNNs have approximation properties as competitive as those of popular reservoir computing/statespace system families like echo state networks, state-affine systems, or linear systems with polynomial/neural network readouts. *These analyses identify feedback from intermediate measurements as a structurally essential ingredient: universality requires that information extracted from the quantum system be re-injected into the recurrent update*.”\n\nOur hybrid QRNN is the first proposal (to our knowledge) realizing an architecture precisely akin to this principle. Instead of measure and reinitialise as in the theory, we maintain coherence by extracting expectation-value readouts which are used in the recurrent feedback. Our work also provides the first empirical demonstration that a feedback-driven quantum recurrent model can be trained successfully on realistic sequence-learning tasks. Prior QNN or QRNN works have been restricted to narrow or downsampled benchmarks, whereas we evaluate the hybrid QRNN on six full-scale tasks including IMDB, MNIST, pMNIST, copying memory, language modeling, and MT. *The goal is not to outperform classical models but to establish viability*: (deliberately) under idealized, noise-free simulation, the architecture can train stably, achieves competitive performance with strong classical baselines, and exhibits favourable gradient propagation properties consistent with its unitary recurrent core, on non-trivial tasks considering the nascent state of field including the inherent limitations of classical simulation costs. \n\n\n**Empirical viability and the notion of “quantum advantage”**\n\nWe also argue as part of the motivation of the paper that classically it would be prohibitive to realise a hidden state of size, say $2^{200}$. QRNN aside, one advantage of a quantum computer is its ability to manipulate a Hilbert space in the Complex domain of size $2^n$, with only $n$ qubits (lines 86-88). Demonstrating viability in noiseless simulations with a moderate qubit count empirically would be a natural first step before scaling up to more qubits, with quantum implementations, on fault-tolerant quantum hardware. Another advantage of the quantum model is that it naturally gives rise to the complex Hilbert space while ensuring unitarity by construction.\n\nFinally, our focus on idealized classical simulation is deliberate. Realistic hardware modelling requires specifying many device-dependent factors, none of which have a universal form across platforms. Introducing arbitrary noise models would not meaningfully inform the learnability of the architecture, especially when we await a working quantum backpropagation method and when noise can only be injected at inference rather than during scalable, realistic quantum backprop training, because such training requires quantum backprop [1]. For this reason, any analysis of hardware noise that does not affect the training procedure itself is inherently limited: it captures neither optimization behaviour nor model capacity, and therefore cannot meaningfully speak to the viability of the architecture. Our aim in this work is thus to establish a clean baseline for learnability under ideal conditions, which can then guide future investigation once training-capable fault-tolerant hardware becomes available, beyond the NISQ regime.\n\n\n**Contributions and Novelty**\n\n1. A new hybrid recurrent mechanism that combines 1) coherent quantum memory with 2) nonlinear classical control and 3) mid-circuit readouts in a novel feedback scheme.\n\n2. The first empirical demonstration of such a quantum model (RNN or otherwise) across realistic sequence-learning tasks (at the scaling limits of single-gpu simulations and limitations of current toolchains).\n\n3. Our architecture provides a concrete, trainable recurrent mechanism identified in recent concurrent theory, linking universality results to an actual implementable design.\n\n\nThese contributions establish the conceptual motivation and the practical viability of a hybrid QRNN, aligned with a universality theory (https://openreview.net/forum?id=248ysaRatx).\n\n[1] https://arxiv.org/abs/2305.13362"}}, "id": "Xa6jO8LNDO", "forum": "MGSIggp1mV", "replyto": "MGSIggp1mV", "signatures": ["ICLR.cc/2026/Conference/Submission21275/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21275/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21275/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763676835926, "cdate": 1763676835926, "tmdate": 1763679221849, "mdate": 1763679221849, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors propose a hybrid RNN in which the recurrent core is a PQC and the classical part comprises a small feedforward network. The quantum state itself is treated as the RNN hidden state and evolved unitarily, which the authors claim naturally yields norm-preserving recurrence and, hence, better gradient propagation. To obtain per-timestep output but keep quantum memory, they simulate mid-circuit measurements/projective readouts and feed the measured values back to the classical controller for the next step. Their empirical results on six sequence tasks show that QRNN variants are competitive with RNNs, LSTMs, and scoRNNs of roughly similar parameter count."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed quantum model is run across several/realistic sequence tasks instead of just MNIST or toy memory tasks. \n\n2. The authors give hyperparameters, optimizer, qubit counts, measurement sets, and even report variability across 50-100 runs in the appendix."}, "weaknesses": {"value": "1. All results are obtained in TorchQuantum on GPUs, and there is no real hardware, no noisy simulator, no demonstration that the mid-circuit readout trick they rely on can actually be executed at the depth/width they need. The paper itself admits that it models mid-circuit measurement “as a limiting case” and that present toolchains are “less optimized” for hybrid recurrence.\n\n2. The paper leans heavily on: “the PQC is unitary ⇒ norm-preserving ⇒ better gradients ⇒ better long-sequence learning.” But: (a) We already have unitary/orthogonal RNNs (Arjovsky et al. 2016; Jing et al. 2019) that give this without simulating a quantum circuit; (b) Their own best results require adding classical nonlinearities (ReLU, GELU, GLU) in the controller, so that the actual performance bump seems to come from the classical part, not the quantum recurrence. They even show QRNNLinear is clearly worse. So the “quantum as recurrent memory” story is blurred; (c) They do not show that the PQC is doing something strictly more complex than an (efficient) unitary RNN. \n\n3. Although the authors cite Bausch 2020, QRNN-like PQC recurrences, and QLSTM variants, the novelty is not tight compared with prior quantum-RNN / quantum-RL / hybrid quantum-classical NN."}, "questions": {"value": "1. Can the authors show one nontrivial sequence task (longer than 400 steps, or multi-turn translation) where all classical baselines degrade but your QRNN still trains?\n\n2. Can the authors show a side-by-side with a classical unitary/orthogonal RNN that has the same number of parameters as your PQC (counting gates) and the same measurement dimension?\n\n3. Can the authors cost and prototype the mid-circuit measurement pipeline on any real backend (even for 4–6 qubits) to demonstrate that the feedback loop is not purely a simulator artifact?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PWYo7K71Fo", "forum": "MGSIggp1mV", "replyto": "MGSIggp1mV", "signatures": ["ICLR.cc/2026/Conference/Submission21275/Reviewer_YrVD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21275/Reviewer_YrVD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921769222, "cdate": 1761921769222, "tmdate": 1762941665098, "mdate": 1762941665098, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel Hybrid Quantum-Classical Recurrent Neural Network (QRNN). The work is one of the first demonstrations of a quantum-grounded model achieving competitive or superior performance against classical baselines across a broad and realistic (but toy) suite of sequence-learning tasks. The paper is well-written, but I do not have enough expertise to properly evaluate this paper and I made an educational guess."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The model is evaluated on six diverse tasks (sentiment analysis, MNIST, pMNIST, copying memory, language modeling, machine translation) and is shown to be competitive with or outperform classical RNNs, LSTMs, and specifically designed orthogonal RNNs (scoRNN).\n\n- The paper is generally well-structured and clearly written. I enjoyed the reading flow.\n\n- The paper thoughtfully discusses the path to hardware implementation, acknowledging current simulation limits and proposing a realistic ancilla-mediated measurement scheme for future work. The choice of a simple, hardware-native PQC ansatz strengthens the practical relevance of the work."}, "weaknesses": {"value": "- What is the advantage  of Hybrid Quantum-Classical Recurrent Neural Network? comparing to Classical RNN or  other Hybrid quantum NN (Like Hybrid quantum CNN if one can implement)? \n- It would be nice if the authors could explain something related to GPU consumption or efficency.\n- It would be nice if the authors could visualize something related to the intermediate hidden states, like the state change in QRNN.\n- To which perspective does the design of QCNN could  benefit the majority of  ICLR audiences. \n- The reviewer would appreciate it if the authors could provide some discussions on existing work like Li et.al. https://arxiv.org/pdf/2302.13812 and many other quantum-classifical hybrid models."}, "questions": {"value": "see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Dz8OAi8JS1", "forum": "MGSIggp1mV", "replyto": "MGSIggp1mV", "signatures": ["ICLR.cc/2026/Conference/Submission21275/Reviewer_VTBd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21275/Reviewer_VTBd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762171083837, "cdate": 1762171083837, "tmdate": 1762941664566, "mdate": 1762941664566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}