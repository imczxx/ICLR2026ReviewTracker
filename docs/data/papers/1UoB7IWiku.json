{"id": "1UoB7IWiku", "number": 19999, "cdate": 1758301329177, "mdate": 1759897007297, "content": {"title": "Code World Models for General Game Playing", "abstract": "Large Language Models (LLMs) reasoning abilities are increasingly being applied to classical board and card games, but the dominant approach---involving prompting for direct move generation---has significant drawbacks. It relies on the model's implicit fragile pattern-matching capabilities, leading to frequent illegal moves and strategically shallow play. Here we introduce an alternative approach: We use the LLM to translate natural language rules and game trajectories into a formal, executable world model  represented as Python code. This generated model---comprising functions for state transition, legal move enumeration, and termination checks---serves as a verifiable simulation engine for high-performance planning algorithms like Monte Carlo tree search (MCTS). In addition, we prompt the LLM to generate heuristic value functions (to make MCTS more efficient), and inference functions (to estimate hidden states in imperfect information games). Our method offers three distinct advantages compared to directly using the LLM as a policy: (1) Verifiability: The generated CWM serves as a formal specification of the game's rules, allowing planners to algorithmically enumerate valid actions and avoid illegal moves, contingent on the correctness of the synthesized model; (2) Strategic Depth: We combine LLM semantic understanding with the deep search power of classical planners; and (3) Generalization: We direct the LLM to focus on the meta-task of data-to-code translation, enabling it to adapt to new games more easily. We evaluate our agent on 10 different games,  of which 4 are novel and created for this paper. 5 of the games are  fully observed (perfect information), and 5 are partially observed (imperfect information). We find that our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10 considered games.", "tldr": "Instead of using LLMs-as-a-policy to play games, we use LLMs to implement an explicit code world model and combine it with a planner to play games, including imperfect information ones.", "keywords": ["large language models", "code world models", "code generation", "information set MCTS", "planning", "partial observability", "two-player games", "imperfect information games"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bf26d1c5fe44fb7b5a59fa7e02431736203f7508.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a very interesting ."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This is a thorough, well-founded work. It is well-motivated and it starts with good rigour and a clever approach to what will eventually become, in my opinion, a large open problem in agentic workflows."}, "weaknesses": {"value": "While the motivations/contributions are strong, the paper's methodology is not there yet. It has some weaknesses that (unfortunately) do not make it, in my _personal_ opinion, ready for publication. \n\n1. The paper's writing is inconsistent across the work. Tonal shifts occur often (e.g., L431 'you can check it in...')\n2. Only one (closed-source) baseline.\n    - While not strictly needed, an ablation on prompts/models would be helpful to ascertain _why_ the results are the way they are.\n3. Paper structuring and presentation needs work. This is different from the paper's writing: overall the presentation / scientific methodology needs to be improved.\n\nHere's how the paper can be improved:\n1. Make the writing consistent--proof-read and ensure that it adjusts to the expected tonality of a scientific article. \n    - Ensure descriptions of tables/figures are well-done. E.g., what is '# LLM Calls' in Table 2? If it is 'number of LLM calls', why is it a float? Is it an average then?\n    - The related work section needs _a bit_ (not a lot) of work. Some known works in both applying Markov processes or getting LLMs to play videogames are missing. I would also suggest adding a small explanation on what they did.\n    - Make sure your paper is proofread. For example, L308 introduces 'OOD' before defining what it is. The sentence in L86 does not need parentheses. This indicates a lack of proofreading.\n    - Definitions are important. Gemini is not indicated as a reasoning model: since the behaviour of an LLM (next-token predictor) and an RLM (baked-in CoT) are quite distinct, referring to Gemini (an RLM) as an LLM does require some clarification.\n2. More open baselines/agents will be beneficial for the robustness, soundness, and longevity of the work. These three are _musts_ for contributions to any conference, let alone ICLR. \n    - Related: the code would be better put in a repository. This will avoid presentation issues like those in App. I.2\n3. On scientific writing:\n    1. Scientific writing follows a very specific template:\n        1. Results/Experiments contain the outcomes of your evaluation of the hypothesis. These should be supported with numerical evidence. Opinions and interpretations of the results (like 5.1.1) are for the discussion.\n        2. Discussion contains the discussion _of the results_, not of your paper. \n        3. Conclusion (which is missing) allows you to draw a conclusion (or interpretation) of your hypothesis based on data.\n    2. Significant digits must be consistent and should make sense (why is accuracy in T2 reported to five significant digits? Is such precision truly needed?).\n    3. Skipping the definition of imperfect info games because they are 'tricky' _would_ make sense if it weren't for the fact that (a) the experimental work does rely on imperfect information; and (b) the appendix to which the reader is referred does not contain a formal definition.\n\nI genuinely think this could be a very strong contribution, but needs more work than might be feasible for this submission.\n\nMinor, and not something that influenced my review: the lack of a reproducibility statement plus (1) the fact that all the code is in an appendix; and (2) the baselines are closed-source, do not indicate good, open science practices. I would encourage the authors to rethink this and add such a statement. Again, not something that can/will impact my assessment of the paper, but always nice to have."}, "questions": {"value": "In addition from my questions above, I'd like to know if it is possible to know what would be the behaviour of a reasoning model alone in this agentic workflow scenario. This _is_ important since a comparison between a Markov-like optimised prompt/workflow versus the effect of a (behind-an-API) reasoning model _versus_ a RLM using the Markov-optimised approaches would allow an ablation on whether it is the prompt, the workflow, or the model that provides the contributions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YtjARRuqB3", "forum": "1UoB7IWiku", "replyto": "1UoB7IWiku", "signatures": ["ICLR.cc/2026/Conference/Submission19999/Reviewer_2crY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19999/Reviewer_2crY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761531467578, "cdate": 1761531467578, "tmdate": 1762932902114, "mdate": 1762932902114, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Code World Models (CWMs), using an LLM to translate natural-language rules plus a few example trajectories into executable Python code that implements a game’s world model (state transitions, legal moves, termination), along with synthesized heuristic value functions and inference functions for imperfect-information games. Experiments cover 5 perfect information games and 5 imperfect information games, and showing promising results while using Gemini 2.5 Pro as the LLM."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. \"data to code\" fashion creates a verifiable simulation of games, and both perfect and imperfect information games can be applied in this fashion.\n2. Two ways of synthesizing inference functions for imperfect information games to avoid the exponential cost is a valuable contribution. Both hidden history inference and hidden state inference are straightforward yet effective."}, "weaknesses": {"value": "1. Synthesize quality relies on generated test cases over a limited amount of trajectories. When LLM failed to parse game rules, it might not build the code world model effectively. \n2. It seems like CWM performs worse than Random in the game of Gin rummy."}, "questions": {"value": "1. In closed-deck learning, can you quantify how the learned state-space size correlates with performance? This corresponds to your hypothesis at Line 455 - 457.\n2. Have you tried iterative online refinement (updating the CWM during play), and if so, does it reduce reliance on high-quality initial trajectories? (You note it’s possible but skipped for efficiency.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "y4GdpBI6kA", "forum": "1UoB7IWiku", "replyto": "1UoB7IWiku", "signatures": ["ICLR.cc/2026/Conference/Submission19999/Reviewer_jLRx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19999/Reviewer_jLRx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891196485, "cdate": 1761891196485, "tmdate": 1762932901634, "mdate": 1762932901634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors extend the Code World Model (CWM) framework by considering two-player games, performing value function code synthesis to improve player performance, introducing the concept of \"inference as code\" to enable state estimation in imperfect information games, and providing a learning algorithm (based on code-based autoencoders) to enable learning in the novel closed deck (strict partial observability) setting. Their results shows the superiority of this approach with respect to LLMs as policies on multiple perfect and imperfect information games, including newly created ones."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Well written paper.\n- Very good related works section\n- Good amount of environments/games tested"}, "weaknesses": {"value": "- Less ablation studies performed\n- Very few baselines\n- Only Gemini 2.5 tested. Other LLMs would bring the variance that is needed to be demonstrated"}, "questions": {"value": "There are many who have shown \"Code as policies\", working in different settings. Why is it better than just creating actions through LLMs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pLDCSMKrOx", "forum": "1UoB7IWiku", "replyto": "1UoB7IWiku", "signatures": ["ICLR.cc/2026/Conference/Submission19999/Reviewer_4ELJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19999/Reviewer_4ELJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978059505, "cdate": 1761978059505, "tmdate": 1762932901069, "mdate": 1762932901069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method for gameplay agents, to use LLMs to generate a code world model, which serves as a verifiable simulation engine for the planning algorithms. The experiments evaluate the gameplay performance on 10 different games, outperforming or rivaling Gemini 2.5 Pro."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. To use the LLM to generate the code world model is a novel idea to represent a specific game in a verifiable manner.\n\n2. The work is solid. I also read the appendix of the paper. It provides all necessary details and examples."}, "weaknesses": {"value": "1. The experiments are made on 10 distinct games, generalizing 4 to the other 6 games. It is hard for readers to assess the OOD generalizability of the method.\n\n2. One concern is what kind of games (e.g. poker-like games) can benefit from the proposed method. Can the method work for any types of games? The complexity to generate a code world for card games is somewhat low, for example, the code cannot be very long, so what about more complex games?"}, "questions": {"value": "Please see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EXimSu5IF8", "forum": "1UoB7IWiku", "replyto": "1UoB7IWiku", "signatures": ["ICLR.cc/2026/Conference/Submission19999/Reviewer_Liqi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19999/Reviewer_Liqi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979110821, "cdate": 1761979110821, "tmdate": 1762932900586, "mdate": 1762932900586, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "New synthesis results using Gemma 27B (open-weights LLM)"}, "comment": {"value": "We have repeated our synthesis method for perfect information games and closed-deck imperfect information games using the open-weights model Gemma 27B. The results are as follows:\n\n### Table 1: Perfect information games\n**Caption:** Refinement via conversation using Gemma 27B, averages over 5 seeds.\n\n| Game | OOD | Transition Acc. (Train) | Transition Acc. (Test) | # LLM Calls |\n| :--- | :---: | :---: | :---: | :---: |\n| Backgammon | ✗ | 0.17462 | 0.16742 | 500.0 |\n| Connect Four | ✗ | 0.07826 | 0.10005 | 500.0 |\n| Tic-tac-toe | ✗ | 0.98049 | 0.98441 | 193.0 |\n| Gen. tic-tac-toe | ✓ | 0.94833 | 0.90307 | 500.0 |\n| Gen. chess | ✓ | 0.49281 | 0.51603 | 500.0 |\n\n### Table 2: Imperfect information games\n**Caption:** Hidden history inference, closed deck using Gemma 27B, averages over 5 seeds.\n\n| Game | OOD | Inference Acc. (Train) | Inference Acc. (Test) | # LLM Calls |\n| :--- | :---: | :---: | :---: | :---: |\n| Bargaining | ✗ | 0.09412 | 0.14296 | 500.0 |\n| Leduc poker | ✗ | 0.13333 | 0.11799 | 500.0 |\n| Gin rummy | ✗ | 0.00797 | 0.01393 | 500.0 |\n| Quadranto | ✓ | 0.09412 | 0.10343 | 500.0 |\n| Hand of war | ✓ | 0.07812 | 0.07949 | 500.0 |\n\n### Discussion\n\nGemma 27B is an open-weights language model with no thinking capabilities. As expected, Gemma 27B is significantly less performant at extracting Code World Models (CWM). For tic-tac-toe, out of 5 seeds, we obtain the perfect CWM in 4 seeds. For the remaining games, the correct CWM is never extracted, although a non-trivial amount of progress is achieved for Generalized tic-tac-toe. We didn’t produce arena results, since with such poor CWMs it is obvious that the resulting agents won’t perform well.\n\nAs expected, our method works best with the most performant coding models. Although more performant models can also produce better actions when used directly as a policy, results can be further improved by using our proposed approach."}}, "id": "jJqWa7JfgR", "forum": "1UoB7IWiku", "replyto": "1UoB7IWiku", "signatures": ["ICLR.cc/2026/Conference/Submission19999/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19999/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission19999/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763679506046, "cdate": 1763679506046, "tmdate": 1763679506046, "mdate": 1763679506046, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}