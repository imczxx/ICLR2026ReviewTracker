{"id": "U6SnDgI3gG", "number": 14528, "cdate": 1758238089241, "mdate": 1759897364576, "content": {"title": "On the Spectral Differences Between NTK and CNTK and Their Implications for Point Cloud Recognition", "abstract": "The Convolutional Neural Tangent Kernel (CNTK) offers a principled framework for understanding convolutional architectures in the infinite-width regime. However, a comprehensive spectral comparison between CNTK and the classical Neural Tangent Kernel (NTK) remains underexplored. In this work, we present a detailed analysis of the spectral properties of CNTK and NTK, revealing that point cloud data exhibits a stronger alignment with the spectral bias of CNTK than images. This finding suggests that convolutional structures are inherently more suited to such geometric and irregular data formats. Based on this insight, we implement CNTK-based kernel regression for point cloud recognition tasks and demonstrate that it significantly outperforms NTK and other kernel baselines, especially in low-data settings. Furthermore, we derive a closed-form expression that connects CNTK with NTK in hybrid architectures. In addition, we introduce a closed-form of CNTK followed by NTK, while not the main focus, achieves strong empirical performance when applied to point-cloud tasks. Our study not only provides new theoretical understanding of spectral behaviors in neural tangent kernels but also shows that these insights can guide the practical design of CNTK-based regression for structured data such as point clouds.", "tldr": "", "keywords": ["Neural Tangent Kernel", "Interpretability of neural networks"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9c2e198665e5b32842cf40a7d2f9489d876ef1f6.pdf", "supplementary_material": "/attachment/8c63867b4355a90bec3809056e0ab0a83236a4f9.zip"}, "replies": [{"content": {"summary": {"value": "This paper finds that CNTK is more suitable for point cloud data than image data, and thus proposes a CNTK-based kernel regression method for point cloud recognition tasks. Experimental results demonstrate its effectiveness, while providing a new theoretical explanation for the spectral characteristics of NTK."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.This paper explains the spectral characteristics of NTK from a new perspective and finds that CNTK is more suitable for point cloud data. The formulas are rigorous and correct, and the experimental results also demonstrate the rationality of this theory."}, "weaknesses": {"value": "1.This paper only conducts training on the ModelNet dataset. Experiments on ScanObjectNN, which is more in line with real-world scenarios and more challenging, should be added to demonstrate the practicality of the method."}, "questions": {"value": "1.The relevant work done in this paper on shared MLP should be extendable to more advanced point cloud models, such as PointMLP. Have the authors made any relevant attempts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "9XYwuTsdLH", "forum": "U6SnDgI3gG", "replyto": "U6SnDgI3gG", "signatures": ["ICLR.cc/2026/Conference/Submission14528/Reviewer_qeWv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14528/Reviewer_qeWv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761186863401, "cdate": 1761186863401, "tmdate": 1762924922343, "mdate": 1762924922343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes the spectral comparison between Convolutional Neural Tangent Kernel (CNTK) and Neural Tangent Kernel (NTK). Through a series of theoretical analysis and validation via synthetic data, the paper concludes that convolutional structures are inherently more suited to irregular point cloud data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The theoretical comparison between CNTK and NTK can potentially guide architectural search of point cloud tasks."}, "weaknesses": {"value": "* The writing of the paper is hard to follow, hard to understand. Though it is a theory paper, the presentation can be made much more accessible by explaining the intuition behind and visualization. Figure 1 seems to have such attempt, but it is not explained well.\n* The conclusion reached by the paper is a well-known fact from empirical experience. The paper only decorates it with some theoretical proof.\n* The conclusion that “convolutional structures are more suited to irregular point cloud data” is supported by Figure 2. But it only has one point cloud dataset and two image datasets, which cannot represent “point cloud” and “image”.\n* In the experiments, the result shows PointNet performs better than PointNTK under all settings. So it is hard to understand what is the practical implication of the paper."}, "questions": {"value": "What can be some practical implication of the paper given PointNTK performs worse than PointNet?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ge2A8JGCLH", "forum": "U6SnDgI3gG", "replyto": "U6SnDgI3gG", "signatures": ["ICLR.cc/2026/Conference/Submission14528/Reviewer_GQJv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14528/Reviewer_GQJv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761525105113, "cdate": 1761525105113, "tmdate": 1762924921781, "mdate": 1762924921781, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the first systematic comparison of the spectral properties of the Neural Tangent Kernel (NTK) and the Convolutional NTK (CNTK). The authors formally prove that for data with a tensor structure, CNTK consistently exhibits a broader eigenvalue spectrum and a smaller mean eigenvalue compared to NTK. Based on this insight, they propose that CNTK's spectral bias is inherently better suited for geometric data like point clouds. This hypothesis is validated by introducing a metric for \"Convolutional Suitability\" and demonstrating experimentally that point clouds align more strongly with CNTK's properties. Finally, the authors propose PointNTK, a CNTK-based kernel regression method, which achieves strong performance on point cloud recognition, particularly outperforming training-based baselines in low-data settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel and Insightful Theoretical Contribution: \n\n    The paper provides the first systematic spectral comparison of NTK and CNTK, offering a novel theoretical lens to understand the inductive biases of convolutional architectures. The introduction of mK and βK as quantitative metrics and the concept of \"Convolutional Suitability\" are significant contributions that provide theoretical guidance on how to choose the right network architecture for a given type of data.\n﻿\n\n- Combining theory with practice: \n\n    A key strength of this work is that it clearly connects theory with practice. The authors start from formal proofs to formulate a verifiable hypothesis—that point clouds are more \"convolutionally suitable\" than images—and then compellingly validate this hypothesis through well-designed experiments.\n﻿\n\n- Explanation a Fundamental Question in Point Cloud Processing: \n\n    This paper tackles a highly relevant question in the 3D vision community: why are convolutional-like structures (such as the shared-MLPs in PointNet) so effective for point cloud data. By approaching this from a theoretical kernel perspective, the work provides a novel explanation."}, "weaknesses": {"value": "- [Minor] Confusing performance:\n﻿\n    The results in Table 1 present a slightly confusing result. For the ModelNet10_6 dataset, the vanilla 1dCNTK (91.96%) outperforms the more complex PointNTK (91.19%). This seems to contradict the paper's motivation for adding MLP layers . A discussion on why this might occur would be beneficial.\n﻿\n- [Minor] Potential Discrepancy Between Ablation Results and the Unorderedness Argument:\n﻿\n    The paper makes a strong argument that a kernel size greater than 1 is detrimental due to the unordered nature of point clouds. Following this logic, one would expect a sharp performance drop when the kernel size increases from 1 to 2. However, the experimental results (Figure 4) show a gradual decline rather than a steep fall. This gentle degradation seems not entirely consistent with the theoretical expectation that aggregating unordered points would cause severe disruption. The paper would be strengthened by a discussion or explanation of this phenomenon . \n﻿\n- [Minor] Practical Limitation of the β_K Metric:\n\n    The use of the initial layer's metric, β_K(0), as a proxy for \"Convolutional Suitability\" is a practical simplification but also a limitation. As Figure 1 shows, β_K evolves with depth. The paper would be stronger if it discussed this evolution or provided bounds on its variation, which would enhance the completeness of the theory.\n﻿\n- [Minor] The Core Concept of \"Convolutional Suitability\" Lacks a Formal Definition\n\n    The paper introduces \"Convolutional Suitability\" as a key concept but fails to provide a formal definition. It is only mentioned that 1 - β_NTK(0) can be \"interpreted as\" this metric. For clarity and to facilitate future work, this concept should be formally defined when it is first introduced."}, "questions": {"value": "- On the Performance of the PointNTK Model: \n    I noticed in Table 1 that for the ModelNet10_6 dataset, the simpler 1dCNTK model slightly outperforms the PointNTK hybrid model. This is counter-intuitive given that the MLP layers are introduced to enhance performance. What is your interpretation of this result? Is it related to dataset-specific properties?\n﻿\n- On the Smooth Decline in the Kernel Size Ablation: \n    Your argument about point cloud unorderedness suggests that a kernel size k > 1 should be highly detrimental. I would have expected a sharp performance drop when moving from k=1 to k=2. Instead, Figure 4 shows a smooth, gradual decline. What is your intuition for this gentle degradation? \n﻿\n- On β_K(0) as a Proxy for Suitability: \n    You use β_K(0) as a practical proxy for \"Convolutional Suitability\" across the entire network. While I understand the computational challenge of evaluating β_K(L) for deep layers, do you have any evidence or theoretical argument suggesting that β_K(0) is a reliable representative? An answer here would strengthen the claim that this initial-layer metric is sufficient."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oFeGwkkFBQ", "forum": "U6SnDgI3gG", "replyto": "U6SnDgI3gG", "signatures": ["ICLR.cc/2026/Conference/Submission14528/Reviewer_qF94"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14528/Reviewer_qF94"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761583583334, "cdate": 1761583583334, "tmdate": 1762924921418, "mdate": 1762924921418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}