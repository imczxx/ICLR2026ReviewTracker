{"id": "rBj2iVyrhh", "number": 18361, "cdate": 1758286812601, "mdate": 1759897108551, "content": {"title": "Classifier-Constrained Alternating Training: Mitigating Modality Imbalance in Multimodal Learning", "abstract": "Modality imbalance, driven by divergent convergence dynamics across modalities, critically limits multimodal model performance. Although alternating training methods mitigate encoder-level interference, they fail to prevent dominance of classifiers by faster-converging modalities, suppressing contributions from weaker ones. To address this core limitation, we propose Classifier-Constrained Alternating Training (CCAT). Our framework first pre-trains an unbiased cross-modal classifier using bidirectional cross-attention and a regularization term that constrains modality contribution differences. This classifier is then frozen as a stable decision anchor during subsequent training, preventing bias toward any modality. To preserve modality-specific features while leveraging this anchor, we integrate modality-specific Low-Rank Adaptation (LoRA) modules into the classifier. During alternating training, CCAT updates only the encoder of the active modality and its corresponding LoRA parameters. Furthermore, a sample-level imbalance detection mechanism quantifies contribution disparities, enabling targeted optimization of severely imbalanced samples to bolster weaker modalities. Extensive experiments across multiple benchmarks demonstrate CCAT’s consistent superiority: it achieves accuracy gains of +1.35% on CREMA-D, +6.76% on  Kinetic-Sound and +1.92% on MVSA over state-of-the-art methods, validating the framework’s efficacy in learning balanced, robust multimodal representations.", "tldr": "We propose CCAT, a framework using a frozen unbiased classifier and modality-specific LoRA adapters during alternating training to prevent modality imbalance, significantly outperforming state-of-the-art methods.", "keywords": ["Multimodal Learning", "Modality Imbalance", "Classifier Freezing", "Alternating Training"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/49d7a0d7bc1a0a286853cbd648234479ec574df5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "To address the overlooked issue of classifier's modality bias in multimodal learning when confronting modality imbalance, this paper proposes an alternating unimodal training approach with classifier constraint. Specifically, a classifier is first trained to achieve equal modality contribution as far as possible and then fixed. Subsequently, LoRA is appended to this fixed classifier, and joint training of LoRA and the encoder is performed. This method not only avoids interference between encoders but also achieves more balanced modality learning at the classifier level."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The observation and resolution of modality imbalance at the classifier level are of innovative significance.\n2. The approach of pretraining the classifier via bidirectional attention is relatively lightweight. Appending LoRA to the classifier not only lightens the training burden of the classifier but also prevents the forgetting of previously learned knowledge.\n3. This paper is well-written, featuring fluent expression and a clear structure."}, "weaknesses": {"value": "1. In Eq. (5) of MI calculation, is the denominator calculated within each batch or all dataset? I assume it is on all dataset with $D$, but this seems to bring about a great deal of calculation.\n2. If LoRA is modality-wise, it is adviced to be reflected in the Figure 3.\n3. While the method proposed in this paper seems directly extensible to three or even more modalities, this part is lacking in the experiments.\n4. The goal of training the classifier in this paper is to maintain equal contributions; however, since inherent capabilities vary across modalities, could this approach lead to reduced performance of originally strong modalities, thereby undermining the utilization of multimodal performance?\n5. Based on Figure 4, the performance of the method proposed in this paper is sensitive to hyperparameters $\\beta$, yet there is no obvious pattern to follow. This makes me skeptical about the effectiveness of the contribution calculation method for sample selection. A comparative experiment involving random sample selection for secondary updates should be added for further verification.\n6. Some methods for comparison are lacking, such as \n[1] Li, Hong, et al. \"Boosting multi-modal model performance with adaptive gradient modulation.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n[2] Wei, Yake, et al. \"Diagnosing and re-learning for balanced multimodal learning.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.\n[3] Fan, Yunfeng, et al. \"Detached and interactive multimodal learning.\" Proceedings of the 32nd ACM International Conference on Multimedia. 2024.\n[4] Hua, Cong, et al. \"ReconBoost: Boosting Can Achieve Modality Reconcilement.\" International Conference on Machine Learning. PMLR, 2024.\n \n7. Some minor typos, such as L085, L320, etc"}, "questions": {"value": "1. In L310, decision-level fusion refers to logit fusion in my view; thus, is the calculation of the contribution value c here also based on the mutual information of logits? \n2. What is the proportion of samples selected for secondary updates when calculated under different values of $\\beta$, and to what extent does this increase the training cost?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "NgXhxqNP8f", "forum": "rBj2iVyrhh", "replyto": "rBj2iVyrhh", "signatures": ["ICLR.cc/2026/Conference/Submission18361/Reviewer_H3wW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18361/Reviewer_H3wW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760885284307, "cdate": 1760885284307, "tmdate": 1762928071605, "mdate": 1762928071605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a novel multimodal learning approach focusing on the classifier to prevent modality dominance during training. The proposed **Classifier-Constrained Alternating Training (CCAT)** first pretrains a balanced cross-modal classifier with contribution-aware regularization and then freezes it during alternating modality-specific optimization, aided by LoRA adapters for flexible adaptation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents extensive experimental results across three benchmarks (CREMA-D, Kinetic-Sound, and MVSA), consistently outperforming strong baselines such as MLA, MMPareto, and LFM. The inclusion of ablation studies and t-SNE visualizations provides additional support for the effectiveness and interpretability of the proposed CCAT framework.\n- The paper provides a clear motivation regarding the persistence of modality imbalance in multimodal learning. The authors correctly identify the issue of classifier dominance by faster-converging modalities, which is an important aspect of the multimodal optimization problem and justifies the need for further exploration."}, "weaknesses": {"value": "**Major**\n\n1. The main contribution of the paper seems very incremental. The proposed approach does not introduce a fundamentally new perspective or identify a critical gap in multimodal learning. As acknowledged in the Related Work section, numerous prior studies have explored modality imbalance through *architectural modifications, adaptive gradient or learning-rate adjustments, and loss-based balancing strategies*. The core design of this work, based on cross-attention and the addition of modality-specific LoRA adapters, appears as a technical variation of existing alternating-training methods rather than a novel conceptual advance.\n2. The paper claims to present a unified theoretical framework for modality imbalance; however, Section 3.1 provides only a conceptual analogy using simplified gradient expressions. The discussion lacks formal definitions, assumptions, or proofs that would substantiate it as a genuine theoretical framework. The claimed theoretical contribution is therefore overstated, and the section functions more as conceptual motivation than rigorous analysis. In other words, the paper does not propose any formal statements or mathematical propositions. If the authors intended merely to express modality imbalance in mathematical terms, it would be more appropriate to describe this as a systematic formulation rather than a theoretical framework.\n\n**Minor**\n\n1. The analyses in Table 2 and the t-SNE visualization are not sufficient to demonstrate that the proposed method effectively resolves modality imbalance. For instance, in the CREMA-D dataset, while conventional fusion methods (e.g., Sum, Concat) lead to dominance of the audio modality, CCAT slightly reverses this dominance toward the video modality. A more detailed quantitative analysis (e.g., per-modality contribution trends or convergence curves) would strengthen the claim.\n2. The paper refers to “full results in the Appendix” in Section 4.3 (line 427), but these results are not included.\n3. (Very minor issue, not affect to the rating score) The paper would benefit from improved formatting and organization (e.g., last sentence on Section 4.2)"}, "questions": {"value": "- Clarification on **Major Weaknesses 1**\n- Clarification on **Major Weaknesses 2**\n- Fundamentally, it remains unclear whether mitigating modality imbalance is treated as an end goal or simply as a means to improve multimodal performance. For instance, in Table 1 (MVSA), methods such as OGM-GE and QMF exhibit noticeable modality imbalance, yet their overall accuracies differ from MMPareto by only about $\\pm 1\\%$. In my understanding, This raises the question of whether reducing imbalance directly translates to better multimodal learning, or if the observed improvements are primarily due to other design factors in CCAT.\n- The role of LoRA within the proposed framework is not sufficiently justified. Although Table 2 shows its quantitative contribution, Section 3.3 (lines 268–293) provides little conceptual explanation beyond its description as a lightweight adaptation layer. It would be helpful for the authors to clarify why LoRA is essential in this setting.\n\n=======================================================\n\n**Note**: I acknowledge that I may have partially misunderstood certain aspects of the paper. Therefore, I am willing to raise my rating score if these questions and concerns are adequately addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "h1XNrlnOb9", "forum": "rBj2iVyrhh", "replyto": "rBj2iVyrhh", "signatures": ["ICLR.cc/2026/Conference/Submission18361/Reviewer_B8hh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18361/Reviewer_B8hh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761618258019, "cdate": 1761618258019, "tmdate": 1762928071177, "mdate": 1762928071177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes the connection between modality imbalance and class imbalance and proposes a classifier-centric multi-stage learning paradigm to mitigate modality imbalance. Specifically, the authors pretrain a shared classifier with contribution-aware regularization to achieve an unbiased initialization, and then freeze the classifier during modality-alternating optimization while introducing lightweight LoRA modules for modality-specific adaptation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "⦁\tThe paper builds a unified theoretical framework linking modality imbalance and class imbalance through gradient optimization dynamics, offering a new and insightful interpretation with solid theoretical motivation.\n⦁\tThe proposed two-stage design (classifier pretraining + frozen constraint + modality-specific LoRA + sample-level re-optimization) forms a coherent and complete framework that effectively handles both dataset-level and sample-level imbalance.\n⦁\tExtensive experiments across three representative multimodal tasks (emotion recognition, action recognition, and sentiment analysis) demonstrate clear performance gains, and the ablation studies are thorough and well-designed."}, "weaknesses": {"value": "⦁\tThe meaning of $\\gamma$ in Equation (3) is unclear. Although the paper claims that $\\gamma$ is implicitly learned, there is no quantitative analysis of modality-specific $\\gamma$ values in experiments. Moreover, in other fusion frameworks (e.g., concatenation), the parameter update:\n$$\n\\nabla W_{[i,j]} = \\frac{\\partial L}{\\partial W_{[i,j]}} = \\frac{\\partial L}{\\partial z_j} \\cdot \\frac{\\partial z_j}{\\partial W_{[i,j]}} = (p_j - y_j) \\cdot f_i\n$$\nshows no inherent modality preference across parameters. Therefore, how should $\\gamma$ be theoretically interpreted? The current derivation lacks rigor and omits discussion on the modality-specific feature term $f$, weakening the theoretical persuasiveness.\n⦁\tThe proposed contribution-aware classifier shares conceptual similarities with existing works: MMCosine [1], Online-Logit [2], SMSL [3]. The paper should clarify the distinction and novelty compared to these approaches.\n⦁\tIt is unclear whether the LoRA fine-tuning pipeline introduces significant training-time overhead compared to direct end-to-end optimization.\n⦁\tIn comparisons with existing methods, since LoRA modules increase the parameter count, the fairness of the comparison is questionabl, especially given that the observed performance gains are modest. Furthermore, some recent strong baselines InfoReg[4] (CVPR2025), Remix[5] (ICML2025), DGL[6] (ICCV2025), AMSS[7] (TPAMI2025) are missing from the comparison\n[1] Ruize Xu, Ruoxuan Feng, Shi-Xiong Zhang, and Di Hu. MMCosine: Multi-Modal Cosine Loss Towards Balanced Audio-Visual Fine-Grained Learning.\n[2] Daoming Zong, Chaoyue Ding, Baoxiang Li, Jiakui Li, and Ken Zheng. Balancing Multimodal Learning via Online Logit Modulation.\n[3] Ying Zhou, Xuefeng Liang, Yue Xu, and Bowen Gao. Sample-level self-paced learning to tackle multimodal imbalance problem.\n[4] Chengxiang Huang, Yake Wei, Zequn Yang, and Di Hu. Adaptive unimodal regulation for balanced multimodal information acquisition.\n[5] Xiaoyu Ma, Hao Chen, and Yongjian Deng. Improving Multimodal Learning Balance and Sufficiency through Data Remixing.\n[6] Shicai Wei, Chunbo Luo, and Yang Luo. Boosting Multimodal Learning via Disentangled Gradient Learning.\n[7] Yang Yang, Hongpeng Pan, Qing-Yuan Jiang, Yi Xu, and Jinghui Tang. Learning to Rebalance Multi-Modal Optimization by Adaptively Masking Subnetworks."}, "questions": {"value": "Refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qIwQoWsgv8", "forum": "rBj2iVyrhh", "replyto": "rBj2iVyrhh", "signatures": ["ICLR.cc/2026/Conference/Submission18361/Reviewer_AmSH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18361/Reviewer_AmSH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815918519, "cdate": 1761815918519, "tmdate": 1762928070559, "mdate": 1762928070559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method called Classifier Constrained Alternative Training (CCAT) to address the issue of modality imbalance in multimodal learning. Modality imbalance refers to the situation where certain modalities (such as visual and audio) dominate the optimization direction of the classifier during training due to faster convergence speed or higher data quality, suppressing the contribution of other modalities and thus limiting the performance of the model. The key idea includes a two-stage training framework and LoRA module adaptation and sample level retraining mechanism. First, pretrain a shared classifier, use bidirectional cross attention and regularization terms (based on mutual information) to constrain modal contribution differences, and obtain a relatively unbiased classifier; Then the classifier is frozen in alternate training to prevent it from deviating from any mode. LoRA module adaptation introduces a lightweight LoRA module for each modality to achieve modality specific representation adaptation based on frozen classifiers. Sample level retraining mechanism identifies samples with extremely imbalanced contributions, conduct targeted retraining on them, and enhance weak modal representations. The experiment was conducted on three multimodal benchmark datasets, covering modal combinations such as audio, video and image text. CCAT significantly outperforms existing methods with accuracy improvements. The ablation experiment validated the effectiveness of each component.."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Innovation: A new paradigm of \"classifier constraint\" has been proposed, which freezes pretrained classifiers to avoid being biased by dominant modalities, and combines LoRA to achieve modality specific adaptation. The method is novel and effective. Revealed the similarity between class imbalance and modality imbalance from the perspective of gradient dynamics, providing theoretical support.\n2. Experimental verification: The generality and robustness of the method were validated on three datasets with different modality combinations and imbalance patterns. Detailed ablation experiments and hyperparameter searches (such as LoRA rank and imbalance threshold) were conducted to enhance the credibility of the results. Provided feature visualization (t-SNE) and clustering metrics (CH, SH, DB) to validate the improvement in representation quality.\n3. Writing: The paper has a clear structure, detailed method description, rich charts, and theoretical analysis and experimental verification complement each other, making it easy to understand and reproduce."}, "weaknesses": {"value": "1. Limitations of the illustration: The experimental section of the paper mentions multiple modalities, including text and image pairs, but the illustrations in the methods section only explain the across modalities network structure of audio data and visual data modalities. What kind of network structure should be adopted for the other modalities. Moreover, there are some issues in Figure 2, please recheck.\n2. Insufficient of the method: This paper discusses the across modalities problem between two modalities and attempts to address it, but it seems that there is no mention of the problem between two or more modalities and the corresponding solutions.\n3. Insufficient of limitations analysis: Some analysis of failure cases is expected to provide further insights into the method's limitations.\n4.Insufficient of problem description: The modality imbalance caused by the different convergence dynamics between different modalities mentioned in the paper, but there is no detailed analysis of the changes in convergence dynamics during training based on specific modality."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "eVgcwo9JLc", "forum": "rBj2iVyrhh", "replyto": "rBj2iVyrhh", "signatures": ["ICLR.cc/2026/Conference/Submission18361/Reviewer_DiSP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18361/Reviewer_DiSP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986883510, "cdate": 1761986883510, "tmdate": 1762928069104, "mdate": 1762928069104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}