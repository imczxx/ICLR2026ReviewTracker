{"id": "VUnwpYZfm2", "number": 12532, "cdate": 1758208439754, "mdate": 1759897503659, "content": {"title": "Exploring the Boundary of Diffusion-based Methods for Solving Constrained Optimization", "abstract": "Diffusion models have achieved remarkable success in generative tasks such as image and video synthesis, and in control domains like robotics, owing to their strong generalization capabilities and proficiency in fitting complex multimodal distributions. However, their full potential in solving Continuous Constrained Optimization problems remains largely underexplored. Our work commences by investigating a two-dimensional constrained quadratic optimization problem as an illustrative example to explore the inherent challenges and issues when applying diffusion models to such optimization tasks and providing theoretical analyses for these observations. To address the identified gaps and harness diffusion models for Continuous Constrained Optimization, we build upon this analysis to propose a novel diffusion-based framework for optimization problems called DiOpt. This framework operates in two distinct phases: an initial warm-start phase, implemented via supervised learning, followed by a bootstrapping phase. This dual-phase architecture is designed to iteratively refine solutions, thereby improving the objective function while rigorously satisfying problem constraints. Finally, multiple candidate solutions are sampled, and the optimal one is selected through a screening process. We present extensive experiments detailing the training dynamics of DiOpt, its performance across a diverse set of Continuous Constrained Optimization problems, and an analysis of the impact of DiOpt's various hyperparameters.", "tldr": "We explore the inherent issues when applying diffusion models to continuous constrained optimization and then develop DiOpt, which learns feasible and near-optimal solution mapping via bootstrapping training.", "keywords": ["Nonconvex Optimization", "Diffusion Solver", "Bootstrapping Training"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b7aa0acb12d62732e227b6d8e1abf31a2142501b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper explores constrained optimization in generative diffusion models. The main problem that the paper tackles is the fact that a diffusion model may end up generating samples outside of the feasible region due to the inherent stochasticity of the generative process. This is indeed an important problem that warrants a rigorous scientific investigation and the paper is timely. To address the problem, the paper proposes DiOpt, which introduces a weighted bootstrapping method to self-supervise the model to generate samples within the feasible region. The idea, as I understand, is to generate samples (\"candidate points\") during training and weigh them according to constraint violation (feasible points get positive weights and infeasible points negative weights); The diffusion model loss term (squared error of predicted noise) is then weighed accordingly and used for training the diffusion model."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper addresses an important problem for the community and has the potential to help us overcome some of the current limitations we are facing with diffusion models. The proposed weighting scheme is somewhat new, and the method is validated against other methods on several benchmarks."}, "weaknesses": {"value": "I guess my biggest problem is with the scientific contribution. First and foremost, even though the paper claims to address the hard-constrained generation problem in various places, such as Table 1 and the intro section, in my opinion, this is still a soft-constrained generation problem. If I understood correctly, the model is simply \"discouraged\" from generating infeasible samples via the bootstrapped weight values during the training stage. I don't find anything that actually hard-constrains the generated samples to be within the feasible region, and their experiment data also shows that (e.g., the first column of Table 2).\n\nHowever, even aside from the discussion of whether it is a hard-constrained method or not, I don't know if the paper contains a sufficient amount of new scientific knowledge or methodological breakthroughs. The main idea of the DiOpt method is to weigh the loss function via bootstrapped samples so that the generation of feasible samples is promoted, whereas infeasible samples are suppressed. However, considering the high scientific standard of ICLR, I don't know if this is something I would call an \"ICLR-worthy\" idea. Also, the mathematical analysis in Section 4 on \"why ... diffusion models encounter infeasibility issues in constrained optimization,\" which is argued as a contribution of this paper, is rather underwhelming: It defines feasibility in **linear** programming mostly, and there are a couple of sentences showing an asymptotic bound on the probability of generated sample existing in the feasible region unfortunately without any proofs or rigorous dicussions. So again, I don't know if this is an ICLR-worthy contribution to the scientific community.\n\nFurthermore, overall, the presentation can be improved significantly. First and foremost, the scientific contribution of this work is unclear. Both the intro and the abstract could benefit from jumping straight to the exact problem that the authors want to address, how they propose to solve it, and what contribution to the scientific community they are presenting. Also, the bullets in the intro, which are supposed to summarize their contributions, don't really do justice. That's because these bullets mostly talk about \"what\" they do, instead of \"why\" it is important. In its current form, the contribution seems to be very narrowly positioned to the development of this very specific recipe that employs bootstrapping to discourage the model from creating infeasible samples.\n\nThe paper could also benefit from more high-level, intuitive explanations of the core scientific idea. Although my research isn't characterized as optimization research, I teach a course on that topic and would claim that I am fairly familiar with the technical content. Despite that, it required me several readings to grasp what the core scientific idea was."}, "questions": {"value": "- Is DiOpt limited only to linear, convex optimization problems, or can it generalize to more complex non-convex optimization problems as well?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IC8IlENsCY", "forum": "VUnwpYZfm2", "replyto": "VUnwpYZfm2", "signatures": ["ICLR.cc/2026/Conference/Submission12532/Reviewer_iA95"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12532/Reviewer_iA95"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12532/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760629047083, "cdate": 1760629047083, "tmdate": 1762923394240, "mdate": 1762923394240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper apply diffusion model on learning to optimize problem to solve constrained optimization problem. Compared to standard supervised diffusion model, which produces infeasible in high dimensional problems, their proposed DiOPt method can hold the constrains better thanks to the combination of supervised and self supervised learning. In self supervised learning stage, a weighted loss is applied to bootstrap feasible samples. The design yields better feasibility and optimality trade-off compared to baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- the bootstrapping self-supervised training can effectively bias the sample towards the feasible region and is compatible with different diffusion formulations\n    \n- the proposed method is empirically validated on diverse constrained optimization problems with detailed ablation"}, "weaknesses": {"value": "- the method introduces extra hyperparameters including weight, reset frequency and lookup updates. It would be beneficial if author and provide heuristics on how to choose those hyperparameters and how sensitive the algorithm are to those parameters.\n    \n- the author only report evaluation time in the main text. It would be helpful to also report training time for different method to see the overhead introduced by two-stage training."}, "questions": {"value": "- can DiOPT handle equality constraints?\n    \n- how sensitive is DiOPT to parameters like rs and Kt in the paper?\n    \n- in standard constrained optimization, Lagrangian multiplier is employed to control the penalty level based on violation. is it possible to use the same practice to make the weight update for constrains less rely on heuristics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2MEuMtOEfk", "forum": "VUnwpYZfm2", "replyto": "VUnwpYZfm2", "signatures": ["ICLR.cc/2026/Conference/Submission12532/Reviewer_tjYr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12532/Reviewer_tjYr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12532/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706877589, "cdate": 1761706877589, "tmdate": 1762923393823, "mdate": 1762923393823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DiOpt, a training framework enhancing the capability of diffusion models for solving optimization problems. The method introduces sample weighting functions to bias the training towards samples which have lower constraint violation and regret. The evaluation is conducted across several interesting problems, most notably the ACOPF setting, which is a challenging and highly nonconvex real-world application."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Empirical Analysis:** The evaluation includes several different optimization problems, the majority of which require adherence to nonconvex constraints sets. In particular, I appreciate the results on the ACOPF settings, which are considered to be an important problem; I believe these experiments add real-world significance to the results.\n\n- **Methodological Simplicity:** The method proposed is fairly intuitive, and the analysis motivating its adoption sets this up well. As the results are strong, the simplicity of the approach should be considered a strength of the work.\n\n- **Exposition:** The paper is easy to follow, and positions itself well within the broader literature."}, "weaknesses": {"value": "- **Novelty:** I have some concerns regarding the novelty of the method, considering the similarity to [1]. While the overlap methodologically leads me to view this work as more of an application paper, it is not currently presented this way. I believe this work could differentiate itself better by leaning further into an exploration the specific weighting function used for this domain. From a theoretical perspective, the analysis surrounding the weighting scheme is fairly limited, and, in its current form, this appears to be closer to a heuristic than a grounded rule. Some of the ablations in the appendix do help strengthen the authors' case, and it would be useful if these could be alluded to better in the main paper.\n\n- **Clarifications of Experiments:** The exposition here seems to be the weakest, in part because little space is dedicated to it. Many key details are buried in the appendix. For example, in the appendix it seems that the QP experiment is convex; if this is the case, why does DC3 report such high violations -- I'd expect these to approach zero, based on the description. Can the authors speak to this? \n\n- **Additional Baselines:** It would be interesting to see how the performance compares to methods that integrate hard constraints. Of course, formal guarantees cannot be provided on the nonconvex settings considered, but it would be of interest to provide results on other methods from Table 1.\n\n- **Out-of-Distribution Testing:** Has any analysis been given to OOD settings? I assume that in all settings the model has been trained on the same distribution (e.g., same constraints and objective) as it is tested on. Could conditioning be used to encourage generalization?\n\n---\n\n[1] Ding, Shutong, et al. \"Diffusion-based reinforcement learning via q-weighted variational policy optimization.\" Advances in Neural Information Processing Systems 37 (2024): 53945-53968."}, "questions": {"value": "See questions in weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "al3PnpobXc", "forum": "VUnwpYZfm2", "replyto": "VUnwpYZfm2", "signatures": ["ICLR.cc/2026/Conference/Submission12532/Reviewer_tDFK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12532/Reviewer_tDFK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12532/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761852542624, "cdate": 1761852542624, "tmdate": 1762923393586, "mdate": 1762923393586, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors discuss solving constrained optimization problems with a generative diffusion model. They show that training the model on a dataset of solutions is not adequate, with the sampled solutions regularly being outside the feasible space. Thus, they propose an alternate training scheme, DiOpt, that mixes \"supervised\" training with solutions and \"unsupervised\" training with random points, weighted by their objective value, to steer the diffusion model towards generating samples in the feasible region. The experiments show that the proposed method can be used as a learned solver on a set of constrained optimization tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The idea of training a diffusion model in an \"unsupervised\" way, i.e., without a ground truth dataset of samples (solutions), is very interesting and has not been explored before to the best of my knowledge. The authors effectively show that with appropriate weighting, they can train the diffusion model to generate samples in the desired region, which in this case, corresponds to the feasible space of solutions to the optimization problem. This could be a significant contribution both to the learned optimization and the overall diffusion crowd.\n\n- DiOpt can effectively produce solutions to the constrained optimization problem, whereas a naive approach of training the diffusion on solutions only fails. Additionally, when compared to two previous baselines, DiOpt consistently achieves results closest to an optimization solver, while only requiring a fraction of the time."}, "weaknesses": {"value": "- The baselines to which the proposed method is compared are not well established in the main text, making it difficult to interpret the results of Table 2. The main result of the paper in Table 2 requires the reader to know how the two baselines (DC3, MBD) work to get a clear picture of the advantages of the proposed algorithm. It seems that DC3 trains a network to perform the optimization, whereas MBD runs some kind of solver within its algorithm (and seems not to work at all). Thus, apart from establishing that DiOpt achieves better results, the experiment does not really provide any information related to what the advantages or critical components of DiOpt are. \n\n- The authors, throughout the paper, compare the proposed DiOpt to the naive approach of training the diffusion model in a supervised way, but do not include results of the \"naive diffusion\" approach in the main table. Some of those results are found in the appendix ablations. Table 2 should include an additional row with the naive approach to establish a baseline of what the problems of training the diffusion without DiOpt are."}, "questions": {"value": "- You mention six related learned constrained optimization methods from the literature, but end up only comparing to two. Are the other methods not applicable to the settings you have applied DiOpt to, and if not, could you apply DiOpt to their settings?\n\n- What is the training time of DC3 in Table 2, and what is the training time of DiOpt? Additionally, MBD seems to be an inference-only method, meaning that it does not require any training at all. Is the comparison fair in that case?\n\n- Is the issue of the naive diffusion approach the amount of training data? If you had a large enough dataset, would you observe the same issue as shown in Figure 2?\n\n- In Algorithm 1, should line 333 be `if n mod 2 == 0 then`? Does the reset of Equation (11) happen for both infeasible and feasible ($\\omega = 0$) points?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "jyS9Riij5b", "forum": "VUnwpYZfm2", "replyto": "VUnwpYZfm2", "signatures": ["ICLR.cc/2026/Conference/Submission12532/Reviewer_2zyr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12532/Reviewer_2zyr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12532/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948079676, "cdate": 1761948079676, "tmdate": 1762923393071, "mdate": 1762923393071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}