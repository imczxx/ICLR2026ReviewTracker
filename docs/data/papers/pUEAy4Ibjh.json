{"id": "pUEAy4Ibjh", "number": 23328, "cdate": 1758342216828, "mdate": 1763096774021, "content": {"title": "Toward Reliable Domain Adaptation under Continuous Spurious Shift", "abstract": "Recent advances in domain adaptation have shown promise in transferring knowledge across domains characterized by a continuous value or vector, such as varying patient ages, where \"age'' serves as a continuous index. However, these approaches often fail when spurious features shift continuously along with the domain index. This paper introduces the first method designed to withstand the continuous shifting of spurious features during domain adaptation. Our method enhances domain adaptation performance by aligning causally transportable encodings across continuously indexed domains. Theoretical analysis demonstrates that our approach more effectively ensures causal transportability across different domains. Empirical results, from both semi-synthetic and real-world medical datasets, indicate that our method outperforms state-of-the-art domain adaptation methods.", "tldr": "", "keywords": ["Probabilistic Models; Continuous Shift"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/ede66890ac505363cd84150c31e7ef043b050827.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies continuously indexed domain adaptation (CIDA), arguing that continuously drifting spurious features can undermine existing methods. The authors cast the problem in a causal framework and primarily invoke the front-door criterion. They present theoretical results suggesting that the method proposed by authoors(CADA)  improves causal transportability across continuously indexed domains. Experiments on a semi-synthetic dataset and two real-world health datasets (SHHS and MESA) are good but not yet conclusive."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The theory is correct; I have checked the proof.  \n* The result on the C2MNIST dataset is good.  \n* The writing is clear, and the causal model is reasonable."}, "weaknesses": {"value": "* The theory shows limited innovation, as it mainly builds on existing theorems in the causal graph proposed in the paper.  \n* In the semi-synthetic image dataset, it seems to be just a dataset with shifting spurious features, which does not clearly relate to the causal model.  \n* For real-world datasets such as SHHS and MESA, in paper [1], other methods achieve better accuracy, while PCIDA shows state-of-the-art performance.  \n\n[1] Hao Wang, Hao He, and Dina Katabi. *Continuously Indexed Domain Adaptation.* In *ICML*, 2020."}, "questions": {"value": "* (a) In the semi-synthetic image dataset, how does the construction demonstrate the causal model? To support the claim, some controlled synthetic experiments are needed.  \n* (b) Why are the baseline results in your paper significantly lower?  \n* (c) More experiments are needed to validate the performance on continuously indexed domain adaptation problems."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2lMTOFR8v1", "forum": "pUEAy4Ibjh", "replyto": "pUEAy4Ibjh", "signatures": ["ICLR.cc/2026/Conference/Submission23328/Reviewer_Sjm5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23328/Reviewer_Sjm5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761162144355, "cdate": 1761162144355, "tmdate": 1762942605134, "mdate": 1762942605134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "CwCVAJUzOE", "forum": "pUEAy4Ibjh", "replyto": "pUEAy4Ibjh", "signatures": ["ICLR.cc/2026/Conference/Submission23328/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23328/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763096773147, "cdate": 1763096773147, "tmdate": 1763096773147, "mdate": 1763096773147, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CADA (Continuously trAnsportable Domain Adaptation), a framework aimed at handling continuous spurious shifts in continuously indexed domain adaptation (CIDA) problems. It combines causal transportability analysis with adversarial domain alignment to learn “causally transportable” encodings that remain invariant across continuously changing domains. Theoretical discussions connect the method to front-door adjustment and transportability (Pearl, 2009), and experiments are conducted on semi-synthetic (C2MNIST) and two medical datasets (SHHS and MESA). While results show consistent performance improvements over baselines, the proposed formulation and experiments exhibit several weaknesses that undermine the novelty and rigor of the work."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "-\tAddresses a plausible and practically relevant problem (continuous spurious shifts).\n\n-\tAttempts to integrate causal reasoning with domain adaptation, a direction of general interest.\n\n-\tProvides complete experiments across both synthetic and medical datasets, with some consistency in results."}, "weaknesses": {"value": "-\tThe method is a trivial extension of existing CIDA + DANN frameworks. The causal encoder and discriminator setup are directly borrowed from adversarial DA literature, and the “causal” aspect is only notational.\n\n-\tTheorems simply restate known transportability claims (Pearl, 2009) without proof of novel conditions or improvements. The reasoning around Eqn. (1–2) is tautological.\n\n-\tOn real datasets (SHHS, MESA), performance differences are marginal (≈1–2%) and lack statistical testing; 100% accuracy on synthetic C2MNIST indicates overfitting or unrealistic setup.\n\n-\tDespite claims, there is no experiment demonstrating invariant causal effect recovery or robustness to interventions.\n\n-\tKey recent causal DG works (IRM, VREx, CORAL++) are missing.\n\n-\tThe paper repeatedly uses “first method” or “theoretical guarantee” without substantiating either.\n\n-\tMany hyperparameters, dataset preprocessing, and implementation details are deferred to appendices, with no code or seed disclosure."}, "questions": {"value": "-\tHow does the causal encoder differ, mathematically or empirically, from simply adding noise augmentation across domain indices as in standard adversarial alignment?\n\n-\tCan you formally show that Eqn. (2) leads to identifiable causal features under continuous shift?\n\n-\tWhy does CADA achieve exactly 100% accuracy on all C2MNIST ranges—was there label leakage or an overly simplified setup?\n\n-\tCould results generalize to high-dimensional real-world settings beyond sleep datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3dxLVqdz7H", "forum": "pUEAy4Ibjh", "replyto": "pUEAy4Ibjh", "signatures": ["ICLR.cc/2026/Conference/Submission23328/Reviewer_8xte"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23328/Reviewer_8xte"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833399807, "cdate": 1761833399807, "tmdate": 1762942604524, "mdate": 1762942604524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a new domain adaptation algorithm based on a minimax objective that aims to find a new \"causal factors\" representation of an input by minimizing prediction error on the main task while maximizing prediction error on a domain prediction task. The form of generator for the \"causal factors\" representation is derived (including theoretical proofs) from a model where an input generates a base representation and the \"causal factors\" representation is derived from that given knowledge of other inputs."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* Outperforms by a large margin a variety of existing domain adaptation techniques on a synthetic dataset that injects a confounding color variable into MNIST\n* Outperforms by a small margin a variety of existing domain adaptation techniques on two sleep stage prediction datasets, SHHS and MESA, where confounding noise has been injected.\n* Includes an ablation that shows that all components of the approach are important for solving the color-confounded MNIST problem."}, "weaknesses": {"value": "* The article is very difficult to read. Critical components of the theorems, e.g., do(x), are not defined, and the intuitions behind the theorems are not well explained. While I appreciate that the appendix contains formal proofs, the main text of the article needs to stand alone such that the proposed approach is understandable without the appendix. The article needs a high level explanation of the proposed algorithm and the intuitions for why it should take the form that it does before it begins diving into theorems and proofs.\n* It doesn't seem like there's any evaluation on a real-world dataset. Though the article claims \"Empirical results on... real-world medical datasets\" it also says that \"SHHS and MESA datasets contain continuously shifting spurious noise to simulate...\" Thus it appears that the spurious noise in these datasets is simulated, not natural. Especially given how small the benefit of the approach is over CUA on the SHHS and MESA datasets, the reader is left wondering whether the approach is useful in the real world or only on datasets with synthetically generated noise.\n* The proposed approach requires a Monte Carlo estimation with three nested sampling loops for each prediction, but computational cost is not discussed in the main text. There is a table in appendix D, but no description of the setup for that table's experiments, nor an explanation of why the proposed model, which requires 55 samples per prediction isn't slower than the other 2 models that don't appear to require any samples. The table is also critically missing the efficiency of CUA, the next best model according to Tables 3 and 4.\n* Figures are often far away from where they are discussed, causing the reader to have to page back and forth over multiple pages."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5xnMCak4Df", "forum": "pUEAy4Ibjh", "replyto": "pUEAy4Ibjh", "signatures": ["ICLR.cc/2026/Conference/Submission23328/Reviewer_81SG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23328/Reviewer_81SG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877663684, "cdate": 1761877663684, "tmdate": 1762942604209, "mdate": 1762942604209, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Continuously trAnsportable Domain Adaptation (CADA), a framework to handle continuous spurious shifts—situations where spurious correlations between features and labels change smoothly with a continuous domain index (e.g., patient age). The authors develop a causal encoder–discriminator architecture that learns causally transportable representations invariant to such shifts by jointly performing causal inference and adversarial alignment across domains. Theoretical analysis proves CADA ensures causal transportability and bounds target-domain error under covariate shift. Experiments on semi-synthetic (Continuous Colored-MNIST) and real-world medical datasets (SHHS, MESA) demonstrate that CADA outperforms state-of-the-art domain adaptation and causal generalization baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an meaningful problem, domain adaptation under continuous domain indices such as age or time, which is relevant in medical and temporal applications."}, "weaknesses": {"value": "- The motivation is not strongly justified. Although the paper claims to address continuous domain adaptation, the continuous component mainly comes from the discriminator design in CIDA rather than the proposed method itself.\n\n- Some main ideas are theoretically questionable. The authors propose to estimate the $ P(y|do(x)) $. However, the estimation of $ P(y|do(x)) $ is not guaranteed to yield the optimal predictor on observational data, where the optimal hypothesis is Bayes classifier $ P(y|x) $.\n\n- The claim that the method learns causal representations $ v $ is inconsistent with the invariant constraint imposed during training because $ v $ may not invariant across domains; enforcing invariance may alter or remove the causal meaning of $ v $.\n\n- The technical novelty is limited. The proposed framework mainly combines causal representation learning (i.e., front-door adjustment, causal encoder) with standard adversarial alignment similar to CIDA. \n\n- The theoretical results are mostly straightforward restatements of known transportability properties and do not offer new insights. In addition, architectural choices (e.g., Gaussian assumptions, one-sample estimation for $ Q(v|x) )$ lack justification in terms of modeling rationale or computational efficiency.\n\n- The experiments are limited to three datasets (C2MNIST, SHHS, MESA), all in constrained settings. There is no validation on diverse domains such as computer vision, time-series, or NLP, reducing the generalizability of the conclusions. The authors are recommended to experiment with more datasets from literature [1,2]\n\n- The literature review is not comprehensive and omits several recent baselines in continuous or temporal domain adaptation and domain generalization [1,2,3,4,5,6,7].\n\n- The ablation experiments are basic and do not analyze parameter sensitivity, training stability, or robustness under varying domain gaps, leaving many empirical aspects unexplored.\n\n- Code is not provided for reproducibility purposes.\n\nReferences\n\n[1] Qin, Tiexin, Shiqi Wang, and Haoliang Li. \"Generalizing to evolving domains with latent structure-aware sequential autoencoder.\" International Conference on Machine Learning. 2022.\n\n[2] Pham, Thai-Hoang, Xueru Zhang, and Ping Zhang. \"Non-stationary domain generalization: Theory and algorithm.\" Conference on Uncertainty in Artificial Intelligence. 2024.\n\n[3] Bai, Guangji, Chen Ling, and Liang Zhao. \"Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks.\" International Conference on Learning Representations. 2023.\n\n[4] Zeng, Qiuhao, et al. \"Generalizing across temporal domains with koopman operators.\" AAAI Conference on Artificial Intelligence. 2024.\n\n[5] Zeng, Qiuhao, et al. \"Foresee what you will learn: data augmentation for domain generalization in non-stationary environment\". AAAI Conference on Artificial Intelligence. 2023.\n\n[6] Xie, Mixue, et al. \"Evolving standardization for continual domain generalization over temporal drift.\" Advances in Neural Information Processing Systems. 2023.\n\n[7] Cai, Zekun, et al. \"Continuous temporal domain generalization.\" Advances in Neural Information Processing Systems. 2024."}, "questions": {"value": "- Could the authors clarify what part of the proposed framework specifically handles the continuous domain index beyond reusing the discriminator from CIDA? Is there any novel mechanism in CADA that models or leverages the continuity of the domain variable (e.g., smoothness constraints, interpolation, or continuous embeddings)?\n\n- Could the authors justify why optimizing $ P(y|do(x)) $ should lead to better generalization performance, and under what assumptions this holds?\n\n- Can the authors provide theoretical or empirical evidence that the learned $v$ preserves causal semantics rather than being just domain-invariant?\n\n- The proposed approach seems to combine causal front-door adjustment with adversarial alignment similar to existing works. Could the authors clarify the unique contribution of CADA beyond integrating these two known ideas? For example, is there any novel insight in how the causal encoder and discriminator interact?\n\n- Can the authors explain why CADA improves over other methods? For instance, do the learned representations show lower mutual information with domain indices or stronger causal disentanglement? Providing quantitative causal metrics or visualizations could strengthen the empirical justification."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1VTpUtfRsi", "forum": "pUEAy4Ibjh", "replyto": "pUEAy4Ibjh", "signatures": ["ICLR.cc/2026/Conference/Submission23328/Reviewer_DniX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23328/Reviewer_DniX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963886237, "cdate": 1761963886237, "tmdate": 1762942604022, "mdate": 1762942604022, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}