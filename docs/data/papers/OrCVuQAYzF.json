{"id": "OrCVuQAYzF", "number": 9149, "cdate": 1758113220631, "mdate": 1759897740916, "content": {"title": "WILD-Diffusion: A WDRO Inspired Training Method for Diffusion Models under Limited Data", "abstract": "Diffusion models have recently emerged as a powerful class of generative models and have achieved state-of-the-art performance in various image synthesis tasks. \nHowever, training diffusion models generally requires large amounts of data and suffer from overfitting when the dataset size is limited. To address these limitations, we propose a novel method called WILD-Diffusion, which is inspired by Wasserstein Distributionally Robust Optimization (WDRO), an important and elegant mathematical formulation from robust optimization area. Specifically, WILD-Diffusion utilizes WDRO to iteratively generate new training samples within a Wasserstein distance based uncertainty set centered at the limited data data distribution. This carefully designed method can progressively augment the training set throughout the training process and effectively overcome the obstacles caused by the limited data issue. Moreover, we establish the convergence guarantee for our algorithm even though the mixture of diffusion process and WDRO brings significant challenges to our analysis in theory. Finally, we conduct a set of experiments to verify the effectiveness of our proposed method. With WILD-Diffusion, we can achieve more than a $10$% reduction in FID using only $20$% of the training data across different datasets. Moreover, our method can attain state-of-the-art FID with as few as $100$ images, both in pretrained and non-pretrained settings.", "tldr": "", "keywords": ["Diffusion model; Wasserstein Distributionally Robust Optimization; Limited Data"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/11c6811d60f1c501b92d86612d53b6b98e78d9db.pdf", "supplementary_material": "/attachment/f3aa068bfc0fc29838fde864201e02c3183d7224.zip"}, "replies": [{"content": {"summary": {"value": "It is known that training diffusion models requires a lot of data. To mitigate this, the paper proposes a training method using Wasserstein Distributionally Robust Optimization (WDRO) called WILD-Diffusion. Using DRO, the paper can train the model to be more fitted on not only given sharp limited training data, but also near smooth distribution by expanding the support of the data. To do this, the paper uses the two-levels update strategy one for updating parameters and the other for updating samples. They also provide convergence analysis for the proposed method."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and provides rich theoretical analysis. Applying DRO to diffusion models for few-shot learning is a new idea and technically sounds. To prove the method works well, they show that the proposed method achieved high performance when the data is limited (e.g. 20%, 50% in Table 1). Also, it can be applied to existing diffusion models easily as they applied the method to various existing models such as EDM, Patch Diffusion and DeepCache."}, "weaknesses": {"value": "- Applying DRO to diffusion models is already studied in previous works (e.g. Improved Diffusion-based Generative Model with Better Adversarial Robustness, ICLR 2025). While the main topics of them and this paper may different, the novelty of the proposed work may decrease.\n- The datasets used in the experiments seem limited. These dataset have relatively narrow in topic, so perturbing them may effectively expand the dataset support. However, for larger and more complex dataset (e.g. ImageNet), expanding the support may introduce degradation by off-manifold samples.\n- The comparisons with other few-shot diffusion model are only conducted on 100-shot and Animal Face datasets. In fact, since the numbers in Table 6 in the appendix show that other few-shot works also achieve comparable performance, it seems necessary to verify whether the performance gap remains consistent across a wider variety of datasets. Comparisons on other datasets such as CelebA, MNIST, and LSUN would strengthen the evaluation."}, "questions": {"value": "- What are the key differences between this work and previous studies that applied DRO to diffusion models? (e.g. Improved Diffusion-based Generative Model with Better Adversarial Robustness)\n- Is the proposed method robust even when the data manifold is highly complex?\n- How much does the training time increase due to the two-level update strategy?\n- Can the data generated by the proposed method but not belonging to the given data distribution be separately visualized?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tL5ti1KepB", "forum": "OrCVuQAYzF", "replyto": "OrCVuQAYzF", "signatures": ["ICLR.cc/2026/Conference/Submission9149/Reviewer_rEDT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9149/Reviewer_rEDT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761141201073, "cdate": 1761141201073, "tmdate": 1762920832808, "mdate": 1762920832808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses overfitting when training diffusion models with limited data, observing U-shaped FID curves and reduced diversity as training proceeds on small subsets.\nConcretely, a training framework inspired by Wasserstein Distributionally Robust Optimization (WDRO) is proposed, termed WILD-Diffusion,  which expands the support of the training distribution by iteratively generating worst-case samples within a Wasserstein ball around the empirical data and mixing them into training.\nTo keep this tractable, the WDRO inner max is dualized into a surrogate loss and optimized with a bi-level interval update (periodically refreshing adversarial samples, then standard parameter updates), and the paper proves a convergence guarantee tailored to the WDRO+diffusion setting.\nExperiments on CIFAR-10, FFHQ, CelebA-HQ, LSUN-Church and several backbones report >10% FID reductions with only 20% data and SoTA FID with as few as 100 images, both with and without pretraining."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper investigates an interesting and important problem for the research community. The proposed approach is technically sound, viewing data scarcity through a distributionally robust lens and converting the push for more data into adversarial, Wasserstein-bounded augmentations that expand support without drifting off-distribution. The optimization is practical: a tractable surrogate objective with a simple bi-level refresh of worst-case samples that plugs into standard training loops and works with or without pretraining. Theoretical analysis supports the design, and experiments show meaningful FID gains in very low–data regimes, demonstrating utility beyond incremental tweaks. Overall, the method is conceptually clean, easy to adopt, and delivers strong sample-efficiency improvements in settings where diffusion models typically overfit."}, "weaknesses": {"value": "1. While the dual surrogate makes the WDRO objective tractable, it can mis-specify the true worst-case set and depends on strong-duality assumptions.\n\n2. The convergence proof requires Lipschitz/log-Sobolev–style assumptions for data and score error bounds; these may not hold for real high-res image manifolds.\n\n3. The bi-level update generates **worst-case** samples and mixes them with real data, but the paper doesn’t quantify how often those samples are usefully hard versus toxic."}, "questions": {"value": "1. How is the robustness radius selected across datasets and data regimes?\n\n2. How closely does the dual surrogate approximate the true worst-case set?\n\n3. What are the wall-clock/GPU-hour and peak-memory overheads of the adversarial refresh loop relative to standard training?\n\n4. Do the improvements extend to high-resolution generation and text-to-image settings, and what changes (if any) are needed to the loss, model, or optimization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZQ5DAjqzuT", "forum": "OrCVuQAYzF", "replyto": "OrCVuQAYzF", "signatures": ["ICLR.cc/2026/Conference/Submission9149/Reviewer_GEiA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9149/Reviewer_GEiA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977502889, "cdate": 1761977502889, "tmdate": 1762920832424, "mdate": 1762920832424, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes WILD‑Diffusion, a WDRO‑inspired, plug‑and‑play training framework for diffusion models under limited data. It extends Wasserstein Distributionally Robust Optimization to train diffusion models. Furthermore, the authors provide a convergence guarantee despite the coupling between the diffusion process and WDRO. Empirically, WILD‑Diffusion shows competitive performance in both fine-tuning and from-scratch setting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Theory‑grounded, practical framework with broad applicability.\n- Beyond heuristic data augmentation, the approach is anchored in WDRO and comes with a convergence guarantee. It shows strong performance in limited‑data regimes in both from‑scratch training and fine‑tuning scenarios, accompanied by ablations that indicate robust gains."}, "weaknesses": {"value": "1. Clarification of few‑shot comparisons and OOD adaptation.\n- In Section 4.3 (Experiments on Few‑shot Generation), Table 2 compares fine‑tuning settings with pretraining, but the original pretrained model’s performance is not shown alongside. Moreover, the FFHQ‑pretrained fine‑tuning appears in‑distribution for faces; it would be informative to evaluate out‑of‑distribution adaptation, for example transferring to a stylized or non‑face domain such as a Pokémon dataset, to assess robustness under distribution shift."}, "questions": {"value": "1. Overhead of bi‑level interval updates.\n- How does the proposed bi‑level interval update compare to standard full fine‑tuning in terms of wall‑clock time, training steps, and memory/compute overhead? A quantitative breakdown would help practitioners assess the cost–benefit trade‑off.\n\n2. Comparison to attention‑only fine‑tuning under limited data.\n- Prior work on fine‑tuning diffusion models with limited data [1] suggests that attention‑only fine‑tuning can prevent overfitting while remaining competitive. Has WILD‑Diffusion been compared against such parameter‑efficient baselines, and if so, under identical data budgets and evaluation protocols?\n\n3. Large scale model experiments on limited data\n- The proposed method demonstrates strong effectiveness under limited-data conditions, but its impact could be further amplified by including experiments on large-scale text-to-image diffusion models. Showing that WILD-Diffusion maintains or improves few-shot performance in such settings would better highlight its generality and practical relevance.\n\nReferences\n\n[1] Moon et al., Fine-tuning diffusion models with limited data"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YqXdNghGHD", "forum": "OrCVuQAYzF", "replyto": "OrCVuQAYzF", "signatures": ["ICLR.cc/2026/Conference/Submission9149/Reviewer_hDug"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9149/Reviewer_hDug"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994866369, "cdate": 1761994866369, "tmdate": 1762920832026, "mdate": 1762920832026, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes WILD-Diffusion, a novel framework that adapts Wasserstein Distributionally Robust Optimization (WDRO) to diffusion models to promote robust training under limited-data regimes via  constructing worst-case distributions that are close to the limited data distribution which effectively expands the support of the training data and mitigates overfitting. Experiments on various benchmark datasets show consistent performance improvements, especially when data are scarce (e.g., N=100). Unlike traditional adversarial training, WILD-Diffusion is a plug-and-play procedure that requires no architectural changes and can be used with or without pretraining."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles a timely and relevant problem—improving diffusion model performance with limited data—supported by both theoretical grounding and extensive experiments. \n- The overall presentation is clear, and the method is well motivated with sound empirical results."}, "weaknesses": {"value": "- **Incomplete reporting of computational overhead** The paper reports a *relative* training-time increase of 1.20–1.22× compared to the baseline (Table 8), but does not provide absolute wall-clock time, FLOPs, or GPU memory usage. Since the method targets data-scarce scenarios where efficiency is important, providing these absolute cost measurements would significantly strengthen the practical relevance. Additionally, the paper should include scaling trends with respect to the inner ascent steps *K* and interval *m*. Table 8 also shows minimal overhead variation across dataset sizes—please clarify what the dominant bottleneck is and which component contributes most to runtime.  \n- **Mismatch between baselines and problem focus** The paper frames the core contribution as a *data-efficient training strategy for diffusion models*, yet some baselines are orthogonal to this goal. For instance, DeepCache (Table 1) focuses on *inference-time acceleration*, not robustness to limited data, and Patch Diffusion primarily aims to *reduce architectural training cost*, rather than address data scarcity. It would help to clarify whether these methods are included to demonstrate orthogonality or to claim direct superiority. In the current form, these comparisons blur the paper’s main message.  \n- **Insufficiently controlled augmentation baselines** In Table 7, WILD-Diffusion is compared with basic augmentation methods such as Mixup and CutMix, which perform even worse than the vanilla model. However, there is no indication that these techniques were tuned (e.g., optimal mixing ratios, label smoothing, class-aware mixing, or dataset-specific configurations). Without proper tuning and control, these results may underestimate augmentation baselines and overstate WILD’s relative advantage.  \n- **Extension to other domain tasks** Experiments are primarily conducted on low-resolution unconditional image generation. To better support claims of broad applicability, the method should also be validated on more practical and diverse settings such as class-conditional generation or text-to-image personalization (e.g., DreamBooth-style few-shot fine-tuning). Evaluating WILD-Diffusion on pretrained text-to-image models under data-scarce adaptation would demonstrate stronger real-world relevance."}, "questions": {"value": "Refer to the above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Q6k8zoxuge", "forum": "OrCVuQAYzF", "replyto": "OrCVuQAYzF", "signatures": ["ICLR.cc/2026/Conference/Submission9149/Reviewer_vXtY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9149/Reviewer_vXtY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762022777451, "cdate": 1762022777451, "tmdate": 1762920831633, "mdate": 1762920831633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}