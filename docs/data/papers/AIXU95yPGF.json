{"id": "AIXU95yPGF", "number": 4638, "cdate": 1757731815515, "mdate": 1759898022282, "content": {"title": "Physics-Inspired Reconfiguring Multimodal Learning Networks", "abstract": "Despite recent progress, current multimodal fusion methods still face three practical issues: gradient interference between task and fusion objectives, fragility under missing modalities, and rigidity from enforcing uniform feature dimensions across modalities.\nWe present Physics-Inspired Multimodal Reconfiguration (PMR), a Poisson–Nernst–Planck (PNP)–inspired structured prior for fusion. Drawing from the principles of conservation and single-potential-driven flow, PMR embeds these as (i) an information-preservation regularizer and (ii) a unified scalar potential that shapes gradient updates, mitigating interference between task and fusion objectives. This unified potential drives disentanglement of shared and modality-specific subspaces. A three-stage mapping (dissolution → dissociation → concentration) instantiates the prior to separate and reconstruct features, improving robustness to missing modalities and naturally supporting unequal feature dimensions.\nAcross audio, image, video, and text, PMR consistently outperforms competitive baselines on classification and cross-modal retrieval, demonstrating the efficacy of a physics-inspired hybrid prior for multimodal learning.", "tldr": "A generalized multimodal fusion model via Poisson-Nernst-Planck Equation, which improve the fusion performance.", "keywords": ["Physics-inspired", "Multimodal Fusion", "Poisson-Nernst-Planck Equation", "Optimization Objective Redefinition", "Feature Disentanglement", "Downstream Task Adaptation"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f775c388318f041a63afc41b02501013ccaaf23d.pdf", "supplementary_material": "/attachment/19d1fffb7bbd53c6331756728b82c3bb89dc466c.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a new method to fuse information in multimodal representation learning for retrieval and classification tasks. It is inspired by the Poisson-Nernst-Planck structured prior and it is validated on image-video, audio-video retrieval tasks and image classification tasks."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "-\tMultiple tasks are considered to validate the models (retrieval, classification) and various baselines are given.\n-\tThe proposed model apparently gives competitive results across all benchmarks."}, "weaknesses": {"value": "-\tThe justification for the proposed method is mysterious, with a lot of background from theoretical physics that has nothing to do with the final loss. The parallel between “Poisson-Nernest-Planck” and the fusion module is far-fetched and never justified throughout the experiments. This module corresponds more or less to a simple MLP with some neurons arbitrarily set to zero to extract the “shared” or “specific” information from different modalities (which is never imposed directly with the proposed reconstruction losses). \n-\tA lot of hyper-parameters are introduced (such as the length of the splits for the shared/specific latent vectors for each modality or the actual structure of the mapping between the extracted features and the output of the fusion module) but they are not discussed or mentioned in the experimental section. How did you pick them and what are the final choices?\n-\tTwo reconstruction losses are mentioned in equation 6. Which one did you use in the end and why? Why did you introduce a cosine similarity in one case and an Euclidean distance in another? What is the rational?\n-\tIn equation 5, you mention that k is the “next modality of m”. So how do you handle the case where m is the “last” modality (assuming that an order exists between modalities) ? \n-\tIn your reconstruction losses, how do you make sure that the “specific” information does not contain “shared” information as well, which would be enough to minimize your reconstruction loss. \n-\tIn your experiments, I would expect the feature extractors to be state-of-the-art foundation models (such as DINOv3, CLIP…) in order to have strong baselines in retrieval or classification tasks. \nOverall, this paper pretends to draw a parallel between equations from theoretical physics (drift-diffusion transport, field-charge coupling) and deep neural networks but their analysis is never justified theoretically or empirically. I have also strong doubts about the fairness and reproducibility of their experiments considering the little implementation details given and the high number of hyperparameters introduced by the proposed fusion module."}, "questions": {"value": "Please, see my previous comments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B94wGcyzoD", "forum": "AIXU95yPGF", "replyto": "AIXU95yPGF", "signatures": ["ICLR.cc/2026/Conference/Submission4638/Reviewer_j5i4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4638/Reviewer_j5i4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943667613, "cdate": 1761943667613, "tmdate": 1762917482358, "mdate": 1762917482358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PMR, a physics-inspired multimodal fusion framework derived from the Poisson–Nernst–Planck equations. PMR aims to address three key challenges in multimodal learning: gradient conflicts between task and fusion objectives, robustness to missing modalities, and the limitations of uniform feature dimensions. The framework unifies task and preservation losses through a single scalar potential and introduces a novel three-stage feature reconfiguration process (dissolve–dissociate–concentrate). Experimental results show that the method provides stable optimization and enhances model flexibility and robustness. PMR demonstrates consistent improvements over baseline methods on classification and retrieval tasks across various modalities including audio, image, video, and text."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a novel perspective on multimodal fusion by leveraging principles from physics.\n2. The addressed challenges are both relevant and critical to the field of multimodal learning.\n3. The paper gives a comprehensive summary of related work and situates the proposed method well within prior research."}, "weaknesses": {"value": "1. While Chapter 3 introduces a novel perspective, the connection between its formulations and the algorithm in Chapter 4 is not clearly established. The mathematical formulations seem more like background information rather than serving as a foundation for the proposed algorithm.\n2. In Chapter 4, it is not clear why only two mapping networks are sufficient to distinguish between shared and specific features, or whether their separation can be strictly guaranteed.\n3. The algorithmic section lacks sufficient detail and clarity; it appears more akin to a multi-task learning approach rather than a fundamentally new method for multimodal fusion.\n4. The experimental results are not particularly compelling. In Tables 3 and 4, the performance is comparable to DrFuse. Additionally, the results in Table 5 show the unimodal approach outperforming others in some cases, which is insufficiently explained."}, "questions": {"value": "Please check the above section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cjjbjZVHl2", "forum": "AIXU95yPGF", "replyto": "AIXU95yPGF", "signatures": ["ICLR.cc/2026/Conference/Submission4638/Reviewer_icSp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4638/Reviewer_icSp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986361312, "cdate": 1761986361312, "tmdate": 1762917482116, "mdate": 1762917482116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PMR (Physics-Inspired Multimodal Reconfiguration), a new multimodal fusion framework inspired by the Poisson–Nernst–Planck equations, which enforces information conservation and uses a unified scalar potential to jointly optimize task and fusion objectives, thereby mitigating gradient interference. By implementing a three-stage dissolve–dissociate–concentrate process, PMR supports unequal feature dimensions, improves robustness to missing modalities, and consistently outperforms strong baselines across audio, image, video, and text tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) It's very interesting to design a new neural network using the framework of the Poisson–Nernst–Planck equations.\n(2) The paper is well-written and nicely presented."}, "weaknesses": {"value": "(1) The experiments in the paper are very weak, all conducted on some rather outdated datasets.  \n(2) The paper lacks comparison with state-of-the-art multimodal large models. Current multimodal models are capable of processing multimodal information and extracting embeddings to tackle a wide range of downstream tasks.  \n(3) It also omits comparisons with other multimodal fusion approaches, such as ImageBind (\"ImageBind: One Embedding Space To Bind Them All,\" CVPR 2023) and OnePeace (\"ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities,\" arXiv 2023).  \n\nOverall, the paper presents an interesting idea, but it lacks large-scale, compelling experimental validation."}, "questions": {"value": "I checked many of the methods compared in the paper (e.g., MDF-FND) and found that none of them reported results on the corresponding datasets. I’m curious: where do the results reported in the paper come from? Did the authors implement these methods themselves? If so, how was fairness ensured? Additionally, could the authors clarify how they selected these baseline methods for comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "cV7nEpRRdb", "forum": "AIXU95yPGF", "replyto": "AIXU95yPGF", "signatures": ["ICLR.cc/2026/Conference/Submission4638/Reviewer_3jVe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4638/Reviewer_3jVe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762090813882, "cdate": 1762090813882, "tmdate": 1762917481693, "mdate": 1762917481693, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose PMR, a physics-inspired multimodal fusion framework that is built upon a scalar potential that minimizes entropy and preserves the system's energy. The PMR imitates the PNP theory well by its 3-stage mapping reconfiguration. The experiments demonstrate the effectiveness of the framework design, and the ablations are sufficient and convincing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written.\n2. The authors explain the PNP theory well and use it to develop a new multimpdal encoding framework PMR.\n3. The experiments demonstrate the effectiveness of the proposed method.\n4. The ablation is sufficient to validate the efficacy of the components in PMR."}, "weaknesses": {"value": "Major:\n1. Line 137-147, consistently minimizing the entropy for all modalities means that we hypothesize all modalities contribute the same to the final task. But does this really apply to real-world scenarios, when there are always some modalities that are dominant, while some are just complementary?\n\n2. For Eq.(4,5,6), how to ensure that the b(m) is meaningful to separate the shared and specific features? Is b(m) learnable? And how? (In Figure. 3 I saw b is a hyperparameter.) But according to the PNP model, the b for different substances should be different, which represents a balanced state for different substance pairs; however, in PMR, b is the same for different modalities. \n\n3. The whole process of PMR looks like just a separate and shared encoder for different modality features and uses a straightforward fusion strategy to obtain joint embeddings. The connection between PNP and PMR is not that close, especially considering that some core mechanisms are different, as mentioned in point 2 that the boundary b is the same for all modalities.\n\n4. It looks like PMR could fit any number of modalities; however, in the experiments, the authors only showcase two-modality experiments. Some tri-modal validation could be better. For example, CMU-MOSI(a+v+t) and UCF101-Three(rgb, optical flow, and rgb diff). \n\nMinor:\n1. The Z should be V in line 121?"}, "questions": {"value": "1. Line 187, how to understand this sentence: \"Increasing the effective length enlarges the region where drift dominates diffusion\"?\n2. In Table 2, how to understand: (1) Feature ratio and learning splitting at b; (2) Magnification factor (effective length)\n3. In line 449, what is the actual meaning of nxb? What about without P_seperate, i.e., b=1? Or b=0?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qgQ3QEbpaI", "forum": "AIXU95yPGF", "replyto": "AIXU95yPGF", "signatures": ["ICLR.cc/2026/Conference/Submission4638/Reviewer_Pypz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4638/Reviewer_Pypz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762579439616, "cdate": 1762579439616, "tmdate": 1762917481354, "mdate": 1762917481354, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}