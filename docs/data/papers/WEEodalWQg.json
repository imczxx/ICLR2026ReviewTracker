{"id": "WEEodalWQg", "number": 15448, "cdate": 1758251436537, "mdate": 1759897306239, "content": {"title": "Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets", "abstract": "Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy exists between current fine-tuning datasets and the token-level optimization mechanism of LLMs: most datasets are designed at the sentence-level, which introduces token-level noise, causing negative influence to final performance. In this paper, we propose XTF, an explainable token-level noise filtering framework. XTF decomposes the complex and subtle contributions of token-level data to the fine-tuning process into three distinct and explicit attributes (reasoning importance, knowledge novelty, and task relevance), which can be assessed using scoring methods, and then masks the gradients of selected noisy tokens accordingly to optimize the performance of fine-tuned LLMs. We conduct extensive experiments on three representative downstream tasks (math, code and medicine) across 7 mainstream LLMs. The results demonstrate that XTF can significantly improve downstream performance by up to 13.7% compared to regular fine-tuning. Our work highlights the importance of token-level dataset optimization, and demonstrates the potential of strategies based on attribute decomposition for explaining complex training mechanisms.", "tldr": "", "keywords": ["Large Language Model", "Fine-tuning", "Token-level Data"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab214b02ea09fbb35509b2e2de72fa14f5a99e69.pdf", "supplementary_material": "/attachment/b2a453d551724241235e38cc2976c432dda5bf26.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the mismatch between sentence-level labeling and token-level optimization in LLM fine-tuning. Most fine-tuning datasets provide labels at the sentence or document level, causing models to learn all tokens with equal importance. As a result, noisy or irrelevant tokens within a sentence can distort the optimization direction.\nTo resolve this issue, the authors propose XTF (eXplainable Token-level Filtering). XTF decomposes each token’s contribution into three interpretable attributes: Reasoning Importance (RI), Knowledge Novelty (KN), and Task Relevance (TR). Based on statistically derived thresholds, noisy tokens are identified and masked during training, ensuring that the model learns from meaningful tokens only. \n\nExperiments across three downstream tasks and multiple LLM architectures demonstrate that XTF consistently outperforms both standard fine-tuning and existing data filtering methods. The authors also provide theoretical evidence showing that filtering improves gradient alignment and accelerates convergence. While token-level computation introduces additional overhead, the paper discusses potential efficiency improvements through model distillation.\n\nOverall, this study presents a theoretically grounded and empirically validated framework for token-level data refinement, offering a practical and interpretable solution to one of the fundamental limitations in LLM fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The three metrics are designed in a complementary manner, which is a notable strength of the paper. Knowledge Novelty (KN) increases as the model’s probability of correctly predicting the next token (PCP) decreases, but on its own, a low PCP could simply indicate meaningless noise. The authors address this by jointly considering Reasoning Importance (RI) and Task Relevance (TR), filtering out tokens with low RI or TR even if KN is high. Only when all three metrics are high is a token regarded as meaningful new knowledge. This complementary design effectively overcomes the limitations of each individual metric and demonstrates a distinctive approach to fine-grained token-level filtering.\n \nS2. The paper takes a logical and rigorous approach by providing mathematical proofs that explain why the proposed filtering mechanism is theoretically effective. This theoretical grounding enhances the credibility of the method and clearly supports the intuition behind its practical usefulness."}, "weaknesses": {"value": "W1. The core techniques are borrowed from existing methods without significant innovation: attention scores for importance, which is a standard interpretability technique, prediction probability, which is a straightforward application, and semantic distance, which is basic embedding similarity. The contribution is primarily engineering existing components rather than introducing novel algorithms or architectures.\n\nW2. While motivated by score distributions (Fig 3), the specific thresholding methods involve some heuristics (e.g., the exact quantile parameter for RI, the fixed 95% PCP threshold for KN, choice of cluster for TR via Multi-Otsu). Sensitivity analysis (Appendix C.1) shows the chosen thresholds work best, but optimality across all scenarios isn't guaranteed.\n\nW3. Ablations are missing. The paper needs: 1) threshold sensitivity, where Table 4 tests ±3% but not other ranges or methods, 2) attribute weighting, where Instead of union, can we weight attributes?, 3) layer selection, where does using different attention layers change results?, and 4) dataset size, where how does XTF perform with more/less training data?\n\nW4. Calculating the three scores for all tokens in a dataset requires inference passes with the base LLM, adding a non-trivial computational cost before fine-tuning can begin. The paper quantifies this in Appendix C.2, but it could be a barrier for very large datasets or models."}, "questions": {"value": "Q1. The paper uses distinct methods (Quantile, fixed threshold, Multi-Otsu) for thresholding the three scores based on observed distributions. Could a more unified approach, perhaps learning optimal thresholds or using a combined score, be feasible or beneficial?\n\nQ2. Appendix C.2 shows scoring time. How does the total time (scoring + XTF fine-tuning) compare to achieving similar performance with baseline methods (e.g., normal fine-tuning for more epochs, or sample-level filtering + normal fine-tuning)?\n\nQ3. Could you provide further justification or analysis on how the adaptive constant (r₁) for RI and the heuristic threshold (e.g., PCP ≥ 0.95) for KN were determined? In particular, it would be helpful if you could include additional discussion or experimental evidence showing how variations in these parameters influence model performance.\n\nQ4. In the current study, the filtering ratio is adjusted in ±3% intervals to examine the effect of threshold changes, but this interval may appear somewhat arbitrary. Could you provide additional experimental results using finer intervals (e.g., ±1%) or a wider range of values to analyze the performance patterns and identify the potential optimal threshold range more precisely?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v5i0FvHiMl", "forum": "WEEodalWQg", "replyto": "WEEodalWQg", "signatures": ["ICLR.cc/2026/Conference/Submission15448/Reviewer_9uW5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15448/Reviewer_9uW5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15448/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761480025779, "cdate": 1761480025779, "tmdate": 1762925735375, "mdate": 1762925735375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the token-level noise problem in fine-tuning datasets, motivated by recent findings that noisy tokens can significantly degrade model performance. To address this issue, the paper proposes XTF, a token-level noise filtering framework that identifies and removes noisy tokens based on three key attributes: reasoning importance, knowledge novelty, and task relevance. These attributes are quantified using the attention score, PCP score, and relevance score, respectively. Extensive experiments across multiple base models and benchmarks demonstrate that XTF consistently outperforms all baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The writing is clear and easy to follow.\n\n- The paper lies in introducing a noisy token filtering framework that jointly leverages several scores (including attention, PCP, relevance scores) to accurately identify and remove noisy tokens, which is novel and interesting.\n\n- The claims are well-supported by empirical experiments across multiple models (LLaMA-3, Mistral, Deepseek-distilled-qwen), and popular evaluation benchmarks."}, "weaknesses": {"value": "-  The authors fail to provide a detailed comparison of computational overhead with existing baselines, such as SLM. Including such analysis would help clarify the efficiency of the proposed method.\n\n-  The benchmarks used in the paper are relatively weak and do not convincingly demonstrate the method’s effectiveness. For instance, in Figure 4, the baselines—namely, the original base model (CA) and the standard fine-tuning version (Normal)—are too naive. The reviewer suggests incorporating more competitive baselines for comparison. Recent work such as [1] provides a strong theoretical foundation for noisy token cleaning and should be considered as an additional baseline.\n\n- The paper would benefit from evaluation on more diverse and challenging datasets to further validate its effectiveness—for example, BBH, ARC, and MMLU, which are widely recognized benchmarks for reasoning and knowledge assessment.\n\n\n[1] Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning, ICML 2025."}, "questions": {"value": "1. The citation format throughout the paper is inconsistent with standard academic conventions. Please revise all references to follow the correct style \n\n2. A reference is missing in Line 101.\n\n3. Could incorporating additional attributes further improve the accuracy of noisy token identification?\n\n4. The effectiveness of SLM largely depends on the quality of its reference model. For SLM (also known as RHO), how many samples were used to train the reference model?\n\n5. Could you provide a detailed comparison of GPU hours between the proposed method and the baselines to clearly illustrate the computational overhead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N80ucs4HEW", "forum": "WEEodalWQg", "replyto": "WEEodalWQg", "signatures": ["ICLR.cc/2026/Conference/Submission15448/Reviewer_XoFh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15448/Reviewer_XoFh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15448/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726850337, "cdate": 1761726850337, "tmdate": 1762925734111, "mdate": 1762925734111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces XTF, a novel learning framework that enhances Large Language Model (LLM) fine-tuning by filtering token-level training data. XTF identifies and removes noisy tokens based on three proposed metrics: reasoning importance, knowledge novelty, and task relevance. Tokens scoring below a threshold on any metric are considered noise, and their loss contribution is blocked during backpropagation. Extensive experiments on mathematical, coding, and medical tasks across seven different LLMs demonstrate the strong performance of the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-  Unlike traditional token-level filtering methods that rely solely on loss values, Authors propose three distinct metrics: reasoning importance, knowledge novelty, and task relevance, to comprehensively assess each token's contribution. These metrics are designed to capture different aspects of the relationship between the model, the training data, and the target task.\n\n- Theoretical analysis are provided to demonstrates the effectiveness and efficiency of the XTF framework.\n\n- Extensive experiments across three downstream domains (math, code, and medicine) and seven LLMs confirm the strong performance of our approach."}, "weaknesses": {"value": "- The threshold selection process for the three metrics appears to be largely empirical. For instance, the use of a quantile method in Equation (5) and a fixed threshold of 0.05 in Equation (6). The generalizability of these specific threshold needs further investigation.\n\n- The paper posits that a lower PCP indicates a token containing novel knowledge. However, a low score can also reflect an incorrect or nonsensical token. This ambiguity creates a paradox that is not addressed: how can the framework reliably distinguish between \"novel knowledge\" and \"noise\"?\n\n- The empirical evaluation, while demonstrating positive results, is conducted on a limited number of datasets (three). This contrasts with related work in the field (e.g., [R1, R2]), which often employs more extensive benchmarks (e.g., seven datasets) to validate generalizability. \n\n- Typos. \"Section ??\" on Line 101, should be corrected.\n\n[R1] RHO-1: Not All Tokens Are What You Need\n\n[R2] Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning"}, "questions": {"value": "1. The threshold selection process requires deeper analysis. A sensitivity analysis exploring different threshold values is needed to justify the current choices.\n\n2. To firmly establish XTF's superiority, evaluations should be expanded to include more datasets and a broader comparison with baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CW2Em1RB99", "forum": "WEEodalWQg", "replyto": "WEEodalWQg", "signatures": ["ICLR.cc/2026/Conference/Submission15448/Reviewer_Ucn3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15448/Reviewer_Ucn3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15448/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727380902, "cdate": 1761727380902, "tmdate": 1762925733712, "mdate": 1762925733712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method called XTF (Explainable Token-level Noise Filtering) to improve fine-tuning for large language models (LLMs). The authors argue that most fine-tuning datasets are designed at the sentence level, while LLMs are optimized at the token level. This mismatch introduces token-level noise that can hurt model performance. The paper brings out three interpretable attributes: reasoning importance, knowledge novelty, and task relevance. Before fine-tuning the model, it will mask the one with the lowest score. This method is tested on three downstream tasks and it shows gaining accuracy compared to normal fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Novel perspective:** The paper focuses on token-level dataset optimization, a topic that has not been well studied in LLM fine-tuning.\n\n**Explainable approach:** The design and introduction of three attributes provides a clear and interpretable way to analyze which tokens are useful.\n\n**Good experiment results:** The authors test on diverse tasks (math, medicine, code) and multiple model sizes, showing stable improvements.\n\n**Good theoretical support:** Appendix A provides formal justification linking token filtering to gradient alignment, which adds credibility."}, "weaknesses": {"value": "**Could do more on stable analysis:** Although results show improvements on accuracy, we don’t know whether the result is chosen based on the best result the experiment gets and whether it is reproducible. Thus, it could be better to include some variance, confidence intervals, or significance tests. It is hard to see how stable the improvements are.\n\n**Could do more on examples:** Although the paper repeatedly emphasizes “explainable” token-level filtering, there is almost no qualitative examples or visualizations showing which tokens were removed."}, "questions": {"value": "Threshold analysis is good but could do more in the future: It is good to see that the authors already include the threshold ablation in Appendix. A little bit of suggestion on this will be analyzing interactions effects between the three thresholds to see whether there is a trade-off or something, also it will be better to make some more discussion on this visible in the main paper.\n\nHow sensitive is the final performance when calculating three attributes in a specific way? For example, how would the different interaction among them affect the result?\n\nCould the paper provide more specific examples on the process of filtering tokens?\n\nHow stable or consistent are these improvements the paper mention?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mryhBTPWXr", "forum": "WEEodalWQg", "replyto": "WEEodalWQg", "signatures": ["ICLR.cc/2026/Conference/Submission15448/Reviewer_GsNo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15448/Reviewer_GsNo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15448/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931259816, "cdate": 1761931259816, "tmdate": 1762925732546, "mdate": 1762925732546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}