{"id": "u2pCkbgEKO", "number": 8900, "cdate": 1758101813660, "mdate": 1759897755594, "content": {"title": "Point2Primitive: CAD Reconstruction from Point Cloud by Direct Primitive Prediction", "abstract": "Recovering CAD models from point clouds requires reconstructing their topology and sketch-based extrusion primitives. A dominant paradigm for representing sketches involves implicit neural representations such as Signed Distance Fields (SDFs). However, this indirect approach inherently struggles with precision, leading to unintended curved edges and models that are difficult to edit. In this paper, we propose Point2Primitive, a framework that learns to directly predict the explicit, parametric primitives of CAD models. Our method treats sketch reconstruction as a set prediction problem, employing a improved transformer-based decoder with explicit position queries to directly detect and predict the fundamental sketch curves (i.e., type and parameter) from the point cloud. Instead of approximating a continuous field, we formulate curve parameters as explicit position queries, which are optimized autoregressively to achieve high accuracy. The overall topology is rebuilt via extrusion segmentation. Extensive experiments demonstrate that this direct prediction paradigm significantly outperforms implicit methods in both primitive accuracy and overall geometric fidelity.", "tldr": "", "keywords": ["CAD Reconstruction"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ed8bbf7a5d5fcf1a739d722341b56ef68eef3a2d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for reconstructing CAD models from unstructured point clouds. The key idea is to reverse the sketch-and-extrude process, focusing on recovering topology and parametric primitives such as lines, arcs, and circles.  The paper introduces a two-stage pipeline: the first step is extrusion segmentation using a PointNet++-based network to cluster points into individual extrusion bodies and classify base/barrel points; second, primitive prediction for each segment via an improved transformer decoder that treats sketch reconstruction as a set prediction problem, where explicit position queries are used for autoregressive optimization. Experimental results on DeepCAD and Fusion 360 Gallery datasets demonstrate significant improvements over SDF-based methods like SECAD-Net and generation approaches like DeepCAD."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "CAD model reconstruction is an important problem. The direct prediction of explicit parametric primitives enables highly editable CAD models.\n\nThe general pipeline is technically sound. The decomposition of the problem into extrusion segmentation and primitive prediction, bridging topology recovery with parametric inference in a unified direct-prediction strategy.\n\nThe improved transformer decoder, where curve parameters serve as explicit position queries, is novel and interesting. This allows autoregressive refinement for precise predictions."}, "weaknesses": {"value": "The overall representational ability is relatively limited, supporting only three primitives (lines, arcs, circles), and is unable to handle advanced curves such as splines or Bézier curves, or will fail when the extrusion path is nonlinear.\n\nI have concerns about the center-prior parameterization. Is this a good representation? It assumes a fixed 6D vector for all primitives, padding unused entries with -1. This may introduce logical inconsistencies for non-center-based primitives, potentially leading to suboptimal encoding and attention guidance.\n\nSome ablation studies need to be added to provide more in-depth insights. The autoregressive parameter update across transformer layers is not ablated individually (that is, no experiments show the isolated impact of layer-by-layer supervision). The query denoising is ablated, but it would be even better to give insights into optimal noise rates or group numbers that are not explored through sensitivity analysis.\n\nThe key idea of this paper is very similar to the work Point2skh: End-to-end Parametric Primitive Inference from Point Clouds with Improved Denoising Transformer (Wang et al. 2024), which also uses an improved transformer for direct sketch primitive prediction with explicit position queries. However, the paper is not discussed in the manuscript. The extrusion segmentation approach builds closely on Point2Cyl, which hinders the paper's novelty.\n\nThe output of extrusion segmentation is directly fed into primitive prediction. These two stages are highly dependent. If there is an error in the segmentation like incorrect clustering, subsequent predictions will fail.\n\nThe Normal Head is supervised using L1 loss, but normals are prone to errors in noisy point clouds. This may lead to significant deviations in the calculation of the extrusion axis ."}, "questions": {"value": "Some technical details can be clarified. How exactly is the attention mask formulated to prevent information leakage in denoising groups? How is M correlated with Nc? This is not discussed in the paper.\n\nWill there be degenerate cases for extrusion axis transformations, but implementation details like handling degenerate cases (e.g., collinear points)?\n\nWhat about the sensitivity to noisy point clouds?\n\nIs it possible to implement an end-to-end joint optimization pipeline? It seems segmentation and primitive prediction can be trained with a shared loss. Currently, the pipeline is relatively complex. Also, why not use PointTransformer instead of PointNet++ for segmentation and so that the architecture is unified? Did you try different backbones and find that PointNet++ is the best?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fyA8KoOsNa", "forum": "u2pCkbgEKO", "replyto": "u2pCkbgEKO", "signatures": ["ICLR.cc/2026/Conference/Submission8900/Reviewer_Cvgt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8900/Reviewer_Cvgt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760789569105, "cdate": 1760789569105, "tmdate": 1762920654840, "mdate": 1762920654840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Point2Primitive, a method for reconstructing CAD models from point clouds by directly predicting explicit parametric sketch primitives (lines, arcs, circles) rather than using implicit representations like Signed Distance Fields. The method decomposes the problem into two stages: (1) extrusion segmentation using PointNet++ to cluster points into extrusion bodies, and (2) primitive prediction using an improved transformer decoder that formulates curve parameters as position queries for autoregressive refinement. The authors demonstrate improvements over SDF-based methods and language model-based methods on DeepCAD and Fusion 360 Gallery datasets, achieving high sketch type accuracy and high parameter accuracy on DeepCAD."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper identifies three concrete limitations of SDF-based methods (lack of semantic structure, blurred edges, difficult conversion) and proposes a compelling alternative through direct primitive prediction. The position-as-query formulation elegantly integrates geometric priors into the transformer decoder.\n2. The evaluation includes multiple datasets (DeepCAD, Fusion 360 Gallery), diverse baselines (SDF methods, LM-based generation, primitive fitting), and importantly, an augmented dataset test demonstrating generalization beyond training distribution. Ablation studies thoroughly validate each component.\n3. The method achieves substantial improvements in both primitive accuracy and geometric fidelity, while producing models closer to human designs. The qualitative results compellingly visualize this quantitative strength, showing sharp, precise boundaries as opposed to the blurry/rounded artifacts from SDF-based methods."}, "weaknesses": {"value": "1. Supporting only three basic curve types (line, arc, circle) is a critical limitation. Real CAD models frequently use splines, ellipses, and B-splines. The paper acknowledges this but provides no analysis of what percentage of real CAD models can actually be represented with these three types. This fundamentally questions the practical applicability.\n2. The method only handles sketch-and-extrude operations, excluding revolve, sweep, loft, boolean operations, fillets, etc.\n3. Missing critical analyses:\n   - No computational cost analysis (inference time, memory)\n   - No failure case analysis despite visible errors in Figure 7\n   - Threshold-based barrel label generation (thresh=0.01) sensitivity not analyzed"}, "questions": {"value": "1. What percentage of CAD models in Fusion 360 Gallery can be fully represented using only lines, arcs, and circles? How many require splines or other curve types? Without this analysis, the practical impact remains unclear.\n2. The method requires loop optimization (Algorithm 2) and parameter fine-tuning (Algorithm 1) as post-processing. How much do these steps improve the final metrics? Can you provide ablation results showing performance with/without post-processing? This is crucial for validating the \"direct prediction\" paradigm.\n3. What are the inference time and memory requirements compared to baselines? For practical CAD reconstruction applications, efficiency matters as much as accuracy.\n4. How robust is the initial extrusion segmentation module? Could the authors provide an analysis of failure cases, particularly on complex geometries where multiple extrusions intersect or are in close proximity? How do segmentation errors propagate to the final primitive prediction stage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aT1rjiITuu", "forum": "u2pCkbgEKO", "replyto": "u2pCkbgEKO", "signatures": ["ICLR.cc/2026/Conference/Submission8900/Reviewer_LgU6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8900/Reviewer_LgU6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761649456335, "cdate": 1761649456335, "tmdate": 1762920654379, "mdate": 1762920654379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This proposes to reconstruct CAD models from point clouds based on 2D sketches composed of parametric planar primitives (lines, arcs, and circles), whose extrusion along an axis can reconstruct the surface more accurately than SDFs, especially on sharp boundaries and straight edges. It shows good reconstruction performance compared to previous CAD modeling methods in terms of precision."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A parametric CAD modeling method is proposed that uses multiple 2D primitives (rather than a single one such as a circle), resulting in better modeling precision of CAD shapes.\n2. Several 3D deep learning components are introduced to segment the input point clouds into regions corresponding to different extrusions and to predict the barrel points for parameterizing 2D sketches. A transformer module is also incorporated to refine the curve parameters.\n3. The reconstruction accuracy is superior compared to previous methods. The contributions of the transformer decoder and the sketch hierarchy are also evaluated through ablation studies."}, "weaknesses": {"value": "1. The paper is not well presented. it requires considerable effort to follow its mathematical notations, which is used extensively throughout the work with many subscripts and superscripts.\n2. How does the quality of the input point cloud affect the reconstruction performance of the proposed method, particularly under varying levels of data sparsity, incompleteness, or noise?\n3. While the method is well tailored for CAD modeling, its reliance on predefined geometric primitives limits its generality in handling a broader range of free-form geometries, compared to implicit representations such as SDFs.\n4. The paper does not include examples or discussion of failure cases on the DeepCAD dataset, which would help illustrate the method’s limitations and clarify the situations where its performance degrades."}, "questions": {"value": "1. How well does the proposed model perform in fitting free-form surfaces, such as those of an airplane or a vessel?\n2.  Is the proposed method applicable to modeling open-surface CAD models?\n3. Line 107: the reference for ExtrudeNet appears incomplete; please include the publication year."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dy2XVYLvZt", "forum": "u2pCkbgEKO", "replyto": "u2pCkbgEKO", "signatures": ["ICLR.cc/2026/Conference/Submission8900/Reviewer_KRCe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8900/Reviewer_KRCe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906096510, "cdate": 1761906096510, "tmdate": 1762920654020, "mdate": 1762920654020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework for reconstructing CAD models directly from point clouds by predicting explicit sketch primitive (lines, arcs, and circles) rather than relying on implicit representations like SDFs. The method decomposes reconstruction into two stages: extrusion segmentation, which clusters point clouds into extrusion bodies, and primitive prediction, which uses a transformer decoder with positional encoding to infer precise curve parameters. Experiments on DeepCAD show advantages over prior implicit SDF based approaches in geometric fidelity, boundary sharpness, and editability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper tackles an important problem that has practical relevance. \n- Replacing the sketch-SDF representation with a transformer is sensible and should work better in practice.\n- The paper delivers this message clearly."}, "weaknesses": {"value": "I find this to be a poor paper, primarily because of the following:\n\n- This paper only has 30 references. Even the Point2Cyl written 4-5 years ago has 56 citations and this field has been rapidly growing since then. The paper just ignores a large body of works including, but absolutely not limited to:   \n\n    * Rukhovich, Danila, et al. \"Cad-recode: Reverse engineering cad code from point clouds.\" ICCV 2025.\n\n    * Dupont, Elona, et al. \"Transcad: A hierarchical transformer for cad sequence inference from point clouds.\" ECCV 2024.\n\n    * Sadil Khan, Mohammad, et al. \"CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention.\" CVPR 2024.\n\n    * Dupont, Elona, et al. \"Cadops-net: Jointly learning cad operation types and steps from boundary-representations.\" 3DV 2022.\n\n    * Li, Jiahao, et al. \"CAD-Llama: leveraging large language models for computer-aided design parametric 3D model generation.\" CVPR 2025.\n\n    * Moreover, BRepGiff, BRepGen and etc... The paper cites no works related to boundary representations. Under this bad scientific practice, the paper requires a major rework of its literature survey and hence I cannot recommend acceptance at this point.\n\n- If the paper admits that the CAD is composed of extrusion sequences, then why don't we leverage something like a sequence transformer for the generation of it? In fact some of the related works mentioned above cover this and of course, the paper does not compare. \n\n- The paper argues against the SDF construction due to smoothness but the training dataset is obtained from SDF. This looks like a contradiction to me and would just degrade performance in real scenarios - in fact if we already know that the data is generated from an SDF wouldn't an SDF representation (even at the sketch level) be an ideal choice?\n\n- Extrusion segmentation is completely inspired by Point2Cyl and is not a contribution here. The paper should make this clear. In general, I don't know why this paper fails to give credit when credit is due.\n\n- I see that over the previous works the only change is in the use of a transformer. As I mentioned, there are some related works that the paper misses, which also use those. Hence they are not discussed, I don't feel confident in accepting the rather outdated experimental evaluation as a point of reference.\n\n- No limitations are discussed."}, "questions": {"value": "Please see weaknesses. In addition, can we see any quantitative comparisons related to Fusion360?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JV1hmzL5yp", "forum": "u2pCkbgEKO", "replyto": "u2pCkbgEKO", "signatures": ["ICLR.cc/2026/Conference/Submission8900/Reviewer_yP5d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8900/Reviewer_yP5d"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974139548, "cdate": 1761974139548, "tmdate": 1762920653553, "mdate": 1762920653553, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}