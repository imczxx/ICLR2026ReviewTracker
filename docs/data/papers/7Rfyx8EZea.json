{"id": "7Rfyx8EZea", "number": 283, "cdate": 1756733428908, "mdate": 1763133832956, "content": {"title": "TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML", "abstract": "We introduce TCUQ, a single pass, label free uncertainty monitor for streaming TinyML that converts short horizon temporal consistency captured via lightweight signals on posteriors and features into a calibrated risk score with an $O(W)$ ring buffer and $O(1)$ per step updates. A streaming conformal layer turns this score into a budgeted accept/abstain rule, yielding calibrated behavior without online labels or extra forward passes. On microcontrollers, TCUQ fits comfortably on kilobyte scale devices and reduces footprint and latency versus early exit and deep ensembles (typically about $50$ to $60\\%$ smaller and about $30$ to $45\\%$ faster), while methods of similar accuracy often run out of memory. Under corrupted in distribution streams, TCUQ improves accuracy drop detection by $3$ to $7$ AUPRC points and reaches up to $0.86$ AUPRC at high severities; for failure detection it attains up to $0.92$ AUROC. These results show that temporal consistency, coupled with streaming conformal calibration, provides a practical and resource efficient foundation for on device monitoring in TinyML.", "tldr": "TCUQ fuses short-horizon temporal consistency with a streaming conformal quantile to provide calibrated accept/abstain TinyML decisions on kilobyte MCUs, while cutting model size ~50–60% and latency ~30–45% vs. early-exit/ensembles.", "keywords": ["TinyML", "uncertainty quantification", "temporal consistency", "conformal prediction", "streaming calibration", "out-of-distribution detection", "microcontrollers", "selective classification"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/699429770eb408778c4dbc40d97cdacca92b88b8.pdf", "supplementary_material": "/attachment/244ec8397705cab9da1b3e261e3270db2e9b0a3d.zip"}, "replies": [{"content": {"summary": {"value": "The authors of this paper propose TCUQ (Temporal-Consistency-based Uncertainty Quantification), a single-pass, label-free uncertainty estimation methodology designed for TinyML deployments where there exist strict memory and latency constraints. The method maintains a short temporal buffer of recent predictions and extracts multiple temporal stability indicators, such as posterior divergence, feature consistency, and confidence variation, which are linearly combined via a lightweight logistic model to yield a unified uncertainty signal. This signal is adaptively calibrated online through a memory-constant quantile tracker and paired with a budget-aware abstention controller to support label-free risk management during deployment."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The strengths of this paper are:\n- The problem statement is relevant and important. Deployment scenarios like phones and drones are always in fashion and makes this paper relevant.\n- Experiments on both large and small microcontrollers are a good touch."}, "weaknesses": {"value": "The weaknesses of this paper are:\n- The conformal quantile is spoken about at a high-level but how it is actually calculated and why they use this over other methods is never mentioned. In all, the methodology as a whole is a little incomplete and reads like high-level ideas instead of an actual methodological framework includes full details and technical justification.\n- The empirical evaluate seems incomplete at times also. The authors compare against standard UQ methods in the TinyML setting but don't compare against many TinyML methods that comprise the SOTA. This is poor in my opinion and makes the experiments seem cherry-picked. Methods in the literature that come to mind are: QUTE, single-shot MC-D, Evidential DL for TinyML. Actually in QUTE show similar experiments to this paper, and by review of both results alone, QUTE could be extremely competetite with TCUQ and in some cases beat it.\n- Do conformal guarantees still stick in this method/setting?"}, "questions": {"value": "- Why were certain SOTA methods excluded from comparison?\n- What exact algorithm is used for the online quantile tracker? How is it implemented and why this?\n- The paper claims “label-free” operation, but the logistic combiner is trained offline. Were labels used there, and how sensitive is performance to domain shift between training and deployment?\n- Does the streaming quantile maintain calibration under distribution drift, or does it require periodic resetting/warm-up?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zaPGCvxQSb", "forum": "7Rfyx8EZea", "replyto": "7Rfyx8EZea", "signatures": ["ICLR.cc/2026/Conference/Submission283/Reviewer_rvgd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission283/Reviewer_rvgd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760864904370, "cdate": 1760864904370, "tmdate": 1762915485239, "mdate": 1762915485239, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "kDS6YmAXlV", "forum": "7Rfyx8EZea", "replyto": "7Rfyx8EZea", "signatures": ["ICLR.cc/2026/Conference/Submission283/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission283/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763133832208, "cdate": 1763133832208, "tmdate": 1763133832208, "mdate": 1763133832208, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes TCUQ, a computationally efficient method in terms of inference speed and hardware requirements, that performs well on OOD detection. TCUQ extracts four features, including predictive divergence, feature stability, decision persistence, and a confidence proxy, then merges them into a single uncertainty score in a single forward pass. In addition, a conformal layer is added on top of this framework to obtain a budgeted accept/abstain rule. Empirical results show TCUQ outperforms early exit and Deep Ensembles in computational efficiency, while improving OOD detection task with AUPRC and AUROC under distribution shifts."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper is generally well-written and is clear to understand the important aspects.\n- I like the motivation of TCUQ, as literature in uncertainty and robustness suffers a trade-off between performance and computational efficiency (e.g., Ensembles, Bayesian-Net, etc.). TCUQ aims to minimize this trade-off, and may be helpful for safety & real-time applications with low-resource devices."}, "weaknesses": {"value": "- From a novelty perspective, I feel the proposed method is not really novel as TCUQ simply merges four existing temporal signals, then applies a conformal layer on top of the framework. \n- There is no theoretical guarantee to formally explain why TCUQ can improve safety performance. This limits the paper's contribution and limits the understanding of TCUQ from a theoretical perspective.\n- TCUQ does not consistently outperform other baselines in safety performance (e.g., Ensembles in Tab.2 with OOD detection, many other baselines in Tab.8 in ECE, etc.).\n- Lack of some important baselines that balance safety and computational efficiency (e.g., BatchEnsemble [1], Rank1-BNN [2], etc.). Note that I still appreciate TCUQ's improvement in computational efficiency, but its safety performance (i.e., accuracy, ECE, OOD detection under distribution shifts) may be worse than the mentioned baselines. My suggestion is that the authors may plot a 2D scatter figure, where the x-axis represents the safety performance (e.g., OOD detection), and the y-axis represents the computational efficiency (e.g., latency), to easier to analyze in the revised version.\n- Although the empirical results are somewhat extensive, many main figures are reported without error bars, raising a concern about the robustness of TCUQ methods."}, "questions": {"value": "1. Do the Ensembles in the experiments use a post-hoc recalibration? I think one limitation of TCUQ, when compared to Ensembles, is that TCUQ requires a post-hoc recalibration dataset to train the conformal prediction layer, while Ensembles do not. This may also raise a consideration about a fair comparison in this setting.\n2. Beyond the baselines mentioned in the weakness, have the authors considered comparing with other light-weight OOD detection baselines (e.g., MLR, ReAct, etc. [3])?\n\n---\nReferences:\n\n[1] Wen et al., BatchEnsemble: An Alternative Approach to Efficient Ensemble and Lifelong Learning, ICLR, 2020.\n\n[2] Dusenberry et al., Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors, ICML, 2020.\n\n[3] Yang et al., OpenOOD: Benchmarking Generalized Out-of-Distribution Detection, NeurIPS, 2022."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OWfTuFzIBv", "forum": "7Rfyx8EZea", "replyto": "7Rfyx8EZea", "signatures": ["ICLR.cc/2026/Conference/Submission283/Reviewer_tW5Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission283/Reviewer_tW5Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761246733971, "cdate": 1761246733971, "tmdate": 1762915485030, "mdate": 1762915485030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TCUQ, a single pass label free uncertainty monitoring method for TinyML. The core idea is to take advantage of short horizon temporal consistency of the model outputs and features by considering a small ring buffer of the last $W$ steps and computing four cheap signals that are later merged using a logistic combination approach and pass a combined score through a streaming conformal quantile to get a decision about accepting or abstaining. The authors provide multiple tests on MCUs which show the improved performance in latency, failure detection, uncertainty quantification, and accuracy drop."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Combining short horizon consistency  with a streaming conformal threshold in a design explicitly created for a single pass MCU seems to me clean and practical. Also, the paper explains well why competitive approaches struggle. \n\n- The engineering is well thought out, the method is O(1) per step with O(W(L +d’)) bytes per state, the posteriors are kept in 8-bit, etc, which makes the whole idea actually deployable on kilobyte scale devices. \n\n- The results, reduce latency by 31-43%, shrinked flash by 38-62%, are very good results.\n\n- For accuracy-drop detection TCUQ improves AUPRC and shows earlier warnings reaching up to 0.86 AUPRC at high severity’s in some setting and for failure detection it reaches up to 0.92 AUROC. There are same consistent gains for calibration as well. \n\n- The method is presented in a clear manner."}, "weaknesses": {"value": "- The approach assumed that successive inputs are related but maybe that is not the case or some extreme event happens, like a step function, what happens then? Maybe you could add an example where you inject a random intermediate input to check for degradation and maybe scenarios that TCUQ is not appropriate. \n\n- The logistic combiner is trained of line on a labelled set. This introduces a mismatch risk if deployment shifts differ from training shifts. Maybe you include an example that you exclude test time corruptions from training and report robustness weights."}, "questions": {"value": "- Can you add a tiny Transformer experiment using the same W L, d’ recipe to substantiate the claim of backbone agnostic deployment. I believe that this would be helpful. \n\n- Please check the weaknesses above and reply to the actions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "viojSHQkSh", "forum": "7Rfyx8EZea", "replyto": "7Rfyx8EZea", "signatures": ["ICLR.cc/2026/Conference/Submission283/Reviewer_7kyN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission283/Reviewer_7kyN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761851429615, "cdate": 1761851429615, "tmdate": 1762915484766, "mdate": 1762915484766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes TCUQ, a method for single-pass uncertainty quantification on resource-constrained microcontrollers. The method utilizes temporal consistency from recent model outputs, combined with streaming conformal calibration, to produce a calibrated risk score for accept/abstain decisions, which is relevant for TinyML applications that require on-device monitoring without access to labels or the capacity for multi-pass inference."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important problem in the TinyML domain: reliable uncertainty quantification under strict hardware constraints. The proposed method is designed with these constraints in mind, employing a single forward pass, a small ring buffer, and constant-time updates. The use of temporal information is a practical approach to generating an uncertainty signal without the overhead associated with ensemble methods. The evaluation is a significant component of the work; it is conducted on two different microcontrollers, providing measurements of latency, memory footprint, and energy consumption. The experiments are detailed, covering accuracy-drop detection, failure detection, and model calibration across several vision and audio datasets."}, "weaknesses": {"value": "The performance of the proposed method depends on a set of hyperparameters, including the temporal window size (W), the lag set (L), and blending parameters. While these are tuned on a development set, the paper does not fully explore the sensitivity of the system to these choices, particularly in dynamic environments where stream characteristics may change. The method's foundation is the assumption of temporal consistency in the input stream, which may not hold for all potential TinyML applications. Nevertheless, this compound design lacks comparison with baselines on MCUs [1].\n\n[1] Ghanathe, et al. \"QUTE: Quantifying Uncertainty in TinyML with Early-exit-assisted ensembles for model-monitoring.\" arXiv, 2024."}, "questions": {"value": "What was the procedure for constructing the development set used to fit the logistic combiner, and how does the composition of this set affect the system's performance on data with previously unseen corruptions?\n\nThe temporal assistance mechanism is introduced for training. Were alternative methods, such as specific data augmentation or regularization schemes, investigated to achieve a similar effect on the quality of the temporal signals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oRWTl2O9oS", "forum": "7Rfyx8EZea", "replyto": "7Rfyx8EZea", "signatures": ["ICLR.cc/2026/Conference/Submission283/Reviewer_h7oC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission283/Reviewer_h7oC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948366570, "cdate": 1761948366570, "tmdate": 1762915484505, "mdate": 1762915484505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}