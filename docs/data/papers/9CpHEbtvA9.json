{"id": "9CpHEbtvA9", "number": 2809, "cdate": 1757257289660, "mdate": 1759898126061, "content": {"title": "reAR: Rethinking Visual Autoregressive Models via Token-wise Consistency Regularization", "abstract": "Visual autoregressive (AR) generation offers a promising path toward unifying vision and language models, yet its performance remains suboptimal against diffusion models. Prior work often attributes this gap to tokenizer limitations and rasterization ordering. In this work, we identify a core bottleneck from the perspective of generator-tokenizer inconsistency, i.e., the AR-generated tokens may not be well-decoded by the tokenizer. To address this, we propose reAR, a simple training strategy introducing a token-wise regularization objective: when predicting the next token, the causal transformer is also trained to recover the visual embedding of the current token and predict the embedding of the target token under a noisy context. It requires no changes to the tokenizer, generation order, inference pipeline, or external models. Despite its simplicity, reAR substantially improves performance. On ImageNet, it reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard rasterization-based tokenizer.  When applied to advanced tokenizers, it achieves a gFID of 1.42 with only 177M parameters, matching the performance with larger state-of-the-art diffusion models (675M).", "tldr": "reAR is a simple regularization method that fixes generator-tokenizer inconsistency in visual autoregressive models, greatly improving quality without altering tokenizer or inference pipeline.", "keywords": ["Visual Generation", "Autoregressive Model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/23b978b04f85a3dc86c1861b5486378814f2b557.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes reAR, a new regularization framework designed to improve the generation quality of visual autoregressive (AR) models. The authors argue that existing visual AR methods suffer from a generator–tokenizer inconsistency, which manifests as exposure bias amplification and embedding unawareness during training and inference. reAR introduces two lightweight regularization techniques: Noisy Context Regularization, which injects random noise into the input token sequence to simulate imperfect contexts during training, mitigating exposure bias. Codebook Embedding Regularization, which aligns the generator’s hidden states with the tokenizer’s embedding space through cosine distance loss."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies a genuine and underexplored problem: the misalignment between generator and tokenizer in visual AR models. This perspective is well-motivated and conceptually interesting.\n2. The proposed regularizations are straightforward, computationally light, and compatible with existing AR models and different tokenizers.\n3. The approach yields improvements across multiple tokenizers (e.g., TiTok, AliTok) and model sizes, and narrows the gap with diffusion-based methods."}, "weaknesses": {"value": "1. While the paper frames generator–tokenizer inconsistency as a new perspective, the actual solutions (noise injection and embedding regularization) looks similar to existing techniques in language modeling.\n2. For a method positioned as “plug-and-play” and intended to generalize across tokenizers and datasets, the paper applies the embedding alignment regularization to specific layers but does not provide analysis behind this choice. The decision appears empirical, based on trying a few configurations and selecting the one yielding the best FID.\n3. While reAR demonstrates improvements across different tokenizers (e.g., TiTok, AliTok), the paper does not provide any analysis of how the proposed embedding regularization interacts with the underlying codebook geometry."}, "questions": {"value": "1. How sensitive is reAR to the noise schedule or regularization strength λ across different datasets and architectures?\n2. Since the proposed method involves embedding alignment, how does it interact with tokenizers of different codebook geometries?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JIO4uEbDbN", "forum": "9CpHEbtvA9", "replyto": "9CpHEbtvA9", "signatures": ["ICLR.cc/2026/Conference/Submission2809/Reviewer_RcEf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2809/Reviewer_RcEf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761417924125, "cdate": 1761417924125, "tmdate": 1762916386043, "mdate": 1762916386043, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes the performance bottleneck in visual autoregressive (AR) models, attributing it to \"generator-tokenizer inconsistency.\" To address this, the authors propose reAR, a plug-and-play training regularization strategy. Without altering the model architecture or inference pipeline, reAR introduces two auxiliary objectives: 1) Noisy Context Regularization, which mitigates exposure bias by training the model in corrupted contexts, and 2) Codebook Embedding Regularization, which forces the model's hidden states to predict the visual embeddings of both the current and next tokens, making the generator aware of the tokenizer's embedding space."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. reAR delivers excellent results, significantly improving model performance without requiring architectural changes, and appears to be a general-purpose strategy for vision AR models.\n2. As a training-only strategy, reAR is highly versatile. Experiments show it works well not only with VQGAN but also significantly boosts other tokenizers like TiTok and AliTok.\n3. The paper clearly defines the \"generator-tokenizer inconsistency\" problem. It uses well-designed comparison experiments (e.g., \"perfect context\" vs. \"imperfect context\" and \"error token embedding replacement\") to convincingly validate that \"exposure bias amplification\" and \"embedding-unawareness\" are indeed critical bottlenecks."}, "weaknesses": {"value": "1. reAR requires applying regularization at specific shallow (e.g., layer 0) and deep (e.g., layer 15) layers, chosen based on CKA analysis and ablations. This feels somewhat like \"alchemy\" or fine-tuning, lacking an adaptive or theoretically-driven mechanism to automatically determine the optimal layers for feature alignment.\n2. The method introduces additional MLP projection layers and an extra loss term, which inevitably increases training complexity and memory consumption. The paper doesn't explicitly quantify the additional training time overhead introduced by the reAR strategy."}, "questions": {"value": "1. reAR innovatively regularizes both the \"current token\" embedding (shallow layers) and the \"next token\" embedding (deep layers). Is there a potential conflict between these two objectives? (e.g., could the shallow layers lose information needed to predict the *next* token in their effort to align with the *current* token?).\n2. Could you provide an ablation study showing that only regularizing the \"next\" token's embedding (which seems like the more direct objective) performs worse than regularizing both?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1VpwEhhup5", "forum": "9CpHEbtvA9", "replyto": "9CpHEbtvA9", "signatures": ["ICLR.cc/2026/Conference/Submission2809/Reviewer_n9Nt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2809/Reviewer_n9Nt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761710528928, "cdate": 1761710528928, "tmdate": 1762916385863, "mdate": 1762916385863, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work identifies a key bottleneck in visual autoregressive generation—the mismatch between the generator’s token sequences and how the tokenizer decodes them. The authors propose a plug‑and‑play regularization strategy that forces the autoregressive model to align its hidden representations with the tokenizer’s codebook embeddings and to remain robust under noisy contexts. This approach requires no changes to the tokenizer, inference pipeline or generation order, yet yields substantial gains. The method is validated across different tokenizers, showing that improving generator ‑ tokenizer consistency significantly boosts AR image generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper clearly identifies a fundamental issue in visual autoregressive models — the inconsistency between the generator and tokenizer — and presents a well-motivated solution.\n\n2. The proposed generator–tokenizer consistency regularization is simple, plug-and-play, and does not require changes to the tokenizer, inference pipeline, or generation order, making it broadly applicable.\n\n3. Extensive experiments demonstrate that reAR significantly enhances class-conditional image generation, yielding notable improvements in FID on ImageNet."}, "weaknesses": {"value": "1. The paper does not report the impact of REAR on downstream multimodal understanding tasks or text-to-image generation benchmarks, leaving the broader utility of the method unclear.\n\n2. While the method improves generation quality, the novelty is somewhat limited, as the approach mainly introduces a regularization term rather than a fundamentally new architecture.\n\n3. The study only investigates reAR’s generalization across different VQ tokenizers, but does not examine its effectiveness when applied to different LLM backbones; additionally, the number of VQ tokenizers included in the experiments is limited."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rojR59s3Bi", "forum": "9CpHEbtvA9", "replyto": "9CpHEbtvA9", "signatures": ["ICLR.cc/2026/Conference/Submission2809/Reviewer_Xk7f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2809/Reviewer_Xk7f"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981184133, "cdate": 1761981184133, "tmdate": 1762916385394, "mdate": 1762916385394, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tries to improve (traditional, raster-order) autoregressive image generation.\n\nProblem statement: inconsistency between a generator and a tokenizer, i.e., the autoregressive model might generate a token sequence that is hard for the tokenizer to decode back to an image.\n\nLogical development\n* The generated token sequence can be unseen by the tokenizer due to exposure bias between training (teacher forcing) and inference (own predictions). It is more problematic in image models than language models because the possibility of the decoder not seeing the combination of generated visual tokens in the training phase.\n* AR models produce token indices and do not care the embeddings produced by the tokenizer.\n\n\nSolutions\n* Expose the model to perturbed context during training.\n    * (context = previous tokens)\n    * It encourages the model not to rely on clean contexts and improves robustness to imperfect histories at inference.\n* Align the generator's hidden states with the tokenizer's embedding space.\n    * It helps the visual embeddings being reconstructed from the unseen tokens.\n    * Method: SimSiam-like architecture and loss for regressing current embedding and next embedding.\n\nExperiments\n* Competitors: many.\n* ImageNet\n* FID 1.42 with 177M parameters (sota diffusion models = 675M)"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Originality:\n1. The idea of aligning the embeddings of the generator and the tokenizer is original.\n2. Please see weakness 1.\n\nQuality:\n1. The experiments thoroughly compare many competitors in Table 1.\n2. Please see weakness 2. \n3. Ablation study is thorough.\n\nClarity:\n1. The problem statement, logical development, solution, and empirical supports are clear as described in Summary.\n2. Please see weakness 3.\n\nSignificance:\n1. The inconsistency between the embeddings of generator and tokenizer and its solution are important because they are the fundamental components of AR models."}, "weaknesses": {"value": "1. Perturbing something is a common practice for robustness. Why is the proposed perturbation non-obvious compared to the literature?\n2. Experiments are conducted only on ImageNet.\n3. The scope should be specified in more detail such as raster-order autoregressive modeling because the paper does not tackle other autoregressive models such as [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction].\n\nminor\n\n1. The term \"context\" should be defined. It is okay-ish to be implied from context (lol) but it can be clearer."}, "questions": {"value": "1. Figure 1 should be explained in more detail. What is wrong in the image of orange cat? Why are the top and bottom images similar although the token indices are different?\n2. Resolving weakness 1 will raise my rating regarding originality.\n3. Resolving weakness 2 will raise my rating regarding soundness.\n4. Resolving weakness 3 will raise my rating regarding clarity. If the proposed method is applicable to VAR, please help me find the statement in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "05Il9DDmTl", "forum": "9CpHEbtvA9", "replyto": "9CpHEbtvA9", "signatures": ["ICLR.cc/2026/Conference/Submission2809/Reviewer_YZ8R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2809/Reviewer_YZ8R"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145701609, "cdate": 1762145701609, "tmdate": 1762916385230, "mdate": 1762916385230, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}