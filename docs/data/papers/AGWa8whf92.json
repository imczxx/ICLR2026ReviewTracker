{"id": "AGWa8whf92", "number": 7970, "cdate": 1758046771134, "mdate": 1763639776080, "content": {"title": "Beyond Linear Probes: Dynamic Safety Monitoring for Language Models", "abstract": "Monitoring large language models' (LLMs) activations is an effective way to detect harmful requests before they lead to unsafe outputs. However, traditional safety monitors often require the same amount of compute for every query. This creates a trade-off: expensive monitors waste resources on easy inputs, while cheap ones risk missing subtle cases. We argue that safety monitors should be flexible--costs should rise only when inputs are difficult to assess, or when more compute is available. To achieve this, we introduce Truncated Polynomial Classifiers (TPCs), a natural extension of linear probes for dynamic activation monitoring. Our key insight is that polynomials can be trained and evaluated progressively, term-by-term. At test-time, one can early-stop for lightweight monitoring, or use more terms for stronger guardrails when needed. TPCs provide two modes of use. First, as a safety dial: by evaluating more terms, developers and regulators can \"buy\" stronger guardrails from the same model. Second, as an adaptive cascade: clear cases exit early after low-order checks, and higher-order guardrails are evaluated only for ambiguous inputs, reducing overall monitoring costs. On two large-scale safety datasets (WildGuardMix and BeaverTails), for 4 models with up to 30B parameters, we show that  TPCs compete with or outperform MLP-based probe baselines of the same size,  all the while being more interpretable than their black-box counterparts. Our anonymous code is available at https://anonymous.4open.science/r/tpc-anon-0708.", "tldr": "Polynomial classifiers give adaptive, interpretable safety guardrails for language models.", "keywords": ["Safety monitoring", "Polynomial classifiers", "Interpretability"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bb789dd0a985aca57bbf1756a421f3ee5103a328.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposed a new dynamic safety monitoring methodology that balances the tradeoff of classification accuracy and compute cost. Instead of using a linear probe, the authors creatively use polynomial classifiers with progressive learning and early stop methodologies, achieving up to 10% improvement in accuracy over linear probes and up to 6% over MLP baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The concept of dynamic safety monitoring with polynomial classifiers is novel. I like the idea of progressive training, early stopping, as well as symmetric CP factorization in order to keep the model weights growing linearly. All these ideas and optimization strategies provide a practical and realistic solution to safety monitoring during the deployment time\n2. The experiment is comprehensive. The author did a comprehensive study on various checkpoints with different sizes, training stages, and reasoning capabilities. The author also compared the polynomial probe with 5 baseline methods, and repeated each experiment 5 times with different random seeds.\n3. The writing is good. All the terminologies are clearly defined, and the plots are clear and easy to understand."}, "weaknesses": {"value": "1. The improvement of TPC seems to be marginal. The author claimed that it can have up to 6% of the improvements compared with the MLP baselines. However, I have no idea if the observation holds for all layers in the model. Theoretically, a fair comparison should be: for each method, we identify the layer that has the best accuracy in the validation set, then test its accuracy on the test set. In this case, we should compare the performance of the TPC and MLP baseline on their corresponding \"best\" layer, instead of the same layer. According to Figure 6, I found that in some cases, MLP baselines have a comparable performance to the TPC. Note that, for MLP, we can still have the early stop strategy to dynamically control the compute cost. In this case, the key issue falls on the fitting function selection, and I think the author should elaborate more on this."}, "questions": {"value": "1. In Figure 3, how do we determine the number of parameters used in TPC? IIRC the number of parameters required by TPC is dynamic and depends on the inputs?\n2. How does the layer id get selected? Do we have to do a layer-wise sweep in order to get the layer with the best performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FqwAdx1t9S", "forum": "AGWa8whf92", "replyto": "AGWa8whf92", "signatures": ["ICLR.cc/2026/Conference/Submission7970/Reviewer_Hn5t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7970/Reviewer_Hn5t"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7970/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761339699492, "cdate": 1761339699492, "tmdate": 1762919982657, "mdate": 1762919982657, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This article introduces the Truncuated Polynomial Classifier (TPC), which serves as a lightweight and adaptable monitoring tool. TPC builds on N-degree polynomials, making it more expressive than simple linear probes applied to activations of LLMs. The authors additionally propose a cascading defense by training TPC in a progressive manner, which allows for the usage of $n<N$ polynomial terms for the classification. After this training, the end user can keep adding polynomial terms until the prediction is confident enough (decided by a threshold $\\sigma(y)\\in(\\tau, 1-\\tau)$. Additionally, to address the issue of the exponential growth of parameters when using higher-order polynomials, the authors propose parametrizing the higher-order polynomial terms through a symmetric CP factorization. To evaluate how well the TPC performs, authors have utilized 2 datasets, WildGuard and BeaverTails, both containing safe and unsafe examples. TPC is trained on both of those datasets on top of 4 models: gemma-3-27b-it, Qwen3-30B-A3B-Base, llama-3.2-3B, and gpt-oss-20b. The authors compare their method to other probing methods, MLPs, and early exit MLPs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The TPC is an original idea that is well motivated by the theoretical background of polynomial networks. The authors have conducted experiments on the BeaverTails and WildGuardMix datasets for training and evaluation. WildGuardMix is a highly difficult dataset even for Guard-like models, highlighting the utility of TPC. On top of that, authors have compared the performance of TPC on 4 models differing in size and kind. The authors have performed an in-depth analysis of Cascading defense, highlighting how it influences the model performance compared to training a full polynomial. These results highlight the advantage of TPC over EE-MLP. The analysis in Figure 3(b) shows the exit degree of TPC, which proves that using this cascading defense can lead to significantly smaller computations compared to the full polynomial. I find this article as an important step towards developing more robust latent-based monitors for LLMs, which could serve as an additional defense during development."}, "weaknesses": {"value": "* Presenting most results in the form of plots, while visually appealing, makes it harder to analyse, and I think that adding a table with the main results would be beneficial for the clarity of this work. \n* For each of the models, the authors have only used 2 layers. I would like to see an ablation for at least one model on how the TPC performs depending on the layer used. I don’t think that all layers have to be checked, but more would be of high benefit for this work. \n* In Figure 6, we can observe that for some layers, using higher-order polynomials is worse in terms of test performance. \n* I suggest that the authors provide additional information regarding the model used in figures when it’s not obvious from the legends, etc., e.g., Figures 3 and 4. \n* The usage of only 1 model from each family doesn’t allow us to fully understand the scaling of TPC. It would be beneficial to analyze how TPC scales with model sizes for at least one family (e.g., use TPC on top of Llama 3.2 1B, 3B, and Llama 3.3 8B). \n* The authors have also trained the TPC on the same dataset that it is evaluated and it would be beneficial to analyze the generalization of TPC to new data. \n* In Figure 3(a) x-axes have a different scales."}, "questions": {"value": "* As we can observe in Figures 6, 10, and 11, for some examples usage of higher order polynomials decreases the TPC performance. Have the authors tried to find a solution for this problem, or have any experiments regarding this problem?\n* Can the authors show how high of FRR this method would achieve on benign prompts from different datasets? I'm interested in the generalization of TPC by looking at the difference in val and test set performance for some layer and model combinations.\n* Can the authors provide an ablation of TPC performance dependent on the layer number?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6DX64StSvu", "forum": "AGWa8whf92", "replyto": "AGWa8whf92", "signatures": ["ICLR.cc/2026/Conference/Submission7970/Reviewer_1PvY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7970/Reviewer_1PvY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7970/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815419890, "cdate": 1761815419890, "tmdate": 1762919982159, "mdate": 1762919982159, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework called Truncated Polynomial Classifier (TPC), which extends traditional linear probing by incorporating quadratic and higher-order interactions among neuron activations to assess the harmfulness of a given query.\n\nThe key advantage of this framework lies in its ability to scale computation dynamically at test time, similar to test-time scaling in reasoning tasks. Specifically, it allows the safety monitor to allocate more computational budget to evaluate complex queries using higher-order terms while keeping lightweight computation for easier cases.\n\nEmpirically, the method achieves consistent improvements in F1 score over previous probing-based approaches on the WildGuardMix and BeaverTails datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces a novel idea of applying test-time scaling to activation-based safety monitoring for LLMs. To the best of my knowledge, this is the first work to apply a polynomial-based approach to safety probing.\n- The experimental results are solid and clearly demonstrate the effectiveness of the proposed method compared to existing baselines.\n- The presentation is clear, and the paper is well-written, making it easy to follow the motivation, methodology, and results."}, "weaknesses": {"value": "- The paper lacks comparison to external guard models (e.g., LLM-based safety classifiers such as Llama Guard or GPT-based judges). While such models are indeed computationally heavier, safety is often a domain where additional cost is justified. Therefore, discussing or quantifying the performance gap between TPC and these more comprehensive safety systems would strengthen the paper’s practical relevance.\n- Although the current experiments on WildGuardMix and BeaverTails provide reasonable validation, the safety domain demands more comprehensive evaluation. Considering the high importance of robustness in safety monitoring, it would be valuable to assess the proposed method on a wider range of safety datasets (e.g., [1], [2], [3]) to verify its generality and reliability across diverse threat scenarios.\n\n[1] Markov et al., A holistic approach to undesired content detection in the real world\n\n[2] Mazeika et al., Harmbench: A standardized evaluation framework for automated red teaming and robust refusal\n\n[3] Lin et al., ToxicChat: Unveiling hidden challenges of toxicity detection in real-world user-AI conversation"}, "questions": {"value": "- What was the criterion for selecting the specific LLMs for evaluation? For example, why was the instruction-tuned version of Qwen3-30B-A3B-Base not included in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "tCFzlMQ9l7", "forum": "AGWa8whf92", "replyto": "AGWa8whf92", "signatures": ["ICLR.cc/2026/Conference/Submission7970/Reviewer_9co4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7970/Reviewer_9co4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7970/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926842933, "cdate": 1761926842933, "tmdate": 1762919981648, "mdate": 1762919981648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Rebuttal summary"}, "comment": {"value": "We thank the reviewers for their thoughtful and constructive feedback. We are grateful that **all three reviewers highlight the novelty of the method and strength of the experimental results**.\n\nWe summarize here the **four new experimental results/comparisons** included in the revised manuscript in response to the reviewers:\n\n- **Initial comparisons to LLM-as-monitors** (**Appendix F.3**): `gpt-4o-mini`, `claude-3-haiku`, and `o3-mini`. We find that TPCs (on the same layer 40 of gemma-3-27b-it) outperform or compete with these models on the WildGuard test set, whilst having significantly fewer parameters.\n- **Cross-dataset evaluation** (**Appendix F.2**): We evaluate TPCs (trained on WildGuard's training set) on three requested external datasets: ToxicChat, HarmBench, and OpenAI-Moderation. Results demonstrate that the TPC model of the main paper generalizes effectively to these test sets.\n- **Family layer sweeps** (**Appendix F.4**): We perform full sweeps across **six** layers for the full `Llama-3.2` family as requested by **Reviewer-1PvY**, confirming reasonable performance across models and extra evidence of best performance being localized to middle / middle-late layers.\n- **Table of static results** (**Table 1**): As requested by **Reviewer-Hn5t** for additional clarity, we have added Table 1 to the main paper summarizing 'best layer' performance with static evaluation of models, complementing the dynamic performance captured in the existing line graphs.\n\nPlease find all additions/updates to the PDF in **green font**. In addition to making clarifications based on the reviews, we note we have updated the manuscript to include an expanded discussion of related work on cascades and ensembles. We also include new discussion throughout on recent related works combining probes with LLM-as-monitors.\n\nWe hope that the new experiments and updates to the manuscript satisfies the reviewers that there is value in this work appearing at ICLR this year."}}, "id": "ROxMluzKb7", "forum": "AGWa8whf92", "replyto": "AGWa8whf92", "signatures": ["ICLR.cc/2026/Conference/Submission7970/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7970/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission7970/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763640945469, "cdate": 1763640945469, "tmdate": 1763640945469, "mdate": 1763640945469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}