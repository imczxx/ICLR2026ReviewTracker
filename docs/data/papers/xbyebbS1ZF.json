{"id": "xbyebbS1ZF", "number": 16835, "cdate": 1758269231729, "mdate": 1759897216643, "content": {"title": "Online Algorithm Configuration for MILP Re-Optimization with LLM Guidance", "abstract": "In this work, we study the re-optimization setting for mixed-integer linear programs, where solving sequentially related instances can benefit from both adaptive solver parameter configuration and the reuse of historical information from previous solves. However, modern solvers expose hundreds of tunable parameters, yielding a large configuration space; and the effectiveness of re-optimization techniques (e.g., warm starts or branching statistics) varies substantially across problem families. To address these challenges, we formulate a generalized algorithm configuration problem that jointly determines solver built-in parameters and the selective use of historical information within a reduced configuration space. Given the sequential nature of re-optimization and the limited number of available instances, offline methods that require large datasets are impractical, so adaptive online configuration selection becomes essential. We therefore propose a two-stage framework: (i) configuration space reduction via large language models, which generate a compact portfolio of candidate configurations; and (ii) adaptive online selection using multi-armed bandit algorithms to minimize solving cost over the sequence. Empirical results on the MIP Workshop 2023 re-optimization benchmarks demonstrate that our method substantially outperforms default SCIP and Gurobi configurations as well as strong baselines, achieving solving time reductions of up to 54.18%, without requiring prior validation data or supervised training.", "tldr": "", "keywords": ["MILP re-optimization; sequential instances; algorithm configuration; large language models; multi-armed bandits"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/906b9df3893e8d389a39fd8c4938a866f2b77ab7.pdf", "supplementary_material": "/attachment/72ae811637ea618fb052437662cba4895d853945.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a two-stage framework for algorithm configuration in the context of MILP re-optimization. The method first leverages LLMs to generate a compact portfolio of candidate configurations, reducing a combinatorially large search space. It then employs a Multi-Armed Bandit algorithm for online adaptive selection from this portfolio across a sequence of related problem instances. The empirical evaluation on established benchmarks demonstrates performance improvements over default solver settings and strong baselines, achieving up to a 54.18% reduction in solving time without requiring offline training data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The integration of LLMs for zero-shot algorithm configuration space reduction is highly innovative and represents a promising new direction for automating solver tuning.\n\n2. The paper effectively formulates the re-optimization problem as a joint configuration of both built-in solver parameters and re-optimization techniques (like primal hints), which is a more holistic approach than tuning parameters in isolation."}, "weaknesses": {"value": "1. The method heavily relies on the zero-shot capability of LLMs to generate high-quality configurations. While over-generation and clustering mitigate this, there is no theoretical foundation or guarantee for the performance or consistency of the LLM-generated portfolio. The approach is sensitive to prompt design, yet the paper lacks a systematic analysis of prompt robustness or variability.\n\n2. The configuration space is restricted primarily to cutting-plane parameters and the primal hint mechanism, as shown in Tables 6 and 7. This overlooks other critical solver components such as branching rules, heuristics, and conflict analysis, which are known to have a profound impact on solver performance. This limitation may prevent the framework from achieving its full potential, especially on complex instances where a more holistic configuration is required.\n\n3. The exploration coefficient (α) in the UCB algorithm is a critical hyperparameter that requires manual setting. The paper fixes α=1 based on sensitivity analysis but does not propose or implement an adaptive mechanism to adjust it during the online process.\n\n4. The primary evaluation metric is solving time. While important, this does not provide a complete picture. Other crucial metrics like the primal-dual integral or optimality gap are not reported, which could reveal different performance characteristics, especially for instances not solved to optimality. Furthermore, even with an extended time limit of 600 seconds, the improvement on the most challenging dataset (`rhs_obj`) is minimal (0.25%), suggesting the method's effectiveness may be limited for particularly difficult re-optimization problems.\n\n5. Generating 100 configurations via an LLM (e.g., using a commercial API) and performing clustering for each problem series incurs significant computational and potential financial cost.\n\n6. The paper does not provide an analysis or theoretical insight into *how* or *why* the LLM arrives at certain configurations from the problem description."}, "questions": {"value": "1. Have you conducted any analysis on the robustness of your method to variations in the LLM prompt?\n\n2. What was the rationale behind limiting the configuration space to cutting planes and primal hints?\n\n3. Could you comment on the performance in terms of optimality gaps for instances that hit the time limit? Would including metrics like the primal-dual integral change the relative ranking of the methods?\n\n4. How significant is the computational overhead of the LLM generation and clustering phase compared to the total solving time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dRCh8Ib1WR", "forum": "xbyebbS1ZF", "replyto": "xbyebbS1ZF", "signatures": ["ICLR.cc/2026/Conference/Submission16835/Reviewer_joEs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16835/Reviewer_joEs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761542595445, "cdate": 1761542595445, "tmdate": 1762926860017, "mdate": 1762926860017, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the \"re-optimization\" setting for solving mixed-integer linear programs (MILP). The basic idea is that there is a sequence of problems with identical sizes/structures, but different coefficients/internal properties. The parameters of the MILP should be adjusted for each instance that is solved to minimize the runtime needed to solve the instance. Experiments are conducted along the lines of the MIP re-optimization challenge that was recently conducted."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The topic is simultaneously highly relevant for industry applications and methodologically interesting. \n2. The MIP workshop creates a relatively good setting for testing out the proposed approach."}, "weaknesses": {"value": "1. The paper ignores the algorithm configuration literature and proposes an LLM-based method without ever examining whether this is a good idea. There are many techniques already available for online algorithm configuration, see the survey by Schede et al. (2022) in JAIR. There is also work on AC landscapes, particularly on analyzing the parameters, see, e.g., Pushak and Hoos (2018) in PPSN. Simply put, the value add of the LLM is not investigated over existing techniques. And, intuitively, I have no idea why an LLM should be able to determine from analyzing descriptions of parameters which parameters are important or are not. This determination should be made through an analysis of algorithm performance.\n2. The paper investigates a restricted re-optimization setting. I ask the authors to correct me if I am wrong, but the basic assumption here seems to be that A, c, and b do not change in size between problems. Under this assumption, we cannot even add an extra customer to a routing problem when resolving, which severely limits the applicability of the problem setting.\n\nLet me note that I consider these such fatal flaws in the work that I did not read the rest in detail.\n\nI also note that I found the MILP formulation in (1) odd: it is correct, but I wonder why standard form is insufficient?"}, "questions": {"value": "1. Why use an LLM rather than existing statistical methods to determine important parameters?\n2. Why use an LLM at all in this AC process? What benefit does it provide?\n3. Why are existing AC methods ignored?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JV05JAwt3c", "forum": "xbyebbS1ZF", "replyto": "xbyebbS1ZF", "signatures": ["ICLR.cc/2026/Conference/Submission16835/Reviewer_SNKv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16835/Reviewer_SNKv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761562022345, "cdate": 1761562022345, "tmdate": 1762926858822, "mdate": 1762926858822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses MILP re-optimization by proposing a two-stage framework: first using LLMs to generate a reduced set of solver parameter configurations, then applying multi-armed bandit algorithms to adaptively select among these configurations online. The authors evaluate their method on 10 benchmark series from the MIP Workshop 2023, each containing 50 sequential instances with varying components (objective coefficients, constraints, bounds, etc.). The experimental results show solving time improvements ranging from 1-54% compared to default SCIP and Gurobi configurations, with stronger gains on harder instances. The method combines both built-in solver parameters (primarily cutting plane controls) and re-optimization mechanisms (warm starts) in a unified configuration space. The ablation studies indicate that both the general parameter tuning beyond just separators and the online MAB selection contribute to performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The progression from problem formulation to methodology to experiments follows a natural structure, making it easy to understand the authors' approach and contributions.\n2. Unlike many algorithm configuration methods that need extensive validation sets or supervised learning, this approach works directly on the sequential instances without requiring additional data, making it more applicable to real-world re-optimization scenarios where instances are limited.\n3. The framework successfully works with both SCIP and Gurobi solvers despite their different parameter spaces and internal architectures, suggesting the approach can generalize across various commercial and open-source MILP solver implementations."}, "weaknesses": {"value": "First, the methodology pipeline lacks great novelty - using LLMs for configuration space reduction involves only straightforward prompting without any sophisticated techniques, and the paper fails to compare against other configuration reduction methods like heuristic-based space reduction methods that could serve as baselines (Li et al., 2023 on separator configuration). Additionally, using MAB for online configuration selection has been explored before (as acknowledged by their comparison with Patel 2024b), making the overall pipeline appear incremental rather than innovative.\n\nSecond, the experimental evaluation is limited to only 10 problem series from a single benchmark suite, with some series differing only in which components vary (e.g., bnd_2 vs bnd_3, rhs_2 vs rhs_4). The solving times are relatively small even for \"hard\" instances (many under 400 seconds), and the paper acknowledges that several instances couldn't reach optimality within the time limit, raising questions about whether these benchmarks adequately represent real-world MILP re-optimization challenges that practitioners face.\n\nThird, the performance improvements over strong baselines are often marginal - while the paper claims up to 54% improvement, the comparison with LLM-coldstart (which simply selects one configuration without any online adaptation) shows differences of less than 2% on many benchmarks, and on some datasets like rhs_2, LLM-coldstart actually outperforms the proposed LLM-MAB method. This suggests the benefit of the bandit-based online selection component may not justify its additional complexity."}, "questions": {"value": "Besides the concerns in the weakness part, I also have the following questions:\n\n1. The authors use MAB without contextual information, but in the evaluation stage, the problem is changing and why MAB is still valid for usage? Contextual bandit that incorporates instance features (problem size changes, which components are varying, magnitude of changes) would be more theoretically sound for this non-stationary environment where configuration effectiveness depends on the current instance properties."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tZfbERkxJ7", "forum": "xbyebbS1ZF", "replyto": "xbyebbS1ZF", "signatures": ["ICLR.cc/2026/Conference/Submission16835/Reviewer_2hya"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16835/Reviewer_2hya"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757248727, "cdate": 1761757248727, "tmdate": 1762926858357, "mdate": 1762926858357, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper observes that near-optimal solver parameters tend to be similar across different instances in MILP reoptimization, while traditional learning-based methods require a large amount of training data and cannot perform online algorithm configuration. The paper proposes using an LLM combined with the Multi-Armed Bandit UCB algorithm to automatically perform online algorithm configuration."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper defines a MILP reoptimization problem that has practical relevance.\n2. The proposed LLM-MAB framework performs strongly on the MILP reoptimization benchmark, outperforming the baselines."}, "weaknesses": {"value": "1. By ICLR standards, the paper lacks sufficient technical novelty. The MILP reoptimization problem is valuable, but the proposed LLM-MAB approach appears to be a straightforward combination of existing components.\n2. In the Multi-Armed Bandit section (Section 4.2), the paper does not justify the choice of the UCB algorithm and should consider comparisons with other MAB algorithms."}, "questions": {"value": "1. As an online reoptimization algorithm for a set of MILP problems, I suggest the authors compare LLM-MAB with a Bayesian optimization approach over hyperparameters, where the optimization objective is to minimize the solving time.\n2. The performance of this method could be heavily influenced by the initial parameter configurations provided by the LLM. Therefore, the authors should investigate how well the LLM generates these configurations for different MILP problems. Does the LLM generally provide good candidate configurations? How much do these candidate configurations vary across problems? How does using different LLMs affect these results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XjXshbli6T", "forum": "xbyebbS1ZF", "replyto": "xbyebbS1ZF", "signatures": ["ICLR.cc/2026/Conference/Submission16835/Reviewer_S2sH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16835/Reviewer_S2sH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989295917, "cdate": 1761989295917, "tmdate": 1762926857990, "mdate": 1762926857990, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}