{"id": "msBSL6JnkZ", "number": 14846, "cdate": 1758244654221, "mdate": 1759897345777, "content": {"title": "Federated Unlearning with Gradient Shielding", "abstract": "Federated unlearning enables the removal of a specific client's data contribution from a trained federated model, thereby avoiding the substantial computational cost of complete retraining. However, existing methods suffer from high memory overhead, training instability, and performance degradation on remaining clients, particularly in non-IID settings. These challenges arise from fundamental issues including gradient explosion and the conflict between forgetting and retaining gradients. To address these limitations, we propose Federated Unlearning with GrAdient Shielding (FUGAS), which integrates a novel forgetting loss with a flexible gradient projection to achieve efficient unlearning while preserving model utility, all without storing extensive historical information. Specifically, we formulate unlearning as a preference optimization problem. The model's original predictions on the data to be forgotten serve as a negative reference, and our objective function encourages the model's current outputs to diverge from this reference, effectively erasing the targeted knowledge. Concurrently, during the server aggregation phase, gradients from unlearning clients are projected onto a dynamically estimated compatibility subspace derived from the gradients of retained clients, which ensures directional coherence and mitigates destructive interference between competing updates. Furthermore, we provide theoretical guarantees that our novel forgetting loss prevent gradient explosion, and that the projection ensures a non-increase in risk on the retained tasks. Extensive experiments demonstrate that FUGAS not only achieves thorough unlearning but also consistently maintains or even improves the model's accuracy on retained data.", "tldr": "", "keywords": ["Federated Learning", "Federated Unlearning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2fbc9ccac4d6da4cbc9ea1d4c1b9e43e94431a6b.pdf", "supplementary_material": "/attachment/433d07aa68c80a7e54c682684a5fa14e87b0394c.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a novel and well-designed framework, Federated Unlearning with GrAdient Shielding (FUGAS), to address critical challenges in federated unlearning. The core contributions—a bounded forgetting loss based on preference optimization and a flexible gradient projection mechanism—are innovative and effectively tackle the fundamental problems of gradient explosion and conflicting updates between forgetting and retaining clients. The methodology is sound and clearly articulated. The experimental evaluation is exceptionally thorough, covering diverse non-IID settings, strong baselines, and a comprehensive set of metrics including accuracy, attack success rate (ASR), and membership inference attacks (MIA). The results strongly support the paper's claims, demonstrating that FUGAS achieves a superior balance between effective unlearning and utility preservation for remaining clients, without the high memory overhead of previous methods. Overall, this is a high-quality paper that makes a significant and practical contribution to the federated learning community and is well-suited for publication."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposed FUGAS framework is innovative, particularly its use of a preference optimization-based objective for a bounded unlearning loss. This is an elegant solution to the gradient explosion problem that plagues methods based on simple loss maximization.\nThe method is memory-efficient as it does not require storing historical client updates, which is a major bottleneck for many federated unlearning approaches. This makes the approach highly practical for deployment in large-scale, real-world systems.\nThe paper's claims are well-supported by a combination of theoretical analysis and thorough empirical evaluations. The experiments cover multiple datasets, IID and non-IID settings, and a comprehensive set of metrics, demonstrating a clear and consistent advantage over strong baselines.\n\nThe flexible gradient projection mechanism is a more nuanced approach to mitigating gradient conflicts than prior work that enforces strict orthogonality. By only requiring directional compatibility, it preserves more information from the unlearning update, leading to better model utility as shown in the ablation studies."}, "weaknesses": {"value": "1. The theory lacks formal guarantees on how closely the resulting model approximates the gold-standard retrained model. The paper should be strengthened by adding an analysis that bounds the divergence between the unlearned and retrained models.\n\n2. The theoretical analysis for utility preservation hinges on a strong assumption that the model has already converged for retained clients. The authors should provide an analysis or empirical study on the method's performance when this assumption is violated, which is common in practice.\n\n3. The paper does not analyze the computational scalability of the gradient projection step, which involves solving a constrained optimization problem. An analysis of how the aggregation time scales with the number of retained clients is needed to assess its practicality in large-scale federations.\n\n4. The empirical evaluation is limited to a simple CNN architecture on relatively small-scale image classification datasets. To demonstrate broader applicability, experiments should be extended to more complex models like ResNet and diverse data modalities.\n\n5. The impact of the temperature hyperparameter T in the forgetting loss function is not investigated. A sensitivity analysis should be included to show how T affects the balance between unlearning effectiveness and model utility.\n\n6. The effectiveness of the proposed method relies on the quality of the pre-unlearning model's predictions, which may be poorly calibrated. The analysis would be more convincing with a discussion on how the initial model's performance on the forget set impacts the unlearning process.\n\n7. The experimental results for non-IID settings, while strong, could be further challenged with more extreme data heterogeneity. The paper should consider evaluating under more severe non-IID partitions to better test the robustness of the gradient shielding mechanism."}, "questions": {"value": "1. Regarding the theoretical contribution, could the authors provide any analysis that bounds the divergence between the model produced by FUGAS and a model retrained from scratch? This would help in formally quantifying how closely your approximation approaches the gold standard.\n\n2. Proposition 2 relies on Assumption 2, which states the model is near-optimal for retained clients before unlearning begins. How does the performance of FUGAS, and the validity of the theoretical guarantee, change in a more practical scenario where the pre-unlearning model is not fully converged?\n\n3. The gradient projection step requires solving a quadratic programming problem on the server. Could the authors provide a complexity analysis for this step, particularly concerning how its computational cost scales with the number of retained clients, which is a key factor for feasibility in large-scale federations?\n\n4. The experiments are conducted on a 4-layer CNN with CIFAR datasets. How do you expect the performance and benefits of FUGAS to translate to more complex and deeper architectures, such as ResNet or Vision Transformers, where gradient dynamics can be more complex?\n\n5. The forgetting loss in Equation 4 introduces a temperature hyperparameter T. Could you comment on the sensitivity of the model's performance to the choice of this hyperparameter and perhaps provide an ablation study showing its effect on the trade-off between unlearning efficacy and retained data accuracy?\n\n6. The unlearning objective uses the model's original predictions on the forgotten data as a negative reference. What would happen if these initial predictions were of low quality or poorly calibrated? Would this negatively impact the stability or effectiveness of the unlearning process?\n\n7. The non-IID experiments use a Dirichlet distribution with α=0.1. How robust is the gradient shielding mechanism to more extreme cases of data heterogeneity, for instance, where clients may only have data from one or two classes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OsYqxLZPBd", "forum": "msBSL6JnkZ", "replyto": "msBSL6JnkZ", "signatures": ["ICLR.cc/2026/Conference/Submission14846/Reviewer_wJMZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14846/Reviewer_wJMZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556781981, "cdate": 1761556781981, "tmdate": 1762925201639, "mdate": 1762925201639, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FUGAS, a method designed to remove the contribution of specific clients in FL while maintaining overall model performance. It introduces a bounded forgetting loss based on preference optimization to prevent gradient explosion and a flexible gradient projection to mitigate conflicts between forgetting and retaining clients. The method aims to achieve efficient, stable, and memory-free unlearning under both IID and non-IID settings.\n\nHowever, this paper is not yet sufficient for publication at ICLR. It is essentially a combination of three existing techniques: modified loss design, gradient preference optimization, and post-training projection (as used in FedOSD). Moreover, the algorithm lacks a theoretical guarantee for complete unlearning. The experiments also suffer from major issues such as imprecise parameter settings, underperforming baselines, and an insufficient number of comparative methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The combination of bounded loss and preference optimization problem offers a theoretically justified way to avoid destructive interference and preserve model utility."}, "weaknesses": {"value": "1. Theoretical limitation in unlearning completeness:\nThe approach does not naturally align with the core requirement of FU, i.e., ensuring complete removal of the target knowledge. The proposed method is essentially a preference-based multi-objective optimization framework, which often converges to a local Pareto front—preventing full unlearning (e.g., achieving ASR ≈ 0). This limitation is theoretically inherent and may occur unintentionally in practice.\n2. Questionable experimental validity:\nThe reported initial accuracies on CIFAR-10 (both IID and non-IID) are unrealistically low, indicating potential implementation or configuration errors. For instance, in the CIFAR-10 Dir(0.1) setting, the initial accuracy should exceed 61%, suggesting inaccuracies that might exaggerate the claimed improvements.\n3. Unfair comparison setup:\nThe unlearning phase uses a fixed learning rate for all methods, which is inappropriate since each algorithm has its own optimal setting. This design choice may lead to biased or unfair comparisons.\n4. Possible suppression of baseline performance:\nThe experimental configuration appears to intentionally or unintentionally weaken baselines such as Gradient Ascent and PGD. With proper learning rate tuning, these methods typically maintain much higher accuracies than the reported ~10%.\n5. Inconsistent results with theoretical claims:\nIn reproduction experiments, FedGAS often fails to reduce ASR to near zero (commonly remaining above 20%), consistent with its tendency to converge to a local optimum. Achieving ASR ≈ 0 requires a substantially larger learning rate, which drastically reduces accuracy—even below that of the baselines—and undermines convergence guarantees. Hence, the proposed method is theoretically and empirically inconsistent.\n6. Incomplete hyperparameter analysis:\nThe paper does not explain the role of the temperature parameter (τ) or analyze its impact on performance. A sensitivity analysis over different τ values should be provided.\n7. Limited baselines:\nThe comparison scope is too narrow, considering only FedOSD as a baseline. More recent and relevant methods such as [1,2] should be included to ensure a fair and comprehensive evaluation.\n   - [1] Zhang J, Zhao M, Wang Z, et al. Model recovery in federated unlearning with restricted server data resources[J]. IEEE Internet of Things Journal, 2025.\n   - [2] Zhou C, Pan C, Li M, et al. Federated Unlearning with Fast Recovery[J]. IEEE Transactions on Mobile Computing, 2025.\n8. Restricted experimental scope and scalability:\nEvaluations are limited to small CNN models and CIFAR datasets, which are insufficient to demonstrate scalability or general applicability in real-world FU scenarios.\n9. Text readability issues:\nThe text in several figures is too small to read clearly, which negatively affects the paper’s presentation quality.\n10. Minor technical and factual issues:\n- Equation (20) should be formulated as a maximization problem.\n- Section 2.2 misrepresents prior work. For example, FedOSD already addresses gradient explosion and conflict issues, contrary to the paper’s claim that it still suffers from them."}, "questions": {"value": "1. Can the above weaknesses be addressed?\n2. Can the method scale to larger models (e.g., ResNet) or more realistic datasets beyond CIFAR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rhY9g07Nhd", "forum": "msBSL6JnkZ", "replyto": "msBSL6JnkZ", "signatures": ["ICLR.cc/2026/Conference/Submission14846/Reviewer_bqb8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14846/Reviewer_bqb8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791538439, "cdate": 1761791538439, "tmdate": 1762925201105, "mdate": 1762925201105, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a novel framework named FUGAS, designed to efficiently eliminate the influence of specific client data while preserving the model utility of the remaining data. Unlike traditional orthogonal projections, the authors propose an approximate projection to resolve gradient conflicts during the unlearning process, which is an interesting idea."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The author effectively integrates research from other fields, offering a fresh perspective for FU.\n2. The author provides a relatively detailed theoretical explanation, which is relatively rare in FU."}, "weaknesses": {"value": "1. The configuration of the non-IID experimental scenario is severely unclear, as the authors have neglected to specify the data distribution and the manner in which data is allocated to each client.\n\n2. The reporting of certain methods (e.g., FedOSD) differs significantly from their original presentation in the cited references. Following Weakness 1, this discrepancy may stem from confusion arising from the unclear specification of the non-IID setting.\n\n3. The experimental settings for clients are rather limited. If the focus is solely on studying unlearning from the clients’ perspective, scenarios involving a greater number of clients should be investigated. Additionally, different non-IID data distribution methods should be explored (e.g., Pathological, Dirichlet).\n\n4. Given that the aggregation direction for retained clients is fixed, can one be certain that an unlearning direction forming an acute angle with this direction will always exist? Why?\n\n5. In the preliminary section, the author does not mention the constraint that the sum of traditional FL aggregation probabilities must equal one. Is the global step size considered during model updates? If the default global update step size is set to 1, a brief explanation would be preferable.\n\n6. The concept of the “pre-unlearning process” first appears in Assumption 2 on page 5, line 265. Since the author has not previously introduced any related content, it is recommended that the unlearning process be introduced beforehand.\n\n7. On page 10, the text references “Appendix ??” — this appears to be a placeholder or unresolved citation."}, "questions": {"value": "1. Given that the aggregation direction for retained clients is fixed, can one be certain that an unlearning direction forming an acute angle with this direction will always exist? Why?\n2. Is the global step size considered during model updates? If the default global update step size is set to 1, a brief explanation would be preferable."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tZ9AvFQY1U", "forum": "msBSL6JnkZ", "replyto": "msBSL6JnkZ", "signatures": ["ICLR.cc/2026/Conference/Submission14846/Reviewer_sBNU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14846/Reviewer_sBNU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971061881, "cdate": 1761971061881, "tmdate": 1762925200356, "mdate": 1762925200356, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on federated unlearning, which involves removing a client’s data influence from a shared model without retraining the entire model from scratch. Existing methods consume excessive memory or become unstable due to gradient explosion and gradient conflict. FUGAS employs a preference-based forgetting loss, which stabilizes the learning process, in conjunction with a gradient aggregation strategy that shields the retaining gradients from conflict with the forgetting gradients."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Robust framework that addresses instability and performance degradation\n- novel forgetting objective\n- theoretical guarantees and empirical evaluation"}, "weaknesses": {"value": "- One of the major concerns is the extent of experimental results. The paper has limited dataset scope. The neural network architecture is too simple (The experiments lack evaluation beyond regular CNNs.), and one of the reasons seems to be that the technique is computationally expensive.\n- The author claim that the technique is “memory-efficient” but they do not quantify the time or computation cost of solving the quadratic projection step. Projection step is in fact under-explained. \n- There is no clarity on the experimental setting used to evaluate the attack success rate. \n- In the gradient projection step at the server, when the number of clients scale, will the compatibility region turn out to be very narrow? \n- What is the guarantee that using a negative reference corresponds to removing the underlying data influence? Is it simply inducing prediction noise?\n- Compatibility is ensured theoretically at each round, but what about long-term consistency? Does cumulative projection error cause drift from the retained clients’ optimum?\n- Does the algorithm assume full gradient visibility from clients? This may hinder FL's practicality. If client updates are encrypted or compressed, how does this affect projection constraints?\n-Solving a QP per round is costly for high-dimensional models.  \n- A proper quantification of how much the client’s contribution is removed (beyond ASR and MIA) is not provided."}, "questions": {"value": "Please address the comments in weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "3cAzm8DeAF", "forum": "msBSL6JnkZ", "replyto": "msBSL6JnkZ", "signatures": ["ICLR.cc/2026/Conference/Submission14846/Reviewer_yv6x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14846/Reviewer_yv6x"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762225719200, "cdate": 1762225719200, "tmdate": 1762925199854, "mdate": 1762925199854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}