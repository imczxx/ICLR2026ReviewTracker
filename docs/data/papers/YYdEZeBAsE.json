{"id": "YYdEZeBAsE", "number": 18501, "cdate": 1758288606242, "mdate": 1759897099403, "content": {"title": "Spectral Analysis of Molecular Kernels: When Richer Features Do Not Guarantee Better Generalization", "abstract": "Understanding the spectral properties of kernels offers a principled perspective on generalization and representation quality. While deep models achieve state-of-the-art accuracy in molecular property prediction, kernel methods remain widely used for their robustness in low-data regimes and transparent theoretical grounding. Despite extensive studies of kernel spectra in machine learning, systematic spectral analyses of molecular kernels are scarce.\nIn this work, we provide the first comprehensive spectral analysis of kernel ridge regression on the QM9 dataset, molecular fingerprint, pretrained transformer-based, global and local 3D representations across seven molecular properties. Surprisingly, richer spectral features, measured by four different spectral metrics, do not consistently improve accuracy. Pearson correlation tests further reveal that for transformer-based and local 3D representations, spectral richness can even have a negative correlation with performance. We also implement truncated kernels to probe the relationship between spectrum and predictive performance: in many kernels, retaining only the top 2\\% of eigenvalues recovers nearly all performance, indicating that the leading eigenvalues capture the most informative features.\nOur results challenge the common heuristic that “richer spectra yield better generalization” and highlight nuanced relationships between representation, kernel features, and predictive performance. Beyond molecular property prediction, these findings inform how kernel and self-supervised learning methods are evaluated in data-limited scientific and real-world tasks.", "tldr": "Spectral analysis on various molecular kernels show that richer spectra do not correlate to better performance in general.", "keywords": ["molecular kernels", "unsupervised learning", "learning representation", "pretrained Molecular embedding models", "self-supervised learning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2c4042fce78465d96acfd6147056e5f1b5652b82.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors perform a spectral analysis of various types of kernels for molecular property prediction on the QM9 dataset, showing that a richer spectrum is not always correlated with better performance. Moreover, the authors show that heavily truncated kernels (where most of the eigenspectrum is removed) often recover almost all the performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "While the scope of the paper might be limited, I believe it is original, and I am not aware of particularly similar studies. The content is exposed clearly and the variety of fingerprints/descriptors and kernels used is good."}, "weaknesses": {"value": "I believe the paper is affected by a number of issues, some of which prevent, in my opinion, acceptance in ICLR.\n\n**Major**\n- In the current form, I do not believe the results of the analysis shown by the authors can be trusted. For example, Fig. 2b shows MAEs on $U_{298}$ around 50 eV for a training set size of 5000 structures (which is the most used throughout the work) with the ACSF descriptors. In the literature, the geometrically equivalent SOAP descriptor (which shows slightly worse results than ACSF in this work) is reported to achieve errors well below 1 eV on the same training set size, and closer to 0.5 eV. Given that the errors are almost 100 times higher than reported values in the literature, I am almost certain that the results are affected by technical issues. The conclusions that the authors extract from the results are also called into question: a performance 100 times worse than expected might very well be the cause why throwing away most of the spectrum makes no difference when trying to retain 95% or 99% accuracy with these descriptors, given that these spectral features might be needed only to achieve accuracies that the authors were not able to obtain for other technical reasons.\n- The point above highlights a second issue: the QM9 results are the only ones that the authors show (i.e., no other dataset is evaluated). If those cannot be trusted, the conclusions might not be reliable either. In their \"limitations\" remarks, the authors argue that the QM9 dataset is the most widely used benchmark in this field, citing evidence between 11 and 5 years ago. Although I agree that QM9 is perhaps the most suitable benchmark even to this day, evaluation on different datasets might still be beneficial.\n- The authors claim (lines 196-201) that linear kernels are not defined for local 3D descriptors. This is not true as far as I know. Global linear kernels can be obtained linearly from local features as a sum over atoms in both environments of all pairs of scalar products.\n- The \"regularization versus truncation\" section is especially dubious. The fact that eigenvalue truncation is a form of regularization has been known for decades. For example, the LAPACK linear algebra standard contains linear solvers where eigenvalue truncation is used as a regularization (or conditioning) parameter. See the documentation of the \"rcond\" parameter in https://www.netlib.org/lapack/explore-html/d9/d67/group__gelsd_ga0bee7e1b9e7e43f59ecf2419b2759c42.html. For an academic reference from the 80s, see http://infolab.stanford.edu/pub/cstr/reports/na/m/86/36/NA-M-86-36.pdf. In the same section, the authors claim that it might have a similar effect to regularizing by adding a multiple of the identity (which is true and well-understood)... yet this was supposed to have already been done with an optimized $\\lambda$ (in the authors' notation) for all experiments.\n\n**Minor**\n- This is obviously not the authors' fault, but kernel methods are losing in popularity, and this diminishes the relevance this paper work might have for the ICLR community. Many practitioners in the molecular domain have moved to GNN- and transformer-based architectures. The authors show that kernels might be useful by fitting properties using latent representations from these neural network models, but the same could be done adding a new prediction head and doing basic transfer learning, which would furthermore allow to fine-tune the whole architecture. In the introduction, the standard claim about kernels being parameter-free appears. However, in practice, kernels move all the design choices to the descriptor and the functional form of the kernel function, and they are extremely sensitive to them. Neural networks, while having indeed hyperparameters, are often more robust to the choice of bad hyperparameters. Bad choices for the kernel and/or descriptor can instead be catastrophic. It is true that kernels tend to be more accurate in the low-data regime, but such data regimes are used less and less in chemical research, once again potentially reducing the scope of interest of this work.\n- Two minor presentation issues. (1) The authors might want to report RMSEs/MAEs instead of $R^2$ values (or in addition to them, in the appendix). In some cases (especially where $R^2$ is very close to one), error metrics can be more informative. They are also easier to compare against results from the literature. (2) Figure 3 should probably be log-log (as opposed to linear-log), according to the authors' ansatz for the decay of spectral eigenvalues. Then, the slope would correspond to $-\\alpha$, in the authors' notation.\n- The strategy of eigenvalue truncation that the author advocate for towards the end of the manuscript does not improve computational efficiency as far as I understand (as opposed to feature selection or kernel sparsification). Given this observation, it is difficult to see practical applications of what the authors propose in this manuscript, once again limiting the practical interest this work might have for practitioners.\n\n**Very minor**\n- Citation format: \\citep{} should be used throughout (according to ICLR formatting) instead of \\cite{} to enclose citations within parentheses.\n- Lines 135 and 136 do not form a coherent sentence."}, "questions": {"value": "Many discussion topics are already present in the weaknesses section above and I invite the authors to comment on those as they see fit. I would be interested in knowing if they can identify the cause the poor accuracy of the ACSF learning curve, as I believe it would need fixing for this work to be published in any form."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5zg7DZsGml", "forum": "YYdEZeBAsE", "replyto": "YYdEZeBAsE", "signatures": ["ICLR.cc/2026/Conference/Submission18501/Reviewer_m5Bb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18501/Reviewer_m5Bb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761505360398, "cdate": 1761505360398, "tmdate": 1762928198122, "mdate": 1762928198122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a comprehensive empirical study of the spectral properties of molecular kernels across multiple molecular representations (ECFP fingerprints, pretrained transformer embeddings, and global/local 3D descriptors) on the QM9 dataset.\nThe authors demonstrate that commonly used spectral richness metrics—power-law decay exponent, spectral entropy, intrinsic dimension, and stable rank—do not reliably predict generalization performance. In many cases, spectral richness even correlates negatively with accuracy, particularly for transformer-based and local 3D kernels.\nThe work further introduces truncated kernel ridge regression (TKRR) experiments showing that retaining only the top ≈ 2 % of eigenvalues recovers > 95 % of predictive performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Comprehensive empirical coverage: The study systematically compares a broad set of molecular kernels, including modern pretrained transformer-based ones.\nNovel diagnostic analysis: The spectral correlation and truncation experiments provide new insights into how kernel spectra relate to downstream generalization.\nClear empirical message: The results decisively challenge the pervasive heuristic in SSL and kernel learning that “richer spectra yield better generalization.”\nHigh potential impact: The findings are relevant not only for molecular property prediction but for any field relying on kernel or representation analysis (e.g., SSL evaluation, NTK theory)."}, "weaknesses": {"value": "1. **Conceptual clarity of “feature richness.”**\n   The empirical results convincingly demonstrate that *spectral richness*—quantified through metrics derived from the eigenvalue spectrum of the kernel matrix—does not consistently predict model generalization. However, the paper would benefit from a clearer conceptual framing: spectral richness primarily reflects the **capacity** of the reproducing kernel Hilbert space (RKHS), not necessarily the *usefulness* of the representation for a particular task.\n   A kernel with a flatter (richer) spectrum corresponds to a higher-capacity function space, which, if insufficiently regularized, can lead to **overfitting**. The authors should therefore clarify that their findings do not contradict kernel theory but instead highlight that **eigenvalue-based capacity measures must always be interpreted together with regularization**.\n\n---\n\n2. **Missing theoretical grounding.**\n   To strengthen the argument, the authors could explicitly connect their findings to the theory of **Kernel Ridge Regression (KRR)**, where the expected generalization error depends both on the **eigenvalues** (the kernel spectrum) and on the **alignment** between the **eigenvectors** and the target function.\n   Classical results show that\n\n   $$\n   \\mathbb{E},|f_\\lambda - f^\\star|^2 \\sim\n   \\sum_j \\frac{\\lambda^2 (u_j^\\top f^\\star)^2}{(\\mu_j + \\lambda)^2},\n   $$\n\n   where ( f_\\lambda ) is the learned predictor, ( f^\\star ) the true regression function, ( u_j ) the eigenfunctions, ( \\mu_j ) the eigenvalues, and ( \\lambda ) the regularization constant.\n   This decomposition illustrates that performance depends jointly on **spectral decay** and **target alignment**, not on the eigenvalues alone. Including this expression—or citing the relevant derivation—would clarify why a richer spectrum can even correlate negatively with test accuracy in the absence of sufficient regularization.\n\n---\n\n3. **Need for falsifiable counterexamples.**\n   The claim that spectral metrics are insufficient predictors of generalization could be made more convincing through a simple counterexample. Two kernel matrices can share **identical eigenvalue spectra** but differ in their **eigenvector alignment** with the target, resulting in distinct generalization performance.\n   Demonstrating this empirically—e.g., by rotating the eigenbasis of a fixed kernel matrix while keeping the eigenvalues constant—would provide a direct disproof of the idea that the spectrum alone determines generalization.\n\n---\n\n4. **Empirical ablations to isolate alignment effects.**\n   The authors could perform targeted ablations to disentangle spectral richness from alignment effects:\n\n   * **Rotation tests:** Randomly rotate the eigenbasis of the kernel matrix while keeping eigenvalues fixed, observing the change in performance.\n   * **Label reshuffling:** Preserve spectral statistics but permute the projections of the labels across eigenfunctions.\n   * **Synthetic controls:** Construct artificial kernel matrices with fixed eigenvalue distributions but randomized eigenvectors.\n     These experiments would provide falsifiable evidence that *alignment*, rather than spectral shape, dominates generalization.\n\n---\n\n5. **Alternative, label-aware metrics.**\n   The current spectral measures—power-law decay rate, spectral Shannon entropy, intrinsic dimension, and stable rank—are purely label-agnostic. More informative alternatives could include:\n\n   * **Kernel–Target Alignment (KTA)**, which measures the correlation between the kernel matrix and the label-similarity matrix.\n   * **Target-weighted effective dimension**, defined as\n\n     $$\n     d_{\\mathrm{eff},y}(\\lambda)\n     = \\sum_j\n     \\frac{\\mu_j}{\\mu_j + \\lambda}\n     \\frac{(u_j^\\top y)^2}{|y|^2},\n     $$\n\n     capturing both spectrum and label alignment.\n   * **Energy concentration indices**, quantifying how much of the label variance is captured by the top-ranked eigenfunctions.\n   * **Truncation recovery curves**, already partially explored by the authors, which show how quickly predictive performance saturates as eigenvalues are progressively retained.\n     Introducing such label-aware diagnostics would provide a stronger connection between spectral analysis and generalization behavior.\n\n---\n\n6. **Interpretation of negative correlations.**\n   The observed negative correlations between spectral richness and predictive accuracy for transformer-based and local 3D kernels likely arise because a flatter spectrum increases model capacity in directions that do not align with the true target function, thereby increasing variance and the potential for overfitting.\n   The authors should make this interpretation explicit: **spectral richness measures potential capacity, not effective representational quality**, and its impact depends critically on the regularization regime."}, "questions": {"value": "1. **Reframing of the central claim.**\n   Could the authors clarify whether the main contribution should be interpreted as *falsifying the assumption that eigenvalue-based spectral richness predicts generalization*?\n   In other words, do the results indicate that effective representation quality depends primarily on **alignment-weighted spectral structure** rather than the raw distribution of eigenvalues?\n\n---\n\n2. **Spectral decay versus alignment effects in Kernel Ridge Regression (KRR).**\n   Would it be possible for the authors to include a brief theoretical section or appendix explicitly distinguishing the effects of **spectral decay** (capacity) and **label alignment** (task relevance) within the KRR framework?\n   A formal expression—such as the expected error decomposition\n\n   $$\n   \\mathbb{E},|f_\\lambda - f^\\star|^2 \\sim\n   \\sum_j \\frac{\\lambda^2 (u_j^\\top f^\\star)^2}{(\\mu_j + \\lambda)^2},\n   $$\n\n   —would help clarify how these two factors jointly determine generalization behavior.\n\n---\n\n3. **Synthetic validation of spectrum insufficiency.**\n   Could the authors consider a **controlled synthetic experiment** to demonstrate concretely that two kernels with **identical eigenvalue spectra** can generalize differently when their **eigenvectors** are differently aligned with the target?\n   Such a result would make the insufficiency of spectral information more tangible and theoretically grounded.\n\n---\n\n4. **Inclusion of alignment-aware diagnostics.**\n   Would the authors consider reporting or discussing **alignment-aware measures** alongside the current spectral metrics?\n   In particular, metrics such as **Kernel–Target Alignment (KTA)**, **energy concentration indices**, or the **target-weighted effective dimension**\n\n   $$\n   d_{\\mathrm{eff},y}(\\lambda)\n   = \\sum_j\n   \\frac{\\mu_j}{\\mu_j + \\lambda}\n   \\frac{(u_j^\\top y)^2}{|y|^2}\n   $$\n\n   could reveal whether predictive performance is better explained by label alignment than by spectral richness alone.\n\n---\n\n5. **Relation between spectral truncation and Tikhonov regularization.**\n   The truncated-KRR (TKRR) results suggest a strong connection between explicit eigenvalue truncation and the effect of ridge regularization.\n   Could the authors comment on this relationship?\n   Specifically, is there a formal or empirical mapping between the truncation level and an equivalent regularization strength ( \\lambda ) that preserves generalization?\n   Clarifying this could motivate future analytical work linking spectral control to classical notions of Tikhonov regularization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8N4tFhRNlO", "forum": "YYdEZeBAsE", "replyto": "YYdEZeBAsE", "signatures": ["ICLR.cc/2026/Conference/Submission18501/Reviewer_3oPM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18501/Reviewer_3oPM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904423208, "cdate": 1761904423208, "tmdate": 1762928197670, "mdate": 1762928197670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides an empirical study on how spectral richness relates to generalization in kernel ridge regression (KRR). The paper evaluates four families of representations on QM9: (i) ECFP fingerprints, (ii) pretrained transformer embeddings (SELFIESTED, SELFormer, MLT-BERT), (iii) global 3D descriptors, and (iv) local 3D descriptors, across seven molecular properties. The paper finds that richer spectra do not reliably predict higher accuracy; for transformer-based and local 3D kernels the correlation can even be negative; and in many cases the top 2% eigenvalues recover >95% of full KRR performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The study is comprehensive in terms of kernel / representation pairs and spectral metrics with clear reporting.\n* The paper gives an interesting insight that the widely held heuristic “richer spectra → better generalization” may fail, especialy on transformer and local 3D representations.\n* The observation that the top 2% eigenvalues often recover >95% R$^2$ is practically valuable for guiding more efficient models."}, "weaknesses": {"value": "* All results are on QM9, with random splits (5k train / 10k test). The conclusions may not generalize to larger/biologically relevant datasets or to scaffold/similarity-aware splits, which are standard in molecular benchmarks to avoid overly optimistic generalization.\n* While the paper shows KRR can outperform linear models on transformer features, it does not compare to strong non-kernel baselines (e.g., modern equivariant GNNs) on the same splits.\n* There is no explanation proposed on why better spectral richness can be detrimental to performance (line 397). Also, the results may depend on how “spectral richness” is quantified; the negative correlation could be an artifact of the chosen measure (the four spectral metrics) rather than an underlying phenomenon."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "yByaTXSZor", "forum": "YYdEZeBAsE", "replyto": "YYdEZeBAsE", "signatures": ["ICLR.cc/2026/Conference/Submission18501/Reviewer_w22r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18501/Reviewer_w22r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957511134, "cdate": 1761957511134, "tmdate": 1762928197282, "mdate": 1762928197282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies whether, across a wide range of kernels, the decay rate of the kernel's eigenspectrum predicts the generalization ability of the method. On the QM9 dataset their finding is that it _does not_."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Overall I think this paper proposes a very good question to understand what it is about kernel methods which still makes them competitive on low-data chemical ML tasks. Even though the answer is negative, scientific work should be judged based on the merit of the _question_ and not the _answer_. As far as I am aware this question has not been specifically studied in the context of molecules or molecular property prediction datasets. The experiments on QM9 are very thorough."}, "weaknesses": {"value": "**Single dataset**: as much as I love the question and methods of this paper, its conclusions are significantly weakened by only studying a single dataset, since the answer will be influenced by all the datasets peculiarities. For QM9, some peculiarities are:\n\n- All molecules are very small, so diversity is low. Molecules probably all have many close neighbors.\n- The properties all involve 3D structures, and each SMILES has multiple 3D structures, hence perfect prediction from just SMILES/2D features is not possible.\n- Lack of \"outliers\" in the dataset\n\nTesting on another dataset would be helpful. Some ideas are\n\n- [GEOM dataset](https://github.com/learningmatter-mit/geom): like QM9 but for larger molecules\n- [MoleculeNet](https://moleculenet.org/) (experimental properties, tasks less intrinsically \"3D\")\n- [Dockstring](https://dockstring.github.io/) (large and in-silico, semi 3D)\n\n**Confounding kernel types and features**: fingerprint features were only studied with \"similarity\" type kernels, which follows a common misunderstanding that certain kernels are intrinsically \"meant for\" certain types of features. I think this was a missed opportunity for an ablation study to understand how much of the effect comes from the kernel type and how much comes from the features (presumably some features are less informative than others). I suggest trying RBF/Laplace kernels on these features too."}, "questions": {"value": "What was the justification behind selecting $\\lambda$ using cross-validation instead according to the eigenspectrum? KRR's $\\lambda$ parameter is deeply related to the eigenspectrum: basis vectors whose eigenvalue is $\\ll \\lambda$ are effectively ignored from the regression. Rather than treating $\\lambda$ as an empirical parameter, shouldn't it be the tool which you use to \"truncate\" the eigenspectrum?\n\nBased on this and my comment above about features, I would suggest the following modified experiment design:\n\n- Focus on some 2D features (at least at first). Eg ECFP.\n- Pick a couple of kernel classes (eg Tanimoto, RBF, Laplace). Maybe add in some extra stationary kernels with different levels of smoothness (eg Matern) and extra non-stationary ones (eg Braun-Blanquet, Dice).\n- For kernel classes with a lengthscale parameter, the lengthscale _highly influences_ the spectrum. Do not just set it to an arbitrary value! Values should generally be based on the distance between data points (which is feature dependent). Calculate the median $\\ell_2$ distance between data points- call this $d_m$. Try values of $0.1d_m,\\ d_m,\\ 10d_m$ for lengthscale. This should make the behavior more consistent between tasks.\n- For each (kernel, feature, hyperparameter pair): calculate the eigenspectrum.\n- Evaluate performance setting $\\lambda$ to, eg, 100th percentile, 99.9th percentile, 99th percentile, ..., 10%th percentile, 1st percentile of eigenspectrum values.\n\nAlthough this data won't fit nicely in a table, it will hopefully allow you to answer questions about spectra more directly. For example:\n\n- Fix a given feature (eg ECFP). In general, does lower decay rate mean better performance? Comparing, eg, RBF vs Laplace would be interesting\n- Fix a given kernel class, look at increasing lengthscale (which should change eigenspectrum), see how that influences performance.\n- Fix a given kernel class / hyperparameters, look across all features, what is the effect of different features\n\nI know this is not a super precise suggestion, but I hope you get roughly what I mean. Augmenting the experimental design with a lot of ablations should help you understand more precisely what is causing the performance differences.\n\n_Please note: this is not a specific experiment request for the rebuttal, so don't just blindly go do it. What I am really trying to suggest is \"design the experiments to get a more precise answer to your question\", and what I wrote above is my thoughts about how I might do that, but I didn't think it through super thoroughly. I bet you can come up with a better design if you think about it._"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0jMX60IPLq", "forum": "YYdEZeBAsE", "replyto": "YYdEZeBAsE", "signatures": ["ICLR.cc/2026/Conference/Submission18501/Reviewer_1fHi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18501/Reviewer_1fHi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762180454926, "cdate": 1762180454926, "tmdate": 1762928196486, "mdate": 1762928196486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}