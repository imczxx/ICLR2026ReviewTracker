{"id": "xfnR9ok8HJ", "number": 14194, "cdate": 1758230118607, "mdate": 1759897384642, "content": {"title": "Latent Wasserstein Adversarial Imitation Learning", "abstract": "Imitation Learning (IL) enables agents to mimic expert behavior by learning from demonstrations. However, traditional IL methods require large amounts of medium-to-high-quality demonstrations as well as actions of expert demonstrations, both of which are often unavailable. To reduce this need, we propose Latent Wasserstein Adversarial Imitation Learning (LWAIL), a novel adversarial imitation learning framework that focuses on state-only distribution matching. It benefits from the Wasserstein distance computed in a dynamics-aware latent space. This dynamics-aware latent space differs from prior work and is obtained via a pre-training stage, where we train the Intention Conditioned Value Function (ICVF) to capture a dynamics-aware structure of the state space using a small set of randomly generated state-only data. We show that this enhances the policy's understanding of state transitions, enabling the learning process to use only one or a few state-only expert episodes to achieve expert-level performance. Through experiments on multiple MuJoCo environments, we demonstrate that our method outperforms prior Wasserstein-based IL methods and prior adversarial IL methods, achieving better results across various tasks.", "tldr": "We propose a Wasserstein adversarial imitation learning method with ICVF-learned metric for imitation learning from observation.", "keywords": ["adversarial imitation learning", "wasserstein distance", "latent state space"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/39b1906e5b4d2921c93eb4dc3d80bba38c8d513e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Latent Wasserstein Adversarial Imitation Learning (LWAIL), a imitation learning framework that learns from state-only expert demonstrations without requiring expert actions or large datasets. LWAIL leverages the Wasserstein distance computed in a dynamics-aware latent embedding, which is obtained through a pre-training stage using an Intention Conditioned Value Function (ICVF) trained on a small set of random state-only data. Experiments on multiple MuJoCo tasks show that LWAIL outperforms prior imitation learning methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and easy to follow.  \n- The experimental results show strong performance compared to both classic imitation learning and learning-from-observation (LfO) methods.  \n- The ablation studies and experimental details seem to be thorough and sufficient."}, "weaknesses": {"value": "- **Novelty**: The paper primarily combines existing methods, as both WAIL and ICVF are established approaches. This limits the overall technical contribution and originality of the work.\n\n- **Lack of Justifications**: The paper does not sufficiently justify why using the ICVF dynamics-aware embedding space should improve performance. From my understanding, standard adversarial imitation learning (AIL) methods based on occupancy matching are already dynamics-aware—the reward or Q-function trained via the adversarial objective implicitly captures the dynamics, as noted in the original IQ-Learn paper [1]. It remains unclear why introducing an additional dynamics-aware latent embedding would further enhance performance. Moreover, while the t-SNE plot in Figure 2 shows some structure in the learned embedding, its connection to the actual system dynamics is not well established, making it difficult to support the claim that the embedding provides a more dynamics-aware metric.\n\n- **Lack of Comparison with Model-based Approaches**: Several existing model-based imitation learning methods also learn latent embeddings through a latent world model, such as [2, 3, 4]. The paper does not provide sufficient discussion or comparison regarding how the proposed dynamics-aware latent space differs from or improves upon these approaches.\n\n- **Potential Misalignment Issue**: The reward function is trained by discriminating between state-action transitions from expert and random policies. During the RL training phase, however, the policy gradually deviates from the random policy, leading to a potential distribution mismatch. The paper appears to overlook this issue and could benefit from an off-policy correction mechanism, such as importance sampling.\n\n- **Choice of Downstream RL Method**: The ablation study in Table 10 shows that changing the RL algorithm significantly degrades performance. For PPO, the poor results might be due to the aforementioned policy misalignment issue, as PPO is an on-policy method. However, even with off-policy algorithms like DDPG, performance remains unsatisfactory, raising concerns about the robustness and generalizability of the proposed embedding approach.\n\n\n[1] Garg, D., Chakraborty, S., Cundy, C., Song, J., & Ermon, S. (2021). Iq-learn: Inverse soft-q learning for imitation. Advances in Neural Information Processing Systems, 34, 4028-4039.\n\n[2] Yin, Z. H., Ye, W., Chen, Q., & Gao, Y. (2022). Planning for sample efficient imitation learning. Advances in Neural Information Processing Systems, 35, 2577-2589.\n\n[3] Li, S., Huang, Z., & Su, H. (2025). Reward-free World Models for Online Imitation Learning. In Forty-second International Conference on Machine Learning.\n\n[4] Kolev, V., Rafailov, R., Hatch, K., Wu, J., & Finn, C. (2024, June). Efficient imitation learning with conservative world models. In 6th Annual Learning for Dynamics & Control Conference (pp. 1777-1790). PMLR."}, "questions": {"value": "1. **Justification of Dynamics-aware Embeddings**: My primary concern is the lack of justification for the effectiveness of the proposed dynamics-aware embeddings. Could the authors provide stronger theoretical insights or additional empirical evidence, such as a more detailed analysis of Figure 2 or an ablation study using original observations as inputs to WAIL, to demonstrate that the dynamics-aware embedding is indeed more effective than using raw observations?\n\n2. **Comparison with Latent World Models**: How does the proposed dynamics-aware latent space improve upon the latent representations learned in existing imitation learning methods that employ latent world models?\n\n3. **Sensitivity to Downstream RL Algorithms**: The results show significant performance degradation when changing the downstream RL algorithm. Could the authors provide more justification for this sensitivity? Are there potential robustness issues with the learned embeddings that may contribute to this behavior?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B2vWcoKNxx", "forum": "xfnR9ok8HJ", "replyto": "xfnR9ok8HJ", "signatures": ["ICLR.cc/2026/Conference/Submission14194/Reviewer_Cuqz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14194/Reviewer_Cuqz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760469450535, "cdate": 1760469450535, "tmdate": 1762924648008, "mdate": 1762924648008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Previous Wasserstein imitation learning methods couldn’t capture the environment’s dynamics accurately. The paper proposes a novel adversarial imitation learning framework, Latent Wasserstein Adversarial Imitation Learning (LWAIL), that integrates the Intention Conditioned Value Function (ICVF) to capture these dynamics to resolve the issue. By using a two-stage process, first pretraining the ICVF with low-quality data and, secondly, running a standard Wasserstein AIL framework in this new latent space, the paper shows expert-level results in multiple locomotion tasks with a single state-only expert trajectory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is clearly written, well-structured, and comprehensive, making the authors' contributions and methodology easy to follow.\n- The paper's primary contribution, LWAIL, is novel in its integration of an ICVF-learned latent space into a Wasserstein AIL framework to create a dynamics-aware distance metric. This is significant as it demonstrates expert-level performance on several locomotion tasks using only a single state-only expert trajectory, a challenging and practical problem setting.\n- The empirical investigation is of high quality. The authors performed a thorough comparison against numerous baselines and provided an extensive set of ablation studies that validate the key components of their approach, such as the choice of embedding and robustness to noise."}, "weaknesses": {"value": "- The empirical evaluation, while thorough on the chosen tasks, is limited to locomotion (MuJoCo) and a simple maze environment. These environments are state-based and have relatively stable dynamics. The applicability of LWAIL to more complex, high-dimensional problems (e.g., vision-based tasks) or environments with more stochastic dynamics is not explored. \n- The paper does not include an ablation study on the sensitivity of key hyperparameters. Adversarial Imitation Learning frameworks are often sensitive to settings like the discriminator update frequency (which the authors note must be balanced ) or the gradient penalty coefficient. An analysis of how performance changes with these hyperparameters would strengthen the paper's claims of robustness.\n- The paper's core motivation, powerfully illustrated in Figure 1(a), is that LWAIL's dynamics-aware metric can solve problems where simple Euclidean distance is misleading (e.g., a state near a goal is \"worse\" than a farther state with a valid path). However, the chosen experiments, while standard, do not fully stress-test this specific claim. The `umaze` environment demonstrates this principle, but is very simple. The MuJoCo locomotion tasks are complex in terms of control, but they do not necessarily exhibit the challenging topological structure implied by the motivating example. The paper would be much stronger if LWAIL and key baselines were evaluated on environments specifically designed to have this deceptive property, such as more complex mazes with traps, one-way paths, or regions that require non-Euclidean navigation to succeed."}, "questions": {"value": "- The paper convincingly argues that an ICVF-learned latent space is beneficial for tasks like `umaze`, where the Euclidean distance is misleading due to the environment's dynamics (e.g., a wall). However, it is less clear how this specific benefit translates to the MuJoCo locomotion tasks. What is the intuition for why a dynamics-aware latent space is superior to the standard state space for tasks like Hopper or Walker2D?\n- To better validate the core contribution, have you considered testing LWAIL and key baselines on more complex environments that explicitly share the properties of Figure 1(a), such as the `ant-maze` or other complex navigation tasks from the D4RL benchmark?\n- The performance plot in Figure 4 is very dense, and many of the colors are similar, making it difficult to distinguish the learning curve for LWAIL from the baselines. Could you please consider using a more distinct color (e.g., a thick, bright red) or a different line style for your method in the final version to improve legibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WoFBsLXeEa", "forum": "xfnR9ok8HJ", "replyto": "xfnR9ok8HJ", "signatures": ["ICLR.cc/2026/Conference/Submission14194/Reviewer_mxsi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14194/Reviewer_mxsi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761456282357, "cdate": 1761456282357, "tmdate": 1762924647541, "mdate": 1762924647541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel Latent Wasserstein Adversarial Imitation Learning (LWAIL) algorithm for state-only imitation. The authors identify that in Wasserstein IL, the gradient penalty commonly used to stabilize adversarial optimization enforces a 1-Lipschitz constraint, which implicitly restricts the underlying distance metric to be Euclidean. To overcome this limitation, LWAIL introduces a dynamics-aware latent space learned via the Intention-Conditioned Value Function, which captures reachability between states and provides a more meaningful ground metric for Wasserstein distance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper identifies and addresses the weakness of using Euclidean metrics in Wasserstein IL by introducing a dynamics-aware latent space. Overall, the presentation is clear, well-structured, and easy to follow."}, "weaknesses": {"value": "1. **Limited novelty**: The contribution is primarily a combination of existing ideas (Wasserstein IL, adversarial learning, and latent representations), with the main advance being the integration of ICVF embeddings.\n\n2. **Narrow experimental scope**: The experiments focus mainly on locomotion tasks. Given the illustrative example in Fig. 1, navigation-style tasks (such as those in Fig. 3) would have been more suitable to highlight the strengths of the proposed approach.\n\n3. **Questionable necessity of state embeddings**: A central motivation of the paper is that Euclidean distances between states are not meaningful. However, in many AIL approaches the divergence is minimized over state transitions rather than individual states. Under the standard expert optimality assumption, these transition distributions already capture the structure of optimal paths, potentially mitigating the issue highlighted in Fig. 1(a). This raises the question of whether a dedicated dynamics-aware embedding is strictly necessary or whether the problem is indirectly addressed by existing formulations.\n\nMinor issues:\n1. DACfO in line 339 outperforms LWAIL.\n2. The Related Work section is missing relevant references, such as: \nGiammarino V, Queeney J, Paschalidis I. Adversarial Imitation Learning from Visual Observations using Latent Information. Transactions on Machine Learning Research."}, "questions": {"value": "1. It is unclear what the expert performance level is in Figure 4. Could you provide a reference line or explicit numbers for comparison?\n\n2. In practice, many AIfO algorithms minimize a divergence over state transitions (as in Eq. (5)) rather than over individual states. Wouldn’t this already mitigate the issue highlighted in Fig. 1(a), since the optimization objective ensures that the agent’s transitions (s,s’) are aligned with the expert’s, regardless of the absolute distance between individual state embeddings? How does the proposed embedding provide an additional benefit beyond what is already achieved by transition-level matching?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aqtOwQV6VN", "forum": "xfnR9ok8HJ", "replyto": "xfnR9ok8HJ", "signatures": ["ICLR.cc/2026/Conference/Submission14194/Reviewer_EztW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14194/Reviewer_EztW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761754454324, "cdate": 1761754454324, "tmdate": 1762924647044, "mdate": 1762924647044, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a state-only imitation learning approach that combines a Wasserstein Adversarial Imitation Learning objective with a learned latent representation (ICVF). The motivation is that Wasserstein distances in the original state space can behave poorly for high-dimensional or redundant dynamics, and that learning an approximately linear latent embedding can yield a geometry where Euclidean distances better reflect transition similarity. The authors provide empirical results on MuJoCo control tasks, demonstrating that training in such a latent space improves sample efficiency and stability in low-demonstration regimes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-The idea of combining a latent, dynamics-aware embedding with a Wasserstein AIL objective is intuitive and well-motivated.\n-The results show consistent gains over baselines in low-data settings, and the ablations suggest that learning a latent embedding indeed facilitates imitation learning.\n-The paper provides a wide range of ablations (different embeddings, action noise, dynamics mismatch), which adds credibility to the empirical findings."}, "weaknesses": {"value": "-Overstated novelty. Methodologically, the approach is largely a combination of known components (Wasserstein AIL and ICVF-based embeddings) rather than a fundamentally new algorithm. The paper currently presents it as a new framework rather than as a targeted study of how these parts interact.\n- Fairness of comparisons. While the paper shows LWAIL with and without the latent, it does not systematically test whether other IL algorithms (e.g., IQ-Learn, OPOLO, GAIfO) would also benefit from the same latent embedding. While they have a short comparison in the appendix details about the comparison are missing (e.g. how where the hyperparameters selected). This makes it unclear whether the improvement comes from the Wasserstein loss or simply from using ICVF features with the other improvements like the adapted reward.\n- Experimental focus and clarity. Important comparisons are buried in the appendix, and it is difficult to attribute which component (embedding, loss type, or regularization) drives the gains. The main tables mostly cover simple MuJoCo tasks, with only a limited exploration of harder or higher-dimensional environments.\n- Limited evaluation breadth. The experiments remain confined to low-dimensional, low-contact locomotion tasks (Hopper, Walker2D, HalfCheetah, Ant). The approach’s claimed robustness would be more convincing with higher-dimensional or vision-based control tasks. For example why was the humanoid environment left out?\n- Presentation imbalance. Some theoretical and background sections could be shortened to leave space for clearer experimental structure and discussion of assumptions. Key ablations and tuning details should be surfaced from the appendix."}, "questions": {"value": "To make the contribution clearer and more convincing, I would recommend the following revisions before acceptance:\n\n- Clarify contribution framing. Recast the paper as an investigation of Wasserstein AIL in learned latent metricsrather than as a new algorithm.\n- Systematic baseline parity. Add a study where the same ICVF embedding is used across strong baselines (IQ-Learn, GAIfO, OPOLO) under searched hyperparameters and matched general setups. This would clarify whether the Wasserstein component itself is crucial. Describe how hyperparameters for baselines and variants were chosen, especially when embedding features are shared.\n- Why was the humanoid environment left out? Why is there not at least one more complex or high-dimensional task (e.g., Humanoid or a visual D4RL environment). A test for scalability and the generality of the embedding is missing. Is the claim that the method can learn from on expert trajectory legitimate when only the “simple” mujoco tasks where tested?\n- Highlight experimental design. Why are the key ablations (embedding vs. no-embedding, Wasserstein vs. f-divergence, baselines with latent embeddings) not all in the main paper? Why are there no clear performance summaries and standard deviations over multiple seeds for the ablations?\n- Theory scope and assumptions. Discuss more explicitly when the linear-in-embedding assumption of Theorem 3.1 holds or fails. Does it fail in a truly stochastic environment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lncMiAxNXK", "forum": "xfnR9ok8HJ", "replyto": "xfnR9ok8HJ", "signatures": ["ICLR.cc/2026/Conference/Submission14194/Reviewer_XUbE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14194/Reviewer_XUbE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896099460, "cdate": 1761896099460, "tmdate": 1762924646286, "mdate": 1762924646286, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}