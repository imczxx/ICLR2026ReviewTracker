{"id": "j0czDrEnFc", "number": 16600, "cdate": 1758266613350, "mdate": 1763707064486, "content": {"title": "A Bayesian Nonparametric Framework for Private, Fair, and Balanced Tabular Data Synthesis", "abstract": "A fundamental challenge in data synthesis is protecting the fairness and privacy of\nthe individual, particularly in data-scarce environments where underrepresented\ngroups are at risk of further marginalization by reproducing the biases inherent in\nthe data modeling process. We introduce a privacy- and fairness-aware for a class\nof generative models, which fuses the conditional generator within the framework\nof Bayesian nonparametric learning (BNPL). This conditional structure imposes\nfairness constraints in our generative model by minimizing the mutual information\nbetween generated outcomes and protected attributes. Unlike existing methods\nthat primarily focus on sensitive binary-valued attributes, our framework extends\nseamlessly to non-binary attributes. Moreover, our method provides a systematic\nsolution to class imbalance, ensuring adequate representation of underrepresented\nprotected groups. Our proposed approach offers a scalable, privacy-preserving\nframework for ethical and equitable data generation, which we demonstrate by\ntheoretical guarantees and extensive experiments on sensitive empirical examples.", "tldr": "Incorporating privacy as well as fairness through Bayesian nonparametric learning", "keywords": ["Bayesian nonparametric", "Dirichlet process", "Differential privacy", "Tabular data generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7f496ab1eab75260dd295abe113317316a538fa7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Proposes a Bayesian–nonparametric pipeline for tabular synthetic data that jointly enforces (i) privacy via Dirichlet-process (global) and copula-based (localized) mechanisms, (ii) fairness via minimizing mutual information between outcomes and protected attributes, and (iii) class balancing by conditioning the generator on group labels; instantiated with a conditional VAE+GAN and evaluated on Adult and COMPAS."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors unified objectives across privacy–fairness–balance. BNPL resampling + MI regularizer + conditional generation is a complete solution to DP + fairness.\n2. DP analysis for a Dirichlet mechanism and localized privacy via copula-based marginals are novel in this combination."}, "weaknesses": {"value": "1. Fairness target & baselines. The method mainly targets statistical parity via MI; could you please justify this choice against equalized odds/opportunity, and have some head-to-head comparisons (or at least rank-correlations) to fairness baselines beyond DECAF/TabFairGAN/FairGAN? \n2. Scalability/“high-dim” claims. DirPMINE is proposed for scalable MI, yet there’s no analysis of variance, sample complexity, or failure modes versus standard MINE. It would be better if authors could discuss more about runtime/memory, or stability across hyperparameters, and add confidence intervals for MI/MMD/utility.\n3. Some simple examples/simulation for intuitive insights. It would be clearer if there were any toy experiment showing: (i) how DP resampling alters the empirical distribution, (ii) how localized privacy trades utility vs. protection per column, (iii) how class balancing alone affects SP/MI vs. fairness-regularization alone. The current figures hint at effects but don’t isolate mechanisms.\n4. Datasets. The authors provide two datasets. However, I feel these two choices are rather too limited. In recent years, there've been multiple studies discussing the limitations of these two datasets (https://arxiv.org/abs/2108.04884 and https://arxiv.org/abs/2106.05498). It's more convincing if there are more datasets considered or include more discussion about the limitations of these datasets."}, "questions": {"value": "Please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "07Ez0Eu6WD", "forum": "j0czDrEnFc", "replyto": "j0czDrEnFc", "signatures": ["ICLR.cc/2026/Conference/Submission16600/Reviewer_PWAy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16600/Reviewer_PWAy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16600/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958759808, "cdate": 1761958759808, "tmdate": 1762926675810, "mdate": 1762926675810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Proposes a Bayesian–nonparametric pipeline for tabular synthetic data that jointly enforces (i) privacy via Dirichlet-process (global) and copula-based (localized) mechanisms, (ii) fairness via minimizing mutual information between outcomes and protected attributes, and (iii) class balancing by conditioning the generator on group labels; instantiated with a conditional VAE+GAN and evaluated on Adult and COMPAS."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors unified objectives across privacy–fairness–balance. BNPL resampling + MI regularizer + conditional generation is a complete solution to DP + fairness.\n2. DP analysis for a Dirichlet mechanism and localized privacy via copula-based marginals are novel in this combination."}, "weaknesses": {"value": "1. Fairness target & baselines. The method mainly targets statistical parity via MI; could you please justify this choice against equalized odds/opportunity, and have some head-to-head comparisons (or at least rank-correlations) to fairness baselines beyond DECAF/TabFairGAN/FairGAN? \n2. Scalability/“high-dim” claims. DirPMINE is proposed for scalable MI, yet there’s no analysis of variance, sample complexity, or failure modes versus standard MINE. It would be better if authors could discuss more about runtime/memory, or stability across hyperparameters, and add confidence intervals for MI/MMD/utility.\n3. Some simple examples/simulation for intuitive insights. It would be clearer if there were any toy experiment showing: (i) how DP resampling alters the empirical distribution, (ii) how localized privacy trades utility vs. protection per column, (iii) how class balancing alone affects SP/MI vs. fairness-regularization alone. The current figures hint at effects but don’t isolate mechanisms.\n4. Datasets. The authors provide two datasets. However, I feel these two choices are rather too limited. In recent years, there've been multiple studies discussing the limitations of these two datasets (https://arxiv.org/abs/2108.04884 and https://arxiv.org/abs/2106.05498). It's more convincing if there are more datasets considered or include more discussion about the limitations of these datasets."}, "questions": {"value": "Please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "07Ez0Eu6WD", "forum": "j0czDrEnFc", "replyto": "j0czDrEnFc", "signatures": ["ICLR.cc/2026/Conference/Submission16600/Reviewer_PWAy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16600/Reviewer_PWAy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16600/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958759808, "cdate": 1761958759808, "tmdate": 1763737940790, "mdate": 1763737940790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a conditional Bayesian nonparametric (BNP) framework for tabular data synthesis that aims to jointly enforce privacy, fairness, and class balance. Privacy is introduced by resampling from a Dirichlet-process posterior (a finite approximation of DP(a, H)), yielding a distributional randomization that the authors formalize as a Dirichlet mechanism with a DP guarantee on the posterior weights. Fairness is enforced by minimizing dependence between outcomes and protected attributes via a mutual-information regularizer based on a BNP variant of the Donsker–Varadhan lower bound (“DirPMINE”). Class balance is handled by conditioning the generator on protected attributes and adding a KL-to-uniform balancing term for other discrete columns. Experiments on Adult and COMPAS suggest improved fairness/utility trade-offs relative to FairGAN/DECAF while supporting non-binary sensitive attributes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper presents a unified objective that couples utility with MI-based fairness and KL-based balancing, all inside a single conditional generator (VAECGAN), which is practical for tabular data."}, "weaknesses": {"value": "1. I think there a few prior works that mention that DP-SGD can disproportionately harm minority groups via clipping + noise. But still, I don't fully understand what is the extra challenge when we consider both privacy and fairness at the same time. It would be better if the authors could address the interaction between privacy and fairness in the up front. In practice, enforcing fairness requires accurate group-conditioned statistics which DP then perturbs and budgets, especially hurting small groups; meanwhile fairness constraints can further tighten an already noisy optimization. So it’s unclear whether the proposed coupling makes the joint problem harder or sometimes acts as a helpful regularizer. To me, this paper feels like a combination of two constraints, but it is not clear how these two constraints play together. Is there any lowerbound for canonical private and fair problems like generative modeling of gaussian distributions?\n\n2. (Minor) the fonts in the plots are hard to read."}, "questions": {"value": "1. Proposition 1 defines adjacency on the probability simplex for posterior weights. How does this mapping correspond to standard record-level neighboring datasets in DP, and what guarantee applies to the atoms/locations vs. just the weights?\n2. When combining the global Dirichlet mechanism with local per-attribute privatization, what is the resulting epsilon delta after composition?\n3. Is it possible to have a plot to draw the privacy–fairness–utility curves for the trade-off?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iCeMUOicKZ", "forum": "j0czDrEnFc", "replyto": "j0czDrEnFc", "signatures": ["ICLR.cc/2026/Conference/Submission16600/Reviewer_194m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16600/Reviewer_194m"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16600/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960081615, "cdate": 1761960081615, "tmdate": 1762926674920, "mdate": 1762926674920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an approach for generating fair and private tabular data by integrating a conditional generator within the framework of Bayesian non-parametric learning. The main objective of the approach is to be able to generate synthetic data that is private, fair and balanced by leveraging a mutual information regularization term which is conditioned on the protected attributes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "-The paper is well-written and the authors have clearly reviewed the challenges associated with the generation of synthetic tabular data. The main contributions are clearly summarized and the outline of the paper is clearly described.\n\n-The proposed approach combines in an innovative way the Dirichlet process together with differentially-private mechanisms such the analytic Gaussian mechanism and randomized response to produce a new differentially-private generative model. One of the strength of the approach is can be combined with a wide range of generator-decoder models. For instance, in the current version of the paper it is implemented through a generative adversarial network combined with variational auto encoder.\n\n-Detailed investigations have been conducted on the Adult and Compas dataset demonstrating that the model is able to generate high quality data that is both privacy-preserving and fair."}, "weaknesses": {"value": "-While the literature review surveys a wide range of approaches for privacy-preserving, fair or balanced tabular data generation there are no mention of existing works at the intersection of these domains such as for instance :\n-David Pujol, Amir Gilad, and Ashwin Machanavajjhala. 2024. PreFair: Privately Generating Justifiably Fair Synthetic Data. In Proceedings of the VLDB Endowment (PVLDB), Vol. 16. https://www.vldb.org/pvldb/vol16/p1573-pujol.pdf\n-Sarmin, F. J., Rahman, A. R., Henry, C. J., & Mohammed, N. (2025). Privacy-Preserving Fair Synthetic Tabular Data. arXiv preprint arXiv:2503.02968.\nAdditionally, how the proposed approach builds on the Dirichlet mechanism from Gohari el al. 2021 should be further clarified. \n\n-The privacy budget considered are quite high and should be better justified. The privacy analysis of the approach should also integrate an analysis of the success of the privacy attacks such as membership inference to be able to assess empirically the strength of the approach provided. \n\n-One of the limit of the approach is that for now it seems limited to the statistical parity fairness metric and there is no discussion if it could easily be extended to integrates other group fairness metrics.\n\n-The figures 2 and 3 are not really visible and should be improved."}, "questions": {"value": "Please see the main points raised in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "Not applicable"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nYHf8a5DZ4", "forum": "j0czDrEnFc", "replyto": "j0czDrEnFc", "signatures": ["ICLR.cc/2026/Conference/Submission16600/Reviewer_6kYv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16600/Reviewer_6kYv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16600/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762097112492, "cdate": 1762097112492, "tmdate": 1762926673477, "mdate": 1762926673477, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Public Respond to Reviewers and AC"}, "comment": {"value": "**Dear Reviewers and AC,**\n\nWe sincerely thank you for the time, care, and thoughtful feedback you invested in reviewing our paper. We have worked very hard on the revision, and we are delighted to highlight the most important updates:\n\n* We have incorporated nearly all reviewer suggestions into the revised manuscript. All updates appear in **light blue** for ease of reference.\n* **Remark 2** has been newly added.\n* **Figure 5**, including **three new diagrams**, was added proactively (not requested) to provide clearer intuition and a more transparent explanation of the proposed approach.\n* A **new toy example** has been added, together with a substantial set of analyses designed directly to address reviewer concerns:  \n  * New **Appendix I.1**, including:  \n      * Data construction  \n      * Isolating privacy  \n          * Membership-inference attack evaluation  \n          * **Figure 6** (six plots) and **Figure 7** (seven plots) with detailed explanations  \n      * Isolating privacy and fairness  \n          * Privacy–fairness–utility trade-off plots (**Figure 8**)  \n      * Isolating class balance and fairness  \n          * **Figure 9**, containing four plots illustrating the effects of class balance and fairness on MI and SP  \n* A **MNIST toy example** has been added to **Appendix I.2** (Figures 10 and 11) to:  \n     * Visually demonstrate how the fairness constraint in our conditional generator reduces the dependence between \\(Y\\) and \\(S\\)  \n     * Illustrate how global and local privacy affect the synthetic samples  \n     * We emphasize that this example is meant only as a **visual realization** of the posterior-sampling diagram in Figure 5, as well as illustrating the fairness mechanism’s performance in reducing dependency. Digit labels are not meaningful sensitive attributes, and therefore we treat this solely as a *toy* demonstration.\n* **Dataset limitations** have been discussed and addressed, and we now reference these points explicitly in the last paragraph of the main text. We also highlight the additional **Bank Marketing dataset** analysis in Appendix I.5, which further supports the empirical discussion.\n* We have reviewed the entire manuscript and corrected some typographical issues we identified.\n\nFurther modifications and clarifications are provided in our point-by-point responses to each reviewer.\n\nOnce again, we truly appreciate the reviewers’ time and constructive suggestions, they greatly strengthened the current version of our paper.\n\n**Sincerely,  \nThe Authors**"}}, "id": "uXJxBhhQwo", "forum": "j0czDrEnFc", "replyto": "j0czDrEnFc", "signatures": ["ICLR.cc/2026/Conference/Submission16600/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16600/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission16600/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763707101883, "cdate": 1763707101883, "tmdate": 1763707101883, "mdate": 1763707101883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}