{"id": "Rr98fNjOlT", "number": 18787, "cdate": 1758290905186, "mdate": 1763493596052, "content": {"title": "LightAgent: Lightweight and Cost-Efficient Mobile Agents", "abstract": "With the advancement of multimodal large language models (MLLMs), building GUI agent systems has become an increasingly promising direction—especially for mobile platforms, given their rich app ecosystems and intuitive touch interactions. Yet mobile GUI agents face a critical dilemma: truly on-device models (4B or smaller) lack sufficient performance, while capable models (starting from 7B) are either too large for mobile deployment or prohibitively costly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose LightAgent, a mobile GUI agent system that leverages device-cloud collaboration to tap the cost-efficiency of on-device models and the high capability of cloud models, while avoiding their drawbacks. Specifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT→GRPO training on synthetic GUI data for strong decision-making, integrates an efficient long-reasoning mechanism to utilize historical interactions under tight resources, and defaults to on-device execution—only escalating challenging subtasks to the cloud via real-time complexity assessment. Experiments on the online AndroidLab benchmark and diverse apps show LightAgent matches or nears larger models, with a significant reduction in cloud costs.", "tldr": "", "keywords": ["GUI Agent", "LLM", "Reinforcement Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e619ad5c5364799218ca2f327bd6063cd0873441.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes LightAgent, a lightweight yet capable mobile GUI agent that uses device–cloud collaboration to balance performance and computational cost. The authors enhance a Qwen2.5-VL-3B model via a two-stage SFT and GRPO training pipeline on synthetic GUI reasoning data. They propose an efficient reasoning template with history summarization and introduce a dynamic switching mechanism that delivers complex subtasks to a cloud LLM only when needed. Experiments on the AndroidLab benchmark and real Android apps show that LightAgent achieves competitive performance while significantly reducing cloud API usage and latency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Practical problem relevance. The paper addresses an important and rapidly growing problem: building mobile GUI agents that operate within strict computing budgets. Despite the paper’s limitations, the motivation and problem framing are valid and meaningful to the agent community.\n\n2. Non-trivial engineering effort with a complete pipeline. This paper implements an end-to-end device-cloud collaborative agent system, including task complexity assessment and a dynamic switching mechanism. The evaluation on the AndroidLab benchmark is conducted in an online manner, making execution closer to real-world deployment."}, "weaknesses": {"value": "1. Limited novelty; mainly a system integration effort. The paper primarily combines existing components including synthetic data generation, GRPO training, CoT-style reasoning templates, and device–cloud fallback. The claimed “device–cloud collaboration framework” is a system-level architecture rather than a methodological innovation, and similar fallback or hybrid execution has been explored before [1].\n2. Heavy reliance on the cloud despite “edge-first” positioning. Despite being presented as an edge-prioritized system, LightAgent still requires cloud offloading for roughly 65% of steps according to its own analysis. This suggests that the 3B base model is still insufficiently capable as an autonomous agent and depends strongly on the cloud model to complete tasks. The paper does not analyze failure cases in offline or no-cloud settings. \n3. Lack of experimental clarity in early figures. Figure 4 reports a comparative performance plot between on-device and cloud models but provides no information regarding the dataset. It is unclear whether results are based on AndroidLab or another benchmark.\n4. Experimental evaluation is narrow and insufficient. The paper only evaluates on AndroidLab and a small set of four Android apps, despite the existence of established GUI agent benchmarks. It ignores offline navigation benchmarks such as GUI-Odyssey and AndroidControl, and does not compare on the standard online benchmark AndroidWorld. This limited evaluation scope makes it unclear whether the method generalizes beyond the narrow AndroidLab setting, and misses critical comparisons that would strengthen claims regarding generality and effectiveness in both offline and online environments.\n5. Limited real-device evaluation weakens “mobile agent” claim. All experiments are performed on GPUs (NVIDIA RTX 3090) rather than real mobile hardware. The paper does not provide inference latency, peak memory usage, or thermal behavior on actual smartphones. Without demonstrating real on-device deployment, it is premature to claim that the model is suitable for mobile usage.\n\n[1] Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks."}, "questions": {"value": "1. What is the size and nature of the synthetic dataset? The dataset design is claimed as a main contribution, but the paper does not report the dataset scale or other details. \n2. The system is evaluated only on Android GUI agents. Do the authors expect their approach to generalize to other platforms like Web, Windows desktop workflows, or iOS? If so, what components are platform-specific?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TDdfgjyscm", "forum": "Rr98fNjOlT", "replyto": "Rr98fNjOlT", "signatures": ["ICLR.cc/2026/Conference/Submission18787/Reviewer_Xhty"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18787/Reviewer_Xhty"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18787/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828153404, "cdate": 1761828153404, "tmdate": 1762999994442, "mdate": 1762999994442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces light agent for on-device GUI agent to help real-world deployment. To improve the performance, they introduce the on-device and cloud-based agent to collaborate. They introduce two-stage training for the on-device agent and a collaborate control framework to decide if switch to cloud-based agent. They carry out experiment on AndroidLab.\n\nThis paper tries to address an important problem for on-device deployment GUI agent, my concerns are mainly in (details see questions and weakness):\nA.\tThe novelty: SFT and GRPO training of GUI agent, as well as their design of implementing these two modules, are not new.\nB.\tExperiment only on one dataset and lack important comparisons with other 3B-4B models. \nC.\tThe efficiency lack important evidence, especially the additional cost of cloud LLMs in monitoring the on-device agent ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1, The paper is clearly and logically structured, making the content highly accessible and easy to follow.\n2, The integration of on-device and cloud LLMs represents a promising approach that could significantly accelerate the industrial deployment of GUI agents.\n3, The author provided sufficient implementation details, including the specific prompts, which greatly facilitates the understanding of the individual modules.\n4, The breakdown of step percentages across the on-device and cloud models is valuable, as it effectively quantifies the source of efficiency improvements."}, "weaknesses": {"value": "1, Lack of evidence to demonstrate the necessity of finetuning on-device agent with the proposed two step strategies. A direct evidence would be comparing with other 3B models like Qwen2.5-VL-3B under w and w/o Cloud LLM setups.\n2, Lack of discussion of the accuracy of the two modules in collaborative control frameworks. From A.4.2 and A.4.3, it seems priors on task complexity are provided in the prompts, but where do these priors come from and how to collect for other apps/tasks are not clear.\n3, Additional Cloud-based agents are involved before the model is switched to cloud models in deciding/ monitoring the on-device agent.  But their cost seems not counted as part of the cloud cost, especially in Figure 6.\n4, Experiment only carried out on one AndroidLab dataset, while others such as Android World[a] and offline datasets such as Android control[b] is not compared.\n[a]AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents\n[b] On the Effects of Data Scale on Computer Control Agents"}, "questions": {"value": "1, Could the author provide the additional cloud-agent costs associated with the two modules: task complexity determination and model monitoring? What is the average number of calls to the cloud agent within these two modules? This information would help in understanding the true cost by integrating the cloud-agent cost into Figure 6.\n2, Could the author discuss the motivation for employing the two-step training process described in Section 2.1, particularly in comparison to other methods? Reasoning or history understanding is a shared strategy in current works (e.g., M3A[a], UI-Tars).\n3, Could the authors provide the average number of steps required to complete tasks under the on-device only, cloud LLM only, and on-device with cloud LLM configurations/settings? The average number of steps is an important criterion for evaluating efficiency. How many cloud LLM calls are made in each setup?\n4. Would the cloud LLMs over write the previous progress by some actions such as Home() and the effort of the on-device agent is ignored?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GhmAAN6wZ2", "forum": "Rr98fNjOlT", "replyto": "Rr98fNjOlT", "signatures": ["ICLR.cc/2026/Conference/Submission18787/Reviewer_kqzB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18787/Reviewer_kqzB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18787/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761844473484, "cdate": 1761844473484, "tmdate": 1762999994405, "mdate": 1762999994405, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper designs a device-cloud collaboration framework to solve mobile\ninteraction tasks efficiently and effectively. The exhibited results are\npromising. However, the paper is not perfectly polished, holds obvious symbol\ninconsistency and typos."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper studies a valuable problem, device-cloud collaborative GUI agent,\n  balancing the invocation cost and overhead with the execution performance.\n2. The exhibited results look promising."}, "weaknesses": {"value": "1. In the proposed execution flow, the active model will not switch back to the\n   on-device model after switching to the cloud model. Why isn't a switch-back\n   mechnism integrated?"}, "questions": {"value": "1. The monitoring starting step is denoted by $\\tau$ on Line 211, but $\\gamma$\n   in Algorithm 1.\n2. Symbols tau in Algorithm 1 is not used. Symbol T in Algorithm 1 is not\n   introduced.\n3. What model is used for task complexity assessment and dynamic orchestration\n   policy?\n4. What is $R_{acc}$ and $R_{fmt}$ in Equation 4?\n5. How is $k$ computed in Equation 4?\n6. The letter cases in Table 1 are not consistent.\n7. The device-cloud model combinations in Table 1 and Figure 6(a) are not\n   consistent? Why does this occur? Are the success rates of combinations like\n   ours+GLM-4.5-V not satisfactory enough to demonstrate the validity of the\n   proposed method? Is the step percentage of Gemini-2.5-Pro too high to be\n   shown in Figure 6(a)?\n8. What's the meaning of SN in Table 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CDNHDoIi8O", "forum": "Rr98fNjOlT", "replyto": "Rr98fNjOlT", "signatures": ["ICLR.cc/2026/Conference/Submission18787/Reviewer_67Au"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18787/Reviewer_67Au"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18787/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996559274, "cdate": 1761996559274, "tmdate": 1762999994448, "mdate": 1762999994448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets a very real bottleneck in mobile GUI agents: small on-device MLLM/VLMs (≈3B) can run locally but are too weak to finish real Android tasks, while cloud LLM/VLM calls are accurate but expensive and latency-sensitive. The goal is to push a 3B open model to be “good enough” for most steps, and only escalate to cloud on hard steps, so that mobile agents become practically deployable."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- Clear decomposition of cost: SFT+GRPO makes the 3B model more reliable; the scheduler makes cloud use predictable; the switch makes it robust.\n- Data generation pipeline: using stronger models to auto-generate GUI episodes with CoT and tool-calls is sensible for this domain."}, "weaknesses": {"value": "- No direct comparison to other 3B GUI-R1 / GUI-G1–style models, e.g., GUI-R1, \"GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents\"; GUI-G1, \"GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents\": the authors compare to larger/stronger or clouded agents on AndroidLab, but not to concurrent 3B R1-like GUI agents, so the “3B is competitive after GRPO” claim is only relative to the chosen baselines. This is the biggest missing experiment.\n- Scheduler is rule/LLM–driven: good engineering, but not theoretically grounded; if app distributions shift, $\\gamma/\\omega$ may need re-tuning.\n- Reliance on AndroidLab: results are shown on one environment; it would be stronger to show that the device–cloud policy transfers to more dynamic benchmarks (e.g., SPA-Bench)."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cVQrRWFK0y", "forum": "Rr98fNjOlT", "replyto": "Rr98fNjOlT", "signatures": ["ICLR.cc/2026/Conference/Submission18787/Reviewer_v4Cz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18787/Reviewer_v4Cz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18787/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019695436, "cdate": 1762019695436, "tmdate": 1762999994417, "mdate": 1762999994417, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}