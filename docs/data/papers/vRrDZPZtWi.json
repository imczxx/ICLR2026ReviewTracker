{"id": "vRrDZPZtWi", "number": 17071, "cdate": 1758271822381, "mdate": 1763438385258, "content": {"title": "SDDuSR: Sparse Feature Matching and Token Dictionary Learning for  Dual-Lens Super-Resolution", "abstract": "Dual-Lens Super-Resolution (DuSR) is an application of Reference-based image Super-Resolution (RefSR) in real-world scenarios. Unlike RefSR, DuSR uses the telephoto image as the high-resolution reference image (Ref) and the wide-angle image as the low-resolution image (LR), where LR and Ref share the field of view (FoV) within a certain area. Then, the Ref image is used to assist the LR image in super-resolution. The existing DuSR methods all employ dense feature matching and warping operation to identify and transfer the high-resolution features of the Ref image to the LR image. However, this approach has two key issues: (1) the smooth low-frequency regions in the LR image can achieve good visual effects without any reference, which leads to significant computational redundancy caused by dense feature matching, and (2) due to the inherent limitations of the warping operation, it is not possible to fully utilize the high-resolution features of the Ref image. To address these issues, we propose a DuSR method based on Sparse Feature Matching and Token Dictionary Learning, called SDDuSR. Specifically, we introduce a mask generator to separate the high-frequency regions from the low-frequency regions of the image, and perform feature matching only on the high-frequency regions, which significantly reduces the computational load during the feature matching stage. Moreover, to fully utilize the features of the Ref image, we abstract it into a token dictionary and employ a dictionary learning strategy to assist the LR image in super-resolution. Extensive experiments have demonstrated that our method achieves state-of-the-arts (SOTA) performance in both quantitative and qualitative aspects.", "tldr": "", "keywords": ["Reference-based Image Super-Resolution", "Dual-Lens Super-Resolution", "Sparse Feature Matching", "Dictionary Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1039247b3166a7bf2d4428c1a461af97b083ff4c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SDDuSR, a Dual-Lens Super-Resolution method that improves efficiency and feature utilization compared to existing DuSR approaches. Instead of dense feature matching and warping, the method performs sparse feature matching only in high-frequency regions using a mask generator, and leverages token dictionary learning to better transfer high-resolution information from the reference image. Experiments show that SDDuSR achieves superior quantitative and qualitative performance over state-of-the-art methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper proposes a well-motivated combination of sparse feature matching and token dictionary learning, which effectively addresses both the computational redundancy and feature utilization limitations in existing DuSR approaches.\nThe paper integrates several components (mask generator, flow-guided alignment, deformable convolution, and token dictionary learning) in a coherent and technically sound framework. The method is rigorously designed, with strong mathematical formulation and empirical validation."}, "weaknesses": {"value": "While the overall framework is interesting, several core components are standard techniques. The originality mainly lies in their integration rather than in new algorithmic contributions."}, "questions": {"value": "1.\tWhile the effect of token number N is explored, the paper does not analyze why larger dictionaries degrade performance or what semantic structures tokens capture.\n2.\tHave the authors analyzed what patterns or structures the token dictionaries learn? Visualizing token attention or diversity could enhance understanding.\n3.\tHow does SDDuSR perform under misaligned or low-light conditions? Could the authors discuss the robustness of SFM and TDL in such scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5YkZqSVAUF", "forum": "vRrDZPZtWi", "replyto": "vRrDZPZtWi", "signatures": ["ICLR.cc/2026/Conference/Submission17071/Reviewer_4EAa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17071/Reviewer_4EAa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821936102, "cdate": 1761821936102, "tmdate": 1762927080367, "mdate": 1762927080367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses two major challenges in dual-camera super-resolution (DuSR): computational redundancy and insufficient utilization of reference features. The authors propose an innovative framework called SDDuSR, which integrates Sparse Feature Matching (SFM) and Token Dictionary Learning (TDL). The SFM module employs a mask generator to dynamically identify high-frequency detail regions and performs feature matching only within these regions, thereby reducing computational complexity. The TDL module maintains an online-updatable token dictionary, enabling the model to overcome the rigidity of conventional deformation operations and to reconstruct fine details from richer feature priors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The SFM module introduces a novel perspective for DuSR tasks — focusing on high-frequency regions only, without causing significant performance degradation.\n2.The paper is well-structured, clearly written, and the formulas are easy to follow."}, "weaknesses": {"value": "1. The novelty is incremental. The ideas of SFM and TDL are not new strategies.\n2 The experimental results are not convincing. One of the core contributions of this paper is using sparse feature matching to reduce dense computation in the spatial dimension. However, the proposed TDL itself is dense computation. Specifically, in the learning stage of TDL, each low-resolution feature vector needs to calculate the similarity with every token in the dictionary to produce an attention map. This is essentially a kind of global dense matching in the feature dictionary dimension, and the redundancy problem does not seem to be solved. It may even make the proposed method less efficient than traditional dense matching methods.\n3. It is suggested to compare the overall computational efficiency of the model with other methods, such as KeDuSR, to prove the efficiency of the proposed model, instead of only discussing the efficiency gain brought by the SFM module. In addition, adding more metrics such as runtime and memory usage can more comprehensively demonstrate the efficiency of SDDuSR .\n4. It is suggested to analyze the sparsity of the mask generated in SDDuSR-rec, which corresponds to using only the reconstruction loss Lres. Because without the Lmask constraint, the mask values may become all 1, which would degenerate into dense feature matching, and SFM would lose its essential function.\n5. In Fig. 2(a), ILR and IRef are the wide-angle image and the telephoto image, respectively, but the two images have the same field of view (FOV), which is confusing.\n6The mask generator of SFM relies on a threshold, yet it’s unclear how robust this heuristic is across different datasets or content types.\n7.Relative to KeDuSR, SDDuSR lacks explicit quantitative comparison on Center-Image regions (Table 1 reports partial metrics for KeDuSR but lacks direct Center-Image PSNR/SSIM comparisons with SDDuSR).\n8.Compared with KeDuSR, the visual improvement of SDDuSR is marginal and occasionally exhibits detail smoothing, which contradicts the claimed effectiveness of TDL in enriching texture details."}, "questions": {"value": "1.What is the quantitative statistics on the mask generator output, such as mean/variance of high-frequency regions kept per image for various datasets and settings? Or can the authors provide the results compared to other adaptive modules?\n3.What is the quantitative comparison on Center-Image regions?\n4.Why are there the observed detail smoothing phenomenon and  why does TDL fail to synthesize sharper textures in these cases?\nOther question see Weakness 2,3,4."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JbHTRHZpA5", "forum": "vRrDZPZtWi", "replyto": "vRrDZPZtWi", "signatures": ["ICLR.cc/2026/Conference/Submission17071/Reviewer_1p2t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17071/Reviewer_1p2t"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881233486, "cdate": 1761881233486, "tmdate": 1762927079913, "mdate": 1762927079913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Dual-Lens Super-Resolution (DuSR) framework named SDDuSR, which integrates Sparse Feature Matching (SFM) and Token Dictionary Learning (TDL) to address two major limitations of existing DuSR methods: computational redundancy in dense matching and incomplete utilization of reference features. Specifically, a mask generator distinguishes high- and low-frequency regions, allowing feature matching only in high-frequency areas to reduce redundant computation. Meanwhile, the TDL module abstracts reference features into token dictionaries and employs cross-attention to transfer high-resolution priors to the low-resolution image. Experiments on multiple real-world DuSR datasets show its effectiveness to some extent."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-motivated. The proposed SFM effectively reduces redundant computation by focusing on high-frequency regions without performance degradation, while the TDL module captures higher-level semantic priors and overcomes the rigidity of traditional warping operations."}, "weaknesses": {"value": "1. In Section 3.1, the fusion of SFM and TDL features relies on simple concatenation and convolutional fusion; more interpretable or adaptive fusion strategies could be explored.\n\n2. In Section 3.3, the TDL design lacks a detailed analysis of key parameters such as update frequency, and attention layer depth.\n\n3. The experiments mainly report PSNR, SSIM, and LPIPS metrics, but do not provide efficiency indicators such as runtime, parameter count, or inference speed.\n\n4. In Section 4.5, the experiment only demonstrates the computational savings of SFM relative to DFM, while omitting the computational cost of the TDL module. To substantiate the claim that \"the overall computing load is almost unchanged,\" it is recommended to provide the total GFLOPS or latency for the entire SDDuSR model (which includes TDL) and present a fair comparison against SOTA methods like KeDuSR.\n\n5. In Section 3.1, the text states, “In the updating phase, the features of F^LRC and F^Refare updated into D^LRC and D^Ref”，however, according to Fig. 2 and the description in Section 3.3, F^Ref should be F_align^Ref.\n\n6. In 3 Methodology, there are too many abbreviations and symbol definitions, which negatively affect the readability."}, "questions": {"value": "1.Will the mask generator misclassify complex texture regions, thereby causing the omission of high-frequency features?\n\n2.SFM reduces the computational load by about 30%, but is the actual speed improvement consistent across GPU platforms?\n\n3.Could more visualizations (such as mask heatmaps and attention distributions of the feature dictionary) be added to aid understanding?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PGowX2Dl2D", "forum": "vRrDZPZtWi", "replyto": "vRrDZPZtWi", "signatures": ["ICLR.cc/2026/Conference/Submission17071/Reviewer_43qp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17071/Reviewer_43qp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968119707, "cdate": 1761968119707, "tmdate": 1762927078985, "mdate": 1762927078985, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}