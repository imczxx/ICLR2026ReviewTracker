{"id": "gX42SSbjcC", "number": 2142, "cdate": 1756996638644, "mdate": 1763649973330, "content": {"title": "FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation", "abstract": "Small Language Models (SLMs) are attractive for cost-sensitive and resource-limited settings due to their efficient, low-latency inference. However, they often struggle with complex, knowledge-intensive tasks that require structured reasoning and effective retrieval. To address these limitations, we propose FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from large language models (LLMs). FutureMind introduces a dynamic reasoning pipeline composed of four key modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. This pipeline is augmented by three distinct retrieval paradigms that decompose complex queries into tractable subproblems, ensuring efficient and accurate retrieval execution. Extensive experiments on multi-hop QA benchmarks, including 2WikiMultihopQA, MuSiQue, Bamboogle, and Frames, demonstrate the superiority of FutureMind. It consistently outperforms strong baselines such as Search-o1, achieving state-of-the-art results under zero-training conditions across diverse SLM architectures and scales. Beyond empirical gains, our analysis reveals that the process of thinking-pattern distillation is restricted by the cognitive bias bottleneck between the teacher (LLMs) and student (SLMs) models. This provides new perspectives on the transferability of reasoning skills, paving the way for the development of SLMs that combine efficiency with genuine cognitive capability.", "tldr": "We introduce FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from LLMs.", "keywords": ["Small Language Models", "Adaptive Knowledge Distillation", "Thinking Pattern"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b2d8bd0ec349f35d7eb790e130fc903778c9d75.pdf", "supplementary_material": "/attachment/923c8383bbe4112a72055d526e9debb9f2937434.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes FutureMind, a training-free four-stage framework with Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. Experimental results demonstrate the effectiveness of the proposed method on four multiple-hop question answering datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method is intuitive and well-elaborated.\n2. The proposed method demonstrates effectiveness and generalizability on four multi-hop QA datasets, using LLMs of different series and sizes."}, "weaknesses": {"value": "1. This paper claims to be \"a new state of the art among training-free methods\", but only Naive Generation, Standard RAG, and Search-o1 are compared, ignoring various baselines on inference-time scaling methods and training-free LLM frameworks.\n2. Section 4.1 Datasets: \"we randomly sample 500 instances from the validation sets of 2WikiMQA and MuSiQue\". However, 2Wiki has about 12.6k validation instances, and MuSiQue has 2.4k validation instances. Sampling only 500 per dataset here is too limited.\n3. Section 4.4 Ablation Studies: This part only shows the ablation of different strategies in the \"Strategy Planning\" module. However, it is even more important to investigate the ablation of each module/stage, i.e., Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance.\n4. The proposed method utilizes more inference-time computing, but an efficiency study is lacking."}, "questions": {"value": "**Questions**:\n1. Section 4.1 Metrics: What exactly is the formula of $ACC_{E}$?\n\n**Suggestions**:\n1. It is suggested to mention the reason for naming the proposed method as \"FutureMind\" in the paper.\n2. It is suggested to include the costs of calling the LLM judge and Google Search API.\n3. Line 84: \"training-free\" or \"inference-only\" sounds better to me, as \"zero-training-cost\" can be ambiguous: it could be a process without training OR a process with some zero-cost \"training\".\n4. Line 467 \"As shown in Table 1 and Table 4\": As Table 1 is on Page 7 and Table 4 is on Page 9, it would be better to present the performance changes ($\\Delta$ ACC) in Table 4, or illustrate the differences using bar charts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KP4iZJzyik", "forum": "gX42SSbjcC", "replyto": "gX42SSbjcC", "signatures": ["ICLR.cc/2026/Conference/Submission2142/Reviewer_xqBy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2142/Reviewer_xqBy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761543474857, "cdate": 1761543474857, "tmdate": 1762916047331, "mdate": 1762916047331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present **FutureMind**, a training-free modular reasoning framework designed to enhance the reasoning and retrieval capabilities of small language models (SLMs). FutureMind leverages a large language model (LLM) as a planner that guides the SLM through multi-hop reasoning tasks. The framework comprises four modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. Through experiments on several multi-hop QA benchmarks, using models from the `Qwen2.5` and `Llama3.1` families, the authors demonstrate that FutureMind achieves state-of-the-art performance among training-free methods. They also find that naively increasing the size of the LLM planner does not necessarily yield better results, highlighting the importance of compatibility between planner and reasoning models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The main idea of the paper is interesting and has clear merit. Leveraging larger LMs to guide smaller ones during multi-hop reasoning is a natural and well-motivated direction. The method is also training free, something that showcases its efficiency and potential to be deployed.\n- The experimental results are promising. Across all model scales, integrating FutureMind consistently outperforms the other baselines in almost all cases, which highlights its potential.\n- The ablation study in Section 4.4 provides further evidence supporting FutureMind’s design, as removing any of the considered retrieval strategies from the planner leads to performance degradation across benchmarks."}, "weaknesses": {"value": "- I think that the way each module is presented in Section 3, although detailed, is unnecessarily abstract and ends up confusing the reader instead of describing the modules clearly. Also, many parts are not adequately explained (such as what exactly is function $\\mathcal{F}$), and there is a gap between the high-level overview of each module, and the actual implementation (for instance, it is not clear how the authors prompt the larger LM at each step of the pipeline). \n\t- A suggestion could be to move the instructions of Appendix E.5 to the main body of the paper, and move the more abstract definitions to the Appendices, (for completeness only).\n- I am not sure whether I agree with the author's conclusions regarding the \"cognitive bias bottleneck\". I wouldn't describe FutureMind as a form of \"knowledge distillation\", nor as \"lossy compression\". I believe that the main observations of Table 2 can be attributed to the *capability gap* of the SLM and the planner LLM: the planner, being more capable compared to the reasoning SLM, generates a plan that overestimates the capabilities of the SLM. Thus, I am not sure whether one can claim that \"noise is amplified during knowledge distillation\"."}, "questions": {"value": "- Are the instructions of Appendix E.5 the exact prompts used?\n- Could you clarify why the method is described as a form of knowledge distillation? From the paper, it appears that the large LM serves primarily as a planner for the smaller model, rather than transferring knowledge in the conventional sense."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Dh9GlDmvFM", "forum": "gX42SSbjcC", "replyto": "gX42SSbjcC", "signatures": ["ICLR.cc/2026/Conference/Submission2142/Reviewer_t5P7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2142/Reviewer_t5P7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796944033, "cdate": 1761796944033, "tmdate": 1762916047069, "mdate": 1762916047069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a framework named FutureMind, which enables SLMs to inherit the strategic planning capabilities of LLMs through a clever \"thinking paradigm distillation.\" This allows SLMs to efficiently solve complex reasoning tasks without additional training. The work presents a unique perspective, and the experimental results are solid."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The most interesting aspect of this work is its redefinition of knowledge distillation. While traditional distillation often involves the student mimicking the teacher's trajectory, FutureMind empowers the student to master the teacher's structured thinking framework.\n    \n2. The experimental results reveal that an overly complex plan can become a barrier to the SLM's understanding and execution. This is a counter-intuitive and interesting phenomenon, for which the authors have provided a corresponding explanation.\n    \n3. The framework's design is exceptionally clear. It delegates the planning task to the more capable LLM while assigning the relatively simpler execution task to the efficient SLM, offering a plug-and-play solution."}, "weaknesses": {"value": "1. I would like to ask the authors if they have considered or attempted to use more direct metrics to quantify or predict the \"cognitive compatibility\" between teacher and student models, beyond observing final performance in experiments. For instance, could the distillation effectiveness be anticipated by analyzing the relationship between the complexity of the teacher's plan and the capability limits of the student model?\n    \n2. The experiments in this paper are primarily focused on structured, multi-hop question-answering tasks, where the FutureMind's P-L-S-R process excels. I am interested in the authors' views on the framework's potential in more open-ended and creative tasks, such as code generation. In such tasks, the \"critical conditions\" and \"logical sequence\" of a problem may be less explicit. Would FutureMind's structured planning still be applicable, or would it require adjustments?\n    \n3. I have a concern that FutureMind makes a premature and irrevocable commitment to an entire logical path before any actual evidence is gathered. This contrasts with the exploratory and iterative methodology employed by LLMs in \"thinking\" mode, and indeed by human experts, when solving complex problems. For example, when faced with a problem that has a vast search space or high ambiguity, a seemingly reasonable initial plan could prove disastrous during execution. Consider the question: \"Who is the poet that was a friend of the author of 'One Hundred Years of Solitude' and also won a Nobel Prize?\"\n    \n    - A powerful teacher model would likely generate a seemingly perfect \"forward\" plan based on the literal structure of the question: [1. Identify the author of 'One Hundred Years of Solitude' (Gabriel García Márquez) -> 2. Retrieve all his friends -> 3. Filter for poets from the list of friends -> 4. Verify which poet won a Nobel Prize].\n        \n    - However, this plan would likely fail at the second step. García Márquez's social circle was extremely wide, making the task of retrieving \"all his friends\" nearly impossible and likely to return a massive amount of irrelevant information, rendering subsequent steps ineffective.\n        \n    - A monolithic LLM with dynamic correction capabilities, upon observing that the result set from the second step is too large, could immediately abandon the original path and adopt a more optimal backward strategy.  \n        Does FutureMind risk losing this flexibility to optimize strategy mid-reasoning due to this characteristic?"}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NNlriq4B8y", "forum": "gX42SSbjcC", "replyto": "gX42SSbjcC", "signatures": ["ICLR.cc/2026/Conference/Submission2142/Reviewer_4F63"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2142/Reviewer_4F63"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762437274318, "cdate": 1762437274318, "tmdate": 1762916046572, "mdate": 1762916046572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a framework named FutureMind, which enables SLMs to inherit the strategic planning capabilities of LLMs through a clever \"thinking paradigm distillation.\" This allows SLMs to efficiently solve complex reasoning tasks without additional training. The work presents a unique perspective, and the experimental results are solid."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The most interesting aspect of this work is its redefinition of knowledge distillation. While traditional distillation often involves the student mimicking the teacher's trajectory, FutureMind empowers the student to master the teacher's structured thinking framework.\n    \n2. The experimental results reveal that an overly complex plan can become a barrier to the SLM's understanding and execution. This is a counter-intuitive and interesting phenomenon, for which the authors have provided a corresponding explanation.\n    \n3. The framework's design is exceptionally clear. It delegates the planning task to the more capable LLM while assigning the relatively simpler execution task to the efficient SLM, offering a plug-and-play solution."}, "weaknesses": {"value": "1. I would like to ask the authors if they have considered or attempted to use more direct metrics to quantify or predict the \"cognitive compatibility\" between teacher and student models, beyond observing final performance in experiments. For instance, could the distillation effectiveness be anticipated by analyzing the relationship between the complexity of the teacher's plan and the capability limits of the student model?\n    \n2. The experiments in this paper are primarily focused on structured, multi-hop question-answering tasks, where the FutureMind's P-L-S-R process excels. I am interested in the authors' views on the framework's potential in more open-ended and creative tasks, such as code generation. In such tasks, the \"critical conditions\" and \"logical sequence\" of a problem may be less explicit. Would FutureMind's structured planning still be applicable, or would it require adjustments?\n    \n3. I have a concern that FutureMind makes a premature and irrevocable commitment to an entire logical path before any actual evidence is gathered. This contrasts with the exploratory and iterative methodology employed by LLMs in \"thinking\" mode, and indeed by human experts, when solving complex problems. For example, when faced with a problem that has a vast search space or high ambiguity, a seemingly reasonable initial plan could prove disastrous during execution. Consider the question: \"Who is the poet that was a friend of the author of 'One Hundred Years of Solitude' and also won a Nobel Prize?\"\n    \n    - A powerful teacher model would likely generate a seemingly perfect \"forward\" plan based on the literal structure of the question: [1. Identify the author of 'One Hundred Years of Solitude' (Gabriel García Márquez) -> 2. Retrieve all his friends -> 3. Filter for poets from the list of friends -> 4. Verify which poet won a Nobel Prize].\n        \n    - However, this plan would likely fail at the second step. García Márquez's social circle was extremely wide, making the task of retrieving \"all his friends\" nearly impossible and likely to return a massive amount of irrelevant information, rendering subsequent steps ineffective.\n        \n    - A monolithic LLM with dynamic correction capabilities, upon observing that the result set from the second step is too large, could immediately abandon the original path and adopt a more optimal backward strategy.  \n        Does FutureMind risk losing this flexibility to optimize strategy mid-reasoning due to this characteristic?"}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NNlriq4B8y", "forum": "gX42SSbjcC", "replyto": "gX42SSbjcC", "signatures": ["ICLR.cc/2026/Conference/Submission2142/Reviewer_4F63"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2142/Reviewer_4F63"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762437274318, "cdate": 1762437274318, "tmdate": 1763701008803, "mdate": 1763701008803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Appreciation and Overall Response."}, "comment": {"value": "&emsp; We sincerely thank all reviewers for their time, constructive feedback, and insightful suggestions. We have carefully addressed every comment and revised the manuscript accordingly. **A improved version of the paper has now been uploaded.** We kindly invite the reviewers to read our responses in conjunction with the revised manuscript, as this will provide clearer context and help illustrate how each concern has been resolved.\n\n&emsp; We deeply appreciate the reviewers’ efforts in helping us strengthen the clarity, technical soundness, and we look forward to further feedback from the reviewers."}}, "id": "vZDD7deB7D", "forum": "gX42SSbjcC", "replyto": "gX42SSbjcC", "signatures": ["ICLR.cc/2026/Conference/Submission2142/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2142/Authors"], "number": 19, "invitations": ["ICLR.cc/2026/Conference/Submission2142/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763706187113, "cdate": 1763706187113, "tmdate": 1763706205835, "mdate": 1763706205835, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}