{"id": "zijZ40pBbV", "number": 7086, "cdate": 1758007180670, "mdate": 1763710954318, "content": {"title": "Data Diversity for Compositional Generalization", "abstract": "Human cognition excels at understanding complex concepts by combining simpler, learned elements, enabling efficient learning and generalization to novel scenarios.\nRecent work suggests that machine learning models may exhibit a similar capability, generalizing to novel scenarios by first acquiring fundamental components and then recombining them.\nData serves as the driving force behind this process, and the diversity of training data plays a crucial role in shaping a model's ability to generalize.\nIn this work, we introduce a framework that disentangles the multifaceted notion of diversity and formalize its impact on model performance and generalization ability from different perspectives.\nThrough both theoretical analysis and empirical validation, we demonstrate that increasing diversity without a principled strategy does not necessarily lead to optimal generalization ability.\nInstead, a deeper understanding of data diversity is required.\nBuilding on this insight, we propose a high-level guideline for dataset designing and preparing that facilitate more efficient learning and enable improved generalization to unseen compositions.", "tldr": "", "keywords": ["diversity", "data-centric AI", "compositionality"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1f40f5d64b4dc0adb681ffa9fe25cf62f67db0dc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies the two data dimensionalities of semantic diversity and structural diversity individually, with Rademacher complexity and covering numbers as theoretical tools, respectively. The experiments on synthetic datasets and real-world datasets with fixed data budget confirm the theoretical findings and provide insights like the importance of a principled strategy with respect to data diversity to improve compositional generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The theoretical findings, e.g., bounds of generalization, are sound. The formulations are well-defined and tools are established (i.e., Rademacher complexity and covering numbers), though there are some typos. \n- The experiments on datasets, including synthetic datasets and real-world datasets, are comprehensive and the conclusions are insightful."}, "weaknesses": {"value": "- The theoretical results still hinge on the validity of the assumptions. The embedding of all compositional functions into a d-dimensional Euclidean space. How well does this idealized geometry capture the true \"conceptual space\" of real-world problems? If the training structural combinations are confined to a narrow space in this d-dimensional space, the generalization performance is expected to be very low (i.e., a large radius $\\epsilon$ to cover all possible combinations). \n- The scope of this work is limited to algebraic circuits. Thus, only structural and semantic diversities are considered, which, based on my understanding, refer to \"how different the training samples are\" and \"how many combinations are in each structure\". The contribution could be further improved by generalizing the ideas to other mathematical settings, which may introduce other types of composlitionality. \n- As pointed out by the author, the equation 5 ignores the potential coupling interactions. How does this correlation affect the generalization error?  \n- There are some typos in the equations, e.g., in line 215, $|\\phi(c_1)-\\phi(x_2)|$ should be $|\\phi(c_1)-\\phi(c_2)|$."}, "questions": {"value": "- Why in figure 4 and 5, M is small (i.e., the maximum examined M is 5), compared with figure 3 (i.e., the minimum examined M is 10)? What happens when M is 10 for GPT-2-XL and Mistral? What will the figure change if increasing the data budget from 4500 to a larger value like 10000?\n- I am curious about the impact of different training strategies. If using parameter-efficient tuning instead of fine-tuning, will the effects of the two types of diversity be different?​​\n- Why is it necessary to define $s(\\cdot)$ as the sub-circuit in $c(\\cdot)$? This notation seems not to be used in the rest of this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MoIOUlwm05", "forum": "zijZ40pBbV", "replyto": "zijZ40pBbV", "signatures": ["ICLR.cc/2026/Conference/Submission7086/Reviewer_JbLv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7086/Reviewer_JbLv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761144687474, "cdate": 1761144687474, "tmdate": 1762919265942, "mdate": 1762919265942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the role of *compositional generalization* under limited data budgets and introduces a theoretical framework that decomposes data diversity into two orthogonal dimensions: **semantic diversity (M: component variations)** and **structural diversity (N: compositional variations)**. The authors provide generalization bounds for intra- and inter-compositional learning and propose an optimal allocation strategy between M and N. The theoretical claims are validated on synthetic algebraic circuit datasets using both Transformers and large language models (e.g., GPT-2-XL, Mistral 7B), and further extended to real-world reasoning tasks such as GSM8K."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is generally well-structured, and the exposition is clear enough to follow the main ideas.\n\nThe theoretical formulation provides a reasonable attempt to justify the proposed perspective."}, "weaknesses": {"value": "Several important related works on compositionality and LLM-based structure-sensitive generalization are missing. For example:\n\t•\t“Compositional Semantic Parsing with Large Language Models” (ICLR 2023)\n\t•\t“Does Data Scaling Lead to Visual Compositional Generalization?” (ICML 2025).\n\nThe evaluation is limited to GSM8K, which is a relatively shallow reasoning dataset where compositional structure is implicitly assumed rather than explicitly grounded. Thus, it remains unclear whether the observations hold in more rigorous compositional benchmarks (e.g., SCAN, COGS, PCFG-based datasets).\n\t\n\nNo comparison is made against standard baselines such as common data augmentation techniques or existing data selection strategies. Therefore, it is unclear whether the reported gains originate from the specific “semantic vs. structural balance” or simply from paraphrase-based data expansion.\n\n\nThe experiments are conducted with only two models (“GPT-2-XL (1.5B)” and “Mistral-7B”), which is insufficient to support general claims about scaling trends or the universality of the proposed findings."}, "questions": {"value": "pls see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wSnE8Yaqan", "forum": "zijZ40pBbV", "replyto": "zijZ40pBbV", "signatures": ["ICLR.cc/2026/Conference/Submission7086/Reviewer_4mRY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7086/Reviewer_4mRY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761377398899, "cdate": 1761377398899, "tmdate": 1762919265603, "mdate": 1762919265603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies data diversity for compositional generalization and argues that “more diverse data” is not uniformly better. It formally separates semantic diversity (many surface realizations of the same structure) from structural diversity (many distinct compositional structures), derives generalization bounds for each, and shows that under a fixed data budget K=M ⋅ N, increasing one kind of diversity can hurt if the other is the real bottleneck. The theory (via Rademacher complexity for intra-compositional generalization and covering-number arguments for inter-compositional generalization) yields an error bound with an interior optimum in N, explaining why we need to balance semantic and structural diversity. Experiments on synthetic algebraic circuits and on GSM8K (via GPT-4o–generated variants) confirm that when component complexity is high and compositional complexity is low, semantic diversity wins; when components are simple and recombination is the challenge, structural diversity wins."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**1. Intuitive and Robust Theoretical Upperbound of compositional generalization error**\n\n-- Authors study both semantic diversity and structural diversity to disentangle data factors that actually influence compositionality. They established theoretical upper bounds for both intra-compositional and inter-compositional generalization error, which corresponds to the two types of diversity.\n\n-- The overall upper bound of generalization error reveals a crucial fact: increasing diversity without a principled strategy does not necessarily lead to optimal generalization ability, and the training dataset requires a balanced allocation between semantic and structural diversity to achieve data efficiency.\n\n**2. Solid experiment design and strong empirical results**\n\n-- The designed experiments align well with the theory to be tested. The synthetic circuit setup is well controlled and directly tests the theoretical stationary point \n\n-- Real-data validation on GSM8K that shows semantic-augmented subsets can match or beat full-data fine-tuning under the same budget."}, "weaknesses": {"value": "**-- Missing citations:** A few previous works [1,2] also discussed the importance of data diversity for compositional generalization.\n\n[1] Zhou, Xiang, Yichen Jiang, and Mohit Bansal. \"Data factors for better compositional generalization.\" EMNLP 2023.\n[2] Akyürek, Ekin, and Jacob Andreas. \"LexSym: Compositionality as lexical symmetry.\" ACL 2023.\n\n**-- Undefined notation of semantic/structure complexity:** See my question below on distinguishing between semantic/structure complexity (d,r) and semantic/structure diversity (M/N)."}, "questions": {"value": "-- A few citation format mistakes: For example, authors should use \\citep in line 156.\n\n-- When the notations of “semantic/structure complexity (d,r)” are first discussed in Theorem 3.3, they are not properly defined. In Theorem 3.1, it’s not immediately clear why the dimension of $\\mathcal{A}$ “characterizes the complexity of the underlying components”. Similarly, in Theorem 3.2, authors mentioned space dimension d characterize structure complexity. Since these two terms are so important for the theoretical contribution of this paper, they should be properly introduced as authors did for semantic/structure diversity (N,M).\n\n-- Most previous work studying compositional generalization trains Transformer networks from scratch rather than from a pretrained checkpoint to eliminate the influence of pretraining data (e.g., a pretrained model may have already learned to do arithmetic compositionally). While Sec 4.1.1 focuses on training encoders from scratch, in Sec 4.1.2, the authors should at least discuss the potential effect of using pretrained models.\n\n-- Can the authors propose a practical estimator of (r,d), even proxy-level, so that the balance between semantic vs structural diversity can be decided automatically for a new task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2iXenM8Uxv", "forum": "zijZ40pBbV", "replyto": "zijZ40pBbV", "signatures": ["ICLR.cc/2026/Conference/Submission7086/Reviewer_dXnA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7086/Reviewer_dXnA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979142035, "cdate": 1761979142035, "tmdate": 1762919265243, "mdate": 1762919265243, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work studies compositional generalization in the algebraic circuits context. The work argues for making a distinction between semantic and structural diversity, emhpasizing that semantic diversity by itself may not be sufficient for achieving compositional generalization. An attempt is made to come up with a theoretical framework to include these diversity conditions into a compositional generalization framework."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The problem of compositional generalization is relevant. The scope (algebraic circuits in controlled settings) is easy to understand and reasonable.\n2. The writing is clear"}, "weaknesses": {"value": "1. Generalization results (Sections 3.2, 3.3) read like speculation. The analysis essentially extrapolates iid generalization arguments to an __assumed__ configuration within Euclidean space. That is not a genuine distribution-shift generalization proof. I don't see any justification of the assumptions, which makes the results disconnected. \n2. Empirical evaluations are tiny, e.g. Fig 3, arguably the graph that should contain most important results, only shows the training progress of three configurations. \n3. Related work has made a distinction between diversity and pure scale and its impact on compositional generalization (see, e.g., [1, 2]); these should be discussed and positioned within this work. \n\n[1] Uselis, Arnas et al. “Does Data Scaling Lead to Visual Compositional Generalization?” arXiv:2507.07102.    \n[2] Zhou, Xiang et al. “Data Factors for Better Compositional Generalization.” arXiv:2311.04420."}, "questions": {"value": "1. Can the analysis be extended to a larger set of variations of of N, M? Current Fig. 3 only shows three configurations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7Wa5ssJ4NC", "forum": "zijZ40pBbV", "replyto": "zijZ40pBbV", "signatures": ["ICLR.cc/2026/Conference/Submission7086/Reviewer_Njx3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7086/Reviewer_Njx3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984210079, "cdate": 1761984210079, "tmdate": 1762919264786, "mdate": 1762919264786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}