{"id": "nR984mi6zD", "number": 4204, "cdate": 1757633999496, "mdate": 1759898047477, "content": {"title": "Online Reusable Resource Allocation with Adversarial Requests", "abstract": "We study an online reusable resource allocation problem with adversarial inputs, where a platform must decide, over a horizon $T$, whether to accept incoming job requests with adversarial resource demands and durations. The goal is to maximize cumulative revenue subject to resource budget constraints.\nWe propose a class of \\textit{online dual dynamic learning algorithms} and \\textit{learning from pricing experts algorithms} that achieve asymptotically optimal competitive ratios, remain computationally efficient, and further improve performances across different regimes of maximum job duration and resource demand. We further extend the model to allow flexible resource allocations, where neither the demand nor the duration is fixed; instead, the amount of allocated resource influences job duration. To address this more general setting, we reduce the problem to the binary allocation case via resource discretization. We prove that the resulting loss is bounded by a constant depending only on the total budget, and this bound is nearly optimal.", "tldr": "", "keywords": ["Reusable resource allocation", "online learing", "adversarial environment", "cloud computing service"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/200f988dc06b6f6463346e90798c303035dfdaa8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper considers an interval selection problem. The way I see the problem. We are given a rectangular grid. Time goes from left to right. At each integer time t, we see an interval in row $x_t$, starting at t, and with some profit. Rows correspond to resources. If that interval does not overlap a previously accepted interval in this row, the we can decide to accept it or not. Accepted intervals are active as long as their right end is not reached. The goal is to maximize the total profit of accepted intervals subject to the total accepted active interval length not exceeding given budget B at any time.\n\nThe performance of an algorithm is measured by the competitive ratio, which is the solution one could compute if all future arriving intervals were known in advance.\n\nEach row is a problem by its own, but the budget B is shared among them. \n\nTwo classes of algorithms are studied. The first one uses the primal-dual framework, with Lagrangian relaxation, and sub-gradient descent. The second the pricing expert framework. Clearly for the problem, the density of an interval, profit over interval length, is of importance, and simple reasonable algorithms accept whenever the density is above some threshold. This threshold might vary over time.\n\nIn the primal dual framework, a promise is considered that the interval never exceed some $\\lambda_\\max$ in length. The time line is then divided into blocks of size $\\lambda_\\max$ each. The algorithm makes decisions only in even or odd indexed blocks according to an initially chosen random bit. In that sense it solves an independent online knapsack problem in each of those blocks. \n\nIn the expert framework, each expert accepts intervals whose density is with some value interval. Every expert has its own value interval. The multiplicative weight update method is used to learn the best expert.\n\nFinally a version is considered where the algorithm can decide on the amount of resource to allocate to each accepted interval, more amount reduces the interval length."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I like the problem a lot, once I understood correctly. I like that two approaches are studied and a variant."}, "weaknesses": {"value": "I think some discussion is missing with other online packing problems, and similarities in the algorithms. But this would mean to remove some of the interesting technical part of the paper."}, "questions": {"value": "Page 2 line 068. I don't understand how the competitive ratio can depend on $x_\\max$, which is the largest index of the resource in the instance. The problem should be invariant to numbering the resources. Hence it might be that I miss-understood something in the problem description. After reading Section 3 I think you mean that there is a single resource available with quantity B. Every interval comes with a resource requirement $x_t$ which is a quantity, not a resource identifier. The paper could do a better job in explaining the problem.\n\nI am wondering if the restriction of having a single request at every time step makes the problem easier?\n\nNotation. Why do you need $f_t, \\lambda_t$ to be functions of $x_t$. They could just be values.\nPage 5 line 240. I find this a complicated way to write $\\tilde a_t=1$ iff $f_t \\geq \\mu_t x_t$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gec6xneHrZ", "forum": "nR984mi6zD", "replyto": "nR984mi6zD", "signatures": ["ICLR.cc/2026/Conference/Submission4204/Reviewer_1QE6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4204/Reviewer_1QE6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4204/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761662569302, "cdate": 1761662569302, "tmdate": 1762917227832, "mdate": 1762917227832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the online resource allocation problem, where the learner receives a sequence of job requests (gain, duration, resource cost) and must determine immediately whether to accept or reject each request. The paper proposes two different approaches, one based on Lagrange duality and the other based on prediction with expert advice. Both approaches are shown, via mathematical analyses, to be provably effective and computationally efficient."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper studies an interesting problem and proposes effective solutions for it. The theoretical results on competitive ratio seem to be optimal. The proof strategies also appear to be novel and could be of independent interest. I verified the correctness of the proofs of Theorem 1 and Theorem 2."}, "weaknesses": {"value": "Please address the following concerns and questions:\n\n*Theorem 1:*\n- Applying regret bound on OLG-ALG without specifying the set of $\\nu$: assume $\\nu$ belongs to a set $V$. Online learning algorithms generally require $V$ to be bounded and convex. However, it seems that this set $V$ is not defined anywhere.\n- Lacking a quantifier for $R(T, \\nu)$ everywhere: in many places, the regret bound $R(T, \\nu)$ is used without any quantifier and undefined $\\nu$. Can *any* $\\nu$ be used here, or should it be $\\max_{\\nu \\in V}R(T, \\nu)$? I suspect it should be $\\max_{\\nu \\in V}R(T, \\nu)$ everywhere, because you are plugging a specific value of $\\nu$ in your bound (line 685).\n- In line 65, the paper claimed that they adaptively learn and use a sequence of $(\\nu_t)_t$, which is contrary to the non-reusable setting that uses a single $\\nu^\\star$. However, if my understanding of the proofs in the appendix is correct, then it is in fact the case that the regret bounds are used with respect to a single $\\nu$. For example, in Algorithm 1, the regret bound is a static bound that holds for a single $\\nu$. \n- Line 269, at the end of page 5: I believe writing $R(T, \\nu) \\leq O(\\sqrt{T})$ is incomplete. There should be a factor on the scale of the losses here.\n\n*Theorem 2*:\n- Continue with the point above, in the proof of Theorem 2, despite the theorem using a path-length bound,  all the comparators in active blocks $\\nu^\\star_t$ are  set to be equal to $f_m / x_m$ (in line 721). Shouldn't this defeat the purpose of using a dynamic regret bound?\n- Line 729 to 734: how is this bound on $P_T$ correct? If $\\nu^\\star_t = f_m / x_m$ and $\\nu^\\star_{t+1} = \\nu^*_t$ for all $t \\in \\mathcal{T}_i$ as set by line 721, then $P_T$ should be $0$.\n- Throughout Section 4.2: the first sentence of this section claims that it needs $\\bar{\\lambda} = \\max_t \\lambda_t$ to be known. However, I cannot find where $\\bar{\\lambda}$ is used in this section. The length of the blocks (Equations 6 and 7) does not use $\\bar{\\lambda}$. The value of $\\rho$ in line 294 does not use it. Algorithm 1 also does not use it. In Theorem 2, the condition $\\bar{\\lambda} \\leq \\lambda_{\\max}$ should be trivial from the problem setup, where $\\lambda_t \\leq \\lambda_{\\max}$ for all $t$. Can the authors clarify where $\\bar{\\lambda}$ is used?\n\n*Theorem 4*: \n- Again, in line 896, you are competing with a single best expert $j^*$. Each expert recommends a single threshold, therefore this implies that a single threshold, instead of a sequence of thresholds, is sufficient to obtain optimal guarantees. I find this to be contradictory to the claim in line 65 that a sequence of pricing thresholds is needed. Can the authors clarify on this? Intuitively, due to the adversarial nature of the sequence of jobs, it appears that a sequence of pricing thresholds must be needed and should do much better than a single threshold, but it seems that your results and their proofs show that a single threshold is sufficient. I find this very surprising.\n\n*Sloppy writing:*\n- Line 68 - 71 and everywhere else in the paper: the use of subscript \"max'' is confusing, as it seems to denote both \"the maximum values over $T$ rounds\" like $x_{\\max} = \\max_{t = 1, 2, \\dots, T} x_t$ and \"the upper bound of the range of values\" like $\\lambda_t \\in [\\lambda_{\\min}, \\lambda_{\\max}]$.\n- Line 193: $\\bar{\\nu}_t$ is not defined until line 221.\n- Line 221: should be $\\mu_\\tau$ instead of $\\mu_t$\n- Line 4 in Algorithm 1: in the argmax, it should specify that a \\in {0, 1}.\n- Theorem 1: $\\nu$ is undefined. From the proof, it should be $\\max_{\\nu \\in V}R(T, \\nu)$, where $V$ is a bounded and convex set for the range of $\\nu$. It is important that this set $V$ must be explicitly defined.\n- Theorem 4: there should be a pseudo-code of the algorithm mentioned in this Theorem 4, at least in the appendix.\n- Line 626: this line should go to the beginning of the appendix. As it is written, you are using $f_m$ everywhere without defining it. Also, I do not see the point of reducing $f_{\\max}$  to $f_m$ \"for simplicity\". It makes the writing much more confusing without any benefits."}, "questions": {"value": "Please address the concerns and questions raised in the Weaknesses above. Additional comments are below:\n\nBecause the techniques in the paper seem quite simple, and because I don't work on this problem setting directly, I couldn't tell whether the approaches are fundamentally new or not. I would be happy to raise the score if other reviewers and AC confirm that the results and proposed approaches are indeed novel, and that the authors' give clear answers to my concerns above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fCNDtroQGM", "forum": "nR984mi6zD", "replyto": "nR984mi6zD", "signatures": ["ICLR.cc/2026/Conference/Submission4204/Reviewer_tJEB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4204/Reviewer_tJEB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4204/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974074514, "cdate": 1761974074514, "tmdate": 1762917227617, "mdate": 1762917227617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles online allocation with reusable capacity under adversarial arrivals, where each job ties up part of a budget for a duration and yields a revenue. It proposes two families of algorithms: (i) primal–dual dynamic pricing (variants alternating-block and duration-aware), and (ii) a pricing-experts approach that learns a threshold over time. Theoretical results give asymptotic competitive-ratio and dynamic-regret guarantees; for a flexible-allocation extension, a powers-of-two reduction offers a ~1/log-B style approximation with a near-matching lower bound. The work positions itself as a first systematic adversarial treatment of reusable resources with ties to GPU/cloud scheduling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear problem formulation that unifies multiple adversarial reusable-resource scenarios with a dynamic-price view\n- Two complementary solution routes (primal–dual and experts) with nontrivial analyses, including a duration-aware variant that removes alternating blocks in the constant-duration regime.\n- Flexible-allocation extension with a simple discretization and a near-matching lower bound that clarifies the cost of reduction"}, "weaknesses": {"value": "- I find the strongest guarantees hard to map to practice. Several results still scale with $\\lambda_{\\max} x_{\\max} / B$ (and the alternating-block scheme effectively halves active time), while additive terms and dynamic-regret/path-length dependencies can dominate unless horizons and capacities sit in a favorable regime. I would recommend the authors to pin down concrete parameter ranges (e.g., GPU-cluster scales) where the bounds are $<$1 and additive terms are provably negligible relative to OPT\n- I’m concerned about reliance on parameters and structural assumptions: bounds often need a known $\\lambda_{\\max}$ (sometimes constant), constraints such as $x_{\\max}\\le B/2$ or $B/3$, and even revelation of $\\lambda_t$ at arrival; the flexible case assumes monotone $\\lambda_t(x)$. My confidence would improve with robustness analyses (e.g., hedging or doubling over misspecified $\\lambda_{\\max}$, handling noisy/unknown durations) and a brief comparison to stochastic/replenishable models to clarify when these assumptions are realistic."}, "questions": {"value": "Please address the concerns raised above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WQ5kiPe5tr", "forum": "nR984mi6zD", "replyto": "nR984mi6zD", "signatures": ["ICLR.cc/2026/Conference/Submission4204/Reviewer_2mRk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4204/Reviewer_2mRk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4204/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762121080275, "cdate": 1762121080275, "tmdate": 1762917227078, "mdate": 1762917227078, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}