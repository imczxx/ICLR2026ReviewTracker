{"id": "tucuU4sQ3s", "number": 17495, "cdate": 1758276725554, "mdate": 1759897171558, "content": {"title": "Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models", "abstract": "Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated remarkable zero-shot generalization, enabling deployment in a wide range of real-world tasks without additional task-specific training.\nHowever, in real deployment scenarios with evolving environments or emerging classes, these models inevitably face distributional shifts and novel tasks.\nIn such contexts, static zero-shot capabilities are insufficient, and there is a growing need for continual learning methods that allow models to adapt over time while avoiding catastrophic forgetting.\nWe introduce NuSA-CL (Null Space Adaptation for Continual Learning), a lightweight memory-free continual learning framework designed to address this challenge.\nNuSA-CL employs low-rank adaptation and constrains task-specific weight updates to lie within an approximate null space of the model's current parameters.\nThis strategy minimizes interference with previously acquired knowledge, effectively preserving the zero-shot capabilities of the original model.\nUnlike methods relying on replay buffers or costly distillation, NuSA-CL imposes minimal computational and memory overhead, making it practical for deployment in resource-constrained, real-world continual learning environments.\nExperiments show that our framework not only effectively preserves zero-shot transfer capabilities but also achieves highly competitive performance on continual learning benchmarks. \nThese results position NuSA-CL as a practical and scalable solution for continually evolving zero-shot VLMs in real-world applications.", "tldr": "", "keywords": ["Continual Learning", "Vision-Language Models", "Parameter-Efficient Fine-Tuning", "Null-Space Methods"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ce8742622dd3be317e5212ad770224809fba9803.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes NuSA-CL, a memory-free continual learning method that leverages orthogonal weight modulation to mitigate catastrophic forgetting. The approach updates model parameters only along directions orthogonal to previously learned subspaces, thus avoiding interference with past knowledge without storing any exemplars. Experiments on several vision and vision-language benchmarks show that NuSA-CL performs competitively among storage-free approaches but lags behind replay-based methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tMemory-free design.\nThe method achieves continual learning without any replay or exemplar storage, offering a clean and theoretically motivated direction for efficient CL.\n2.\tStrong performance among storage-free models.\nWithin the memory-free setting, NuSA-CL demonstrates solid results and stable learning behavior across multiple benchmarks."}, "weaknesses": {"value": "1.\tLimited performance.\nThe method performs worse than all storage-based models, showing limited competitiveness in practical CL scenarios.\n2.\tSimplicity vs. effectiveness.\nThe proposed approach is simple, but its results do not convincingly show that such a minimal mechanism can achieve strong continual learning.\n3.\tScalability concern.\nAs also noted by the authors, under extreme lifelong settings the null-space directions may saturate. Without a clear advantage in scalability over storage-based methods, the claimed benefit of being memory-free remains modest."}, "questions": {"value": "1.\tWhat prevents NuSA-CL from surpassing any storage-based methods in performance, despite its theoretically clean orthogonal design?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hvtEqvW6sx", "forum": "tucuU4sQ3s", "replyto": "tucuU4sQ3s", "signatures": ["ICLR.cc/2026/Conference/Submission17495/Reviewer_TeKM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17495/Reviewer_TeKM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17495/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760692067045, "cdate": 1760692067045, "tmdate": 1762927377257, "mdate": 1762927377257, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "NuSA-CL addresses continual learning (CL) by balancing stability (retaining old knowledge) and plasticity (adapting to new tasks). The core idea is a low-rank adaptation strategy that constrains task-specific weight updates to the model’s approximate null-space, minimizing interference with previously learned knowledge and preserving the model’s zero-shot learning ability. Unlike methods that rely on replay buffers or high-cost distillation, NuSA-CL requires minimal computation and memory, making it suitable for resource-constrained scenarios. Experimental results demonstrate that the framework not only maintains strong zero-shot transfer performance but also achieves competitive results on continual learning benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduces the novel idea of updating in null-space directions (Tail), which is conceptually different from previous approaches that focus on Top singular directions or random subspaces. Combines multimodal adaptation and rank-limited updates, which is a creative integration addressing the stability–plasticity trade-off. \n2. Significance Tackles catastrophic forgetting, a central challenge in continual learning. Demonstrates practical low-cost, robust implementation suitable for large-scale models and multimodal tasks. \n3. The paper is well-structured, with clear motivation, methodology, and empirical validation. Extensive ablation studies and visualizations (e.g., subspace and rank analysis) make the mechanisms and design choices transparent. \n4. Strong experimental evaluation, including comparisons with Top/Random subspaces and analysis of rank choices. Shows robustness to hyperparameters and demonstrates practical feasibility with low SVD overhead."}, "weaknesses": {"value": "1. The method assumes that tasks have sufficiently distinct distributions, enabling interference reduction via orthogonalization or projection. However, when tasks are highly correlated or share overlapping features, the model may struggle to separate old and new knowledge, leading to reduced stability and adaptability.\n2. The experimental evaluation is limited to standard vision benchmarks (e.g., CIFAR, ImageNet subsets) with relatively few tasks, focusing only on class-incremental learning. The absence of experiments on more complex multimodal settings such as VQA or image-text retrieval limits the demonstration of generalizability.\n3. The method’s performance is sensitive to key hyperparameters, including projection dimension, update ratio, and orthogonalization strength. The lack of an adaptive tuning mechanism may hinder robustness and scalability in real-world, dynamic scenarios.\n4. In class-incremental tasks, the method has not been compared with other Parameter-Efficient Fine-Tuning (PEFT) approaches such as LPI, TAM, MoELora，or DIKI, limiting the completeness of its performance validation."}, "questions": {"value": "1. Q: In class-incremental tasks, NuSACL has not been compared with other PEFT approaches such as LPI, TAM, MoELora, or DIKI. How does it perform relative to these methods in terms of both accuracy and memory efficiency?\n2. Q: While NuSACL improves stability via orthogonal projection, catastrophic forgetting may still occur in challenging incremental protocols (e.g., many classes, highly overlapping features). Have the authors quantified forgetting under these extreme settings?\n3. Q: Although the method is described as lightweight, how does it scale to large models (e.g., ViT-L/14 or multimodal transformers) where repeated SVD computations might be expensive?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Lij0l9Amby", "forum": "tucuU4sQ3s", "replyto": "tucuU4sQ3s", "signatures": ["ICLR.cc/2026/Conference/Submission17495/Reviewer_SL2R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17495/Reviewer_SL2R"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17495/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724363523, "cdate": 1761724363523, "tmdate": 1762927376834, "mdate": 1762927376834, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes NuSA-CL, a memory-free continual learning method for VLMs (e.g., CLIP). It identifies a low-energy “null” subspace via SVD before each task, constrains low-rank updates to this subspace during training, then merges updates into the backbone to avoid parameter growth. Experiments on MTIL (full/5-shot) and CIFAR-100 CIL show strong performance and efficiency; analyses include rank/null-space dynamics, subspace/rank ablations, and core mechanism ablations."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Simple, natural idea: SVD-based separation of principal vs. null-like directions; persistent constraint prevents drift and reduces interference.\n2. Truly memory-free and fixed-size: no replay, no task-specific modules; efficient and scalable.\n3. Strong empirical results with comprehensive cost reporting; SOTA among storage-free baselines and close to storage-based methods.\n4. Clear, informative ablations (Top/Tail/Random; rmax; persistent constraint; multimodal adaptation) and mechanism evidence (effective-rank, null-ratio trajectories).\n5. Practical and robust: negligible SVD overhead; stable across energy thresholds; single-GPU training."}, "weaknesses": {"value": "1. Theory is mostly motivational; tighter links between parameter-space bounds and function-level forgetting would help.\n2. Long-horizon spectral drift and null-space quality: Although the method re-computes SVD per task, after many merges the spectrum will evolve. A more systematic study of whether low-energy subspaces gradually become “contaminated” (especially for highly correlated task sequences) and how to monitor/remedy this (e.g., periodic re-orthogonalization, spectral gating) would be valuable.\n3. Merged updates limit reversibility; lightweight selective rollback is not explored.\n4. Scalability guidance for larger backbones (ViT-L/H) would aid practitioners."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Nf1oS3Wboa", "forum": "tucuU4sQ3s", "replyto": "tucuU4sQ3s", "signatures": ["ICLR.cc/2026/Conference/Submission17495/Reviewer_4o99"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17495/Reviewer_4o99"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17495/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757441286, "cdate": 1761757441286, "tmdate": 1762927376374, "mdate": 1762927376374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes NuSA-CL, a lightweight memory-free continual learning framework to address distributional shifts/novel tasks during real-world CLIP usage. NuSA-CL employs low-rank adaptation and null space constraint via SVD to constrain the update of parameters in a way that has low influence on previous knowledge. The experiments demonstrate its effectiveness among memory-free methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical motivation is clear and reasonable.\n2. The experiments demonstrate a favorable result among memory-free methods. The analysis and discussions are comprehensive, showing the method's practicality and robustness."}, "weaknesses": {"value": "1. Storage-free baseline models are not that strong. Then a question is: using null-space may constrain the model expressivity. Is it still able to trade off by increasing the memory cost to get a stronger performance? Or the null-space also constrain the performance upperbound?"}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XmpnAbgAFl", "forum": "tucuU4sQ3s", "replyto": "tucuU4sQ3s", "signatures": ["ICLR.cc/2026/Conference/Submission17495/Reviewer_JRHi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17495/Reviewer_JRHi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17495/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994854866, "cdate": 1761994854866, "tmdate": 1762927375841, "mdate": 1762927375841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}