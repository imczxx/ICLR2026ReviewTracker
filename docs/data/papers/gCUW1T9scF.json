{"id": "gCUW1T9scF", "number": 18840, "cdate": 1758291308989, "mdate": 1759897078408, "content": {"title": "LLM2Token: Distilling Large Language Models into Task-Specific Tokenizer", "abstract": "We present LLM to Tokenizer, a new distrilling method that preserves the prior knowledge from LLMs in the form of tokenizer, diverging from neural network based methods. This simple, intuitive method allows strong performance even only using one-hot encoding and a simgle-layer logistic regression. Based on the generated tokenizer, without any pre-training, surpressing GPT-2 with just 0.01\\% parameters. On event recognition tasks, the L2T method achieves an F1 score of 0.408 while using only 0.1\\% of the parameters compared to previous models. We also observed that stronger foundation models lead to improved tokenizer performance. And long tokenizers can harm the performance since the capacity of single-layer logistic regression is limited. This demonstrates a zero-shot capability of LLMs--through training on internet-scale corpora, they can recognize words that are important for specific tasks. We released all models, codes and the dataset to promote the furture exploration.", "tldr": "We present LLM to Tokenizer, a new distrilling method that preserves the prior knowledge from LLMs in the form of tokenizer", "keywords": ["Tokenizer", "Distrill", "Large language models (LLMs)"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/223a9885b904bd50f6023751246603c7c7637a40.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents LLM2Token (L2T), a novel knowledge distillation paradigm that departs from traditional neural network-based methods by distilling the knowledge of Large Language Models (LLMs) into task-specific tokenizers instead of smaller neural networks."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The claim that prior knowledge from LLMs can be distilled in the form of tokenizer is interesting."}, "weaknesses": {"value": "1. First of all, this paper contains quite a few writing errors. For instance, there is a spelling mistake in the word \"distilling\" in Line 11; line 5 in table 3 is confusing; additionally, the paper claims in Line 15 and Line 66 that the proposed method outperforms GPT-2 and GPT-3.5 respectively, which has left me very confused.\n2. This paper claims that LLM2tokenizer is a knowledge distillation method, yet it fails to compare LLM2tokenizer with mainstream knowledge distillation methods. Besides, the experiments in this paper are only conducted on a single dataset, which cannot effectively validate the claims made in the paper.\n3. I am very confused by the training process shown in Figure 3—it seems extremely unstable and fluctuates constantly. The authors need to analyze this phenomenon. In my view, this reflects the uncertainty and instability of the proposed method, which makes it unable to be generalized to other tasks.\n4. LLM2tokenizer relies on a large model to extract tokens, and I highly doubt whether this result is reliable across all tasks. This paper needs to conduct a detailed analysis of this issue."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aBxnB7VXqP", "forum": "gCUW1T9scF", "replyto": "gCUW1T9scF", "signatures": ["ICLR.cc/2026/Conference/Submission18840/Reviewer_DqBF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18840/Reviewer_DqBF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761398222299, "cdate": 1761398222299, "tmdate": 1762930809710, "mdate": 1762930809710, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a new paradigm distillation method for LLMs, which extracts the teacher model’s knowledge into a task-specific tokenizer via feature selection, rather than distilling it into a traditional student model. A simple classifier is then trained on the resulting tokenizer to complete the distillation. This approach reduces distillation costs and makes the distilled knowledge more interpretable."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors propose a novel lightweight knowledge distillation paradigm, which enables extremely fast distillation."}, "weaknesses": {"value": "1.There is a typo in the abstract, line 14: “simgle-layer” should be corrected to “single-layer”.\n\n2.In the experimental section, the authors only compare their method with three other feature selection approaches, but do not benchmark against traditional knowledge distillation methods, which makes it difficult to convincingly demonstrate the effectiveness of the proposed method as a distillation paradigm.\n\n3.The experiments are limited to event recognition tasks, without evaluation on a broader range of language model tasks such as generation, mathematical reasoning, or code understanding, thus limiting the generality claims of the approach.\n\n4.The token selection relies heavily on prompts fed to the teacher model, yet the authors do not describe how these prompts are designed, nor do they analyze whether different prompt choices affect the token selection outcome."}, "questions": {"value": "1.The authors should clarify which LLM served as the teacher during distillation. Additionally, would the choice of teacher model affect the quality of the selected tokens and the downstream performance of the proposed method?\n\n2.Since one of the claimed advantages is interpretability, it would be helpful to visualize or list the token sets selected for different tasks to demonstrate what knowledge is being distilled.\n\n3.A direct comparison with standard distillation baselines would help position this work more clearly and validate its effectiveness beyond feature selection."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aozPmA0bqU", "forum": "gCUW1T9scF", "replyto": "gCUW1T9scF", "signatures": ["ICLR.cc/2026/Conference/Submission18840/Reviewer_ReQ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18840/Reviewer_ReQ1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813832684, "cdate": 1761813832684, "tmdate": 1762930808872, "mdate": 1762930808872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript claims to introduce a method to distill LLMs into a \"task-specific tokenizer\" instead of a smaller neural net. The proposed method boils down to prompting an LLM to obtain a vocabulary suitable for a task, and then training a logistic regression model over such a vocabulary."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The idea of distilling LLMs into non neural kinds of models is not without interest\n- The goal to reduce the size and computational cost of LLMs is certainly praiseworthy"}, "weaknesses": {"value": "- The manuscript mistakes a tokenizer with a logistic regression model over a feature vocabulary. Indeed, the paper is not about tokenizers at all (i.e., algorithms that map sequences of strings in one vocabulary into sequences of strings in a different vocabulary; cf. [Sennrich et al, 2016](https://arxiv.org/abs/1508.07909), [Kudo et al, 2018](https://arxiv.org/abs/1808.06226), [Gastaldi et al, 2025](https://arxiv.org/abs/2407.11606)). What is here called \"tokenizer\" is actually a feature selection model for training classifiers.\n- What the manuscript calls \"distillation\" of a \"task-specific vocabulary\" is just prompting an LLM, with the prompt \"You are an expert in linguistics and data science. Your goal is to identify the most discriminative words for a text classification task.\" The \"entirely new paradigm\" proposed boils down to \"instruct the LLM to act as an expert in linguistics and data science. We clearly define the task, including a description of the positive and negative classes.\" This can be barely considered a method, let alone a scientific one, under any rigorous standard.\n- The remaining part of the work reduces to applying logistic regression over the obtained vocabulary, which is far from being a novel or original technique.\n- In the face of these flaws, many claims concerning the novelty and advantages of the method appear as unsubstantiated. In particular, the efficiency and the interpretability are no more and no less than those of logistic regression.\n- The manuscript exhibits numerous typos and linguistic and stylistic mistakes, which could, of course, be fixed, but which also suggest that the paper was not in its final state at the moment of submission."}, "questions": {"value": "- Why do you call \"tokenizer\" a classifier?\n- What is your justification for prompting LLMs as a rigorous scientific method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "23IPgKyS2A", "forum": "gCUW1T9scF", "replyto": "gCUW1T9scF", "signatures": ["ICLR.cc/2026/Conference/Submission18840/Reviewer_h2A2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18840/Reviewer_h2A2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990031416, "cdate": 1761990031416, "tmdate": 1762930808167, "mdate": 1762930808167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a “knowledge distillation” method to transfer LLM's knowledge into a “symbolic and interpretable representation”, terming it task-specific tokenizer. Instead of transferring logits or features to the student model, the LLM is prompted to generate discriminative tokens for a classification task. These tokens form a custom vocabulary used to represent inputs via one-hot encoding, followed by logistic regression model training for event recognition. Experiments on two binary event recognition tasks from the People's Daily corpus show that L2T outperforms manual, chi-square, and linear model based feature selection, achieving 0.408 F1 with 0.1% of the parameters compared to previous models. The authors argue this demonstrates LLMs' zero-shot ability to identify task-relevant features, offering an alternative to standard distillation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of utilizing LLM for zero-shot feature selection is conceptually interesting. It reframes LLM use beyond generation or fine-tuning, suggesting an interesting way of using pretrained knowledge to inform lightweight models.\n2. The paper emphasizes efficiency, and achieves strong performance using extremely lightweight models, which could appeal to low-resource deployment settings.\n3. The methodology is clearly written and can be easily followed. All steps from prompting to classification are sufficiently described."}, "weaknesses": {"value": "1. The assumption that the LLM can provide the top-k most relevant tokens is not directly tested. It is possible that the LLM outputs semantically similar words rather than truly discriminative tokens, as the LLM is prompted with examples rather than accessing the actual data distribution. The paper would be stronger if it compared representations built from LLM-selected tokens with those derived from actual top-k tokens based on LLM's probability distribution.\n\n2. The framing as “knowledge distillation” may be misleading, as it deviates from the standard teacher-student optimization, logit transfer, or soft-target training. The method is closer to LLM-guided feature selection. The terminology demands a stronger comparison with established distillation literature, and the lack of such discussion weakens the conceptual positioning.\n\n3. The necessity of using an LLM for the distillation is not clear. The LLM operates only through prompting and does not access the training data directly. It remains unclear whether the same or better token sets could be obtained from TF-IDF or frequency-based selection. Including such comparisons would clarify whether the LLM meaningfully contributes beyond conventional feature extraction.\n\n4. The experiments are limited in scope. The evaluation is confined to two binary classification tasks from a single Chinese corpus. It remains unclear whether the method generalizes to other domains, languages, or multi-class setups. The paper should include English corpus for broader relevance.\n\n5. The paper lacks analysis of the quality and consistency of the selected tokens. There are no examples illustrating what kinds of tokens the LLM identifies, whether they are semantically meaningful, or whether results are stable across different prompts or runs. Moreover, the interpretability claim of the LLM-generated vocabulary itself is not demonstrated. Providing qualitative examples would make the interpretability argument more convincing."}, "questions": {"value": "1. Please see the Weakness section for points where additional analysis/clarification or experimentation would strengthen the paper. \n\n2. Could you specify which LLM(s) were used, their version or API source, and prompting parameters such as temperature and top-p?\n\n3. Could you include the examples of few-shot inputs and LLM’s outputs?\n\n4. Did you observe substantial synonymy or duplication among the generated tokens? If so, how was this handled? \n\n5. The Related Work section on Deep SISR Models appears unrelated to the proposed method. Can you clarify the relevancy of it in the paper’s argument?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TznU5Gp7xD", "forum": "gCUW1T9scF", "replyto": "gCUW1T9scF", "signatures": ["ICLR.cc/2026/Conference/Submission18840/Reviewer_Apzd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18840/Reviewer_Apzd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997241951, "cdate": 1761997241951, "tmdate": 1762930807437, "mdate": 1762930807437, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents LLM2Token, a novel distillation paradigm that leverages large language models (LLMs) to generate a set of task-relevant keywords for text classification. By using either a task description or a small number of examples, LLM2Token efficiently extracts discriminative features that capture the underlying knowledge of the LLM. The approach is evaluated on two benchmarks and demonstrates strong performance using only a minimal number of parameters."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Despite its simplicity and efficiency, the proposed method achieves strong performance on two binary classification benchmarks.\n\n- The method presents a novel approach to knowledge distillation by focusing on token-level selection, offering a distinct alternative to traditional output- or feature-based distillation techniques."}, "weaknesses": {"value": "- The distillation process is tailored to a specific task, which means a separate distillation must be performed for each new task, potentially limiting scalability and reusability.\n- The evaluation is limited to two benchmarks and binary classification tasks. Given that LLMs are designed for general-purpose language understanding, comparing them with a task-specific distilled method may not provide a fully fair or comprehensive assessment of their relative capabilities.\n- Since L2T is only evaluated on classification tasks, its applicability to other NLP task types—such as generation, question answering, or sequence labeling—remains unclear and warrants further investigation."}, "questions": {"value": "Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vIHrngdC2S", "forum": "gCUW1T9scF", "replyto": "gCUW1T9scF", "signatures": ["ICLR.cc/2026/Conference/Submission18840/Reviewer_b2CE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18840/Reviewer_b2CE"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762005018366, "cdate": 1762005018366, "tmdate": 1762930806978, "mdate": 1762930806978, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}