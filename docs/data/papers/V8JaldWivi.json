{"id": "V8JaldWivi", "number": 12331, "cdate": 1758207105187, "mdate": 1759897516387, "content": {"title": "The Origins of Representation Manifolds in Large Language Models", "abstract": "There is a large ongoing scientific effort in mechanistic interpretability to map embeddings and internal representations of AI systems into human-understandable concepts. A key element of this effort is the linear representation hypothesis, which posits that neural representations are sparse linear combinations of `almost-orthogonal' direction vectors, reflecting the presence or absence of different features. This model underpins the use of sparse autoencoders to recover features from representations. Moving towards a fuller model of features, in which neural representations could encode not just the presence but also a potentially continuous and multidimensional value for a feature, has been a subject of intense recent discourse. We describe why and how a feature might be represented as a manifold, demonstrating in particular that cosine similarity in representation space may encode the intrinsic geometry of a feature through shortest, on-manifold paths, potentially answering the question of how distance in representation space and relatedness in concept space could be connected. The critical assumptions and predictions of the theory are validated on text embeddings and token activations of large language models.", "tldr": "We describe a mathematical framework which could explain how and why representation manifolds emerge in large language models.", "keywords": ["mechanistic interpretability", "linear representation hypothesis", "superposition"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7b5f070521bfc144dcf9b40919f55637f878fbd6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper strives to provide a better mathematical grounding of terms that are commonly used in the interpretability community, in particular \"features\" and \"feature representations\".\n\nIn particular, the paper suggests to define a \"feature\" $f$ as a metric space ($Z_f$, $d_f$), where depending on the nature of the feature, we can design/expect an appropriate distance metric $d$ (examples can be found in Section 2.3). \n\nThe authors then hypothesize that there exists a (continuous correspondence) mapping $\\phi$ from the metric space $Z$ to its feature representation in the model's embedding space ($v_f$), allowing us to relate the two spaces. Interestingly, with a careful definition of distance in each of the two spaces, they provide some evidence of isometry between the two spaces, adding support for their proposed definition of a feature as a metric space.\n\nOverall a fun read!"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is written nicely with clear definitions to properly formalize terms being thrown around in interpretability (\"feature\") or to connect with prior work that tries to establish a framing for how we should characterize model representations. Though whether the field will adopt the authors' provided definitions/framing is to be seen, the authors provide compelling evidence that their provided framing (i.e., defining features as a metric space the continuous correspondence hypothesis) fits nicely with the few examples that they study."}, "weaknesses": {"value": "To be honest I'm not sure if the title \"The origins of representation manifolds in large language models\" is a bit too broad of a title that doesn't reflect the findings/claims of the paper. In particular, I think the paper has a heavy focus on the use of a metric space, and in part studying the role that distance (in either metric space or embedding space) plays to support their definition of features as metric spaces.\n\nAlbeit the paper being a fun read, its claims and evidence are mostly based on a few observations of feature representations previously found. The authors' claims fit nicely with these few examples, but on one hand it's unclear whether all the provided theorems/hypotheses are \"overfit\" to these few examples. For instance, I am not sure how to apply their provided insights to non-continuous or non-periodic concepts. On a similar note, it's not clear how to apply these insights. The authors acknowledge some of these points in their Limitations section."}, "questions": {"value": "* What are some ways we might characterize non-contiuous features, for instance atomic features? In particular what might be a suitable distance metric? Or, to use the examples used in the intro, features like \"floppy ears\" / \"Eiffel_Tower\" / \"is Arabic\"?\n\n* What was the thought process behind expressing each year as `log(2019 - year)`? I am just curious to know the research process was underlying this discovery. \n\n* Near the end of Section 3 - can you add details (perhaps in appendix?) regarding the experiments you conducted for low-dimensional projections?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YFsgFqgVht", "forum": "V8JaldWivi", "replyto": "V8JaldWivi", "signatures": ["ICLR.cc/2026/Conference/Submission12331/Reviewer_FJtV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12331/Reviewer_FJtV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761770596134, "cdate": 1761770596134, "tmdate": 1762923254586, "mdate": 1762923254586, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a \"minimum viable mathematical theory\" that generalizes the Linear Representation Hypothesis by modeling complex features as metric spaces. The core result (Thm 1) claims (under various hypotheses) that distances in representation space encodes the intrinsic geometry of a feature. Empirical validation is given for temporal and colour concepts and trained LLM embeddings.\n\nSpecifically, the paper assumes that \n - each feature f correspond to a metric space Z_f (only 1-D spaces considered)\n - under the embedding/representation mapping of words(/tokens), words that vary in a particular feature map to a manifold (on the unit sphere) isomorphic to the feature space Z_f\n - cosine similarity between embeddings is function of distance in feature space (independent of location) and in particular the gradient of that function is a constant as distances approach zero (independent of location)\n\nThe conclusion (Thm 1)  is that path lengths over the manifold are linearly proportional to path lengths in feature space."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper looks to generalise the linear representation hypothesis (LRH). \n\nHypotheses are presented that imply a linear relationship between path distances on feature manifolds in embedding space and distance in an assumed feature (metric) space.\n\nEmpirical results for 3 features (colour/dates) show an apparent linear relationship, subject to feature parameterisation."}, "weaknesses": {"value": "* The paper is titled \"The origins ...\", but no *origins* seem to be explained (or even discussed). Sufficient conditions are posited (Hyp 1 & 2) that imply path lengths in feature space are directly proportional to those in embedding space. Even if all true, this simply pushes back the question one level to why do those hypotheses hold. The existence of manifolds is well known, it is not clear that the paper explains \"their origins\".\n* While the paper claims to give a simpler definition (Def 2) relative to \"Riemannian manifolds\", the examples all appear to be 1-D manifolds (color wheel, dates), so this claimed distinction/benefit doesn't seem material/obviated.\n* For (measurable) path lengths in embedding space to be proportional to \"path lengths in feature space\" requires the existence of an intrinsic distance measure in feature space. But that is entirely subject to parameterisation and there is no grounding of that parameterisation. While ordinality/ordering of feature values is intrinsic (i.e. their topology), an intrinsic metric doesn't seem well grounded.\n   - I note that the authors acknowledge this and reparameterise the year experiment to fit the model\n* \"even though we know (almost) nothing about g\" glosses over the assumption that cosine similarity is a function of feature difference, independent of feature value, which seems a strong assumption."}, "questions": {"value": "* 401: \"a low-dimensional projection tends to be necessary for the representations to plausibly show isometry\" - unclear what this is referring to. Where has this projection been applied?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3EYm6qbfCd", "forum": "V8JaldWivi", "replyto": "V8JaldWivi", "signatures": ["ICLR.cc/2026/Conference/Submission12331/Reviewer_L8Xe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12331/Reviewer_L8Xe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843334220, "cdate": 1761843334220, "tmdate": 1762923253901, "mdate": 1762923253901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the internal representations of language models by studying how features can be represented as manifolds. Specifically, going beyond the standard linear representation hypothesis, the authors bring in manifolds and study the intrinsic geometry of the feature through these manifolds and through the distances in them. Here, each feature $f$ is represented as a manifold in $V_f$ (the associated subspace of $f$). While there had been previous accounts of this idea before, the authors formalize this modeling mathematically. The hope in this formalization is that the topology and geometry of the manifold can reflect a human conceptualization of $f$.\n\nThe authors formalize this manifold approach mathematically, which allows them to precisely state Hypothesis 1 and 2. Hypothesis 1 assumes that the topology/shape of the concepts is preserved. Hypothesis 1 allows the authors to prove Proposition 1, which links the topology present from the metric space $Z_f$ into its image $M_f$. Hypothesis 2 assumes that cosine similarity (which is a well-known distance used in these topics) reflects distance accurately (i.e., distance is also preserved). This allows the authors to prove Theorem 1, which says that one can moreover recover the intrinsic geometry of $M_f$ (stated with the length of a path). The interpretation of Theorem 1 is that the language model internal representation can be understood as a distance-preserving map of the human concept.\n\nThe authors provide various plots to illustrate the findings. Specifically, they consider the concepts of colours, years, and dates, and plot post-processings of the representation manifolds in token activations, to visually illustrate the distances between the concepts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper has good mathematical rigor and the formalism introduced allows us to tackle this problem going beyond the standard LRH.\n- The concepts are well-defined and the hypotheses considered are sensible. I liked that all mathematical statements and definitions were accompanied by intuitive explanations that are more digestible. \n- The paper is well-written and tackles an important research area. Mechanistic interpretability is a very relevant problem and we need more theoretical work in this space. \n- The Figures provide good intuition for the kinds of mappings that the authors are exploring, and they help understand this idea of studying human concepts on the representation manifolds."}, "weaknesses": {"value": "The main weakness of the paper is the experimental design, which does not seem to support the theoretical findings with enough evidence. This is important, because the main results of the paper (which are Proposition 1 and Theorem 1) depend on strong hypotheses (Hypothesis 1 and Hypothesis 2, respectively). Hence, it is crucial that the experiments are able to support these hypotheses (and thus the theoretical results) with enough evidence. \n- The experimental design is lacking in details in the text and in breadth in the experiments. In the text, the experimental details are not given, and rather the figures are interwoven in the text without enough explanation.\n- For example, for Figure 1: how were the token activations processed by an SAE? How does this processing affect the representation? Why is it OK to perform PCA all the way down to 3 dimensions in order to support the theoretical model?\n- The experiments don't seem comprehensive enough. Figure 1 includes English names for colors, years of the 20th century, and dates of the year, and similarly for Figure 3. Figure 2 only has months of the year and days of the week. These are only three concepts -- too few. Not enough LLMs are considered either. Hence, it is hard to justify generalizability. \n- Even for the figures presented, the evidence is weak. This is acknowledged by the authors: about Figure 1, they say that the embeddings are \"roughly arranged around a loop which, perhaps after some stretching and bending, could seem consistent with the abstract circular model we might have for such concepts\", \"again reminiscent up to some geometric distortion\", etc. The correlations obtained in the figures are not high enough in various cases. Also, the metrics are decided after seeing the figures, and it seems that they are decided as to increase the correlation (e.g., when the authors consider the modified representation for $Z_{years}$ in page 8). It isn't the right order to first decide on the best metric, and then compute the correlation as to try to make the hypothesis be more faithful. (And as the authors point out, we can't really learn the metric a priori.)\n- In the limitations section, it says that the authors use K-nearest neighbour graphs to approximate the manifold. Similarly, there is not enough experimental details about this. The same paragraph says that the authors had to \"manually prune the graph in order to achieve reasonable manifold distance estimates\". This information is very important, and it is not explained.\n\nIn conclusion, I think that the ideas explored here and the formalization provided are interesting and potentially useful, but given that the main two results depend on hypotheses the experiments need to be a lot more comprehensive and detailed to support the theory."}, "questions": {"value": "- Why are you carrying out your experiments following Engels et al., and what is the relationship to their work? (E.g., Figure 2.) What do you mean that the \"example is taken from Engels et al.\"?\n- This is a comment, but it would be good to make sure that the abbreviations and terminology is always properly defined and introduced. E.g., LHR should appear in parenthesis after \"linear representation hypothesis\", a putative metric space should be defined, Chatterjee's correlation coefficient, etc.\n- How does the final dimension shown in the figures affect the result? E.g., you say that previous work missed the topology-preserving observations due to 2D projection.\n- Given the importance of this topic, and the well-known use of cosine similarity, the paper is lacking discussion on related work. What other formalizations have been done in this space? How does your work relate to them?\n- What do you mean that you had to manually prune the graphs? How does this affect your experimental results? \n- Given that you are analyzing the post-processing of the activations with a SAE, how are you avoiding confounding factors here? How do you know that what we see visually hasn't been introduced by the SAE?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "n9vs8jo17I", "forum": "V8JaldWivi", "replyto": "V8JaldWivi", "signatures": ["ICLR.cc/2026/Conference/Submission12331/Reviewer_mGVh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12331/Reviewer_mGVh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983246885, "cdate": 1761983246885, "tmdate": 1762923253340, "mdate": 1762923253340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}