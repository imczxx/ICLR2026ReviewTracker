{"id": "GLOOoWqbCV", "number": 8909, "cdate": 1758102025862, "mdate": 1759897754638, "content": {"title": "Adaptive Sampling Scheduler", "abstract": "Consistent distillation methods have evolved into effective techniques that significantly accelerate the sampling process of diffusion models. Although existing methods have achieved remarkable results, the selection of target timesteps during distillation mainly relies on deterministic or stochastic strategies, which often require sampling schedulers to be designed specifically for different distillation processes. Moreover, this pattern severely limits flexibility, thereby restricting the full sampling potential of diffusion models in practical applications. To overcome these limitations, this paper proposes an adaptive sampling scheduler that is applicable to various consistency distillation frameworks. The scheduler introduces three innovative strategies: (i) dynamic target timestep selection, which adapts to different consistency distillation frameworks by selecting timesteps based on their computed importance; (ii) Optimized alternating sampling along the solution trajectory by guiding forward denoising and backward noise addition based on the proposed time step importance, enabling more effective exploration of the solution space to enhance generation performance; and (iii) Utilization of smoothing clipping and color balancing techniques to achieve stable and high-quality generation results at high guidance scales, thereby expanding the applicability of consistency distillation models in complex generation scenarios. We validated the effectiveness and flexibility of the adaptive sampling scheduler across various consistency distillation methods through comprehensive experimental evaluations. Experimental results consistently demonstrated significant improvements in generative performance, highlighting the strong adaptability achieved by our method.", "tldr": "We propose an adaptive sampling scheduler for consistency distillation that dynamically selects important timesteps and leverages bidirectional trajectory jumps, improving sampling efficiency and generation quality across diverse diffusion models.", "keywords": ["Diffusion models", "Consistency distillation", "Adaptive sampling scheduler"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/27951858518a8d866d4ca4566f04476d49868b59.pdf", "supplementary_material": "/attachment/21144e5773c67d0448c6295fe9a162b5da0d23b0.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes an adaptive sampling scheduler for consistency distillation frameworks, with its core design focused on dynamic timestep selection. The authors define the rate of signal change through Equation 7, using this metric to assess the importance of timesteps for selection during distillation. Additionally, a smoothing mechanism for the CFG method is introduced to further improve the quality of the generated output. The authors validate their approach across a variety of scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The design approach, which incorporates the properties of forward diffusion, is highly meaningful as it considers the impact of the dynamic properties of the diffusion process.\n\n+ Validation across various consistency model frameworks demonstrates the method's ability to generalize effectively."}, "weaknesses": {"value": "My primary concerns with this paper are as follows:\n\n+ **The meaning of Equation 7 is not entirely clear.** The authors define it as \"the rate of signal change,\" but the numerator appears to be the derivative of the log SNR with respect to timestep t, while the denominator represents the maximum value. However, the specific physical significance of this definition is not thoroughly discussed—why is this definition accurate? The authors provide only a basic analysis in Figure 2. Therefore, I suggest that the authors elaborate further on the significance of Equation 7 and provide a more compelling analysis to justify its use.\n\n+ The conclusion that different timesteps contribute differently to the diffusion model has been extensively explored in prior works. For example, it has been observed that timesteps with high SNR are more challenging to train [1,2,3], and P2 [4] emphasizes the greater importance of intermediate timesteps—findings that are closely aligned with the motivation of this paper. I recommend that the authors review these important relevant works to highlight the novel contributions of this paper.\n\n[1] Denoising Task Difficulty-based Curriculum for Training Diffusion Models. ICLR-2025\n\n[2] Beta-tuned timestep diffusion model. ECCV-2024\n\n[3] A closer look at time steps is worthy of triple speed-up for diffusion model training. CVPR-2025\n\n[4] Perception Prioritized Training of Diffusion Models. CVPR-2022"}, "questions": {"value": "1. All experiments are built upon and evaluated with the old SD backbone, a model that is outdated and no longer representative of the current state of the field. Given the rapid shift toward transformer-based architectures like DiT, MMDiT, FLUX, and SD3, it is essential to validate the proposed method on these more advanced models. Without this, the experimental claims are difficult to generalize or take seriously.\n\n2. The latest work Meanflow [1] has already achieved high-quality generation in a single step. Could the authors discuss the respective advantages of each approach?\n\n[1] Mean Flows for One-step Generative Modeling. NeurIPS-2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YGCTqfJuY2", "forum": "GLOOoWqbCV", "replyto": "GLOOoWqbCV", "signatures": ["ICLR.cc/2026/Conference/Submission8909/Reviewer_tw27"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8909/Reviewer_tw27"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760600489512, "cdate": 1760600489512, "tmdate": 1762920661307, "mdate": 1762920661307, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an importance-based consistency distillation for diffusion models, which changes the timestep partitioning used in consistency distillation from equal partition to \"importance partition\" with more timesteps in the region of greater distributional change (in terms of signal-to-noise ratio). The authors also proposes a $\\gamma$-$I$ sampler, tailoring the existing $\\gamma$-sampler to their setting, and a couple of heuristics to mitigate the CFG exposure issue in text-to-image diffusion models. The proposed methods show consistent improvenment over exsiting Stable Diffusion-based distillation benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The proposed methods, especially the sampling scheduler in consistency training, show steady improvements on quantitative evaluation on MSCOCO, compared with other existing consistency distillation methods (Tables 1 & 2). The performance boost against existing methods except TDD is also qualitatively obvious (Figure 5). The paper essentially proposes a time-reparameterization of diffusion models so that the SNR changes linearly, which is an interesting perspective."}, "weaknesses": {"value": "While the underlying idea of the proposed method is interesting, the manuscript can be substantially improved in many aspects:\n- [W1] **Reproducibility.** It seems very difficult to reproduce the proposed methods from the paper.\n    - [W1-1] $T_I$ and $T_E$ in Eq. 8 are not defined mathematically, and I do not think the authors' explanation in natural language (e.g., \"timstep with the maximum importance in diferent intervals\") is enough.\n    - [W1-2] In Figure 1 there are multiple timesteps appearing such as $t_n, t_{n+1}$ and the target steps $t_e, t_e'$. I could not find any definition of them. How can they be derived from Section 5? \n    - [W1-3] There are basically no explanation on training in Section 6. What datasets were used for training? What is \"PCM + Ours\" for example (is it finetuned from PCM or trained with PCM from scratch with proposed timesteps)? They are not explained even in the Supplementary Material.\n- [W2] **Presentation.** The paper is not easy to read, and the presentation is not very consistent throughout the paper.\n    - [W2-1] **SNR** is referred to as an important factor of the method in Introduction (and Conclusion), but it is never mentioned in Section 2 to Section 6. Similarly, \"**deterministic-stochastic target**\" seems to be describing the feature of the proposed sampling scheduler, it only appears in Introduction and is never discussed in the method section; I do not see how the description in Section 5 is related to this concept or Figure 1 (please see [W1-2] as well).\n    - [W2-2] The method section (Section 5) is hard to read. The four different methods (adaptive sampling scheduler, $\\gamma$-$I$ sampling, color balance, clipping) are explained in a single paragraph. Moreover, **\"clipping\" is even not mentioned in Section 5**. I assume the L294-L300 explains the proposed clipping technique, but it is impossible to reproduce the method from the description.\n- [W3] **Contribution.** The framing of the contribution is not very clear.\n    - [W3-1] If the proposed method can be combined with any existing consistency distillation techniques as in Figure 5, it is worth discussing. At the current stage of the manuscript, the position of the paper is unclear; is it a method to boost existing distillation methods, or is it a stand-alone distillation method etc. The title of the manuscript also fails to describe the contribution.\n    - [W3-2] While the performance improvement from the methods except TDD is impressive, the improvement from TDD is marginal. The authors should discuss the algorithmic/performance difference between the proposed methods and TDD more seriously, since $(\\text{TDD})-(\\text{Other methods})\\approx (\\text{Proposed method}) - (\\text{Other methods})$ in performance. In addition, TDD is framed as a method taking balance between efficiency and adaptability around L126, and I think this framing also applies to the proposed method; I wonder how the methods in Section 2 and the proposed method (at least the methods compared in the experiments) are different in terms of training efficiency. The current report does not distinguish the training inefficiency from the incapability of learning few-step sampling.\n    - [W3-3] I do not see the relevance of clipping and color balance in this paper. It seems like combining two or three mini-papers on diffusion models, which makes the contribution of the paper ambiguous."}, "questions": {"value": "- [Q1] Related to [W1], what are the mathematical definitions of $T_E$ and $T_I$ and what does the actual algorithm look like given those sets (pseudocode is also fine) ?\n- [Q2] Related to [W3-2], I'm not sure whether the performance boost is only valid with limited budget or the proposed method is inherently better than existing methods when the loss converges. Do the authors have any idea on that?\n- [Q3] (Just a comment) Why computing importance and divide the timesteps into just two sets? I think placing the timesteps so that the SNR (or log-SNR) changes in the constant speed is more reasonable."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iCj4c6DJE0", "forum": "GLOOoWqbCV", "replyto": "GLOOoWqbCV", "signatures": ["ICLR.cc/2026/Conference/Submission8909/Reviewer_u8ae"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8909/Reviewer_u8ae"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760945678991, "cdate": 1760945678991, "tmdate": 1762920660941, "mdate": 1762920660941, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an approach to enhance consistency distillation methods in diffusion models for image generation. It proposes an adaptive sampling scheduler that dynamically selects timesteps based on their computed \"importance\". Experimental results demonstrate significant performance improvements, particularly with fewer sampling steps (2, 4), outperforming baselines like LCM, PCM, TCD, and TDD."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- A method that can be additionally applied with ease to a number of consistency distillation methods, and shows significant performance improvement over baselines. Qualitatively also show significant improvements."}, "weaknesses": {"value": "- This paper is not well written, and very hard to follow; mainly due to notations that are used without defining, notations significantly abused, and lots of design choices that are not justified.\n- To list some:\n  - Figure 2 shows $T=0$ to $T=999$ in DDPM. $T$ was defined to be a total number of diffusion timesteps, what does this figure mean? Does it mean $t$ instead of $T$?\n  - How does Eq (7) represent SNR? What is the motivation of the construction of this \"Importance\"? How do we know that how figure 2 changes correspond to this importance? This seems very arbitrary and not well explained.\n  - $T_I$ is defined to be: timestep with the maximum importance in different intervals. While $T_I$ seems to be a set, what is this \"different intervals\"?\n  - What is original equidistant sampling timestep $T_E$? Is this a set $\\{1,2,...,T\\}$?\n  - $\\theta$ is both used for $f_\\theta$ and a hyperparameter for adaptive sampling: which is confusing. Why setting $\\theta=0.7$ is a reasonable choice?\n  - What is $T_n$?\n  - How is Figure 4(a) related to Eq (8)? Where is $T_I$ in Figure 4(a)? It is not clear from the figure whether $T_E$ and $T_{as}$  are sets.\n  - If $\\gamma$ sampler is an algorithm central in the development of the proposed $\\gamma-I$ sampler, it should have been explained in Preliminaries.\n  - How is $\\gamma-I$ sampler different from $\\gamma$ sampler?\n  - As far as I understand, $\\gamma-I$ sampler is the sampler that uses $\\gamma$-sampler when $t_n \\in T_E$ and uses $R_t$ instead of $\\sqrt{(1-\\gamma)^2}$ when $t_n\\in T_I$. Is this correct? It is very hard to infer this, as there is no textual description at all on this, and equations somehow have different indices $n+1$ and $n$ for these two cases. The text says we need to look at figure, but figure also does not have much information.\n  - What is \"varying degrees of exposure issues\"?\n  - What is the solutions offered by Saharia et al and Lu et al?\n  - Why $\\alpha,\\beta=0.5$ a reasonable choice? and it is very confusing to have $\\alpha,\\beta$ and $\\alpha_t,\\beta_t$ at the same time with very different meanings.\n  - It is very confusing to have Eq. (11) with equalities, as those are program statements, not equations.\n\n- Overall, the paper shows strong experimental results, but provides so little motivations on the heuristical design of the proposed approach. Experimental results are mostly about the performance metrics, not about why these works. Moreover, the proposed method itself is only summarized in a single page, which is very poorly written that it is almost impossible to fully understand."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XPo2M9Dt98", "forum": "GLOOoWqbCV", "replyto": "GLOOoWqbCV", "signatures": ["ICLR.cc/2026/Conference/Submission8909/Reviewer_Xe4N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8909/Reviewer_Xe4N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761484323200, "cdate": 1761484323200, "tmdate": 1762920660609, "mdate": 1762920660609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an Adaptive Sampling Scheduler for consistency-distilled diffusion models. The key idea is to compute the **importance of each timestep** based on the rate of change in the Signal-to-Noise Ratio (SNR), and to sample timesteps non-uniformly, allocating denser sampling in regions where the SNR changes more rapidly. The authors argue that existing deterministic or stochastic schedulers ignore such non-uniform importance and hence fail to allocate computation efficiently.\n\nEmpirically, the method reportedly improves generation quality across several few-step sampling settings (2–8 steps) on SDXL and SD-v1.5 backbones, especially under high CFG scales."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper contributes to the growing literature on **sampling efficiency and timestep scheduling** in consistency distillation, a topic of active research interest.\n* The formulation of timestep “importance” through SNR change rate provides an interpretable heuristic criterion that can be implemented easily in practice.\n* The empirical gains (especially in the extreme few-step regime) show potential practical relevance for the consistency model."}, "weaknesses": {"value": "I have marked particularly important points with a star (★).\n\n★ **Misleading Terminology — “Adaptive”**\nThis is a personal opinion, but the term *adaptive* in “Adaptive Sampling Scheduler” is misleading. Despite the name, the scheduler is **not adaptive in the learning or inference sense**, i.e., it does not adjust dynamically to data, training feedback, or model states. The so-called adaptivity arises solely from a **pre-computed, deterministic heuristic** derived from the fixed noise schedule.\n\nThus, the method is better characterized as a *static, SNR-weighted timestep scheduler* rather than an adaptive one.\n\n**Literature review**\nNon-uniform or importance-weighted timestep sampling has been studied extensively. Relevant prior works have proposed to:\n\n* Heuristic: Log-normal distribution with respect to SNR, e.g., Elucidating the Design Space of Diffusion-Based Generative Models (https://arxiv.org/abs/2206.00364), SD3 (https://arxiv.org/abs/2403.03206)\n* Theory: Equalize conditional entropy across timesteps (https://arxiv.org/abs/2504.13612v3; https://arxiv.org/abs/2211.15089).\n\n★ **Experimental Scope and Baseline Fairness**\nExperiments are limited to **text-to-image** (T2I) diffusion models (SDXL, SD-v1.5). Given the general claim of universality across consistency distillation methods, broader validation is expected. I strongly recommend including **CIFAR-10** and comparing against canonical methods such as **sCM** (https://arxiv.org/abs/2410.11081) and **ECM** (https://arxiv.org/abs/2406.14548) using the proposed scheduler. Please compare the method's performance based on FID, or FD-DINO (https://arxiv.org/abs/2306.04675). This would demonstrate whether the gains persist beyond high-capacity text-conditioned models.\n\n* The paper does not clarify whether baselines were re-tuned or simply reused. The reported numbers for PCM/TCD/TDD appear substantially worse than typically published, raising concerns about fair comparison."}, "questions": {"value": "Ablations on smoothing and color balance and I-$\\gamma$-sampler are presented only qualitatively. Please provide quantitative comparisons (e.g., FID) for these components."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pFcsP6Kqoi", "forum": "GLOOoWqbCV", "replyto": "GLOOoWqbCV", "signatures": ["ICLR.cc/2026/Conference/Submission8909/Reviewer_hCpJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8909/Reviewer_hCpJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948695615, "cdate": 1761948695615, "tmdate": 1762920660238, "mdate": 1762920660238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}