{"id": "BxGrZFfTp5", "number": 6807, "cdate": 1757996674727, "mdate": 1759897892349, "content": {"title": "L4Dog: Towards BEV Perception for Quadruped Robots in Complex Urban Scenes", "abstract": "Embodied intelligence in quadruped robots faces significant challenges in complex urban environments due to the limitations of traditional perception systems and the lack of comprehensive datasets for exteroceptive 3D perception. To address this, we introduce L4Dog, the first large-scale exteroceptive 3D perception dataset tailored for quadruped robots in open urban scenarios. L4Dog provides high-quality 360-degree surround-view sensor data and manual annotations, covering diverse urban scenes such as traffic-light intersections, open roads, subway station, etc. By formulating perception tasks as bird’s-eye-view (BEV) space perception problems, we establish a multi-benchmark framework for BEV detection, tracking, trajectory prediction, and 3D traversable space occupancy estimation. The OmniBEV4D baseline method is proposed to unify multi-task perception (detection, tracking, prediction, and occupancy prediction) through shared temporal BEV features, enabling efficient and robust processing of dynamic urban environments. This work bridges the gap between current research and real-world deployment needs, offering a foundational resource for advancing autonomous navigation and decision-making in complex urban settings. The dataset will be made publicly available upon acceptance of this work.", "tldr": "", "keywords": ["quadruped robot perception", "dataset and benchmark"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/13f38fbf199f8e2f2e2c2a7a0f9cc0cdae29752c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents L4Dog, a large-scale exteroceptive 3D perception dataset designed for quadruped robots in complex urban environments. It offers 360° surround-view sensor data with manual annotations across diverse scenes and introduces a unified BEV-based multi-task perception framework (OmniBEV4D) for detection, tracking, prediction, and occupancy estimation. The work aims to bridge the gap between research and real-world deployment by providing a comprehensive benchmark for embodied intelligence in urban navigation."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "•  The dataset is of impressive scale and diversity, covering highly complex urban scenarios.\n\n•  Collecting and annotating such large-scale multimodal data is a major effort and can benefit future research in robotics.\n\n•  The unified BEV-based formulation provides a coherent framework for multiple perception tasks, which may inspire follow-up work."}, "weaknesses": {"value": "•  Although the paper emphasizes embodied intelligence, it primarily focuses on perception tasks. It would be valuable to include benchmarks or discussions related to Vision-and-Language Navigation (VLN) or Visual Question Answering (VQA) to demonstrate broader embodied reasoning capabilities.\n\n•  The paper presentation could be improved: the use of \\citet and \\citep is wrong, and table captions are placed awkwardly, affecting readability."}, "questions": {"value": "How does the proposed OmniBEV4D framework generalize across different robot platforms or sensor configurations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Gft7n2QZNN", "forum": "BxGrZFfTp5", "replyto": "BxGrZFfTp5", "signatures": ["ICLR.cc/2026/Conference/Submission6807/Reviewer_xKdU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6807/Reviewer_xKdU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761237536975, "cdate": 1761237536975, "tmdate": 1762919077266, "mdate": 1762919077266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a dataset designed to evaluate BEV (Bird’s Eye View) perception for quadruped robots. Example BEV perception tasks include object detection, tracking, trajectory prediction, and occupancy prediction. The dataset contains both indoor and outdoor scenes and is substantially larger than those used in related studies.\n\nThe primary strength of this dataset lies in its scale. However, the dataset offers limitated coverage for complex terrain, which is a key capability of quadruped robots. Additionally, the paper does not clearly describe the identity anonymization procedures used in the dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. BEV perception for quadruped robots is an important research direction, and there is a clear need for a more comprehensive dataset in this area. The proposed dataset targests a key research gap in this domain. \n2. In terms of scale, it is significantly larger than those presented in related works."}, "weaknesses": {"value": "1. Missing complex terrain: If I understand correctly, the proposed dataset primarily contains planar terrain scenarios, both indoor and outdoor. However, it lacks coverage of challenging vertical terrains such as hills, slopes, stairs, and elevators. This omission is significant because one of the key advantages of quadruped robots over wheeled robots is their ability to navigate complex and uneven terrain. As a result, the dataset is limited in its ability to support comprehensive evaluation of future quadruped robot perception research.\n2. Additionally, the paper does not clearly describe the identity anonymization procedures used in the dataset."}, "questions": {"value": "1. It would be valuable to include a comparison of motion statistics with related datasets. For example, presenting pitch, roll, yaw, and acceleration curves from the quadruped robot’s motion sensors could help assess the complexity of the terrains captured in this dataset.\n2. Furthermore, the data collection process may involve identity-related information such as children, human faces, or vehicle license plates. The paper should clarify how such sensitive information is handled during data collection and processing to ensure proper anonymization and ethical compliance."}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "The paper does not clearly describe the identity anonymization procedures used in the dataset."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e7EnjX2ZIO", "forum": "BxGrZFfTp5", "replyto": "BxGrZFfTp5", "signatures": ["ICLR.cc/2026/Conference/Submission6807/Reviewer_igbW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6807/Reviewer_igbW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861402379, "cdate": 1761861402379, "tmdate": 1762919076847, "mdate": 1762919076847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a large-scale BEV perception dataset for quadruped robots in complex urban scenarios, featuring high-quality manual annotations. A benchmark and baseline framework tailored for the evaluation and modeling of simultaneous multiple BEV perception tasks is concomitantly established. The paper is also the first one to contribute 360-degree occupancy annotations with a corresponding network."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. To address the limitation of perception data for quadruped robotics in complex real-world urban scenarios, a large-scale 3D perception dataset with high-quality manual annotations for multiple BEV tasks is established.\n2. The proposed dataset contains high-quality 360-degree 3D occupancy annotations for fine-grained quadruped robotics perception, with a corresponding occupancy prediction network.\n3. A multi-task framework with shared temporal BEV space for multiple BEV perception tasks is developed.\n4. Experimental results demonstrate the effectiveness of the multi-task framework."}, "weaknesses": {"value": "1. Concern about the generalization ability. As shown in Fig. 3(b), the number of classes is fixed to several, which may hinder the generalization to objects beyond the predefined categories.\n2. What's the detailed architecture of the proposed OmniBEV4D?"}, "questions": {"value": "1. What are the actual computational costs of OmniBEV4D, in terms of memory consumption, latency, etc?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IpZ00zDJ4r", "forum": "BxGrZFfTp5", "replyto": "BxGrZFfTp5", "signatures": ["ICLR.cc/2026/Conference/Submission6807/Reviewer_adqi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6807/Reviewer_adqi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154426303, "cdate": 1762154426303, "tmdate": 1762919076427, "mdate": 1762919076427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a large-scale BEV perception dataset for quadruped robots in complex urban scenarios, featuring high-quality manual annotations. A benchmark and baseline framework tailored for the evaluation and modeling of simultaneous multiple BEV perception tasks is concomitantly established. The paper is also the first one to contribute 360-degree occupancy annotations with a corresponding network."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. To address the limitation of perception data for quadruped robotics in complex real-world urban scenarios, a large-scale 3D perception dataset with high-quality manual annotations for multiple BEV tasks is established.\n2. The proposed dataset contains high-quality 360-degree 3D occupancy annotations for fine-grained quadruped robotics perception, with a corresponding occupancy prediction network.\n3. A multi-task framework with shared temporal BEV space for multiple BEV perception tasks is developed.\n4. Experimental results demonstrate the effectiveness of the multi-task framework."}, "weaknesses": {"value": "1. Concern about the generalization ability. As shown in Fig. 3(b), the number of classes is fixed to several, which may hinder the generalization to objects beyond the predefined categories.\n2. What's the detailed architecture of the proposed OmniBEV4D?"}, "questions": {"value": "1. What are the actual computational costs of OmniBEV4D, in terms of memory consumption, latency, etc?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IpZ00zDJ4r", "forum": "BxGrZFfTp5", "replyto": "BxGrZFfTp5", "signatures": ["ICLR.cc/2026/Conference/Submission6807/Reviewer_adqi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6807/Reviewer_adqi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154426303, "cdate": 1762154426303, "tmdate": 1763723068714, "mdate": 1763723068714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}