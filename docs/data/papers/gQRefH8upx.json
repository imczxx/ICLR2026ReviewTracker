{"id": "gQRefH8upx", "number": 2836, "cdate": 1757268171493, "mdate": 1759898124070, "content": {"title": "KnowGuard: Knowledge-Driven Abstention for Multi-Round Clinical Reasoning", "abstract": "In clinical practice, physicians refrain from making decisions when patient information is insufficient. This behavior, known as abstention, is a critical safety mechanism preventing potentially harmful misdiagnoses. Recent investigations have reported the application of large language models (LLMs) in medical scenarios. However, existing LLMs struggle with the abstentions, frequently providing overconfident responses despite incomplete information. This limitation stems from conventional abstention methods relying solely on model self-assessments, which lack systematic strategies to identify knowledge boundaries with external medical evidences. To address this, we propose \\textbf{KnowGuard}, a novel \\textit{investigate-before-abstain} paradigm that integrates systematic knowledge graph exploration for clinical decision-making. Our approach consists of two key stages operating on a shared contextualized evidence pool: 1) an evidence discovery stage that systematically explores the medical knowledge space through graph expansion and direct retrieval, and 2) an evidence evaluation stage that ranks evidence using multiple factors to adapt exploration based on patient context and conversation history. This two-stage approach enables systematic knowledge graph exploration, allowing models to trace structured reasoning paths and recognize insufficient medical evidence. We evaluate our abstention approach using open-ended multi-round clinical benchmarks that mimic realistic diagnostic scenarios, assessing abstention quality through accuracy-efficiency trade-offs beyond existing closed-form evaluations. Experimental evidences clearly demonstrate that KnowGuard outperforms state-of-the-art abstention approaches, improving diagnostic accuracy by 3.93\\% while reducing unnecessary interaction by 7.27 turns on average.", "tldr": "", "keywords": ["multi-agent system", "clinical reasoning", "medical question answering"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/095443f3fd690a8df9b9cbc2dc95272ae33b289a.pdf", "supplementary_material": "/attachment/d6c82dfd5d96ad1a156301f0876cf63566f1fce2.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces KnowGuard, a framework for LLMs that leverages knowledge graphs to drive abstention decisions in multi-round clinical reasoning. Instead of solely relying on internal knowledge, KnowGuard explores structured medical knowledge to identify evidence gaps before making or abstaining from a diagnosis. The approach involves a two-stage process: evidence discovery (systematic retrieval and expansion of relevant medical facts) and evidence evaluation (multi-factor scoring and prioritization, including graph coherence, embedding similarity, LLM selection, temporal decay, and patient population reasoning). Experiments on several open-ended multi-round clinical benchmarks show that KnowGuard achieves improved diagnostic accuracy and reduced unnecessary patient-provider interaction compared to existing abstention and reasoning strategies."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focuses on the valuable and practical issue of abstention in multi-round dialogue for LLM-based medical diagnosis, which is essential for efficiency and reliability in clinical applications.\n2. The proposed approach achieves improvements in both diagnostic accuracy and the number of interaction rounds compared to  baselines. Comprehensive ablation studies further validate the independent contributions of each module."}, "weaknesses": {"value": "1. Limited Novelty in Retrieval and Evaluation Mechanisms: The specific mechanisms for evidence retrieval and evaluation do not appear fundamentally innovative beyond existing literature on RAG and knowledge-enhanced medical reasoning. The paper would benefit from a clearer positioning against recent state-of-the-art works utilizing similar approaches.\n2. Incomplete Evaluation of Abstention Performance: Although timely and appropriate abstention is claimed as the core motivation, the paper lacks dedicated abstention-quality metrics. The evaluation is limited to diagnostic accuracy and conversation turns; it omits quantitative analysis of abstention rates, false or missed abstention cases, the timing of abstention decisions, and abstention precision/recall. \n3. Limited Baseline Coverage: The experimental section does not provide thorough comparisons with more recent or diverse RAG architectures, especially those specifically designed for clinical reliability or abstention tasks. This limits the strength of the claims regarding advancement over existing retrieval-enhanced methods.\n4. Absence of Expert Evaluation and Real-World Validation: The evaluation is fully automated and lacks assessment by clinical experts or real-world usability studies. This limits evidence for practical utility and adoption outside of benchmark datasets.\n5. Knowledge Coverage and Maintenance Concerns: There is insufficient discussion of the medical knowledge graph’s domain completeness, update frequency, and capacity for handling rare, newly emerging, or rapidly changing conditions. Without assurances of knowledge freshness and coverage, the real-world effectiveness and reliability may be restricted.\n6. Scalability and Resource Overhead Not Addressed: The method’s multi-stage retrieval and repeated evidence evaluation may introduce considerable computational and resource costs, but there are no experiments or analysis regarding runtime efficiency, memory footprint, or suitability for deployment at scale.\n7. Lack of robustness to noisy or misleading evidence: The paper does not analyze how KnowGuard handles noisy or misleading evidence during retrieval. It is unclear whether the system becomes overconfident or makes errors when faced with irrelevant or conflicting information. Experiments testing robustness to noise and corresponding mitigation strategies are missing."}, "questions": {"value": "Please see the weaknesses section for detailed discussion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "i5vtWMGHV1", "forum": "gQRefH8upx", "replyto": "gQRefH8upx", "signatures": ["ICLR.cc/2026/Conference/Submission2836/Reviewer_Zuzr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2836/Reviewer_Zuzr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2836/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761138184375, "cdate": 1761138184375, "tmdate": 1762916399593, "mdate": 1762916399593, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "KnowGuard tackles a common clinical LLM flaw: giving confident answers when evidence is thin. It builds a medical knowledge graph and, at each turn, searches and scores external evidence (embedding match, LLM relevance, graph coherence, time decay, and patient-population signals) before either asking a pointed follow-up or answering with support. The authors test it on a new multi-round benchmark drawn from MEDQA, CRAFT-MD, and AFRIMEDQA against confidence-based abstention, self-consistency, and long-context retrieval, plus ablations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The proposed multi-round medical QA benchmark is well-motivated and thoughtfully curated, with a clear connection to real clinical reasoning processes. \n\n(2) The paper is well-presented, offering a clear and structured introduction to each module of the proposed framework."}, "weaknesses": {"value": "(1) The evaluation is narrow. Experiments report accuracy but omit calibration/uncertainty metrics (e.g., ECE, Brier, NLL, risk–coverage) and related baselines (temperature scaling, ensembles, conformal methods). Given the risk-aware motivation, it’s unclear why these are absent. \n\n(2) The knowledge-graph integration is described only at a high level. Key implementation details, e.g., entity/relation extraction, the graph-search/expansion algorithm, how graph signals are fused with LLM scores, and crucial hyperparameters. These details are scattered in the appendix or left implicit, which limits reproducibility and interpretability."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns", "Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "The work targets medical decision-making but reports only accuracy-style metrics and lacks subgroup fairness/calibration analysis. Without clear disclosure of dataset composition and demographic performance, there’s a risk of biased or unsafe behavior, especially around abstention decisions. The paper should also carry stronger non-clinical-advice disclaimers."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "36DiklELUk", "forum": "gQRefH8upx", "replyto": "gQRefH8upx", "signatures": ["ICLR.cc/2026/Conference/Submission2836/Reviewer_6Fan"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2836/Reviewer_6Fan"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2836/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761870034556, "cdate": 1761870034556, "tmdate": 1762916399385, "mdate": 1762916399385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an Investigate-Before-Abstain (IBA) framework for multi-round clinical question answering with large language models. Instead of forcing the model to answer or abstain directly, the method first expands a medical knowledge graph through two modes—graph-based neighborhood traversal and direct retrieval—to assemble an evidence pool before making the decision to answer, abstain, or query further. A new benchmark combining MEDQA, CRAFT-MD, and AFRIMEDQA is introduced to evaluate open-ended multi-round dialogue. Experiments show that IBA improves factual accuracy and abstention calibration over baseline systems such as simple retrieval-augmented generation or confidence-based abstention"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "•\tTackles a meaningful and under-explored problem: when and how clinical agents should abstain.\n\n•\tTechnically coherent pipeline that bridges knowledge-graph reasoning with retrieval-augmented generation.\n\n•\tNew benchmark resource and detailed evaluation across multiple datasets.\n\n•\tSolid empirical results demonstrating improvements in both correctness and cautiousness metrics."}, "weaknesses": {"value": "• Somewhat heuristic combination of scoring factors; lacks ablation or theoretical grounding for weights.\n\n•\tBenchmark construction may inherit biases from source datasets; unclear generalizability to unseen guideline domains.\n\n•\tLimited discussion of system latency or computational cost compared with long-context baselines.\n\n•\tNo human expert evaluation to verify that “abstain” decisions align with clinical expectations."}, "questions": {"value": "1.\tHow sensitive are results to the relative weights among the five scoring components?\n\n2.\tCould the approach be extended to handle contradictory or time-evolving medical evidence (e.g., updated guidelines)?\n\n3.\tDoes the model explicitly track patient-specific vs. population-level context, or is this purely implicit through graph features?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v1F86rZ0XQ", "forum": "gQRefH8upx", "replyto": "gQRefH8upx", "signatures": ["ICLR.cc/2026/Conference/Submission2836/Reviewer_gj7Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2836/Reviewer_gj7Q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2836/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956876069, "cdate": 1761956876069, "tmdate": 1762916399079, "mdate": 1762916399079, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical problem of overconfidence in Large Language Models (LLMs) used for clinical reasoning. Current LLMs often provide premature or incorrect diagnoses when patient information is incomplete, failing to \"abstain\" as a human physician would. In the paper, the authors propose KnowGuard, a novel \"investigate-before-abstain\" paradigm. Instead of asking \"how confident am I?\", KnowGuard systematically investigates \"what specific evidence am I missing?\" by exploring an external, multi-modal medical KG. The authors converted the traditional medical datasets into interactive-multi-round formats for the evaluation of the proposed method. Through the experiments, the results show that the proposed method outperform the baseline methods by an obviously large margin."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation and the writing of the paper is clear and easy to follow, and the framework seems very reasonable and intuitive, which could be convenient for downstream applications. The paper addresses the critical and unsolved problem of LLM overconfidence and its failure to abstain, which is a major barrier to deploying AI in high-stakes fields like medicine.\n2. The presentation of the framework and case study is very clear and informative for readers to understand the use scenarios.\n3. From the results of the experiment section, the proposed method is very effective in terms of accuracy in the constructed datasets."}, "weaknesses": {"value": "1. The details of the how the constructed datasets were incorporated with other baseline methods are not described in the experiment section or the appendix. I think it would be better to describe in more details of how you ensure that the baseline methods get the same extent of information and knowledge during evaluation with KnowGuard.\n2. I have some questions on the necessity of evaluating conversation turn count for the proposed method. To my understanding, it seems that the proposed method can benefit from gathering more information with more turn counts. Given Figure 3 (Left) shows accuracy improving with conversation length, should the method's strength be framed as \"more effective use of turns\" rather than \"reduction of turns\"?\n3. The method relies heavily on the external KG. How does the system behave when the correct diagnostic evidence is not present in the knowledge graph? Does it learn to abstain gracefully due to a lack of a coherent evidence path, or could the lack of a positive \"hit\" lead it to a premature (and incorrect) answer?"}, "questions": {"value": "See the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Dq8VXTn5hp", "forum": "gQRefH8upx", "replyto": "gQRefH8upx", "signatures": ["ICLR.cc/2026/Conference/Submission2836/Reviewer_daFK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2836/Reviewer_daFK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2836/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762031415791, "cdate": 1762031415791, "tmdate": 1762916398806, "mdate": 1762916398806, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}