{"id": "bbbcARy3Hf", "number": 5014, "cdate": 1757833763119, "mdate": 1759898000234, "content": {"title": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction", "abstract": "Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable evolutionary trajectory, characterized by the continual emergence of immune-evasive variants. This poses persistent challenges to public health and vaccine development. \n\n While large-scale generative pre-trained transformers (GPTs) have revolutionized the modeling of sequential data, their direct applications to noisy viral genomic sequences are limited. In this paper, we introduce PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based on evolutionary trajectories derived from phylogenetic trees rather than raw RNA sequences. This method effectively mitigates sequencing noise and captures the hierarchical structure of viral evolution. \n\nWith a weighted training framework to address substantial geographical and temporal imbalances in global sequence data, PETRA excels in predicting future SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide mutations and 17.10% for spike amino-acid mutations, compared to 0.49% and 6.64% respectively for the best baseline. PETRA also demonstrates its ability to aid in the real-time mutation prediction of major clades like 24F(XEC) and 25A(LP.8.1).", "tldr": "A transformer pretrained on evolutionary trajectory aids real-world SARS-CoV-2 mutation prediction.", "keywords": ["Generative Pretrained Transformers", "Phylogenetics", "Mutation Prediction", "Computational Biology", "SARS-CoV-2 Prediction"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1c0bb970f5f9a0c2b7d9bf53a9bb1c381d16cf6e.pdf", "supplementary_material": "/attachment/84ce67d444965a9605ab5b960f776f9d61cde654.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes PETRA, a transformer trained on evolutionary trajectories extracted from phylogenetic trees (UShER) rather than raw RNA sequence. They found PETRA can predict future SARS-CoV-2 mutations with a weighted recall@1 of 9.45% for nucleotide mutations and 17.10% for spike amino-acid mutations, which is a large improvement compared to 0.49% and 6.64% of the respective baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is overall well-structured and clearly written. It tackles an important problem of predicting SARS-CoV-2 evolution."}, "weaknesses": {"value": "- The quality of the underlying phylogenetic trees data is questionable. The authors themselves acknowledge that the variant definitions from UShER, Nextstrain, and Cov-Spectrum “disagree in a lot of corner cases.”\n- The sampling probability and temporal reweighting appears somewhat arbitrary, and it risk overfitting to recent and over-represented regions.\n- Treating each country as homogeneous can distort the representativeness weighting and exaggerate biases toward well-sequenced urban centers."}, "questions": {"value": "- The three-step variant-definition pipeline is reasonable, but appears heuristic. Have you evaluated the robustness of your method when trained on different tree construction methods? \n- Any ablations to show sensitivity of sampling probability and temporal factor parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VwzUmDl6Nc", "forum": "bbbcARy3Hf", "replyto": "bbbcARy3Hf", "signatures": ["ICLR.cc/2026/Conference/Submission5014/Reviewer_vbe6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5014/Reviewer_vbe6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761114820318, "cdate": 1761114820318, "tmdate": 1762917822084, "mdate": 1762917822084, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors trained a GPT model on top of existing sars-cov-2 sequences and try to predict the possible \"next-strain\" using the learned \"evolutionary plausibility\". While previous community effort on protein engineering have proven this strategy is effective, this paper is one of the several attempts in applying the same schema to dangerous infectious virus."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well written."}, "weaknesses": {"value": "1. The model learns to extrapolate the pre-existing UShER tree, not viral evolution itself, making it useless for novel variants like Omicron where no such tree exists. It is pattern-matching on a graph, not learning biology.\n2. The evaluation is critically flawed by the omission of direct comparisons to the actual state-of-the-art viral forecasting models discussed in recent scientific literature (e.g., scientific works mentioned in Nature News: https://www.nature.com/articles/d41586-024-04195-3).\n3. The necessity of a massive GPT architecture is unproven, as the paper fails to benchmark against a much simpler, non-GPT autoregressive model applied to the same trajectory data.\n4. Despite its predictive goal, the paper offers zero actionable scientific insights or generalizable rules of evolution, failing to justify the ethical risks of training a generative model on a dangerous pathogen.\n5. The authors' ethical defense—that the model only predicts \"natural\" mutations—is doubly flawed: if so, why do we need your model? And the authors naively ignores the well-known risk of Transformer hallucination. Training generative models on viral sequences is fundamentally irresponsible."}, "questions": {"value": "See comments above"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "This paper presents a fundamental and severe ethical problem that, in my view, makes it unsuitable for publication. The authors have trained a generative model, PETRA, with the explicit goal of predicting future, potentially more successful, mutations of SARS-CoV-2. This constitutes a form of in-silico gain-of-function research, providing a roadmap for engineering more dangerous viral variants. The authors' plan to release their models and code publicly is deeply irresponsible, as it would democratize access to a tool that could be misused for malicious purposes. The potential benefit of forecasting natural variants does not outweigh the significant and foreseeable risk of abuse. The entire line of research is ethically questionable and represents a dangerous precedent for the field of generative AI in biology."}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KBHpC82uwU", "forum": "bbbcARy3Hf", "replyto": "bbbcARy3Hf", "signatures": ["ICLR.cc/2026/Conference/Submission5014/Reviewer_DEE8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5014/Reviewer_DEE8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962067014, "cdate": 1761962067014, "tmdate": 1762917821781, "mdate": 1762917821781, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a transformer-based model, called PETRA, for learning the sequence of SARS-CoV-2 mutations which accumulate over time in different variants. A time- and geography- based weighting scheme is used to mitigate the effects of sampling biases and sampling time. The model can then be probed to predict the next mutations. On a new benchmark introduced in this paper, PETRA outperforms Bloom scores on predicting novel mutations of SARS-CoV-2."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The time- and geography- based weighting is interesting and sounds more broadly applicable.\n- The way in which the sequence is encoded is interesting -- one-hot encoding each site x mutation pair and concaternating them.\n- Careful temporal train/test splits."}, "weaknesses": {"value": "- The paper is poorly written in terms of grammar and phrasing. The abstract is split into three paragraphs. Grammatical errors are broadly present. Citation is non-standard, with citations after the period. An oddly harsh and dismissive phrase is used when referring to existing work:\n\n\"There also exist researches attempting to build up transformer-based models directly for SARS-CoV-2. (Shou et al., 2023; Feng et al., 2024) Nevertheless, these attempts focus on specially framed datasets of sequences from certain countries and time periods, and are hard to generalize and update according to developments of the virus, making them practically useless.\"\n\nIt is very likely that (1) this is the first time the authors are submitting to a major ML conference, (2) the authors are not fluent in English. These are not grounds for rejection, but it undermines the quality of the work.\n\n-  The Bloom baseline is described as a \"deep-mutational-scanning(DMS) based project\" [side note: the space IS missing from the main text. There are several instances of these kinds of formatting oversights]. I took a look at the Bloom paper and it seems that Bloom is not a DMS-based method. The Bloom method used phylogenetic trees (much like PETRA) to map mutations and count their frequencies, leading to the fitness estimates for different mutations. The Bloom method is *validated* against DMS data, but is not a DMS-based method.\n- PETRA only evaluates on its own mutation prediction task. How do the PETRA predictions correlate to the DMS datasets used in the Bloom paper? This would at least provide a clearer comparison against Bloom.\n- It is not clear to me that Bloom scores are being used as intended by the Bloom paper. The PETRA paper proposes a composite Bloom score via s = ce^{\\alpha f} which they show does better on their mutation prediction task than the Bloom fitness score or expected counts. This is quite odd. Why wouldn't the original Bloom paper propose such as score? Would this composite score s = ce^{\\alpha f} also improve the Bloom correlations against DMS? Overall, it is not clear to me that the Bloom scores are being used as expected. Some discussion is necessary. The paper also arbitrarily sets \\alpha=1 with no explanation."}, "questions": {"value": "- Why did you split the abstract into three paragraphs?\n- Why do you place citations after the period?\n- Do you agree that the phrase \"making them practically useless\" is oddly harsh and dismissive of current published scientific work?\n- Why do you call Bloom a \"deep-mutational-scanning(DMS) based project\"? From what I gathered from the Bloom paper, Bloom is a tree-based method (much like PETRA), which is *validated* against DMS data.\n- Have you considered validating against the same DMS data as in the Bloom paper? While DMS data is not ground truth (several counterintuitive DMS scores are discussed in the Bloom paper), it would provide additional support for the performance of PETRA.\n- How did you come up with the s = ce^{\\alpha f} score for Bloom? How did you choose \\alpha=1?\n- Do you think the s = ce^{\\alpha f} score for Bloom would improve correlation to DMS data?\n- How exactly do you use Bloom scores to rank mutations? Provide further background on Bloom and how you use it in your benchmark."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XS6drw3QoB", "forum": "bbbcARy3Hf", "replyto": "bbbcARy3Hf", "signatures": ["ICLR.cc/2026/Conference/Submission5014/Reviewer_Zz8M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5014/Reviewer_Zz8M"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982899283, "cdate": 1761982899283, "tmdate": 1762917821427, "mdate": 1762917821427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript introduces PETRA, a pretrained evolutionary modeling framework designed to estimate virus mutations. PETRA leverages large-scale evolutionary sequence data to learn statistical patterns of antigen diversification, eliminating the need for experimental assays such as deep mutational scanning. The model outputs mutation-level fitness scores and functional annotations, and is intended to support high-throughput antigen evaluation and rational vaccine design. By learning both global evolutionary constraints and local biophysical signals, PETRA aims to generalize to previously unseen antigens and assist in predicting which mutations are likely to emerge or be tolerated under immune selection pressure."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "A key strength of PETRA is that it addresses a major bottleneck in immunogen design: experimental characterization of mutational effects is slow, expensive, and inherently incomplete. The model’s zero-shot capability suggests it captures generalizable evolutionary principles rather than memorizing training examples. The authors emphasize that mutational fitness depends jointly on structural context and immune-driven selection, an important insight consistent with known antigenic drift dynamics. PETRA’s ability to annotate mutation functionality at scale is highly relevant for surveillance pipelines, early variant risk assessment, and computational vaccine candidate prioritization. The approach is also timely, given the growing interest in foundation-style models for biological sequence evolution."}, "weaknesses": {"value": "One limitation is that the manuscript appears to focus primarily on sequence-based learning; explicit integration of three-dimensional structural context, epistatic coupling, or antibody–antigen interface geometry is not clearly articulated. Viral evolution is strongly epistatic, yet the evaluation setup seems to emphasize single-mutation effects, leaving open how well PETRA handles combinatorial variants observed in real variants of concern. The experimental validation section would benefit from broader benchmarking against state-of-the-art protein language models, sequence-to-fitness predictors, or phylogenetic fitness estimators. It is also unclear how robust PETRA is across diverse viral families with different evolutionary pressures. Finally, while zero-shot results are highlighted, the study does not deeply quantify failure cases, calibration, or false-positive risk."}, "questions": {"value": "1. How does PETRA model non-additive interactions among multiple mutations, especially those common in real antigenic evolution (e.g., RBD co-mutational clusters)?\n2. Does the model incorporate protein structure (e.g., contact maps, surface exposure), and if not, how might this limitation impact predictions at antibody epitopes?\n3. How well does PETRA transfer to viruses with distinct evolutionary constraints, such as influenza HA or HIV Env?\n4. Are fitness scores calibrated to biological magnitude (e.g., effect sizes comparable to deep mutational scanning measurements), or only relative rankings?\n5. Can PETRA highlight specific residues or functional regions driving predicted fitness changes, and are these consistent with known neutralizing epitopes?\n6. What controls are in place to avoid over-prediction of beneficial mutations, given that most random mutations are deleterious in nature?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hsxPsEIZxt", "forum": "bbbcARy3Hf", "replyto": "bbbcARy3Hf", "signatures": ["ICLR.cc/2026/Conference/Submission5014/Reviewer_UrUX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5014/Reviewer_UrUX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998170736, "cdate": 1761998170736, "tmdate": 1762917821038, "mdate": 1762917821038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}