{"id": "8TkNRNboyg", "number": 3922, "cdate": 1757568224081, "mdate": 1759898062503, "content": {"title": "Towards Understanding the Effect of NTP Paradigm in Unstructured Knowledge Editing", "abstract": "Editing Large language models (LLMs) with real-world, unstructured knowledge is critical for correcting and updating their internal knowledge bases. However, current methods often oversimplify this knowledge, leading to information loss and suboptimal performance.\nWhile existing editing techniques based on the next-token prediction (NTP) paradigm show promise, our investigation reveal a core limitation: context reliance. The edited knowledge heavily rely on the preceding context available during editing, but this context is often absent in practical inference. This gap between editing and inference limits the generalization of acquired knowledge. We validate this issue both theoretically and experimentally, demonstrating that the absence of preceding context prevents model from recalling the edited knowledge, thereby causing a performance drop on editing success rate.\nTo address this, we propose a simple yet effective COntext-INdependent unstructured knowledge editing framework (COIN), encouraging the model to internalize new knowledge properly, rather than merely memorizing fixed patterns with its preceding context.\nComprehensive evaluations show that COIN significantly reduces the performance drop and outperforms strong baselines by 23.6\\% in editing success rate, highlighting the potential of NTP paradigm for robust unstructured knowledge editing.", "tldr": "We identify the context reliance problem in the NTP paradigm for unstructured knowledge editing and develop a simple yet effective mitigation strategy.", "keywords": ["Large language models", "Knowledge editing"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c8e2ed4cd2eadd7ce67437bfdcf2dce5520ef04b.pdf", "supplementary_material": "/attachment/dab68f11219e2db3fff7aef74ff59dce130f16da.zip"}, "replies": [{"content": {"summary": {"value": "This paper identifies a significant and previously underexplored issue in unstructured knowledge editing for Large Language Models (LLMs): context reliance within the Next-Token Prediction (NTP) paradigm. \n\nThe authors observe that knowledge edited into a model using full-text NTP becomes overly dependent on its preceding context, leading to a performance drop when that context is absent during inference. \n\nTo address this, they propose COIN, a simple yet effective training framework that uses context alignment and knowledge consistency losses to encourage context-independent knowledge internalization."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper focus on the UNSTRUCTURED KNOWLEDGE EDITING, which is more useful in the real world application.\n\nThis paper notice the context will influence the editing performace, and make some analyze in details."}, "weaknesses": {"value": "* The paper observes that the model's accuracy degrades when relevant knowledge is positioned near the end of the input context, as detailed in Figure 2. It would be valuable to further investigate how performance is affected when the critical context appears at the beginning or in the middle. Moreover, since not all model editing methods require integrating context with the input, could the authors clarify how their approach differs from retrieval-based methods?\n\n* The training procedure illustrated in Figure 6 requires further clarification. What are the specific inputs and outputs for the model during this process? Furthermore, what does the \"consistency\" objective precisely constrain—is it the output distribution or another aspect of the model's behavior?\n\n* The results and metrics primarily focus on the success of the edits. How well does the method perform in terms of localization—that is, ensuring that unrelated knowledge or model behaviors remain unchanged?\n\n* What is the computational cost of the proposed method? Given that its performance is sometimes comparable to Fine-Tuning (FT), a discussion of their relative efficiency would be insightful."}, "questions": {"value": "* Although Table 3 is intended to demonstrate that an effective unstructured knowledge editing method must also handle structured knowledge, it only includes comparisons with other structured-based methods. A comparison with leading unstructured methods would make the argument more compelling.\n\n* Beyond the performance metrics, what broader insights does this work provide regarding the interaction between knowledge editing and language modeling?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JUhVOhWtfx", "forum": "8TkNRNboyg", "replyto": "8TkNRNboyg", "signatures": ["ICLR.cc/2026/Conference/Submission3922/Reviewer_8hZB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3922/Reviewer_8hZB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761047515230, "cdate": 1761047515230, "tmdate": 1762917099331, "mdate": 1762917099331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates a fundamental limitation of the Next-Token Prediction (NTP) paradigm when applied to unstructured knowledge editing in large language models (LLMs). The authors identify and formalize a phenomenon they call context reliance, where edited knowledge becomes overly dependent on its preceding context during editing, leading to retrieval failure when that context is missing at inference. To address this, the paper introduces COIN (COntext-INdependent editing), a framework augmenting standard NTP training. Extensive experiments on AKEW and UnKEBench datasets (with LLaMA3-8B and Qwen2.5-7B) demonstrate that COIN substantially improves editing success (up to 23.6% ROUGE-F1 gain) and reduces performance drop across positional contexts by 45%. Theoretical analysis (Theorem 3.1) and ablation studies support the identified cause of context reliance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper identifies a subtle yet impactful issue—context reliance—that had not been rigorously studied before in the model editing literature. This conceptual framing provides a fresh lens for understanding why next-token-based fine-tuning often fails to generalize edited knowledge.\n\n2. The COIN framework extends NTP training with two intuitive regularization terms that have clear theoretical underpinnings: one encourages invariance to context window size, and the other prevents catastrophic forgetting. The use of KL alignment between global and local distributions is simple yet effective, and the analytical formulation of the knowledge consistency constraint demonstrates mathematical rigor.\n\n3. The paper is clearly written and logically structured. And proposed COIN achieves consistent improvements over strong baselines."}, "weaknesses": {"value": "1. COIN currently uses a fixed-size sliding window for defining “local context,” which the authors themselves note as a limitation. This may underperform for long, discourse-rich texts where context relevance varies.\n\n2. While AKEW and UnKEBench are suitable, they primarily test single-fact retrieval. It remains unclear whether COIN improves reasoning tasks that require integrating multiple edited facts or narrative comprehension. Authors can Include an evaluation on multi-fact narrative editing (e.g., multi-hop MQuAKE reasoning chains or synthetic story edits) to demonstrate generalization to compositional inference.\n\n3. Both alignment and consistency losses add auxiliary computation, yet the paper does not report training time, memory, or scalability."}, "questions": {"value": "How sensitive is COIN’s performance to the choice of window size k and the trade-off hyperparameters (α, β)? Are these fixed across datasets or tuned per task?\n\nCan COIN be combined with existing locate-then-edit methods (e.g., ROME/AlphaEdit) to yield hybrid improvements?\n\nHave the authors examined whether COIN affects unrelated factual recall accuracy on general QA datasets like Natural Questions or TriviaQA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jYrnaxIn0c", "forum": "8TkNRNboyg", "replyto": "8TkNRNboyg", "signatures": ["ICLR.cc/2026/Conference/Submission3922/Reviewer_TmC2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3922/Reviewer_TmC2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761603925666, "cdate": 1761603925666, "tmdate": 1762917098924, "mdate": 1762917098924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies unstructured knowledge editing by sticking with the most “native” training objective—next-token prediction (NTP) over full text—rather than converting facts into triples or synthetic QA. The authors identify a robust failure mode they call context reliance: when the edited fact appears later in a paragraph, performance drops sharply; and if the query at test time omits the preceding context seen during editing, the model often fails to retrieve the fact. They show this empirically and offer a simple one-layer, one-step GD argument explaining why the learned mapping can hinge on a specific pair of context tokens. Building on this diagnosis, they propose COIN, adding a context-alignment loss to match predictions under full vs sliding-window context, and a knowledge-consistency loss to keep behavior stable on unrelated inputs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper clearly identifies and substantiates context reliance as the central failure mode of NTP-based unstructured editing—showing that edited knowledge becomes entangled with preceding context and collapses once that context is removed—offering a precise, empirically grounded diagnosis of why full-text fine-tuning often fails to generalize. This finding can contribute to the community.\n\n- COIN’s two regularizers are easy to bolt onto standard NTP editing, and they directly target the identified gap (train with global context vs test with local context). The method section is straightforward.\n\n- The experiments are comprehensive: on AKEW/UnKEBench, COIN achieves significant gains over the strongest baseline in terms of BERT/ROUGE-F1; on MQUAKE (multi-hop), it also substantially outperforms ROME, MEMIT, and AlphaEdit, demonstrating the superiority of the proposed method."}, "weaknesses": {"value": "- The theoretical analysis is built on an extremely simplified setting—a single-layer Transformer, a single gradient-descent update, and an attention pattern dominated by just two tokens (p and q). While this abstraction is useful for illustrating how context reliance can emerge, it does not capture the dynamics of deeper, multi-head, multi-step training typical of actual LLMs.\n\n- The details of experiment, such as sampling strategy and numerical stability of the covariance-style objective aren’t reported in enough detail.\n\n- The main text largely focuses on the strengths and successful results of COIN. Important limitations—including the bounded theoretical analysis and the impact (if any) on language generation models beyond the tested scale—are acknowledged only in appendices or passing remarks.\n\n- Limited Baseline Diversity: Most empirical comparisons focus on variants of NTP-based editing or classic baselines."}, "questions": {"value": "1. Can the authors clarify precisely how local context windows $k$ are defined/selected, and how robust the approach is against variable-length or semantically structured local contexts? Would more adaptive windows improve performance or efficiency?\n\n2. Given that the theoretical analysis (Theorem C.1) applies under strong simplifying assumptions, might the context reliance phenomenon be weaker/stronger in multi-layer, multi-step training scenarios? Did you observe any qualitative mismatches between theorem predictions and empirical findings?\n\n3. The paper briefly mentions meta-learning editors such as MEND and memory-based approaches, but it remains unclear how these methods would behave under the same unstructured NTP setting. Have the authors considered, even qualitatively, whether such approaches exhibit similar context-reliance effects?\n\n4. For the knowledge consistency loss, does increasing $|\\mathbf{K}_0|$ (number of sampled keys) materially affect model collapse or knowledge retention? Additionally, does this approach generalize to \"unstructured\" or ambiguous keys, such as those found in natural dialogues?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "anOjy8fhuP", "forum": "8TkNRNboyg", "replyto": "8TkNRNboyg", "signatures": ["ICLR.cc/2026/Conference/Submission3922/Reviewer_AES3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3922/Reviewer_AES3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761856616206, "cdate": 1761856616206, "tmdate": 1762917098719, "mdate": 1762917098719, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper examines unstructured knowledge editing in the next-token prediction (NTP) setting and observes that models can become reliant on the preceding context used during editing; consequently, the edited knowledge is harder to retrieve when queried without that context. To address this, the authors propose COIN, which augments the standard editing loss with a context-alignment objective that encourages the model’s predictions under a global window to match those under a local window. The approach is evaluated on several unstructured editing benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets a meaningful and timely issue in unstructured knowledge editing under NTP, with clear implications for reliability and deployment.\n\n2. The finding that edited knowledge retrieval depends on the preceding context is interesting and practically important; the proposed mitigation idea is reasonable.\n\n3. The paper is generally well written and easy to follow; figures/tables and section flow make the narrative accessible."}, "weaknesses": {"value": "1. Some setup details need elaboration. namely,  Section 3.3’s two mitigation strategies are insufficiently specified. It remains ambiguous how they are implemented in practice. Similarly, for splitting/paraphrasing, it is unclear whether the order of knowledge is permuted to control for position-dependent difficulty. Concrete examples (with before/after text) would help disambiguate the procedure.\n\n2. The central “alignment loss” idea, which aims to remove global context impacts, does not appear new in my opinion. It has been explored in the long-context learning/understanding literature [1]. The authors should make it clearer on the connection and uniqueness of the solution proposed in this paper. \n\n3. The design of consistency loss solution looks suboptimal. As mentioned by the authors, the concept of \"unrelated knowledge\" $K_0$ as in ROME/MEMIT/AlphaEdit. However, the the paper opts for a generic regularization on $W_0$ rather than a more structure-aware constraint as in AlphaEdit. \n\n4. As claimed by the authors, the core issue identified in this work is inherent to the NTP training paradigm. In addition, the proposed alignment loss should be tested across diverse NTP-based editors (fine-tuning, LoRA, ROME/MEMIT) to demonstrate generality and systematic gains, rather than a specific method.\n\n5. The problem appears related to known overfitting phenomena in editing, which has been widely studied in the literature [2, 3, 4, 5], but these links were not discussed clearly. \n\n[1] What Is Wrong with Perplexity for Long-Context Language Modeling? 2024.\n\n[2] Neighboring Perturbations of Knowledge Editing on Large Language Models, 2024.\n\n[3] Uncovering Overfitting in Large Language Model Editing, 2025. \n\n[4] Revealing and Mitigating Over-Attention in Knowledge Editing, 2025.\n\n[5] Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing, 2025."}, "questions": {"value": "Please see my comments in the weakness sections."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YVZLG4G2BL", "forum": "8TkNRNboyg", "replyto": "8TkNRNboyg", "signatures": ["ICLR.cc/2026/Conference/Submission3922/Reviewer_awnm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3922/Reviewer_awnm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935932805, "cdate": 1761935932805, "tmdate": 1762917098451, "mdate": 1762917098451, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}