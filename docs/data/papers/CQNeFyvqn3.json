{"id": "CQNeFyvqn3", "number": 10239, "cdate": 1758164854857, "mdate": 1759897664288, "content": {"title": "Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Scene Reconstruction", "abstract": "While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its extension to dynamic scenes introduces significant challenges.\nExisting dynamic 3DGS methods suffer from either over-smoothing due to low-rank decomposition or feature collision from high-dimensional grid sampling. \nThis is because of the inherent spectral conflicts between preserving motion details and maintaining deformation consistency at different frequency. \nTo address these challenges, we propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions. \nOur approach contains three key innovations: \na spectral-aware Laplacian encoding architecture which merges Hash encoding and Laplacian-based module for flexible frequency motion control, \nan enhanced Gaussian dynamics attribute that compensates for photometric distortions caused by geometric deformation,\nand an adaptive Gaussian split strategy guided by KDTree-based primitive control to efficiently query and optimize dynamic areas.\nThrough extensive experiments, our method demonstrates state-of-the-art performance in reconstructing complex dynamic scenes, achieving better reconstruction fidelity.", "tldr": "", "keywords": ["Deformable Gaussian Splatting", "4D reconstruction", "Novel view synthesis", "Laplacian Transformation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/40356ecfd5a9e94e84afcbb3cc22f293d7c13c2f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new paradigm for 4D dynamic scene reconstruction. This paradigm introduces three new components: a spectral Laplacian motion flow representation which replaces the previous direct motion representation, an enhanced per-Gaussian dynamics attribute with adaptive regularization, and an adaptive Gaussian split derived from KDTree and KL divergence. These components jointly enhance the representation capability of 4D modeling and provides better performances than previous methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motion Laplacian decomposition serves as a novel motion representation, where the learnable parameters are transformed from rigid movements to high-complexity Laplacian parameters. It is assumed that this representation has the capability to hold more vivid and flexible motions. \n2. The proposed method achieves higher visual performances compared to previous baselines, illustrating the effectiveness of the proposed method."}, "weaknesses": {"value": "1. Motivation and novelty. Although the Laplacian decomposition serves as a novel replacement over previous direct motion modeling method, the other contributions are neither well motivated nor correlated to main novelty. The per-Gaussian dynamics embedding is an adaptive variant of previous work [R1]. The KL divergence in 4D optimization is previously used in [R2]. \n2. Unclear attention mechanism. It is unclear how the 'attention mechanism' works in this paradigm. Is this a multiplication between two features? How it impacts the modeling capability?\n3. The proposed method enhances the representation capability with more complex motion representation while the convergence speed is compromised, leading to unneglectable sacrifice.\n4. Baselines. Recent advancements on 4D representation based on Gaussian Splatting are not considered [R3]. Previous advanced method 4DGS is not included into consideration [R4].\n5. Typically, primitive-based methods (like 4DGS [R4] or STG [R5]) provide better performance than deformation-based methods. The proposed method is built upon deformation-based method. It is interesting to investigate if this Laplacian decomposition works and can be integrated in other paradigms.\n6. From the ablation study, it seems that the adaptive split strategy does not provide sufficient gains.\n\n[R1] Bae, Jeongmin, Seoha Kim, Youngsik Yun, Hahyun Lee, Gun Bang, and Youngjung Uh. \"Per-gaussian embedding-based deformation for deformable 3d gaussian splatting.\" In European Conference on Computer Vision, 2024.\n\n[R2] Guo, Zhiyang, Wengang Zhou, Li Li, Min Wang, and Houqiang Li. \"Motion-aware 3d gaussian splatting for efficient dynamic scene reconstruction.\" IEEE Transactions on Circuits and Systems for Video Technology (2024).\n\n[R3] Li, Hao, Sicheng Li, Xiang Gao, Abudouaihati Batuer, Lu Yu, and Yiyi Liao. \"GIFStream: 4D Gaussian-based Immersive Video with Feature Stream.\" In Proceedings of the Computer Vision and Pattern Recognition Conference, 2025.\n\n[R4] Yang, Zeyu, Hongye Yang, Zijie Pan, and Li Zhang. \"Real-time photorealistic dynamic scene representation and rendering with 4d gaussian splatting.\" arXiv preprint arXiv:2310.10642 (2023).\n\n[R5] Li, Zhan, Zhang Chen, Zhong Li, and Yi Xu. \"Spacetime gaussian feature splatting for real-time dynamic view synthesis.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8508-8520. 2024."}, "questions": {"value": "1. The authors are expected to provide clarifications on how the proposed contributions benefit the proposed pipeline comprehensively. The differences between the proposed method and baselines should be enhanced.\n2. The explanations on the deformation calculation mechanism, especially how the attention calculation works, is recommended to be enhanced.\n3. Consistent with Weakness 5, it is curious to think whether the proposed design is applicable to primitive-based 4DGS methods, as the Laplacian decomposition should be a general motion representation format.\n4. The comparison should include more results to show the effectiveness of the proposed method. The Laplacian decomposition is an interesting part in this paper. It is suggested to include more content on verifying its effectiveness. For example, the frequency distribution can be visualized to find some insights. This is not a weakness or compulsory question for the authors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RgCaZUTFtW", "forum": "CQNeFyvqn3", "replyto": "CQNeFyvqn3", "signatures": ["ICLR.cc/2026/Conference/Submission10239/Reviewer_6NAJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10239/Reviewer_6NAJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760970038907, "cdate": 1760970038907, "tmdate": 1762921599395, "mdate": 1762921599395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper rethinks dynamic 3DGS through Laplacian spectral analysis, providing a hybrid framework for local frequency analysis. Meanwhile, it focuses on the dynamic properties of each Gaussian and the optimization issues in the derivation process, proposing a novel explicit–implicit hybrid algorithmic model."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes a novel Laplacian-based transformation to enhance dynamic modeling capability.\nIt also introduces an adaptive Gaussian segmentation strategy that automatically adjusts the original density and anisotropy through KDTree-guided spectral analysis."}, "weaknesses": {"value": "1. The paper’s writing is somewhat disjointed, and several details are unclear.\nMany of the arguments lack solid experimental support — for example, line 68: “existing deformable methods suffer from,” and line 211: “Incorporation of learnable frequencies,” etc.\n\n2. Methods based on deformation fields are inherently limited in handling complex temporal variations (such as fast motion or object disappearance/reappearance). Although the authors attempt to improve this class of methods, they do not provide sufficient experimental evidence to support their claims.\n\n3. In Fig. 4 (a) and (b), the results only demonstrate that the Laplacian motion flow is effective, but they do not show that its quality surpasses the current SOTA. Many existing methods have already achieved excellent results in this scenario.\n\n4. Regarding dataset selection, current dynamic methods have already performed well on datasets such as D-NeRF and N3DV, where reconstruction quality is close to saturation. The real challenge now lies in large-scale dynamic reconstruction. It is strongly recommended to evaluate the proposed method on large-scale datasets such as  Nvidia Dynamic Scene datasets [1], Dynamic3DGS [2] or VRU [3]  for more convincing results. If the proposed approach can efficiently model complex dynamic scenes at this scale, it would be truly exciting. In addition, providing supplementary video results would further strengthen the paper’s credibility.\n\n\n[1] Neural Trajectory Fields for Dynamic Novel View Synthesis\n\n[2] Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis\n\n[3] Swift4D: Adaptive divide-and-conquer Gaussian Splatting for compact and efficient reconstruction of dynamic scene"}, "questions": {"value": "1. How are $A_s$ and $A_l$ combined and fed into the MLP?\n2. What about the training time, inference speed, and storage requirements?\n3. The ablation study is insufficient — what happens if the hash module is removed? Is the dynamic training mainly driven by the hash module?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "QhWNtO1SX9", "forum": "CQNeFyvqn3", "replyto": "CQNeFyvqn3", "signatures": ["ICLR.cc/2026/Conference/Submission10239/Reviewer_cN8c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10239/Reviewer_cN8c"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761544809878, "cdate": 1761544809878, "tmdate": 1762921598964, "mdate": 1762921598964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified dynamic radiance field framework that integrates Laplacian spectral analysis with 3D Gaussian Splatting (3DGS). The authors claim that decomposing motion into multiple frequency components allows for more stable and detailed reconstruction of dynamic scenes. The approach also incorporates per-Gaussian dynamic attributes and an adaptive Gaussian splitting strategy to handle complex motion patterns. Experiments are conducted on Neu3DV and Hyper-NeRF datasets, showing competitive results.\n\nHowever, the paper’s originality and empirical justification are limited. The idea of modeling motion in the frequency domain is not novel—similar decompositions have been explored in Shape of Motion (2024), which also represents motion as weighted combinations of frequency components. Furthermore, the proposed method does not outperform strong baselines such as Motion-Aware Gaussian Splatting, which achieves higher PSNR on both Neu3DV (33.26 dB vs 32.12 dB) and Hyper-NeRF (27.87 dB vs 25.82 dB). The lack of motion trajectory visualization and testing on high-motion datasets further weakens the empirical validation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper attempts to connect **spectral Laplacian analysis** with **explicit Gaussian primitives**, providing an interesting hybrid theoretical perspective.  \n- The **framework design** (spectral decomposition + per-Gaussian dynamics + adaptive splitting) is logically coherent."}, "weaknesses": {"value": "1. **Limited Novelty**  \n   - The concept of decomposing motion into frequency components is not new. *Shape of Motion*[1] (2024) already investigated spectral motion representation and weighted recomposition within a Gaussian Splatting framework.  \n\n2. **Insufficient Empirical Advantage**  \n   - The claimed superiority in reconstruction quality is not supported by quantitative results. *Motion-Aware GS*[2] achieves higher PSNR on both Neu3DV dataset (33.26 dB) and Hyper-NeRF dataset(27.87 dB) than the proposed method (32.12 dB and 25.83 dB respectively).  \n\n3. **Lack of Motion Visualization and Analysis**  \n   - The paper provides only abstract schematic figures to illustrate Laplacian frequency decomposition, with **no visualization of motion trajectories, spectral components, or temporal consistency**.  \n   - Without explicit motion visualizations or error heatmaps, it is difficult to assess whether the frequency-domain modeling genuinely captures complex motion.\n\n4. **Limited Dataset Diversity**  \n   - All evaluated datasets involve smooth or slow motion. The method is not tested on **high-motion or large-deformation datasets** such as CMU-Panoptic used in *D-3DGS*[3], Kubric, or the NVIDIA Dynamic Dataset used in *Shape of Motion*.  \n   - As a result, the generalization of the proposed approach to challenging real-world motion remains unclear.\n\n5. **Unclear Advantage in Model Characteristics**  \n   - The claimed benefits (stability, detail, adaptability) are qualitative and not supported by consistent quantitative or visual evidence.  \n   - The framework increases complexity without demonstrating clear performance or interpretability gains.\n\n6. **Weak Method Organization and Missing Formulation**  \n   - The **method section (Section 3)** lacks a clear structure and summary. A concise overview at the beginning would help readers grasp the relationship between components.  \n   - There is **no explicit formulation or algorithm** describing how the Laplacian motion field \\( L(t) \\) and the spatial hash features actually influence or update Gaussian attributes.  \n   - Subsection 3.1.2 is disproportionately long and focuses heavily on basic Laplacian decomposition concepts that are well-established in information processing. The presentation could be streamlined and redirected toward showing the actual coupling mechanism between spectral motion and Gaussian updates.\n\n\n```\n[1] Wang, Qianqian, et al. \"Shape of motion: 4d reconstruction from a single video.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2025.\n[2] Guo, Zhiyang, et al. \"Motion-aware 3d gaussian splatting for efficient dynamic scene reconstruction.\" IEEE Transactions on Circuits and Systems for Video Technology (2024).\n[3] Luiten, Jonathon, et al. \"Dynamic 3d gaussians: Tracking by persistent dynamic view synthesis.\" 2024 International Conference on 3D Vision (3DV). IEEE, 2024.\n```"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Jwo8gnEzf1", "forum": "CQNeFyvqn3", "replyto": "CQNeFyvqn3", "signatures": ["ICLR.cc/2026/Conference/Submission10239/Reviewer_Hger"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10239/Reviewer_Hger"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755879962, "cdate": 1761755879962, "tmdate": 1762921598336, "mdate": 1762921598336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a dynamic reocnstruction method based on the 3DGS technology. They integrateed laplacian spectral analysis to the motion modeling to solve the problem in dynamic reconstruction like over-smoothing. Meanwhile, they combined some regularization and split strategies to improve the robustness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper tried to inject the laplacian analysis to the dynamic reconstruction to improve the fidelity.\n2. This paper introduceda KDTree-guided strategy to adaptively split Gaussians."}, "weaknesses": {"value": "1. The adopted benchmark seems already dont have huge challengy to prove the effectiveness. Many previous methods have shown the similar effects, and I encourage the author to choose more challenging benchmarks and to find the improvement aspect.\n2. The declared advantage in the motion modeling is not demonstrated clearly.\n3. Maybe needs to add more discussion with existing methods that adopt the fourier analysis methods, which all use the predifined trajectory prior."}, "questions": {"value": "see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qEHwWX8IKj", "forum": "CQNeFyvqn3", "replyto": "CQNeFyvqn3", "signatures": ["ICLR.cc/2026/Conference/Submission10239/Reviewer_wPrG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10239/Reviewer_wPrG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982810411, "cdate": 1761982810411, "tmdate": 1762921597697, "mdate": 1762921597697, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}