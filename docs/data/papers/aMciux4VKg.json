{"id": "aMciux4VKg", "number": 18165, "cdate": 1758284578698, "mdate": 1759897122330, "content": {"title": "AEGIS: Authentic Edge Growth In Sparsity for Link Prediction in Edge-Sparse Bipartite Knowledge Graphs", "abstract": "Bipartite knowledge graphs in niche domains are typically data-poor and edge-sparse, which hinders link prediction. We introduce AEGIS (Authentic Edge Growth In Sparsity), an edge-only augmentation framework that resamples existing training edges—either uniformly simple or with inverse-degree bias degree\\_aware—thereby preserving the original node set and sidestepping fabricated endpoints. To probe authenticity across regimes, we consider naturally sparse graphs (game design pattern’s game–pattern network) and induce sparsity in denser benchmarks (Amazon, MovieLens) via high-rate bond percolation. We evaluate augmentations on two complementary metrics: AUC-ROC (higher is better) and the Brier score (lower is better), using two-tailed paired $t$-tests against sparse baselines. On Amazon and MovieLens, copy-based AEGIS variants match the baseline while the semantic KNN augmentation is the only method that restores AUC and calibration; random and synthetic edges remain detrimental. On the text-rich GDP graph, semantic KNN achieves the largest AUC improvement and Brier score reduction, and simple also lowers the Brier score relative to the sparse control. These findings position authenticity-constrained resampling as a data-efficient strategy for sparse bipartite link prediction, with semantic augmentation providing an additional boost when informative node descriptions are available.", "tldr": "", "keywords": ["graph neural network", "link prediction", "data augmentation", "bipartite graphs"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/120387333c99666f8a09b5f3df2947f9c52892ad.pdf", "supplementary_material": "/attachment/f22a217f4a6a37008e1d3456c735c328fff8551e.zip"}, "replies": [{"content": {"summary": {"value": "The paper tackles the challenge of link prediction in edge-sparse bipartite knowledge graphs. Traditional graph augmentation methods—especially those involving random or synthetic edge generation—tend to distort structure and yield unreliable gains. The authors propose AEGIS (Authentic Edge Growth in Sparsity), a framework for authenticity-constrained edge-only augmentation. Rather than synthesizing new nodes or endpoints, AEGIS resamples existing edges within the training graph, preserving the node set and two-mode bipartite structure. Two policies are introduced: (i) AEGIS-Simple (uniform resampling of existing edges) and (ii) AEGIS-Degree (inverse-degree biased resampling to favor low-degree “cold-start” nodes). To benchmark performance under sparsity, the authors simulate extreme edge removal (bond percolation at 0.99 drop rate) on MovieLens and Amazon datasets, and evaluate on a naturally sparse Game Design Pattern (GDP) graph. Complementary metrics—AUC-ROC (ranking ability) and Brier score (probabilistic calibration)—are reported using paired t-tests. Five augmentation strategies are compared: AEGIS-Simple, AEGIS-Degree, random Erdos–Rényi additions, perturbation-based synthetic edges (SMOTE-style), and semantic-KNN completion (adding links between semantically similar nodes using cosine similarity). Results show that copy-based AEGIS variants maintain parity with sparse baselines, while semantic-KNN augmentation substantially improves both AUC and Brier. Random and synthetic edges generally degrade performance. The analysis highlights that semantic richness of node attributes governs augmentation success: GDP’s detailed textual descriptions yield the strongest calibration gains, whereas MovieLens’s minimal metadata offers little benefit."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors propose a well-defined and technically clear framework for the Rule-based augmentation setting over Sparse Single-relation Bipartite KGs. This makes the analysis straightforward to assess. \n\n2. The use of AUC and Brier are good evaluation criteria; this I commend the authors focusing on these instead of the usual metrics which provide an incomplete picture."}, "weaknesses": {"value": "1. The experimental analysis is severely lacking. The authors experimented with the single 0.99 percolation pass, however, it is important to demonstrate what happens at different values such as – 0.95, 0.9, 0.8 and such. Furthemore, the choice of 1% seems arbitrary, without any citation or specific design choice. \n\n2. Similar to the above point, the choice of 100x upscaling/augmetation is also interesting, but there is no supporting experiment for the variation of this augmentation factor.  \n\n3. A major concern is the lack of experimental details around the Hetero GAT (I am assuming the authors mean Graph Attention Network’s Heterogeneous variant here [2]) \n\n4. Some concerns about the benchmarks used. Especially, the size of the benchmarks in terms of the numbers of nodes in each of the partitions. Practically speaking, one would also want to see the behavior on larger sized bipartite graphs, akin to the link prediction literature for KGs [1]. Can the authors shed some light on the selection of the benchmarks, the GDP benchmark is especially small. \n\n5. The AEGIS-simple and AEGIS-degree methods are quite common in the literature ([3] as an example). Why did the authors then need to rename those? More specifically, of the first two claims on page 1 in the introduction, only claim 1 seems to be reasonable, albeit with the caveats mentioned above. \n\n[1] Sardina, J., Kelleher, J. D., & O’Sullivan, D. A Survey on Knowledge Graph Structure and Knowledge Graph Embeddings. arXiv preprint arXiv:2412.10092 (2024). \n\n[2] Heterogeneous Graph Attention Network Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Peng Cui, P. Yu, Yanfang Ye \n\n[3] Fitting the Linear Preferential Attachment Model Phyllis Wan1 , Tiandong Wang2 , Richard A. Davis1 , and Sidney I. Resnick2"}, "questions": {"value": "1. The major questions surround the experimental choice for the bond percolation value, the augmentation scale. \n\n2. Since the Hetero GAT experimental details are lacking in the paper, there are further questions around that. Especially, depending upon the number of GAT layers used, the effective aggregation radius around the nodes changes. That had a huge impact on the downstream performance, involving all the 5 upstream augmentation methods considered here. \n\n3. Can the authors provide some runtime analysis and degree distributions of the nodes in the benchmarks considered?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HCs0W22eps", "forum": "aMciux4VKg", "replyto": "aMciux4VKg", "signatures": ["ICLR.cc/2026/Conference/Submission18165/Reviewer_f1XV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18165/Reviewer_f1XV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760770807178, "cdate": 1760770807178, "tmdate": 1762927917489, "mdate": 1762927917489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We deeply appreciate the reviewers for their thoughtful and constructive feedback. This work tackles the critical challenge of link prediction in edge-sparse bipartite graphs—a problem that frequently arises in real-world applications such as knowledge representation and discovery within the game design domain. Our motivating dataset, Game Design Pattern (GDP), exemplifies this scenario with 208 games, 296 patterns, and 715 expert-verified links, which makes it inherently sparse and significantly challenging for downstream tasks like link prediction to achieve practical performance.\n\nUnlike typical bipartite graphs (e.g., user–item networks), knowledge graphs impose strict authenticity requirements because they rely on expert-verified relationships. This constraint fundamentally limits the applicability of synthetic or random augmentation strategies commonly used in other domains. To address this, we propose authenticity-constrained edge augmentation as a rigorous and principled approach to improve link prediction performance while preserving semantic integrity. Our study introduces AEGIS as an essential first step toward robust and scalable solutions for sparse bipartite knowledge graphs, balancing structural fidelity with improved predictive reliability.\n\nWe thank you once again for your comments and the references provided. Please find below our detailed and structured responses to each reviewer’s comment."}}, "id": "owWMOcj4Lq", "forum": "aMciux4VKg", "replyto": "aMciux4VKg", "signatures": ["ICLR.cc/2026/Conference/Submission18165/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18165/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18165/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763565218687, "cdate": 1763565218687, "tmdate": 1763565218687, "mdate": 1763565218687, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the impact of edge augmentation methods in the context of link prediction over bipartite graphs. To this end, it considers five different techniques aiming to augmented sparse edge information, each with its own variation (e.g., leveraging semantic node information, fully random, degree-biased, ...). The main empirical setting for this problem is a set of dense graphs (Amazon, MovieLens, GDP) that are sparsified, with the resulting link prediction performance following each augmentation strategy being compared against both the sparse baseline and the original graph. \n\nGiven its experimental results, the paper offers a discussion on the significance and effectiveness of each of its 5 proposed techniques, highlighting that only semantically-driven augmentation was a meaningful improvement over the sparse baseline in this context."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The setting is well-designed: Starting with a dense graph and working this into a sparse setting offers natural upper and lower bounds for performance, and sets the stage well for an analysis of augmentation techniques. \n- The intuitions behind the paper's methods are easy to follow."}, "weaknesses": {"value": "- The paper makes no substantial contribution, as its main insights are highly predictable just from the conceptual empirical setting. Indeed, given a 99% sparsification and the introduction of such a large number of ultimately random edges, it is hard to imagine any other outcome than those reported in this paper. The authors mention exploring other sparsification settings as a future work. However, I think this is a necessary step towards obtaining any meaningful insights that may add more color to the different augmentation algorithm dynamics. At the moment, the extreme sparsification and randomization levels render any comparison hard to interpret. \n\nI suggest to the authors that they explore a more continuous augmentation gradient, showcasing how performance evolves as augmentation levels increase (fixing sparsification level), and then doing the opposite (changing sparsification level, i.e., how much of the original graph is preserved, given a fixed level of augmentation), to actually study the robustness and sensitivity of the 5 techniques. I also highly recommend emphasizing performance in more realistic settings (augmentation will usually be within the same order of magnitude as the number of existing edges to maintain a reasonable amount of signal to noise). \n\n- The paper lacks meaningful baselines to compare against its own approaches, and doesn't seem to bring any of the works from the related work section into its experimental analysis. More generally, the paper offers limited experimental insights and needs a substantial amount of additional work (including the above suggestions) with other baselines to be ready for publication. \n\nOverall, this work is insufficiently developed in my opinion, and is based in a sparsification setting that is not optimal for the link prediction and augmentation analyses being targeted. Moreover, it doesn't offer any conceptually novel approaches or techniques. As a result, I don't think this work should be published in its current form."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Wki6k9QS0n", "forum": "aMciux4VKg", "replyto": "aMciux4VKg", "signatures": ["ICLR.cc/2026/Conference/Submission18165/Reviewer_xXuc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18165/Reviewer_xXuc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964909578, "cdate": 1761964909578, "tmdate": 1762927917069, "mdate": 1762927917069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces AEGIS, an edge-only augmentation framework targeting extreme edge sparsity in single-relation bipartite graphs. AEGIS duplicates existing training edges (either uniformly — simple — or inverse-degree biased — degree-aware) to densify training supervision without creating new nodes. The authors compare AEGIS to three other augmentation families : **random ER-like, perturbation-synthetic (SMOTE-style), and semantic-KNN**.\n\nEvaluation uses ROC-AUC and Brier score; significance is assessed with paired two-tailed t-tests and Cohen’s d. Main empirical claim: copy-style AEGIS matches sparse baselines, while semantic-KNN recovers AUC and calibration when node descriptions are informative"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Clear, reproducible algorithmic description**: The AEGIS variants and competing augmentation algorithms are specified precisely (pseudo-code, sampling weights, semantic-KNN algorithm).\n\n2. **Insightful empirical observation**: Resampling (authentic) augmentation is a stable baseline; semantic similarity–based augmentation is required to meaningfully recover performance when textual metadata are informative.\n\n3. **Paper well organized**"}, "weaknesses": {"value": "1. **GAT model tested**: performance could differ with other GNNs or matrix-factorization baselines.\n\n2. **AEGIS shows weak gains**: \n- Often statistically indistinguishable from baseline on MovieLens & Amazon \n- Semantic KNN provides most improvements, overshadowing AEGIS resampling.\n\n3. **Ambiguous effect of degree-aware resampling**: The inverse-degree (degree-aware) resampling is intended to help cold-start nodes, but results are mixed; e.g., GDP AUC decreases significantly for degree-aware (−0.028). The paper should investigate why degree-aware can hurt ranking while improving calibration."}, "questions": {"value": "1. What would be results on big datasets like ogbl-wikikg2 or ogbl-biokg?\n2. The experiments currently focus on one percolation case (q=0.01). How would they change for other values such as q = 0.05 or 0.1?\n3. How will the results improve if you use other models like GraphSAGE, SEAL/GNN subgraph method, or KGE models (e.g., ComplEx or RotatE)?\n4. Can you give some explanations for **Weaknesses** 3 and 4?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Y9x17Ylfug", "forum": "aMciux4VKg", "replyto": "aMciux4VKg", "signatures": ["ICLR.cc/2026/Conference/Submission18165/Reviewer_uN2E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18165/Reviewer_uN2E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972775197, "cdate": 1761972775197, "tmdate": 1762927916555, "mdate": 1762927916555, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AEGIS, a simple  framework for link prediction in edge-sparse bipartite graphs. Instead of generating synthetic edges, AEGIS augments training data by resampling authentic existing edges, with variants like degree-aware and semantic KNN sampling. Experiments show that it has some improvements in some cases."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an ealistic problem — link prediction under extreme edge sparsity in bipartite knowledge graphs, which is interesting.\n\n2. The proposed idea of authentic edge augmentation is intuitive and easy to implement, avoiding noisy or unrealistic synthetic edges."}, "weaknesses": {"value": "1. The paper is not well organized, and the motivation behind the proposed authentic edge–based augmentation is not clearly articulated.\n\n2. The method description is limited to pseudo-code without sufficient explanation of design details or implementation. \n\n3. The proposed AEGIS variants perform very close to the baseline, raising questions about the method’s effectiveness. What's the definition of \"baseline\" in the experiment?\n\n4. The contribution is relatively incremental — resampling existing edges is conceptually simple."}, "questions": {"value": "please refer to the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2N8nsE4IJh", "forum": "aMciux4VKg", "replyto": "aMciux4VKg", "signatures": ["ICLR.cc/2026/Conference/Submission18165/Reviewer_Gfnf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18165/Reviewer_Gfnf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989623417, "cdate": 1761989623417, "tmdate": 1762927916077, "mdate": 1762927916077, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}