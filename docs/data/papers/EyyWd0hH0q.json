{"id": "EyyWd0hH0q", "number": 15587, "cdate": 1758252936632, "mdate": 1759897297451, "content": {"title": "DeepPrim: a Physics-Driven 3D Short-term Weather Forecaster via Primitive Equation Learning", "abstract": "Solving primitive equations is essential for accurate weather forecasting. However, traditional numerical weather prediction (NWP) methods often incorporate various simplifications that limit their effectiveness in parameterizing unresolved physical processes. Meanwhile, existing deep learning-based models mostly focus on pure data-driven paradigms, overlooking the fundamental physical principles that govern atmospheric dynamics. To address these challenges, we present DeepPrim, a novel 3D \\underline{deep} weather forecaster designed to learn \\underline{prim}itive equations of the Earth’s atmosphere. Specifically, DeepPrim aims at accurately modeling 3D atmospheric motion through Navier-Stokes equation in pressure coordinates, and effectively capturing the interactions between the solved advection and key weather variables (e.g., temperature and water vapor) through corresponding equations. By seamlessly integrating fundamental atmospheric physics with advanced data-driven techniques, our model effectively approximates complicated physical processes without relying on empirical simplifications. Experimentally, DeepPrim achieves impressive performance in both short-term global and regional weather forecasting tasks, and exhibits the superior capacity to capture 3D atmospheric dynamics. The code is available at https://anonymous.4open.science/r/DeepPrim.", "tldr": "We propose DeepPrim, a physics-informed 3D deep weather forecaster designed to learn primitive equations of the Earth’s atmospheric dynamics.", "keywords": ["Weather forecasting", "Physics-informed neural networks", "Primitive equations", "Earth atmospheric dynamics", "Deep learning."], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5d54d35eb0f88d0963290ed99d5bf732afe75b3b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "A novel 3D deep weather forecaster that explicitly integrates physical principles for short-term, continuous-time prediction. It addresses the trade-off between traditional Numerical Weather Prediction (NWP) models and purely data-driven deep learning models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The model pioneers the explicit learning of the Primitive Equations (Navier-Stokes Force Terms) via a Neural ODE system. This design is highly original, ensuring physical consistency and enabling continuous-time prediction, which is superior to fixed-step forecasting methods.\n\n2.It introduces the novel 3D Bi-Component Vision Transformer, which provides a physics-motivated inductive bias for modeling the atmosphere. This architecture is specifically designed to accurately capture heterogeneous inter- and intra-pressure-level interactions, which are crucial for 3D atmospheric motion."}, "weaknesses": {"value": "1.While the Learnable Source-Sink Network is an innovative structural component, it essentially replaces complex, semi-empirical parameterization schemes used in NWP with a data-driven black-box parameterization. The network lacks explicit physical constraints or built-in interpretability, limiting the scientific novelty. It represents a missed opportunity to provide causal or physically restricted learned parameterizations that could advance our understanding of unresolved atmospheric processes.\n\n2.The empirical validation is heavily concentrated on short-term forecasting (sub-24h). While the paper provides some longer-term results (up to 5-6 days) in the Appendix, the core analysis and demonstrated dominance are not extended to medium-to-long-range prediction. This limitation leaves the model's robustness and scalability in capturing cumulative errors over longer time horizons largely unexplored in the main text.\n\n3.The paper lacks theoretical guarantees (e.g., stability analysis, energy conservation) that typically accompany physics-driven models. Without proof that the learned dynamics $f_{\\theta}$ adhere to fundamental laws beyond empirical fitting, the claimed \"physics-driven\" novelty is limited to an architectural constraint rather than a proven theoretical foundation.\n\n4.The paper omits a crucial analysis of inference time/computational complexity (FLOPs). Given the complexity of the 3D-BiViT architecture combined with the iterative nature of the Neural ODE solver, DeepPrim is likely more computationally expensive for real-time deployment than direct mapping models, a trade-off that is not quantified."}, "questions": {"value": "1.Can the authors provide a targeted ablation study comparing the current Euler solver against a higher-order numerical integrator (e.g., RK4) for lead times of 36h and 72h? This is crucial for determining if the model's reduced performance at longer ranges is due to the learned dynamics $f_{\\theta}$ or the numerical instability of the integration method.\n\n2.What is the specific physical interpretation and necessity for introducing the \"intermediate atmospheric motion\" $v^*$ separate from the horizontal wind components $(v_x, v_y)$ within the prognostic variable $\\mathbf{u}$? Is this required for numerical stability or does it represent a specific component of the flow?\n\n3.The paper emphasizes capturing interactions with the solved advection. How is the advection term itself computed? Is it handled entirely implicitly by the neural network, or is it computed explicitly using a traditional numerical scheme (like semi-Lagrangian or finite differencing) and then corrected/fused by the network?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "U9EywMUrTL", "forum": "EyyWd0hH0q", "replyto": "EyyWd0hH0q", "signatures": ["ICLR.cc/2026/Conference/Submission15587/Reviewer_Rdm2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15587/Reviewer_Rdm2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811787682, "cdate": 1761811787682, "tmdate": 1762925859417, "mdate": 1762925859417, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Physics-informed modeling of weather has recently gained attention. Building on the existing work on neural advection, this work advocates modeling 3D dynamics of weather evolution with both inter- and intra-pressure-level interactions pertaining to upper-air and surface variables, drawing inspiration from the Navier-Stokes equation. A bicomponent vision transformer architecture is invoked for this purpose. Experimental focusing on short-term global and regional weather forecasting tasks are also provided."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "--- Weather modeling has clearly emerged as an important area of research within the ML community, so the topic is of broad interest.\n\n--- Incorporating additional physics-inspired priors (e.g., using pressure gradients), to augment data-driven pipelines can potentially provide a useful inductive bias."}, "weaknesses": {"value": "--- Novelty of the proposed approach is limited. Essentially, with the exception of  a component called 'force network' that models external forces such as pressure gradients, the entire approach is directly adopted from ClimODE. Surprisingly, in the entire paper, the authors fail to acknowledge ClimODE for proposing and implementing neural advection as a fundamental principle for weather modeling.\n\n--- The implementation is not consistent with the formulation. For instance, equation 5 describes a source-sink network operating on  \\dot{v} (the gradient of intermediate atmospheric motion), but in practice, a ClimODE-style approach is adopted, wherein the network is applied on ODE predictions instead of ˙\\dot{v}˙.\n\n--- It is unclear how the pressure-based information is handled in practice. The dataset contains a few variables pertaining to pressure, and estimating the gradient with respect to pressure (equation 5) would necessitate segregating the equations for each variable. Absent this, information leakage due to correlations between pressure gradients across different variables cannot be ruled out.    \n\n--- The evaluation and reporting of results (e.g., in Table 2) is also unsatisfactory, and oftentimes, even misleading. For instance, it is mentioned in Appendix D that \"In line with (Nguyen et al., 2023), we selected 6 atmospheric variables at 7 pressure levels, 3 surface variables, and 3 static variables for the ERA5 dataset with 5.625° resolution, as detailed in Table 14. In our model training, we choose all variables as input variables, and all variables except three static variables as output variables that are used for loss calculation.\" This is in contrast to ClimODE that reported use of only five variables in total, namely {z, t2m, u10, v10, t at 500hPa}, for training. \n\n--- Comparisons are also unfair in terms of size of data used for training. DeepPrim used data from 1979–2015 for training, while ClimODE was trained with only 10 years of data.  \n\nOverall, the methodology (including evaluation) falls considerably short of expected standards."}, "questions": {"value": "Could the authors please address my concerns mentioned in the Weaknesses section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8gRWjHtRM9", "forum": "EyyWd0hH0q", "replyto": "EyyWd0hH0q", "signatures": ["ICLR.cc/2026/Conference/Submission15587/Reviewer_ZswK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15587/Reviewer_ZswK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963791157, "cdate": 1761963791157, "tmdate": 1762925858763, "mdate": 1762925858763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents DeepPrim, a physics-driven 3D deep learning framework for short-term weather forecasting. DeepPrim combines the learning of primitive equations—including the 3D Navier-Stokes equations for atmospheric dynamics—with data-driven neural modules, specifically a 3D bicomponent Vision Transformer (3D-BiViT) to capture both horizontal and vertical (pressure-level) interactions, source-sink networks for unresolved processes, and explicit ODE solvers for continuous-time forecasting. Extensive experiments on global and regional ERA5 datasets show that DeepPrim outperforms recent deep learning and NWP baselines in RMSE and demonstrates improved physical fidelity in 3D temporal weather modeling"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Integration of Physics and Deep Learning: DeepPrim thoughtfully incorporates the full set of primitive atmospheric equations—including the 3D Navier-Stokes equation in pressure coordinates—into a neural architecture\n2. Comprehensive Ablations and Interpretability: The authors ablate every core module—initialization, source-sink, and especially 3D pressure-coupling\n3. Architectural Innovation for 3D Coupling: The force network introduces explicit intra-pressure and cross-pressure attention mechanisms, directly modeling vertical and horizontal dynamics."}, "weaknesses": {"value": "1. Limited Experimental Scope for Longer-term Forecasting: Despite strong short-term (sub-24h) results, the paper’s focus on short-range forecasting leaves a gap in evaluating DeepPrim’s stability and error accumulation at multi-day or weekly horizons.\n2. Insufficient Comparison on Precipitation and Rare-event Metrics: Although DeepPrim is evaluated on standard atmospheric state variables (z500, t850, t2m, u10, v10), it lacks explicit performance metrics for short-term precipitation, extreme wind/storm events, or severe weather proxies restricts insight into the practical significance for domains that are most sensitive to rare or impactful events.\n3. Absence of Explicit Uncertainty Quantification: Modern operational forecasting demands not just pointwise predictions, but calibrated uncertainty—either through ensembles or explicit probabilistic modeling. DeepPrim delivers deterministic outputs, and there is no discussion of uncertainty, confidence intervals, or systematic error analysis."}, "questions": {"value": "1. Out-of-Sample Evaluation: Have the authors tested DeepPrim on years/geographies not included in the training/discussed regions, or on different reanalysis datasets (e.g., JRA-55, MERRA-2), to further demonstrate generalization capabilities?\n2. Physical Interpretability of the Source-Sink Module: Please elaborate on how the source-sink network is parameterized. Can its outputs be mapped back to interpretable physical processes? Are particular source/sink terms discoverable in the learned model, and how does this inform trust in the system for operational forecasters?\n3. Long-range Forecasting and Accumulated Error: Can the authors provide quantitative results for forecast horizons >24h, using the full DeepPrim model, to assess whether short-term gains remain stable at longer lead times? If degradation is significant, what additional mitigations (e.g., rolling initialization, explicit error correction) might be needed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fncIgesUFL", "forum": "EyyWd0hH0q", "replyto": "EyyWd0hH0q", "signatures": ["ICLR.cc/2026/Conference/Submission15587/Reviewer_k1Xf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15587/Reviewer_k1Xf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004562044, "cdate": 1762004562044, "tmdate": 1762925858368, "mdate": 1762925858368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors highlight limitations of both numerical weather prediction (NWP) methods and deep learning weather prediction (DLWP) models. They propose DeepPrim that learns primitive equations of the Earth's atmosphere. DeepPRIM models 3D atmospheric motion using the Navier-Stokes equation for the pressure and captures the interactions between the advective and other variables.\n\nThis is a good applied paper but is lacking some algorithmic novelty since it is using a standard Vision Transformer."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Nice combination of physical/numerical methods within deep learning methods.\n- Authors clearly identify 3 main challenges with current DLWP methods\n- Nice emphasis on the importance of physical constraints\n- Strong results of RMSE improvement by ~35-38%\n- Nice method overview in Table 1.\n- Nice use of RK4 instead of Euler time-stepping\n- Nice use of ERA dataset at various resolutions over various predictive variables, e.g., geopotential, air temperature, wind speeds.\n- Strong results in most cases.\n- Good comparisons to IFS, Pangu-Weather and GraphCast in Table 3.\n- Nice that the method can learn the BCs\n- Nice ablation studies"}, "weaknesses": {"value": "- Missing reference to DLWP benchmarking paper across the various SOTA methods Karlbauer et al., \"Comparing and contrasting deep learning weather prediction backbones on navier-stokes and atmospheric dynamics\", 2024.\n- Missing references on physical constraints in deep learning models for PDEs especially to hard-constrained methods: \n  -  Negiar et al., \"Learning differentiable solvers for systems with hard constraints\", ICLR, 2023\n  - Chalapathi et al., \"Scaling physics-informed hard constraints with mixture-of-experts\", ICLR 2024\n   - Hansen et al., \"Learning Physical Models that Can Respect Conservation Laws\", ICML 2024\n    - Mouli et al., \"Using uncertainty quantification to characterize and improve out-of-domain learning for pdes\", ICML, 2024 \n  - Saad et al., \"Guiding continuous operator learning through Physics-based boundary constraints\", ICLR, 2023\n   - Utkarsh, U., \"End-to-End Probabilistic Framework for Learning with Hard Constraints\", https://arxiv.org/pdf/2506.07003?, 2025.\n- Metrics other than point-wise ones should be considered, e.g., probabilistic ones like CRPS or a constraint/physics-based metric"}, "questions": {"value": "1. The authors mention that the proposed method does well on short-term prediction. How would it extend to longer term weather prediction?\n2. What made the authors choose a Vision Transformer backbone?\n4. The ODE in Eqn, 6 looks like it is just solved with Neural ODE?\n5. Do the authors know why some of the other baselines do better on the z500 variable?\n6. Do the authors know why GraphCast has better performance in several cases in Table 3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3Yrn8u9hCX", "forum": "EyyWd0hH0q", "replyto": "EyyWd0hH0q", "signatures": ["ICLR.cc/2026/Conference/Submission15587/Reviewer_axZ9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15587/Reviewer_axZ9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762410943196, "cdate": 1762410943196, "tmdate": 1762925858032, "mdate": 1762925858032, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}