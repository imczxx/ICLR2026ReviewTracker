{"id": "u6JLh0BO5h", "number": 25587, "cdate": 1758369310001, "mdate": 1759896714097, "content": {"title": "Jet Expansions: Restructuring LLM Computation for Model Inspection", "abstract": "Large language models are becoming general knowledge engines for diverse applications. However, their computations are deeply entangled after training, resisting modularization which complicates interpretability, auditing, and long-term maintenance. We introduce Jet Expansions, a framework for expanding computational graphs using jet operators that generalize truncated Taylor series. Our method systematically decomposes language models into explicit input-to-output computational paths and complementary remainders. This functional decomposition provides a principled, knife-like operator for cutting through entanglement in LLMs, enabling scalable model inspection. We demonstrate how Jet Expansions ground and subsume the popular interpretability technique Logit Lens, reveal a (super-)exponential path structure with respect to recursive residual depth, and support several interpretability applications, including sketching a transformer language model with $n$-gram statistics extracted from its computations and indexing model toxicity levels *without* curated benchmarks.", "tldr": "After training, LLM computations become deeply entangled. For interpretability, we introduce a knife-like operator that cuts through this entanglement, separating the part we care about from the remainder and enabling scalable model inspection.", "keywords": ["transformer", "decomposition", "interpretability", "neural-symbolic", "n-grams", "XAI"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8efb3befff58c10df3a363b56d398c90a6cb45f4.pdf", "supplementary_material": "/attachment/d1fcedecb740aa500679647c78d3ceb61fd9ba56.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes a new interpretability method for examining transformer-based language models based on jet expansions. The method works by approximating the full language model by its Taylor expansion and analyzing low-order terms. This extracts low-order behavior from the model and allows one to interpret it functionally, without relying on any additional data or training. The authors propose an implementation of the framework for a transformer-based language model and analyze its efficiency. \nJet expansions subsume existing interpretability techniques such as logit lens and $n$-gram statistics-based interpretability methods. Thus, the authors use their method to analyze open-source language models and find interpretable results. For example, by comparing fine-tuned and non-fine-tuned models, they find that the fine-tuning did not affect certain parts of model behaviour."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed methodology seems broadly applicable and useful\n\t- I particularly like that the approach is dataset-free, which removes many possible confounders in the analysis\n\t- Similarly, I like that the method is more holistic than individual neurons, etc.\n- The algorithm is thoroughly described and seems applicable and useful\n\t- It’s interesting that the analysis can even be done on CPUs\n- I liked the thoroughness of the experiments, which cover many open-source models.\n- Experiments clearly show that taking higher-order jets ($k = 1$ instead of $k = 0$ for logit lens) actually matters"}, "weaknesses": {"value": "- Unfortunately, I found it a bit hard to follow the transition between the empirical results and the theoretical setup. More explicitly stating what the measured quantities in the experiments correspond to in terms of the theory and the notation introduced above would be useful here, I think.\n\t- For example, how do $n$-gram statistic map to jets?\n- It is unclear to me to what degree the results should be trusted as a truthful representation of the model. For example, without knowing anything in advance, is it not possible that most of the model behavior is only explained by higher order terms than those in the jet?\n- The work mostly reframes existing techniques as jet expansions but doesn’t, to my understanding, propose novel applications of this framework for analyses that weren’t possible before."}, "questions": {"value": "- Is there any way to understand how good the approximation is, i.e., how large the remainders are?\n- How much of this methodology relies on the transformer architecture? Would it be easy to port to other neural LM architectures?\n- Could the same methodology even be used for things like model compression (where only the jets are retained/used)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vGP6Pat261", "forum": "u6JLh0BO5h", "replyto": "u6JLh0BO5h", "signatures": ["ICLR.cc/2026/Conference/Submission25587/Reviewer_QKXz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25587/Reviewer_QKXz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761034093419, "cdate": 1761034093419, "tmdate": 1762943488229, "mdate": 1762943488229, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The authors introduce Jet Expansions, a framework for expanding computational graphs using jet operators that give interpretability to complex models (e.g., transformers).\n- A jet expansion uses a transformer's residual structure to expand it to many smaller layer combination terms, plus some remainder.\n- For interpretability, you look at the different orders of jets to understand what the model is trying to predict."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper's main contribution, turning LLMs into jet-expanded paths, requires only model access and no extra data to probe models or compare two models with a shared vocabulary.\n- The paper does a good job explaining the background and motivation, given the complexity of the work."}, "weaknesses": {"value": "I question the practicality of jet expansions for interpretability. The paper only demonstrates the method on small to mid-sized open models, and even there, higher-order jets already add significant runtime. It's unclear how feasible this is for larger / frontier models."}, "questions": {"value": "How large are remainders in practice, and can we be more explicit about their sizes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EnXcsZD40K", "forum": "u6JLh0BO5h", "replyto": "u6JLh0BO5h", "signatures": ["ICLR.cc/2026/Conference/Submission25587/Reviewer_KiGr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25587/Reviewer_KiGr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957734461, "cdate": 1761957734461, "tmdate": 1762943487589, "mdate": 1762943487589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Jet Expansions, a framework that expands computational graphs using jet operators (generalizing truncated Taylor series) to decompose transformers into input-output computational paths and complementary remainders. The authors demonstrate how this functional decomposition stimulates advances in the area of interpretability applications, such as grounding and subsuming the traditional interpretability techniques such as the Logit Lens technique and defending against jailbreak attacks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper has an impressive theoretical foundation. They introduced the concept of jet operators from differential geometry to define interpretability rigorously, which is both novel and effective.\n\n2. Using the novel framework, the paper elegantly unifies the framework and as a result, introduces a technique to subsume traditional foundations of interpretability.\n\n3. Unlike most interpretability methods, jet expansions operate directly on model structure without requiring probe datasets. This is a significant practical advantage.\n\n4. The topic has broad applications, including model safety and mechanistic analysis"}, "weaknesses": {"value": "My major concern is the remainder interpretation. The remainder $\\delta$ seems to be a critical quantity to ensure performance and credibility, yet it is not analyzed rigorously enough. For instance, in Remark 2 on page 6, they mentioned \"Empirically, remainders are often small and expansion logits nearly collinear with model outputs\". From a theoretical point of view, how small is \"small enough for the task\"?"}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "CSoJVfGppu", "forum": "u6JLh0BO5h", "replyto": "u6JLh0BO5h", "signatures": ["ICLR.cc/2026/Conference/Submission25587/Reviewer_tf63"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25587/Reviewer_tf63"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959480842, "cdate": 1761959480842, "tmdate": 1762943487023, "mdate": 1762943487023, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors aim to solve the problem of \"entangled\" computation in LLMs, which makes their internal workings difficult to interpret. They use the core insight to treat LLMs as residual networks (a sum of paths) and apply jet operators, the functional equivalent of Taylor series, to analyze them. This approach is well-suited for the problem because jets are mathematically designed to handle compositions of functions and, via Lemma 1, can \"disentangle\" a nonlinear function of a sum into a weighted sum of its parts. This functional decomposition allows the authors to \"carve out\" and analyze specific computational paths. Their main contributions are the \"jet lens,\" which generalizes the popular Logit Lens (showing it's just the $k=0$ case), and \"jet n-grams,\" a novel \"corpus-free\" method to extract symbolic knowledge tables directly from the model's parameters. The authors provide strong empirical results, showing their decompositions are highly faithful (high cosine similarity) and that their $k>0$ jet lens provides a more stable interpretation for models like GPT-Neo where the standard Logit Lens has more chaotic results."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "Principled Framework: The paper's primary strength is its formalism. It gives interpretability a more formal mathematical framework/tool grounded in approximation theory.\n\nGeneralization of Existing Tools: Proving that the Logit Lens is simply the $k=0$ case of the iterative jet lens is a great benfit. It places a popular tool on solid theoretical footing and simultaneously shows its limitations.\n\nEmpirical Support: The results strongly support the claims.\n\nFaithfulness: The high cosine similarity (e.g., 0.993 in Figure 4) between the expansion logits and the model logits shows the decomposition is not just theoretical but empirically sound.\n\nSuperiority: The $k>0$ iterative lens provides a much more stable and interpretable computational trace for models like GPT-Neo, where the standard $k=0$ Logit Lens is more chaotic (as shown clearly in Appendix I, Figs. 8 vs. 9).\n\nApplications & Insights:\n\nRLHF & Toxicity: The finding in Table 4 provides strong, quantitative evidence that RLHF alignment masks toxic associations rather than erasing them (ToxiGen score drops to 0, but toxic bi-gram mass is unchanged). The method of demonstrating it via a \"corpus-free\" n-gram analysis is novel and powerful.\n\n\"Corpus-Free\" n-grams: The idea of extracting symbolic n-gram tables without a dataset is a powerful one. The application of \"diffing\" models (Llama-2 vs. CodeLlama) by comparing their n-gram tables is a practical method for verifying fine-tuning.\n\nFuture Work: The framework opens up many exciting possibilities for \"functional-level\" interpretability."}, "weaknesses": {"value": "Tractability and Clarity: The paper's discussion of the $O(2^L)$ exponential expansion (Algorithm 2) versus the practical, $O(L)$ linear-in-depth applications (the lenses) could be clearer. The tractability of these expansions, especially for $k>1$ is a major practical concern that is only briefly touched upon.\n\nNew Hyperparameters: The method introduces new hyperparameters for interpretability, namely the jet order $k$ and the jet weights $w$. The sensitivity of the results to these choices is not fully explored. Also how efficient and practical is it to get arbitrary order expansions?"}, "questions": {"value": "The RLHF & toxicity result supports some results from \"Safety Alignment Should be Made More Than Just a Few Tokens Deep\" that alignment usually only masks the problems. It would be interesting to see if the toxic bi-gram mass changed significantly in the \"more robustly\" tuned models from \"Safety Alignment Should be Made More Than Just a Few Tokens Deep\".\n\nCost of $k>0$ Lenses: Could the authors quantify the practical computational overhead of using the $k=1$ iterative jet lens (Fig. 9) versus the $k=0$ lens (Fig. 8)? How much more expensive is it, and does this limit its real-world applicability as a drop-in replacement?\n\nChoice of $k$: The results for GPT-Neo are dramatically better for $k=1$, but the results for GPT-2-large (Figs. 11 vs. 12) seem comparable. Does this suggest $k=0$ is \"good enough\" for some model families? How should a practitioner choose the optimal $k$ for a new model?\n\nWould the authors release the code?\n\nNotation in Example 1: The expression $J^1\\gamma(x_1)(x_2)$ is unclear. Could the authors confirm this is meant to be $J^1\\gamma(x_1)(x_1+x_2)$, as I think it expands as $J^1 \\gamma(x_1)(x_1+x_2) = \\gamma(x_1) + \\gamma'(x_1)((x_1+x_2) - x_1)$?\n\nLemma 1 Proof: In the proof of Lemma 1 (Appendix A), the evaluation point for the jets appears to be mislabeled as 'x' when it should be 'y' (e.g., $\\sum w_i J^k f(x_i)(x)$). Can the authors confirm if this is a typo? Or clarify the difference between x and y?\n\n\n\"Data-Free\" Clarification: The \"data-free\" claim for n-grams seems to be a source of confusion. The method is clearly input-dependent (it evaluates on token embeddings). Would \"corpus-free\" or \"dataset-free\" be a more accurate descriptor?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cQOKdpnlYM", "forum": "u6JLh0BO5h", "replyto": "u6JLh0BO5h", "signatures": ["ICLR.cc/2026/Conference/Submission25587/Reviewer_F5cx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25587/Reviewer_F5cx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964521577, "cdate": 1761964521577, "tmdate": 1762943486407, "mdate": 1762943486407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}