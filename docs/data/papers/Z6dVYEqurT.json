{"id": "Z6dVYEqurT", "number": 22150, "cdate": 1758326783947, "mdate": 1759896883487, "content": {"title": "MILCO: Learned Sparse Retrieval Across Languages via a Multilingual Connector", "abstract": "Learned Sparse Retrieval (LSR) combines the efficiency of bi-encoders with the transparency of lexical matching, but existing approaches struggle to scale beyond English. We introduce MILCO, an LSR architecture that maps queries and documents from different languages into a shared English lexical space via a multilingual connector. MILCO is trained with a specialized two-stage regime that combines Sparse Alignment Pretraining with contrastive training to provide representation transparency and effectiveness while mitigating semantic collapse. Motivated by the observation that uncommon entities are often lost when projected into English, we propose a new LexEcho head, which enhances robustness by augmenting the English lexical representation with a source-language view obtained through a special [ECHO] token. MILCO achieves state-of-the-art multilingual and cross-lingual LSR performance, outperforming leading dense, sparse, and multi-vector baselines such as BGE-M3 and Qwen3-Embed on standard multilingual benchmarks, while supporting dynamic efficiency through post-hoc pruning. Notably, when using mass-based pruning to reduce document representations to only 30 active dimensions on average, MILCO 560M outperforms the similarly-sized Qwen3-Embed 0.6B with 1024 dimensions.", "tldr": "MILCO aligns queries and documents into a shared English lexical space with two-stage training and a LexEcho head, preserving key source tokens while ensuring strong sparse multilingual performance and efficiency via pruning.", "keywords": ["learned sparse retrieval", "multilingual retrieval", "cross-lingual retrieval", "neural lexical search"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7ed2930ac32dc1cac9bebfbc4fd3f288287f51ae.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes MILCO, a multilingual learned-sparse retriever that projects inputs from many languages into a shared English lexical space via a lightweight multilingual connector. The model is trained in two stages: Sparse Alignment Pretraining (SAP) using large bitext corpora and an English LSR teacher, followed by Sparse Contrastive Training (SCT) with KL-distillation and InfoNCE. To preserve rare source-language entities lost in projection, the authors propose LexEcho, a dual-view head combining an English view with a weighted source view via an ECHO token. The method is empirically evaluated on MIRACL, MTEBv2, MLDR, MKQA and shows strong performance, supporting LSR post-hoc pruning and interpretability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Addresses an important practical challenge**: multilingual sparse retrieval with interpretability.\n2. **Good technical contributions**: SAP (sparse-aware MSE on logits) and LexEcho (dual view + [ECHO]) address semantic collapse of bi-text logits mapping.\n3. **Strong empirical results** across multiple benchmarks, with efficiency/accuracy tradeoff analysis (post-hoc pruning)."}, "weaknesses": {"value": "1. **Motivation needs to be strengthened**: why choosing to map multilingual tokens to English tokens? Could the authors clarify the rationale for specifically choosing English as the shared lexical space? What makes the English vocabulary a preferable or necessary choice in this framework?\n2. **Necessity outside of cross-lingual bi-text retrieval**: Does the proposed alignment (via the English teacher model) offer empirical or conceptual benefits that would not hold if the shared space were defined in another language or script? For purely monolingual retrieval scenarios (e.g., Chinese-to-Chinese), is the English-space projection still beneficial, or does it primarily target cross-lingual retrieval only?\n3. **Experimental comparison could be more rigorous**: disclosure of training compute, teacher model details, and dataset overlaps with baselines is incomplete. Without that, claims of beating much larger models risk being influenced by differing training data/compute.\n4. **Robustness to low-resource languages and domain shifts is not fully analyzed**: SAP relies on parallel corpora which may bias alignment.\n5. **Engineering/operational metrics (index size, latency, end-to-end retrieval QPS)** are not fully reported but are crucial for claims about effectiveness and deployability."}, "questions": {"value": "1. Please answer **Weakness 1** by clarifying the motivation for mapping multilingual tokens to English tokens.\n2. Please answer **Weakness 2** by clarifying the necessity of your design except for cross-lingual bi-text retrieval. Any related comparison results or experiments are welcome.\n3. Please provide a more detailed training budget (GPU type/count, total GPU hours) and distillation/teacher details (which teacher checkpoints, how produced).\n4. How does MILCO perform on truly low-resource languages not well represented in parallel corpus? Can the authors report per-language numbers for the lowest-performing languages?\n5. What are the index size and query latency numbers (both full representation and after pruning) using typical inverted index settings (e.g. Anserini with Lucene9) and hardware?\n6. Can you provide more ablations on LexEcho fusion (e.g., varying weight between English and source views) and present error types where LexEcho hurts ranking?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dN6qzMwpzA", "forum": "Z6dVYEqurT", "replyto": "Z6dVYEqurT", "signatures": ["ICLR.cc/2026/Conference/Submission22150/Reviewer_4uhs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22150/Reviewer_4uhs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920402997, "cdate": 1761920402997, "tmdate": 1762942091132, "mdate": 1762942091132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response to reviewers"}, "comment": {"value": "We thank all reviewers for their time and thoughtful evaluations of our work. We are happy to see that reviews consistently highlighted that our method is creative, effective, and clearly presented, with novel and well-motivated technical contributions supported by our empirical evaluation. In the following part of this rebuttal, we reply and address the raised concerns in separate responses to each individual reviewer."}}, "id": "gLlpTUtGYl", "forum": "Z6dVYEqurT", "replyto": "Z6dVYEqurT", "signatures": ["ICLR.cc/2026/Conference/Submission22150/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22150/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22150/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763739764597, "cdate": 1763739764597, "tmdate": 1763739764597, "mdate": 1763739764597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MILCO, a LSR architecture for multilingual and cross-lingual retrieval. MILCO maps queries and documents into a shared English lexical space through the integration of a multilingual connector and a LexEcho head, enhancing robustness to uncommon entities. The paper also proposes a SAP strategy, which addresses the entity loss issue and improves retrieval effectiveness. Experimental results show that MILCO outperforms existing methods on multilingual and cross-lingual benchmarks, demonstrating high efficiency and accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper identifies that during cross-lingual projection, entities from non-Latin languages (e.g., Chinese or Arabic proper nouns) are often lost. To address this, it introduces the LexEcho head, which generates dual sparse representations — one from the English view and one from the source-language view — significantly improving robustness to rare entities and enhancing cross-lingual consistency.\n\n2. The paper introduces Sparse Alignment Pretraining (SAP), a novel pretraining strategy specifically designed for multilingual LSR. Unlike prior methods that align multilingual inputs within dense semantic spaces, SAP directly aligns multilingual inputs with English lexical targets at the vocabulary level.\n\n3. The paper is well-written."}, "weaknesses": {"value": "Although MILCO improves training efficiency by mapping multilingual inputs into a unified English lexical space via the “Multilingual Connector,” this approach may introduce an English-centric bias. For languages with syntactic structures or lexical mappings that differ substantially from English, such monolingual alignment could lead to semantic distortion or representational misalignment, raising concerns about its generalization and fairness across diverse linguistic systems."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "OY7K0PDJCN", "forum": "Z6dVYEqurT", "replyto": "Z6dVYEqurT", "signatures": ["ICLR.cc/2026/Conference/Submission22150/Reviewer_LS1r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22150/Reviewer_LS1r"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997888367, "cdate": 1761997888367, "tmdate": 1762942090790, "mdate": 1762942090790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel method for a learned sparse retriever (LSR) model targeting multilingual and cross-lingual retrieval tasks, an area where LSRs typically struggle. Dense embedding retrievers usually perform better on such tasks due to cross-lingual lexical and entity mismatches, which make sparse methods harder to optimize. The authors introduce a LexEcho head that maps sparse representations into an English pivot space while preserving the original language tokens with predicted weights for indexing. This multilingual fusion representation is shown to be crucial through ablation studies. The final model is trained using language alignment pre-training and contrastive learning with distillation. Experimental results on both multilingual and cross-lingual benchmarks demonstrate the effectiveness of the proposed LSR method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is creative and effective.\n2. The ablation studies on the modeling components are insightful and clearly demonstrate the importance of each part of the method."}, "weaknesses": {"value": "1. The paper evaluates efficiency only through token pruning. However, it does not report the actual retrieval latency when using the sparse index, nor compare it to the latency of dense embedding models. Fewer tokens or sparsity does not necessarily guarantee faster retrieval, since inverted indices may produce very long posting lists in multilingual settings.\n2. A baseline dense embedding model trained with the same language alignment pre-training and contrastive learning with distillation (from the same cross-encoder and data) would strengthen the comparison of sparse vs dense. The paper presents an effective LSR model for multilingual retrieval. However, the weaknesses highlight missing experimental comparisons that make it difficult to determine whether sparse or dense models are ultimately more suitable for this task."}, "questions": {"value": "- How does the proposed model compare to the dense retrieval model under the same training setup?\n- How does the sparse retriever model with token pruning compare to the dense model running on GPU on latency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qTTl2g7wlU", "forum": "Z6dVYEqurT", "replyto": "Z6dVYEqurT", "signatures": ["ICLR.cc/2026/Conference/Submission22150/Reviewer_ej1c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22150/Reviewer_ej1c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762104298223, "cdate": 1762104298223, "tmdate": 1762942090607, "mdate": 1762942090607, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}