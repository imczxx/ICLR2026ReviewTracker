{"id": "XlRbpFj3lJ", "number": 513, "cdate": 1756743332803, "mdate": 1759898256252, "content": {"title": "ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting", "abstract": "We introduce ODE-GS, a novel approach that integrates 3D Gaussian Splatting with latent neural ordinary differential equations (ODEs) to enable future extrapolation of dynamic 3D scenes. Unlike existing dynamic scene reconstruction methods, which rely on time-conditioned deformation networks and are limited to interpolation within a fixed time window, ODE-GS eliminates timestamp dependency by modeling Gaussian parameter trajectories as continuous-time latent dynamics. Our approach first learns an interpolation model to generate accurate Gaussian trajectories within the observed window, then trains a Transformer encoder to aggregate past trajectories into a latent state evolved via a neural ODE. Finally, numerical integration produces smooth, physically plausible future Gaussian trajectories, enabling rendering at arbitrary future timestamps. On the D-NeRF, NVFi, and HyperNeRF benchmarks, ODE-GS achieves state-of-the-art extrapolation performance, improving metrics by 19.8% compared to leading baselines, demonstrating its ability to accurately represent and predict 3D scene dynamics.", "tldr": "", "keywords": ["gaussian splatting", "latent ODE", "extrapolation", "reconstruction"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2e8fe5973b99510f377e5914329d85450b9e4111.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The proposed ODE-GS method enhances dynamic scene prediction by first training a pretrained 3D Gaussian deformation (interpolation) network to reconstruct observed scenes and generate continuous Gaussian trajectories. These trajectories are then used to train a Transformer-based latent ODE model, where the ODE solver integrates latent dynamics over time to predict future trajectories."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The idea of introducing an ODE formulation for modeling dynamic 3D Gaussian Splatting (3DGS) is interesting. Representing scene evolution through continuous-time latent dynamics provides a different way to achieve extroplation."}, "weaknesses": {"value": "1. Complexity and dependence on neural networks\nThe reliance on a neural network make the architecture complicate. It is not entirely clear whether this provides substantial benefits over simply using a learned deformation network.\n\n\n2. Dataset simplicity\nThe benchmark datasets seem to include simple or synthetic trajectories (e.g., Lego, Mutant), which may be easily modeled by smooth ODE dynamics. It remains unclear how the method would perform on more complex or irregular real-world motion patterns, or on camera paths that deviate significantly from known trajectories."}, "questions": {"value": "Could the authors provide a visual comparing with and without the ODE component? It would be helpful to understand why the ODE-based model has much better results than the Transformer-only baseline reported in Table 4. If visualization is difficult to include, please report additional quantitative results (e.g., using a simple baseline such as copying the last/nearest frame of interpolation network or scaling up the transformers) on the NVFi dataset for reference. \n\nCould the authors provide training (interpolation pretrained model and the ode part) and inference time comparisons with Deformable 3DGS and GaussianPrediction? This would help assess the computational trade-offs introduced by the latent ODE and Transformer components over baselines.\n\n\nThe paper states:\n“...for the interpolation model, we follow Deformable GS (Yang et al., 2024) implementation.”\nDoes this mean the interpolation model is a pretrained Deformable-GS network reused as a data generator? If so, what is the quantitative performance of this interpolation model itself on HyperNeRF dataset over deformable GS on the interpolation mode?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qOQeQXau8Q", "forum": "XlRbpFj3lJ", "replyto": "XlRbpFj3lJ", "signatures": ["ICLR.cc/2026/Conference/Submission513/Reviewer_rwuC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission513/Reviewer_rwuC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761525373889, "cdate": 1761525373889, "tmdate": 1762915535625, "mdate": 1762915535625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles dynamic scene extrapolation problem, predicting future 3D states beyond observed timestamps. The authors propose ODE-GS, which couples 3D Gaussian Splatting with a Transformer-based latent neural ODE: 1) an interpolation stage first fits accurate Gaussian trajectories within the observed window; 2) a Transformer encoder summarizes past trajectories into a latent state; 3) then a neural ODE evolves this state in continuous time, and numerical integration yields smooth, physically plausible future Gaussian trajectories for rendering at arbitrary times. Experiments on D-NeRF, NVFi, and HyperNeRF report consistent rendering quality improvement and demonstrate that ODE-GS achieves state-of-the-art extrapolation task through the proposed latent ODE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper is well-written and easy to understand.\n- This paper targets the underexplored extrapolation problem in dynamic reconstruction and proposes a solution that makes sense.\n- Across both synthetic and real scenes, the results are consistently strong, with visualizations aligning well with the quantitative metrics."}, "weaknesses": {"value": "- Missing references for some important dynamic reconstruction works:\n  - [CVPR 2024] Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis, by Zhan Li et al.\n  - [CVPR 2024] SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes, by Yi-Hua Huang et al.\n- Frozen teacher prevents end-to-end correction. Canonical Gaussians and the deformation network are frozen before training the ODE module, limiting the system’s ability to adjust interpolation when extrapolation exposes inconsistencies. It would be much better if the authors do an ablation about joint training pipeline.\n- Long-horizon robustness not guaranteed. Dynamic trajectory sampling exposes the model to varied horizons, but there’s no quantitative guarantee or analysis of failure rates as horizons grow. It would be much better if the authors could do some experiments to suggest they can prevent potential drift on very long extrapolations.\n- Although ODE-GS leverages a Transformer, it is essentially a per-scene reconstruction method and does not readily scale up into a large model for more generalizable tasks.\n- This method relies heavily on the teacher Gaussians being well fit. When applied to real-world scenes with imperfect camera poses, those errors propagate and can severely degrade the accuracy of ODE-GS extrapolation.\n- Minor typo errors:\n  - L123: `representing dynamics scenes` -> `representing dynamic scenes`\n  - L129: `enables flexible editing` -> `enabled flexible editing`\n  - L129: Add space between `GaussianVideo (Bond et al., 2025))` and `uses`\n  - L680: `focuses on` -> `focus on`\n  - L683-684: `as shown in 5` -> `as shown in Figure 5`"}, "questions": {"value": "1. How are the Gaussian parameters encoded? Which subsets (positions, scales, rotations, opacities, SH features) are fed to the encoder?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "36nBR40Duq", "forum": "XlRbpFj3lJ", "replyto": "XlRbpFj3lJ", "signatures": ["ICLR.cc/2026/Conference/Submission513/Reviewer_MsUn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission513/Reviewer_MsUn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761542621017, "cdate": 1761542621017, "tmdate": 1762915535425, "mdate": 1762915535425, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to integrates 3D Gaussian Splatting with latent neural ordinary differential equations to enable future extrapolation of dynamic 3D scenes. It models parameter trajectories as continuous-time latent dynamics and ahieves state-of-the-art extrapolation performance. \n\nIt focuses on extrapolation, which is a somehow new problem worth studying. But this is not a totally new field and I believe so many works has been studying this issue. \n\nBut since I am not an expert in this field, I would like read the other reviewer's opinions about the contributions of this work, especially about the novelty."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper combines Neural Ordinary Differential Equations with 3DGS for 4D modeling, which seems to be novel, well-motivated design.\n2. This paper tried to forecast future 3D states in the context of dynamic scene reconstruction (as dynamic scene extrapolation), which is an interesting topic.\n3. The paper proposes a practical and effective two-stage training strategy.\n4. The paper provides consistent gains across D-NeRF, NVFi, and HyperNeRF datasets with comprehensive ablations."}, "weaknesses": {"value": "1. The foremost weakness is that, there is not enough experimental results on real-world datasets. The results on PlenopticVideo dataset should be included.\n2. It seems that the proposed method \"collapes\" on fallingball, Bouncingballs datasets. The phenomenon should be discussed and more collapsed cases need to be analyzed. The generalizability and robutness need to be discussed.\n3. There has been a lot of advanced SOTA 4D reconstruction methods, but the paper only compare with 4D-GS/ Deformable-GS, which is quite old at this time."}, "questions": {"value": "1. Why not supervise the extrapolation module directly with image reprojection error. Another option is using weak supervision or a distillation hybrid approach instead of relying entirely on pseudo-GT Gaussian trajectories produced by the interpolation model.\n2. Beyond smoothness regularization, could you incorporate velocity bounds, momentum conservation, or constrained optimization (e.g., constraint-based pose updates)?\n3. Have you ever run comparisons with end-to-end fine-tuning or mixed supervision?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KqFe17NYUZ", "forum": "XlRbpFj3lJ", "replyto": "XlRbpFj3lJ", "signatures": ["ICLR.cc/2026/Conference/Submission513/Reviewer_x185"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission513/Reviewer_x185"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761568549956, "cdate": 1761568549956, "tmdate": 1762915535256, "mdate": 1762915535256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper points out that existing dynamic 3D reconstruction methods can only handle temporal interpolation and fail to predict future scene dynamics. To address this, it introduces a new task called dynamic scene extrapolation, aiming to forecast future 3D states beyond observed frames. The paper proposes a model called ODE-GS combining 3D Gaussian Splatting with latent neural ODEs. It consists of three main parts: a Gaussian interpolation model for reconstructing observed scenes, a Transformer encoder for encoding motion histories into latent states, and a neural ODE module that evolves these states to predict future dynamics. The overall goal is to achieve physically plausible, temporally smooth, and consistent 3D scene extrapolation."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The paper explicitly defines and tackles dynamic scene extrapolation, which predicting future 3D scene states beyond the observed temporal window. It's a meaningful and underexplored extension of existing dynamic 3D reconstruction research.\n\n* The integration of 3D Gaussian Splatting with latent neural ODEs is conceptually elegant and well-motivated. Modeling Gaussian trajectories as continuous latent dynamics naturally enforces temporal smoothness and physical plausibility."}, "weaknesses": {"value": "Interesting work. I only have a few questions regarding the experiments:\n\n* I am curious about how ODE-GS performs in dynamic extrapolation on real-world datasets. I could not find clear visualizations of HyperNeRF and more real-world scenes (especially those containing both dynamic and static regions) in the main text or appendix. It would be helpful to see whether the model can accurately distinguish and predict the different evolution trends of dynamic versus static areas in complex real-world scenes.\n\n* I would like to know the effective extrapolation range of the model. The paper does not provide a systematic analysis of how performance degrades with increasing extrapolation distance — i.e., how far into the future the model can extrapolate before failure. This is an important factor for evaluating forecasting models.\n\n* I would like to better understand how ODE-GS performs on the novel view synthesis (NVS) task, both within the observed time window (interpolation) and the future extrapolation period.\n\n* If possible, I would appreciate video demonstrations of the extrapolated results to more intuitively assess temporal consistency and motion realism."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "77GI3hFgZW", "forum": "XlRbpFj3lJ", "replyto": "XlRbpFj3lJ", "signatures": ["ICLR.cc/2026/Conference/Submission513/Reviewer_AuTy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission513/Reviewer_AuTy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814429570, "cdate": 1761814429570, "tmdate": 1762915535028, "mdate": 1762915535028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}