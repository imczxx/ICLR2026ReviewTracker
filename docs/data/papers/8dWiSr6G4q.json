{"id": "8dWiSr6G4q", "number": 14410, "cdate": 1758234707290, "mdate": 1759897371983, "content": {"title": "One-Shot Weighted Ensemble Estimation for Federated Quantile Regression: Optimal Statistical Guarantees under Heterogeneous Structured Data", "abstract": "Federated Quantile Regression (FQR) has emerged as a powerful modelling paradigm for estimating conditional quantiles, offering a more comprehensive understanding of response distributions than standard conditional mean regression. However, achieving communication efficiency and optimal statistical guarantees for FQR remains challenging, particularly due to the nonsmooth nature of quantile loss functions and the presence of heterogeneously structured data, where each local agent trains its conditional quantile models with distinct sets of features. In this paper, we propose a data-driven, one-shot weighted ensemble estimator for FQR that incorporates scalable weighting schemes to effectively leverage the partially observed features at each local agent, thereby enjoying both communication efficiency and estimation optimality. Theoretically, we present a unified analysis of the proposed learning procedure, establishing that the resulting estimator exhibits asymptotic normality and attains uniformly minimum variance. Furthermore, we investigate the estimator's sensitivity to perturbations introduced by local agents and derive conditions under which the estimator achieves stability and enjoys strong out-of-sample generalization. Extensive simulations under various scenarios validate the asymptotic normality of our estimator and demonstrate its superior estimation accuracy and uniform convergence compared to several baseline methods across a range of quantile levels.", "tldr": "", "keywords": ["Federated learning; quantile regression; heterogeneous structured data"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3aca7238745219d28d62ec83b2c61905f33206ba.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper develops a federated quantile regression framework for heterogeneous data and provide corresponding theoretical guarantees."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "While some assumptions are strong (e.g., Assumption 4.1), the authors provide a comprehensive analysis with detailed theoretical justification."}, "weaknesses": {"value": "I'm wondering whether it is possible to relax Assumption 4.1 to isotropic sub-Gaussian features? If not, what are the restrictions in the proof?\n\nAnother question is that, in the proof, how should you handle the o_p terms if M can also asymptotically increase? Based on previous literature, e.g., Volgushev, Stanislav, Shih-Kang Chao, and Guang Cheng. \"Distributed inference for quantile regression processes.\" (2019): 1634-1662. they provide an upper bound on the number of workers. I'm wondering if there is a similar result like that in the federated scenario?"}, "questions": {"value": "Please answer my questions in the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FLF8mOByLb", "forum": "8dWiSr6G4q", "replyto": "8dWiSr6G4q", "signatures": ["ICLR.cc/2026/Conference/Submission14410/Reviewer_eSZq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14410/Reviewer_eSZq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760657867228, "cdate": 1760657867228, "tmdate": 1762955193252, "mdate": 1762955193252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel one-shot weighted ensemble estimator for FQR that effectively handles heterogeneously structured data. By incorporating an optimal weighting scheme, the method achieves communication efficiency while establishing optimal statistical guarantees, which is validated through extensive experiments on both synthetic and real-world data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper introduces a communication-efficient FQR method, specifically designed for a unique form of heterogeneous structured data. Its primary strength lies in its theoretical results, which demonstrate that the proposed estimator achieves both asymptotic and non-asymptotic theoretical guarantees."}, "weaknesses": {"value": "There are some critical issues the authors need to address, including: (1) strong modeling assumptions and an unusual definition of heterogeneity; (2) questionable stability arguments with respect to non-i.i.d. agents; and (3) a simple experimental design with limited experimental baselines."}, "questions": {"value": "1. The assumption of a linear data-generation process in the problem setup is overly strong and does not align well with most real-world scenarios.\n2. The definition of heterogeneity employed in the paper is somewhat unusual. In typical federated learning settings, it is more common to assume heterogeneity in the model parameter (e.g., $\\beta^*$).\n3. The paper is mathematically dense and uses a large number of notations. It would be beneficial to include a dedicated section that introduces and summarizes all of the notations used throughout the manuscript.\n4. In Remark 3.1, the authors present the communication cost of the proposed method, but they do so without providing comparison for other FQR methods. For readers less familiar with this field, it would be helpful if the authors compared the communication overhead of their method with that of existing methods, and discussed whether the communication cost becomes especially large in applications with very large problem scales.\n5. In Section 4.2, we know that traditional sample-level algorithmic stability typically assumes each sample is i.i.d. However, in the present setting the authors consider agent-level stability where each agent may be non-i.i.d. Therefore, it is unclear whether the standard algorithmic stability framework can be directly applied to this setup.\n6. In the numerical experiments, the authors compare the proposed method only against two very simple baselines (“Naive-local” and “Naive-OSFL”). The limited number and simplicity of these baselines weaken the evidence for the superiority of the proposed method. Additionally, the authors are encouraged to report mean values together with standard errors (over multiple runs) in order to demonstrate the robustness of their results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "QuXXKcT9Ny", "forum": "8dWiSr6G4q", "replyto": "8dWiSr6G4q", "signatures": ["ICLR.cc/2026/Conference/Submission14410/Reviewer_h1sK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14410/Reviewer_h1sK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760862613129, "cdate": 1760862613129, "tmdate": 1762924819908, "mdate": 1762924819908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a quantile regression framework for federated learning with structured missing data and provide a one-shot weighted ensemble estimation algorithm. Theoretical guarantees, including convergence rates and asymptotic normality, are presented and are noted as being solid and comprehensive."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "*   Well-established theoretical results with detailed proofs covering both convergence rates and asymptotic normality.\n*   The proposed algorithm addresses the challenge of structured missing data in a federated learning context."}, "weaknesses": {"value": "*   **Lack of Clear Innovation:** The core methodological innovation appears limited, as the algorithm seems to be a direct adaptation of existing work (Chen Cheng, 2023) by merely substituting the gradient and Hessian calculations for the quantile loss, without a significant abstraction or generalization.\n*   **Insufficient Motivation for Quantile Regression:** The paper lacks a dedicated discussion on the specific properties and challenges of the quantile loss function (e.g., non-differentiability, computational aspects), failing to justify why this specific loss is used and how its peculiarities are handled.\n*   **Inadequate Experimental Evaluation:** The experiments are considered thin. Key baselines and analyses are missing, including:\n    *   Comparison with a pooled estimator.\n    *   Comparison with an estimator using fully observed data.\n    *   Experimental validation of the theoretical asymptotic normality.\n    *   Experiments on heavy-tailed distributions (e.g., Cauchy).\n    *   Analysis of estimation error variability.\n    *   Sensitivity analysis regarding the number of quantiles (M)."}, "questions": {"value": "1.  What is the fundamental methodological advancement beyond the work of Chen Cheng (2023)? Specifically, how does the proposed framework abstractly generalize the problem for a broader class of loss functions, or, if it is specific to quantile regression, what unique technical challenges does it solve?\n2.  Why is there no discussion on the inherent properties of the quantile loss function (like non-differentiability), and how does the proposed algorithm effectively manage these challenges?\n3.  Can the authors provide more comprehensive experiments, including the missing baselines (full-data ) and a verification of the asymptotic normality results?\n4.  How does the method perform under heavy-tailed noise distributions, and how does the number of quantiles (M) impact the estimation stability and accuracy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X6xgtxsNWp", "forum": "8dWiSr6G4q", "replyto": "8dWiSr6G4q", "signatures": ["ICLR.cc/2026/Conference/Submission14410/Reviewer_QhDW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14410/Reviewer_QhDW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760927927272, "cdate": 1760927927272, "tmdate": 1762924818991, "mdate": 1762924818991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a one-shot Federated Quantile Regression (FQR) method for heterogeneous structured data where agents observe distinct feature subsets. Each agent fits local linear QR on its features  then the server solves a weighted ERM mixing local estimators. Theory claims provided include asymptotic normality for any positive-definite weights; existence of variance-optimal W⋆,  and generalization bound via agent-dependent stability among few more things."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) Relevant problem and one-shot design: FQR with heterogeneous feature access is under-explored;  transformation reconciles partial features via cross-correlations rather than truncation; avoids iterative rounds\n2)  Good theory contributions ie: asymptotic normality for broad weights, variance-optimal W⋆ characterization, practical plug-in construction, and agent-perturbation stability bound\n3) Transparent communication: Per-agent payload d²ᵢ+3dᵢ explicit which is a good sign  and n-independent"}, "weaknesses": {"value": "1) Since this is mainly a theory based paper it seems the major results require gaussian designs and structural coverage requiring that the union of local supports spans the full feature space. Computing the key quantities Tₘ and W⋆ requires access to matrices A and B that depend on unobserved counterfactual data x⁻. Broadly speaking a little gap seems to exist in the theory and empirical part of the paper. More on this in my next point\n\n2) The empirical part of the paper seems a bit thin when compared to the strength of the theory claim: For instance, the paper compares only against weak baselines (Naive-Local and simple averaging), using a single small real-world dataset (California Housing, median quantile τ=0.5). I would appreciate if the experimental section can be expanded to consider more variant setting"}, "questions": {"value": "Weaknesses and Questions merged"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5tEr8GmdJM", "forum": "8dWiSr6G4q", "replyto": "8dWiSr6G4q", "signatures": ["ICLR.cc/2026/Conference/Submission14410/Reviewer_MF5F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14410/Reviewer_MF5F"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762261996880, "cdate": 1762261996880, "tmdate": 1762924818295, "mdate": 1762924818295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}