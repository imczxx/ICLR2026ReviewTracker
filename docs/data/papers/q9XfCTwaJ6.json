{"id": "q9XfCTwaJ6", "number": 20880, "cdate": 1758311319616, "mdate": 1763566196035, "content": {"title": "LLMGD: Compressing LLMs with Layerwise Geodesic Distances", "abstract": "Understanding how internal representations evolve across layers in large language models (LLMs) is critical for interpretability, robustness, and efficient model design. We introduce LLMGD, a stability-guided pruning metric grounded in spectral graph theory. For each layer, we estimate a precision matrix from embedding vectors that characterize the model’s internal states, and then compute the geodesic distance on the cone of symmetric positive definite (SPD) matrices between successive layers. This yields a smooth and robust measure of representational distortion, identifying layers with minimal geodesic change as candidates for removal or replacement, thereby providing a principled foundation for model compression. Empirically, across multiple LLMs and tasks, including OPT-1.3B and OPT-2.7B models, LLMGD consistently detects structurally redundant segments and, when combined with lightweight replacement layers, delivers strong compression–accuracy trade-offs compared to existing pruning methods. We further establish a bi-Lipschitz upper-bound interpretation of LLMGD, which clarifies its robustness as a pruning criterion. Together, these results demonstrate that LLMGD reliably identifies structurally important layers and enables robust model compression with minimal performance degradation.", "tldr": "We introduce LLMGD, a spectral geodesic metric that quantifies layer-wise distortion in LLMs via bi-Lipschitz bounds, with applications in efficient model compression and robustness analysis.", "keywords": ["Large Language Models", "LLM", "Model Compression", "Probabilistic Graphical Models", "Bi-Lipschitz Maps", "Riemannian Manifold", "Spectral Geometry"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/804ba4491e456c57b69d82fb49a27d10a8ff06e0.pdf", "supplementary_material": "/attachment/288790bc6c53ae276a4e990806882c51d9452515.zip"}, "replies": [{"content": {"summary": {"value": "This paper aims to address the compression problem of large language models (LLMs), specifically how to reduce computational costs through layer pruning. The authors point out that many existing pruning methods lack a solid theoretical foundation. To this end, the paper proposes a new, theoretically grounded pruning metric called LLMGD (Large Language Model Geodesic Distances).\n\nThe core idea of LLMGD is to quantify the representational distortion between adjacent layers in the model. If the LLMGD value (i.e., the geodesic distance) between two layers is small, it indicates low representational distortion, and the corresponding layer block can be regarded as structurally redundant and pruned. Furthermore, the paper theoretically establishes the relationship between LLMGD and the bi-Lipschitz constant, proving that LLMGD serves as an upper bound for representational distortion.\n\nIn the experimental section, the authors conduct pruning experiments on OPT-1.3B and OPT-2.7B models, replacing redundant layers with lightweight modules, and compare the results with baseline methods such as cosine similarity and KL divergence."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces a new layer-wise metric, LLMGD, which estimates the layer-wise SPD precision matrix using a probabilistic graphical model and computes the geodesic distance on a Riemannian manifold to guide LLM pruning."}, "weaknesses": {"value": "The weaknesses mainly focus on experimental validation.\n1. Table 1 (OPT-1.3B) and Table 2 (OPT-2.7B) use different evaluation datasets, making direct comparison unreliable.\n2. For multiple-choice tasks such as MMLU, model accuracy hovers around 25%, which is essentially random guessing; thus, these results fail to demonstrate the effectiveness of different pruning strategies.\n3. The experiments only involve OPT-1.3B and OPT-2.7B. Although the paper claims future extension to larger models, this is unconvincing since newer models such as Qwen3-0.6B and Qwen3-1.7B are smaller yet significantly stronger; these should have been included for comparison.\n4. While cosine similarity and KL divergence are considered, other key pruning baselines in recent literature are missing.\n5. The study does not include experiments on generative tasks, which limits the generalizability of the proposed approach. [1][2]\n\n[1] BlockPruner: Fine-grained Pruning for Large Language Models\n\n[2] Shortened LLaMA: Depth Pruning for Large Language Models with Comparison of Retraining Methods"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VSSSRYPLng", "forum": "q9XfCTwaJ6", "replyto": "q9XfCTwaJ6", "signatures": ["ICLR.cc/2026/Conference/Submission20880/Reviewer_Ucuh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20880/Reviewer_Ucuh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20880/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620448673, "cdate": 1761620448673, "tmdate": 1762937474498, "mdate": 1762937474498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "Da8LIYBSo5", "forum": "q9XfCTwaJ6", "replyto": "q9XfCTwaJ6", "signatures": ["ICLR.cc/2026/Conference/Submission20880/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20880/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763566195191, "cdate": 1763566195191, "tmdate": 1763566195191, "mdate": 1763566195191, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LLMGD, a novel compression method for large language models (LLMs) based on Layerwise Geodesic Distances. The approach quantifies inter-layer representational geometric distortion by computing the geodesic distance between corresponding SPD matrices of adjacent layers, thereby identifying and pruning structurally redundant layers.\n\nHowever, the theoretical interpretation of LLMGD remains insufficiently developed. Although the paper establishes a theoretical connection between the value of LLMGD (i.e., the inter-layer geodesic distance) and the bi-Lipschitz constant, it lacks a deeper explanation of how LLMGD inherently captures structural redundancy and how well this mechanism generalizes across different models and tasks.\n\nMoreover, the current experiments only evaluate the method on classification benchmarks using OPT-1.3B and OPT-2.7B models. The approach still lacks validation across broader model families, larger scales, and generation tasks such as reasoning, code generation, and long-text understanding."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces the geodesic distance as a metric to quantify geometric changes between layer representations, which allows it to capture more complex nonlinear geometric distortions compared to methods based on cosine similarity or KL divergence.\n- The proposed LLMGD method leverages the Affine-Invariant Riemannian Metric (AIRM) on Symmetric Positive Definite (SPD) matrices and establishes a theoretical connection with the bi-Lipschitz constant, providing a solid mathematical foundation for assessing the geometric stability of layer transformations.\n- On classification tasks using OPT-1.3B and OPT-2.7B models, LLMGD outperforms pruning schemes based on Cosine Similarity and KL Divergence across multiple datasets."}, "weaknesses": {"value": "1. Although the paper theoretically connects the LLMGD value (inter-layer geodesic distance) to the bi-Lipschitz constant, showing that LLMGD can measure the geometric stability of layer transformations, it only establishes a correlation between geometric properties (low distortion) and pruning decisions (removability) without probing the causal mechanism behind this link.\n2. There is a lack of key hyperparameter specification and analysis: the paper neither reports the exact values used nor studies their impact. For example:\n  - The k value in the k-NN graph\n  - The β regularization parameter in Graphical Lasso\n  - The architecture and training settings of the lightweight replacement layer\n3. Experiments are conducted only on OPT models. Different architectures can have very different internal geometries and information flows. Is the geometric distortion measured by LLMGD still a reliable indicator of redundancy across other architectures and model scales?\n4. The method is evaluated only on classification benchmarks, with no assessment of generative tasks. Classification is often less sensitive to fine-grained representational nuances than generation.\n5. The method’s MMLU scores are below random guess. The baselines (OPT-1.3B/2.7B) exhibit little knowledge/reasoning ability on MMLU (a 4-choice task where random is ~25%). If the original models lack this ability, the pruning study cannot meaningfully assess whether LLMGD better preserves it than competing methods.\n6. Missing ablations:\n  - Component contributions in LLMGD: The pipeline comprises several steps (e.g., PGM/precision-matrix estimation, geodesic computation). There is no ablation quantifying each component’s contribution (e.g., what if a different precision-matrix estimator is used?).\n  - Effect of the replacement layer: The paper uses a lightweight replacement module to substitute pruned layers. Please compare against pruning without a replacement to isolate the module’s benefit.\n7. Incomplete baselines vs. recent pruning advances, such as:\n  - ShortGPT: Layers in large language models are more redundant than you expect (Men et al., 2024)\n  - SLEB: Streamlining LLMs through redundancy verification and elimination of transformer blocks (Song et al., 2024)\n  - LLM-Pruner: On the structural pruning of large language models (Ma et al., 2024)\n  - SliceGPT: Compress large language models by deleting rows and columns (Ashkboos et al., 2024)\n  - LaCo: Large language model pruning via layer collapse (Yang et al., 2024)"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GBcIOdSbM5", "forum": "q9XfCTwaJ6", "replyto": "q9XfCTwaJ6", "signatures": ["ICLR.cc/2026/Conference/Submission20880/Reviewer_rQmr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20880/Reviewer_rQmr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20880/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761639811783, "cdate": 1761639811783, "tmdate": 1762937473110, "mdate": 1762937473110, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper “LLMGD: Compressing LLMs with Layerwise Geodesic Distances” introduces a geometry-based approach to analyze and compress large language models (LLMs). The authors propose a pruning framework that quantifies representational change across layers by computing geodesic distances between precision matrices estimated from hidden states. Using probabilistic graphical models and the affine-invariant Riemannian metric on symmetric positive definite (SPD) matrices, LLMGD identifies layers that cause minimal geometric distortion—interpreted as redundant layers suitable for removal or lightweight replacement. The method is theoretically supported through a bi-Lipschitz upper bound interpretation and empirically shown to outperform existing pruning metrics on models such as OPT-1.3B and OPT-2.7B, achieving improved compression–accuracy trade-offs."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Originality: This paper introduces a new method to evaluate how information shifts from layer to layer which has never been introduced before, based on computing geodesic distances between precision matrices estimated from internal reps of LLMs. In particular, the use of probabilistic graphical models on internal reps of LLMs is novel.\n- Quality: The techniques explained draw from mathematically grounded concepts. Computational expense is kept feasible despite several heavy operations are involved.\n- Clarity: The idea is explained clearly and the strategy is illustrated in depth throughout the paper.\n- Significance: the effort of reducing LLM is certainly timely and important."}, "weaknesses": {"value": "I have a few objections about this work:\n- Broad comment: the authors repeat frequently that in the business of understanding how LLMs layers process and distort information, previous work is mostly empirical and not theoretically grounded. While this might be true (with exceptions), it is hard for me to justify how this work takes a theoretically grounded approach to this problem. It seems to me that, instead, the authors take a mathematically grounded technique to evaluate information processing through layers, using these evaluations to prune layers, which is not the same as addressing the theoretical problem of how information flows through layers. I might have misunderstood, more the reason for the authors to clarify this point as a way of improving their manuscript.\n- The set of experiments is limited to small-medium models (and only one model really, OPT), while existing literature (cited in the work) has results on larger models. I believe the authors should compare more closely to existing literature (e.g. Men et al, Gromov et al.) with similar models and setups, to prove their method is better performing.\n- Mean pooling over the token dimensions seems not the standard choice for causal LLMs, given the last token has most of the information. The authors should consider changing this choice, or motivating why they use mean pooling.\n- In experiments, the authors quote results for MMLU benchmark, for which the models they consider already performs basically random choice before pruning. This is testing the method in an unstable limit where results do not make sense (after pruning, the model performs worst than random choice?)\n- Relevant work section seems to be limited to probabilistic graphical models, while literature on pruning LLMs is mentioned a bit sparsely (and with some omissions, e.g. Zhang et al. 2024, Kim et al. 2024, Gardinazzi et al. 2025 just to name a few)."}, "questions": {"value": "I will formulate more precise questions along the lines of what written above:\n- Can the authors run a set of experiments to directly compare to previous literature (e.g. Gromov et al, Men et al)?\n- Can the authors run a quick experiment to compare the current pipeline to choosing last token representation over mean pooling?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jjwcamHTRD", "forum": "q9XfCTwaJ6", "replyto": "q9XfCTwaJ6", "signatures": ["ICLR.cc/2026/Conference/Submission20880/Reviewer_qhwy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20880/Reviewer_qhwy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20880/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761742558837, "cdate": 1761742558837, "tmdate": 1762937471584, "mdate": 1762937471584, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LLMGD, a geometry based method for pruning layers in LLMs. The main idea is to look at each layer through the covariance structure of its hidden representations and to measure the change between consecutive layers by using the affine-invariant Riemannian metric (AIRM). Layers that induce only a small geometric change are considered redundant and are removed. To mitigate significant accuracy loss, a lightweight replacement layer is trained on input/output pairs generated from the original model. On OPT-1.3B/2.7B, across several benchmarks (BoolQ, PIQA, COPA, ARC-Easy) LLMGD usually outperforms cosine and KL based pruning at similar pruning ratios. The method is data-driven, but some of its drawbacks are the computational cost of estimating precision matrices/eigendecompositions and that the experiments are limited to mid-sized, mainly classification style evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Experiments on multiple tasks and two OPT model sizes show gains over cosine/KL.\n- The pipeline includes a recovery step where a lightweight layer is trained to reduce the performance loss.\n- The theoretical framing with a bi-Lipschitz argument gives the approach a clear justification.\n- The approach targets structured (layer-level) compression, which is better for deployment than unstructured sparsity.\n- The method is data driven, deriving pruning decisions from actual layer activations rather than simple static weight statistics."}, "weaknesses": {"value": "- The related work section is quite short and does not clearly position the method among structured/unstructured pruning, depth-adaptive models, or recent data based criteria.\n- The method does not always outperform baselines on every task and pruning level.\n- The approach depends on being able to estimate precision matrices and being able to do eigen decompositions, which becomes significantly expensive as the sample size grows (Table 3) thus limiting the practicality for large-scale use-cases.\n- The evaluation is restricted to mid-sized OPT models and mainly classification based benchmarks, so it is not clear how well the method would transfer to larger, instruction-tuned, or generative settings.\n- The pruning signal is explored together with a retraining/replacement step, so it is hard to understand how strong the geometric criterion is by itself."}, "questions": {"value": "- Please expand the related work to make sure it covers structured vs unstructured pruning as well as depth-adaptive methods, and recent data-driven pruning criteria while clearly stating where LLMGD fits.\n- Report aggregate metrics (average accuracy) for Tables 1-2 so the overall effect is clear despite per-task variance.\n- Clarify the computational setup for Table 3 (hardware, per-layer cost, number of pairs) and compare it to simpler signals like cosine/KL.\n- Add generation based evaluations (e.g. perplexity) to show the method transfers beyond classification on OPT and also expand to a different family of models.\n- Separate the effect of the geometric signal from the retraining step by reporting accuracy right after pruning as well, before the replacement.\n\nI'd be happy to increase my score if these points are resolved!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wi9UNfKyEC", "forum": "q9XfCTwaJ6", "replyto": "q9XfCTwaJ6", "signatures": ["ICLR.cc/2026/Conference/Submission20880/Reviewer_qPJo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20880/Reviewer_qPJo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20880/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972154910, "cdate": 1761972154910, "tmdate": 1762937470471, "mdate": 1762937470471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}