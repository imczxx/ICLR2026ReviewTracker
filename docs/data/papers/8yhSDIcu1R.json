{"id": "8yhSDIcu1R", "number": 16857, "cdate": 1758269535312, "mdate": 1759897215314, "content": {"title": "Revisiting Differential Attention: A Fine-Tuning Perspective on Practical Noise Mitigation", "abstract": "The self-attention mechanism in Transformer models is widely adopted but remains vulnerable to attention noise. Differential Transformer and its variant DEX attempt to address this issue; however, the former requires training from scratch, while the latter cannot directly mitigate noise during the attention computation process. In this paper, we propose DAA, a novel method that can both reduce attention noise and be flexibly inserted during the fine-tuning stage. Specifically, DAA introduces learnable modules to the self-attention mechanism in the the process of calculating attention scores, to achieve a differential mechanism. We find that DAA can offset attention noise while introducing few parameters (less than 1\\% of the total model parameters), and directly act on the updates of the K and Q matrices, achieving effects similar to those of a Differential Transformer model trained from scratch. We further compare our approach with two methods that explore different positions of differentiation: one modifies the input sequence to separately compute K, Q, or V, while the other regulates the output matrix (DEX). Experimental results show that DAA can better effectively improve model performance with a small amount of fine-tuning data.", "tldr": "", "keywords": ["LLMs", "Differential Attention", "Model Fine-Tuning", "Architecture Migration"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ebe30da213818ea84bfe76917459c1d59c014b66.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper attempts present a flexible plug-in module in fine-tuning stage to reduce the attention noise, termed Differential Attention Adaption (DAA), which introduces a learnable block to compute attention score and suppresses noise. Experiments demonstrate some improved performance of the proposed module over the baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The paper is clearly written, well organized and presents some interesting contributions\n+ The paper presents a new approach, called DAA, to reduce the attention noise in fine-tuning  stage, and also provides a set of variants of DEX from different branches of the dot-product attention model\n+ The empirical evaluation shows improvements over the listed baseline methods"}, "weaknesses": {"value": "- While the novel contributions looks interesting, they are somewhat incremental, given the prior work, DIFF and DEX.\n\n- It is claimed that the proposed DAA \"effectively reduces attention noise\" (L096). However, the theoretical justification for the noise cancelling mechanism is still unclear. In Eq. (8), a noise component $\\xi$ is added into the attention logits, and it is expected that the proposed approach, DAA, could cancel the noise $\\xi$. Unfortunately, the theoretical justification part is disappointing. \nIn L330-340, it is stated that: during the fine-tuning, the model is assumed that the second attention matrix $A_2$ approximate the noise term. However, this is merely a conjecture, without any theoretical justification how the second attention term could learn to approximate the noise component. In another words, how the model could be incentivized to learn the noise is unclear yet. Without the substential justification into the mechanism, the theoretical analysis is void. \n\n- Some expression is experiments are somewhat arbitrary, e.g., regarding to the training loss curves in Fig.3, the differences seems minor but it stated \"the training loss of DAA is #signficantly# lower than DEX\" (see L406-407).  Without a bar of the standard deviation or a testing, it is not clear whether the differences are significant. When referring the significant, it is meaning to significant in statistics. \n\n- The empirical performance in Table 3 show slightly improvements over DEX. Which is the advantage of DAA comparing to DEX? How about the complexity or computation cost of the proposed DAA and the prior counterpart method DEX are unclear.  \n\n- Minor issues: The format for the citing references seems not properly used and the references are incomplete."}, "questions": {"value": "Please Refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Q66psqv02i", "forum": "8yhSDIcu1R", "replyto": "8yhSDIcu1R", "signatures": ["ICLR.cc/2026/Conference/Submission16857/Reviewer_qUxy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16857/Reviewer_qUxy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16857/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814295605, "cdate": 1761814295605, "tmdate": 1762926877575, "mdate": 1762926877575, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DAA (Differential Attention Adaptation), a lightweight learnable module inserted during fine-tuning. DAA directly modifies the query and key computations in the self-attention mechanism to reduce attention noise. Evaluated across multiple base models and downstream tasks, DAA outperforms standard fine-tuning, DEX, and other baselines while adding less than 1% additional parameters. It presents a practical and effective solution for attention noise reduction."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. DAA introduces minimal parameter overhead and can be applied to existing LLMs without retraining from scratch.\n2. The experiments and ablation studies are comprehensive and well presented."}, "weaknesses": {"value": "1. The paper lacks a discussion on its limitations.\n2. The noise reduction claims are mostly qualitative, with evidence based primarily on downstream performance.\n3. Most evaluations are conducted on small-scale models, so the effectiveness on larger models remains unclear.\n\nOverall, the numerous non-self-contained parts in the writing make me feel that this paper was rushed before the deadline."}, "questions": {"value": "1. Could the authors provide more discussion on the limitations of DDA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hMVI9x1Tls", "forum": "8yhSDIcu1R", "replyto": "8yhSDIcu1R", "signatures": ["ICLR.cc/2026/Conference/Submission16857/Reviewer_KWBS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16857/Reviewer_KWBS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16857/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828330780, "cdate": 1761828330780, "tmdate": 1762926877121, "mdate": 1762926877121, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Differential Attention Adaption (DAA), a novel, parameter-efficient method designed to mitigate attention noise in Transformer models during the fine-tuning stage. DAA addresses the limitations of both predecessors by inserting lightweight learnable modules directly into the process of calculating attention scores. This method is analogous to the common-mode signal rejection found in differential amplifiers. Experiments comparing DAA against DEX and various input differentiation strategies (DiffQ, DiffK, DiffV) on GPT-2 and Llama models (Llama-3.2-1B, Llama-3.1-8B) confirm DAA's superiority. DAA achieved the highest accuracy on challenging retrieval and reasoning tasks like LAMBADA and Needle-in-a-Haystack. It consistently showed the most substantial performance gains across model scales in multi-task fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- DAA is theoretically positioned as the most effective fine-tuning differential adaptation because it intervenes directly in the attention score calculation process. This allows it to model and subtract attention noise at its source. \n- DAA can be flexibly inserted during the fine-tuning stage of existing pretrained models, overcoming the critical limitation of the original Differential Transformer, which requires training from scratch. \n- DAA directly regulates the attention score calculation process, allowing it to suppress noise at its source by intervening in the crucial Query-Key interaction. This is theoretically the most effective approach for noise mitigation."}, "weaknesses": {"value": "- The exploration of alternative architectures that differentiated the input sequence (DiffQ, DiffK, DiffV) yielded inconsistent and ultimately poor results. Specifically, the DiffV method was found to be the least effective, resulting in a performance decrease for both Llama 1B and 8B models. \n- DAA, similar to DEX, adopts a dynamic weight governed by an annealing mechanism. While this helps guide the model, the success of the differential mechanism relies on successfully defining this weight over time. \n- While DAA is conceptually superior to DEX by intervening before the softmax, DEX still delivers consistent improvements over the baseline and standard fine-tuning, leaving open questions about their statistical significance."}, "questions": {"value": "- The core hypothesis of DAA states that the lightweight, learnable matrix $W_{DAA}$ enables the secondary attention map to approximate the noise component. What empirical analysis confirms that $W_{DAA}$ is indeed isolating and subtracting the specific hypothesized noise pattern?\n- The input differentiation method targeting the Value stream (DiffV) was found to be the least effective, resulting in a performance decrease for both Llama 1B and 8B models. Why does DiffV prove so much less robust and effective for noise mitigation compared to DAA and DEX?\n- The ablation study provided only focuses on the initialization constant. How sensitive is DAA's performance to the choice of the annealing duration?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "GLOFpSjyMq", "forum": "8yhSDIcu1R", "replyto": "8yhSDIcu1R", "signatures": ["ICLR.cc/2026/Conference/Submission16857/Reviewer_sJ4K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16857/Reviewer_sJ4K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16857/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962963518, "cdate": 1761962963518, "tmdate": 1762926876502, "mdate": 1762926876502, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DAA (Differential Attention Adaption), a method aimed at mitigating attention noise during the fine-tuning stage of pre-trained models. The method introduces a lightweight learnable module within the attention score calculation. Experimental results demonstrate that DAA achieves superior performance on long-sequence benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- DAA introduces minimal extra parameters (less than 1% of the total parameters), making it an efficient and lightweight solution for attention noise mitigation.\n- By intervening directly in the Query-Key interaction process, DAA addresses the noise problem in attention scores more fundamentally compared to DEX, which operates on the attention output."}, "weaknesses": {"value": "- Formatting/Citation Style: The paper seems to mix or inconsistently use \\citep and \\citet (or directly uses \\cite) citation formats. It is recommended to unify the style throughout the paper.\n\n- Formatting/Presentation: There are small errors in the text presentation (e.g., a reference tag shows as 'undefined' in the first paragraph; some punctuation marks lack the necessary preceding space). A careful proofread of the typography is suggested.\n\n- Abstract/Clarity: When the acronym 'DEX' first appears in the second line of the Abstract, I recommend using the full name 'Differential Extension' for clarity.\n\n- Structure/Content: The Background section's detailed introduction to Differential Transformer and Differential Extension may be overly long. I suggest moving the detailed technical aspects of these related works to the Appendix or significantly shortening the section to keep the main content more focused on the proposed DAA method.\n\nSince I am not very familiar with this field, I am willing to adjust my comments based on the feedback from other reviewers during the rebuttal stage."}, "questions": {"value": "-  Judging from the architecture design (Figure 2), DAA and its variants (Diff K, Diff Q, Diff V) appear to be a decomposition, combination, and fusion of existing differential architectures (Differential Transformer and DEX). Could the authors elaborate further on whether DAA possesses deeper theoretical or structural innovations beyond being an exploratory combination?\n\n- In the training Loss curve (Figure 3), I did not observe a significant difference between DAA and other baseline methods. How do the authors explain this phenomenon? Does this imply that DAA's advantage is primarily reflected in evaluation metrics (such as accuracy, perplexity) rather than the convergence speed or absolute value of the loss during training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I6kv4pzsSk", "forum": "8yhSDIcu1R", "replyto": "8yhSDIcu1R", "signatures": ["ICLR.cc/2026/Conference/Submission16857/Reviewer_kx4s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16857/Reviewer_kx4s"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16857/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967727385, "cdate": 1761967727385, "tmdate": 1762926876072, "mdate": 1762926876072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}