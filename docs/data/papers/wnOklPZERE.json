{"id": "wnOklPZERE", "number": 4104, "cdate": 1757601330286, "mdate": 1763622854736, "content": {"title": "FlowOpt: Fast Optimization Through Whole Flow Processes for Training-Free Editing", "abstract": "The remarkable success of diffusion and flow-matching models has ignited a surge of works on adapting them at test time for controlled generation tasks. Examples range from image editing to restoration, compression and personalization. However, due to the iterative nature of the sampling process in those models, it is computationally impractical to use gradient-based optimization to directly control the image generated at the end of the process. As a result, existing methods typically resort to manipulating each timestep separately. In this work we introduce FlowOpt - a zero-order (gradient-free) optimization framework that treats the entire diffusion/flow process as a black box, enabling optimization through the whole process without backpropagation through the model.\nOur method is both highly efficient and allows users to monitor the intermediate optimization results and perform early stopping if desired. We prove a sufficient condition on FlowOpt's step-size, under which convergence to the global optimum is guaranteed. We further show how to empirically estimate this upper bound so as to choose an appropriate step-size.\nWe demonstrate the effectiveness of FlowOpt in the context of image editing, showcasing two use cases: (i) inversion (determining the initial noise that generates a given image), and (ii) directly steering the edited image to be similar to the source image while conforming to the target text prompt. \nIn both settings, our method achieves state-of-the-art results while using roughly the same number of neural function evaluations (NFEs) as existing methods.", "tldr": "A new zero-order optimization method through the whole flow processes for zero-shot image inversion and image editing", "keywords": ["Zero-order optimization", "Image inversion", "Image editing", "Flow Matching", "Diffusion models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a15d7c60474b5593693a8ed08e7772f1b818b722.pdf", "supplementary_material": "/attachment/87a7444ef083f15f5a9a8ad2b612430bf055e235.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a method for image inversion and editing with flow models. The idea is to optimize a $z_t$ (typically $z_T$) to reconstruct the input image. Since it is not feasible to propagate gradients through the entire denoising process, the optimization update omits the Jacobian term. So the update step becomes $z_0^{(i)} - y$, where $z_0^{(i)}$ is the image generated from the current state of the optimization, and $y$ is the input image.\nThe optimization uses a small learning rate, and the paper shows that if the lr is not small enough, this process does not converge."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The method is novel, and it is initially surprising that it works. The authors provide an analysis and theoretical justification (but I do have concerns regarding the theoretical part, see weaknesses section).\n- The method itself is simple, and the paper presentation is clear.\n- The authors performed extensive evaluations against competing methods and the results are plausible (but I do have concerns here, see weaknesses section).\n- The limitations of the method are clearly discussed in the Appendix.\n- The method's results seem to adhere to the provided edit while staying well aligned with the original image in cases where competing methods fail."}, "weaknesses": {"value": "### Major Concerns\n1. The method requires a relatively large number of NFEs in order to provide an advantage over existing methods (e.g., FireFlow and UniInv) in reconstruction. \n\n2. The authors present a theorem that guarantees the method's convergence under certain assumptions, however why and if these assumptions hold in practice is not clear. In addition, I think that the proof itself in Appendix F is potentially flawed, as explained next. \nEven assuming the condition holds, for the proof to hold we need to show that there exists some fixed $\\kappa > 0$ such that the range in Eq. S8 exists. Otherwise, the limit argument is invalid for this claim. \nFurthermore, there exist many functions for which the condition holds, yet for any fixed $\\kappa$ the range doesn't exist. Examples include $\\tanh(x)$ where the supremum of $u_1$ and $u_2$ in the expression of $\\eta_1$ is infinite and $x^3$ where the infimum of $u_1$ and $u_2$ in the expression of $\\eta_2$ is $0$. Both functions satisfy the required condition with $\\beta = 1$.\n\n3. While the method compares with relevant inversion-based editing methods, there are also other approaches for text-based image editing, and it is not clear that the general framework (inversion + denoising with a different prompt) is the most effective one. For example, the method is not compared with Flux Kontext or Qwen Image Edit which are the SOTA text-based image editing models.\n\n### Minor Concerns\n- Assuming that the Theorem holds, from the results in Appendix C it seems that the convergence is very slow, and in practice the initialization is crucial for the success of the method. It would be interesting to analyze convergence and performance when using other initializations, such as random noise or an interpolation between random noise and the final image. \n- Analysis of performance on few-step models is missing, even though they are potentially strong candidates to benefit from this method. \n- The method seems to support only appearance changes.\n- Why ReNoise is not included in the editing results? And no visual results of reconstruction are provided.\n- Showing other applications for this optimization framework will strengthen the paper.\n\n### Final Note\nDespite these weaknesses, I find the paper overall good. I would be willing to raise my score if the authors address the issues related to the convergence claims and provide a more thorough discussion of the origins of the method's limitations."}, "questions": {"value": "I would like to see more experiments that empirically support the claim of convergence to a unique solution from different initial conditions. If these cannot be provided, I would suggest the convergence guarantee claims to be removed from the paper.\n\nMethods that involve noise optimization, even gradient-free ones, can often produce inverted latents that don't exhibit properties of typical high dimensional Gaussian samples. Such properties may limit the editability of images generated by these latents (see e.g ReNoise, where the authors try to tackle this issue with regularization during optimization). I would like to see an analysis of the properties of the inverted latents found by this method, which may explain some limitations in editability, and perhaps hint towards a future solution for these limitations.\n\nThe limitation for pose editing as presented in figure S16 is counter-intuitive. I would expect that using a larger number of optimization steps would make the edited image deviate less from the original image (as is seen in Figure 4 and Figure S17), and not the other way around."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zdFL6wcUOk", "forum": "wnOklPZERE", "replyto": "wnOklPZERE", "signatures": ["ICLR.cc/2026/Conference/Submission4104/Reviewer_NSam"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4104/Reviewer_NSam"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4104/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761420134010, "cdate": 1761420134010, "tmdate": 1762917178765, "mdate": 1762917178765, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the task of editing images (and potentially other generative tasks)  using pre-trained flow/diffusion models in a gradient-free manner. The key idea being, treating the entire sampling process as a \"black box\" instead of tweaking each sampling step individually (which is the case with many existing approaches) and using a zero-order optimisation approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is very well written. \n1. This paper presents a clean idea of optimising the whole process rather than per-timestep manipulation. \n2. The paper also presents a theoretical contribution: i.e., a sufficient condition on the step-size for convergence of the opimizer in this setting. \n3. The edits looks visually appealing and demonstrate a good tradeoff between fidelity and edit strength."}, "weaknesses": {"value": "1. Although the paper compares methods quantitatively and qualitatively, a user study is missing.\n\n2. Paper doesn't really discuss how the Zero-order method performs with increase/decrease in dimension since zero-order methods may suffer from bad convergence with increase in dimension."}, "questions": {"value": "1. Why have the authors not compared against a gradient-based inversion baseline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O0GAbFQpMc", "forum": "wnOklPZERE", "replyto": "wnOklPZERE", "signatures": ["ICLR.cc/2026/Conference/Submission4104/Reviewer_j7YL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4104/Reviewer_j7YL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4104/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939793409, "cdate": 1761939793409, "tmdate": 1762917178568, "mdate": 1762917178568, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents FlowOpt, a zero-order (gradient-free) optimization framework for training-free image editing with pretrained diffusion and flow models. Instead of backpropagating through the model or optimizing per timestep.\nThat said, this work is exactly similar to existing literature, particularly FlowChef, and lacks comprehensive and community-standard evaluations. See details below."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Theorem 1 provides a sufficient condition on the step size under which the FlowOpt iterations provably converge. This formal analysis of convergence is a valuable addition to flow-based optimization literature, where most prior methods rely on heuristic step-size tuning."}, "weaknesses": {"value": "The novelty is limited. The proposed zero-order optimization across the full flow process is conceptually identical to FlowChef [1] (ICCV 2025, arXiv Dec 2024), which already introduced a gradient-free control framework with theoretical guarantees and broad task coverage (inversion, editing, and restoration). The main difference, introducing a step-size bound, is a modest theoretical insight rather than something novel or different.\n\nThe work lacks comprehensive evaluation on community-standard editing benchmarks such as PIE-Bench [2], which is now widely adopted for fair comparison across inversion-based and inversion-free methods.\n\nThe paper doesn’t clarify the conceptual distinction between FlowOpt and FlowChef, despite their almost identical formulations (both optimize the initial latent by approximating the flow trajectory without backpropagation).\n\n[1] “FlowChef: Steering of Rectified Flow Models for Controlled Generations,” ICCV 2025.\n[2] “Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code,” ICLR 2024."}, "questions": {"value": "Can the authors clearly articulate the difference between FlowOpt and FlowChef, both theoretically and empirically?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ilIEn3pKIJ", "forum": "wnOklPZERE", "replyto": "wnOklPZERE", "signatures": ["ICLR.cc/2026/Conference/Submission4104/Reviewer_FeKp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4104/Reviewer_FeKp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4104/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989317626, "cdate": 1761989317626, "tmdate": 1762917178279, "mdate": 1762917178279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}