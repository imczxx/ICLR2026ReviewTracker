{"id": "gCHEQFuv1j", "number": 4541, "cdate": 1757702911629, "mdate": 1759898027493, "content": {"title": "PDTrack: Progressive Dense 3D Tracking", "abstract": "We propose a novel algorithm for accelerating dense long-term 3D point tracking\nin videos. Through analysis of existing state-of-the-art methods, we identify two\nmajor computational bottlenecks. First, transformer-based iterative tracking be-\ncomes expensive when handling a large number of trajectories. To address this,\nwe introduce a coarse-to-fine strategy that begins tracking with a small subset of\npoints and progressively expands the set of tracked trajectories. The newly added\ntrajectories are initialized using a learnable interpolation module, which is trained\nend-to-end alongside the tracking network. Second, we adopt a lightweight im-\nplementation for the 4D correlation block that reduces its computational cost on\ncommon GPU backends. Together, these improvements lead to a 5–100× speedup\nover existing approaches while maintaining state-of-the-art tracking accuracy.", "tldr": "", "keywords": ["3D tracking"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e8b0a5a9390580e624d955f95478b182dae89fc7.pdf", "supplementary_material": "/attachment/dc397ae9a92a47b07a33291e2ec5bd65da093c2f.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a framework that employs a coarse-to-fine strategy together with a learnable interpolator to gradually increase the number of tracked pixels. This approach significantly reduces overall memory consumption and speeds up the original baseline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strength:\n\nNovelty: A well-designed combination of iterative refinement and coarse-to-fine strategy that substantially improves tracking speed while maintaining the baseline accuracy.\n\nQuality: The paper includes extensive experiments and ablation studies demonstrating the importance of the proposed module. The writing is clear and the methodology is easy to follow."}, "weaknesses": {"value": "1) Is the learnable interpolator’s weight shared across iterations?\n\n2) Table 7: The performance (OA & APD) on PSTUDIO lags behind BootsTAPIR and CoTracker2, which are 2D methods. Could the authors provide intuition or an explanation for this behavior?\n\n3) Table 12: Tables (a) and (b) present the interpolator accuracy before and after upsampling. However, why does the accuracy decrease as the number of iterations increases? Why is the “learnable” interpolator performing worse than “nearest” and “bilinear”? I would expect the learnable version to achieve the best results—or do these numbers represent error rather than accuracy? \n\n4) Additionally, I could not find any discussion of Table 12 in the paper.\n\n5) Comparison with CoTracker3, TAPIP3D."}, "questions": {"value": "Please check the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NDHXWrGg8n", "forum": "gCHEQFuv1j", "replyto": "gCHEQFuv1j", "signatures": ["ICLR.cc/2026/Conference/Submission4541/Reviewer_mKiS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4541/Reviewer_mKiS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760994636459, "cdate": 1760994636459, "tmdate": 1762917430122, "mdate": 1762917430122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "The General Response to Reviewers (1/3)"}, "comment": {"value": "We would like to thank all reviewers for their thoughtful feedback. We are encouraged that several reviewers noted: (i) the paper is clearly written and easy to follow (mKiS, Pxyp); (ii) the method is well designed with thorough analysis (pkxP, ZpXS, mKiS); and (iii) the experiments are extensive and justify the design choices (all reviewers).\n\n# Common issues\nBelow, we address common questions raised by the reviewers.\n\n**Question C1. About the technical novelty.** \nThe reviewers note that the coarse-to-fine strategy and interpolation are not new ideas, and we agree to some extent. Coarse-to-fine is a general and abstract idea that is employed in countless papers, but it is not a drop-in recipe: across vision, many work propose new coarse-to-fine frameworks tailored to their setting—thus crafting an effective variant is itself a substantive contribution.\n\nOur contribution is **the first rigorously analyzed, token-level coarse-to-fine framework for dense, long-term, transformer-based 3D tracking**. It is a non-trivial effort, as we pushed the accuracy–efficiency trade-off of the abstract coarse-to-fine idea very successfully, achieving over 5× speedup with minimal accuracy loss compared to the fastest existing dense tracker, and 19–100× faster runtime than other sparse trackers while improving accuracy in dense tracking settings.\n\n**Why this is non-trivial for 3D tracking:**\n1. **3D tracking is inherently unstructured.** Although we operate on a regular grid of 3D tracks, this grid only defines neighborhood relationships at the initial frame. As time progresses, neighboring tracks in the original grid may diverge significantly, making consistent coarse-to-fine refinement nontrivial.\n2. **Recent trends in tracking favor single-resolution models**. Modern tracking frameworks avoid coarse-to-fine to reduce error accumulation. Designing a coarse-to-fine strategy that maintains high accuracy requires careful trade-offs and is widely recognized as a difficult problem in tracking. \n3. **Coarse-to-fine designs remain underexplored in transformer-based trackers.** Many state-of-the-art systems—e.g., FlowFormer [1], TransFlow [2], CoTracker [3,4], SpatialTracker [5], and DELTA[5]—operate at a single token density rather than adopting a token-level coarse-to-fine hierarchy. While a few transformer variants attempt multi-scale processing, the design space is still limited, and we view a principled, token-level scheme as a meaningful research contribution. \n\n**On related paradigms:**\n1. **Optical flow**: while earlier optical-flow pipelines (FlowNet[6], PWCNet[7]) have coarse-to-fine designs, tracking is fundamentally different. 3D tracking is more difficult, because particles have to be tracked over a longer time. Optical flow in some sense always resets between two frames and doesn't have these long term temporal dependencies. The insight that a coarse-to-fine approach can work for 2D and 3D tracking alone is an important novel insight.\n\n2. **DOT[8] (two-stage dense tracking)**. DOT’s coarse (sparse tracking) and fine (optical flow) stages are **separate, heterogeneous modules**. Our approach keeps everything **inside one transformer pipeline**, using a **lightweight, learnable interpolator** to activate new tokens between refinement steps.\n\n3. **DELTA (frame-level “coarse”)**. DELTA downsamples frames once but still processes **every low-res token in every iteration**, leaving per-iteration attention cost unchanged. Our method is token-level: start very sparse (4–8×), interpolate dense proposals, progressively densify, then finish with one full pass for pixel-level accuracy.\n\nDifferent from these approaches, our work poses an orthogonal question: can we reduce the token load within the transformer while preserving pixel-level accuracy? We address this by introducing a token-level sparsity schedule that begins with extremely sparse sampling (stride 4×–8×), interpolates dense proposals using a learnable, feature-aware interpolator, and progressively densifies the token set over subsequent iterations. The full design space is detailed in Section 3.2. Below, we briefly summarize our key findings:\n\n1. **Which dimension to downsample?** Spatial, temporal, and trajectory subsampling are benchmarked in Table 1; only trajectory subsampling preserves accuracy.\n2. **Which schedule?** Figure 5a and 5c show runtime vs. accuracy trade-offs across different sparsity schedules. A very-sparse-to-dense schedule achieves the best balance.\n3. **Which sampling pattern?** Table 5 compares uniform grid, random, and SIFT-based patterns. The uniform grid proves to be the most reliable.\n4. **Which interpolator?** Figure 5b and Supplementary Figures 4–7 evaluate nearest, bilinear, and our attention-based interpolator. The learnable interpolator consistently performs best, especially at large strides."}}, "id": "DKf3kOlSlD", "forum": "gCHEQFuv1j", "replyto": "gCHEQFuv1j", "signatures": ["ICLR.cc/2026/Conference/Submission4541/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4541/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4541/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763698798478, "cdate": 1763698798478, "tmdate": 1763698995944, "mdate": 1763698995944, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PDTrack, a dense 3D point tracking framework that aims to improve efficiency over DELTA.\nThe method introduces three changes: (i) Coarse-to-fine trajectory subsampling, which tracks a sparse subset of points first and progressively densifies them; (ii) learnable interpolation module that predicts motion for untracked pixels based on nearby tracked ones; (iii) an optimized 4D correlation implementation for faster GPU execution. PDTrack reports up to 5-100× speedup compared to DELTA while maintaining similar accuracy on Kubric3D and TAP-Vid3D. The method is evaluated on both dense 3D and long-range 2D tracking benchmarks, with ablations on runtime and sampling strategies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper clearly identifies bottlenecks in dense tracking pipelines and provides quantitative analysis of each.\n- Extensive runtime and accuracy trade-off studies justify the design choices, such as subsampling strategies and interpolation variants.\n- The authors provide speed-accuracy curves, per-module breakdowns, and ablations on multiple datasets.\n- Paper presentation is clean and easy to follow."}, "weaknesses": {"value": "## Limited novelty\nThe coarse-to-fine scheme itself is an engineering improvement, not a new learning paradigm. Consequently, PDTrack reads as an efficiency-oriented extension of DELTA rather than a novel research contribution. **While runtime improvements are valuable and appreciated,** the paper lacks a deeper insight that would justify a full ICLR publication.\n\n## Connection to prior work\n- The interpolation mechanism is very similar to TAPTRv2 [1]’s iterative feature-weighted update rule, raising concerns about novelty.\n- The coarse-to-fine densification mirrors strategies used in optical-flow pipelines, such as FlowFormer [2], but applied here at token level.\n\n## Evaluation and completeness\n- The motivation emphasizes efficiency, but Appendix B6 shows 40.1 GB GPU memory usage, indicating the method is still heavy.\n- Table 4 (TAP-Vid3D) omits key recent 2D trackers with depth lifting such as CoTracker3 [3], Track-On [4], and BootsTAPNext [5], which are necessary to contextualize the performance advantage of full 3D tracking.\n\n## Overall\nWhile speedups are significant, the research insight is incremental. The method neither alters the representation of motion nor introduces a new way to reason about geometry. This makes the work better suited as an engineering-oriented extension of DELTA, not a standalone contribution.\n\n---\n\n## References  \n[1] Li et al., TAPTRv2: Attention-based Position Update Improves Tracking Any Point, NeurIPS 2024\n\n[2] Huang et al., FlowFormer: A Transformer Architecture for Optical Flow, ECCV 2022\n\n[3] Karaev et al., CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos, ICCV 2025\n\n[4] Aydemir et al., Track-On: Transformer-based Online Point Tracking with Memory, ICLR 2025\n\n[5] Zholus et al., TAPNext: Tracking Any Point as Next-Token Prediction, ICCV 2025"}, "questions": {"value": "- Is the depth estimation time included in the reported run-time calculations?\n- What explains the greater robustness on extended optical-flow sequences (Table 2) despite minimal architectural changes from DELTA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "86kDEpeMP7", "forum": "gCHEQFuv1j", "replyto": "gCHEQFuv1j", "signatures": ["ICLR.cc/2026/Conference/Submission4541/Reviewer_Pxyp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4541/Reviewer_Pxyp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761388699901, "cdate": 1761388699901, "tmdate": 1762917429839, "mdate": 1762917429839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PDTrack, a progressive dense association framework designed to accelerate 3D point cloud single-object tracking. The core idea is to replace complex matching processes in existing trackers with a lightweight, progressively refined association scheme that improves tracking efficiency without substantially sacrificing accuracy. Experiments are conducted on several LiDAR-based tracking benchmarks to validate the method’s speed and accuracy balance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed progressive dense association structure is well-engineered and appears to provide tangible runtime benefits for 3D tracking, which is valuable for real-time applications.\n2. Experimental results demonstrate moderate improvements in speed compared to existing baselines, suggesting that the method may serve as an efficient alternative in resource-limited scenarios."}, "weaknesses": {"value": "1. The contributions are mostly engineering-oriented, improving efficiency through architectural simplifications rather than introducing new algorithmic or theoretical ideas. \n2. The progressive dense association concept feels like an incremental adaptation of existing dense matching or coarse-to-fine refinement techniques already explored in 3D tracking literature.\n3. The motivation is not clearly articulated. Why progressive dense association is fundamentally better than sparse matching or correlation-based tracking is not convincingly justified.\n4. The method’s acceleration effect is not comprehensively validated across different 3D tracking architectures. Since this is a general acceleration technique, it should ideally be tested on multiple 3D point tracking methods."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "V6NoO2jBIE", "forum": "gCHEQFuv1j", "replyto": "gCHEQFuv1j", "signatures": ["ICLR.cc/2026/Conference/Submission4541/Reviewer_ZpXS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4541/Reviewer_ZpXS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791113735, "cdate": 1761791113735, "tmdate": 1762917429546, "mdate": 1762917429546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PDTrack, a fast and dense long-term 3D pixel tracking method for RGB-D videos. It addresses two key bottlenecks in DELTA and proposes three novel modules: a coarse-to-fine trajectory densification strategy, a learnable attention-based interpolation module, and a kernel-efficient 4D correlation block. PDTrack achieves comparable or slightly better accuracy than DELTA on dense 3D tracking and long-range optical flow tasks, while delivering a 5–100× speedup over existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes a coarse-to-fine tracking algorithm with learnable attention-based interpolation that starts with sparsely sampled trajectories and densifies them over iterations\n2. The author designed an simple accelerated 4D correlation implementation that improves kernel efficiency on common GPU backends.\n3.The paper identifies the runtime bottlenecks in existing tracking methods and proposes a simple yet effective solution, supported by extensive experiments demonstrating its efficiency and effectiveness."}, "weaknesses": {"value": "1. The paper evaluates the accelerated 4D correlation implementation only on the A100 GPU, without assessing its performance on other GPU architectures.\n2. The interpolator employs four nearest neighbors, but the impact of using different numbers of neighbors is not analyzed.\n3. The interpolator itself is not novel, as it is adapted from the DELTA framework."}, "questions": {"value": "1. How do you apply your model to sparse tracking? Were any modifications made?\n2. Could you conduct an ablation study to evaluate the effect of different numbers of nearest neighbors used in the interpolator?\n3. Have you tried using other depth estimation models, such as UniDepthv2 [1]? It would be interesting to see how a more accurate depth estimator could improve the overall performance.\n\n[1] Piccinelli, Luigi, et al. \"Unidepthv2: Universal monocular metric depth estimation made simpler.\" arXiv preprint arXiv:2502.20110 (2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethical concerns identified."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KPDrqUpXuz", "forum": "gCHEQFuv1j", "replyto": "gCHEQFuv1j", "signatures": ["ICLR.cc/2026/Conference/Submission4541/Reviewer_pkxP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4541/Reviewer_pkxP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978141440, "cdate": 1761978141440, "tmdate": 1762917429354, "mdate": 1762917429354, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}