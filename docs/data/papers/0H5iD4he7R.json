{"id": "0H5iD4he7R", "number": 24471, "cdate": 1758357192051, "mdate": 1759896764314, "content": {"title": "A Unified Framework for Diffusion Model Unlearning with f-Divergence", "abstract": "Machine unlearning aims to remove specific knowledge from a trained model. While diffusion models (DMs) have shown remarkable generative capabilities, existing unlearning methods for text-to-image (T2I) models often rely on minimizing the mean squared error (MSE) between the output distribution of a target and an anchor concept. \nWe show that this MSE-based approach is a special case of a unified $f$-divergence-based framework, in which any $f$-divergence can be utilized.\nWe analyze the benefits of using different $f$-divergences, that mainly impact the convergence properties of the algorithm and the quality of unlearning. \nThe proposed unified framework offers a flexible paradigm that allows to select the optimal divergence for a specific application, balancing different trade-offs between aggressive unlearning and concept preservation.", "tldr": "", "keywords": ["machine unlearning", "diffusion models", "f-divergence"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fdc476126ec69532b1dc4e0377d2bc0e0aa18520.pdf", "supplementary_material": "/attachment/d71c45a22db08d53a7c3b022703ec331a121c4c8.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes f-DMU, a unified framework for diffusion model unlearning based on f-divergence. It generalizes existing MSE-based and KL-based unlearning approaches by allowing any f-divergence. The method provides two formulations—closed-form and variational—to balance simplicity and generality. The authors offer theoretical analyses of gradient behavior and convergence properties, showing that different divergences lead to distinct unlearning dynamics. Empirical results on Stable Diffusion v1.4 demonstrate that the Hellinger-based loss achieves better trade-offs between erasure effectiveness and image quality preservation compared to the standard MSE loss."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors rigorously generalize MSE-based unlearning to a broad family of f-divergences, showing that KL divergence and MSE are just special cases. It demonstrates a strong theoretical foundation linking unlearning dynamics to divergence curvature and gradient scaling.\n\n2. The paper derives explicit gradient behaviors and proves local exponential stability for the variational form. The gradient comparison gives interpretable insight.\n\n3. The experimental results clearly support the theoretical claims. The Concept Ablation explicitly shows that bounded gradients prevent artifacts such as distorted faces or textures. This close alignment between mathematical reasoning and empirical observation increases the paper’s credibility."}, "weaknesses": {"value": "1. Although the authors discuss how curvature affects convergence, they don’t propose a quantitative criterion for choosing which f-divergence to use in practice. To my understanding, I think the choice is heuristic. For example, while Table 1 suggests H^2 outperforms MSE for concept erasure, the paper provides no procedure for selecting between closed-form vs. variational objectives or among multiple f-divergences based on task statistics.\n\n2. All experiments are performed on Stable Diffusion v1.4 with a few synthetic concepts. Considering many DM unlearning works are performing unlearn multiple concepts at once, how does the proposed method performs when unlearn many concepts (say > 10 concepts)? It is important that the unlearning algorithm can handle such practical scenario, which demonstrate the robustness of the method.\n\n3. While CAbl and MSE-based methods are compared, newer or adversarial unlearning methods (e.g., DoCo[1] or defensive adversarial unlearning [2]) are omitted. Besides these two, the author also needs to compare with other baselines such as SalUn, FMN, SPM, ESD, MACE, etc. I suggest the author compare with similar approach unlearning and different types of unlearning, which will make the proposed method more convincing.\n\n\n[1] Wu, Yongliang, et al. \"Unlearning concepts in diffusion model via concept domain correction and concept preserving gradient.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39. No. 8. 2025.\n\n[2] Zhang, Yimeng, et al. \"Defensive unlearning with adversarial training for robust concept erasure in diffusion models.\" Advances in neural information processing systems 37 (2024): 36748-36776."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "E1UyvbBM9t", "forum": "0H5iD4he7R", "replyto": "0H5iD4he7R", "signatures": ["ICLR.cc/2026/Conference/Submission24471/Reviewer_ygvk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24471/Reviewer_ygvk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883517143, "cdate": 1761883517143, "tmdate": 1762943090670, "mdate": 1762943090670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified framework for diffusion model (DM) unlearning based on f-divergences. The work introduces a theoretical generalization of concept erasure via any f-divergence in DM. The contributions are: closed-form derivations for special cases (Hellinger, χ², Jeffreys), a variational adversarial formulation for general divergences and gradient behavior analysis & local convergence guarantees. Authors show empirical evaluation on Stable Diffusion 1.4 with multiple concepts and anchors. The paper argues that Hellinger divergence yields better stability and prior preservation while χ² gives more aggressive unlearning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper elegantly reformulates prior MSE-based objectives as specific instances of the f-divergence family, providing a principled foundation for a range of unlearning losses.\n2) The gradient and convergence analyses are rigorous, connecting divergence curvature to optimization dynamics in a meaningful way.\n3) The experiments demonstrate that the squared Hellinger divergence achieves bounded gradients, leading to stable unlearning with fewer artifacts, a convincing empirical validation of the theory. \n4) The inclusion of post-, fine-, and variational-based unlearning frameworks in the appendix positions this as a unifying theoretical effort."}, "weaknesses": {"value": "1) Limited baselines: comparison with several recent baselines (e.g., MACE, SAFREE) are missing in the experiments section.\n2) Empirical focus is narrow. All experiments use the same model (Stable Diffusion 1.4). Although reasonable, it would help to clarify whether results depend on architecture details or on properties of the diffusion loss. It is unclear how the proposed f-divergence solution are scalable to newer diffusion architectures (e.g., SDXL, Flux)."}, "questions": {"value": "Q1. Did you try benchmarking on LDM-based SDXL and Flow-matching models to validate generality?\nQ2. Does the insight on having a bigger family of f-divergence lead to better unlearning performance? This requires comparison with latest DM unlearning methods which is missing in the paper. Particularly, the authors do not discuss the unlearned model's robustness to attacks like membership inference attacks. \nQ3. Could you report compute cost vs standard MSE KL-minimization?\nQ4. The authors highlight Jeffreys, Hellinger, and χ² but omit other f-divergences (e.g., JS, Rényi). A short discussion on why these three were prioritized would improve completeness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jPKOFZQz27", "forum": "0H5iD4he7R", "replyto": "0H5iD4he7R", "signatures": ["ICLR.cc/2026/Conference/Submission24471/Reviewer_thXe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24471/Reviewer_thXe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762075843664, "cdate": 1762075843664, "tmdate": 1762943090328, "mdate": 1762943090328, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a generalization of the KL divergence-based unlearning algorithm to a broader class of f-divergence and performs a detailed analysis of the behavior of different divergence measures. Specifically, the paper compares the closed-form solution of Squared Hellinger ($H^2$) distance, the Pearson $\\chi^2$ divergence, and the KL-divergence measures. The gradient analysis shows that $H^2$ distance has a much lower gradient norm, which leads to a more stable unlearning process with less disruption on the nearby unrelated concepts. The paper also proposes a variational framework for a general f-divergence-based training, but this is shown to be much more disruptive, although fast."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The generalization of the unlearning objective from MSE/KL divergence to a unified f-divergence framework is really insightful. It offers a flexible paradigm that allows for balancing the trade-offs between unlearning effectiveness and the preservation of other concepts. The theoretical analysis of the gradients for the closed-form loss functions provides a reasonable rationale for their differing empirical behaviors.\n\n2. The experimental results align well with the gradient analysis. The $H^2$ divergence is shown to better preserve generative quality on unrelated concepts (as measured by metrics like KID) when compared to MSE, which appears to cause more degradation."}, "weaknesses": {"value": "1. The empirical comparison is primarily against KL-based methods like Concept Ablation. The evaluation would be more comprehensive if benchmarked against other recent state-of-the-art baselines, such as EraseAnything [1] or MACE [2].\n\n2. In addition, an analysis of adversarial robustness (e.g., using a method like Ring-A-Bell [3]) can provide a stronger and more rigorous measure of how completely a concept has been erased. The robustness behaviour of different divergence measures can be interesting to know as well. \n\n3. The paper's evaluation of collateral damage from the unlearning method focuses on \"unrelated concepts.\" A detailed quantitative evaluation of the impact on semantically nearby concepts would be valuable. For instance, in the style removal experiments, does unlearning \"Van Gogh\" (an Impressionist) also degrade the model's ability to generate \"Monet\" or \"Impressionist paintings\"? The current analysis (e.g., Fig. 4) is helpful, but a quantitative study on this would strengthen the work (as done in Concept Ablation as well)\n\n4. The advantages of the variational framework versus the closed-form solutions are not fully clear. The results show it is faster while also more disruptive, but a deeper analysis of why the min-max optimization leads to faster convergence and a discussion of its stability trade-offs would be beneficial for developing a more general-purpose unlearning algorithm based on this paradigm.\n\n[1] EraseAnything: Enabling Concept Erasure in Rectified Flow Transformers \n[2] Mace: Mass concept erasure in diffusion models \n[3] Ring-a-bell! how reliable are concept removal methods for diffusion models?"}, "questions": {"value": "Please look at the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "x4uX4ylIiK", "forum": "0H5iD4he7R", "replyto": "0H5iD4he7R", "signatures": ["ICLR.cc/2026/Conference/Submission24471/Reviewer_PcLV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24471/Reviewer_PcLV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762131960538, "cdate": 1762131960538, "tmdate": 1762943090092, "mdate": 1762943090092, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors generalize existing concept unlearning methods in diffusion models by replacing KL divergence with more general f-divergence. The authors then theoretically analyze the impact of different choices of f on convergence behaviors near equilibria and gradient size. Empirically, it was found that the squared Hellinger distance has more stable gradient updates and better prior preservation."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- A detailed convergence analysis is provided and a theoretically principled way of choosing f to have better convergence properties is provided"}, "weaknesses": {"value": "- The results are poorly presented and some claims are not well justified\n   - For example, in Figure 1, it is unclear how to interpret the white boxes that zoom in on portions of the image. Additionally, Figure 3 has a lot of noise in the plot, so some smoothing and a better caption explaining the main takeaway would help a great deal.\n   - While a great deal of theoretical emphasis in the paper is regarding the variational approach, it appears details surrounding the training procedure on the minimax objective are not provided and the empirical results are minimal (lines 402-412) and not favorable.\n   - There appears to be somewhat of an overreliance on qualitiative results for supporting important claims such as \"This behavior characterizes the losses properties and explains why, for instance, H2 less probably leads to strange artifacts during fine-tuning.\" While Figure 2 is a great to include for us to visualize the nature of the benefit of H2, it would be great to quantitatively measure and keep track of these strange artifacts across multiple examples and present it in a table. Otherwise, the reader is left to believe that the Van Gogh example was ad hoc. \n- Small note: It appears many citations that need to be using parantheticals are not using them (e.g., related works section doesn't have any paranthetical citations).\n\nWhile I believe there is merit to the exploration of different choices of f and the authors' theoretical analysis, I believe the paper and experimental results will need a couple more iterations to be fully polished and conference ready."}, "questions": {"value": "Please address the comments and concerns in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qHr39n2Dwi", "forum": "0H5iD4he7R", "replyto": "0H5iD4he7R", "signatures": ["ICLR.cc/2026/Conference/Submission24471/Reviewer_zCjU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24471/Reviewer_zCjU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762137561333, "cdate": 1762137561333, "tmdate": 1762943089785, "mdate": 1762943089785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}