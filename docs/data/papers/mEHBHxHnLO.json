{"id": "mEHBHxHnLO", "number": 18319, "cdate": 1758286367756, "mdate": 1763769631515, "content": {"title": "HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models", "abstract": "Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose \\textbf{HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation)}, a framework designed to improve \\textcolor{blue}{\\textbf{fidelity, controllability, and domain alignment}} of diffusion-generated damage images. HERS fine-tunes a base diffusion model via \\textcolor{blue}{\\textbf{domain-specific expert adaptation}}, without requiring manual annotation. Using self-supervised image–text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category—such as dents, scratches, broken lights, or cracked paint—as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe \\textcolor{blue}{\\textbf{consistent improvements: +5.5\\% in text faithfulness and +2.3\\% in human preference ratings}} compared to baselines. Beyond image fidelity, we discuss \\textcolor{blue}{\\textbf{implications for fraud detection, auditability, and safe deployment}} of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.", "tldr": "HERS enables domain-specific, self-supervised text-to-image diffusion for realistic vehicle damage generation, improving fidelity, controllability, and safety in high-stakes insurance applications.", "keywords": ["Text-to-Image (T2I) Diffusion", "Vehicle Damage Synthesis", "Domain-Specific Generative Modeling", "Self-Supervised Expert Adaptation", "Fraud Detection / Safety-Critical AI", "Controllable Image Generation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/300c4e698f47bc593b0dbf07f2ef20e14ecbfb97.pdf", "supplementary_material": "/attachment/98e0fd0a3bdb676aa1147908be7c3d7d2f2f7e51.pdf"}, "replies": [{"content": {"summary": {"value": "Authors focus on creating synthetic data for car crashes. To generate more diverse images, they generate a variety of prompts with an LLM. They train separate LoRA parameters for each domain, and combine the weights. They evaluate on a private dataset."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "S1) A variety of qualitative examples are included.\n\nS2) The car crashes are an interesting application of synthetic data."}, "weaknesses": {"value": "Primarily, my rating is based on that it is difficult to evaluate this method compared to other SOTA methods, due to lack of comparison (see W2, W4, W6) and the choice to only evaluate on a private dataset (see W5). Additionally, the methods and motivation are not clear to me (see W1, W3, W8).\n\nW1) Some parts of the motivation seem contradictory. For example, in the abstract lines 37-39, there is the sentence \"The ability to generate...\"--but the creation of higher-quality synthetic data could itself introduce a higher risk of fraud. The motivation would be stronger if these ideas in the abstract and introduction were written more carefully, to retain consistency.\n\nW2) Much necessary context is missing in the related works.\nW2a) Several key and related papers in synthetic data are missing, including: [A, B, C]\nW2b) Comparing to existing work in car crashes is important. Preferably synthetic data for car crashes, if these methods exist, or else methods without synthetic data. \nW2c) If there is not a lot of work in car crashes, you could also discuss work in other out-of-distribution domains, such as satellite data [D].\n\nW3) The method sections are not clear (see Q1), making the method difficult to understand.\n\nW4) The novelty of the method is not fully clear, especially in light of missing related works (e.g. [A], [E]). Moreover, LLM-based prompt augmentation was done in [B]. An explanation of how it differs would greatly help in understanding the novelty of this work.\n\nW5) The evaluation is only on a private dataset--this is very problematic for reproducibility and for future work to compare. Also presenting results on some related publicly available dataset is necessary.\n\nW6) the chosen diffusion models (newest being SDXL) are a bit out-of-date. Understanding how this fits into contemporary literature would strengthen the impacts, e.g. with FLUX or Qwen-Image.\n\nW7) If the motivation involves training with the data: the metrics chosen reflect synthetic data comparison with real. This makes the chosen metrics only a proxy for the real task--the impact of this data would be easier to understand if results were presented for the given task, such as in [A, B, C, E] and Sariyildiz et al. (cited in paper). Also see Q2.\n\nW8) The motivation is not fully clear to me after reading the abstract and introduction. It is clear that the work tries to generate synthetic images, but it is not clear for what purpose. The paper would be better motivated if this were written more clearly. (W7 may not apply, if the motivation is different)\n\nW9) The use of multiple LoRA weights and merging them is itself a design choice--it would be better justified if compared to LoRA fine-tuning a single set of weights as an ablation.\n\nWriting tips (unless written above, these are not used to evaluate the paper, but may be helpful):\n\nt1) Using ~\\citep would help readability.\n\nt2) The related work section could use more structure, with specific sub-headings for the different areas.\n\nt3) Related works should overall be longer.\n\n\n\n[A] DataDream: Few-shot Guided Dataset Generation, Kim et al., ECCV 2024.\n\n[B] Is synthetic data from generative models ready for image recognition? He et al., ICLR 2023.\n\n[C] Diversified in-domain synthesis with efficient fine-tuning for few-shot classification, da Costa et al., 2023.\n\n[D] Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification. Nguyen et al., 2024.\n\n[E] LoFT: LoRA-fused Training Dataset Generation with Few-shot Guidance, Kim et al., 2025."}, "questions": {"value": "Q1) I am a bit confused by the method, outlined in sections 3.1-3.4. In stage 2, synthetic data is generated, but it is not clear to me what for--is that the final data? Section 3.3 describes training LoRA weights, but doesn't specify what model--I would assume the diffusion model, based on section 3.4?\n\nQ2) Why do you choose these metrics?\n\nQ3) Could you please outline the difference between your method and [E]?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5IdnZQ1xuf", "forum": "mEHBHxHnLO", "replyto": "mEHBHxHnLO", "signatures": ["ICLR.cc/2026/Conference/Submission18319/Reviewer_iSQP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18319/Reviewer_iSQP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842344023, "cdate": 1761842344023, "tmdate": 1762928036688, "mdate": 1762928036688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HERS (Hidden-Pattern Expert Learning), which adapts LLM + text-to-image diffusion models for risk-specific vehicle damage generation. HERS learns “hidden-pattern” experts that specialize in vehicle damage cues and integrates them into existing diffusion backbones. The paper emphasizes dual-use risks: while HERS can improve fraud-detection training, it could also be misused to generate synthetic fraud, highlighting the need for detection and watermarking safeguards."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- HERS is demonstrated across multiple diffusion backbones.\n\n- The proposed method delivers strong empirical improvements, showing consistent gains over a competitive expert-based baseline in text faithfulness and human-preference proxy metrics."}, "weaknesses": {"value": "- The proposed method appears somewhat trivial. Specifcially, it uses GPT-4 to generate diverse, damage-specific prompts, then uses a base T2I model (e.g., SDXL) to create self-supervised image–text pairs. It then trains lightweight LoRA experts for each damage category and context type, and finally averages the LoRA weights in parameter space.\n\n- Generalization ability. While promising, the approach’s generalization to other safety-critical domains is untested. I would suggest that the authors include preliminary cross-domain experiments or ablations to support the claimed extensibility.\n\n- Model robustness. I would also suggest that the authors examine performance across diverse vehicle types, lighting and occlusions, and regional variations; more importantly, assess whether HERS introduces systematic biases, given that the model is primarily based on synthetic data."}, "questions": {"value": "Please see the weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MPctcye9aZ", "forum": "mEHBHxHnLO", "replyto": "mEHBHxHnLO", "signatures": ["ICLR.cc/2026/Conference/Submission18319/Reviewer_mMdz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18319/Reviewer_mMdz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879971700, "cdate": 1761879971700, "tmdate": 1762928035843, "mdate": 1762928035843, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HERS, a framework claimed to adapt text to image diffusion models such as SDXL and MoLE for risk specific vehicle damage synthesis through hidden pattern expert learning. The proposed pipeline includes prompt generation via GPT4, synthetic image rendering with SDXL, LoRA expert fine tuning, and LoRA weight merging to create a unified generator. The authors claim improved text image faithfulness and visual quality over SDXL and MoLE, evaluated using VQA based metrics and human preference scores. However, while the paper is presented as a risk specific generative modeling framework for insurance, it is unclear what the technical or scientific novelty of HERS actually is, how the LoRA merging mechanism functions in detail, or what hidden pattern learning represents beyond a general descriptive term."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses an under-explored area of applying generative models to vehicle damage simulation. \n2. Uses a modular LoRA based structure which is computationally efficient. \n3. Includes evaluations across multiple diffusion backbones. \n4. Acknowledges dual use risks and ethical issues."}, "weaknesses": {"value": "**Soundness:** The methodology lacks sufficient technical depth and clarity. LoRA averaging and mixing are not explained properly. The paper states that experts are merged through LoRA weight averaging but does not include any mathematical detail or algorithmic breakdown. It is unclear whether averaging is normalised, layer specific, or includes conflict resolution. There is no comparison with established baselines such as ZipLoRA, LoRA composition, or LLAVA MoLE. Without these, the reader cannot assess if HERS truly provides any improvement beyond existing parameter efficient fine tuning averaging methods. The evaluation only measures prompt image similarity and perceptual quality. There is no analysis on whether HERS improves insurance specific outcomes, such as classification or fraud detection accuracy. The model remains dependent on SDXL. Since training data and generation rely on SDXL itself, the reported improvements may arise from curated prompts rather than genuine model enhancement. Finally, the concept of hidden pattern expert learning is never defined or measured. The term appears rhetorical rather than technical.\n\n**Presentation:** Figures are visually clear but the presentation does not convey methodological clarity. Later figures omit the prompts used for generation, preventing readers from verifying alignment quality. Sections 3.3 and 3.4 describe complex processes with vague language and no equations or pseudocode. The paper’s purpose is also ambiguous, switching between being a new image generation technique and an insurance domain application. Qualitative samples lack consistent captions or evaluation context, reducing interpretability.\n\nFirst part of the abstract give the impression that the work will tackle the problem of synthetic images for fraudulent automated insurance workflows, some kind of content authentication system, however, later it focused on generation. \n\n**Contribution:** The claimed contribution, risk specific adaptation for vehicle damage generation, is interesting but scientifically weak. There is no rigorous ablation study or new algorithmic component. The expert merging process is a simple weight average, not an optimisation procedure. The work is not evaluated on any insurance related benchmark. The notion of hidden pattern learning remains unexplained and unquantified. \n\nAs a result, the paper reads more as an internal technical report or applied project rather than a research contribution suited for ICLR.\n\n1. Lack of clear technical innovation or theoretical grounding. \n2. Hidden pattern learning is undefined and lacks evidence. \n3. Missing comparisons to relevant methods such as ZipLoRA and LLAVA MoLE. \n4. Weak connection to the insurance domain with no downstream testing. \n5. Evaluation is limited to visual similarity, not functional performance. \n6. Dependence on SDXL for generation may overstate improvements. \n7. Incomplete figures and missing prompts in qualitative results."}, "questions": {"value": "1. Define hidden pattern learning in operational terms. \n2. Include experimental comparisons with ZipLoRA, LoRA composition, and LLAVA MoLE.\n3. Demonstrate that HERS creates new generative capacity rather than reproducing SDXL results. \n4. Add prompts alongside all qualitative results for reproducibility. \n5. Include evaluation on a real insurance task to justify domain relevance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No immediate ethical violations detected, though potential misuse for fabricating vehicle damage images should be discussed in more detail. Responsible use and watermarking strategies should be outlined more clearly."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Yrpp77yIM5", "forum": "mEHBHxHnLO", "replyto": "mEHBHxHnLO", "signatures": ["ICLR.cc/2026/Conference/Submission18319/Reviewer_6iNB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18319/Reviewer_6iNB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930105532, "cdate": 1761930105532, "tmdate": 1762928035178, "mdate": 1762928035178, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HERS, a self-supervised framework designed to adapt text-to-image diffusion models for the specialized task of generating realistic vehicle damage. The authors highlight the dual-use nature of such technology in the auto insurance industry: it can be used beneficially for data augmentation and training rare-event models, but also maliciously for creating fraudulent claims. The HERS framework operates in four automated stages: Prompt Synthesis, Image Generation, Expert Learning and Expert Merging. The authors evaluate HERS against several strong baselines (including SDXL, MoLE, and SELMA) on a large, private benchmark from the car insurance domain. The results, measured by automatic text-faithfulness metrics and human preference scores, demonstrate that HERS consistently produces images with higher visual fidelity, better semantic alignment, and more convincing fine-grained details (e.g., scratches, dents, cracked paint) than existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a highly relevant and practical problem. The authors do an excellent job of framing the problem, clearly articulating both the opportunities (e.g., data augmentation for rare events) and the significant risks (e.g., sophisticated fraud), which motivates the need for more controllable and semantically-aware generation.\n2. The proposed HERS framework is clever and pragmatic. By leveraging existing powerful models (LLMs and T2I backbones), it creates a fully automated, self-supervised pipeline. This circumvents the need for expensive and time-consuming manual data collection and annotation, which is a major bottleneck for domain-specific adaptation. The idea of training specialized experts and merging them is an intuitive and effective approach to balancing specialization and generalization.\n3. The paper is well-written, clearly structured, and easy to follow. The method is described systematically, and the results are presented effectively."}, "weaknesses": {"value": "1. The primary weakness of this paper is its reliance on a large-scale private benchmark collected \"in collaboration with an industry insurance startup.\" While the authors promise to release prompt templates, the inability of the research community to access the evaluation data makes direct replication and verification of the reported results impossible. This is a significant issue for a paper submitted to a top-tier conference, where reproducibility is paramount.\n2. While the overall application and framework are novel, the individual technical components are well-established. Using LLMs for prompt engineering, fine-tuning with LoRA, and merging models with weight averaging are all existing techniques. The paper's main contribution lies in the specific combination and application of these techniques. The technical depth could be improved by exploring more advanced merging techniques beyond simple arithmetic averaging and analyzing why this specific pipeline is so effective."}, "questions": {"value": "Thank you for the insightful paper. My question concerns a fundamental aspect of the HERS framework: the use of synthetically generated images as training data to fine-tune the very same class of models.\nThe methodology involves a two-step generation process: first, a base T2I model generates a large dataset of images from LLM-crafted prompts; second, this synthetic dataset is used to fine-tune specialist LoRA modules, which are then merged to create a superior model.\nCould you elaborate on why this self-improvement loop is effective? Specifically:\n1. Intuitively, using a model to generate its own training data risks merely amplifying its existing biases and failure modes. For instance, if the base model struggles to render realistic scratches, the initial synthetic dataset would contain flawed examples. How does the \"Expert Learning\" stage manage to distill genuine, high-fidelity patterns from this potentially imperfect data, rather than simply learning to replicate the base model's own artifacts and limitations?\n2. Is the success of this process primarily driven by the sheer volume and semantic diversity of the LLM-generated prompts? Does the structured curriculum (Typical Parts, Scene Narratives, Implausible Scenarios) force the model to explore and refine specific regions of its latent space that would otherwise be ignored, thereby \"unlocking\" capabilities that were already present but not easily accessible?\n3. Could it be that training on synthetic data, even if imperfect, acts as a form of implicit regularization? Perhaps forcing the model to align with a vast number of diverse (but algorithmically consistent) image-text pairs encourages it to learn a more robust and generalizable representation of \"damage\" than fine-tuning on a small, noisy, and potentially narrow set of real-world images would allow?\n\nIn essence, what is the theoretical or empirical justification for why a model, when trained on its own outputs guided by structured text, can transcend its initial capabilities and learn to generate details (the \"hidden patterns\") that were not explicitly or perfectly rendered in its initial training data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xC9J3sQOEx", "forum": "mEHBHxHnLO", "replyto": "mEHBHxHnLO", "signatures": ["ICLR.cc/2026/Conference/Submission18319/Reviewer_qBar"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18319/Reviewer_qBar"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972460804, "cdate": 1761972460804, "tmdate": 1762928034721, "mdate": 1762928034721, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}