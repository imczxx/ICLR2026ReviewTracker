{"id": "u0UjdCMPLc", "number": 21019, "cdate": 1758312875987, "mdate": 1759896946714, "content": {"title": "Intrinsic Explanation of Random Subspace Method for Enhanced Security Applications", "abstract": "Random subspace method has wide security applications such as providing certified defenses against adversarial and backdoor attacks, and building robustly aligned LLM against jailbreaking attacks. However, the explanation of random subspace methods lacks sufficient exploration. Existing state-of-the-art feature attribution methods, such as Shapley value and LIME are computationally impractical and lack robustness guarantees when applied to random subspace methods. In this work, we propose EnsembleSHAP, an intrinsically faithful and robust feature attribution for random subspace methods that reuses its computational byproducts. Specifically, our feature attribution method is 1) computationally efficient, 2) maintains essential properties of effective feature attribution (such as local accuracy), and 3) offers guaranteed robustness against attacks on feature attribution methods. To the best of our knowledge, this is the first work to establish provable robustness against explanation-preserving attacks. We also perform comprehensive evaluations for our explanation’s effectiveness when faced with different empirical attacks, including backdoor attacks, adversarial attacks, and jailbreak attacks.", "tldr": "A faithful and certifiably robust feature attribution method for random subspace methods", "keywords": ["Feature attribution", "Certified Robustness", "Jailbreak Attack"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fbc77e4b52fdc06c7dc63b62ec57f07f956a074e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies explanations for models built with the random subspace method. It proposes an attribution method that reuses random subspace method inference byproducts to produce importance and develops a certified lower bound for detecting explanation-preserving attacks. Experiments focus mainly on text classification and LLM jailbreak detection across different metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well organized and easy to follow.\n2. The certified lower bound for detecting explanation-preserving attacks provides a certified guarantee that links attribution to robustness.\n3. It studies attribution under adversarial, backdoor, and jailbreak settings, which is a novel perspective."}, "weaknesses": {"value": "1. The proposed method is proposed for only random subspace methods, which limits its generalizability to other ensemble methods or broader applications.\n\n2. The experiments emphasize a small set of attribution methods (e.g., Shapley/LIME/ICL). It is suggested to include more diverse families, e.g., propagation-based methods (LRP/DeepLIFT) or gradient-based variants (IG + smoothing), to strengthen the empirical case and reduce experiment bias.\n\n3. Section 5.2.3 shows hyperparameter sensitivity. The analysis mainly compares with Shapley. More attribution baselines and detailed analysis would strengthen this study."}, "questions": {"value": "1. Can the method work beyond RSM?\n2. How does your method compare to other attribution families?\n3. What causes the hyperparameter sensitivity, and how can it be mitigated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CpbiBKD3lZ", "forum": "u0UjdCMPLc", "replyto": "u0UjdCMPLc", "signatures": ["ICLR.cc/2026/Conference/Submission21019/Reviewer_wd8j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21019/Reviewer_wd8j"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761698192563, "cdate": 1761698192563, "tmdate": 1762940602649, "mdate": 1762940602649, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes an enhancement for arbitrary partition-based certified defenses that (1) provides explanability and (2) is in itself certifiably robust.\n\nFor context, partition-based defenses, here referred to as \"random subspace methods\", are a commonly used flavor of randomized smoothing that performs self-ensembling over (random) subsets of features or training samples. If the number of subsets that a single element can appear in is bounded, then it can only have limited influence on the ensemble prediction. This allows for the derivation of robustness certificates.\n\nThe authors propose a method for computing per-feature importance scores given the ensemble model's prediction.\nThey then show that this method has three desirable properties:\n* The importance scores can be computed from the same feature subsets that are already used for making smoothed predictions. Thus, the computational overhead is small.\n* The importance scores inherit desirable properties of Shapley values, which are a powerful (but in this setting intractable) feature attribution method\n* Using the standard argument for partition-based defenses, the method is in itself certifiably robust. Specifically, if an adversarial attack on the ensemble model is successful, then many of the modified features will be assigned a high importance score.\n\nIn the experiments, the method is first empirically evaluated based on its ability to provide useful (as measured by \"faithfulness\") explanations under adversarial attacks on standard classification datasets, as well as an LLM jailbreaking benchmark. Afterwards, the certificates are evaluated in terms of certified detection rate (essentially certified ratio for explanations)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The proposed method is very broadly applicable, with partition-based defenses being a standard approach to certified robustness at both training time (poisoning attacks) and inference time (sparse attacks on images, graphs, point clouds etc.)\n* The approach is incredibly elegant, achieving multiple goals via relatively straight-forward procedure (see desirable properties above)\n* Section 4.3 provides provable utility guarantees in addition to provable robustness guarantees. This is somewhat unusual for randomized smoothing papers and definitely a positive\n* The chosen range of datasets and models appears adequate for a paper that is primarily focused on provable robustness\n* Provably robust explanation is mostly underexplored, i.e., novelty appears high"}, "weaknesses": {"value": "The work is primarily held back by its presentation. In particular:\n* There are various typos and grammatical errors (tense, conjugation, duplicate words like \"is a is a\" in l.075 etc.). The manuscript could be significantly improved by running it through grammarly, the Copilot grammar checker, or a similar tool\n* The main theorem is somewhat awkwardly forwarded (see Eq. 12-16) and incredibly dense. If the theorem itself cannot be further simpliified, I would encourage the authors to at least expand its intuitive explanation in l. 332ff.\n* There are no explanatory figures. Adding one or two could help readers not familiar with randomized smoothing to more easily follow the paper.\n\nOther than that, I only see two issues with the experimental evaluation:\n* When varying parameters of the explanation method (see, e.g., Fig. 16), only the effect on certified detection rate is shown. However, it is not clear how varying these parameters impacts model utility. It would be better to additionally visualize the trade-off between utility and provable robustness (similar to certified accuracy in classification).\n* Assuming the authors do, in fact, only want to show certificate strength: Constraining the experiments to a specific dataset and model as in Fig. 1 leads to a reductive view on the certification procedure (it fixes the dataset size and the model's confidence etc. to a particular value). It would be more informative to just treat these as additional parameters to vary (as is already done with $\\beta$, $\\rho$, $N$, etc.). Varying these additional parameters could be a nice experiment for the camera-ready version.\n\n### Summary\nOverall, this work makes a novel, elegant, and broadly applicable contribution to the field of provably robust machine learning There is \n minor room for improvement in the experimental evaluation.\nAssuming that the authors will improve the presentation for the camera-ready version (at least fixing most of the grammatical errors and typos), I recommend acceptance."}, "questions": {"value": "### Other suggestions:\n\nThe following paper appeared ca. three months before the submission deadline. I would encourage the authors to discuss it as concurrent work:\n\nAnani et al.. Pixel-level Certified Explanations via Randomized Smoothing. ICML 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pCM5vtOdpX", "forum": "u0UjdCMPLc", "replyto": "u0UjdCMPLc", "signatures": ["ICLR.cc/2026/Conference/Submission21019/Reviewer_DnnL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21019/Reviewer_DnnL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854648840, "cdate": 1761854648840, "tmdate": 1762940601770, "mdate": 1762940601770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes EnsembleSHAP, an explanation method for Random Subspace Method ensembles that is efficient and certifiable. During the inference of an ensemble method, EnsembleSHAP uses the model’s prediction to assign credit to features, then derives a certified detection lower bound of explanation-preserving attacks that modify at most T features. Experiments show that EnsembleSHAP achieves higher faithfulness with small overhead."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe method suits well with RSM since it explains the ensemble by reusing its votes, so it is efficient and well-motivated.\n2.\tThe method is model agnostic since it only requires votes and some ablations, making it easy to adapt.\n3.\tVarious types of attacks are evaluated such as jailbreaking, token edits, trigger based."}, "weaknesses": {"value": "1.\tThe certification is limited to at most T feature perturbations, which may be limited since many real-life attacks can modify an arbitrary number of features (e.g., sinusoidal signal poisoning).\n2.\tThe tools used in theoretical analysis are fairly elementary, such as frequency counting, confidence intervals, and binary search, so the novelty of the theorems and proofs appears limited.\n3.\tThe threat model is limited for explanation-preserving attacks only, which is overly restrictive: in practice, many attackers will at least partially disrupt the explanation (e.g., by shifting saliency), so this limited certification guarantee seems limited to real-world scenarios."}, "questions": {"value": "1.\tThis method assumes equal contribution among a subset of features. What is the rationale behind this choice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9wvC61Kkxf", "forum": "u0UjdCMPLc", "replyto": "u0UjdCMPLc", "signatures": ["ICLR.cc/2026/Conference/Submission21019/Reviewer_QMf6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21019/Reviewer_QMf6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762014628392, "cdate": 1762014628392, "tmdate": 1762940596777, "mdate": 1762940596777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}