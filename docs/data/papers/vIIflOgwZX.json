{"id": "vIIflOgwZX", "number": 11432, "cdate": 1758198832156, "mdate": 1759897575914, "content": {"title": "GeometryZero: Advancing LLM Geometry Solving via Group Contrastive Policy Optimization", "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities across diverse domains, particularly in mathematical reasoning, amid which geometry problem solving remains a challenging area where auxiliary construction plays a enssential role. Existing approaches either achieve suboptimal performance or rely on colossal LLMs (e.g., GPT-4o), incurring massive computational costs.\nWe posit that reinforcement learning with verifiable reward (e.g., GRPO) offers a promising direction for training smaller models that effectively combine auxiliary construction with robust geometric reasoning. However, directly applying GRPO to geometric reasoning presents fundamental limitations due to its dependence on unconditional rewards, which leads to indiscriminate and counterproductive auxiliary constructions.\nTo address these challenges, we propose Group Contrastive Policy Optimization (**GCPO**), a novel reinforcement learning framework featuring two key innovations: (1) *Group Contrastive Masking*, which adaptively provides positive or negative reward signals for auxiliary construction based on contextual utility, and a (2) *Length Reward* that promotes longer reasoning chains. Building on GCPO, we develop GeometryZero, a family of affordable-size geometric reasoning models that judiciously determine when to employ auxiliary construction. \nOur extensive empirical evaluation across popular geometric benchmarks (w.r.t. Geometry3K and MathVista) demonstrates that GeometryZero models consistently outperform RL baselines (e.g. GRPO, ToRL) across various benchmarks.", "tldr": "", "keywords": ["Geometry", "Reinforcement Learning", "Large Language Model"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5a4527c3c7357e195eed9ee424468e6fdfb1d1ec.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Group Contrastive Policy Optimization (GCPO), a reinforcement learning framework designed to improve geometric problem solving by selectively encouraging auxiliary line construction. GCPO differs from prior methods by applying conditional rewards based on the effectiveness of auxiliary constructions, using a group contrastive masking mechanism. It also adds a length reward to support longer, multi-step reasoning processes. Built on GCPO, the authors train GeometryZero, a set of small-scale models that achieve improved accuracy without relying on large-scale LLMs. The approach is evaluated on several benchmarks, showing consistent gains over existing RL baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper tackles the often-overlooked question of whether to use auxiliary lines, not just how, by introducing a contrastive reward mechanism that encourages or discourages use based on actual benefit.\n\n2. The authors run clear ablations across model sizes, showing how each component (auxiliary reward, masking, length reward) impacts performance. And they provide useful insights into training dynamics, like how response length and masking evolve."}, "weaknesses": {"value": "1. The optimization goal is overly narrow. The method focuses only on auxiliary line construction, which is just one of many challenges in geometric reasoning; other strategies such as setting up coordinate systems or using reverse reasoning are not discussed.\n\n2. The reward estimation is inefficient and potentially inaccurate. Using the accuracy gap between two rollout groups to decide whether to apply auxiliary lines is both costly and noisy; it would be more reliable to pre-annotate which problems benefit from auxiliary constructions or design a list-wise reward based on multiple rollouts.\n\n3. The methodological novelty is limited. The work mainly introduces reward engineering on top of GRPO rather than proposing a new algorithm.\n\n4. The experiments are not fully convincing. The models are only trained on the Qwen2.5 family, and the chosen baselines such as GNS-LLaVA are outdated; the paper lacks comparison with newer geometry-specific or multimodal reasoning models.\n\n5. The experimental analysis is insufficient. Although the model improves on out-of-domain benchmarks like MathVista and OlympiadBench, there is no detailed analysis explaining which kinds of problems contributed to these gains.\n\n6. The study only covers text-based geometry problems. It remains unclear how the proposed method would perform with real visual inputs or under multimodal settings."}, "questions": {"value": "1. On the OOD benchmarks MathVista and OlympiadBench, which types of problems show the largest improvement? The paper only presents in-domain case studies but lacks OOD examples.\n\n2. How does GCPO perform compared to stronger multimodal SOTA models such as GPT‑4V or Gemini? Can the method be transferred to such visual‑language models?\n\n3. Since the training data come only from Geometry3k and Geomverse (~3.4k samples), will GCPO’s advantage still hold on larger or more diverse datasets? Are there plans to test its generalization further?\n\n4. Is auxiliary line construction truly the core difficulty in geometric reasoning? Has there been any analysis of other potential reasoning bottlenecks in geometry problem solving?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "IWETA729mJ", "forum": "vIIflOgwZX", "replyto": "vIIflOgwZX", "signatures": ["ICLR.cc/2026/Conference/Submission11432/Reviewer_LeaT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11432/Reviewer_LeaT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760614756156, "cdate": 1760614756156, "tmdate": 1762922546927, "mdate": 1762922546927, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Group Contrastive Policy Optimization (GCPO), a new reinforcement learning algorithm designed to improve LLM-based geometric problem solving, especially by enabling judicious use of auxiliary constructions (such as drawing extra geometric lines) in reasoning. GCPO introduces a group contrastive masking mechanism providing context-sensitive rewards (encouragement or penalty) for auxiliary construction, and augments this with a length reward to promote deeper reasoning. Building on GCPO, the authors present GeometryZero, a family of lightweight models that surpass standard RL (GRPO, ToRL) and SFT baselines across multiple geometry benchmarks, as validated by extensive experiments (Geometry3K, Geomverse, MathVista, and OlympiadBench) and ablation studies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Motivated, Well-Positioned Task: The focus on geometry problem-solving with LLMs is timely and important, given the unique challenges of integrating formal diagram understanding and reasoning.\n\n2. Methodological Innovation: GCPO’s group contrastive masking is a significant step forward in RL for tool-augmented reasoning, dynamically providing positive/negative reward signals depending on the utility of auxiliary constructions. This is a tangible conceptual and algorithmic advance beyond unconditional reward methods like ToRL.\n\n3. Accessible and Well-Documented: Implementation details, dataset construction (Table 3), and training pipeline are presented in sufficient detail for reproduction; the appendix is extensive, supporting the main claims."}, "weaknesses": {"value": "1. Empirical Scope Limitation: All experiments are restricted to models under 7B parameters, whereas recent trends in geometric reasoning often report results for larger, near-state-of-the-art models. This limits claims for broader applicability; for instance, Table 1 lacks comparison to the largest scale public models (e.g., GPT-4o, Gemini), even if computational restrictions are real.\n\n2. Definitional Ambiguity in Conditional Masking: In Equation 4 and its surrounding narrative (Pages 5–6), the treatment of $\\epsilon$ is reasonable, but the masking decision relies on mean accuracy reward differentials; this could underplay per-instance variability or rare-case utility/harm of auxiliary construction (i.e., GCPO may still reinforce suboptimal construction in edge cases). More discussion or empirical analysis of these edge cases, perhaps via qualitative categorization, would help.\n\n3. Regarding Auxiliary Lines and Answer Length: Intuitively, the construction of auxiliary lines and increased answer length should contribute to solving more challenging geometry problems. Although experimental results indicate quantitative improvements on existing benchmarks, more concrete examples (such as visualizations) are necessary to convincingly demonstrate this enhancement for high-difficulty tasks.\n\n4. Regarding the Use of TikZ: The use of TikZ code for generating auxiliary lines requires further clarification. During reasoning, does the system construct a new image to perform interleaved visual and textual inference? Furthermore, TikZ might not be the optimal tool for drawing auxiliary lines, primarily due to potential precision issues."}, "questions": {"value": "please refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YDwhUfoXUg", "forum": "vIIflOgwZX", "replyto": "vIIflOgwZX", "signatures": ["ICLR.cc/2026/Conference/Submission11432/Reviewer_QdLU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11432/Reviewer_QdLU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980640893, "cdate": 1761980640893, "tmdate": 1762922546185, "mdate": 1762922546185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an RL framework for geometric reasoning, named GCPO (Group Contrastive Policy Optimization). Specifically, it builds upon the verifiable reward in GRPO by introducing a group contrastive masking mechanism that assigns positive, negative, or zero rewards to “auxiliary drawing” actions depending on whether they contribute to the final correctness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clarity of writing: The paper is well written and easy to follow, with a clear logical flow.\n\n2. Clarity of the proposed method: GCPO is conceptually straightforward and easy to implement while remaining effective.\n\n3. Comprehensive experimental evaluation: The experiments are extensive and demonstrate clear effectiveness."}, "weaknesses": {"value": "1. Limited OOD evaluation: The OOD datasets contain only a small number of samples, which makes it difficult to convincingly demonstrate the generalization ability of the proposed method beyond the training distribution.\n\n2. Lack of critical ablation studies: Some key hyperparameters and design factors are not systematically analyzed, such as the KL coefficient, sampling temperature/decoding strategy, and the quantitative relationship between positive/negative masking ratios and performance."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "DNpy6k7TLT", "forum": "vIIflOgwZX", "replyto": "vIIflOgwZX", "signatures": ["ICLR.cc/2026/Conference/Submission11432/Reviewer_ewCt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11432/Reviewer_ewCt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999594664, "cdate": 1761999594664, "tmdate": 1762922545203, "mdate": 1762922545203, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce Group Contrastive Policy Optimization (GCPO) as a novel\nreinforcement learning mechanism for LLMs to improve geometric reasoning. The\nmethod includes a auxiliary reward, group contrastive masking and a length\nreward. Experimental results show that GCPO outperforms GRPO and ToRL models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "S1: GCPO outperforms the existing GRPO and ToRL reinforcement learning frame-\nworks.\n\nS2: GCPO can be applied to relatively small models (e.g., 1.5GB, 3GB and 7GB).\n\nS3: The ablation study and discussion in the paper is interesting."}, "weaknesses": {"value": "W1: The proposed modifications to GRPO are inspired by other, existing \ntechniques and thus the novelty is somewhat limited. For example, the length\nreward was introduced earlier."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z4QDJZhhd9", "forum": "vIIflOgwZX", "replyto": "vIIflOgwZX", "signatures": ["ICLR.cc/2026/Conference/Submission11432/Reviewer_aY5U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11432/Reviewer_aY5U"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762081144774, "cdate": 1762081144774, "tmdate": 1762922544522, "mdate": 1762922544522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}