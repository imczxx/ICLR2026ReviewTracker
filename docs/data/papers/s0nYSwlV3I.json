{"id": "s0nYSwlV3I", "number": 19630, "cdate": 1758297830734, "mdate": 1759897029404, "content": {"title": "Influence without Confounding: Causal Discovery from Temporal Data with Long-term Carry-over Effects", "abstract": "Learning causal structures from temporal data is fundamental to many practical tasks, such as physical laws discovery and root causes localization.\n   Real-world systems often exhibit long-term carry-over effects, where the value of a variable at the current time can be influenced by distant past values of other variables. These effects, due to their large temporal span, are challenging to observe or model. Existing methods typically consider finite lag orders, which may lead to confounding from early historical data. Moreover, incorporating historical information often results in computational scalability issues. \n   In this paper, we establish a theoretical framework for causal discovery in complex temporal scenarios where observational data exhibit long-term carry-over effect, and propose LEVER, a theoretically guaranteed novel causal discovery method for incomplete temporal data. Specifically, based on the \\textit{Limited-history Causal Identifiability Theorem}, we refine the variable values at each time step with data at a few preceding steps to mitigate long-term historical influences. Furthermore, we establish a theoretical connection between QR decomposition and causal discovery, and design an efficient reinforcement learning process to determine the optimal variable ordering. Finally, we recover the causal structure from the R matrix.\n   We evaluate LEVER on both synthetic and real-world datasets. In static cases, LEVER reduces SHD by 17.29\\%-40.00\\% and improves the F1-score by 5.30\\%-8.79\\% compared to the best baseline. In temporal cases, it achieves a 64\\% reduction in SHD and a 45\\% improvement in F1-score. Additionally, LEVER demonstrates significantly higher precision on real-world data compared to baseline methods.", "tldr": "", "keywords": ["Causal Discovery", "Reinforcement Learning", "QR Decomposition", "Long-term Carry-over Effects"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3a1a2d378abc2dc1fd0fd53bd146a54ffae7b8a1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of causal discovery in time series systems that exhibit long-term carry-over effects, where past influences persist far beyond a limited time lag and can create historical confounding. The authors show that instead of modeling the entire history, it is sufficient to regress out only a small recent window of past observations to obtain refined residual signals that preserve causal identifiability. Building on this result, they propose LEVER, a causal discovery algorithm that uses QR decomposition to represent variable relationships and employs reinforcement learning to efficiently search for the optimal causal ordering. Once the order is determined, causal edges are estimated and pruned to recover the final causal graph. Experiments on both synthetic and real-world datasets demonstrate that LEVER outperforms existing methods in accuracy and efficiency, particularly in scenarios with long-term temporal dependencies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Addresses an important problem, long-term historical confounding, which is not adequately addressed in existing temporal causal discovery methods.\n2. Instead of requiring full historical data (which is often unavailable, expensive, or noisy), the method works only with a small recent window, which is practically useful.\n3. The method can work in both static and temporal settings.\n4. The motivation and algorithmic pipeline are clearly explained."}, "weaknesses": {"value": "1. The method has been evaluated only on one real-world dataset. Broader validation would strengthen claims of general applicability.\n2. The method assumes the relationships between variables are linear and time-invariant. But in many real-world systems, relationships are often nonlinear.\n3. The method requires choosing the window size, yet no automatic way to select it is given."}, "questions": {"value": "1. How should practitioners choose the window size w in settings where the decay pattern of historical effects is unknown?\n2. Can LEVER be extended to handle nonlinear causal relationships?\n3. How does LEVER perform when some variables have very weak or delayed effects that only appear far beyond the chosen history window?\n4. Is the learned causal ordering stable under subsampling?\n5. Could LEVER be combined with domain knowledge, and how would that be incorporated into the RL reward or state representation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DEioWWqhpR", "forum": "s0nYSwlV3I", "replyto": "s0nYSwlV3I", "signatures": ["ICLR.cc/2026/Conference/Submission19630/Reviewer_EqNz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19630/Reviewer_EqNz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971431920, "cdate": 1761971431920, "tmdate": 1762931481781, "mdate": 1762931481781, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of causal discovery from time-series data. Specifically, this authors address the case when the system may exhibit long-term carry-over effects, i.e., $X[t]$ may depend on $X[t-h]$ for large or even infinite $h$. Most existing methods assume that the lag order is finite; hence, applying these methods to the considered setting may lead to spurious edges in the recovered causal graph. The authors first show that, for static data (i.e., when only instantaneous causal effects exist), the correct causal ordering can be identified by performing QR decomposition on the observed data. Furthermore, for temporal data, they show that by assuming that the infinite effect function can be summarized by a linear combination of finite effects, the correct causal ordering can be recovered by first regressing $X[t]$ on limited-history data $(X[t-1],\\cdots, X[t-h])$ and then applying the method for static data to the residuals. The authors develop an identification algorithm based on the theoretical results and evaluate its performance on both synthetic and real datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear explanation of all theoretical results, along with motivating examples and detailed proofs.\n2. The overall presentation is clear and easy to follow.\n3. The authors conduct extensive simulations to demonstrate the performance of the proposed algorithm."}, "weaknesses": {"value": "The main weakness is that the considered setting substantially overlaps with existing work on causal structure learning. In the case with static data, the problem reduces to causal discovery in linear SCMs with i.i.d. noise distributions. It has already been shown that the model is uniquely identifiable under either Gaussian or non-Gaussian noise distributions, and many existing algorithms can be applied to this setting for causal structure learning. In the case of temporal data, the authors show that, under Assumptions 1, 2 and 3, there exists an $h$ such that the residuals can be written in the form of a linear SCM with equal noise variances (line 901). Further, in the proposed algorithm, it seems that the RL component could also be replaced by existing algorithms (see Q4 below)."}, "questions": {"value": "1. Should Equation (1) be $g(\\tau) X[t-\\tau]$, since $g(\\tau)$ is a $d\\times d$ matrix?\n2. In the case of static data, is there a reason why the proposed method outperforms existing approaches (e.g., NOTEARS), especially in the simulation results? My understanding is that the considered problems are essentially the same.\n3.  In Section 4.1, does the optimal selection of $w$ always correspond to the $h$ in Assumption 3? If not, I am not sure whether the results in Theorem 6 can be directly applied to the residual $\\dot{\\mathbf{x}}$ in Equation (7).\n4. Can the DQN framework (i.e., steps 2 and 3 in Figure 2) be replaced by existing causal structure learning algorithms?\n5. Is the existence of time-dependent effects (i.e., whether the data are static or temporal) provided as an input under the different settings in the simulation results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c0Dm01wJ8f", "forum": "s0nYSwlV3I", "replyto": "s0nYSwlV3I", "signatures": ["ICLR.cc/2026/Conference/Submission19630/Reviewer_Kj1Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19630/Reviewer_Kj1Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977059394, "cdate": 1761977059394, "tmdate": 1762931481176, "mdate": 1762931481176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduce a method called \"LEVER\", which uses a (QR-decomposition)-based, \"static\" score and RL to infer a complete topological (causal) order; based on i.i.d. samples from time series. The theory part mainly aims at \"static skeleton recovery\", assuming i.i.d. samples, and then consider \"historical refinement\" via regression of variables on their past values. The baselines of the empirical experiment consider \"static discovery methods\" and embed them into the LEVER framework (of Figure 2), and a couple of temporal baselines (not a comprehensive list, missing main recent ones). \n\nOverall: The only \"temporal\" modeling of the theory part comes in the historical refinement framework, unlike other recent studies, e.g., [Mastakouri, Schölkopf, Janzing ICML 21]; [Sun,Schulte,Guiliang,Pascal,Poupart AISTATs 23]; [Liu, Sun, Hu, Wang, NeurIPS23]; and [Stein,Shadaydeh,Blunk,Penzel,Denzler ICLR 25]. Also, temporal baselines are limited. I see the contribution is more limited to static skeleton discovery, unlike what the current presentation of the paper suggests. Please see more details in the Weaknesses section."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The QR-based score function for static skelton learning, as formalized and used in LEVER, and supported by theory in Sections 3.1-3.3, is novel, up to the best of my knowledge."}, "weaknesses": {"value": "===The theory part===\n\n- Abstract & intro give the impression that the proposed method solves for a \"full\" causal discovery problem, including recovering directions; but objective, theory, and experiments sections mainly solve for \"causal skeleton (adjacency matrix)  recovery\"; while rely on limited connections between the two.  Lemma 1 discusses a bijection between the sets of \"exact\" topological orders & \"complete\" DAGs, i.e., those with all edges directed consistently with a given full ordering. This follows from classic results in graph theory but it does not certainly address the complexity of the \"full\" causal discovery problem, where DAGs could be still recovered based on partial topological orders. Theorems 3&4 determine edge coefficients based on the same assumptions. \n\n- Sec 3.1-3.3 do not seem to model for time-series data including the proposed score. Sections 3.2 & 3.3 explicitly assume i.i.d. samples as stated in the 2nd para of Sec 3.2 ``Formally, let $Y \\in R^{m\\times  d}$ consists of $m (m > d)$ $\\textbf{i.i.d.}$ observations of $d$ random variables''. This assumption is clear in Thm 1 for \"Full column rank\" of data matrix $Y$, the proposed score in Eq (3), and Thms 3&4.  While such an assumption is common for \"static\" causal discovery, it shouldn't be assumed when modeling \"temporal\" dependence.  Sec 3.4 then introduce historical confounding by regressing $X[t]$ on its complete history $\\{X[t−\\tau]\\}_{\\tau \\geq 1}$ and taking the residuals. This is the only place where temporal modeling is assumed. \n\n- There is no explicit relation between \"the theory proposed by authors\" and \"existing work on the same topic\" is provided. Existing work, which provide more rigorous temporal modeling in their theory include: [Mastakouri, Schölkopf, Janzing ICML 21];[Sun,Schulte,Guiliang,Pascal,Poupart AISTATs 23]; [Liu, Sun, Hu, Wang, NeurIPS23]; [Stein,Shadaydeh,Blunk,Penzel,Denzler ICLR 2025]. Only [Sun,Schulte,Guiliang,Pascal,Poupart AISTATs2023] & [Liu, Sun, Hu, Wang, NeurIPS23] are cited in this submission, the other two are not. \n\n=== Experiments === The only temporal baseline considered is [Sun,Schulte,Guiliang,Pascal,Poupart AISTATs2023]."}, "questions": {"value": "I don't think reference [Liu et al., NeurIPS 2023] assumes either \"time-invariant skeleton\" nor \"stationary lag-dependency\" as claimed by authors below Assumptions 1 & 2, no?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0X1JVEepmz", "forum": "s0nYSwlV3I", "replyto": "s0nYSwlV3I", "signatures": ["ICLR.cc/2026/Conference/Submission19630/Reviewer_1PFq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19630/Reviewer_1PFq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154987222, "cdate": 1762154987222, "tmdate": 1762931480620, "mdate": 1762931480620, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies causal-structure recovery from time series with long-term carry-over effects. It (1) proves that a score based on OLS/QR identifies the true topological order in the static case, (2) shows that regressing out a limited recent history suffices under a linear-recurrence assumption to remove historical confounding, (3) uses the R matrix from QR as an RL-friendly compact state and trains a DQN to recover a topological ordering, and (4) recovers edges from the optimal R and prunes small weights. Theory, algorithm, and strong empirical gains on synthetic and a wind-tunnel dataset are presented."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "• Clean, provable identifiability result linking QR diagonal terms and the order score. Theorems 1–4 give solid, interpretable mechanics for order scoring and weight recovery. \n\n• Practical mechanism to mitigate long-range confounding via residualization on limited history and a clear sufficient condition (linear recurrence) under which limited history suffices. The Limited-history Causal Identifiability theorem is useful. \n\n• Engineering innovation: using the R matrix as an RL state is simple, computationally efficient, and justified by the theory. This yields large runtime and memory savings versus prior RL encoders. \n\n• Strong empirical performance. The method outperforms several static and temporal baselines in F1 and SHD and shows large improvements in temporal scenarios. Results are reported on multiple synthetic regimes and a real dataset. \n\n• Reproducibility: code and dataset links and implementation details are noted in the appendix."}, "weaknesses": {"value": "1. The related-work section treats prior temporal methods as finite-lag. But there is a body of work that models dependencies without imposing a strict finite lag (rate-agnostic or effectively infinite-memory representations). The paper should explicitly compare and position itself relative to those methods (both conceptually and empirically when possible). Examples the authors did not cite (add and discuss): \n- Rate-Agnostic (Causal) Structure Learning — Sergey Plis et al. — 2015. \n- Generalized Rate-Agnostic Causal Estimation via Constraints (GRACE-C) — M. Abavisani et al. 2023\n- Consistency of Mechanistic Causal Discovery in Continuous Time (Neural ODEs) — A Bellot et al. 2022\n, plus other works that address causal structure under subsampling or continuous-time kernels. Including these clarifies novelty and assumptions. \n\n2. The Limited-history theorem depends on Assumption 3 (linear recurrence of g(τ)). The paper acknowledges this, but lacks an empirical sensitivity analysis showing how performance degrades when the linear-recurrence assumption is violated or only approximately holds. A stronger empirical section on robustness is needed.\n\n3. Figure 3 is hard to parse and compare to ground truth. The visualization layout, legends, and the mapping between recovered and true edges are not easy to read.\n\n4. The RL ordering module is novel here, but the paper would benefit from (a) an ablation that replaces RL ordering with a simple heuristic (e.g., greedy order by marginal variance or SCORE ordering) to quantify the RL contribution and (b) more baselines that explicitly handle long memory when available"}, "questions": {"value": "1. How sensitive is LEVER when Assumption 3 is only approximately true? Please include an experiment where g(τ) is not exactly linear-recurrent.\n\n2. The RL state uses the R matrix. How does numerical stability affect performance when columns are nearly collinear? Do you need column normalization or regularization in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CP1IWz9yAq", "forum": "s0nYSwlV3I", "replyto": "s0nYSwlV3I", "signatures": ["ICLR.cc/2026/Conference/Submission19630/Reviewer_eY1p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19630/Reviewer_eY1p"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762876450304, "cdate": 1762876450304, "tmdate": 1762931479749, "mdate": 1762931479749, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}