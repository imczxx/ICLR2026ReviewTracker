{"id": "gkTx4sPyAw", "number": 8248, "cdate": 1758076205501, "mdate": 1759897796369, "content": {"title": "Improving Tool Calling Accuracy for Large Language Models", "abstract": "We introduce a novel method for improving LLM tool calling accuracy. Our approach uses a template-based generation instead of existing schema-constrained generation. Experiments on different datasets and LLM models demonstrate that our method improves F1 scores for tool names and parameters on most tests.", "tldr": "", "keywords": ["large language models", "tool calling"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/94699447b0879efcf2f4ddeddcecc962a0c7f2c4.pdf", "supplementary_material": "/attachment/cbd3b889d4a685ecf932de6743df65626fc459a9.zip"}, "replies": [{"content": {"summary": {"value": "Considering that the paper is clearly incomplete, I believe it should be strongly rejected."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Provides limited empirical comparison across models and datasets."}, "weaknesses": {"value": "1. The paper is incomplete and lacks depth; it reads like an early-stage draft.\n2. The idea—replacing structured JSON with a natural-language template—is trivial and does not constitute a substantive research contribution."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Mm8cQQokoj", "forum": "gkTx4sPyAw", "replyto": "gkTx4sPyAw", "signatures": ["ICLR.cc/2026/Conference/Submission8248/Reviewer_RBtx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8248/Reviewer_RBtx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760964109888, "cdate": 1760964109888, "tmdate": 1762920191883, "mdate": 1762920191883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a template-based approach to tool calling for LLMs: instead of emitting JSON or another schema-constrained format, the model produces natural-language templates which are then parsed into structured calls. Experiments on API-Bank, ToolACE, and When2Call with several models suggest gains on many F1 metrics."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Schema brittleness is a real source of failure in function calling. Demonstrating fewer schema violations via NL templates is a useful angle."}, "weaknesses": {"value": "1. The core technique appears to be a prompt swap followed by regex parsing. There’s little discussion of design choices, alternative templating schemes, or robust parsing. Relative to the breadth of tooling literature, the contribution as framed feels incremental.\n---\n2. This paper’s writing quality is poor. It contains almost no discussion of related work, gives only a cursory treatment of the core method, devotes much of the main text to unstructured result listings with visible whitespace, and does not provide implementation details.\n---\n3.This paper asserts that templates align better with NL pretraining, but does not provide mechanistic or error-mode evidence beyond counts such as which violations decline."}, "questions": {"value": "API-Bank L3 or ToolACE multi-call dialogs stress plan quality. Do templates help with tool selection across turns, or only with single-shot formatting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nGaMg1TrOO", "forum": "gkTx4sPyAw", "replyto": "gkTx4sPyAw", "signatures": ["ICLR.cc/2026/Conference/Submission8248/Reviewer_H8Ad"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8248/Reviewer_H8Ad"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761150886843, "cdate": 1761150886843, "tmdate": 1762920191473, "mdate": 1762920191473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a template-based generation method to improve LLM tool-calling accuracy, replacing conventional schema-constrained outputs with natural language templates. The approach is evaluated across three datasets and four LLMs . Results show consistent F1 improvements for tool names/parameters in most tests. The method leverages LLMs' natural language alignment, reducing schema violations and enhancing contextual understanding. However, performance varies with model architecture."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "(1)Addresses a limitation of schema-constrained tool calling (misalignment with LLMs' natural language training).\n\n(2)Template-based generation is simple yet effective, offering a practical alternative to rigid schemas.\n\n(3)Tests diverse models and uses multiple datasets with varying complexity. Includes statistical significance testing."}, "weaknesses": {"value": "(1)The paper argues that template-based generation is superior to schema-constrained generation, based on the assumption that the template-based format is more closely aligned with natural language. However, these assumptions and views lack both in-depth theoretical analysis and rigorous experimental verification.\n\n(2)Calculating the Macro F1 score separately for the tool name and tool parameters in the experiment seems inappropriate, as incorrect names or incorrect parameters can lead to failure. Only correct names and parameters can lead to task success. Furthermore, the 0.9 threshold set for semantic similarity is arbitrary, and different embedding models can also affect this threshold.\n\n(3)The paper's logic and presentation lack rigorousness, and many principles, concepts, and terminology lack prior explanation and clarification. In some areas, the description is incomplete and unclear."}, "questions": {"value": "(1)Why is template-based generation better than schema-constrained generation? The paper concludes that \"Current LLMs are predominantly pretrained and fine-tuned for schema-constrained generation (e.g., JSON output).\"(line 383) Based on this, schema-constrained generation should be better.\n\n(2)What's the rationale for setting the semantic similarity threshold at 0.9?\n\n(3)Are there better metrics for measuring tool calling accuracy? The F1 score doesn't directly reflect the success or failure of tool calling.\n\n(4) (Table 2 and Table 3) Why does GPT5 perform comparable to or better than other models on the API-Bank L1 and When2Call datasets, regardless of whether it's a schema-constrained or template-based method, but perform worse than almost all other models on the API-Bank L2 and ToolAce datasets?\n\n(5)Why not compare with other tool calling studies? After all, simply relying on improvements to prompt format and style isn't necessarily an effective approach."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FNPBPmf1pU", "forum": "gkTx4sPyAw", "replyto": "gkTx4sPyAw", "signatures": ["ICLR.cc/2026/Conference/Submission8248/Reviewer_g2fS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8248/Reviewer_g2fS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761658723357, "cdate": 1761658723357, "tmdate": 1762920191038, "mdate": 1762920191038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to generate tool calls from models by using a natural language template rather than a json-like schema. It is shown to be better than using a json-like schema in some scenarios."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N/A."}, "weaknesses": {"value": "1. Lack of comparison with chat templates that models are trained in. LLMs nowadays are trained to use tools following a certain template (see https://huggingface.co/docs/transformers/main/en/chat_extras). This can either be achieved using chat templates for open source LLMs or using tool call APIs for closed LLMs (https://platform.openai.com/docs/guides/function-calling). Since models are trained this way, it is only fair to compare with them in this setting, instead of directly putting the tool schemas in the prompt.\n\n2. Lack of comparison with constrained decoding methods. Lots of the errors spotted by the authors such as schema violation, incorrect tool name, incorrect parameter name, can be avoided with constrained decoding, because it limits the vocabulary to only the valid tokens during a tool call. Constrained decoding/structured output has been implemented by major closed LLMs (https://platform.openai.com/docs/guides/structured-outputs) and open-source inference engines such as sglang (https://docs.sglang.ai/advanced_features/structured_outputs.html). Hence, a major part of the problem that this paper is solving no longer exists.\n\n3. Marginal improvements over the baseline. In Table 2 and Table 3, many scenarios show worse results for template-based tool calling than schema-based. I'm not sure if this method is only working for certain scenarios, as there is no motivation or justification behind its effectiveness."}, "questions": {"value": "see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QrYdFTIwIu", "forum": "gkTx4sPyAw", "replyto": "gkTx4sPyAw", "signatures": ["ICLR.cc/2026/Conference/Submission8248/Reviewer_6R8D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8248/Reviewer_6R8D"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012860332, "cdate": 1762012860332, "tmdate": 1762920190537, "mdate": 1762920190537, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}