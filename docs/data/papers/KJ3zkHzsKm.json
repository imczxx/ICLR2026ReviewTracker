{"id": "KJ3zkHzsKm", "number": 8806, "cdate": 1758098803706, "mdate": 1759897762878, "content": {"title": "Constrained Reinforcement Learning using Bender’s Decomposition and Exact Constraint Satisfaction", "abstract": "Recent advancements in reinforcement learning (RL) have expanded its applications beyond sequential decision-making to encompass non-sequential tasks, such as matrix decompositions, automatic generation of sorting networks, and combinatorial optimization. However, these tasks often require problem-specific algorithm designs to ensure the validity of the solution.\nTo address this limitation, we propose a universal framework that reformulates non-sequential tasks as constrained RL problems by learning to generate cutting planes, i.e., mathematical constraints that systematically refine the solution space. We ensure constraint satisfaction throughout the training process, enabling safe and efficient training even during deployment.\nWe show the efficacy of our framework on two complex optimization problems: a reward-maximizing stochastic job-shop scheduling problem and a nonlinear, nonconvex packing problem. Our method achieves near-globally optimal solutions while accelerating convergence by up to a factor of 800.", "tldr": "We propose a novel Constrained Reinforcement Learning technique that guarantees hard constraints are upheld by using an implicit parametrization based on Bender's decomposition.", "keywords": ["Reinforcement Learning", "Constrained Reinforcement Learning", "Optimization"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b4963b0b80a0ce923a637eef551466b8d2f16472.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method based on Bender's decomposition to solve constrained combinatorial optimization problems. As far as I can tell, given an initial feasible solution (which must be generated by an existing method), feasibility cuts are generated by something, I don't really know what, but whatever it is it is learned through RL. The approach (BOO) is tested on a non-linear optimization problem (there are literally no more details than this, other than that the A matrix is semidefinite) and some kind of scheduling problem (again, I cannot describe it because the authors do not even provide a name from the literature). A comparison is made versus the pointer network from Bello et al. (2016). \n\nTo summarize my views on this paper pre-response: the idea sounds great, the problem is important, but I have no idea what is going on in most of the rest of this paper."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The setting is one of great importance: we need RL methods that respect constraints to solve highly constrained MI(N)LPs. The literature currently offers essentially nothing that can solve these problems other than playing with penalization of violated constraints, which does not work well.\n2. The method proposed is theoretically sound, assuming the (w, b) pairs generated are valid. I suppose this is the case, but I really do not understand from this paper why it is the case.\n3. I find it hard to say much about the performance, but at least on the optimization problem on \"unknown instances\" the pointer network is outperformed."}, "weaknesses": {"value": "1. The primary issue with this paper is that I do not understand the method. I am well-versed in Benders decomposition and in reinforcement learning. Algorithm 1 is rather high level (with some minor issues, see below), but the main issue is this: where does (b, w) come from and why can we guarantee that this cut is valid? The point that we do not need to solve the Benders subproblem to optimality is well-taken, and I note, well-known in the OR literature. I am missing, however, is what then happens to generate this point. I hope the authors can somehow clear this up in the response.\n2. The experimental evaluation in this paper is rather unique, and not in a good way. The \"nonconvex constrained problem\" has practically no details provided, and what even are the constraints? The type of constraints matter, perhaps even more than the number of constraints. This whole section is so vague that I do not really know how to interpret it. I do not even know how the pointer network can be used to solve the problem given. But this leads to the next point...\n3. The pointer network used is very old. It is indeed the basis for future work, but beating the pointer network from Bello et al. is really not an accomplishment worthy of ICLR. \n4. The scheduling problem provided feels almost randomly pulled from the literature. Why should we care about this random problem? The formulation used is not even a good one -- the paper the authors cite (Ku & Beck) literally says in the abstract that there are better formulations. Then there is a dynamic/stochastic aspect that is added, but it is not clear to me exactly how it even works. Furthermore, I do not understand the experimental results on this problem (Table 2) at all. There is a wide literature on neural combinatorial optimization, please see any of these papers to see how to compare two algorithms to one another. I also note that further baselines are necessary.\n\nMinor notes:\n1. In the introduction, the authors write about infeasible dead-ends. The example given regarding a sparsely connected graph is not correct. For a TSP with no additional side constraints, a sparse graph will not lead to infeasibility unless the problem itself is infeasible. If we had, e.g., time windows, then infeasibility is possible. The principle is of course correct, the example just needs tweaking.\n2. On page 4, some of the y*'s have the asterisk not in the superscript.\n3. Algorithm 1 line \"add stochastic constraints\" this is the first time the paper talks about stochastic constraints.\n4. The paper uses quite a bit of space to vaguely describe the scheduling problem (page 6 and page 8) and might as well show the model rather than beating around the bush.\n5. Regarding the model in Appendix C, it should say \"Constraints\" or \"Inequalities\" not \"Equality\"\n6. Table 2: which MILP solver is being used here?\n7. The discussion on the top of page 9 about the stochastic planning problem: indeed no \"solver\" for this problem exists since it seems to be completely made up rather than taken from the literature, for which solvers will exist."}, "questions": {"value": "1. See question above regarding the generation of (b,w)\n2. Why is it interesting that you beat this old pointer network?\n3. Where are any other interesting baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "W5eUPTNLfU", "forum": "KJ3zkHzsKm", "replyto": "KJ3zkHzsKm", "signatures": ["ICLR.cc/2026/Conference/Submission8806/Reviewer_JvvW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8806/Reviewer_JvvW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755661454, "cdate": 1761755661454, "tmdate": 1762920576276, "mdate": 1762920576276, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Reinforcement Learning (RL) has been recently applied to non-sequential decision making tasks including matrix decompositions, algorithm discovery, and combinatorial optimization through the Constrained Reinforcement Learning (CRL) framework. Traditionally, CRLs are modeled using Constrained Markov Decision Process (CMDPs). However, CMDPs does not allow for hard constraints, as it enforces the constraints in expectation over trajectories instead of per trajectory. \n\nThe paper proposes to use the Bender’s Decomposition framework, which divides a problem into a master problem and a subproblem based on complicating variables. The subproblem can be used to propose optimality cuts, which identifies better solutions without affecting their feasibility. The paper then introduces Bender’s Oracle Optimization (BOO), which learns to generate Bender’s optimality cuts using RL without affecting feasibility. Experiments show that BOO achieves near optimal results in significantly shorter time than the classical solver SCIP."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Bender’s decomposition is a well established technique for iteratively solving a difficult integer programming problem, it is interesting to see how it can be used in combination with a machine learning approach.\n\nThe experiments show promising results as the proposed method converges much faster than the classical solver SCIP."}, "weaknesses": {"value": "The paper is difficult to follow, specifically, the connection from Constrained RL to Benders Decomposition is not very clear. AlphaTensor is used to motivate the method a lot in the introduction (line 92 states that the method can be used to reframe alphatensor). But the rest of the paper makes no reference to it. It would be useful to see how a reformulation can take place to make the connection clearer. \n\nThe paper refers to “design problems” without a clear definition. Specifically, the experimental results only compare to pointer networks and classical solvers, and claim that these are the only 2 ways of solving general design problems. A clearer definition would allow better support for the claim. It is also unclear how the nonconvex constrained problem and the scheduling problem represents design problems. \n\nThe paper describes the guaranteed satisfiability at every state as a major advantage of the framework. However, this guarantee comes from the fact that the state at each step comes from an exact classical optimizer since the actions of the proposed framework simply add optimality cuts to the master problem. Wouldn’t adding an exact classical optimizer and the exact feasibility constraints to other CMDP approaches also enable guaranteed satisfiability?"}, "questions": {"value": "The subproblem fixes the complicating variables in Benders Decomposition, and becomes much simpler to solve, as the paper points out. What are then the benefits to bypassing the solving step and approximating the cuts?\n\nDid the author test with classical solvers other than SCIP?\n\nBenders Decomposition utilizes the Dual of the Subproblem to add cuts while BOO learns to generate the cuts directly. Can the framework also utilize the dual?\n\nMisc:\n\nLine 214 equation has a small formatting error.\n\nTable 1 should specify what the bolded values are."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yNORSVDMpN", "forum": "KJ3zkHzsKm", "replyto": "KJ3zkHzsKm", "signatures": ["ICLR.cc/2026/Conference/Submission8806/Reviewer_xngN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8806/Reviewer_xngN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965672621, "cdate": 1761965672621, "tmdate": 1762920575463, "mdate": 1762920575463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Bender’s Oracle Optimization (BOO), a framework for constrained reinforcement learning with hard, per-instance feasibility guarantees. Instead of acting in a sequential action space that can reach dead ends, a GNN policy proposes linear cutting planes (w,b) that are added to a master optimization problem; a classical solver (e.g., SCIP/IPOPT) then re-solves while always remaining within the known constraint set C. This couples RL with Bender’s decomposition: the policy learns optimality cuts without solving the subproblem, while the solver enforces feasibility. A safety theorem (Theorem 1) shows that BOO never leaves C is nonempty. Two examples are shown in the experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Hard-constraint satisfaction is guaranteed by construction via the master problem and linear cuts (Theorem 1).\n1. Recasts non-sequential design/optimization tasks as constrained RL over known C, sidestepping CMDP “in-expectation” limitations\n1. Leverages mature MIP/MINLP solvers for feasibility while learning problem-specific optimality guidance\n1. Strong gains vs. pointer networks on nonconvex combinatorics and vs. MILP baseline under stochasticity; notable speedups vs. direct MINLP"}, "weaknesses": {"value": "1. BOO adds only linear inequality cuts; highly nonlinear subproblem structure may require many cuts or limit convergence quality. Unfortunately, this is not explored or tested via experiments. \n1. It relies on outside solvers. Practical performance hinges on solver quality and modeling effort; repeated solves per cut can be computationally heavy at larger scales. \n1. The paper does include meaningful baselines (pointer network, MINLP/MILP), but the heuristic coverage is limited—useful for a first look, yet not exhaustive for the target domains.\n1. Experiments are on one synthetic nonconvex problem and one scheduling setup; broader benchmarks (incl. stronger CRL baselines beyond pointer networks/MILP) and ablations (e.g., number of cuts K, policy features) would strengthen claims."}, "questions": {"value": "1. What's the training cost for the RL model (hours or hardware)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2GUhF2s9eY", "forum": "KJ3zkHzsKm", "replyto": "KJ3zkHzsKm", "signatures": ["ICLR.cc/2026/Conference/Submission8806/Reviewer_Jt8Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8806/Reviewer_Jt8Y"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979302263, "cdate": 1761979302263, "tmdate": 1762920574301, "mdate": 1762920574301, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Bender's Oracle Optimization (BOO), a framework that reformulates non-sequential optimization tasks as constrained reinforcement learning problems by learning to generate cutting planes that refine the solution space. The method ensures constraint satisfaction throughout training by delegating constraint handling to classical optimizers like SCIP, enabling safe learning during deployment. BOO demonstrates effectiveness on two complex problems: a nonlinear, nonconvex packing problem achieving near-globally optimal solutions up to 800× faster than traditional solvers, and a stochastic job-shop scheduling problem where it outperforms mixed-integer linear programming by learning to account for stochastic effects. The framework represents the first reinforcement learning approach that enforces arbitrary constraints during both training and inference while maintaining strict feasibility guarantees."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses a hard problem -- maintaining constraints in reinforcement learning both during training and inference\n2. Using Bender's decomposition is a novel idea that has not been explored before\n3. Clear evaluations against prior solutions and classical solutions in MILP. Proposed solution is faster and gets higher performance compared to state-of-the-art.\n4. Theoretical guarantee for safety"}, "weaknesses": {"value": "1. The language used can be simplified to be accessible to a wider audience\n2. Constraints are known beforehand, not true in realistic settings\n3. No convergence or optimality guarantee\n4. Learned policy is not explainable"}, "questions": {"value": "- I wonder what happens if you use approximate constraints, would the solution still converge to optimal?\n- Given that added constraints change the optimization landscape drastically, can you guarantee reaching the optimal solution theoretically? Is it possible that the policy never converges?\n- How do you determine the number of cuts? Is the solution sensitive to the choice?\n- How does your work differ from these works?\n[1] Huang, Zeren, et al. \"Learning to select cuts for efficient mixed-integer programming.\" Pattern Recognition 123 (2022): 108353.\n[2] Paulus, Max B., et al. \"Learning to cut by looking ahead: Cutting plane selection via imitation learning.\" International conference on machine learning. PMLR, 2022"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ZHyjjUBGRe", "forum": "KJ3zkHzsKm", "replyto": "KJ3zkHzsKm", "signatures": ["ICLR.cc/2026/Conference/Submission8806/Reviewer_PiVQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8806/Reviewer_PiVQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762227672415, "cdate": 1762227672415, "tmdate": 1762920573442, "mdate": 1762920573442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}