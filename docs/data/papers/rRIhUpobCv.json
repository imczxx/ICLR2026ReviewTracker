{"id": "rRIhUpobCv", "number": 16254, "cdate": 1758262376202, "mdate": 1759897251978, "content": {"title": "Rényi Sharpness: A Novel Sharpness that Strongly Correlates with Generalization", "abstract": "Sharpness (of the loss minima) is a common measure to investigate the generalization of neural networks. Intuitively speaking, the flatter the landscape near the minima is, the better generalization might be. Unfortunately, the correlation between many existing sharpness measures and the generalization is usually not strong, sometimes even weak. To close the gap between the intuition and the reality, we propose a novel sharpness measure, i.e., \\textit{Rényi sharpness}, which is defined as the negative Rényi entropy (a generalization of the classical Shannon entropy) of the loss Hessian. The main ideas are as follows: 1) we realize that \\textit{uniform} (identical) eigenvalues of the loss Hessian is most desirable (while keeping the sum constant) to achieve good generalization; 2) we employ the \\textit{Rényi entropy} to concisely characterize the extent of the spread of the eigenvalues of loss Hessian. Normally, the larger the spread, the smaller the (Rényi) entropy. To rigorously establish the relationship between generalization and (Rényi) sharpness, we provide several generalization bounds in terms of Rényi sharpness, by taking advantage of the reparametrization invariance property of Rényi sharpness, as well as the trick of translating the data discrepancy to the weight perturbation. Furthermore, extensive experiments are conducted to verify the strong correlation (in specific, Kendall rank correlation) between the Rényi sharpness and generalization. Moreover, we propose to use a variant of Rényi Sharpness as  regularizer during training, i.e., Rényi Sharpness Aware Minimization (RSAM),  which turns out to outperform all existing sharpness-aware minimization methods. It is worthy noting that the test accuracy gain of our proposed RSAM method could be as high as nearly 2.5\\%,  compared against the classical SAM method.", "tldr": "", "keywords": ["generalization", "sharpness", "sharpness aware minimization"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/853267ad4dbd4165718c9c0c0a2ca71b8d9b72de.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a novel sharpness measure to predict generalization performance: Renyi sharpness. They provide generalization bounds based on this measure, and experimental studies on CIFAR and TinyImagenet. Further, they also introduce a variant of the sharpness-aware minimization (SAM) algorithm that is based on an approximation of the Renyi sharpness, with experiments on Cifar and TinyImageNet."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper aims to address a fundamental problem in deep learning: the poor correlation between many generalization measures, and the empirically observed generalization performance. Using the Renyi sharpness as generalization measure because it captures uniformity is novel (to the best of my knowledge). In the provided experiments, the Renyi sharpnes shows good correlation (albeit doubts remain, see weaknesses below)."}, "weaknesses": {"value": "I have strong doubts on the conclusions that can be drawn from the experiments provided by the authors. In particular, I have concerns regarding the considered sharpness setup, the baselines that were used, the insightsfulness of the generalization bounds, and the effectiveness of the provided RSAM algorithm. \n\n1. Sharpness setup:  \nThe present study on the connection between Renyi sharpness and generalization is much less extensive than other work investigating the relationship between sharpness measures and generalization (e.g. Andriushchenko et al [1]). In [1], the authors also found setups - similar to the ones considered in this work - where sharpness _could_ predict generalization. However, Andriushchenko et al [1] showed that this might only be true for certain subgroups of the training parameters. In particular, when considering their “modern” setup (ViTs, ImageNet-scale, varied pretraining+finetuning schemes, OOD generalization and transfer learning, Language and Vision tasks,  …), the correlation disappeared. To show the effectiveness of the Renyi sharpness, experimental evidence on the scale of [1] would be necessary. \n\n\n\n2. Sharpness baselines and tuning of alpha:  \nThe provided results are for extensively tuned alpha values, whereas the baselines are apparently not tuned (e.g. the $\\rho$ values for SAM and ASAM). Further, many sharpness variants (e.g. the ones from [1]) are omitted from the study, and there are no details on how exactly the baseline measures are computed or what they mean.\n\n\n\n3. Generalization bounds:  \nThe generalization bound in theorem 3.2 is based on upper-bounding a generalization bound from [2] by upper-bounding the log-determinant of the Hessian with the Renyi sharpness. Using the log-determinant of the hessian (like done in [2]) would thus be better motivated by the bound. Same for theorem 3.3, where the log-determinant is also upper-bounded by the Renyi sharpness. There is thus a disconnect between the generalization bounds and the measure used. \n\n\n4. RSAM:  \nThe provided RSAM algorithm seems to be brittle (as admitted by the authors: warmup required, length depends on task) and barely brings improvements beyond error bars over ASAM. Further, from Tables 4 and 5 it seems that $\\rho$ has been tuned for RSAM, but not for the other SAM variants. Finally, there exists a plethora of SAM variants, that are all ignored in the comparison, and the study is limited in terms of dataset size (no ImageNet scale) and models (no ViTs). \n\n\n5. More comments:\n\n- reparametrization-invariant sharpness measures (w.r.t. layerwise rescaling) have been investigated before (see e.g. [1]), and I assume that the ASAM measure used in the provided study is one variant of the measures in [1]. So reparametrization invariance alone cannot be the reason for the (potential) success of a novel sharpness measure. I recommend discussing this when arguing about reparametrization invariance. \n- the authors claim “in our opinion, what matters the most for characterizing the generalization\nis the extent of the spread of the spectrum” when introducing the Renyi sharpness as generalization measure, but it is unclear to me where this opinion stems from. \n- The authors describe how alpha might be chosen, depending on the spectrum, but do not elaborate how this choice might look like in practice, and then tune alpha extensively in their experimental section. Is there an intuition on when to chose low or high alpha? Is it necessary to manually inspect the spectrum and decide on multi-cluster vs uniform? \n\n\n\nTypos:\n\nseveral times (e.g. Line 147): denote vs donate\n\nLine 215 Ler vs Let\n\n\n[1]  Maksym Andriushchenko, Francesco Croce, Maximilian Müller, Matthias Hein, and Nicolas Flammarion. A modern look at the relationship between sharpness and generalization. \n\n[2] Zhiwei Jia and Hao Su, Information-Theoretic Local Minima Characterization and Regularization, ICML 2020"}, "questions": {"value": "I do not have specific questions where an answer would change my opinion on the paper - I think significant changes, addressing the weaknesses outlined above, are necessary to convincingly argue in favour of Renyi sharpness:\n- a much extended experimental setup, like in Andriushchenko et al\n- more and better tuned baselines \n- a practical way of choosing alpha, without the necessity of tuning it\n- convincing arguments why the generalization bounds argue in favour of Renyi sharpness instead of log-det (H)\n- convincing evidence that RSAM improves robustly for fair comparison (tuned rho) over baselines"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qHPWFWK6p0", "forum": "rRIhUpobCv", "replyto": "rRIhUpobCv", "signatures": ["ICLR.cc/2026/Conference/Submission16254/Reviewer_NtAE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16254/Reviewer_NtAE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761153068229, "cdate": 1761153068229, "tmdate": 1762926407896, "mdate": 1762926407896, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a novel sharpness measure, Renyi sharpness, to consider the spread of the Hessian eigenvalues.\nIt shows a better correlation with generalization. They also propose a regularization method, RSAM, which outperforms other SAM variants."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- strong empirical results\n    - strong performance of RSAM\n    - strong  correlation between Renyi sharpness and generalization\n- scaling invariance of Renyi sharpness (see weaknesses)"}, "weaknesses": {"value": "-  **Lack of motivation**. Why do we need to consider the **spread** of Hessian eigenvalues? \n    - The authors said \"uniform eigenvalue is the most desirable to ensure good generalization, since if there exists no particularly large eigen direction, small perturbation of data would just incur small loss change\"\n    - This seems like a wrong statement.\n    - If all eigenvalues are large but similar (small spread), e.g., isotropic, then there surely exists large eigen direction, but Renyi sharpness is small as it only consider the spread, not the magnitude.\n    - $H_\\alpha(cI)=1/(1-\\alpha)\\log \\sum (1/n)^\\alpha=\\log n$ does not depends on the value of $c>0$.\n\n- The concept in Prop 2.2 is **not \"reparameterization\" invariance, but \"scaling\" invariance**. Renyi sharpness may not be (nonlinear) reparameterization invariant.\n\n- It seems like $A$ in the bound in (4) is not constant and depends on $\\theta$. \n\n- There is no definition for capital $N$.\n\n- Not a fair comparison. \"We vary $\\alpha$ and plot the sharpness that attains the highest correlation coefficient\". At least, you should report the best $\\alpha$ for each layer. It would be better to draw a scatter plot for $(\\alpha, \\tau)$-pairs (compared to the other baselines, e.g., trace) for each layer. If you pick the best measure (or $\\alpha$) after observing the gap, it is not an useful generalization measure.\n\n- use $\\langle w_j', v_j\\rangle$ or $w_j^{'\\top}v_j$ to improve readability.\n\n- It would be better to write $|g_j|^{2\\alpha}$ or $(g_j^2)^\\alpha$ instead of $g_j^{2\\alpha}$ in (10) to avoid a confusion for the case of $\\alpha=0.5$.\n\n- Can you elaborate more on the meaning of the **layerwise** Renyi shaprness? Is it important because Prop 3.1 can be applied to a single layer?"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4bZhkMZ3LF", "forum": "rRIhUpobCv", "replyto": "rRIhUpobCv", "signatures": ["ICLR.cc/2026/Conference/Submission16254/Reviewer_VHgD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16254/Reviewer_VHgD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726249053, "cdate": 1761726249053, "tmdate": 1762926407247, "mdate": 1762926407247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors study a new sharpness measure motivated by Rényi divergences in statistics. \nThe authors argue that uniformity in eigenvalues of Hessian (for a constant sum of eigenvalues) is desirable to promote generalization, as opposed to the original SAM, which aims to only minimize the largest eigenvalue of Hessian, being independent of the uniformity. They show that Rényi entropy, when applied to the normalized eigenvalues of the Hessian, can characterize the spread of the spectrum. Moreover, they prove generalization bounds from Rényi sharpness using two ideas: (1) Rényi sharpness, according to its definition, is a normalized function of Hessian eigenvalues, thus it is invariant to rescaling of parameters in homogeneous neural networks such as ReLU nets. (2) Multiplicative weight perturbations, according to orthogonal transformations. Furthermore, they experimentally show how generalization correlates with Rényi sharpness (Section 5) and propose Rényi-SAM, achieved via a new loss function. The method is validated over various datasets. \n \n\n \n\n\n\n\nHere is a detailed summary of their main contributions: Rényi sharpness is introduced, and it is shown that it is invariant to rescaling. Its correlation to generalization is shown. In Proposition 3.1, they show that perturbation via orthogonal matrices allows us to upper bound the population loss (Equation 3). This leads to a PAC-bayesian generalization bound in Theorem 3.2 and Theorem 3.3 that relates the population loss to the empirical risk plus some term involving Rényi sharpness.\n\n\nThey use PyHessian to estimate the Hessian of the neural network, which leads to Section 4.1. This includes a comprehensive discussion of how to choose the parameter alpha involving Rényi sharpness. \n\nTo estimate Rényi sharpness, they propose a method based on writing the quantity in terms of the trace of powers of the Hessian, and they use the Hutchinson method along with other quadrature methods used to approximate integrals/expectations. It is given in Algorithm 1."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- A new notion of sharpness, which is theoretically and practically correlated to generalization, is of potential interest to the community\n\n- The paper is an interesting mix of theory and practice"}, "weaknesses": {"value": "- The algorithm (Rényi sharpness) is poorly explained in the paper"}, "questions": {"value": "This is an interesting paper on SAM, relating Rényi sharpness to generalization. I think the paper is making good contributions, spanning from theory to algorithms and insights about generalization. Here are some comments/questions:\n\n\nDefinition 2.1: What happens if $H$ is non-positive definite? How do you define Rényi sharpness then? Please clarify this in the paper\n\n\nReparametrization invariance in Proposition 2.2: Why in Equation 1, alpha has to be different from one? Couldn't we take the limit and conclude that the identity also holds for that case?\n\n\n\nProposition 2.2: At first glance, I thought the invariance holds for the Hessian of the whole network, but looking at the proof, it looks like it holds only for an arbitrary fixed later. I ask the authors to clarify this in the text. The invariance follows from the fact that in the definition of Rényi sharpness, the authors introduced a normalization factor (the trace). \n\n\n\nPlease include some explanations about Algorithm 1 in the next version of the paper. Currently, it is really difficult to follow what it means.  \n\n\n\nEq. 9: If the gradients are vectors, then what do you mean by taking squares? You mean $hh^T$?\n\n\nHow do you optimize the objective in Eq. 11? Do you compute the gradients of it? Do you have something like a 'base optimizer' similar to the original SAM? If you compute the gradient of Eq. 11, then you have second-order derivative terms (prohibited). Do you use the same approximations as the original SAM to resolve this? I believe a rigorous explanation of what the Rényi SAM algorithm really is is required for the next version of the paper. Since this is one of the main contributions of this paper, you need to explain this in detail, probably having a clear algorithm dedicated to it. \n\n\nThere are some other notions of sharpness similar to Rényi in recent works that have never been discussed in the paper: For instance, I found 'Tilted SAM' in [1] and 'Frobenius SAM' in [2] on the web. There might also exist others, but at least these two are pretty similar. At least one expects some discussion and comparison in the paper. Please do search for more because I believe there might be other papers. \n\n\n[1] Li, Tian, Tianyi Zhou, and Jeff Bilmes. \"Tilted sharpness-aware minimization.\" ICML 2025\n\n[2] Tahmasebi, Behrooz, Ashkan Soleymani, Dara Bahri, Stefanie Jegelka, and Patrick Jaillet. \"A universal class of sharpness-aware minimization algorithms.\" ICML 2024"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YJ2ZjpGmNF", "forum": "rRIhUpobCv", "replyto": "rRIhUpobCv", "signatures": ["ICLR.cc/2026/Conference/Submission16254/Reviewer_3Nf3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16254/Reviewer_3Nf3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819492094, "cdate": 1761819492094, "tmdate": 1762926406728, "mdate": 1762926406728, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel measure using the equation for Renyi entropy. The normalized eigenvalues of the loss Hessian are treated as a distribution, and the Renyi entropy of this distribution is used as a measure. A generalization bound is derived in terms of this entropy, and the experimental results using Renyi entropy regularizer showed small improvements on accuracy on benchmark data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The presented method is novel. Experiments show improvement in accuracy."}, "weaknesses": {"value": "The presented method is novel, but it is difficult to recommend the paper for acceptance for several reasons. \n\nThe most problematic aspect is that the entropy is defined for a probability distribution, whereas eigenvalue spectrum is not a probability distribution. It is unclear what probability model the authors assume and whether it is valid. In the derived bound, the authors use a posterior distribution Q, but its definition and justification are not clearly explained.  It is very hard to recognize the eigenvalue spectrum as a distribution because no corresponding random variable is defined. Does the largest eigenvalue represent \\the probability of the first random variable? The overall setup and explanation are too vague to assess whether the application of Renyi entropy is conceptually meaningful. For example, I have seen using the information-theoretic measures for the output of the network because the output can be naturally considered as a probability distribution over predicted classes. However, in the case of Hessian eigenvalues, such a probabilistic interpretation is not justifiable.\n\nThe explanation in lines 176-184 is unclear What are the functions h(.), g(.) and other perturbation constants A and rho? \n\nHessian should be a very large matrix, making its computation and eigenvalue calculation at each optimization step computationally expensive. The authors used the square of gradient to approximate the hessian eigenvalues in the experiment without sufficient explanation. Is the eigenvalue distribution related to the square of gradient components in each dimension? During optimization, the gradient should approach zero, while the hessian does not."}, "questions": {"value": "Please address the weaknesses to increase score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FuYURZ4eeg", "forum": "rRIhUpobCv", "replyto": "rRIhUpobCv", "signatures": ["ICLR.cc/2026/Conference/Submission16254/Reviewer_2BS3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16254/Reviewer_2BS3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943735124, "cdate": 1761943735124, "tmdate": 1762926406333, "mdate": 1762926406333, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}