{"id": "6jzadKYz3W", "number": 4915, "cdate": 1757805060481, "mdate": 1759898005326, "content": {"title": "Breaking Independence: Learning Correlated Views for Variational Incomplete Multi-View Clustering", "abstract": "Incomplete multi-view clustering (IMVC) aims to uncover shared cluster structures from data with partially observed views. Although recent imputation-free methods based on variational inference demonstrate robustness to missing views, they commonly rely on a conditional independence assumption across views, which fails to capture the inherently structured and potentially correlated nature of multi-view data. In this paper, we propose a variational framework that explicitly breaks this assumption by introducing a learnable cross-view correlation structure. Specifically, we explicitly model and learn correlations between views by utilizing the covariance structure of posterior estimation errors. To facilitate robust and efficient learning, the correlation matrix is parameterized through a normalized Cholesky decomposition, ensuring positive definiteness and enabling the entire model to be trained jointly through a unified variational objective. Extensive experiments on multiple IMVC benchmarks demonstrate that our method consistently outperforms state-of-the-art approaches across a wide range of missing-view settings. These results highlight the effectiveness of adaptive correlation modeling in variational incomplete multi-view clustering.", "tldr": "", "keywords": ["Incomplete multi-view clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/670a0b86264b777d626ad578a6682f0ce6a8e906.pdf", "supplementary_material": "/attachment/6b0ebd983467a5490f743dd550416ad6466ce03a.zip"}, "replies": [{"content": {"summary": {"value": "This paper challenges the independence assumption in multi-view learning, arguing that in real-world scenarios, different views are often statistically correlated rather than independent. The authors propose a new framework that explicitly models inter-view correlations, achieving better results on various benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The proposed framework introduces a clear mathematical mechanism to capture inter-view dependencies, instead of assuming factorized likelihoods.\n\n2.The derivations are formal, and empirical results confirm that dependency modeling improves both accuracy and robustness."}, "weaknesses": {"value": "1.Experiments only consider moderate missing ratios (30‚Äì70%), not extreme cases like 90%. When co-occurrence among views becomes sparse, correlation estimation becomes unreliable.\n\n2.Although the paper claims to ‚Äújointly learn correlation structures,‚Äù the learned parameters correspond to a global covariance, capturing only linear, global dependencies.\n\n3.The text claims experiments are conducted on four datasets, while tables clearly list five. This inconsistency undermines experimental clarity and should be corrected."}, "questions": {"value": "1.Can your method handle extreme missing-view ratios (e.g., 90%)? Could you provide performance curves versus missing ratios?\n\n2.The learned correlation structure is always shared globally. Can it happen that view dependencies behave differently for different samples? Is a single correlation matrix no longer a good fit?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tbc1JELplp", "forum": "6jzadKYz3W", "replyto": "6jzadKYz3W", "signatures": ["ICLR.cc/2026/Conference/Submission4915/Reviewer_DFgg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4915/Reviewer_DFgg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551744596, "cdate": 1761551744596, "tmdate": 1762917763642, "mdate": 1762917763642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limitations of existing imputation-free variational methods for incomplete multi-view clustering (IMVC), which typically rely on the assumption of conditional independence across views. \n\nThe authors propose ACOVA (Adaptive Correlation-aware Variational Aggregation), a novel variational framework that explicitly models and learns inter-view correlations by leveraging the covariance of estimation errors between view-specific posteriors. The correlation matrix is parameterized through a normalized Cholesky decomposition, ensuring positive definiteness and enabling joint end-to-end optimization with model parameters.\n\nComprehensive experiments on several standard IMVC benchmarks (Scene15, Caltech5V, Handwritten, Fashion-MV, NoisyMNIST) show that ACOVA consistently outperforms previous state-of-the-art methods under various missing-view settings. Ablation and visualization analyses further confirm the benefit of modeling adaptive correlations for robust and discriminative latent representation learning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper identifies a fundamental issue in variational IMVC ‚Äî the conditional independence assumption among view posteriors. Proposing to ‚Äúbreak independence‚Äù by modeling cross-view correlation of estimation errors is both theoretically motivated and empirically useful.\n- Built upon a linear‚ÄìGaussian variational framework, the proposed ACOVA explicitly models structured posterior covariance by decomposing the estimation error covariance as Œ£=DRD.  The normalized Cholesky parameterization of R captures the correlations among view-specific variances and enables joint optimization, providing a principled generalization from DVIMC (independent) ‚Üí CoDE (fixed scalar correlation) ‚Üí ACOVA (adaptive correlation).\n- Experiments on five IMVC benchmarks demonstrate consistent gains across missing-view rates (10‚Äì70%), confirming the method‚Äôs robustness. Qualitative visualizations ‚Äî including t-SNE plots and learned correlation matrices ‚Äî clearly illustrate that the model captures meaningful inter-view dependencies.\n- Overall, the paper ‚Äî together with its appendices ‚Äî forms a coherent and complete study, covering theoretical justification, empirical validation, and in-depth analysis."}, "weaknesses": {"value": "Motivation\n1. The work is focused narrowly on incomplete multi-view clustering (IMVC), a relatively specific subproblem. It would strengthen the contribution to discuss whether the proposed adaptive correlation learning principle generalizes to broader multi-modal or self-supervised representation learning tasks.\n2. The paper defines the ‚Äúerror of estimation‚Äù as the bridge to cross-view correlation modeling, but this definition appears somewhat _indirect_. The authors should provide a higher-level motivation early in the introduction ‚Äî e.g., why modeling estimation errors is the right abstraction for inter-view dependence, rather than just citing Winkler (1981) and Mancisidor et al. (2025).\n\nMethod\n\n3. The adaptive correlation learning is elegant, but the derivation (Eq. 9‚Äì11) and the optimization of R (Eq. 16) could use _clearer intuition_. It‚Äôs not entirely clear how learning R avoids degeneracy when views are highly incomplete or uncorrelated.\n4. The paper provides only a Frobenius norm bound for R, which is purely structural and does not guarantee _stability_ or _identifiability_ of learned correlations, especially under high missing ratios.\n5. In Eq. 6, since both the diagonal scaling $D$ and the correlation matrix $R$ are learned jointly, and $R$ itself is derived from a normalized Cholesky factor $L$, how do you ensure parameter identifiability? In other words, could different $L$ (or scaling of $D$ ) lead to equivalent $\\Sigma=D R D$ and thus yield degenerate solutions?\n\nExperiments\n\n6. The authors mention averaging over five runs, but this should be stated clearly in the main text rather than only in the appendix. \n7. I appreciate that you provide a complexity analysis in Appendix A.4 and a time-cost comparison in Appendix C.3. However, the theoretical complexity $ùëÇ(ùëÅùê∑ùëâ^3)$ scales cubically with the number of views $ùëâ$, primarily due to per-sample matrix inversion. Have you analyzed how the actual runtime or memory cost changes with increasing $ùëâ$?\n8. Although the proposed framework ensures $R \\succ 0$ via the normalized Cholesky parameterization, matrix inversion of $R$ (and thus $\\Sigma=D R D$ ) is required per sample and per latent dimension. This could introduce numerical instability when $R$ becomes ill-conditioned during training.\n9. All datasets used are standard, small to medium-scale benchmarks (Scene15, Caltech5V, Handwritten, Fashion-MV, NoisyMNIST). There are no experiments on high-dimensional or large multi-view datasets to demonstrate scalability or generalization capability.\n\nIf the authors can adequately address the above concerns, I would be inclined to raise my score."}, "questions": {"value": "Please refer to weaknesses section, thanks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "06XCHdrdBT", "forum": "6jzadKYz3W", "replyto": "6jzadKYz3W", "signatures": ["ICLR.cc/2026/Conference/Submission4915/Reviewer_h14L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4915/Reviewer_h14L"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891477131, "cdate": 1761891477131, "tmdate": 1762917763074, "mdate": 1762917763074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper targets the problem of Incomplete Multi-View Clustering (IMVC). It identifies a key limitation in recent variational IMVC approaches: their reliance on aggregators that assume conditional independence between views, which is a potentially over-restrictive assumption in real-world multi-view scenarios. To alleviate this limitation, the paper proposes ACOVA, a variational framework that relaxes this assumption by explicitly modeling cross-view correlations to achieve a more robust representation aggregation method. The core mechanism involves learning a correlation matrix, which is parameterized to ensure positive definiteness and trained end-to-end within a unified variational objective. Experimental results on several datasets demonstrate that ACOVA achieves superior performance, particularly surpassing methods that rely on an independence assumption."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper identifies a practical limitation in prior variational IMVC work: the conditional independence assumption inherent in the aggregation method, especially in the Product-of-Experts (PoE) approach, which might be over-restrictive in many multi-view scenarios, thereby limiting such IMVC method performance. The proposed solution of parameterizing a learnable correlation matrix via Cholesky decomposition (to ensure positive definiteness) is an elegant and technically sound approach to address this limitation in an unsupervised manner. Additionally, the experiments reveal the effectiveness of explicitly modeling and incorporating inter-view correlations."}, "weaknesses": {"value": "1. Several key notations in the methodology (Sec 4.1) are ambiguous or insufficiently defined, which significantly hinders the comprehension of the proposed method. For example, the definition of $\\mu$ as a $\\mathbb{R}^{VD\\times1}$ column vector is confusingly represented as $[\\mu^1, \\mu^2, ..., \\mu^D]^{\\mathrm{T}}$. Furthermore, the precise structure of the design matrix $\\mathbb{1}$ in Eq.5 is not clearly specified; it appears to be a block matrix where the $d$-th $V$-row block contains ones in the $d$-th column and zeros elsewhere, but this requires explicit definition. Additionally, terms like $\\mathbf{A}_\\mathbf{M}$, $\\mathbf{M}$ in Eq.9-11 are used in the main text without sufficient introduction.\n2. While the current experiments demonstrate the method's effectiveness to some extent, the chosen multi-view datasets (e.g., Handwritten, Fashion) appear relatively simple, with potentially obvious inter-view correlations. To further validate the robustness and generalizability of the proposed correlation modeling, the method should be evaluated on more complex, real-world multi-view datasets where inter-view relationships may be more subtle or heterogeneous."}, "questions": {"value": "1.Modeling view correlation seems fundamentally beneficial. Theoretically, should this approach also be expected to outperform independence-assuming methods in the complete multi-view setting?\n\n2.The current datasets seem to have relatively simple view structures. How is the method expected to perform on more complex heterogeneous views (e.g., involving different modalities) where the inter-view correlations might be more intricate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "kOUMRgD2PO", "forum": "6jzadKYz3W", "replyto": "6jzadKYz3W", "signatures": ["ICLR.cc/2026/Conference/Submission4915/Reviewer_AN2K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4915/Reviewer_AN2K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990082493, "cdate": 1761990082493, "tmdate": 1762917762410, "mdate": 1762917762410, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an IMVC model by introducing a variational framework that explicitly models and learns cross-view correlations, thereby addressing a significant limitation of existing imputation-free methods based on variational inference.  Overall, with more extensive experimental validation, sensitivity analysis, discussion of limitations, and visualizations, this paper has the potential to make a substantial impact in the field."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The introduction of a learnable cross-view correlation structure is a significant contribution to the field of IMVC. \n2. The authors designed an adaptive cross-view correlation learning mechanism to jointly learn the correlation matrix and model parameters, leading to improved performance"}, "weaknesses": {"value": "1. It is suggested to perform more comparison experiments with state-of-the-art methods on a wider range of datasets and evaluation metrics. This would help to solidify the claims about the robustness and efficiency of the proposed approach.\n2. The advancement of this paper and the derivation of the intermediate process are expected to receive more mathematical support, such as Eq. (1)-(3)."}, "questions": {"value": "1. What is the complexity of the proposed method? How does it compare with other methods, especially on the large-scale datasets?\n2. How does it perform on the data with complex noise? How to ensure the accuracy of the learned cross-view correlation structure?\n3. How many hyperparameters are there in the proposed model, and how can they be set in a new IMVC task?\n4. How does the computational complexity scale with the number of views or the size of the dataset? Are there any scenarios where the proposed method might not perform well?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "e9sypwp6BF", "forum": "6jzadKYz3W", "replyto": "6jzadKYz3W", "signatures": ["ICLR.cc/2026/Conference/Submission4915/Reviewer_XMzh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4915/Reviewer_XMzh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762164642385, "cdate": 1762164642385, "tmdate": 1762917759549, "mdate": 1762917759549, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}