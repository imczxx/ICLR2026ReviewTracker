{"id": "uq6UWRgzMr", "number": 25580, "cdate": 1758369274119, "mdate": 1759896714540, "content": {"title": "Neuron-Aware Data Selection in Instruction Tuning for Large Language Models", "abstract": "Instruction Tuning (IT) has been proven to be an effective approach to unlock the powerful capabilities of large language models (LLMs). \nRecent studies indicate that excessive IT data can degrade LLMs performance, while carefully selecting a small subset of high-quality IT data can significantly enhance their capabilities. Therefore, identifying the most efficient subset data from the IT dataset to effectively develop either specific or general abilities in LLMs has become a critical challenge.\nTo address this, we propose a novel and efficient framework called Nait. Nait evaluates the impact of IT data on LLMs performance by analyzing the similarity of neuron activation patterns between the IT dataset and the target domain capability. Specifically, Nait captures neuron activation patterns from in-domain datasets of target domain capabilities to construct reusable and transferable neuron activation features. It then evaluates and selects optimal samples based on the similarity between candidate samples and the expected activation features of the target capabilities.\nExperimental results show that training on the 10\\% Alpaca-GPT4 IT data subset selected by Nait consistently outperforms methods that rely on external advanced models or uncertainty-based features across various tasks. Our findings also reveal the transferability of neuron activation features across different capabilities of LLMs. In particular, IT data with more logical reasoning and programmatic features possesses strong general transferability, enabling models to develop stronger capabilities across multiple tasks, while a stable core subset of data is sufficient to consistently activate fundamental model capabilities and universally improve performance across diverse tasks.", "tldr": "NAIT is an efficient algorithm that selects high-quality instruction tuning data by analyzing neuron activation pattern similarity, enhancing large language models' performance and general capabilities.", "keywords": ["Instruction Tuning", "Data Selection", "Large Language Models"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/18bd38fd6481cddfc7387a35e40feda9a8a92462.pdf", "supplementary_material": "/attachment/2601be187f12cc1ece53c0f8c3f523866a3b2a69.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes NAIT, a novel and efficient framework for selecting high-quality instruction tuning (IT) data based on the similarity of neuron activation patterns between candidate data and a target capability's in-domain reference set."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clarity and Presentation: The paper is well-written and easy to follow.\n\n2. Relevance of Core Idea: The paper successfully addresses the critical insight that the quality of instruction data is more important than the quantity. The proposed method offers a potential, scalable approach for constructing high-quality instruction datasets."}, "weaknesses": {"value": "1. The central hypothesis, that the effectiveness of instruction data lies in its ability to activate task-relevant neurons, is merely an assumption and is not widely recognized or proven.\n\n2. The use of a small, in-domain reference dataset to extract the neuron activation features (for the target capability) may introduce significant bias into the feature extraction process, potentially limiting the generality of the resulting selection criterion.\n\n3. The primary base model used for experimentation is LLaMA and Mistral. Compared to other similarly-sized open-source LLMs (Qwen2.5, Qwen3) available today, LLaMA and Mistral series are generally considered weaker, which lacks sufficient persuasiveness for the experimental results.\n\n4. The experimental evaluation section uses a limited number of benchmarks and fails to include some newer and more comprehensive evaluation benchmarks (MMLU-pro, GPQA, LiveCodeBench, MBPP, HumanEval, MATH-500, Minerva-Math, OlympaidBench, etc.). This limits the ability to fully assess the efficacy and generalizability of the proposed NAIT method."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1nXF9euh1y", "forum": "uq6UWRgzMr", "replyto": "uq6UWRgzMr", "signatures": ["ICLR.cc/2026/Conference/Submission25580/Reviewer_76SK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25580/Reviewer_76SK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25580/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635618161, "cdate": 1761635618161, "tmdate": 1762943483526, "mdate": 1762943483526, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NAIT, a novel framework for efficient instruction tuning data selection by analyzing neuron activation patterns in Large Language Models to identify data that effectively enhances specific or general capabilities. The core hypothesis is that IT data samples are more effective if their neuronal activation patterns closely align with the activation characteristics associated with a target capability. NAIT extracts reusable neuron activation features from in-domain datasets and selects optimal IT samples based on their similarity to these target capability activation features, demonstrating superior performance and cost efficiency compared to existing methods. Experiments show NAIT consistently improves LLM performance (e.g., 3% with only 10% of data), reveals the strong general transferability of logical reasoning and programmatic features, and identifies a stable core subset of data universally beneficial across diverse tasks. Ablation studies reveal that optimal performance is achieved with approximately 30% of the IT dataset selected by NAIT, with larger proportions leading to degradation due to redundant data.  The paper open-sources a cross-task neuron feature library and the Alpaca-NAIT dataset, a high-quality IT dataset curated using the proposed NAIT framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of using the model’s own internal neuron activation patterns to evaluate data quality is novel and interesting. Unlike prior data selection methods that rely on external scorers or surface heuristics, NAIT directly taps into the model’s internal representation. This provides a more interpretable and fine-grained signal and is externally independent.\n2. NAIT effectively addresses the scenario of enhancing specific capabilities in an LLM. The method is flexible – by providing an in-domain sample set for a desired skill, the framework can pick out relevant training data to boost that skill. Experiments confirm that NAIT tuning on a skill-focused subset yields better performance on that domain’s benchmark than generic fine-tuning.\n3. The approach shows that a 10% subset selected by NAIT can outperform or equal the full 100% data training in many cases. These results reinforce the claim that more data isn’t always better, and smart selection can yield efficiency gains. It’s impressive that NAIT even beat methods like AlpaGasus and Q2Q which leverage GPT4 or uncertainty measures.\n4. A notable strength is the paper’s analysis of neuron activation transferability. Those findings provide insight into what kinds of instructional data are broadly useful. Such analysis adds depth to the work, beyond just performance numbers.\n5. By avoiding external model calls and using efficient feature extraction, NAIT is relatively lightweight. The authors compare computational cost and show significant speedup and cost reduction versus prior methods."}, "weaknesses": {"value": "1. A practical concern is that NAIT requires a representative in-domain dataset for each target capability as a starting point. In real scenarios, such labeled data may not be readily available for every “capability” one wishes to improve. This reliance potentially limits NAIT’s applicability to cases where one can clearly define and obtain data for the target skill. If the in-domain examples are too few or not truly representative, the quality of the activation feature (and thus the selection) might suffer. The paper does not deeply explore how sensitive the method is to the choice or size of this in-domain set.\n2. One of the claims is that NAIT can enhance specific or general capabilities. However, the results suggest that focusing on a single strong capability (like GSM for math) yielded the highest average boost, even more than combining all capability features. The model fine-tuned on the GSM-selected subset outperformed the model using a multi-capability combined subset (35.42 vs 35.18 AVG). This is somewhat counter-intuitive – ideally, integrating multiple skills would give broader improvement. The fact that the “all capabilities” selection did not significantly outperform single-capability selections raises concerns. It suggests NAIT might struggle to simultaneously optimize for many skills, or that the method for merging activation features may be suboptimal. This limitation should be better addressed: if one wants a generally strong model, do they have to run NAIT for every capability and merge data ad-hoc? \n3. The paper lacks direct comparison to an embedding-based selection baseline. How does NAIT compare to a simpler strategy like using embedding similarity for data selection? For instance, one could embed each candidate instruction (using the same LLM) and each in-domain example, then select those with highest similarity to the in-domain set (or to a mean in-domain embedding). This makes it harder to assess how much benefit comes from the neuron-level analysis versus just using the model’s last-layer representation or other heuristics.\n4. There are some open questions about NAIT’s scalability and certain design choices. The paper would benefit from clarity on which layers or neurons are used for the activation pattern – is it the entire hidden state of the model, a subset of layers, or aggregated over the whole sequence? Additionally, while the authors claim adaptability to different model sizes, it’s not explicitly shown how NAIT scales to very large models (e.g., 70B parameters) – the experiments seem limited to one model family (likely around 7B-13B scale)."}, "questions": {"value": "1. Could you clarify the construction of the “activation feature” and alignment score? Specifically: (a) Do you use the entire model’s neuron activations for the input (all layers) or only a particular layer’s output (e.g., last hidden state)? (b) What is ∆A($P_i$) exactly (activation difference relative to what baseline)? (c) Once you have PCA-compressed features for in-domain and candidate data, is the similarity score simply a dot product or cosine similarity in that feature space? Providing these details (perhaps I missed them in the text).\n2. In the experiment combining all capability features, how was this combination done? Did you union the top-k selections from each capability run, or aggregate the activation features into one composite feature vector for scoring all data at once? The result that this combined approach didn’t outperform the best single-capability selection is interesting – could you elaborate on why you think that happened?\n3. Have you tried applying NAIT with a larger base model or on a larger pool of candidate data? The cost analysis suggests NAIT is efficient on 52k data with a 7B-ish model. If we consider, say, a 70B model and a few hundred thousand instructions, do any new challenges arise (e.g., needing to handle many more neurons, longer activation vectors, etc.)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8Yzup9IkZI", "forum": "uq6UWRgzMr", "replyto": "uq6UWRgzMr", "signatures": ["ICLR.cc/2026/Conference/Submission25580/Reviewer_SZW9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25580/Reviewer_SZW9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25580/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819116167, "cdate": 1761819116167, "tmdate": 1762943483270, "mdate": 1762943483270, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a neuron-aware framework for selecting instruction-tuning data based on neuron activation similarity. Instead of relying on external models or uncertainty metrics, NAIT extracts neuron activation features from small in-domain reference sets and scores candidate samples by alignment with these features. Experiments  show that training on 10% of the selected Alpaca-GPT-4 data improves average performance across multiple benchmarks and domains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Strong data‑efficiency. NAIT with 10% of Alpaca‑GPT‑4 matches/exceeds full‑data tuning and outperforms several selection baselines.\n- The neuron‑feature construction and per‑candidate alignment score are conceptually simple and effective across many tasks."}, "weaknesses": {"value": "- The experiments didn’t compare against some strong recent data selection methods like LESS (ICML 2024).\n- The paper seems doesn’t specify which layers’ activations are used to compute features or why. Since different layers capture different types of information, this choice may matters. explanation or ablations could be added."}, "questions": {"value": "Did you compute ΔA(Dn) analogously to Eq. (3), then apply the same PCA transform learned on in‑domain features before scoring? Do you use cosine similarity or dot product? Any per‑sample length or norm? Providing an algorithm box would be better."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AojKgm5k1N", "forum": "uq6UWRgzMr", "replyto": "uq6UWRgzMr", "signatures": ["ICLR.cc/2026/Conference/Submission25580/Reviewer_wy8Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25580/Reviewer_wy8Y"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25580/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988306840, "cdate": 1761988306840, "tmdate": 1762943483024, "mdate": 1762943483024, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper introduces NAIT, a novel framework for selecting high-quality data for the instruction tuning LLMs. \n- The proposed NAIT method first captures a characteristic activation feature for a target capability by processing a small set of examples and applying PCA to their neuron activations. Second, it scores and selects data from a larger candidate pool by measuring the alignment between the candidate data's neuron activations and this characteristic feature."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- While neuron activation analysis has been used to interpret LLMs, its application as a direct signal for instruction data selection is novel and interpretable. \n- The paper is well written, and the experiments are conducted on a wide range of datasets and base models.\n- The cost-efficiency analysis is a crucial and compelling strength, showing improvements in speed and cost, which is a highly practical advantage in the LLM era.\n- The interpretable analysis on transferability and the relation of different activation features supports the motivation of the proposed method."}, "weaknesses": {"value": "- The framework's first step requires a capabilities-specific in-domain dataset. For the tasks evaluated (MMLU, GSM, etc.), these datasets are readily available from established benchmarks. However, if one wishes to enhance a more abstract or novel capability, curating a high-quality, representative in-domain dataset becomes a significant, and potentially subjective, bottleneck. \n- This paper should provide a few qualitative examples to illustrate the difference between data points in the \"core set\" (selected for most capabilities) and those that are task-specific (e.g., selected only when targeting CodeX)? \n- The related work section correctly identifies Loss and Gradient-based Coreset Sampling Methods as a relevant category of data selection techniques. However, no gradient-based method was included as a baseline in the experimental comparisons."}, "questions": {"value": "Same as the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4XrmSpIItm", "forum": "uq6UWRgzMr", "replyto": "uq6UWRgzMr", "signatures": ["ICLR.cc/2026/Conference/Submission25580/Reviewer_2hWE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25580/Reviewer_2hWE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25580/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762102225567, "cdate": 1762102225567, "tmdate": 1762943482811, "mdate": 1762943482811, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}