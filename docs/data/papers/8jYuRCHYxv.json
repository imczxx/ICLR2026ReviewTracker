{"id": "8jYuRCHYxv", "number": 5941, "cdate": 1757947825643, "mdate": 1759897943331, "content": {"title": "Missingness-MDPs: Bridging the Theory of Missing Data and POMDPs", "abstract": "We introduce missingness-MDPs (miss-MDPs); a subclass of partially observable Markov decision processes (POMDPs) that incorporates the theory of missing data.\nMiss-MDPs capture settings where, at each step, features of the current state may go missing, that is, the state is not fully observed.\nMissingness of state features occurs dynamically, governed by the missingness function, a restricted observation function.\nIn miss-MDPs, we distinguish three types of missingness functions: \nmissing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR).\nOur problem is to compute a policy for a miss-MDP with an unknown missingness function from a dataset of observations. \nWe propose probably approximately correct (PAC) algorithms that, from a dataset, approximate the missingness function and, thereby, the true miss-MDP.\nWe show that, for specific missingness functions, the policy computed on the approximated model is epsilon-optimal in the true miss-MDP. \nThe empirical evaluation confirms these findings and shows that our approach becomes more sample-efficient when exploiting the type of the missingness function.", "tldr": "We introduce a framework that integrates the theory of missing data into POMDP planning and propose algorithms for learning observation functions under different missingness processes.", "keywords": ["Decision and Control", "Missing Data", "Model-Based RL", "Planning", "Reinforcement Learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ec3779874c24ece67826a742a2c3746fdcd69831.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "- This work addresses a particular type of POMDP, called a \"miss-MDP,\" where certain state features are missing at random or through dependencies with other state features, and proposes an approach for estimating the missingness function from a historical dataset and computing a near-optimal PAC policy.\n- They evaluate the proposed algorithm (and its variants) using an ICU dataset and a toy domain under different assumptions about the missingness function and compare their performance to the oracle and the uniform action-selection baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Originality and significance: This work extends existing research on POMDPs and MDPs with missing state observations by introducing an estimation method for the missingness function under different assumptions about missingness. \n\n- Quality: The paper includes both a toy domain and a clinical dataset.\n\n- Clarity: Overall, the writing is clear, with a few outstanding questions regarding the distinction between MNAR and non-simple MAR (which the reviewer elaborates on in the Weaknesses section). Figure 2 effectively illustrates different cases of missingness and is helpful to include."}, "weaknesses": {"value": "Originality and significance: \n- While the problem itself is interesting and important, the analysis and applicability of the proposed algorithm are limited to tabular states, and it is unclear how the method could be extended to high-dimensional states. Adding to this point, the experimental domains have fairly small state spaces (2 for the predator task and 4 for the ICU task) whereas in real-world settings, where the motivation for POMDPs and missingness comes from, state observations are typically high-dimensional, which limits the applicability and significance of this work. \n\n- Although the inclusion of a PAC analysis is valuable, it is fairly standard and not technically novel enough to constitute an independent contribution. \n\nExperiments: \n- The current experiments include only variants of the authors’ own algorithms (besides the uniform and the oracle baselines). The authors could consider modifying or including baselines from prior work, such as deep variational methods by Igl et al., 2018, since it is difficult to calibrate the empirical advantages without comparisons to other approaches, even if those methods are based on different assumptions about missingness. (Igl et al., 2018. Deep variational reinforcement learning for POMDPs. There may be other works that can be adapted to the problem setup of this paper and can be included as comparisons.)\n\nClarity:\n- The distinction between non-simple MAR and MNAR discussed in Section 4.2 (where the authors state that the non-simple MAR case satisfies the three conditions of independence, no self-censoring, and positivity) is unclear. In particular, the example provided for \"MAR but not simple MAR\" is: “Now, the missingness probability of feature 1 depends on the value of feature 2 (only if observed), while feature 2 itself misses with probability 0.5.” This example appears to correspond to the MNAR case shown in Figure 2, where $S_2$ affects $R_1$ (so feature 1 depends on the value of $S_2$ if it's observed), while $S_2$ itself can be missing as suggested by $R_2$. \n\n- This confusion continues with Lines 200-201, where the authors describe MNAR as cases where \"missingness probabilities may depend on the values of missing functions\" and provide a self-censoring example for MNAR. However, in the later sections (particularly 4.2), MNAR is described as non-self-censoring, independent, and positive. The authors could consider providing a different example of MNAR that satisfies these conditions to clearly distinguish between non-simple MAR and MNAR. Without further clarification, the description of MNAR may mislead readers into interpreting it as cases where missingness depends on the feature’s value (e.g., when temperature is too high or too low to be recorded properly, making the missing value itself informative about the measurement)."}, "questions": {"value": "- Question about the distinction of MNAR in section 4.2 and non-simple MAR is raised in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5F8rVKfTnX", "forum": "8jYuRCHYxv", "replyto": "8jYuRCHYxv", "signatures": ["ICLR.cc/2026/Conference/Submission5941/Reviewer_BvRg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5941/Reviewer_BvRg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761675273020, "cdate": 1761675273020, "tmdate": 1762918366128, "mdate": 1762918366128, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper formalizes miss-MDPs and gives PAC-type guarantees for learning missingness under simple MAR and MNAR with independent incidators and no self-censoring, then use a standard POMDP method. Experiments suggest convergence to optimal policy with reasonable data sizes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Formalize the miss-MDPs to bridge between missing data taxonomy and sequential decision making.\n- Shows under MAR, belief updates do not depend on missingness probabilities."}, "weaknesses": {"value": "- AsMAR estimates the set $\\hat{I}_{always}$, but Theorem 1's PAC statement does not condition on this set. \n- Counting set for AIMI is too restrictive. $Z_s^{i,r_i}$ requires all features $j\\neq i$ be observed and exactly match $s$, discarding any sample where any other component is missing. This can devastate sample efficiency, even under positivity, and the paper gives no guidance on the resulting rates. \n- By design, $M$ depends only on $s$ (not $a$ or $t$), and your POMDP observation in prelims is also action-independent. Many practical missingness processes (e.g., clinical testing) are action-selected."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "d9Qs9L5eBb", "forum": "8jYuRCHYxv", "replyto": "8jYuRCHYxv", "signatures": ["ICLR.cc/2026/Conference/Submission5941/Reviewer_bJ4V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5941/Reviewer_bJ4V"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858042858, "cdate": 1761858042858, "tmdate": 1762918365731, "mdate": 1762918365731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a subclass of POMDPs where the state can be observed with certain components missing. Standard assumptions on missingness from the theory of missing data are investigated. Theoretical analysis is provided for estimating the missingness model given a dataset of trajectories sampled by running a so-called fair policy, and the consistency of a policy computed using the estimated model. The theoretical insights are empirically validated on two simple problems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Incomplete state observations can arise in practice. Formalizing and analyzing this are interesting.\n* The writing is clear and easy to follow."}, "weaknesses": {"value": "* The main contribution of the paper is in the theoretical analysis, but this applies to POMDPs with finite state and action spaces only, which is not particularly surprising.\n* Empirical experiments are only done on simple small problems.\n* A minor comment is that PAC as used in this paper is different from the standard concept of PAC as introduced by Valiant, which can be confusing.\n* Another minor comment is that \"observation\" and \"trajectory\" are used synonymously at some places (e.g. the abstract mentions \"a dataset of observations\", while it means a dataset of trajectories)."}, "questions": {"value": "* Does the analysis cover the case when some states are not reachable from some other states?\n* In Theorem 1 and Theorem 2, presumably the result holds for not just a particular $n^{\\*}$, but for any sufficiently large $n^{\\*}$, is it?\n* The experiments show that exact missingness function can be estimated. It is surprising that probabilities can be estimated without any error using random datasets. Did I miss something?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3SdAH2bKNs", "forum": "8jYuRCHYxv", "replyto": "8jYuRCHYxv", "signatures": ["ICLR.cc/2026/Conference/Submission5941/Reviewer_mvJv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5941/Reviewer_mvJv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979752858, "cdate": 1761979752858, "tmdate": 1762918365338, "mdate": 1762918365338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel formalism, so-called missingness Markov decision processes (miss-MDPs), which is a subclass of partially observable MDPs (POMDPs). The main contribution of the paper is to introduce three types of missingness functions, which are missing completely at random (MCAR), missing at random (MAR),\nand missing not at random (MNAR), into MDPs. The authors prove finite-time PAC guarantees for estimating missingness functions and ensuring \\epsilon-optimal policies."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper gives an interesting formalism for a subclass of POMDPs and has PAC-bounds on learning policies for miss-MDPs."}, "weaknesses": {"value": "Overall, I believe the paper has an interesting theoretical approach, but it lacks motivation in using the miss-MDP formalism instead of POMDPs, as the authors did not show a specific computational advantage either in theory or in practice. I will have some questions in my review."}, "questions": {"value": "What is the main advantage of using miss-MDPs instead of simply treating them as a special observation function in POMDPs?\n\nWhat new capabilities or insights does the miss-MDP formalism provide that POMDPs do not? You only showed finite-time PAC bounds in your paper.\n\nCan you provide some examples where this approach may provide better theoretical and practical guarantees compared to just using POMDPs?\n\nHow does admittability affect learning or belief updates later? Could multiple states admit the same observation z? If so, how does this ambiguity influence identifiability?\n\nWhat is the rate at which the error in \\hat{M} translates into policy suboptimality \\epsilon? Is it possible to establish bounds as a function of the number of states, observations, and the missingness function?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PQ8eq9LbI8", "forum": "8jYuRCHYxv", "replyto": "8jYuRCHYxv", "signatures": ["ICLR.cc/2026/Conference/Submission5941/Reviewer_xCFs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5941/Reviewer_xCFs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762133895796, "cdate": 1762133895796, "tmdate": 1762918364714, "mdate": 1762918364714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}