{"id": "0UMXSQOmDY", "number": 8282, "cdate": 1758077329519, "mdate": 1761291118775, "content": {"title": "CAMERA CONDITIONED VIDEO GENERATION WITH IMPROVED POSE FIDELITY", "abstract": "Novel-view video generation from dynamic scenes has emerged as a compelling research direction with the advancement of video diffusion models. However, current approaches face key constraints that restrict flexibility. Specifically, methods exploiting Image-to-Video models as a baseline are constrained by the bias of the base model, limiting the target camera pose of the initial frame to remain close to the source. Limited diversity of camera trajectories in currently available datasets also confines trained models to generating output with limited camera trajectories. The generation results of projection-based methods that rely on depth estimation are affected by projection errors present in the depth-warped input video. In this paper, we present FreeCam, a camera trajectory conditioned Video-to-Video generation framework that enables depth-free novel-view video generation for a constraint-free camera trajectory. We introduce infinite homography warping that encodes 3D camera rotations directly in 2D latent space without depth, enabling high camera pose fidelity. Also, we augment existing multi-view datasets with identical initial frames into the dataset with arbitrary-trajectories and heterogeneous intrinsic parameters, enabling training on diverse camera motions and focal lengths. Our experimental evaluation demonstrates that FreeCam delivers enhanced trajectory precision over existing state-of-the-art approaches while preserving visual fidelity. Notably, despite training exclusively on synthetic data, FreeCam generalizes effectively to real-world videos. Through comprehensive ablation studies and comparative analyses, we confirm the complementary advantages of our proposed data processing pipeline and infinite homography warping technique, together establishing a novel framework for achieving precise and flexible camera motion control in video synthesis applications.", "tldr": "camera trajectory-conditioned video generation framework that enables unconstrained-trajectory synthesis without external geometric priors.", "keywords": ["camera-conditioned video generation", "novel view generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/ee3b0f4f0856a50fdf9e2b573d9a857608c40692.pdf", "supplementary_material": "/attachment/0e33fb5631cc88e382c52fe2c2df03214486ae08.zip"}, "replies": [{"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "KvV9T4V1xD", "forum": "0UMXSQOmDY", "replyto": "0UMXSQOmDY", "signatures": ["ICLR.cc/2026/Conference/Submission8282/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8282/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761291117361, "cdate": 1761291117361, "tmdate": 1761291117361, "mdate": 1761291117361, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}