{"id": "qqlWHIjJ24", "number": 15049, "cdate": 1758247198305, "mdate": 1759897333377, "content": {"title": "DCR$^2$-AD: Dynamic Context Routing and Reasoning Multi-Modal Large Language Model for Anomaly Detection", "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have shifted the anomaly detection paradigm from traditional classification-based approaches toward a novel diagnostic framework based on MLLM-driven question answering. In contrast to conventional architectures characterized by “single-scenario, single-purpose designs”, these models use pretraining to attain robust generalization capabilities and provide expert-level diagnostic performance. However, current MLLM-based anomaly detection methods rely predominantly on internalized knowledge of visual defects, which limits their effectiveness in open-domain settings where anomalies demonstrate significant cross-scenario ambiguity. For example, logical anomalies differ fundamentally from common visual defects, and hence cannot be effectively identified using conventional visual defect-based rules. To overcome this limitation, we propose an innovative Dynamic Context Routing and Reasoning model (DCR²-AD), which integrates knowledge-routed reasoning trajectory synthesis (KR-RTS) and knowledge-routed direct preference optimization (KR-DPO) to improve the model’s capacity for appropriate external knowledge utilization during reasoning. We first constructed an object-agnostic knowledge base encompassing extensive defect-related knowledge. By substituting knowledge from correct reasoning trajectories with information drawn from incorrect trajectories, we synthesized erroneous reasoning trajectories. Furthermore, we introduce the KR-DPO algorithm, which conditions on the selectively routed knowledge to promote correct reasoning trajectories and suppress incorrect ones, thereby refining the model’s ability to identify optimal reasoning pathways. Through extensive experiments, our approach achieves state-of-the-art performance, attaining 83.36\\% on the comprehensive MMAD benchmark, surpassing the base model by 6.00\\%, outperforming ordinary human by 4.67\\%, and exceeding the previous best method by 1.41\\%. These significant gains substantiate the efficacy of our proposed framework. Our code and data will be made publicly available upon publication of the paper.", "tldr": "", "keywords": ["Anomaly Detection", "Multi-modal Large Language Model", "Reasoning", "Chain-of-Thought"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a79fdf703ce7337618dd8cce678464c86ce5408f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a multi-modal large language model designed to advance anomaly detection beyond simple visual defect identification and toward more sophisticated reasoning. To achieve this, the authors construct a knowledge base of both positive and negative anomaly reasoning logic. This knowledge base is then used to train a policy model via Direct Preference Optimization, enhancing the model's reasoning capabilities. The proposed method achieves state-of-the-art performance on the MMAD benchmark for anomaly reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) This paper addresses the critical and challenging problem of anomaly reasoning, a task complicated by the open-ended nature of anomalies encountered in real-world applications.\n\n2) To enable more fine-grained reasoning, the authors propose constructing a knowledge database that details the descriptions and causes of various anomaly types. This database is then used to synthesize both positive and negative reasoning trajectories for training a multi-modal Large Language Model.\n\n3) The model is subsequently fine-tuned and post-trained on these synthesized reasoning trajectories, ultimately achieving robust anomaly reasoning capabilities on the MMAD benchmark.\n\n4) The paper is well-structured, and its core methodology is presented in a clear and accessible manner."}, "weaknesses": {"value": "Overall, while this paper presents a practical application for visual anomaly reasoning, its contributions to the broader multi-modal language model community may be limited. The primary concerns are as follows:\n\n1) From the perspective of multi-modal model training, the proposed pipeline lacks significant novelty. It employs a standard sequence of supervised instruction tuning followed by Direct Preference Optimization (DPO), without introducing specific architectural or algorithmic adaptations tailored to the unique challenges of anomaly reasoning. Consequently, the primary contribution appears to be confined to the application domain of industrial visual anomaly detection rather than advancing general multi-modal training paradigms.\n\n2) A critical question is whether the constructed anomaly reasoning trajectories are overfitted to the MMAD benchmark. The paper does not provide evidence that the learned knowledge is generalizable to out-of-domain object categories. An evaluation on unseen object types is necessary to validate the robustness and scalability of the model's reasoning capabilities.\n\n3)  The proposed method exhibits a degradation in anomaly discrimination performance compared to the baseline model. The paper should provide a more thorough analysis of this issue. It is crucial to investigate and clarify why enhancing reasoning capabilities comes at the cost of fundamental detection accuracy.\n\n4) The paper does not sufficiently address how the object-centric knowledge base handles the context-dependent nature of anomalies. Anomaly patterns and descriptions are often specific to an object category (e.g., a \"dent\" is an anomaly for a car door but not for a piece of clay). It is unclear how the proposed method generalizes across these semantic differences. The paper should clarify whether this is managed through manual human curation for each category and discuss the implications for scaling the approach to new objects."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ejeEo6dqEJ", "forum": "qqlWHIjJ24", "replyto": "qqlWHIjJ24", "signatures": ["ICLR.cc/2026/Conference/Submission15049/Reviewer_utpA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15049/Reviewer_utpA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15049/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760830762567, "cdate": 1760830762567, "tmdate": 1762925371412, "mdate": 1762925371412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors develop two new datasets for Industrial Anomaly Detection: AD-Instruct 10K and AD-KRDPO-1K. They modify DPO to prioritize the extraction of relevant domain knowledge for user queries over a preference for the ground truth answer alone. They perform SFT to warm start their DPO. They emphasize the transferability of their approach by training on their custom datasets, based on Real-IAD, and evaluating on another Industrial Anomaly Detection dataset: MMAD. \n\nThe authors demonstrate some impressive results, beating the best closed-source models like GPT-4o (by 3.09% and 5.45% using Qwen2.5-VL-7B-Instruct and 72B-Instruct, respectively) in a 1-shot setting. The authors beat human non-experts in Industrial Anomaly Detection by more than 4% when external domain knowledge is injected, with a significantly larger margin of >17% without external domain knowledge. The authors also show that incorporating external domain knowledge can boost average scores by 2.5-7% without finetuning, and 2.5-5% after finetuning, in a one-shot setting. The authors evaluate their Anomaly Detection method on a significantly more interesting and challenging AD regime than standard by engaging not just in standard classification or spatio-temporal segmentation but by extending towards defect description, analysis, and object analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors collect their own datasets of answers formulated using incorrect knowledge premises for SFT and DPO and transfer improvements to a larger public benchmark.\n\nThe authors are able to demonstrate significant improvements over the best LLMs in a one-shot setting without domain knowledge."}, "weaknesses": {"value": "The authors do not compare their method to other competitors that selectively leverage external knowledge (like GraphRAG), nor do they consider other interpretable Anomaly Detection methods (like ECHO, which is also developed specifically for Industrial Anomaly Detection). The authors also do not provide any comparison to other fine-tuning methods, like GRPO.\n\nThe authors do not experimentally justify several modifications, including “replacing all words referring to object names with placeholder [object]”, and why DPO is conducted on the “knowledge selection path” instead of just the best answer, which is the standard approach. Further, what statistics can the authors provide to show that knowledge routing has actually improved? These modifications form the basis for the method’s novelty. Without these modifications, the authors need to explain why this paper is more than an introduction to a reformulated dataset.\n\nFrom Figure 4, it appears that omitting SFT leads to a drop of 5.82% for the average score. Meanwhile, omitting Knowledge-Routing DPO leads to a fall of 2.45%. These results would seem to indicate that KR-DPO might help, but SFT is doing most of the heavy lifting."}, "questions": {"value": "The authors should clarify why results for GPT-4o and Gemini-1.5-Pro under the 1-shot with external knowledge setting are missing from Table 2, and why their 0-shot results are also not reported in Table 3. Similarly, the omission of Human (ordinary and expert) baselines in Table 3 needs justification.\n\nThe reported numbers for Qwen2.5-VL-7B-Instruct in Figure 4 differ from those in Tables 1–3. Were these generated using a different random seed or experimental configuration? Please specify which setting (0-shot, 1-shot, or 1-shot with knowledge) corresponds to Figure 4.\n\nThe paper argues that one-class anomaly detection suffers from limited transferability due to reliance on defect-free samples from specific contexts. However, incorporating external domain knowledge could similarly introduce contextual bias. How is transferability preserved in that case?\n\nThe authors state that “logical anomalies…require reasoning based on structured domain knowledge,” yet do not discuss whether perceptual features from deep learning or image processing could complement this reasoning. Why are such methods not included in the comparisons in Tables 1–3 to demonstrate potential gains from multimodal reasoning?\n\nFinally, why are comparisons made against non-expert humans when the stated goal is to surpass expert anomaly detection models? The motivation for including this baseline should be clarified."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1bUiMyA4vD", "forum": "qqlWHIjJ24", "replyto": "qqlWHIjJ24", "signatures": ["ICLR.cc/2026/Conference/Submission15049/Reviewer_bJsW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15049/Reviewer_bJsW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15049/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761797435531, "cdate": 1761797435531, "tmdate": 1762925370966, "mdate": 1762925370966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel and well-executed study that addresses a critical limitation in current Multimodal Large Language Model (MLLM)-based anomaly detection systems. The core issue is their over-reliance on internalized visual knowledge, which hampers their ability to reason about logical or context-dependent anomalies. To overcome this, the authors propose DCR²-AD, a framework that dynamically integrates external, object-agnostic knowledge. The two key methodological contributions are highly compelling: (1) Knowledge-routed Reasoning Trajectory Synthesis (KR-RTS), which constructs a knowledge base and synthesizes erroneous reasoning trajectories by swapping in incorrect knowledge, and (2) Knowledge-routed Direct Preference Optimization (KR-DPO), a novel training objective that explicitly optimizes the model to select correct knowledge paths over incorrect ones, even when the subsequent reasoning is logically self-consistent. The experimental results are impressive, demonstrating state-of-the-art performance on the comprehensive MMAD benchmark, where the 72B model achieves 83.36%, surpassing strong base models, ordinary human performance, and previous best methods by significant margins. The ablation study clearly validates the contribution of the KR-DPO component."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of dynamic context routing is innovative. Instead of just improving the model's internal chain-of-thought, the paper creatively focuses on the critical step of knowledge selection. Formulating knowledge path selection as an integral part of the generative process, rather than a separate task, is a novel and meaningful contribution.\n\n2. The methodology is systematic, forming a complete pipeline from knowledge base construction to trajectory synthesis and preference optimization. The experiments are extensive, featuring comprehensive evaluations on the MMAD benchmark under both 0-shot and 1-shot settings, comparisons with a wide array of open-source and closed-source MLLMs, and a clear ablation study that validates the contribution of the KR-DPO component.\n\n3. The paper is well-structured and clearly written. The overall framework is effectively illustrated in Figure 2, making the process easy to follow. The technical descriptions of KR-RTS and KR-DPO, including the formalization of the loss function, are sufficiently detailed for understanding and replication."}, "weaknesses": {"value": "1. The object-agnostic knowledge base, with only 147 entries, feels limited in scale. Its construction primarily from existing datasets (MMAD, Real-IAD) raises questions about its comprehensiveness and transferability to a truly open-domain setting. A discussion on strategies for scalable and continuous knowledge acquisition is missing.\n\n2. The negative reasoning trajectories in KR-RTS are manually synthesized. While the authors emphasize logical self-consistency, there is no validation of how well these synthetic errors reflect the diverse and complex failure modes of real-world models, such as semantic distractions or nuanced rule misunderstandings. This may limit the model's robustness against real-edge cases.\n\n3. The observation that larger models benefit less from external knowledge is interesting but under-analyzed. It remains unclear whether this is due to emergent internal knowledge in larger models or simply a performance ceiling effect. A deeper investigation is crucial for understanding the method's applicability to more parameter-efficient, smaller models.\n\n4. The modification to the DPO loss function, while intuitive and empirically effective, is presented without theoretical justification. The paper would be strengthened by an analysis of the optimization properties of the KR-DPO loss or a discussion of how it differs from the standard DPO formulation from a theoretical perspective."}, "questions": {"value": "The manuscript would be strengthened by addressing several key aspects. The limited scale and scope of the current knowledge base necessitates a discussion on strategies for scalable expansion to ensure broader applicability. The realism of the synthetically generated negative trajectories requires validation against real-world failure modes. The observed relationship between model scale and external knowledge utility merits deeper analysis to determine its underlying cause. Furthermore, providing stronger theoretical justification for the KR-DPO modification and evaluating the computational overhead of the routing mechanism are crucial for assessing both theoretical soundness and practical deployability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ARl7SPLAgb", "forum": "qqlWHIjJ24", "replyto": "qqlWHIjJ24", "signatures": ["ICLR.cc/2026/Conference/Submission15049/Reviewer_RKFL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15049/Reviewer_RKFL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15049/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815476277, "cdate": 1761815476277, "tmdate": 1762925370480, "mdate": 1762925370480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a key limitation of existing MLLM-based Anomaly Detection methods—their over-reliance on internalized visual defect knowledge and poor adaptability to open-domain cross-scenario ambiguity such as logical anomalies. It proposes the DCR²-AD model, which integrates Knowledge-Routed Reasoning Trajectory Synthesis and Knowledge-Routed Direct Preference Optimization."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper explores addressing a gap in existing MLLM-AD methods that overlook external context.\n2. It trains and evaluates the 72B-scale model, providing valuable insights into how model size and external knowledge jointly influence MLLM-AD performance."}, "weaknesses": {"value": "1. The paper fails to fully explain the motivation for designing an object-agnostic knowledge base and ignores the inherent link between objects and defects. This oversight may cause model hallucinations when distinguishing defect types tied to specific objects during reasoning.\n2. While the introduction highlights the model’s ability to handle logical anomalies through context routing, the experiments do not measure the consistency between the model’s reasoning process (internal chain of thought) and final detection results. They also do not explicitly demonstrate context routing’s significant impact on logical anomaly detection, such as lacking comparative data on performance gains between logical and visual anomalies."}, "questions": {"value": "Does \"context\" refer to the external knowledge provided when the model receives input or the internal reasoning knowledge generated during the model’s thinking process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ThGohzMRTi", "forum": "qqlWHIjJ24", "replyto": "qqlWHIjJ24", "signatures": ["ICLR.cc/2026/Conference/Submission15049/Reviewer_X9sy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15049/Reviewer_X9sy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15049/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761817938298, "cdate": 1761817938298, "tmdate": 1762925370034, "mdate": 1762925370034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}