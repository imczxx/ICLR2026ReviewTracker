{"id": "TkerLrovDn", "number": 14897, "cdate": 1758245272343, "mdate": 1763700384814, "content": {"title": "Stretch Transformation for Tabular Data", "abstract": "Tabular data presents unique challenges for deep learning due to its heterogeneous nature, where features exhibit diverse distributions, scales, and statistical properties. Although recent advances have achieved strong performance on tabular benchmarks, feature transformation, a critical preprocessing step, remains largely unsupervised despite the availability of target information during training. We introduce the stretch transformation framework, which formulates feature preprocessing as an optimization problem to make the target function smoother and thus more learnable. Our framework has two variants: (1) unsupervised stretch, which uniformly redistributes feature density via minimax optimization, and (2) supervised stretch, which is the first method to systematically leverage target information for numeric features by minimizing the target function's Dirichlet energy in the transformed space. Our theoretical analysis reveals fundamental connections to existing methods, as unsupervised stretch explains why empirical CDF transformation can improve learning despite being label-agnostic, and supervised stretch generalizes target encoding with principled regularization for numeric features. Comprehensive experiments on 38 datasets from the TALENT benchmark demonstrate that supervised stretch consistently outperforms all baselines. These results show that explicitly optimizing for target function smoothness is a powerful and underexplored strategy for tabular deep learning.", "tldr": "We propose a \"stretch\" transformation framework featuring the first supervised method to make target functions smoother for numerical data, achieving SOTA performance.", "keywords": ["Tabular Machine learning", "Preprocessing"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/510e4c348d7cc9571a572042a724e1876d891b58.pdf", "supplementary_material": "/attachment/5f349de3b1e2fb760004a146e77fd04e0904c248.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents Stretch Transformation, a new framework for numerical feature preprocessing in tabular deep learning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a clear theoretical formulation that optimizes target smoothness through Dirichlet energy minimization.\n- The paper shows consistent and meaningful performance improvements while remaining simple and practical to implement.\n- The paper offers insightful connections to existing transformations (CDF/PLE), enhancing interpretability and understanding of why it works."}, "weaknesses": {"value": "While the proposed stretch transformation is theoretically well-grounded and effective for numerical features, its applicability is limited because it only operates on monotonic scalar inputs. Categorical variables, which constitute a substantial portion of many tabular datasets, are handled through standard encoding rather than benefiting from the proposed method. This raises concerns about the generality of the approach, especially on datasets where categorical features dominate or where meaningful information lies in high-cardinality or non-ordinal categories. It would be helpful to clarify the method’s impact under such conditions, and to discuss possible extensions that account for categorical semantics or joint mixed-type transformations."}, "questions": {"value": "- Could the authors clarify how the approach performs on datasets where categorical variables dominate or carry the majority of predictive signals? Additionally, could the authors suggest how the stretch principle might be extended to high-cardinality or non-ordinal categorical features, rather than relying solely on standard encodings?\n- Given that stretch transformation aims to improve learnability by reducing high-frequency variations in the target function, does the method maintain its advantages when data quality degrades? Could the authors include experiments under noisy settings, such as label noise or corrupted features?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5rfbs0ezJU", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Reviewer_DEWc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Reviewer_DEWc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551019192, "cdate": 1761551019192, "tmdate": 1762925241826, "mdate": 1762925241826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- Proposes a piecewise-linear feature transform (“stretch”) that reduces high-frequency components of the target function to make neural networks learn it more effectively.\n- Introduces two types of stretch transform: a supervised stretch that uses target information, and an unsupervised stretch that aims to maximize worst-case smoothness without targets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Provides a principled formulation of feature transformations and a quantitative smoothness measure (discrete Dirichlet energy), deriving a target-aware supervised stretch transform.\n- Stretch variants outperform prior transforms on the TALENT Tiny Benchmark 1 across multiple architectures."}, "weaknesses": {"value": "- Equations for the unsupervised transform seem incorrect. There is an inconsistency between Eqs. (7–9) in the main text and Eqs. (22–27) in the appendix. Furthermore, substituting ${|\\Delta{f} |} =C\\Delta{y} $ (from the appendix) into the discrete Dirichlet energy makes $\\mathcal{E}_{disc}$ a constant, which renders the subsequent optimization steps in the main text unclear.\n- The method operates on the marginal $f(x)=E[t|x=x_i]$. When a single feature does not meaningfully affect the target value, $f(x)$ becomes flat where the supervised stretch may be less effective. This is expected to be common in datasets with many features or strong feature interactions. A comprehensive analysis of performance versus feature count or feature interaction strength would clarify applicability. Tiny Benchmark 1 may not include enough high-dimensional datasets to support firm conclusions.\n- Feature transforms may be architecture-agnostic. Thus, evaluating on more recent architectures and boosting previous state-of-the-art models would be valuable. Additionally, the conclusion of the analysis that \"transformation preferences vary by architecture\" would benefit from varification on a broader set of datasets."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k1o1l6lb9R", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Reviewer_ddPv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Reviewer_ddPv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761818375942, "cdate": 1761818375942, "tmdate": 1762925241500, "mdate": 1762925241500, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank the reviewers for their constructive feedback and insightful questions. Below, we address the general points: we clarify the scope of our contribution, elaborate on baseline comparisons, and outline the major revisions made to the manuscript. Please refer to the responses to reviewers for more specific questions.\n\n1. Clarification on Scope and Focus on Numeric Feature Transformation\n\n   - **Focus on Numeric Feature Transformation**: Numeric features pose unique challenges due to their continuous nature and unbounded high-frequency components, which are difficult for neural networks to learn (Beyazit et al., 2023). Our Stretch Transformation framework is explicitly designed to address this bottleneck by optimizing for target function smoothness in the transformed space, bridging the gap between raw inputs and neural network inductive biases.\n   - **Orthogonality to Categorical Handling**: We view preprocessing the numeric and categorical features as orthogonal research questions. Applying continuous smoothing to discrete, unordered categorical sets is theoretically ill-posed. Therefore, our experimental design isolates the impact of numeric transformations, ensuring a rigorous evaluation of *Stretch* against established numeric baselines.\n\n2. Rationale for Baseline Selection\n\n   Reviewers 2zBF and fz56 raised questions on specific baseline choices. We kindly explain the rationale for our baseline selection as follows.\n\n   - **Tree-based Models (GBDTs)**: Tree-based approaches, such as XGBoost and CatBoost, are **theoretically invariant to monotonic transformations**. Since *Stretch* and all compared baselines (e.g., Yeo-Johnson, Quantile) are strictly order-preserving, decision trees would identify mathematically identical split points, resulting in no meaningful performance gain. Thus, they are not suitable baselines for evaluating the efficacy of monotonic transformations.\n   - **Tabular Foundation Models**: Models like TabPFN are pre-trained with specific fixed preprocessing priors (e.g., Power Transforms). Simply comparing against them is methodologically misaligned. A fair comparison would require **re-pretraining the foundation model** with Stretch Transformation to integrate it into the prior, which is computationally infeasible for this study but represents an interesting future direction. Our current focus is on empowering trainable deep neural networks (e.g., FT-Transformer, RealMLP) to learn more effectively.\n\n3. Summary of Key Revisions \n\n   - **Noise Robustness Analysis (Appendix H)** [Reviewer 2zBF and DEWc]: New experiments on 10%–50% label noise demonstrate that **Supervised Stretch maintains resilience.**\n   - **Marginal Signal Analysis (Appendix F)** [Reviewer fz56 and ddPv]: Quantitative analysis confirming that real-world tabular data is characterized by non-uniform marginal signals, validating our method's core motivation.\n   - **Performance by Feature Composition (Appendix E)** [Reviewer 2zBF and DEWc]: Stratified results show that Supervised Stretch yields additive gains even in category-dominant datasets.\n\n\nEge Beyazit, Jonathan Kozaczuk, Bo Li, Vanessa Wallace, and Bilal H Fadlallah. An inductive bias for tabular deep learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=XEUc1JegGt."}}, "id": "l7Hredwenh", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763697705622, "cdate": 1763697705622, "tmdate": 1763697705622, "mdate": 1763697705622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank the reviewers for their constructive feedback and insightful questions. Below, we address the general points: we clarify the scope of our contribution, elaborate on baseline comparisons, and outline the major revisions made to the manuscript. Please refer to the responses to reviewers for more specific questions.\n\n1. Clarification on Scope and Focus on Numeric Feature Transformation\n\n   - **Focus on Numeric Feature Transformation**: Numeric features pose unique challenges due to their continuous nature and unbounded high-frequency components, which are difficult for neural networks to learn (Beyazit et al., 2023). Our Stretch Transformation framework is explicitly designed to address this bottleneck by optimizing for target function smoothness in the transformed space, bridging the gap between raw inputs and neural network inductive biases.\n   - **Orthogonality to Categorical Handling**: We view preprocessing the numeric and categorical features as orthogonal research questions. Applying continuous smoothing to discrete, unordered categorical sets is theoretically ill-posed. Therefore, our experimental design isolates the impact of numeric transformations, ensuring a rigorous evaluation of *Stretch* against established numeric baselines.\n\n2. Rationale for Baseline Selection\n\n   Reviewers 2zBF and fz56 raised questions on specific baseline choices. We kindly explain the rationale for our baseline selection as follows.\n\n   - **Tree-based Models (GBDTs)**: Tree-based approaches, such as XGBoost and CatBoost, are **theoretically invariant to monotonic transformations**. Since *Stretch* and all compared baselines (e.g., Yeo-Johnson, Quantile) are strictly order-preserving, decision trees would identify mathematically identical split points, resulting in no meaningful performance gain. Thus, they are not suitable baselines for evaluating the efficacy of monotonic transformations.\n   - **Tabular Foundation Models**: Models like TabPFN are pre-trained with specific fixed preprocessing priors (e.g., Power Transforms). Simply comparing against them is methodologically misaligned. A fair comparison would require **re-pretraining the foundation model** with Stretch Transformation to integrate it into the prior, which is computationally infeasible for this study but represents an interesting future direction. Our current focus is on empowering trainable deep neural networks (e.g., FT-Transformer, RealMLP) to learn more effectively.\n\n3. Summary of Key Revisions \n\n   - **Noise Robustness Analysis (Appendix H)** [Reviewer 2zBF and DEWc]: New experiments on 10%–50% label noise demonstrate that **Supervised Stretch maintains resilience.**\n   - **Marginal Signal Analysis (Appendix F)** [Reviewer fz56 and ddPv]: Quantitative analysis confirming that real-world tabular data is characterized by non-uniform marginal signals, validating our method's core motivation.\n   - **Performance by Feature Composition (Appendix E)** [Reviewer 2zBF and DEWc]: Stratified results show that Supervised Stretch yields additive gains even in category-dominant datasets.\n   - **Competitiveness against GBDTs** [Reviewer 2zBF]: Additional win-rate analysis demonstrates that **Supervised Stretch helps advanced NN models become even more competitive with GBDTs**. (see specific response to Reviewer 2zBF)\n\nEge Beyazit, Jonathan Kozaczuk, Bo Li, Vanessa Wallace, and Bilal H Fadlallah. An inductive bias for tabular deep learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=XEUc1JegGt."}}, "id": "l7Hredwenh", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763697705622, "cdate": 1763697705622, "tmdate": 1763759386490, "mdate": 1763759386490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the common practice of applying unsupervised feature transformation to numeric features despite available target information, by proposing the Stretch Transformation framework. The core idea is to formulate preprocessing as an optimization problem to maximize the smoothness of the target function in the transformed space. The framework features two variants: Supervised Stretch, which minimizes the Dirichlet Energy to allocate resolution to regions of high target variability, and Unsupervised Stretch, which achieves uniform density redistribution. Experiments across 38 datasets in the TALENT benchmark claim that Supervised Stretch consistently outperforms all baselines, demonstrating substantial gains, especially in Regression tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Principled Supervised Transformation: The paper challenges the existing unsupervised preprocessing paradigm with a theoretical motivation, proposing to explicitly optimize for smoothness through Dirichlet Energy minimization (Eqn. 6) to potentially alleviate the neural network's spectral bias problem.\n\nConsistent Superiority Claim in Extensive Experiments: Supervised Stretch achieves the highest Overall Score across a broad set of 38 datasets and 5 architectures (190 total combinations), showing superiority, particularly with a \"substantial margin\" in Regression tasks (Figure 2, Figure 3).\n\nEfficiency of Unsupervised Stretch: The Unsupervised Stretch variant is mathematically shown to be equivalent to Piecewise Linear Encoding (PLE) but achieves an $O(1)$ memory footprint compared to PLE's $O(T)$, offering a clear computational efficiency advantage."}, "weaknesses": {"value": "(Novelty)Supervised Stretch is viewed as a principled refinement of Target Encoding applied to numeric features via Dirichlet Energy minimization, rather than a fundamental paradigm shift. The contribution represents a deep and creative fusion of ideas (Weak Accept level). Unsupervised Stretch's primary novelty lies in its memory efficiency ($O(1)$ vs $O(T)$) improvement over PLE, rather than a new core principle.\n\n(Technical Quality)CRITICAL FLAW: The experimental design is severely lacking as it omits strong, modern SOTA architectures. The comparison set (MLP, ResNet, DeepFM, TabNet) excludes recent, powerful Transformer/Attention-based models (e.g., FT-Transformer, TabTransformer, Saint). This omission prevents validation of whether the proposed method provides an additive, generalizable gain or merely compensates for the representational limitations of basic models like MLP. Furthermore, the method relies on independent 1D transformation for each feature, failing to account for high-dimensional feature interactions. Analysis on performance degradation with an increasing number of features ($D$) is missing, raising serious doubts about scalability and practical significance in real-world high-dimensional tabular data. Finally, the results lack quantitative statistical evidence (e.g., Metric $\\pm$ Standard Error), making it impossible to judge the statistical significance of the claimed improvements.\n\n(Significance)While the observed gains in Regression tasks (Figure 2) point to potential, the weak baseline comparison set severely limits the perceived significance. Without validation against current SOTA, the research's impact is likely restricted to a sub-optimal subset of deep learning models for tabular data.(Writing & Presentation)The core optimization process for Supervised Stretch (Section 3.4, Eqn. 13) is underexplained in the main text, with critical derivation and stability details relegated to the Appendix (A.3, B.1). This negatively impacts the clarity and self-contained nature of the main manuscript."}, "questions": {"value": "Comparison with SOTA Architectures: Please provide additional experimental results comparing Supervised Stretch when applied to latest SOTA Tabular Deep Learning architectures (e.g., FT-Transformer, TabTransformer, or Saint). This will determine if $\\phi$ offers a general, additive gain beyond compensating for the weaknesses of basic models.\n\nQuantitative and Statistical Significance: Please present concrete performance metrics (Metric $\\pm$ Standard Error) for the overall results in Table 1 and for each task/architecture, and clearly demonstrate the statistical significance (p-value) of Supervised Stretch's improvement over the strongest baselines (XGBoost, TabNet).\n\nHigh-Dimensional Scalability and Feature Interaction: Since the method uses independent 1D transformations, please provide analysis on how the benefit diminishes on datasets with a large number of features ($D$) or discuss how feature interactions are implicitly handled or why their exclusion is acceptable in practice.\n\nRigour of Dirichlet Energy Approximation: The theoretical motivation relies on an approximation valid in the small bandwidth regime ($\\sigma \\to 0$) (Eqn. 4, 5, 6). Please provide additional analysis (e.g., sensitivity analysis on $\\sigma$) to show that this approximate motivation remains rigorously valid in a typical neural network training environment."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AvnztY4zy6", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Reviewer_fz56"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Reviewer_fz56"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980266231, "cdate": 1761980266231, "tmdate": 1762925241166, "mdate": 1762925241166, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new feature preprocessing framework for deep learning on tabular data that aims to make target functions smoother and more learnable. The authors propose supervised and unsupervised “stretch” transformations that adaptively rescale numerical features through principled optimization. Extensive experiments across numerous tabular datasets show consistent gains over existing preprocessing approaches. However, it is not"}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- well presented and written\n- motivation is clear, e.g. effective data preprocessing is crucial for tabular and deep machine learning,\n- novel solution \n- adequate number of datasets for benchmarking \n- strong results of the proposed method with selected models"}, "weaknesses": {"value": "### Method\n- The proposed method supports only the transformation of numerical features. However, tabular data is usually highly heterogeneous, meaning it contains many categorical features, which presents a challenge for deep learning methods\n\n### Benchmarking\n\n- No standard machine learning benchmarks such as XGBoost, CatBoost, LightGBM, and more recent ones like TabM and TabPFNv2 are included\n\nMinor \n- No citation for the ResNet model\n\n\n###  Missing references \n\n- Erickson, Nick, et al. \"Tabarena: A living benchmark for machine learning on tabular data.\" arXiv preprint arXiv:2506.16791 (2025).\n- Van Breugel, Boris, and Mihaela Van Der Schaar. \"Why tabular foundation models should be a research priority.\" arXiv preprint arXiv:2405.01147 (2024).\n- Borisov, Vadim, et al. \"Deep neural networks and tabular data: A survey.\" IEEE transactions on neural networks and learning systems 35.6 (2022): 7499-7519.\n- Shwartz-Ziv, Ravid, and Amitai Armon. \"Tabular data: Deep learning is not all you need.\" Information Fusion 81 (2022): 84-90.\n- Hancock, John T., and Taghi M. Khoshgoftaar. \"Survey on categorical data for neural networks.\" Journal of big data 7.1 (2020): 28"}, "questions": {"value": "- I understand that your method is designed for *deep* tabular learning. However, it would be very interesting to see whether the proposed method also benefits traditional, so-called first-choice models for tabular data, such as decision-tree-based methods.\n- The method optimizes transformations only for numerical features; how does it handle real-world tables with mixed or predominantly categorical variables, and can the “stretch” idea be extended to model cross-feature interactions between numeric and categorical fields without breaking monotonicity or introducing heavy hyperparameter tuning?\n- Supervised stretch relies on out-of-fold target estimates, how robust is it to label noise, distribution shift, and choices of bin count $T$ binning, and what is its computational overhead relative to the base model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "iewO32qnRW", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Reviewer_2zBF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Reviewer_2zBF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989319370, "cdate": 1761989319370, "tmdate": 1762925240432, "mdate": 1762925240432, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new feature preprocessing framework for deep learning on tabular data that aims to make target functions smoother and more learnable. The authors propose supervised and unsupervised “stretch” transformations that adaptively rescale numerical features through principled optimization. Extensive experiments across numerous tabular datasets show consistent gains over existing preprocessing approaches."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- well presented and written\n- motivation is clear, e.g. effective data preprocessing is crucial for tabular and deep machine learning,\n- novel solution \n- adequate number of datasets for benchmarking \n- strong results of the proposed method with selected models"}, "weaknesses": {"value": "### Method\n- The proposed method supports only the transformation of numerical features. However, tabular data is usually highly heterogeneous, meaning it contains many categorical features, which presents a challenge for deep learning methods\n\n### Benchmarking\n\n- No standard machine learning benchmarks such as XGBoost, CatBoost, LightGBM, and more recent ones like TabM and TabPFNv2 are not included\n\nMinor \n- No citation for the ResNet model\n\n\n###  Missing references \n\n- Erickson, Nick, et al. \"Tabarena: A living benchmark for machine learning on tabular data.\" arXiv preprint arXiv:2506.16791 (2025).\n- Van Breugel, Boris, and Mihaela Van Der Schaar. \"Why tabular foundation models should be a research priority.\" arXiv preprint arXiv:2405.01147 (2024).\n- Borisov, Vadim, et al. \"Deep neural networks and tabular data: A survey.\" IEEE transactions on neural networks and learning systems 35.6 (2022): 7499-7519.\n- Shwartz-Ziv, Ravid, and Amitai Armon. \"Tabular data: Deep learning is not all you need.\" Information Fusion 81 (2022): 84-90.\n- Hancock, John T., and Taghi M. Khoshgoftaar. \"Survey on categorical data for neural networks.\" Journal of big data 7.1 (2020): 28"}, "questions": {"value": "- I understand that your method is designed for *deep* tabular learning. However, it would be very interesting to see whether the proposed method also benefits traditional, so-called first-choice models for tabular data, such as decision-tree-based methods.\n- The method optimizes transformations only for numerical features; how does it handle real-world tables with mixed or predominantly categorical variables, and can the “stretch” idea be extended to model cross-feature interactions between numeric and categorical fields without breaking monotonicity or introducing heavy hyperparameter tuning?\n- Supervised stretch relies on out-of-fold target estimates, how robust is it to label noise, distribution shift, and choices of bin count $T$ binning, and what is its computational overhead relative to the base model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "iewO32qnRW", "forum": "TkerLrovDn", "replyto": "TkerLrovDn", "signatures": ["ICLR.cc/2026/Conference/Submission14897/Reviewer_2zBF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14897/Reviewer_2zBF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989319370, "cdate": 1761989319370, "tmdate": 1763721589422, "mdate": 1763721589422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}