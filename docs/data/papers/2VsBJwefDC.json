{"id": "2VsBJwefDC", "number": 108, "cdate": 1756728825160, "mdate": 1763728237365, "content": {"title": "HoloPart: Generative 3D Part Amodal Segmentation", "abstract": "3D part amodal segmentation--decomposing a 3D shape into complete, semantically meaningful parts, even when occluded--is a challenging but crucial task for 3D content creation and understanding. Existing 3D part segmentation methods only identify visible surface patches, limiting their utility. Inspired by 2D amodal segmentation, we introduce this novel task to the 3D domain and propose a practical, two-stage approach, addressing the key challenges of inferring occluded 3D geometry, maintaining global shape consistency, and handling diverse shapes with limited training data. First, we leverage existing 3D part segmentation to obtain initial, incomplete part segments. Second, we introduce HoloPart, a novel diffusion-based model, to complete these segments into full 3D parts. HoloPart utilizes a specialized architecture with local attention to capture fine-grained part geometry and global shape context attention to ensure overall shape consistency. We introduce new benchmarks based on the ABO and PartObjaverse-Tiny datasets and demonstrate that HoloPart significantly outperforms state-of-the-art shape completion methods. By incorporating HoloPart with existing segmentation techniques, we achieve promising results on 3D part amodal segmentation, opening new avenues for applications in geometry editing, animation, and material assignment.", "tldr": "", "keywords": ["3D Generation", "3D Segmentation", "3D Part"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/85098043111bc1e001cd97ebaccb1b91ae648346.pdf", "supplementary_material": "/attachment/7ef5c745e8505fa14c464217d7862175850fca5d.zip"}, "replies": [{"content": {"summary": {"value": "HoloPart introduces a novel diffusion-based model for 3D part shape completion and formally introduces the 3D part amodal segmentation task with two benchmarks (ABO and PartObjaverse-Tiny). It outperforms SOTA shape completion methods on these two benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The 3D part amodal segmentation task and the ability to infer occluded 3D geometry of less complex geometric structures (i.e., Parts) are important for 3D understanding and can be beneficial for broad applications.\n2. HoloPart outperforms competitors on the benchmarks on ABO and PartObjaverse-Tiny datasets."}, "weaknesses": {"value": "## Major Weaknesses\n1. In the two-stage pipeline, the 3D part segmentation method is crucial for final performance. SAMPart3D is not a very robust method. The segmented part definitions are not in control and often require additional merging for evaluation. Missing parts or incompatible segmented part definitions will significantly impact performance. So I don't think it is a very good initialization for the benchmark evaluation.\n\n## Minor Weaknesses\n1. Leveraging 3D generative priors indeed overcomes the limitations of scarce training data. However, it will also introduce their failure modes and may still fail on challenging cases for current 3D shape diffusion models."}, "questions": {"value": "1. Based on weakness 1, given a rendered image of a mesh having 3D part annotations, could we use the 2.5D geometry of this view as the initialization for part completion (only consider visible parts in this view)?  It is a more challenging part-completion scenario. Could you demonstrate HoloPart's performance on this 2.5D part geometry on a small scale (e.g., 20-50 examples)?\n\n2. It would also be valuable to provide additional qualitative and quantitative results of HoloPart on car and airplane categories (68 meshes in total) in the 3DCompat++ [1] dataset to show HoloPart's generalization ability in outdoor objects and with more semantically meaningful part definitions. 3DCompat++ has rendered images, and it would be easy to extract the 2.5D part geometry.\n\n[1] 3DCOMPAT++: A comprehensive dataset for 3D object understanding with fine-grained part annotations"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zvWfXDO8tZ", "forum": "2VsBJwefDC", "replyto": "2VsBJwefDC", "signatures": ["ICLR.cc/2026/Conference/Submission108/Reviewer_BYbA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission108/Reviewer_BYbA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845634721, "cdate": 1761845634721, "tmdate": 1762915452594, "mdate": 1762915452594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Response"}, "comment": {"value": "We sincerely thank the reviewers for their time and constructive feedback. We have revised the paper to address the concerns, highlighting changes in the updated manuscript. Below, we address the common questions raised by the reviewers:\n\n1. **Two-Stage Design.**\n3D Part Amodal Segmentation is a challenging task that demands both semantic understanding (segmentation) and geometric inference (completion of invisible parts). This capability is particularly vital for **generated or scanned objects**, which often exist only as **\"holistic surface shells\"** and are inherently incomplete. Solving this end-to-end is extremely difficult due to data scarcity and optimization complexity. Our two-stage design strategically decomposes this into manageable sub-problems. This modularity is a deliberate design choice, not a limitation: it allows HoloPart to flexibly integrate with any state-of-the-art surface segmentation model. As demonstrated in Fig. 5, our method seamlessly adapts to various upstream models (SAMPart3D, SAMesh, PartField, and P3-SAM), ensuring the framework remains effective as segmentation techniques evolve.\n\n2. **Robustness to Segmentation Noise.**\nTo address concerns regarding reliance on mask quality (e.g., handling thin structures or artifacts), we incorporate mask augmentation strategies (random noise, erosion, and dilation) during training. This forces HoloPart to learn robust shape priors rather than over-fitting to the input mask. As shown in Fig. 15, our model successfully reconstructs intricate, thin structures (e.g., glasses) despite imperfect input segments. Furthermore, in Fig. 6, HoloPart generates clean and complete part geometries even when given noisy 2.5D masks from the 3DCoMPaT++ dataset, and the quantitative results are shown in Tab. 2. These results confirm that our generative prior effectively acts as a regularizer, correcting and completing parts even when Stage-1 outputs are imperfect.\n\n3. **Generalization Capabilities.**\nWe provide comprehensive evidence of our model's generalization:\n\n- Performance on 2.5D Completion Tasks: We present a comparison with baselines on the 2.5D completion task in the new Table 2. HoloPart significantly outperforms baselines (PatchComplete, DiffComplete, SDFusion), demonstrating superior generalization to outdoor objects and robust handling of sparse 2.5D inputs.\n\n- Generalization to Novel Part Compositions: We highlight HoloPart's strong zero-shot generalization beyond the training domain. As shown in Figure 5 (revised), we evaluate our model on scanned objects from OmniObject3D and generated objects, which possess significantly different distributions from our training data. HoloPart seamlessly integrates with zero-shot segmentation models to produce high-quality parts. Notably, in the robot example in Figure 5, HoloPart successfully reconstructs precise mortise-and-tenon joint structures at the connections, demonstrating its capacity to infer functional geometry in novel compositions."}}, "id": "wuVWShEvMr", "forum": "2VsBJwefDC", "replyto": "2VsBJwefDC", "signatures": ["ICLR.cc/2026/Conference/Submission108/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission108/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission108/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763728702741, "cdate": 1763728702741, "tmdate": 1763728925167, "mdate": 1763728925167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes HoloPart, a framework that decomposes a complete 3D object into multiple complete and coherent 3D parts. The pipeline first employs SAMPart3D to obtain semantic mesh segmentation masks, and then feeds each incomplete segmented mesh into the proposed model, which reconstructs the complete 3D part meshes.\n\nThe contributions lie primarily in the architectural design of the proposed model and the construction of a new dataset for training and evaluation. The method is compared against state-of-the-art shape completion approaches — PatchComplete, DiffComplete, and SDFusion — and achieves superior performance across Chamfer Distance, IoU, F1-Score, and Success Rate metrics. Ablation studies further validate the effectiveness of the Context-Aware Attention, Local Attention, and the influence of the Guidance Scale."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles a valuable and underexplored problem, focusing on the generation of complete 3D parts rather than full-object completion.\n2. The construction of a dedicated dataset for 3D part completion is a useful contribution that can facilitate future research in this direction."}, "weaknesses": {"value": "1. The approach relies heavily on existing 3D part segmentation techniques, which could limit its robustness when segmentation quality is poor.\n2. The task formulation assumes the input is a complete object mesh, yet the pipeline includes VAE compression and flow matching in latent space. It is unclear whether the reconstructed meshes remain geometrically consistent with the original object after decoding."}, "questions": {"value": "1. Since the pipeline encodes the 3D mesh via a VAE, performs flow matching in latent space, and then decodes it back, does the reconstructed mesh deviate geometrically from the original input mesh? If so, how do the authors mitigate or correct such deviations?\n\nThings to improve the paper that did not impact the score:\n- Table 2: The Success Rate metric is mentioned in the text but not shown in the table — please clarify where it is reported."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aTwBkAlfx9", "forum": "2VsBJwefDC", "replyto": "2VsBJwefDC", "signatures": ["ICLR.cc/2026/Conference/Submission108/Reviewer_LGMD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission108/Reviewer_LGMD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928327725, "cdate": 1761928327725, "tmdate": 1762915452467, "mdate": 1762915452467, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a 2 step procedure to do 3D amodal segementation. Stage 1:  it uses an off-the-shelf approach to segment out the semantically consistent but visible portions of the occluded object.  Stage 2:  uses a local and global context aware diffusion method to  complete the occluded 3d subobject. Additionally they also propose a data pipeline strategy to curate  3D shapes with labeled semantic sub parts and their full (amodal) geometry for training and evaluation"}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1) The central idea of completing the occluded 3d sub part with a local and globally conditioned diffusion model is quite appealing\n\n2) The datapipeline strategy to curate paired data is simple and easy to engineer and would be quite useful for future models.\n\n3) Evaluate their model for various settings and compare to various baselines."}, "weaknesses": {"value": "1) Reliance on segmentation quality of the off-the-shelf model in stage-1. Difficulties would arise due to some type of domain shift, due thin structures or heavy occlusions that prevent the stage 1 model from being able to segment the sub part well.\n\n2) In general two stage training pipelines are a bit clunky as it requires two models to be trained unlike end-to-end trained models."}, "questions": {"value": "I am curious to know about the compute comparison between the proposed model and baselines, in terms of flops/training time/ number of model parameters."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9JqMPpo7bx", "forum": "2VsBJwefDC", "replyto": "2VsBJwefDC", "signatures": ["ICLR.cc/2026/Conference/Submission108/Reviewer_WfB3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission108/Reviewer_WfB3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000866477, "cdate": 1762000866477, "tmdate": 1762915452316, "mdate": 1762915452316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces 3D part amodal segmentation, a new task aimed at decomposing a 3D shape into its complete, semantically meaningful parts, including portions that are occluded. The authors propose HoloPart, a novel diffusion-based generative model that takes incomplete part segments and completes them by leveraging both local part geometry and global shape context."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The task presented in the paper is well-motivated and practical.\n2. The dual local and context-aware attention mechanisms is a good design for balancing fine-grained part detail with overall shape consistency.\n3. The presented results look good."}, "weaknesses": {"value": "1. It is unclear how well the model generalizes to novel part compositions not well-represented in the finetuning data, as the completion may be heavily reliant on the part-whole priors learned from the ABO and Objaverse datasets.\n2. The method's handling of semantic ambiguity is not discussed. For instance, if a mask incorrectly bridges two distinct semantic parts (like a chair leg and the seat), the model's behavior is unpredictable.\n3. The generative completion process can introduce geometric hallucinations that deviate from the original shape's implicit structure. For instance, in Figure 13 (the turkey), the completed parts appear to add new geometry not implied by the original surface, and the final merged object shows significant inter-part overlaps.\n4. There is a disconnect between the paper's \"amodal segmentation\" framing and its core \"part completion\" contribution. The method is entirely dependent on the quality of the initial segmentation and lacks any mechanism to refine, correct, or handle the noisy and often semantically incorrect outputs of the first stage, thus not fully addressing the end-to-end segmentation problem. Changing the narrative of the paper would make the contribution more aligned."}, "questions": {"value": "Please see the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ozK6TZMuEZ", "forum": "2VsBJwefDC", "replyto": "2VsBJwefDC", "signatures": ["ICLR.cc/2026/Conference/Submission108/Reviewer_BTkd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission108/Reviewer_BTkd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762068991439, "cdate": 1762068991439, "tmdate": 1762915452207, "mdate": 1762915452207, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}