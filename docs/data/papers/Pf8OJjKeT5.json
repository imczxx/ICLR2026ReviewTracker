{"id": "Pf8OJjKeT5", "number": 13295, "cdate": 1758216106964, "mdate": 1759897448032, "content": {"title": "MindAttention: Foveated Visual Encoding for Neural Response Synthesis and Concept-selective Region Localization", "abstract": "Synthesizing brain activity via generative models to localize concept-selective cortical regions represents a promising advancement beyond traditional experimental paradigms. However, existing methods largely overlook the spatial selectivity of visual attention -- when visual stimuli contain multiple central targets. The spatial selectivity of human attention significantly reduces the signal intensity of unattended targets during neural encoding, leading to suppressed neural representations and consequently causing bias or failure in data-driven neural concept localization. To address this *synthesis-attention misalignment* problem, we propose *MindAttention*, a generative brain visual encoding framework that anchors concept representation to foveal gaze position. Grounded in the neuroscientific principle that only high-acuity foveal input reliably drives semantic-level cortical responses, we thereby construct a gaze-conditioned generator: simulated activation of a target concept is triggered only when the corresponding object falls within the foveal field. Experiments show that *MindAttention* significantly outperforms existing generative methods in localization accuracy. The incorporation of spatial attention constraints endows the framework with neuro-mechanistic interpretability and cognitive plausibility, establishing a more reliable and biologically grounded paradigm for data-driven exploration of brain concept maps.", "tldr": "", "keywords": ["Brain Encoding"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cd2fd6166aad5c14a948fd8367b2be174a81e146.pdf", "supplementary_material": "/attachment/4ecc37b862e75ea534f2f5d6c48bfa9ba929fe0b.zip"}, "replies": [{"content": {"summary": {"value": "The authors observe that current methods that reconstruct or synthesize brain activity from visual input often treat all image regions equally, ignoring how human vision is centered around the fovea. They argue that as a result, these models fail to capture the spatial bias of real neural responses (e.g., not all brain regions are equally important and that attention is selectively allocated to specific regions). The authors claim that modeling this foveated attention explicitly can make visual encoding more biologically accurate and improve both prediction quality and interpretability. For this claim ,they provide experimental results.\n\nDisclaimer: I am not an expert in this field. While I feel reasonably well suited to review this paper I am not perfectly aware of the literature and baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors provide motivation for their approach from previous research in the neuroscience domain \n- The method improves upon baselines on relevant benchmarks\n- A side effect of their modeling are interpretable attention maps, which can help analyzing, which image regions are most relevant for neural responses"}, "weaknesses": {"value": "- I found the abstract hard to follow. It was not clear to me what the core difference between the proposed method and prior methods is after reading it.\n- Very strong claims: \"endows the framework with neuro-mechanistic interpretability and cognitive plausibility, establishing a more reliable and biologically grounded paradigm for data-driven exploration of brain concept maps.\" that would require stronger evidence.  \n- The model predicts gaze internally but does not validate this against real eye-tracking data, making biological claims less convincing (connected to strong claims).\n- Evaluation is limited to a single dataset and subject group (again very strong claims for this sort of evidence)\n- It is unclear to me how much of the gain comes from foveation versus the larger diffusion backbone. In general, gains in the ML literature are often difficult to pinpoint, and methodological innovation is unfortunately often not the reason for improvement. Results in Table 2 appear to show no considerable improvements"}, "questions": {"value": "- Have you compared your predicted gaze locations to real fixation data? Could such experiments be provided?\n- How reliable is synthetic fMRI as a substitute for real data when used for localization tasks? Are there literature results on that?\n- Did you test whether the foveation module still helps if the diffusion generator is replaced by a simpler decoder? Is it possible to control for architecture choices in comparison with baselines?\n- How does the model perform across different subjects without retraining? Can it generalize to new subjects (e.g., did you test wether leaving one subject out of the training data still enables accurate predictions on their data)?\n- The authors list considerable amount of prior work on this topic. However, the paper provides only limited baseline comparisons. Is there any specific reason why approaches from prev. papers have not been benchmarked?\n\nI am very open to increasing my score if my concerns are addressed (not necessarily in the form of experiments, arguments are also sufficient)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "cu5FWg0xL8", "forum": "Pf8OJjKeT5", "replyto": "Pf8OJjKeT5", "signatures": ["ICLR.cc/2026/Conference/Submission13295/Reviewer_3XiH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13295/Reviewer_3XiH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761388348120, "cdate": 1761388348120, "tmdate": 1762923963168, "mdate": 1762923963168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The current paper introduces a fovea-grounded generative brain encoding framework called MindAttention, to address the so-called synthesis-attention misalignment, i.e. the mismatch between conventional encoding models that process entire visual scenes uniformly and the spatially selective processing of the human visual system driven by attention and foveal versus peripheral sampling. The proposed framework combines a fovea-guided visual encoder, a fMRI variational autoencoder, and a diffusion-based conditional generator to synthesize fMRI data based on an image input. The authors demonstrate that reconstructed images based on this synthetic fMRI capture both low-level structure and higher-level semantics, outperforming existing generative encoding methods. Moreover, by incorporating predicted foveal coordinates from the visual encoder together with object detection, the framework facilitates more precise localization of concept-selective cortical regions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-situated within the body of previous works, bridging prior research from both the machine learning domain and the neuroscientific and psychophysical background. \n- The paper makes both methodological and empirical contributions, introducing a fovea-grounded diffusion-based brain encoding framework and demonstrating improved synthetic fMRI and concept-selective region localization accuracy.\n- The paper offers contributions to both machine learning and neuroscience: it demonstrates that fovea-grounded generative models enhance the quality of synthetic fMRI generation, and it provides neuroscientific evidence that foveated attentional spatial sampling plays a critical role in forming semantically meaningful visual representations."}, "weaknesses": {"value": "Main conceptual concern:\n- The introduction sets the problem of synthesis-attention alignment, as affected by gaze. However, the neural data used (Natural Scenes Dataset) in the current paper is collected under fixed-gaze conditions. Although the implementation of spatial gating through a foveated field (using a Gaussian) may partially mitigate this alignment problem -  as supported by [1], which shows that spatial based features selection based on ganglion cell sampling generally improves encoding performance in the context of EEG - the capacity of the model’s attentional center to shift spatially differs from the human viewing conditions under which the data were obtained. Could the authors clarify the current setup in the context of this discrepancy?\n\nOther weaknesses are primarily technical or structural in nature and, if adequately addressed, could substantially increase the quality of the paper, making it suitable for acceptance:\n- Definitions of some evaluation metrics are insufficiently defined. Based on the text, one could infer that voxel-level may refer to pixel-level reconstruction accuracy (in which case the term “voxel-level” might be misleading, as it rather more closely reflects low-level image similarity), while semantic-level may denote a category-level match score between reconstructed and original images. However, these definitions are not clearly stated in the manuscript. Similarly it remains unclear from the main manuscript how performance for localization of concept-selective regions was defined (Table 3). Additionally, maintaining consistency in definitions would improve clarity. For example, section 3.2 refers to a predictor, Figure 2 to a residual CNN backbone, and Appendix C to a Central Fovea Attention mechanism.\n- Results of ablation studies (Table 2) and localization of concept-selective regions (Table 3) only include one participant instead of four (as in Table 1). Could you include the results of the remaining subject here?\n- There appears to be an underemphasis on the results related to the improved localization of concept-selective regions achieved through the proposed framework. Although this aspect is highlighted in the title, abstract and conclusion, it is not clearly stated among the paper’s contributions, nor is its implementation sufficiently detailed in the main text. Given its potential as a highly relevant application of the proposed approach, the paper may benefit from discussing this aspect in more detail. Furthermore, a clearer description of how the localization is implemented, i.e. how predicted foveal coordinates from the visual encoder are combined with object detection, would help the reader better understand the reported results for MindAttention (selected) in Table 3.\n- Results could be presented more clearly with descriptive subsection titles to really drive the message home. For example, Section 5.1 could highlight “MindAttention demonstrates high-fidelity synthetic fMRI at voxel and semantic levels”. Section 3.1 seems somewhat redundant with the Introduction, and Section 6 might be better integrated into the Results.\n\n[1] Mueller, N., Scholte, H. S., & Groen, I. I. (2024). Spatial sampling of deep neural network features improves encoding models of foveal and peripheral visual processing in humans. bioRxiv, 2024-08."}, "questions": {"value": "- In the Introduction, the authors state that “the performance gap widens in complex, multi-object scenes where attentional competition is high”.  However, it is not clear where this effect is measured or quantified in the Results. Could the authors clarify whether this claim is supported by their analyses, or indicate where it is shown?\n- Could the authors elaborate on how modulation of the [CLS] token through the global context weight affects performance on both voxel-level and semantic-level metrics? Is it the provided semantic context that causes high fMRI synthesis accuracy? Additionally, how can the biological plausibility of this implementation be justified?\n- Table 1 presents two versions of the MindAttention model with different thresholded sigma values. Could the authors clarify how and why the cut-off of 0.2 was chosen, and how many observations fall within this range? Additionally, how can it be explained that including observations with sigma between 0 and 0.2 improves fMRI synthesis accuracy and what neuroscientific implications does this have?\n- Is it correct that for voxel-level measurements in Table 1 Pearson is associated with an upwards arrow and MSE with a downwards arrow, while Table 2 shows the opposite?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CegX3jVjMZ", "forum": "Pf8OJjKeT5", "replyto": "Pf8OJjKeT5", "signatures": ["ICLR.cc/2026/Conference/Submission13295/Reviewer_PaZ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13295/Reviewer_PaZ1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923281190, "cdate": 1761923281190, "tmdate": 1762923962828, "mdate": 1762923962828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a generative framework for synthesizing neural responses to visual stimuli, with its primary claimed innovation being the integration of a \"foveated attention\" mechanism to better mimic the biological principles of human vision. While the engineering is sophisticated, a critical analysis raises significant questions about both its novelty and the validity of its core premise. The central idea of disentangling spatial (\"where\") and feature-based (\"what\") information in neural encoding is not new, echoing earlier work by Klindt et al. (2017), and the specific implementation of a Gaussian-factorized readout for a receptive field was previously proposed by Lurz et al. (2021). More fundamentally, the entire justification for a dynamic attention mechanism is undermined by the choice of the Natural Scenes Dataset (NSD) for validation. In the NSD experiment, participants were explicitly instructed to maintain a fixed gaze on a central point, a condition that was successfully verified with eye-tracking. This experimental constraint directly contradicts the paper's motivation of modeling a shifting foveal focus, making the utility of predicting a \"foveal gaze position\" highly questionable in this context. Although the model demonstrates improved quantitative performance over baselines, the success cannot be confidently attributed to its purported ability to model natural foveal vision, as this behavior was absent in the data; instead, the performance gains may arise from other architectural choices or the model's ability to learn a static, center-biased spatial weighting. Consequently, the work is best viewed as an incremental advancement that skillfully packages prior concepts into a new generative architecture, rather than a novel framework whose success is supported by its central biological claims."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The framework's performance is rigorously evaluated against multiple representative baselines across a wide array of metrics, covering both low-level voxel-wise correlations and high-level semantic alignment. Furthermore, the paper validates the practical utility of its synthetic fMRI data on a challenging downstream task: the localization of concept-selective brain regions, where it again demonstrates superior performance. The inclusion of detailed ablation studies methodically justifies the contribution of each architectural component, lending credence to the overall design.\n1. The proposed model is shown to consistently and significantly outperform existing baseline methods in both voxel-level and semantic-level evaluations, with performance metrics that closely approach the empirical upper bound set by ground-truth fMRI data.\n2. The authors employ a robust evaluation strategy that not only measures pixel- and voxel-level accuracy but also assesses the semantic fidelity of the synthesized brain activity using multiple, diverse metrics.\n3. The work successfully demonstrates that the high-quality synthetic fMRI can be used to accurately predict the locations of functionally specialized brain regions, validating its potential as a tool for computational neuroscience research."}, "weaknesses": {"value": "The work's primary weaknesses stem from a significant disconnect between its core motivation and its experimental validation, alongside overstated claims of novelty for its central components. These issues challenge the interpretation of the model's success and its claimed contributions to the field.\n1. The most critical weakness is the use of the Natural Scenes Dataset (NSD) to validate a model built around a dynamic foveal attention mechanism. The NSD protocol explicitly required participants to maintain fixation on a central point, and the dataset's own high-quality eye-tracking data confirms that participants did so successfully. This experimental design directly contradicts the paper's central premise of modeling how the brain processes information from shifting foveal gaze. The model was therefore not tested under the conditions it was designed for, making it impossible to conclude that its success is due to accurately capturing a dynamic attentional process. The mechanism may have simply learned a static, center-biased spatial filter, which is a much simpler and less novel concept than what the authors claim.\n2. The paper presents its \"fovea-guided\" encoder as a key innovation, but the foundational concepts have clear precedents in prior literature. The idea of factorizing a neural encoding model into \"what\" (feature) and \"where\" (spatial) components was established by works such as Klindt et al. (2017). Furthermore, the specific implementation of a Gaussian-factorized readout to model a neuron's spatial receptive field was previously introduced by Lurz et al. (2021). While the integration of these ideas into a new generative framework is a valid engineering contribution, the paper frames them as more foundational innovations than they are, thus overstating its conceptual novelty.\n\n[1] DA Klindt, AS Ecker, T Euler, and M Bethge. Neural system identification for large populations separating “what” and “where.”. Advances in Neural Information Processing Systems, 2017.\n\n[2] Konstantin-Klemens Lurz, Mohammad Bashiri, Konstantin Willeke, Akshay K Jagadish, Eric Wang, Edgar Y Walker, Santiago A Cadena, Taliah Muhammad, Erick Cobos, Andreas S Tolias, et al. Generalization in data-driven models of primary visual cortex"}, "questions": {"value": "1. Did the authors z-score the data? \n2. Is the data averaged across repeats?\n3. Can the authors provide inflated map explained variance plots, and those normalized by the noise ceiling?\n\nOverall the paper is significantly lacking, and does not provide strong evidence that the work is a better encoder than prior work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "e8zHucut75", "forum": "Pf8OJjKeT5", "replyto": "Pf8OJjKeT5", "signatures": ["ICLR.cc/2026/Conference/Submission13295/Reviewer_LZLq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13295/Reviewer_LZLq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988081232, "cdate": 1761988081232, "tmdate": 1762925579499, "mdate": 1762925579499, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper emphasizes the critical role of visual attention and foveation in predicting brain responses to visual stimuli. By explicitly incorporating fovea-centered information, the proposed MindAttention framework aligns the visual encoding process with biology. This attention-guided representation allows the model to generate more accurate and semantically meaningful fMRI predictions, reflecting how the human brain prioritizes attended regions over peripheral details. Despite the limitations of limited scope of generalization dataset, the paper’s novel idea and the identified problem in brain encoding/decoding should be passed on to the community."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is novel in terms of framing the fovea-guided brain decoding problem. It provides a novel and useful direction for more realistic brain decoding.  The computationally learned fixation parameters (mu_x, mu_y, sigma) offer an interpretability. \n- The paper shows that conditioning the diffusion decoder on foveated embedding yields consistently high voxel-wise correlations (+3-4%) and semantic alignment (+5%) vs non-foveated baselines. \n- When human analysis images, it’s not a static process and the fovea is not fixed. I wonder if the model could incorporate multiple fovea locations and jointly influence the encoding representations and whether it would further improve the results and make it more biologically plausible."}, "weaknesses": {"value": "- Evaluation scope is limited to NSD dataset; cross-subject generalization would further improve the paper’s credibility. \n- Although due to the time constraints, it’s not plausible to perform this, but I wonder if the same fovea can be used in video instead of static images."}, "questions": {"value": "Could you also decode the fovea location from the predicted fMRI response and see if they actually align with the predicted fovea location in the encoder?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "H4tZxcsIIE", "forum": "Pf8OJjKeT5", "replyto": "Pf8OJjKeT5", "signatures": ["ICLR.cc/2026/Conference/Submission13295/Reviewer_hm28"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13295/Reviewer_hm28"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762246477836, "cdate": 1762246477836, "tmdate": 1762923962117, "mdate": 1762923962117, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}