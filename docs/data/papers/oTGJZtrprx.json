{"id": "oTGJZtrprx", "number": 24676, "cdate": 1758359178558, "mdate": 1759896755367, "content": {"title": "Hiding in the Phase: A Provably Robust Watermark for Diffusion Models", "abstract": "Recent advancements in generative AI, particularly diffusion models, have necessitated robust methods for image watermarking. While state-of-the-art semantic watermarks offer impressive robustness, they share a fundamental, unaddressed vulnerability: their reliance on a systematic and uniformly applied structural constraint. This architectural uniformity creates a predictable attack surface, leaving them susceptible to mechanism-targeted attacks that exploit the embedding method's operational principles rather than the secret key. To address this critical vulnerability, we introduce Phase-Quantization Invisible Marking (PQIM), a novel, training-free framework that shifts the paradigm to structural heterogeneity and provable robustness. PQIM's strength is twofold. First, it introduces a secret subspace paradigm, using a cryptographic key to generate a sparse, pseudo-random embedding space that lacks a universal, predictable structure. Second, its distributed encoding architecture, operating exclusively on the phase spectrum, comes with the first information-theoretic proof of robustness for a semantic watermark, guaranteeing an exponential reduction in bit error rate. Extensive experiments demonstrate that PQIM consistently outperforms existing methods against a wide array of attacks, including a targeted latent perturbation attack designed to validate our hypothesis. By replacing predictable structures with a key-dependent secret subspace and providing a mathematical guarantee of resilience, PQIM establishes a new standard for secure and reliable watermarking in generative models.", "tldr": "We identify a vulnerability in existing watermarks: their reliance on a uniform structural constraint, making them susceptible to mechanism-targeted attacks. PQIM circumvents this by embedding information in phase domain.", "keywords": ["Diffusion Models", "Watermark"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2e31d86ee2952ec43b129778d8f01713353d94b1.pdf", "supplementary_material": "/attachment/e94c0eeb41666cbb073d1fc34dc979192db06da9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Phase-Quantization Invisible Marking (PQIM), a robust and provably secure watermarking method for diffusion models. Addressing the vulnerability of existing techniques that use uniform, predictable embedding patterns (which are prone to targeted removal attacks), PQIM leverages a cryptographic key to pseudo-randomly select regions in the phase spectrum of the noise latent for watermark embedding. This structural heterogeneity makes the watermark difficult to locate or remove without the key. The approach guarantees reliability through information-theoretic analysis and preserves image quality by restricting modifications to mid-frequency phase components. Extensive experiments demonstrate that PQIM outperforms previous state-of-the-art in both robustness to common and advanced attacks and in maintaining high perceptual fidelity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Originality:**\n\nPQIM presents a novel phase-based watermarking strategy for diffusion models, making use of cryptographic keys to ensure robustness and security against targeted attacks.\n\n**Quality:**\n\nMethodology is thorough, with theoretical guarantees and extensive experiments showing strong robustness and fidelity compared to prior approaches.\n\n**Clarity:**\n\nThe paper explains the motivations, methods, and findings with clear logic supported by diagrams and empirical results.\n\n**Significance:**\n\nPQIM advances watermarking in generative AI by offering a training-free, provably secure, and high-fidelity solution, which is timely for increasing demands in content authentication and provenance."}, "weaknesses": {"value": "1. White-box Extraction Requirement. From the Section 3.2 (Watermark Extraction), Conclusion, the extraction protocol currently relies on DDIM inversion using access to the original diffusion model. This white-box assumption may not suit real-world use when the model weights or architecture are inaccessible. Extending to black-box recovery or ensemble approaches would broaden usability.\n2. While PQIM is robust to most distortions and attacks, it struggles under strong Gaussian and salt-and-pepper noise, with detection rates and bit accuracy dropping significantly. Improving noise resilience through advanced decoding or training is an unresolved challenge highlighted in quantitative tests.\n3. PQIM’s ability to embed long messages is limited by the number of frequency bins available and the redundancy needed for robustness. When using the largest payloads (e.g., 512 bits), the bit accuracy and reliability gradually degrade, which constrains applications needing large metadata or cryptographic tags."}, "questions": {"value": "1. Can the authors elaborate on possible improvements or alternative encoding strategies to increase the maximum recoverable payload size, while maintaining robustness and fidelity? Are there practical ways to enable higher capacity for real-world metadata or secure tags beyond the tested 512 bits?\n2. Is it possible to implement watermark extraction in scenarios where the diffusion model is inaccessible (“black-box” settings), or via model-agnostic techniques? If so, what future directions or adaptations could extend PQIM to broader practical contexts, especially for proprietary models?\n3. Given the notable reduction in watermark accuracy under strong Gaussian or salt-and-pepper noise (Appendix A.4, Table 3), could the authors propose further improvements in noise-aware decoding or preprocessing? Would retraining or adversarial robustness techniques meaningfully boost reliability for these edge cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vzf24ysx9T", "forum": "oTGJZtrprx", "replyto": "oTGJZtrprx", "signatures": ["ICLR.cc/2026/Conference/Submission24676/Reviewer_gnUq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24676/Reviewer_gnUq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815068284, "cdate": 1761815068284, "tmdate": 1762943160212, "mdate": 1762943160212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper showed an important weakness in current semantic image watermarking schemes and proposed a new watermarking scheme for Stable Diffusion models as an alternative to the current PRC, Gaussian Shading, etc. These current schemes in semantic watermarking all share one common vulnerability: dependence on systematic and uniform structural rules. Each semantic scheme, depending on its specific structure, impose different types of susceptibilities, leaving possibility for a developed attack surface. \n\nThe authors provide a novel alternative, PQIM, which writes bits into the phase of the initial noise while keeping the amplitude statistics the same, ensuring the latent and image quality are preserved. They use a secret key to pick a sparse set of frequency locations, where each bit is spread across many of them. These bits are then read back by DDIM inversion with a quantize-and-vote decoder.\n\nKey results: PQIM beats Tree-Ring and Gaussian Shading on most attacks (JPEG, blur, resize, regeneration, learned codecs) while keeping image quality, and the watermark survives under a targeted latent-perturbation test; the few cases where others do better are heavy Gaussian or salt-and-pepper noise, where GS/Tree-Ring keep higher TPR, but PQIM still recovers bits. Their claim is that overall, this scheme outperforms most existing schemes across a broad range of advanced attacks, although some specific schemes may outperform in some specific attacks. \n\nMain contributions: a keyed secret subspace that avoids uniform structure, a phase-only QIM encoder with distributed redundancy and quantize-and-vote decoding, plus an analysis showing the PQIM bit error rate drops exponentially with more redundancy. They also provided a perceptual watermark version (a watermarker that hides a whole bit message rather than 1/0 bit, i.e. a stenography scheme).\n\nThe authors conclude that global, uniform structured schemes expose a predictable attack, whereas keyed phase-only subspace shrinks the predictable attack surface."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "There are some strengths of this paper. They do provide a functional, mostly secure, watermarking scheme, with satisfactory quality results. Their claim that current watermarkers have a uniform, predictable attack surface appears solid and aligns with their reasoning.\n\nIn terms of quality, PQIM appears to perform quite well, clearly outputting the perceptually closest result to the original. The same is apparent with the perceptual tuning scheme. \n(However, I would like to specify the following: PQIM having a closer prompt to original is due to how it perturbs the generation pipeline; other schemes perturb the generation more, such as PRC where the watermark is embedded into the generation token. Contrary to what the paper implies, resembling the original generated image is not the goal of AI image generation. As long as it matches the prompt with quality, it succeeds.)\n\nMain contributions: a keyed, phase-only QIM watermark for diffusion latents, a simple quantize-and-vote decoder, a constraint on bit error, and a proof that more redundancy lowers BER. They also provided insight to a fundamental weakness regarding current watermarking schemes. The authors devised an acceptable scheme, but QIM-style embedding and majority-vote guarantees are already recognized. The same goes for invert-and-detect pipelines, which are already used in Tree and GS."}, "weaknesses": {"value": "I did not find their claims about its “superior consistency” and “consistently outperforms existing methods” to be conclusive enough. Firstly, for the basic attacks, the results shown in the comparative does not show the scheme to conclusively or continually outperform the best of the other schemes. It seems they show two contradicting tables. According to the table 1 in the main paper, PQIM doesn’t have a TPR @ 1%FPR rate less than 90%. However, we can see that it performs inadequately across many a few different attacks when compared to GS (Gaussian Shading) or Tree (Tree-Ring), especially Gaussian and SP Noise, in table 3 in the appendix. The authors also state that PQIM lacks in these forms of attacks, showing that it does not have superior consistency nor consistently outperforming other methods. Although this isn’t as significant of a margin, in section A.5 of the appendix, they show it is outperformed by Gaussian Shading and Tree-Ring in two out of three stable diffusion attacks. \nThus, paper’s claim of “consistently outperforms” does not hold across all attacks (beaten by GS/Tree-Ring on heavy Gaussian, salt-and-pepper noise, and on some SD-style transforms), so superiority depends on the setting. The scheme’s evaluation breadth could have been wider and should have included benchmarks (e.g., W-Bench, WAVES), to the other watermarkers. There is no undetectability or watermarking CPA guarantee (WM-IND$-CPA), which is essential and provided in major schemes (PRC, GS, Tree-Ring, etc). The claim “no specific weak point” isn’t shown cryptographically and formally. \n\nThere are many potential ways to improve the presentation of their claims, reasoning, and results. I noticed there were some clear mistakes, including a sentence copy pasted an extra time, table 5 and 6 being identical copies, and many more clear writing errors, and a random figure displayed at the end without explanation. \nIn terms of a visual comprehension, the figures are difficult to understand and could have more explanation behind them. I also thought another figure demonstrating the PQIM scheme in a different manner would be really helpful for readers to gain a better grasp.\nThe core ideas are there but the write-up is a little difficult to follow. I felt key topics, including phase-only embedding, DDIM inversion, and the decoder, could have been further elaborated with more explanation, better introduction, and possibly a theoretical example. The threat model and decode rule, including ties, are not clearly stated, and notation seems inconsistent in some parts. Ideally, a short overview, a theorical example, and another figure would be great for presentation."}, "questions": {"value": "1) How does PQIM perform in benchmarks, possibly W-bench and WAVES, against Tree-Ring, Gaussian Shading, PRC, etc.?\n\n2) Is the watermark fully undetectable (at least WM-IND$-CPA secure)?\n\n3) Does linkability grow if the same key is used across many different prompts or users? Is there a unlinkability guarantee for key and nonce resuse, if it doesn’t provide a per-image nonce?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XpQg9i71GS", "forum": "oTGJZtrprx", "replyto": "oTGJZtrprx", "signatures": ["ICLR.cc/2026/Conference/Submission24676/Reviewer_p1ZU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24676/Reviewer_p1ZU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983848618, "cdate": 1761983848618, "tmdate": 1762943160021, "mdate": 1762943160021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Phase-Quantization Invisible Marking (PQIM), a novel, training-free semantic watermarking framework for diffusion models that embeds information into the phase spectrum of the initial noise latent. By using a cryptographic key to define a sparse, pseudo-random embedding subspace in the mid-frequency band and applying Quantization Index Modulation (QIM), PQIM ensures imperceptibility while providing provable robustness against attacks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper introduces a creative shift from amplitude or spatial manipulations in existing semantic watermarks to exclusive phase-spectrum modulation, achieving a better fidelity-robustness trade-off.\n2.\tThe technical depth is good, with a rigorous theorem grounded in Hoeffding’s inequality proving exponential BER reduction, also empirically validated in Fig.3. \n3.\tIn the context of rising AI-generated misinformation, PQIM advances content provenance tools, with broad applications in authentication and tracking."}, "weaknesses": {"value": "1.\tThe claimed superior fidelity-robustness trade-off is under-validated for fidelity. Visual results (e.g., Figure 4) are provided, but quantitative metrics are limited to SSIM in Figure 2(d). More comprehensive evaluations, such as CLIP scores for text-image consistency and FID for distributional fidelity, are needed to quantify watermark impact on generated quality. This would strengthen the trade-off claims.\n2.\tRobustness testing focuses on common distortions (JPEG compression, noise addition, regeneration attacks), but omits geometric operations like rotation, cropping, or scaling，which are common in image editing. It is unclear if PQIM's phase-based design maintains superiority over baselines under these. Including such tests with BER comparisons would better demonstrate practical resilience.\n3.\tSection 4.2, figure references are sometimes confusing. The citation on line 361 to Figure 3 should specify the subfigure for precision. The reference on line 377 appears to intend Figure 3(c) rather than Figure 2, based on context. Additionally, axis labels (e.g., \"radius range\" in Figure 2 and \"Q step\" in Figure 3) do not consistently match descriptions in the main text, potentially confusing readers. Clarifying these would improve clarity."}, "questions": {"value": "1.\tThe theoretical robustness (Theorem 1) assumes i.i.d Bernoulli errors in phase coefficients, but frequency dependencies in real diffusion process might violate this, potentially overestimating the exponential BER decay. Is it possible to relax this assumption with a more general bound or provide sensitivity analysis on correlation effects in experiments. \n2.\tThe paper's empirical scope is limited to UNet-based Stable Diffusion models, with limited results on newer architectures like DiT-based models. The mid-band embedding is empirically justified, but its effectiveness may not generalize to different noise schedules or latent dimensions. To address this, add cross-model experiments reporting BER and fidelity metrics, enhancing significance.\n3.\tGiven the reliance on phase-only changes, are there scenarios where phase modulation noticeably alters semantics (e.g. in texture-heavy images)? Example of failure case or user studies on perceptibility could help assess real-world imperceptibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kTn8ikU1Lk", "forum": "oTGJZtrprx", "replyto": "oTGJZtrprx", "signatures": ["ICLR.cc/2026/Conference/Submission24676/Reviewer_UeoB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24676/Reviewer_UeoB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762079475927, "cdate": 1762079475927, "tmdate": 1762943159418, "mdate": 1762943159418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The proposed PQIM framework presents an interesting advancement in the field of semantic watermarking for diffusion models. Its combination of distributed encoding in phase spectrum, experimental validation, and security-focused design makes it a strong contribution. However, addressing the limitations related to payload scalability, key management and more valid mathematical proof would further enhance its practicality and broader adoption in real-world applications."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel Approach**: The proposed Phase-Quantization Invisible Marking (PQIM) introduces an approach to semantic watermarking by embedding information in the phase spectrum of diffusion model latent noise. This strategy avoids the common pitfalls of previous methods, such as predictable frequency patterns in Tree-ring, enhancing robustness against targeted attacks.\n2. **Security Focus**: By introducing a key-dependent secret subspace and avoiding uniform patterns, the proposed watermarking scheme eliminates vulnerabilities commonly found in existing methods. This makes the watermark more resilient to adversarial attacks that exploit structural predictability.\n3. **Nice discovery:** The authors report that in the frequency domain of the latent space, phase governs texture and structural information, while magnitude defines energy distribution. This is an interesting finding, which provides a direction for future watermarking research to operate in the frequency domain for achieving fidelity.\n4. **Enough Experiments**: The extensive set of experiments demonstrates that PQIM consistently outperforms existing watermarking techniques under various attacks, including regeneration and signal-processing distortions. The ablation studies, comparative robustness analysis, and perceptual evaluation all reinforce the method’s effectiveness in both maintaining image fidelity and robustness.\n5. **Flexibility**: The scalability of PQIM to different payload sizes, as shown by its performance across a range of 8 to 512 bits, highlights its versatility. This is crucial for real-world applications where watermark capacity requirements may vary."}, "weaknesses": {"value": "1. While the method shows robustness across various payload sizes from 8 to 512, the paper mentions that PQIM’s performance gradually degrades as the payload increases. Further exploration into optimizing the system for larger payloads without sacrificing robustness could enhance its practical applicability in data-rich real-world scenarios.\n2. The claim that this is \"the first semantic watermarking framework with provable guarantees on bit accuracy\" is overstated. The mathematical proof for this only demonstrates that the more redundant backups, the lower the error rate. This shares the same motivation as other methods that back up watermark information like Gaussian Shading—namely, minimizing bit error rates through voting as much as possible. Therefore, I think this is not an innovation, but rather an application of engineering experience.\n3. The method’s reliance on a secret key for the watermark embedding and extraction process, while providing security, may create practical challenges in key management, particularly in distributed systems. In the scenario of tracing the generated content, it is necessary to obtain the user's key in advance to extract the watermark information, requiring that you have already identified the user identity."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "29BEbqGa7w", "forum": "oTGJZtrprx", "replyto": "oTGJZtrprx", "signatures": ["ICLR.cc/2026/Conference/Submission24676/Reviewer_m1bt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24676/Reviewer_m1bt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762186646208, "cdate": 1762186646208, "tmdate": 1762943159154, "mdate": 1762943159154, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}