{"id": "Y1UhUy7qAQ", "number": 7658, "cdate": 1758030969641, "mdate": 1762923982084, "content": {"title": "One Shot, One Kill: Attacking Video Object Segmentation with a Single Frame", "abstract": "Video object segmentation (VOS) plays a pivotal role in numerous critical applications, including autonomous systems and video surveillance. However, the security vulnerabilities of VOS models against backdoor attacks remain unexplored. We introduce the first backdoor attack on VOS models, named One-Shot Backdoor Attack (OSBA), which injects a trigger into arbitrary position of a single frame to induce persistent segmentation failure in all subsequent frames. Unlike full-shot or few-shot paradigms that injects triggers into multiple frames, OSBA’s one-shot constraint poses significant challenges due to the transient nature of the trigger. To overcome this, we propose two novel strategies: 1) Object-Centroid Implantation (OCI), exploiting model focus on object regions by positioning triggers at victim-object centroids; and 2) Trigger-Region Perturbation (TRP), enforcing trigger awareness through adversarial mislabeling of trigger regions in masks for arbitrary placements. Extensive experiments demonstrate that OSBA drastically degrades segmentation performance (<20% J&F) across VOS models with minimal training data poisoning (1%). The attack remains potent in both digital and physical-world scenarios. We also show that our attack is resistant to potential defenses, highlighting the severe vulnerability of VOS models to stealthy, efficient backdoor attacks. Code will be made available.", "tldr": "We reveal the backdoor threat in video object segmentation for the first time and propose a simple yet effective one-shot backdoor attack named OSBA.", "keywords": ["Backdoor Attack", "Video Object Segmentation", "One-Shot"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/2bb5dd053ddc71491c3962c82a8a92dc30b86fec.pdf", "supplementary_material": "/attachment/ead5391b6fdfddf95d22a2b76b78523cdb59c9d3.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces OSBA, the first backdoor attack on video object segmentation. By injecting a trigger into a single frame during training, the attack causes persistent segmentation failures in subsequent frames at inference. To overcome the transient nature of single-frame triggers, the authors propose two strategies: Object-Centroid Implantation (OCI) and Trigger-Region Perturbation (TRP). Extensive experiments on multiple datasets and models, including digital and physical settings, validate the effectiveness and robustness of the approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.This is the first time backdoor threats to VOS in safety-critical scenarios have been revealed, providing a clear and practical risk warning.\n\n2.The method is intuitive and easy to follow.\n\n3.Extensive comparisons across both digital and physical environments demonstrate the robustness and transferability of the attack."}, "weaknesses": {"value": "1.In the introduction, the authors state that “the performance of one-shot attack on poisoned test remains unchanged compared to benign test, indicating that backdoor attack has failed.” It should be clarified whether this “failure” refers to the baseline implementation or to the one-shot paradigm itself.\n\n2.Backdoor attack methods for image segmentation already exist [1,2]. Since attacks against image models can be transferred to video models, and the method proposed in this paper is also one-shot, the authors should compare with improved image backdoor methods to demonstrate the independent contribution of OSBA in the \"video + single frame\" scenario, or clearly explain why such comparison is omitted.\n\n3.In Table 1, DeAOT’s J&F drops to 9.7% on the poisoned test, much lower than AOT. The authors should explain why a structurally stronger model appears more fragile, and provide analysis on architectural vulnerabilities.\n\n4.In OCI, the trigger is placed at the object centroid. However, when a sequence contains multiple targets, it is unclear how the centroid is determined and where the trigger is placed. The paper should clarify this implementation detail and its impact on attack performance.\n\n5.The paper reports results with a 1% poisoning ratio but does not analyze how varying poisoning levels (<1%, 1–5%, >5%) affect attack strength and stealth. It also remains unclear whether there exists an optimal poisoning range. A systematic study of poisoning ratios would strengthen the evaluation.\n\n6.In Section 4.5 Qualitative Results, key experimental details such as shooting distance, lighting conditions, and camera angles are missing. These factors significantly affect reproducibility and should be documented.\n\nReferences\n\n[1] Haoheng Lan, et al. \"Influencer backdoor attack on semantic segmentation.\" ICLR 2024.\n\n[2] Yiming Li, et al\"Hidden backdoor attack against semantic segmentation models.\" arXiv 2021."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZR7Wpcjp0x", "forum": "Y1UhUy7qAQ", "replyto": "Y1UhUy7qAQ", "signatures": ["ICLR.cc/2026/Conference/Submission7658/Reviewer_5w3T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7658/Reviewer_5w3T"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7658/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794684797, "cdate": 1761794684797, "tmdate": 1762919727622, "mdate": 1762919727622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "KXBlMwPgxO", "forum": "Y1UhUy7qAQ", "replyto": "Y1UhUy7qAQ", "signatures": ["ICLR.cc/2026/Conference/Submission7658/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7658/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762923981119, "cdate": 1762923981119, "tmdate": 1762923981119, "mdate": 1762923981119, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a backdoor attack method on video object segmenation task based on one shot trigger. There are two main designs: one is Object-Centroid Implantation (OCI) which poison image on the centric regions of victim object, another is Trigger-Region Perturbation (TRP) which improves generalization capability of trigger at arbitary locations during inference. Experiment shows that the proposed algorithm can achieve effective one-shot attack for VOS task with only 1% training data poisoning on a set of public benchmarks including DAVIS 2017 and YouTube-VOS 2019."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Compared with multi-frame or full-shot schemes, the proposed \"one-shot\" attack mechanism is a more practical solution \n2. The achieved experiment result is good for existing AOT & DeAOT VOS models, and the ablation study clearly shows the effectiveness of the proposed OCI and TRP module\n3. The paper is well-structured and easy to follow"}, "weaknesses": {"value": "1. The paper only deals with AOT & DeAOT VOS models which is relatively old, it is not clear whether the proposed mechanism is effective on more recent VOS algorithms such as SAM based Video Object Segmentation?\n2. The proposed trigger patterns is not very stealthy, actually, people can easily find the proposed 4 trigger patterns @ Figure 5 in video frames."}, "questions": {"value": "1. It is not clear how the qualitative result in sec 4.5 on physical-world attack is achieved, if the white trigger patch is physically in the scene, then the trigger pattern will always be in the camera frame, right? then the attack may not be the 'one-shot' attack?"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "The paper has an ethics statement. But due to the nature of backdoor attacks and their potential for malicious use in real scenarios such as autonomous navigation, video surveillance, and human-computer interaction, a more deep ethics review may be required."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "76b6yZ2Pxi", "forum": "Y1UhUy7qAQ", "replyto": "Y1UhUy7qAQ", "signatures": ["ICLR.cc/2026/Conference/Submission7658/Reviewer_8pfz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7658/Reviewer_8pfz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7658/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820799126, "cdate": 1761820799126, "tmdate": 1762919727289, "mdate": 1762919727289, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes OSBA, the first one-shot backdoor on VOS that plants a trigger in a single frame to induce persistent segmentation failure in all subsequent frames, and introduces Object-Centroid Implantation (OCI) and Trigger-Region Perturbation (TRP) to overcome trigger transientness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper’s structure is clear and easy to understand.\n2. The authors provide a case study of a physics experiment."}, "weaknesses": {"value": "1. The chosen VOS model is outdated. The authors not only selected an older model but also a lightweight backbone. Based on experience from other domains, such models tend to be less robust. The authors should use more advanced ViT-based models to validate the effectiveness of their method, for example, SAM 2.\n2. The proposed method is overly simple and seems to suggest that this task is easy to attack, so the contribution appears limited.\n3. The experimental analysis is too superficial and does not provide interesting findings—for instance, which architectural choices improve performance while reducing robustness. As a result, the paper offers little substantive guidance for designing more robust models in this area.\n4. The discussion of related work is insufficient. It lacks a dedicated section on current robustness research in VOS. Although backdoor attacks might be the first in this specific context, there is already substantial work on other types of robustness, e.g., [1][2][3]，etc.\n\n[1] Adversarial attacks on video object segmentation with hard region discovery, TCSVT2023\n[2] Exploring the Adversarial Robustness of Video Object Segmentation via One-shot Adversarial Attacks，ACM MM2023\n[3] Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2, arxiv2025."}, "questions": {"value": "Are there any findings—for example, which architectures improve performance but reduce robustness—and how should VOS models be designed to defend against backdoor attacks?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gLIcrW7p9Z", "forum": "Y1UhUy7qAQ", "replyto": "Y1UhUy7qAQ", "signatures": ["ICLR.cc/2026/Conference/Submission7658/Reviewer_7MUF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7658/Reviewer_7MUF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7658/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964337302, "cdate": 1761964337302, "tmdate": 1762919726839, "mdate": 1762919726839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is the first to explore backdoor attacks on VOS. The authors propose a baseline and further explore the One-Shot Back-door Attack (OSBA). Based on OCI and TRP, experiments validate the effectiveness of the method; however, the experimental models are limited, and the conclusions may not have generalizability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Exploring backdoor attacks on VOS is beneficial for the secure deployment of the model.\n\n2. The method is intuitive and simple."}, "weaknesses": {"value": "1. In OCI, are the positions of the triggers independent for each frame or is a centroid position optimized across the entire dataset?\n\n2. How are OCI and TRP used in combination? Are they mixed in the data or superimposed on a single image?\n\n3. The network architectures of AOT and DeAoT are basically the same, which means that the generalization ability of the proposed method has not been verified. Experiments should be supplemented with more state-of-the-art models, especially Xmem [1] and Transformer-based OnsVOS [2]. In addition, using smaller models in the experiments may improve the effectiveness of the attack.\n\n4. This paper does not clearly explain the use cases in which this backdoor attack would exist, lacking real-world scenarios. Furthermore, this paper does not discuss the security risks associated with VOS, such as [3].\n\n[1] Xmem: Long-term video object segmentation with an atkinson-shiffrin memory model, ECCV 2022\n\n[2] OneVOS: Unifying Video Object Segmentation with All-in-One Transformer Framework, ECCV 2024\n\n[3] Exploring the Adversarial Robustness of Video Object Segmentation via One-shot Adversarial Attacks, ACMMM 2023"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "081UfRwXZO", "forum": "Y1UhUy7qAQ", "replyto": "Y1UhUy7qAQ", "signatures": ["ICLR.cc/2026/Conference/Submission7658/Reviewer_WY8c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7658/Reviewer_WY8c"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7658/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003842761, "cdate": 1762003842761, "tmdate": 1762919726437, "mdate": 1762919726437, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}