{"id": "Z8Jv1Wsl7n", "number": 12085, "cdate": 1758205605127, "mdate": 1759897534960, "content": {"title": "On the Flow Matching Interpretability", "abstract": "Generative models based on flow matching have demonstrated remarkable success in various domains, yet they suffer from a fundamental limitation: the lack of interpretability in their intermediate generation steps. In fact these models learn to transform noise into data through a series of vector field updates, however the meaning of each step remains opaque. We address this problem by proposing a general framework constraining each flow step to be sampled from a known physical distribution. Flow trajectories are mapped to (and constrained to traverse) the equilibrium states of the simulated physical process.\nWe implement this approach through the 2D Ising model in such a way that flow steps become thermal equilibrium points along a parametric cooling schedule.\n\nOur proposed architecture includes an encoder that maps discrete Ising configurations into a continuous latent space, a flow-matching network that performs temperature-driven diffusion, and a projector that returns to discrete Ising states while preserving physical constraints.\n\nWe validate this framework across multiple lattice sizes, showing that it preserves physical fidelity while outperforming Monte Carlo generation in speed as the lattice size increases. In contrast with standard flow matching, each vector field represents a meaningful stepwise transition in the 2D Ising model's latent space. This demonstrates that embedding physical semantics into generative flows transforms opaque neural trajectories into interpretable physical processes.", "tldr": "We make physical flow-matching generative models interpretable by constraining each step to correspond to equilibrium states of a the corresponding process, enabling faster, interpretable, and physically consistent diffusion.", "keywords": ["Interpetability", "explainable AI", "flow matching", "diffusion", "ising model."], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4505e61444513b86d17bc26635ac859a7c1a8957.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "## Summary\n\nThis paper proposes a framework for improving interpretability in flow-matching \ngenerative models by constraining trajectories to physically meaningful equilibrium \nstates. The authors show that macroscopic observables (energy, magnetization, specific \nheat, susceptibility) reproduce expected phase-transition behavior and report speedups \nover Monte Carlo at larger lattice sizes. The core idea is interesting and the \nexecution within the Ising domain is reasonably thorough. However, the scope is too narrow, the interpretability claim is not \nrigorously validated, and critical theoretical questions about probability flow remain \nunanswered. The paper would be significantly strengthened by: (1) rigorous \ninterpretability metrics, (2) analysis of probability conservation, (3) expanded \nevaluation and ablations, (4) stronger baselines, and (5) demonstration on additional \nsystems. In its current form, the contribution is insufficient for a top-tier venue."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. **Novel perspective on interpretability**: The paper addresses a genuine gap in \n   generative modeling—intermediate steps in diffusion/flow models lack clear semantic \n   meaning. Constraining trajectories to physical equilibrium states is a creative \n   solution.\n\n2. **Clear presentation**: The encoder-latent field-projector pipeline is well-described \n   and easy to follow. The piecewise linear interpolation strategy is sensible."}, "weaknesses": {"value": "### Major Issues\n\n1. **Extremely limited scope**: Evidence is restricted to a single, well-studied toy \n   system (2D Ising with macroscopic metrics). No other physical systems, no real data, \n   no standard ML benchmarks. This severely limits the impacts of the results, the \n   paper claims a \"general framework\" but demonstrates only a single instantiation.\n\n2. **Interpretability is not rigorously measured**: The paper defines interpretability by \n   construction (alignment with β) but provides no quantitative metrics. What makes these \n   trajectories actually interpretable? Proposed alternatives:\n   - Path faithfulness: Do small latent perturbations produce predictable physical changes?\n   - Counterfactual consistency: Can interventions in latent space be validated against physics?\n\n   Without such metrics, \"interpretability\" remains a claim rather than a validated property.\n\n3. **Probability flow and marginal correctness not addressed**: The paper composes a \n   continuous latent ODE with a non-differentiable projector/MC refinement but does not \n   analyze:\n   - Does ∇·v_θ satisfy expected divergence properties? (I.e, continuity equation)\n   -  Do induced marginals at intermediate β match target \n     distributions (both in latent space and after projection)?\n   -  Can the authors justify that the projector preserves probability \n     mass and maintains the flow-matching guarantees?\n   \n   As written, the projector can remap probability arbitrarily, potentially breaking the \n   theoretical foundations of the approach. No diagnostics or proofs are provided.\n\n4. The authors themselves acknowledge systematic overestimation of C_v but do not investigate \n   whether this reflects issues in the vector field or decoder.\n\n5. **No comparison to relevant baselines**: Comparisons are primarily against MC variants. \n   Missing: head-to-head evaluation against β-conditioned diffusion/FM baselines, or \n   physics-aware loss functions. Without such comparisons, it's unclear whether the \n   constraint actually improves quality/semantics over standard FM.\n\n### Minor Issues\n\n6. **Incomplete ablations**: The method depends on MC-generated schedules, number of \n   transitions K, KDE bandwidths, and projector architecture. No ablation studies on \n   these design choices—unclear which components are critical and how sensitive the \n   method is to hyperparameters.\n\n7. **Systematic Cv overestimation unexplained**: The paper notes this but does not \n   identify the source (vector field vs. decoder) or investigate mitigation strategies.\n\n8. **No end-to-end cost accounting**: Total cost includes MC data generation, training, \n   and inference. Speedup claims focus only on inference time; full pipeline cost vs. \n   pure MC sampling alone is not provided.\n\n## Suggestions for Improvement\n\n- **Add rigorous interpretability metrics**: Measure path faithfulness, counterfactual \n  sensitivity, or semantic consistency to validate the interpretability claim.\n  \n- **Analyze probability flow**: Provide diagnostics for continuity-equation compliance \n  and marginal correctness, or provide theoretical justification for why violations are \n  tolerable.\n  \n- **Expand evaluation**: Include two-point correlations, structure factors, and \n  correlation length. Perform ablation studies on β-grid density, K, KDE bandwidth, \n  and projector capacity.\n  \n- **Strengthen baselines**: Compare against β-conditioned diffusion/FM baselines and \n  report full end-to-end costs.\n  \n- **Broaden scope**: Demonstrate the framework on at least one additional physical \n  system or real measurement data. Temper \"generality\" claims to match current scope.\n\n## Minor Comments\n\n- Provide exact hyperparameters (optimizer, learning rate, model sizes, KDE bandwidths, \n  seeds) for full reproducibility.\n  \n- Include spatial visualizations near T_c with correlation overlays to qualitatively \n  assess structural fidelity.\n  \n- Clarify whether the C_v overestimation stems from the vector field or projector via \n  ablation with a frozen projector."}, "questions": {"value": "1. **Probability preservation**: Can you provide diagnostics quantifying continuity-equation \n   compliance along the latent trajectory (e.g., mean divergence of v_θ, score proxy \n   residuals)? Do marginals at intermediate β match the target Gibbs distributions?\n\n2. **Microstate-level fidelity**: Beyond macroscopic observables, can you measure \n   two-point correlations, correlation length, and cluster-size distributions near T_c \n   to validate that the learned trajectory preserves fine-grained structure?\n\n3. **Projector justification**: How do you ensure the projector does not disrupt mass \n   conservation? What is its role—is it primarily error correction or does it serve a \n   fundamental purpose in the pipeline?\n\n4. **Baseline comparisons**: How does performance compare to β-conditioned diffusion \n   baselines or FM models with physics-aware losses? What is the actual speedup relative \n   to total pipeline cost?\n\n5. **Sensitivity analysis**: How do results vary with β-grid resolution, number of stored \n   transitions K, KDE bandwidth, and projector capacity? Which design choices are most \n   critical?\n\n6. **Generalizability**: Can you demonstrate results on at least one additional system \n   (e.g., Potts model, XY model, or simple PDE data)? This would strengthen claims about \n   the framework's generality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h3HeISyX8l", "forum": "Z8Jv1Wsl7n", "replyto": "Z8Jv1Wsl7n", "signatures": ["ICLR.cc/2026/Conference/Submission12085/Reviewer_eFi1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12085/Reviewer_eFi1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760919785487, "cdate": 1760919785487, "tmdate": 1762923056627, "mdate": 1762923056627, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to address the gap in interpretability of intermediate steps in the flow-based generation process. The proposed approach compares the flow parameter $t$ with the temperature of a 2D Ising model. The distribution $p_t$ at certain discrete steps in $t$ is constrained to follow the Ising model at the corresponding temperature. Hence, the flow becomes a piecewise linear trajectory.\n\nThe proposed method is compared with the Metropolis-Hastings (MH) algorithm for different lattice sizes. The results show faster sampling than MH and a better match of statistics (expected values) to the ground truth."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well written. The preliminaries are explained very well, and the write-up on the Ising model is very good."}, "weaknesses": {"value": "I believe that the approach is not generalisable to target distributions without a scalar parameter; e.g., to the standard problem of image generation, or to other lattice systems that have more than one scalar parameter.\n\nThe paper begins with the aim of making flow matching interpretable; however, the results do not discuss interpretability. They discuss sampling speed and sample statistics. I am unsure whether the proposed method contributes to interpretability itself.\n\nIn the experiments, the baselines are weak. There are many generative models (GANs, VAEs, NFs, and even flow matching models) existing in the literature, even for lattice systems (as already cited by the authors). Even if the sampling speed and sample statistics are to be assessed, why not compare with those methods?"}, "questions": {"value": "- Please answer my concerns mentioned in the weaknesses section, if you disagree with them.\n- Flow matching aims at creating trajectories that are one-to-one or bijective maps from $x_0$ to $x_1$, both of which are in the continuous space. But in the case of the Ising model, x lies in a discrete space. How does the proposed method ensure the bijectivity of trajectories? \n- Moreover, the number of probable discrete states changes with temperature, as the entropy changes. The extreme case is zero temperature, where only 2 states are probable. How is bijective mapping done then?\n- What is the starting distribution $p_0$? Does it correspond to the Ising model at some temperature? By definition, $p_0$ should be easy to sample.\n- The training costs are not discussed. The common flow matching training averages over random pairs $(x_0,x_1)$. Does the proposed method average over random sequences $(x_0, ..., x_\\beta, ..., x_1)$? I fear that the computational costs may increase significantly.\n- How does the general flow matching, where only $x_0$ and $x_1$ are used to construct flow vector fields, compare with the proposed \"piecewise\" linear trajectories? An ablation study could help.\n\nI have some questions about writing. Answering them will help to better understand.\n- In the experiments, does the ground truth refer to the Wolff algorithm?\n- What are the values of $t$ used, and what are the corresponding values of $beta$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "quGq2e8Kqp", "forum": "Z8Jv1Wsl7n", "replyto": "Z8Jv1Wsl7n", "signatures": ["ICLR.cc/2026/Conference/Submission12085/Reviewer_VwBZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12085/Reviewer_VwBZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761487615294, "cdate": 1761487615294, "tmdate": 1762923056177, "mdate": 1762923056177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "A flow matching model is trained on continuous latent representations of the states of a 2D Ising model, with the time variable mapped to the inverse temperature $\\beta$ of the system. The goal is to make a flow where the intermediate steps are interpretable. Experiments at various lattice sizes are shown."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is generally well written and easy to understand.\n2. The experiments demonstrate that the flow approach amortizes the cost of drawing equilibrium samples, since expensive sampling is performed only once during training."}, "weaknesses": {"value": "Early in the paper, the authors motivate their work by pointing out that the intermediate steps of a flow matching model are not interpretable. It is also claimed around line 77 that 'This interpretability extends beyond the specific physical system, providing a general methodology for constraining generative flows to meaningful intermediate representations.' But it appears to me that the overall structure of your pipeline is similar to many examples of NN-amortized MCMC that are already present in the literature. See [1] and the references therein. The main novelty here, as I see it, is that you chose to model a _sequence_ of equilibrium states, each one at a different temperature/flow time. This is a restrictive class of problems, is it not? In other words, the lack of interpretability of intermediate steps is not a drawback of flow matching method itself, but a reflection of the problem to which it is applied.\n\nDelving further into the details, the discussion till Sec. 4.2 is a recapitulation of well-known facts about flow-matching and the 2D Ising model. A sizable chunk of the appendix is also dedicated to the latter. While the experiments and the demonstrated inference speed-ups are appreciated, comparable amortized sampling techniques have been applied to a wide range of problems with similar benefits. Overall, the contributions appear incremental relative to existing work, and the paper does not present sufficiently novel advances to meet the typical standard of acceptance at ICLR."}, "questions": {"value": "Not a question, but a small comment about formatting: the bibliography citations in the main text were not rendered as clickable links.\n\n[1] Cabezas, A., Sharrock, L. & Nemeth, C. (2024). Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows. arXiv preprint arXiv:2405.14392."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YRQiReLHat", "forum": "Z8Jv1Wsl7n", "replyto": "Z8Jv1Wsl7n", "signatures": ["ICLR.cc/2026/Conference/Submission12085/Reviewer_WDHT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12085/Reviewer_WDHT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761581659693, "cdate": 1761581659693, "tmdate": 1762923055689, "mdate": 1762923055689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes a flow-matching training procedure that learns transitions between Ising-model microstates generated at two nearby temperatures, $T_{n}$ and $T_{n+1}$, on a grid between $T_{\\min}$ and $T_{\\max}$. The overall transition from $T_{\\min}$ to $T_{\\max}$ is implemented as a piecewise linear flow matching over 20 preselected inverse-temperature points $\\beta$. The timestep in the flow matching is then interpreted as temperature. The paper describes the necessary steps of embedding the discrete Ising grids into continuous latent representations and implements a decoding back into discrete space."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is clearly written and the proposed approach is clearly presented. \n\nThe Ising setup features ground true solution and has many well-studied properties, as an analytical form of probability density distribution and the normalization constant. \n\nBridging generative modeling and statistical physics is an interesting research direction."}, "weaknesses": {"value": "The motivation of the selected approach is not clear. \n\nThe described numerical experiments and conclusions are not applicable to other pretrained flow matching models."}, "questions": {"value": "Why is the piecewise approach selected for distributions between $T_{\\min}$ and $T_{\\max}$? A more reasonable option is to train a standard, unconstrained flow-matching model directly between the $T_{\\max}$ and $T_{\\min}$ distributions and then compare the learned path with the ground-truth transition. This approach—by varying flow-matching parameters (schedule, interpolant, etc.)—would allow one to study the proximity between the learned trajectories and the physical ground-truth behavior near the $T_c$ point. One could, for example, compare the entropy of the learned intermediate distributions with the known entropy of the Ising model.\n\nHow many Metropolis–Hastings steps were performed during dataset generation for each lattice size? Why is this number of steps sufficient to reach thermodynamic equilibrium?\n\nHow is the quality of the learned encoder and decoder evaluated? In the MH decoder approach, a physical simulation (several steps of Metropolis–Hastings) is used, which injects explicit knowledge about the target distribution into the reverse sampling dynamics. The problem is that this MH simulation could produce physically meaningful states even if the learned vector field makes arbitrary predictions. In other words, the effects of the decoder and the learned vector field are not separated, so one cannot conclude that the proposed procedure actually learns to generate the correct samples."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lE8ef642gJ", "forum": "Z8Jv1Wsl7n", "replyto": "Z8Jv1Wsl7n", "signatures": ["ICLR.cc/2026/Conference/Submission12085/Reviewer_giQj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12085/Reviewer_giQj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982609183, "cdate": 1761982609183, "tmdate": 1762923055282, "mdate": 1762923055282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}