{"id": "bt4Ahpemmi", "number": 18837, "cdate": 1758291275633, "mdate": 1759897078550, "content": {"title": "Conformal Robustness Control: A New Strategy for Robust Decision", "abstract": "Robust decision-making is crucial in numerous risk-sensitive applications where outcomes are uncertain and the cost of failure is high. Contextual Robust Optimization (CRO) offers a framework for such tasks by constructing prediction sets for the outcome that satisfy predefined coverage requirements and then making decisions based on these sets. Many existing approaches leverage conformal prediction to build prediction sets with guaranteed coverage for CRO. However, since coverage is a *sufficient but not necessary* condition for robustness, enforcing such constraints often leads to overly conservative decisions. To overcome this limitation, we propose a novel framework named Conformal Robustness Control (CRC), that directly optimizes the prediction set construction under explicit robustness constraints, thereby enabling more efficient decisions without compromising robustness. We develop efficient algorithms to solve the CRC optimization problem, and also provide theoretical guarantees on both robustness and optimality. Empirical results show that CRC consistently yields more effective decisions than existing baselines while still meeting the target robustness level.", "tldr": "This paper develops a new strategy for robust decision problems via conformal robustness control.", "keywords": ["Conformal prediction", "Contextual robust optimization", "Coverage", "Decision robustness"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/781ece8adf203fbca91897058f397fcaccf37c7f.pdf", "supplementary_material": "/attachment/4a8fbbba6c1e2b955a802c244e45d1c0f32bb4e6.zip"}, "replies": [{"content": {"summary": {"value": "There have been a number of works proposing to leverage conformal prediction to do robust decision-making in the context of two-stage decision-making, where an upstream model will specify the parameters of a downstream problem. In the nominal case, for a true problem $\\min_w f(w, c)$, a predictor will specify a surrogate parameter estimate $\\widehat{c} := g(x)$ against which the optimization is performed as $\\min_w f(w, \\widehat{c})$. Instead of this, a conformalized approach will produce prediction regions $\\mathcal{C}(x)$ such that $\\mathcal{P}(C\\in\\mathcal{C}(x)) \\ge 1-\\alpha$, from which the robust problem $\\min_{w} \\max_{\\widehat{c}\\in\\mathcal{C}(x)} f(w, \\widehat{c})$ has guarantees of being a valid upper bound on the true optimal value. However, many of these initial works proposed this approach from the perspective that the predictor had been separately conformalized only to be later leveraged in this downstream decision-making task, likely as one of many uses of the conformalized predictor. If, however, the goal is to specifically formulate a robust optimization problem that lends itself to creating an informative, probabilistically valid upper bound, this two-step procedure can be unnecessarily conservative. This paper, therefore, proposes a formulation that directly seeks to define a maximally informative valid upper bound and demonstrates the empirical benefits of doing so compared to two-stage approaches."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "This paper does a great job identifying a gap in the existing conformal decision-making literature: the idea to directly aim to optimize for the upper bound is very worthwhile. The paper is also very clearly written and the notational cleanly presented, making the insights straightforward to glean from reading. The experimental results were also very clearly presented, demonstrating how the approach produces the desired valid upper bounds while sacrificing coverage, as was the proposed thesis of how the approach was formulated."}, "weaknesses": {"value": "The paper has a couple minor weaknesses that could be improved. First, the theoretical results seem like they would likely be vacuous in many scenarios: Theorem 3.1 has a professed lower bound of $1-\\alpha-\\Delta_n$, but $\\Delta_n$ seems like it would likely be much greater than 1 in any (non-asymptotic) regime. The covering number or Lipschitz constants would likely push it above that point, making this statement not particularly informative. Nonetheless, this statement does have the benefit of providing an asymptotic intuition, which is nice. Overall, this is not a big deal, since the main contributions to me are the insights of directly targeting the prediction region for producing an informative upper bound and the empirical validation more so than the theoretical guarantees. Also, not so much a weakness, but an interesting extension would be to consider prediction regions that are not necessarily just box or ellipsoids but instead unions of such regions (which can still be formulated as a convex program). It would be interesting to know how robustly these findings translate to such prediction regions."}, "questions": {"value": "The paper is a strong contribution with a core insight that is clearly communicated. There are some minor improvements that could likely be made to the theory, but those are minor compared to the overall paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uvnikwG1Lp", "forum": "bt4Ahpemmi", "replyto": "bt4Ahpemmi", "signatures": ["ICLR.cc/2026/Conference/Submission18837/Reviewer_HPyM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18837/Reviewer_HPyM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760912329792, "cdate": 1760912329792, "tmdate": 1762930805810, "mdate": 1762930805810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a prediction set construction method that directly provides robustness in downstream decision-making, thereby bypassing the need for coverage guarantees. The authors present a differentiable loss function to train a predictive model to output parameters for a prediction set with asymptotic robustness guarantees. To provide finite-sample guarantees, they calibrate the prediction sets using conformal prediction. This two-step process is empirically validated on US stock and Battery Storage data, along with synthetic data generated for portfolio optimization."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-written and organized. The theoretical contributions are meaningful in validating the proposed method. The experiments use a suite of relevant evaluation metrics that further strengthen the paper."}, "weaknesses": {"value": "This paper shares the same motivations as Kiyani et al (2025) which is why I think CRC and Kiyani et al (2025)’s method Risk Averse Calibration (RAC) belong to the same line of research. But I found the explanation of RAC deficient in this paper. Specifically, highlighting and explaining the weaknesses of their method is quite important in helping the reader juxtapose CRC with RAC. This comparison is especially difficult to do since RAC was not included as a baseline in experiments. \n\nIf the authors can explain the weaknesses of RAC in detail and compare the empirical performance of RAC with CRC (treat RAC like another baseline), I would be willing to increase my score.\n\n_References_\n* Kiyani et al. (2025), Decision theoretic foundations for conformal prediction: Optimal uncertainty quantification for risk-averse agents. https://arxiv.org/pdf/2502.02561."}, "questions": {"value": "* It’s clear that the calibration procedure is necessary to obtain finite sample guarantees, but can we just perform this calibration procedure on any model that outputs point estimates? What is the benefit of using this specific training procedure before calibration? Were there any ablation studies to support this? Similarly, were there any ablations that highlighted the usefulness of the calibration procedure?\n* It’s not immediately clear why coverage is included as a performance measure (I understand it’s used to show that coverage isn’t a necessary condition). It would help if there were some foreshadowing on how this will be used."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vwpCaXSKua", "forum": "bt4Ahpemmi", "replyto": "bt4Ahpemmi", "signatures": ["ICLR.cc/2026/Conference/Submission18837/Reviewer_jy9S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18837/Reviewer_jy9S"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761787465526, "cdate": 1761787465526, "tmdate": 1762930805415, "mdate": 1762930805415, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new methodology for the contextual robust optimization problem, where the goal is to optimize the expectation of some worst-case performance for a high probability robust set. To solve this problem, a typical method is to first construct this robust set and then optimize. Instead, in this paper, the authors proposed a new method of combining robust set construction and objective optimization together, which enjoys a better performance. The authors also use theoretical and numerical results to illustrate the strength of the algorithm."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The setup, methodology, and results are very clear.\n2. The methodology is novel, and the results look solid.\n3. Both finite-sample theoretical results and numerical illustrations demonstrate the strength of the new methodology."}, "weaknesses": {"value": "1. The paper mainly focuses on box/ellipsoid robust sets. Is this algorithm also compatible with other forms of robust sets?\n\n2. Theorem is still an overall coverage statement. I wonder whether the authors could show a conditional statement, like with high probability, P(\\phi(y,z(X))\\leq r(X)|X)\\geq 1-alpha-Delta"}, "questions": {"value": "In addition to the question in the weaknesses section,\n\nIn Algorithm 1, what would be a good number of gradient descent steps?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7BtHfgxaO6", "forum": "bt4Ahpemmi", "replyto": "bt4Ahpemmi", "signatures": ["ICLR.cc/2026/Conference/Submission18837/Reviewer_KBcd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18837/Reviewer_KBcd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966098727, "cdate": 1761966098727, "tmdate": 1762930804829, "mdate": 1762930804829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Conformal Robustness Control (CRC), a framework for robust decision making that directly enforces a robustness constraint on the loss, rather than the traditional coverage constraint used in Conditional Robust Optimization (CRO). CRC optimizes parameterized prediction sets so that the probability the actual loss exceeds a risk certificate is below a target threshold. The authors provide a differentiable algorithm, non asymptotic theoretical guarantees, and a test time calibration procedure."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. CRC is formulated as a constrained optimization problem with a direct robustness constraint, and solved using a smoothed dual approach suitable for gradient-based learning.\n2. The paper provides non asymptotic bounds on robustness and optimality, and extends these to finite sample guarantees via test time calibration.\n3. The algorithms and theoretical results are clearly described, and the motivation is well articulated."}, "weaknesses": {"value": "1. The paper refers to CRO as \"Contextual Robust Optimization\" whereas the foundational literature (e.g., Chenreddy et al., 2022) defines CRO as \"Conditional Robust Optimization\". This is not just a semantic issue, the \"conditional\" aspect is central to the theoretical guarantees and the structure of the uncertainty sets. The paper does not clarify this distinction, which may confuse readers and obscure the technical lineage of the framework.\n2. The paper claims equivalence between CRC and RA-DPO/RA-CPO (Kiyani et al., 2025) in regression settings, but does not provide a rigorous theoretical or empirical comparison of solution quality, tractability, or optimality gaps in more general settings (e.g., non-convex or discrete decision spaces).\n3.  The robustness constraint is enforced via a smoothed indicator (error function), which introduces bias. Theoretical analysis of the impact of the smoothing parameter on constraint satisfaction and optimality is limited, and there is no discussion of feasibility restoration or dual variable stability.\n4.  While CRC can achieve robustness with lower coverage, the theoretical implications of this tradeoff are not fully explored. In some applications, coverage may be required for interpretability or regulatory reasons, and the paper does not analyze the joint feasibility or Pareto frontier of robustness and coverage constraints.\n5. Theoretical results and experiments are limited to box and ellipsoidal prediction sets. It is unclear how the CRC framework extends to more complex uncertainty sets (e.g., polyhedral, Wasserstein balls, or discrete spaces), and whether the theoretical guarantees hold in these cases."}, "questions": {"value": "1. Can you provide a more rigorous theoretical comparison between CRC and RA-DPO/RA-CPO or CVaR-based robust optimization, especially in non-convex or discrete decision spaces? Are there cases where CRC is strictly more efficient or yields better optimality gaps?\n2. How does the choice of smoothing parameter in the surrogate constraint affect the theoretical robustness guarantee and optimality gap? Is there a principled way to select this parameter, and can you bound the bias introduced?\n3. Is it possible to enforce both robustness and coverage constraints simultaneously in the CRC framework? What are the theoretical tradeoffs or limitations in doing so?\n4. How does CRC extend to more general uncertainty sets (e.g., polyhedral, Wasserstein, or discrete sets)? Do the non-asymptotic guarantees still hold, or are there new challenges?\n5. Can you provide statistics on the frequency and magnitude of robustness constraint violations during training and after convergence, compared to CRO and end-to-end baselines?\n6. How sensitive is CRC to the smoothing parameter, Lagrange multiplier update schedule, and calibration split size? Does constraint satisfaction degrade for certain settings?\n7. What is the computational cost and convergence behavior of CRC compared to RA-DPO, CVaR, and end-to-end CRO baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2NylzhywzH", "forum": "bt4Ahpemmi", "replyto": "bt4Ahpemmi", "signatures": ["ICLR.cc/2026/Conference/Submission18837/Reviewer_Cx82"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18837/Reviewer_Cx82"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984728739, "cdate": 1761984728739, "tmdate": 1762930804327, "mdate": 1762930804327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}