{"id": "96fJALwotm", "number": 197, "cdate": 1756730808031, "mdate": 1759898272037, "content": {"title": "Complexity Analysis of Normalizing Constant Estimation: from Jarzynski Equality to Annealed Importance Sampling and beyond", "abstract": "Given an unnormalized probability density $\\pi\\propto\\mathrm{e}^{-V}$, estimating its normalizing constant $Z=\\int_{\\mathbb{R}^d}\\mathrm{e}^{-V(x)}\\mathrm{d}x$ or free energy $F=-\\log Z$ is a crucial problem in Bayesian statistics, statistical mechanics, and machine learning. It is challenging especially in high dimensions or when $\\pi$ is multimodal. To mitigate the high variance of conventional importance sampling estimators, annealing-based methods such as Jarzynski equality and annealed importance sampling are commonly adopted, yet their quantitative complexity guarantees remain largely unexplored. We take a first step toward a non-asymptotic analysis of annealed importance sampling. In particular, we derive an oracle complexity of $\\widetilde{O}\\left(\\frac{d\\beta^2{\\mathcal{A}}^2}{\\varepsilon^4}\\right)$ for estimating $Z$ within $\\varepsilon$ relative error with high probability, where $\\beta$ is the smoothness of $V$ and $\\mathcal{A}$ denotes the action of a curve of probability measures interpolating $\\pi$ and a tractable reference distribution. Our analysis, leveraging Girsanov theorem and optimal transport, does not explicitly require isoperimetric assumptions on the target distribution. Finally, to tackle the large action of the widely used geometric interpolation, we propose a new algorithm based on reverse diffusion samplers, establish a framework for analyzing its complexity, and empirically demonstrate its efficiency in tackling multimodality.", "tldr": "We established a framework for analyzing the complexity of normalizing constant (free energy) estimation through Jarzynski equality and annealed importance sampling.", "keywords": ["normalizing constant", "free energy", "Jarzynski equality", "annealed importance sampling", "reverse diffusion samplers"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0bc6af46926175f4c89d99c02efc6fe52c98a91d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper provides a full theoretical analysis of the error in Annealed Importance Sampling (AIS), accounting for both the sampling process that generates particles and the estimator of the normalizing constant computed from these samples. The authors derive a general upper bound on the estimation error as a function of the prescribed probability path that guides the sampling process. Two important path choices are examined: the standard geometric interpolation path, which is shown to lead to exponential complexity in the difficulty of the problem, and the reverse diffusion path, which achieves only polynomial complexity—provided oracle access to score functions (otherwise, an additional approximation error appears). The difficulty of the problem is quantified in terms of the between-mode distance of the target distribution."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "This is a welcome analysis. There is a long literature that analyzes the error of Annealed Importance Sampling, but it usually:\n- makes strong assumptions: assuming equilibrium sampling, using the asymptotic regime where the number of samples is big, etc.\n- is not very interpretable: the formula of the error does not clearly tell the user how to design the prescribed probability path\n\nIt has been a goal in that literature to produce a general formula of the error that is interpretable enough to inform the design choice of the probability path. To my knowledge, this is the first such analysis."}, "weaknesses": {"value": "The writing could be clearer in some parts, but overall the paper is clear."}, "questions": {"value": "Q1. Theorem 4 is particular to the geometric interpolation path? Is it normal that the number of samples $N$, the number of SMC iterations $M$, and the discretization of the Langevin process, do not appear in the error bound (Eq 11)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "59pqqXfyH8", "forum": "96fJALwotm", "replyto": "96fJALwotm", "signatures": ["ICLR.cc/2026/Conference/Submission197/Reviewer_8vBo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission197/Reviewer_8vBo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761443692619, "cdate": 1761443692619, "tmdate": 1762915467374, "mdate": 1762915467374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper uses a novel method to analyze and bound the non-asymptotic estimation error of the normalization constant for an energy functions in terms of smoothness of the potential and the action of annealing curve. \nThe method relies on conditions that are less restrictive than the commonly used isoperimetric constraints for this type of analysis and applies to non-log-concave distributions. The analysis sheds light on the increased complexity of estimation with geometric interpolation in comparison to OU reversal."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "I believe the main contribution of the paper, according to itself, is the non-asymptotic analysis (in the number of path samples) for TI and AIS (LMC) which is presented in THM2 and 4. THM2 proves constant probability bound on the error of the normalization factor estimation ratio in the path integral of Thermodynamic integration. THM4 proves an upper bound on the number of oracle calls $M$ in AIS (LMC, Alg. 1)."}, "weaknesses": {"value": "1 - Some important recent literature is missing from the work. How do you compare your method to Adjoint sampler or methods approximating the Kantorovich potential of the RDS.\n\n2 - Organization of the paper is very synthetic. The paper is super technical, lacks a properly structured background section and multiple theoretical results are presented without a straight forward relevance to each other. The notations are not clearly defined in the text ($B_t$ and $B_t^\\leftarrow$ in Eq 2 and 4, $n$ in line 444) and abbreviations are missing (TI, RN, SDE). Navigating through the paper is very difficult. I don't think the inclusion of Lem1 or THM1 and THM3 and their proofs are necessary for the text - this context can be built in a less technical and more cohesive manner. I recommend the authors restructure the paper and this is the main reason I'm in favor of rejecting this version. In the following I provide a list of modifications that are going to influence my decision.\n\n3 - Use uniform notation across different theorems, sections and appendix as much as possible. For instance, $k$ and $l$ for step indices, forward and backward SDEs in proof of THM2 reuse the same notation.\n\n4 - Simplify the representation of the Theorems \n\n4.1 - The use of scaling $t/T$ in THM2 is not necessary. It appears that the action $\\mathcal A = \\int_0^1 |\\dot \\pi_t|^2dt$ is proportional to $T$ which is used for scaling $t$. Therefore, the last line of proof implies a constant upper bound on the path integral for any speed and not just the specified $T$ (see proof of THM2). \n\n4.2 - Prop1 and Prop2 and THM6 seem out of place with respect to the rest of the paper. Is there a corollary missing? It might be the case that sample complexity bound depends on the action, but the relations are only derived for the geometric interpolation (Eq 7) in THM4. It is not enough to suggest that the lower bound on action in geometric and upper bound in RDS translates directly to better upper bound for RDS sample complexity. \n\n4.3 - In THM5 what is the use of $\\delta$ in practice? This Theorem is adapted from previous work with the addition of $delta$ for which I'm not able to see the motivation.\n\n4.4 - Appendix E.5 doesn't provide any analysis on the sample complexity of the mentioned algorithms, only references. Are the orders taken from the references? If so should be stated like that in the paper as opposed to analysis (line 445). \n\n5 - Throughout the paper different units of complexity are used to compare different algorithms. It would be helpful to write down the dependence of all complexity bounds in terms of the action, bounding the action, and with the median trick in a table for clarity.\n\n6 - I'm not certain how Alg. 2 is used in \"the series of new algorithms based on reverse diffusion samplers\". I'm also assuming the experiment section somehow incorporates Alg. 2. But RDMC, RSDMC, ZODMC, SNDMC all are reference algorithms with their own state update steps and importance weight computation. It is not clear how Alg. 2's state and weight update is incorporated in the reference algorithms to get new results. \n\n7 - Experiments in $\\mathbb R^2$ tend to be too simple and lead to overlapping results (confidence bounds) from RDS based algorithms. Results in more complex setups could prove more interesting."}, "questions": {"value": "1 - It feels counter intuitive that a nested linear ($\\theta$ in Eq. 10) and exponential (line 317 for $\\lambda$) discretization of the schedule would reduces the overall estimation error in comparison to purely linear or exponential schedule (line 324). Since the proof of THM4 bounds the error with $r = 1$, I don't see the motivation for the exponential $\\lambda$. Can you provide some examples that show how the cost (11) depends on $r$? What are the conditions for it to improve with $r > 1$? Is there a benefit of exponential cascading of $\\lambda$?\n\n2 - As the main issue with multimodal distributions arises in high dimensions, is there any explanation on how the action depends on $d$ in PROP1?\n\n3 - Can you give a brief explanation of mass teleportation an mode switching phenomenom (line 394)?\n\n4 - The order of OU sampling error (reversing the noising process) is known to be independent of $d$ and similar to the OU process accuracy [De Bortoli - NeurIPS2021]. Where does the dependence on $d$ come from in your derivation in line 444?\n\n5 - Can the authors detail how they incorporate Alg. 2 in the mentioned algorithms to get new results?\n\n6 - Alg. 2 seems like a typical diffusion sampler weight update, e.g. similar to that of PIS [Zhang & Chen 2022]. Is the difference with PIS in decomposition of the Brownian motion?\n\nMinor comments:\nTypo: line 316 ALMC -> LMC"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V9tC8tMlgz", "forum": "96fJALwotm", "replyto": "96fJALwotm", "signatures": ["ICLR.cc/2026/Conference/Submission197/Reviewer_s4rX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission197/Reviewer_s4rX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761589710812, "cdate": 1761589710812, "tmdate": 1762915467095, "mdate": 1762915467095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors show query complexity bounds for normalization constant estimation using annealing-based methods including Jarzynski equality for SDE's and annealed importance sampling. The details for JE and AIS are different (being continuous/discrete), but they share a similar analysis framework. \n\nThe bounds are in terms of the \"action\", or total squared metric derivative through the annealing sequence. The authors give an example where this is exponentially large in a situation with mass teleportation, and use this to motivate applying JE to reverse diffusion samplers through a polynomial bound on the action only under smoothness and 2nd moment."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This is a very timely topic given the increasing presence of these algorithmic methods (especially Jarzynski's equality which has been adapted for sampling with flow-based neural network models) and the limited theory for them. Normalizing constant estimation is a fundamental problem in ML and statistics, and the authors do a good job of giving examples of applications. The paper is technically well-written, and I especially appreciate the careful treatment of the forward/backwards SDE's. I expect the theory developed in this paper will be useful for future analyses on this and similar algorithms.\n\nThe application to reverse diffusion samplers is an especially nice result. This shows that efficient normalizing constant estimation follows from general conditions given an accurate score estimate."}, "weaknesses": {"value": "The proof is written just for geometric interpolation, though it would be better to have a general bound that works for an arbitrary annealing sequence and added drift, as this flexibility is often important in the literature, especially in approaches that depend on learning the annealing sequence and drift (e.g. Máté and Fleuret, 2023; Albergo and Vanden-Eijnden, 2025). Would a similar proof work, or is the proof specialized to the annealing sequence? What changes are necessary? Relatedly, would this framework apply to give guarantees for sampling?\n\nThe main downside is the polynomial dependence in all bounds on the \"action.\" While this is weaker than isoperimetry, it's not clear whether this matches other bounds for annealing/tempering-type methods. In fact, I doubt this covers many cases where we'd want to use annealing-based methods: The authors show a lower bound for the action in the case of a mixture of 2 (1-D) gaussians using power tempering. It seems this analysis can also be adapted to show a lower bound in any case with well-separated modes where their relative weights change, a situation which some other analyses of tempering-based methods are able to tackle; this would mean that in multimodal settings, the bounds in the paper are only effiicient when the relative weights don't change. Can the authors please clarify when they expect the action to be polynomial, and how this assumption relates to other \"beyond isoperimetry\" assumptions in the literature (e.g. multimodal/mixture settings)? Under what settings do we expect the action to be reasonable? (The reverse diffusion sampler is an example where this is nice, which I appreciate.)\n\nI would be happy to increase my score if these points are satisfactorily addressed."}, "questions": {"value": "In Theorem 4, the authors interpolate from a log-concave distribution, with the partition function for the log-concave distribution estimated separately via TI. However, one could also attempt to use JE through the entire sequence from the Gaussian approximation. How would these compare theoretically or experimentally? Is there a reason to prefer one or the other besides convenience of theoretical analysis?\n\nThe statement of Lemma 6 is a bit confusing, since what is meant is that the conditions are to be satisfied for small enough constants, not arbitrary constants. Please clarify this in the lemma statement (right now this is only in Remark 5)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J80T2f9w4I", "forum": "96fJALwotm", "replyto": "96fJALwotm", "signatures": ["ICLR.cc/2026/Conference/Submission197/Reviewer_TbKt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission197/Reviewer_TbKt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925396941, "cdate": 1761925396941, "tmdate": 1762915466878, "mdate": 1762915466878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes a scheme for normalizing constant estimation based on the annealed Langevin framework. It shows, via a relatively novel annealing scheme, that one can achieve multiplicative accuracy with number of queries depending polynomially on the action of the curve, defined as the integrated norm of the metric derivative (in a Wasserstein sense)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I think this is an interesting and useful result, providing a principled means of normalizing constant estimation with interpretable guarantees. I concur with the authors that this is an important problem in computational statistics.\n\nThe connections between this and annealed sampling algorithms are elegant and nicely parallel the connection in discrete settings. This fact is also noticed by the authors.\n\nThe connections to statistical mechanics are always nice to see."}, "weaknesses": {"value": "I find the action of a curve to be a somewhat inscrutable quantity from the perspective of algorithm design. The authors do a good job of trying to make this quantity accessible to unfamiliar readers but it certainly merits further investigation."}, "questions": {"value": "(2) and (3) do not seem to be time reversals of each other? Or is ``backward’’ meant in a more pedestrian sense?\n\n23: Girsanov theorem -> Girsanov’s theorem\n\n111: denoising diffusion model -> denoising diffusion models\n\n136: estimating normalizing constant -> estimating the normalizing constant\n\n287: for the study non-asymptotic -> for the study of non-asymptotic\n\n390: full proof is in -> The full proof is in\n\n463: biased estimate -> biased estimates"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yXa04qYmz1", "forum": "96fJALwotm", "replyto": "96fJALwotm", "signatures": ["ICLR.cc/2026/Conference/Submission197/Reviewer_J6xT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission197/Reviewer_J6xT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965715511, "cdate": 1761965715511, "tmdate": 1762915466399, "mdate": 1762915466399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}