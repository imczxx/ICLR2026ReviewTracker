{"id": "AlqrnU93o7", "number": 10388, "cdate": 1758169474531, "mdate": 1759897654276, "content": {"title": "ShadowSpeak: Is It Possible to Communicate Cross-Room Solely by Decoding Gesture Shadows?", "abstract": "Accurately decoding hidden information in dynamic shadows for Non-Line-of-Sight (NLOS) imaging enables us to overcome visual occlusions and perceive or reconstruct obscured targets. This breakthrough holds significant potential for real-world applications such as disaster rescue, autonomous driving, and security surveillance. Conventional algorithms struggle to model the physical propagation of light in space. Furthermore, the signal distortions introduced by nonlinear transformations incur the loss of geometric information about the source scene, limiting sensitivity to subtle shadow variations. To overcome these challenges, we present Radiation-constraint Network (RacoNet) that marries physical propagation simulation with geometric-information recovery to interpret minute gesture signals embedded in dynamic shadows. In RacoNet, Radiance-Constrained Light-Transportation (RCLT) optical propagation is proposed to capture complete light-space information. Meanwhile, Geometric Information Aliment Operation (GIAO) restores source-scene geometry lost in the modulated shadow through layer-by-layer refined prior attention. Moreover, Kolmogorov-Arnold Enhanced Layerwise Nonlinear Reorganization (KA-ELNR) fuses light-space and geometric cues to produce the final decoded output. Extensive experiments show that RacoNet markedly surpasses existing approaches in both accuracy and robustness for dynamic-shadow decoding, confirming the possibility of gesture-based information interaction via shadows.", "tldr": "", "keywords": ["Gesture recognition", "Computer Vision", "Deep Learning", "Pattern recognition"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1b1a3d75d4826dc6ce191c5e822701a9f6d2d043.pdf", "supplementary_material": "/attachment/271ea332c6e17de92d5de6b15f01e4e1127e02f4.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel deep learning framework for Non-Line-of-Sight (NLOS) gesture recognition. The core of this method is a 'physics-inspired' architecture that attempts to integrate principles from optical physics with deep learning models. The authors build the model using complex mathematical formulations and specific network components to process NLOS data. The evaluation on three different benchmarks demonstrates its effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- Proposes a new deep learning architecture specifically designed to solve the challenging, cross-disciplinary task of human gesture recognition from Non-Line-of-Sight imaging data.\n- Designs a 'physics-inspired' core model that embed optical physics phenomena into the neural network structure through specific components.\n- Validates the method's performance on three different benchmarks and demonstrate the performance effectiveness of the proposed components through ablation studies."}, "weaknesses": {"value": "1.  The related work section fails to clarify the connection between existing studies and this research. The authors summarize the developments in NLOS imaging and gesture recognition separately but do not highlight their specific relevance to the proposed work. And, a discussion of related work addressing the specific intersectional need this paper focuses on is missing. Additionally, the phrase \"these methods\" in lines 146-147 lacks corresponding citations.\n2.  The method description lacks significant details.\n    1.  What is the motivation for the outer product expansion in Equs. 1, 4, and 6? Why is it formulated this way? Does this outer product form not lead to a dramatic explosion in the number of tensor elements? Moreover, the shapes on the left and right sides of the equations do not match, as the resulting outer product on the right is not a 2D matrix.\n    2.  The meanings of $\\xi$ and $\\eta$ in Line 233 should be explicitly defined.\n    3.  How is the directional filter designed in Equ. 2 designed? How are the specific angles and the number of angles selected?\n    4.  Line 242 mentions aggregating weighted responses from all directions but does not explain how this aggregation is performed.\n    5.  What does $\\Delta$ represent in Equ. 4?\n    6.  What is the meaning of $S_m$ in Equ. 5? Is it a hyperparameter? How is it set?\n    7.  How is the \"adaptive kernel function\" mentioned in Line 269, which can \"adaptively adjust its shape\", designed? Does it use an existing algorithm?\n    8.  What are $H’$ and $W’$ in Line 296? How do they differ from the output height $\\alpha$ and width $\\beta$ (from Line 208)? What is the original input shape? Why is it necessary to further expand it to $H’ \\times W’$?\n    9.  What does the symbol $\\mathcal{S}^{\\circ 3}$ in Line 383 specifically refer to?\n    10. The paper uses three different datasets but lacks details about the datasets themselves, such as data format, dimensions, and scale.\n3.  The ablation study is too coarse. It merely provides a combinatoric comparison of component performance. The current experiments and corresponding analysis fail to reflect the reasonableness of individual components or link them to their intended design motivations.\n4.  The paper's contribution is obscured by its opaque and dense writing style. The readability is poor, posing a significant barrier to accurately assessing its novelty, technical correctness, and contribution. The authors tend to use lengthy, overly-specialized jargon and forcibly \"stitch\" complex concepts from optical physics and deep learning into single sentences, resulting in convoluted explanations. More critically, the core \"physics-inspired\" design lacks clear, high-level intuition. Instead of first conceptually explaining why specific architectural choices are reasonable analogies for particular physical phenomena, the authors directly present structural descriptions and implementation details, before immediately jumping into complex mathematical derivations. This makes the \"physics-inspired\" claims feel more like post-hoc justifications rather than the driving force behind the design.\n5.  There are formatting issues. The authors have excessively compressed the line spacing in the text (e.g., Lines 203 and 308). I am unsure if this violates the ICLR conference's formatting requirements, but it creates a visually jarring layout."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kY98p91vWt", "forum": "AlqrnU93o7", "replyto": "AlqrnU93o7", "signatures": ["ICLR.cc/2026/Conference/Submission10388/Reviewer_hbsw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10388/Reviewer_hbsw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761651032526, "cdate": 1761651032526, "tmdate": 1762921709961, "mdate": 1762921709961, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies NLOS vision by classifying hand gestures from indirect wall shadows. It proposes RacoNet, a physics-guided model combining light-transport constraints (RCLT) and a geometry-recovery module (GIAO), fused via KA-ELNR. Across three simulated sign-language datasets (plus one small measured setup), RacoNet beats general-purpose vision backbones, suggesting that physics-informed modeling helps on this synthetic shadow-classification task."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper propose a physics-aware deep architecture that explicitly models light transport and incorporates geometric reasoning, which is conceptually sound. This reflects a thoughtful attempt to bridge physical modeling with neural network design."}, "weaknesses": {"value": "- The paper frames the work as NLOS decoding, but the core evaluation is closed-set classification of static hand gestures. NLOS problems typically prioritize reconstructing occluded geometry/appearance and then reasoning on top. Without any reconstruction, pose recovery, or even an interpretable intermediate, it’s hard to claim broader NLOS competence. A simple multi-task variant or silhouette/pose proxies would strengthen the case.\n\n- Most baselines are general-purpose vision backbones that aren’t designed for NLOS. The paper should compare against passive NLOS pipelines that first reconstruct an image/silhouette/volume from wall observations and then classify. A two-step reconstruct-then-classify baseline might be competitive and would reveal whether RacoNet’s end-to-end approach is truly advantageous for NLOS.\n\n- The main results rely on shadows simulated from sign-language datasets; the single measured set appears to be captured in a controlled testbed with fixed geometry. There is no evidence of performance in realistic conditions. Claims about cross-room communication remain speculative without demonstrations under varied, messy setups.\n\n- Apart from limited lighting variation within the simulator, the paper does not stress test common NLOS failure modes: ambient flicker, dynamic illuminants, motion blur, defocus, rolling-shutter distortions, low-bit-depth quantization, mixed wall materials, or geometry shift. A principled robustness suite and cross-setup generalization study are needed."}, "questions": {"value": "Please refer to weakness for more details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XFh6k4Qki3", "forum": "AlqrnU93o7", "replyto": "AlqrnU93o7", "signatures": ["ICLR.cc/2026/Conference/Submission10388/Reviewer_tf9f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10388/Reviewer_tf9f"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809173437, "cdate": 1761809173437, "tmdate": 1762921709511, "mdate": 1762921709511, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenging problem of Non-Line-of-Sight (NLOS) gesture recognition by proposing a method to decode gestures solely from their highly distorted, dynamic shadows . The central contribution is a novel deep learning framework, named RacoNet, designed to interpret these subtle shadow variations. The key idea behind RacoNet is to decompose the complex inverse problem into modeling two distinct aspects: the physics of light propagation and the geometry of the occluded source . To this end, the framework incorporates: (1) a Radiance-Constrained Light-Transportation (RCLT) module, which further splits into two streams to separately model axial and scattered light paths ; (2) a Geometric Information Aliment Operation (GIAO) module to recover the latent geometry of the hand gesture ; and (3) a Kolmogorov-Arnold Enhanced Layerwise Nonlinear Reorganization (KA-ELNR) module to effectively fuse the physical and geometric features for the final classification . The authors validate their approach through experiments on both simulated (S-Numbers, S-MNIST) and physically captured (S-MNISTm) datasets, demonstrating that RacoNet significantly outperforms existing methods in decoding accuracy and robustness ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Originality and Significance of the Problem:** I appreciate the problem posed in this paper—camera-based Non-Line-of-Sight (NLOS) gesture recognition. This task elegantly bridges the two interesting fields of NLOS perception and gesture recognition and has clear practical implications. To my knowledge, this is the first work to investigate this specific problem. I am pleased to see efforts aimed at extending the scope of passive NLOS tasks.\n\n2. **Methodological Innovation:** I think the proposed Radiance-Constrained Light-Transportation (RCLT) module particularly novel. This module provides a well-reasoned decomposition of the NLOS projection problem into direct (axial) and scattered components. This is a clever way to introduce strong physical priors into the network architecture, and this physics-informed approach is a clear strength over generic vision models. While the novelty of the GIAO and KA-ELNR modules is less immediately apparent to me, the overall methodological framework remains innovative, primarily due to the RCLT design.\n\n3. **Completeness of the Work:** The paper's appendix provides a solid mathematical formalism to illustrate the physical principles behind RCLT (e.g., Appendix A.1, A.2), which I greatly appreciate. Furthermore, the appendix includes an innovative extension to the decoding of continuous gesture sequences (via the text reassembly experiment in Appendix A.7), and also presents thorough robustness experiments (Appendix A.10, A.11). Overall, this makes the work feel well-rounded and comprehensive.\n\nCollectively, these significant strengths in problem formulation and methodological design form the basis for my positive assessment of the paper."}, "weaknesses": {"value": "However, the paper has significant weaknesses in other areas (primarily the two major concerns listed below), which make me to recommend a score of 4 (Borderline Accept). Should the authors be able to address these two primary concerns during the rebuttal phase, I would be happy to raise my score to 5-6.\n\n1. **Generalization of the proposed network:**\n\n   The experimental evaluation, while extensive in some aspects, critically lacks validation of the model's generalization capabilities. I think generalization is one of the most important aspect for any NLOS method due to the ill-posed nature of the NLOS problem. The current experiments are performed on datasets generated under specific, controlled conditions. It is unclear how the model would perform under slight variations, which are inevitable in real-world scenarios. Key unanswered questions include:\n\n   * **Cross-Subject Generalization:** How does the model perform on gestures made by a person not seen during training?\n   * **Scene Generalization:** How robust is the model to minor changes in the physical scene, such as a different camera position or light source angle?\n\n   Without these experiments, it is difficult to assess whether the network has learned a generalizable physical model or has simply overfit to the specific training environment.\n\n   Although the appendix gives robustness experiments on illumination (Appendix A.10) and noise (Appendix A.11), this is different from generalization experiments, because illumination and noise do not have an essential impact on the optical transport model, nor are they the main factors of variation in practical applications (different people and scenes).\n\n   Therefore, I strongly suggest the authors to provide generalization results under different subjects and scene conditions in their rebuttal, as this will critically impact the evaluation of the proposed method.\n\n2. **Clarity and Presentation:**\n\n   The other primary weakness of the paper lies in its clarity, particularly in the introduction. The final paragraph of the introduction (Section 1), which is meant to outline the proposed method, is laden with highly technical and unexplained jargon (e.g., \"high-order optical joint encoding,\" \"missing latent space prior,\" \"subspace decomposition nonlinear blocks\"). This makes it exceedingly difficult, even for a reader familiar with the NLOS field, to grasp the core intuition and workflow of the proposed method without delving deep into the methodology section. This significantly hinders the accessibility and initial feeling of the paper.\n\n   Furthermore, Figure 2, the main architecture diagram, is confusing as it fails to clearly illustrate the data flow between the GIAO module and the main RCLT-KA-ELNR pipeline.\n\n   I suggest that the authors clearly state in their rebuttal how they plan to modify the Introduction and Figure 2 to improve readability.\n\n3. **Minor Issues:**\n\n   * The literature review in the Related Works section (Section 2.1) could be more comprehensive, as it appears to omit some classic and relevant works in passive NLOS imaging.\n   * The use of the term \"photonic propagation\" is imprecise for a system using a conventional camera; \"light propagation\" or \"optical propagation\" would be more appropriate."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V4EFVcqz33", "forum": "AlqrnU93o7", "replyto": "AlqrnU93o7", "signatures": ["ICLR.cc/2026/Conference/Submission10388/Reviewer_Mv3c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10388/Reviewer_Mv3c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910729429, "cdate": 1761910729429, "tmdate": 1762921708830, "mdate": 1762921708830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the innovative direction of \"achieving cross-room communication solely by decoding gesture shadows\" and proposes a Radiation-constraint Network (RacoNet) to address the core challenges of dynamic shadow decoding. The key contributions are: designing the RCLT module to model axial and scattered light transmission via dual paths, accurately capturing light-space information; proposing the GIAO module to hierarchically recover the source-scene geometric structure, compensating for geometric loss caused by nonlinear transformations; constructing the KA-ELNR module to realize nonlinear fusion of light-space and geometric information. Experiments show that RacoNet achieves state-of-the-art performance on three datasets and exhibits robustness under illumination changes and noise interference, providing a new solution for non-line-of-sight communication, privacy-preserving gesture interaction and other scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Outstanding originality: For the first time, it systematically explores the feasibility of gesture shadows as a cross-room communication medium, proposing a complete framework of \"physical modeling-geometric recovery-feature fusion\". The design of three core modules specifically addresses the unique challenges of shadow decoding, with innovative research direction and technical route.\n2.Excellent research quality: The experimental design is comprehensive, covering synthetic and measured datasets, verifying model performance through multiple metrics; ablation experiments detailedly validate the necessity of each module and key components; supplementary robustness experiments under illumination changes and noise interference enhance the credibility of conclusions.\n3.Clear presentation: The paper has a coherent structure, progressing layer by layer from problem formulation, related work to method design and experimental verification; framework diagrams and ablation tables intuitively show the method flow and advantages, and technical details (such as frequency modulation of RCLT, hierarchical encoding of GIAO) are elaborated in detail for easy understanding.\n4.Practical value: Focusing on practical needs such as non-line-of-sight communication and privacy protection, the results can be applied to disaster rescue, security surveillance, intelligent interaction and other scenarios, and provide new research ideas for shadow semantic decoding, NLOS imaging and other fields."}, "weaknesses": {"value": "1.Limited scene adaptability: Experiments only verify the decoding effect of static gestures (digital and alphabet sign language) and do not involve dynamic continuous gesture sequences; the decoding performance under different distances and different diffusive surface materials is not evaluated, and the adaptability to real scenarios needs to be verified.\n2.Suboptimal computational efficiency: RacoNet has a high parameter count (188.4M) and computational complexity (43.1G FLOPs), lacking efficiency advantages compared to lightweight models; no model lightweight schemes are explored, which is not conducive to deployment on edge devices.\n3.Insufficient transparency of module design details: The nonlinear reorganization mechanism based on Kolmogorov-Arnold theory in the KA-ELNR module is described relatively abstractly, lacking clear mathematical derivation and intuitive visualization explanation; the fusion strategy of RCLT dual-path branches does not explain whether it dynamically adapts to different shadow scenarios."}, "questions": {"value": "1.What is the performance of RacoNet in decoding dynamic continuous gesture sequences? Can supplementary experiments under different gesture speeds and sequence lengths be provided to illustrate its adaptability to dynamic scenarios?\n2.Can supplementary decoding experiments under different propagation distances and different diffusive surface materials (such as walls, fabrics) be provided? What is the performance boundary of the model in extreme scenarios such as severely blurred shadows and multiple occlusions?\n3.Compared with NLOS geometric recovery methods proposed after 2024 (such as models based on neural radiance fields), what are the advantages of RacoNet in decoding accuracy, robustness, and computational efficiency?\n4.How sensitive is the model to shadow projection angle and light source intensity? Can relevant ablation experiments be supplemented to illustrate the impact of these factors on decoding performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "zrP1KqYJJ0", "forum": "AlqrnU93o7", "replyto": "AlqrnU93o7", "signatures": ["ICLR.cc/2026/Conference/Submission10388/Reviewer_XFgg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10388/Reviewer_XFgg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762086348394, "cdate": 1762086348394, "tmdate": 1762921708385, "mdate": 1762921708385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}