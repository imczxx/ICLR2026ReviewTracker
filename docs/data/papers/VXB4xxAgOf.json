{"id": "VXB4xxAgOf", "number": 15413, "cdate": 1758251086750, "mdate": 1759897308591, "content": {"title": "Discrete Adjoint Matching", "abstract": "Computation methods for solving entropy-regularized reward optimization—a class of problems widely used for fine-tuning generative models—have advanced rapidly. Among those, Adjoint Matching (AM, Domingo-Enrich et al., 2025) has proven highly effective in continuous state spaces with differentiable rewards. Transferring these practical successes to discrete generative modeling, however, remains particularly challenging and largely unexplored, mainly due to the drastic shift in generative model classes to discrete state spaces, which are nowhere differentiable. In this work, we propose Discrete Adjoint Matching (DAM)—a discrete variant of AM for fine-tuning discrete generative models characterized by Continuous-Time Markov Chains, such as diffusion-based large language models. The core of DAM is the introduction of discrete adjoint—an estimator of the optimal solution to the original problem but formulated on discrete domains—from which standard matching frameworks can be applied. This is derived via a purely statistical standpoint, in contrast to the control-theoretic viewpoint in AM, thereby opening up new algorithmic opportunities for general adjoint-based estimators. We showcase DAM’s effectiveness on synthetic and mathematical reasoning tasks.", "tldr": "Discrete Adjoint Matching for fine-tuning discrete generative models on reasoning tasks.", "keywords": ["Discrete Diffusion Model", "Fine Tuning", "Continuous-Time Markov Chain", "Adjoint Matching"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ec34d860a8edad01dcf1e0e291c05247561c3e76.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper under consideration proposes an algorithm to fine-tune a discrete generative model. The core idea is to develop a discrete analog of the Adjoint Matching method recently proposed by Domingo Enrich et al. for continuous models. To achieve this generalization, the authors obtain at Theorem 2.2 an equation for the adjoint discrete variable that mirrors the stochastic Maximum principle for the auxiliary stochastic control problem used in Domingo Enrich et al. The resulting algorithm (Algorithm 1) is then derived following closely the strategy used in continuous spaces, with some differences. For example, samples from the optimal law $p^{\\star}$, which are required to leverage the adjoint equation, are approximated using importance weights (Prop 2.4). The paper is completed by further theoretical results that elucidate similarities with the continuous setting (Sec. 3) and a section on numerical experiments where the method is tested both on synthetic examples and more complex mathematical reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper extends an algorithmical framework that has drawn quite some attention for continuous models to the discrete setting in a principled way. The numerical results appear quite convincing."}, "weaknesses": {"value": "- There is no theoretical guarantees of convergence for the proposed method (as there is none for its continuous counterpart). This is a sever limitation, in my opinion.\n\n* On the methodological side, AM in continuous state space requires the pre-trained model to be such that the initial and final states are independent. I find this a very strong requirement hard to satisfy in practice, unless the pre-trained model had been designed to have such property. If I am not mistaken the same limitation is present here. I encourage the authors to clarify this point."}, "questions": {"value": "- It seems to me that in equation (6) $f(y)$ should be replaced by $f(y)-f(X_\\tau)$\n\n\n\n- The paper puts quite some emphasis on the fact that the derivation of Theorem 2.2 avoids \"convoluted control-theoretic derivation adopted in original AM and providing a more general framework for adjoint-based estimators.\" But at the end of the day, it seems to me that equation (8) is a form of the Pontryagin maximum principle for jump process, and I don't feel that it would be so difficult to obtain following for example  the framework developed in Appendix F of [1] for the control of CTMCs. From this perspective, many aspects of (8), such as the multiplicative nature of the control, appear as rather natural than surprising. I believe that adding the statistical estimator perspective offered in this work is valuable, and I am happy to see it. However, offering also a control theoretical approach would make it even clearer why the method proposed here is the discrete counter part of AM which ultimately relies on equation (3), which is nothing but the Pontryagin maximum principle. Relegating the control-theoretic derivation of Theorem 2.2 to the appendix does not appear to be a good choice to me. \n\n*[1]  Le-Tuyet-Nhi, P. H. A. M., Shariatian, D., Ocello, A., Conforti, G., & Durmus, A. O. Discrete Markov Probabilistic Models: An Improved Discrete Score-Based Framework with sharp convergence bounds under minimal assumptions. In Forty-second International Conference on Machine Learning.*"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CuAPewrb1W", "forum": "VXB4xxAgOf", "replyto": "VXB4xxAgOf", "signatures": ["ICLR.cc/2026/Conference/Submission15413/Reviewer_uj3e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15413/Reviewer_uj3e"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15413/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761167917743, "cdate": 1761167917743, "tmdate": 1762925689844, "mdate": 1762925689844, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces **Discrete Adjoint Matching (DAM)**, a framework for **fine-tuning discrete generative models**—such as diffusion-based large language models—through an **entropy-regularized optimization** approach. DAM extends the Adjoint Matching (AM) method, previously designed for continuous diffusion models, to discrete state spaces modeled as Continuous-Time Markov Chains (CTMCs).\n\nThe authors derive a **discrete analogue of the adjoint system** using Dynkin’s formula, providing a statistical interpretation that avoids the control-theoretic derivations used in AM. This leads to an estimator for the optimal transition rates between discrete states, enabling fine-tuning without requiring differentiability.\n\nTo make DAM computationally feasible, the paper introduces **variance reduction** and **importance weighting** techniques, and adapts the method to masked diffusion models, common in language modeling. Theoretically, it provides guarantees via fixed-point and adjoint equations linking DAM to optimal control formulations.\n\nExperiments on synthetic datasets show DAM closely matches the true optimal distributions, outperforming prior baselines like `D1` and `SVDD`. Applied to mathematical reasoning tasks (`GSM8K`, `MATH500`, `Countdown`), DAM yields consistent improvements in accuracy and reward metrics over `D1`."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. **Clear conceptual motivation:**\nThe paper addresses a timely and well-motivated gap — extending adjoint-based optimization methods, previously limited to continuous diffusion models, to the discrete generative setting, which is crucial for language and symbolic models.\n2. **Principled extension of Adjoint Matching:**\nDAM is a nontrivial discrete analogue of Adjoint Matching (AM), retaining its optimization-by-simulation philosophy while adapting it to the constraints of discrete-time, discrete-state Markov processes.\n3. **Practical algorithmic contributions:**\nThe inclusion of variance reduction and importance weighting makes the method computationally tractable and numerically stable, which is key for large-scale discrete models.\n4. **Bridge between theory and practice:**\nBy grounding the derivation in both stochastic process theory and discrete optimization, DAM provides a conceptual bridge linking probabilistic control, discrete diffusion, and reinforcement-style objectives.\n5. **Empirical effectiveness:**\nExperiments show consistent and interpretable improvements over strong baselines (e.g., D1, SVDD) on synthetic reasoning and mathematical datasets, validating the theoretical claims."}, "weaknesses": {"value": "1. **Clarity and depth of the theoretical exposition:**\nThe theoretical development is solid and well-motivated, but occasionally dense. Some key derivations—particularly the transition from Dynkin’s formulation to the discrete adjoint system—could be presented with more intuition and interpretive discussion, to help the reader understand the underlying mechanics beyond the formal algebra.\n2. **Limited discussion of importance sampling techniques:**\nThe paper briefly introduces importance weighting and variance reduction, which are essential for practical implementation, but this part remains somewhat underexplored.\nA more detailed analysis of variance control, proposal distribution selection, or adaptive resampling strategies would strengthen the empirical and theoretical credibility of the approach. It would also help to understand how importance sampling interacts with the entropy-regularized objective in high-dimensional discrete settings.\n3. **Positioning within the broader literature:**\nThe paper’s theoretical contribution could be better contextualized by referencing recent advances connecting stochastic control and diffusion models, such as Pham et al. (2025) [1], where the control–diffusion duality and adjoint computations bear a strong resemblance to those derived here. Acknowledging and comparing these perspectives would clarify the novelty and relevance of DAM within this rapidly developing area.\n4. **Empirical diagnostics and ablations:**\nAlthough results are consistent and promising, the paper would benefit from additional ablation studies—for example, isolating the contributions of entropy regularization, importance weighting, and the adjoint update itself. Such diagnostics would offer clearer insight into which components most directly influence performance.\n\n[1] Pham, L.T.N., et al. “_Discrete Markov Probabilistic Models: An Improved Discrete Score-Based Framework with Sharp Convergence Bounds under Minimal Assumptions._” Forty-second International Conference on Machine Learning (ICML, 2025)."}, "questions": {"value": "1. **On the discrete adjoint formulation:** Are there particular conditions (e.g., reversibility, bounded rates) under which the discrete adjoint simplifies to known forms?\n2. **On importance sampling and variance reduction:**\n- The section on importance weighting is promising but rather concise. Could the authors expand on how proposal distributions are selected or adapted during training?\n- Can the authors quantify the variance or bias behavior of the estimator as a function of time horizon or dimensionality?\n- How sensitive is DAM to poor proposal distributions, and could hybrid approaches (e.g., reweighting combined with entropy regularization) mitigate this issue?\n3. **On the link with stochastic control theory:** There are strong conceptual parallels between this work and recent formulations of diffusion models within stochastic control frameworks, such as in Pham et al. (2025) [1]. Could the authors clarify whether DAM can be interpreted as a discrete analogue of the Hamilton–Jacobi–Bellman (HJB) formulation underlying those control-based methods?\n4. **On scalability and applicability:**\n- How does the computational cost of DAM scale with the number of discrete states or sequence length?\n- Could the authors comment on potential approximations or sparsity strategies for handling large vocabularies in text diffusion models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HJsAxQgkHb", "forum": "VXB4xxAgOf", "replyto": "VXB4xxAgOf", "signatures": ["ICLR.cc/2026/Conference/Submission15413/Reviewer_Gkkg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15413/Reviewer_Gkkg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15413/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917863339, "cdate": 1761917863339, "tmdate": 1762925689406, "mdate": 1762925689406, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes discrete adjoint matching, which is a theoretical framework to conduct reinforcement learning on discrete diffusion models."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1, The motivation is clear and significant, locating at the need of reward-guided fine-tuning of discrete diffusion-based models.\n\n2, The theoretical seems to be sound."}, "weaknesses": {"value": "This seems to be a quite good paper. But I am not a theory expert. So I will be alert to any issues raised by other reviewers. Also, I want to raise a question about the performance of Llada-8b on GSM-8K. According to [A], the performance of base Llada model on GSM-8K is 80+. But in your paper, the performance is 60-70. Could you please explain this gap?\n\nReference:\n\n[A] Revolutionizing Reinforcement Learning Framework for Diffusion Large"}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "IkYlUp62LQ", "forum": "VXB4xxAgOf", "replyto": "VXB4xxAgOf", "signatures": ["ICLR.cc/2026/Conference/Submission15413/Reviewer_d4QG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15413/Reviewer_d4QG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15413/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962167957, "cdate": 1761962167957, "tmdate": 1762925688805, "mdate": 1762925688805, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Discrete Adjoint Matching (DAM), which is a novel method for solving the following problem: how to fine-tune discrete generative models (like mask-based diffusion Large Language Models) using the reward-based framework called Adjoint Matching (earlier approach works on continuous diffusion/flow models).\n\nThe work is a significant contribution, providing a solution that is not only mathematically elegant and theoretically sound but also demonstrably effective in practice, achieving state-of-the-art results on complex reasoning tasks.\n\nThe paper's context is entropy-regularized optimization, which is a formal way to fine-tune a pre-trained generative model ($p^{\\text{base}}$) to maximize a reward (or minimize a terminal loss, $g(X_1)$) without straying too far from its original training. The previous method for this, Adjoint Matching (AM), is highly effective for continuous models (like image diffusion models) because it uses gradients ($\\nabla g$) as a steering signal. However, this gradient-based approach fails for discrete models because it needs to take a gradient over a discrete set of words. The authors bridge this gap. They propose Discrete Adjoint Matching (DAM), a new formulation that adapts AM to the discrete world. The core innovation is replacing the additive gradient correction of AM with a multiplicative correction factor derived from the exponential of the terminal loss difference (i.e., $e^{-g(y)+g(X_1)}$)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors provide a deep theoretical analysis to prove their method for discrete version of AM. They use fixed-point equations to prove that their practical algorithm is guaranteed to converge to the true, theoretically perfect optimal solution\n- The authors address a computationally impossible problem in their theoretically optimal solution. They then methodically build a practical solution: estimation via sampling and approximate the correction factor by sampling a few possible futures (K samples). They also adapts the method to masked diffusion models. \n- The experiments are clear and decisive. DAM achieves state-of-the-art accuracy on three difficult mathematical reasoning benchmarks"}, "weaknesses": {"value": "- The algorithm requires $K$ model-forward passes per training step to build its estimator. While this is clearly effective on an 8B model, the cost for fine-tuning much larger models (e.g., 70B+) is not discussed. A small experiment reporting training time vs. final accuracy for DAM and D1 would make the paper's practical claims much stronger.\n- A valuable addition to the empirical analysis would be an ablation study on the number of samples K used in the importance-weighted estimator."}, "questions": {"value": "Please see the weakness above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ouMa5QVcfU", "forum": "VXB4xxAgOf", "replyto": "VXB4xxAgOf", "signatures": ["ICLR.cc/2026/Conference/Submission15413/Reviewer_Wztv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15413/Reviewer_Wztv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15413/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972183232, "cdate": 1761972183232, "tmdate": 1762925688456, "mdate": 1762925688456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}