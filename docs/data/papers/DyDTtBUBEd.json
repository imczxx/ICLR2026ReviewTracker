{"id": "DyDTtBUBEd", "number": 16976, "cdate": 1758270842087, "mdate": 1759897206756, "content": {"title": "Learning Ising Models under Hard Constraints using One Sample", "abstract": "We consider the problem of estimating the inverse temperature parameter $\\beta$ of an $n$-dimensional truncated Ising model using a single sample. Given a graph $G = (V,E)$ with $n$ vertices, a truncated Ising model is a probability distribution over the $n$-dimensional hypercube {-1,1}$^n$ where each configuration $\\mathbf{\\sigma}$ is constrained to lie in a truncation set $S \\subseteq $ {-1,1}$^n$ and has probability $\\Pr(\\mathbf{\\sigma}) \\propto \\exp(\\beta\\mathbf{\\sigma}^\\top A_G \\mathbf{\\sigma})$ with $A_G$ being the adjacency matrix of $G$. We adopt the recent setting of [Galanis et al. SODA'24], where the truncation set $S$ can be expressed as the set of satisfying assignments of a $k$-CNF formula. Given a single sample $\\mathbf{\\sigma}$ from a truncated Ising model, with inverse parameter $\\beta^*$, underlying graph $G$ of bounded degree $\\Delta$ and $S$ being expressed as the set of satisfying assignments of a $k$-CNF formula, we design in nearly $\\mathcal{O}(n)$ time an estimator $\\hat{\\beta}$ that is $\\mathcal{O}(\\Delta^3/\\sqrt{n})$-consistent with the true parameter $\\beta^*$ for $k \\gtrsim \\log(d^2 k)\\Delta^3.$\n\nOur estimator is based on the maximization of the pseudolikelihood, a notion that has received extensive analysis for various probabilistic models without [Chatterjee, Annals of Statistics '07] or with truncation [Galanis et al. SODA '24]. Our approach generalizes recent techniques from [Daskalakis et al. STOC '19, Galanis et al. SODA '24], to confront the more challenging setting of the truncated Ising model.", "tldr": "", "keywords": ["Ising Model", "Truncated Statistics", "Pseudo-Likelihood Estimation", "Parameter Estimation"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b46e14b445019b4d758e841993912b902d580764.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper considers the problem of estimating the inverse temperature parameter of a Ising model constrained to the satisfying assignments of a $k$-SAT formula, from 1 sample. \n\nThe graph and formula are given, and the graph is assumed to have bounded degree $\\Delta$, and for the SAT formula the number of clauses is assumed large relative to the degree of the graph and the formula, $\\Omega(\\Delta^3\\log(dk+1))$. The main result is an efficient (nearly linear-time) algorithm using the maximum pseudolikelihood estimator, which learns $\\beta$ within $O(\\Delta^3/\\sqrt n)$ with high probability. There is an exponential dependence on the size $B$ of $\\beta$.\n\n(Note that the setting of \"learning under 1 sample\" encomposses the setting of learning under multiple ($N$) samples, by simply defining a graph and constraints that are disjoint copies of the original, giving the natural $1/\\sqrt{N}$ scaling in error.)"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem of learning graphical models is an important problem. This paper follows a line of work on learning the Ising model, where a natural generalization is to consider a model truncated by hard constraints. SAT formulas provide a natural family of constraints. The pseudolikelihood estimator is a widely used estimator for its computation efficiency, and this paper gives guarantees for it in a constrained setting.\n\nThe work is technically novel, as learning a model under constraints requires new techniques compared to learning without constraints. To bound error in the pseudo-likelihood estimator it suffices to (1) upper bound the first derivative of the log pseudo-likelihood using the technique of exchangeable pairs and (2) lower-bounding the Hessian. The latter is the main challenge, and is done by (a) constructing a linear-sized independent set such that conditioned on the variables outside, the variables inside become a product distribution (ignoring the constraints), and such that the restricted constraints still have large-enough clause sizes, ensured using the Lovasz Local Lemma; this product structure means there are a large number of flippable variables which (b) each contribute to the Hessian by at least a constant, lower bounded by lower-bounding the squared magnetizations of the neighbors of each $i$. \n\nThe proof sketch does a good job of conveying the main ideas of the proof at a high level."}, "weaknesses": {"value": "I find this to be an interesting learning theory paper, but my main concern is whether it is appropriate for the general machine learning audience at NeurIPS. A theoretical CS conference may be a better fit. In particular, the fact the problem considered is solely that of learning the temperature, rather than the entire model, makes the problem quite niche. \n\nThe title is somewhat misleading, as the only parameter that is being learned is the temperature. I suggest \"Learning the temperature of an Ising model under hard constraints\".\n\nThe paper only deals with the case of bounded-degree graphs, and so does not apply to mean-field type models."}, "questions": {"value": "Does the theory work in the case where different weights are allowed on the edges? Needing $A_{ij}\\in \\{\\pm \\frac 1\\Delta\\}$ is quite limiting. It would be much more general to allow all $|A_{ij}|\\le \\frac 1\\Delta$. \n\nIt's necessary for Theorem 2 to exclude the empty graph (where the model is the same under every temperature). Is it sufficient to exclude the empty graph or is there a missing condition?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TbvVQLNbXa", "forum": "DyDTtBUBEd", "replyto": "DyDTtBUBEd", "signatures": ["ICLR.cc/2026/Conference/Submission16976/Reviewer_ymcN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16976/Reviewer_ymcN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962524201, "cdate": 1761962524201, "tmdate": 1762926992784, "mdate": 1762926992784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "At a high-level this can be seen as a paper that combines learning ising models from one sample with learnign with truncations. More specifically, the paper studies one-sample estimation of the inverse temperature $\\beta$ for a truncated Ising models where the state space is the satisfying set $S$ of a bounded-degree $k$-SAT formula. The estimator is the standard maximum pseudolikelihood (MPLE), optimized by projected gradient descent. The analysis shows the MPLE gradient concentrates at $\\beta^*$ (via exchangeable pairs) and that the normalized log-pseudolikelihood is strongly convex w.h.p. The latter is the challenging part, and requires proving the existence of a linear number of flippable coordinates using an independent-set/LLL argument, under large enough $k$."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a novel setting, that seems somewhat motivated.\n- The analysis requires new techniques to prove strong convexity, which involves circumventing a few challenges.\n- The paper is generally well-written, and easy to follow. It also does a good job of covering related work."}, "weaknesses": {"value": "- The paper could do with a bit more motivation for the setting, and in particular $k$-SAT, since it seems more of a purely theoretical pursuit.\n- The clause-size requirement $k \\gtrsim e^{2B}\\Delta^3(\\log d+\\log k)$ is quite large. In bounded-degree regimes, such $k$ pushes the truncation toward an LLL-like easy regime where $|S|/2^n = 1-o(1)$. The constraint can become somewhat vacuous, making the setting not clear.\n- The assumptions and dependencies seem a bit loose or proof technique specific. For example, Assumption $A_{ij}\\in{\\pm 1/\\Delta}$ and $\\Delta=o(n^{1/6})$ feels stronger than necessary."}, "questions": {"value": "- My main question is around the choice of $k$ being justified. As a follow-up, which of their techniques would extend to more interesting settings?\n- It would be helpful if the authors describe which dependencies are necessary and tight, and which are loose. Especially $\\Delta$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HrRPH4d9JE", "forum": "DyDTtBUBEd", "replyto": "DyDTtBUBEd", "signatures": ["ICLR.cc/2026/Conference/Submission16976/Reviewer_2qpS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16976/Reviewer_2qpS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762229328209, "cdate": 1762229328209, "tmdate": 1762926992222, "mdate": 1762926992222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of learning the inverse temperature of a truncated Ising model from one data sample. The Ising model is constrained to lie within a specific set (referred to as that satisfying the k-SAT formula). The authors provide various practical scenarios to motivate this setting. The theoretical results hinge on the analysis of the maximum pseudolikelihood estimator and demonstrate its consistency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Theoretical arguments are well-stated (although there are some key definitions are missing; see Weaknesses section). The theoretical analysis is based on establishing guarantees on the first order and second order gradients of the pseudolikelihood estimator relative to the inverse temperature function. The novelty is (seemingly) claimed in terms of establishing the bound on the second order derivative in Lemma 3.3."}, "weaknesses": {"value": "1. The key definition of $k$-SAT formula or how it leads to a hard constraint on the Ising model is not defined with sufficient rigor. Therefore, I could not fully understand why this particular setting was of interest.\n2. The novelty within the theoretical results should be emphasized better- some results seem to be simple extensions of previous works, while others are novel. The distinction between the two should be elucidated.\n3. While I appreciate the theoretical flavor of this work, some effort into making the theoretical results interpretable for practitioners would have improved this paper."}, "questions": {"value": "1. What is meant by ${\\cal O}(\\Delta^3 n \\log n)$-Algorithm?\n2. The theoretical bound in Theorem 2 becomes tighter with increasing $n$--suggesting that the estimator is likely to perform better when estimating a larger Ising model with a single sample. Could you elaborate on this aspect? Shouldn't the estimation problem become 'harder' with increasing 'n'?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2V4R38R18L", "forum": "DyDTtBUBEd", "replyto": "DyDTtBUBEd", "signatures": ["ICLR.cc/2026/Conference/Submission16976/Reviewer_fnoj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16976/Reviewer_fnoj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762290401293, "cdate": 1762290401293, "tmdate": 1762926991670, "mdate": 1762926991670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers a truncated Ising model, where an Ising model on a graph G of size $n$ with inverse temperature $\\beta$ is sampled and samples are accepted only based on satisfiable assignments for a $k$-SAT formula. The main question is can you learn inverse temperature parameter $\\beta$ from a single sample from this truncated model. \n\nAuthors show that one can learn the inverse temperature parameter up to an error of $\\Delta^3/\\sqrt{n}$ when the number of clauses in the k-SAT formula exceeds $\\tilde{O}({\\Delta^3})$ and the inverse temperature is in a bounded interval around $0$. Authors main key ideas are by doing a MLE estimate for $\\beta$ on the pseudo likelihood which is the product of likelihood of Glauber flip of every variable conditioned on all others.  1) First, the error in the MLE estimate is bounded by ratio of the magnitude of the first derivative and the minimum second derivative of the log pseudo likelihood. So authors proceed to show that the numerator is small and lower bound the second derivative.  2) Concentration due to exchangeable pairs take care of the concentration of the first derivative which has to be close to zero for the stationary point with a deviation of $\\sqrt{n}$  and the lower bound on the second derivative is at least n/\\Delta^3. \n3) Key issue is that second derivative's lower bound is non trivial only if there are linear number of flippable variables - variable coordinates that can be flipped from the sample without violating $k-SAT$ constraints. Clever trick is that authors show that there is a large enough independent set in the graph such that it encapsulates linear number of variables and conditioning on the rest, the probability of variables in the independent set factorizes. Then it is easy to show that some variable from the independent set will satisfy the clause in which another fixed variable is in with constant probability. This ensures there are enough flipped variables which contributes then to the lower bound on the second derivative."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "Paper considers a very non trivial Ising model with a truncation on the set of satisfiable boolean assignments in a K-SAT formula. Then authors use the Glauber flip based pseudo likelihood to do the MLE estimation of inverse temperature beta from a single sample. \n\nTechniques are quite novel compared to classical results on single sample learning of un-truncated Ising models and other recent works. specifically the independence set finding algorithm that truncates the k-SAT formula with some guarantees used a clean and elegant version of Lovasz Local Lemma. The trick of creating a conditional product distribution and arguing about flippability of variables that lower bound the second derivative is also pretty neat."}, "weaknesses": {"value": "1) My main concern is that Section 3.3.1 starts with arguments ensuring enough variables are flippable. However, there is only a small two line comment of how it is related to second derivative lower bounding. So the reader is forced to look in the supplement as to why this issue is prominent. lemma 3.7 in the supplement shows why enough of such flippable variables are important. It is important to include that argument (in a sketch form) at the beginning of Section 3.3.1 \n\n2) Where does the constraint (or what steps in the proof contribute): $\\Delta \\sim o(n^{1/6}) $ comes from precisely ? \n\n3) After an independent set is chosen, then the rest of the argument about flippability splits into two parts - one is flippability of variables within the independent set and outside. It seems like the first one directly follows from prior work ? So the main novelty is in the construction of the independent set and the argument for flippability of variables outside it ?"}, "questions": {"value": "I have asked all my questions in the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3Z60tN0kOl", "forum": "DyDTtBUBEd", "replyto": "DyDTtBUBEd", "signatures": ["ICLR.cc/2026/Conference/Submission16976/Reviewer_ean9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16976/Reviewer_ean9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762849588110, "cdate": 1762849588110, "tmdate": 1762926990759, "mdate": 1762926990759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}