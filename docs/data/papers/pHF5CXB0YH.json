{"id": "pHF5CXB0YH", "number": 16852, "cdate": 1758269396390, "mdate": 1763560156589, "content": {"title": "CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition", "abstract": "Most machine learning-based image segmentation models produce pixel-wise confidence scores that represent the model’s predicted probability for each class label at every pixel. While this information can be particularly valuable in high-stakes domains such as medical imaging, these scores are heuristic in nature and do not constitute rigorous quantitative uncertainty estimates.\nConformal prediction (CP) provides a principled framework for transforming heuristic confidence scores into statistically valid uncertainty estimates. However, applying CP directly to image segmentation ignores the spatial correlations between pixels, a fundamental characteristic of image data. This can result in overly conservative and less interpretable uncertainty estimates.\nTo address this, we propose CONSIGN (*Conformal Segmentation Informed by Spatial Groupings via Decomposition*), a CP-based method that incorporates spatial correlations to improve uncertainty quantification in image segmentation.\nOur method generates meaningful prediction sets that come with user-specified, high-probability error guarantees.\nIt is compatible with any pre-trained segmentation model capable of generating multiple sample outputs.\nWe evaluate CONSIGN against two CP baselines across three medical imaging datasets and two COCO dataset subsets, using three different pre-trained segmentation models. Results demonstrate that accounting for spatial structure significantly improves performance across multiple metrics and enhances the quality of uncertainty estimates.", "tldr": "We developed a conformal prediction strategy for image segmentation that accounts for spatial correlation to achieve improved results", "keywords": ["Conformal prediction", "Uncertainty quantification", "Image segmentation"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/32d4e15bc1ed0eba4523776ef3ef41b08dbfaf78.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces CONSIGN to improve uncertainty quantification in image segmentation. By leveraging spatial correlations between pixels, CONSIGN produces more meaningful prediction sets with rigorous coverage guarantees compared to traditional pixel-wise conformal prediction methods. The key innovation of CONSIGN is its ability to create spatially-aware prediction sets by incorporating principal component analysis to capture uncertainties in correlated regions, resulting in tighter, more interpretable prediction intervals. Through experiments on medical imaging datasets and COCO dataset subsets, the authors show that CONSIGN significantly outperforms existing CP-based methods, offering improved performance across multiple metrics, including uncertainty volume, empirical coverage, and correlation of samples."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. CONSIGN effectively incorporates spatial correlations between pixels, a critical aspect in image segmentation tasks. This spatial awareness improves the quality of uncertainty estimates by reducing the size of prediction sets, providing more meaningful and interpretable results compared to traditional pixel-wise CP methods.\n2. CONSIGN is highly adaptable to various applications and datasets without requiring significant changes to the underlying model architecture."}, "weaknesses": {"value": "- The method assumes that the calibration and test datasets are exchangeable, which may not hold in many real-world scenarios where distribution shifts or out-of-distribution data are present. The current version of CONSIGN does not address such cases, and extending it to handle distribution shifts could significantly improve its robustness in dynamic environments.\n- it heavily relies on the pre-trained model to generate multiple sample predictions. This means that the method's performance is closely tied to the quality of the pre-trained model, and it may not perform well (like inflated prediction sets) if the base model produces unreliable or poor-quality predictions\n- The method excels at identifying larger uncertain regions, but for small, localized uncertainties (e.g., fine-grained segmentation boundaries), the spatial grouping approach might still lead to overly broad prediction sets. Fine-tuning how small-scale uncertainty is handled, or integrating multi-resolution strategies, could improve the method's accuracy in these cases. \n- The calibration step involves solving a constrained minimization problem to identify the optimal parameter λ, this process can be numerically challenging and does not guarantee global optimality"}, "questions": {"value": "1. Could there be a more robust way to incorporate model uncertainty into the CONSIGN framework to mitigate potential performance degradation?\n2. CONSIGN improves uncertainty quantification by leveraging spatial correlations, how does the method perform in regions with small or subtle uncertainties, such as fine boundaries in segmentation? Are the spatial correlations still effective in these contexts, or does the method tend to overestimate uncertainty in such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KKM94gHJxx", "forum": "pHF5CXB0YH", "replyto": "pHF5CXB0YH", "signatures": ["ICLR.cc/2026/Conference/Submission16852/Reviewer_cy3U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16852/Reviewer_cy3U"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761535148131, "cdate": 1761535148131, "tmdate": 1762926871902, "mdate": 1762926871902, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CONSIGN to improve uncertainty quantification in image segmentation. By leveraging spatial correlations between pixels, CONSIGN produces more meaningful prediction sets with rigorous coverage guarantees compared to traditional pixel-wise conformal prediction methods. The key innovation of CONSIGN is its ability to create spatially-aware prediction sets by incorporating principal component analysis to capture uncertainties in correlated regions, resulting in tighter, more interpretable prediction intervals. Through experiments on medical imaging datasets and COCO dataset subsets, the authors show that CONSIGN significantly outperforms existing CP-based methods, offering improved performance across multiple metrics, including uncertainty volume, empirical coverage, and correlation of samples."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. CONSIGN effectively incorporates spatial correlations between pixels, a critical aspect in image segmentation tasks. This spatial awareness improves the quality of uncertainty estimates by reducing the size of prediction sets, providing more meaningful and interpretable results compared to traditional pixel-wise CP methods.\n2. CONSIGN is highly adaptable to various applications and datasets without requiring significant changes to the underlying model architecture."}, "weaknesses": {"value": "- The method assumes that the calibration and test datasets are exchangeable, which may not hold in many real-world scenarios where distribution shifts or out-of-distribution data are present. The current version of CONSIGN does not address such cases, and extending it to handle distribution shifts could significantly improve its robustness in dynamic environments.\n- it heavily relies on the pre-trained model to generate multiple sample predictions. This means that the method's performance is closely tied to the quality of the pre-trained model, and it may not perform well (like inflated prediction sets) if the base model produces unreliable or poor-quality predictions\n- The method excels at identifying larger uncertain regions, but for small, localized uncertainties (e.g., fine-grained segmentation boundaries), the spatial grouping approach might still lead to overly broad prediction sets. Fine-tuning how small-scale uncertainty is handled, or integrating multi-resolution strategies, could improve the method's accuracy in these cases. \n- The calibration step involves solving a constrained minimization problem to identify the optimal parameter λ, this process can be numerically challenging and does not guarantee global optimality"}, "questions": {"value": "1. Could there be a more robust way to incorporate model uncertainty into the CONSIGN framework to mitigate potential performance degradation?\n2. CONSIGN improves uncertainty quantification by leveraging spatial correlations, how does the method perform in regions with small or subtle uncertainties, such as fine boundaries in segmentation? Are the spatial correlations still effective in these contexts, or does the method tend to overestimate uncertainty in such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KKM94gHJxx", "forum": "pHF5CXB0YH", "replyto": "pHF5CXB0YH", "signatures": ["ICLR.cc/2026/Conference/Submission16852/Reviewer_cy3U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16852/Reviewer_cy3U"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761535148131, "cdate": 1761535148131, "tmdate": 1763650142936, "mdate": 1763650142936, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The submission studies conformal prediction for segmentation models. The submission proposes to construct prediction sets that take into consideration the spatial correlation of the predictions of the base model in order to construct more informative prediction sets. The proposed method uses PCA to find principal directions along which to perturb the raw output of the model.\n\nExperiments compare the proposed method with existing baselines on diverse datasets, containing both medical and natural images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Calibration of segmentation models is an important and under-developed field.\n* Applying PCA decomposition is novel for conformal prediction of segmentation models.\n* Experiments are comprehensive."}, "weaknesses": {"value": "* Presentation could be made more precise.\n* The proposed algorithm is not guaranteed to terminate.\n* The construction is interesting, at the cost of less interpretable prediction sets."}, "questions": {"value": "**Exit condition of Algorithm 1**\n\nThe main limitation of the current method is that it is not guaranteed to terminate with a finite parameter $\\hat{\\lambda} < \\infty$. This seems to contradict the claim that the proposed method will eventually find a $\\lambda$ that contains the ground truth.\n\n- Could the authors expand on whether they experienced this behavior in their experiments? \n\n- Could $\\beta$ be chosen adaptively to guarantee termination of the algorithm?\n\n**Experiments**\n\n- Figure 1 should be introduced more clearly. It is only afterwards, in the experimental results, that it is explained how these segmentation masks are generated via sampling. To a first time reader, it is not clear how Figure 1 is generated.\n\n- The fact that sampling from pixel-wise uncertainty intervals does not respect spatial correlations isn't particularly surprising on its own. Pixel-wise uncertainty intervals are not constructed to sample individual segmentation masks. So, it might be misleading to mention these as inherent limitations of existing works, as it is not what they are designed to solve.\n\n- Have the authors considered applying PCA to the pixel-wise uncertainty intervals? This would also allow to sample segmentation masks that take into consideration the spatial correlation of the pixels. I wonder whether comparing with this baseline could provide stronger evidence in support of the proposed algorithm, that integrates spatial correlation at a deeper level.\n\n- The name \"sampled empirical coverage\" might be confusing because it is reminiscent of the marginal statistical guarantee each method provides. That is, readers might expect all methods to provide sampled empirical coverage at level $1 - \\alpha$ by design.\n\n- It might be helpful to compare with Blot et al. \"Automatically Adaptive Conformal Risk Control\", who include examples on semantic segmentation.\n\n---\n\n**Minor comments**\n\n- The operator $P$ is never defined. It is unclear what taking the argmax of a vector in $\\mathbb{R}^{W \\times H \\times L}$ means. I assume $P$ first reshapes the column vector to $W \\times H \\times L$ and then takes the argmax along the $L$ dimension. This should be made clear.\n- Is $\\beta$ an error rate or an accuracy rate? Typo on line 206 $\\geq 1 - \\beta$?\n- It might be helpful to explicitly define the indicator function in Eq. (8), or to spell it out as set inclusion.\n- It might be helpful to include the raw predictions of the model in Fig. 5"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eOJHegbUDZ", "forum": "pHF5CXB0YH", "replyto": "pHF5CXB0YH", "signatures": ["ICLR.cc/2026/Conference/Submission16852/Reviewer_6bMr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16852/Reviewer_6bMr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761585623763, "cdate": 1761585623763, "tmdate": 1762926871290, "mdate": 1762926871290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The submission studies conformal prediction for segmentation models. The submission proposes to construct prediction sets that take into consideration the spatial correlation of the predictions of the base model in order to construct more informative prediction sets. The proposed method uses PCA to find principal directions along which to perturb the raw output of the model.\n\nExperiments compare the proposed method with existing baselines on diverse datasets, containing both medical and natural images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Calibration of segmentation models is an important and under-developed field.\n* Applying PCA decomposition is novel for conformal prediction of segmentation models.\n* Experiments are comprehensive."}, "weaknesses": {"value": "* Presentation could be made more precise.\n* The proposed algorithm is not guaranteed to terminate.\n* The construction is interesting, at the cost of less interpretable prediction sets."}, "questions": {"value": "**Exit condition of Algorithm 1**\n\nThe main limitation of the current method is that it is not guaranteed to terminate with a finite parameter $\\hat{\\lambda} < \\infty$. This seems to contradict the claim that the proposed method will eventually find a $\\lambda$ that contains the ground truth.\n\n- Could the authors expand on whether they experienced this behavior in their experiments? \n\n- Could $\\beta$ be chosen adaptively to guarantee termination of the algorithm?\n\n**Experiments**\n\n- Figure 1 should be introduced more clearly. It is only afterwards, in the experimental results, that it is explained how these segmentation masks are generated via sampling. To a first time reader, it is not clear how Figure 1 is generated.\n\n- The fact that sampling from pixel-wise uncertainty intervals does not respect spatial correlations isn't particularly surprising on its own. Pixel-wise uncertainty intervals are not constructed to sample individual segmentation masks. So, it might be misleading to mention these as inherent limitations of existing works, as it is not what they are designed to solve.\n\n- Have the authors considered applying PCA to the pixel-wise uncertainty intervals? This would also allow to sample segmentation masks that take into consideration the spatial correlation of the pixels. I wonder whether comparing with this baseline could provide stronger evidence in support of the proposed algorithm, that integrates spatial correlation at a deeper level.\n\n- The name \"sampled empirical coverage\" might be confusing because it is reminiscent of the marginal statistical guarantee each method provides. That is, readers might expect all methods to provide sampled empirical coverage at level $1 - \\alpha$ by design.\n\n- It might be helpful to compare with Blot et al. \"Automatically Adaptive Conformal Risk Control\", who include examples on semantic segmentation.\n\n---\n\n**Minor comments**\n\n- The operator $P$ is never defined. It is unclear what taking the argmax of a vector in $\\mathbb{R}^{W \\times H \\times L}$ means. I assume $P$ first reshapes the column vector to $W \\times H \\times L$ and then takes the argmax along the $L$ dimension. This should be made clear.\n- Is $\\beta$ an error rate or an accuracy rate? Typo on line 206 $\\geq 1 - \\beta$?\n- It might be helpful to explicitly define the indicator function in Eq. (8), or to spell it out as set inclusion.\n- It might be helpful to include the raw predictions of the model in Fig. 5"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eOJHegbUDZ", "forum": "pHF5CXB0YH", "replyto": "pHF5CXB0YH", "signatures": ["ICLR.cc/2026/Conference/Submission16852/Reviewer_6bMr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16852/Reviewer_6bMr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761585623763, "cdate": 1761585623763, "tmdate": 1763745993713, "mdate": 1763745993713, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an approach, CONSIGN, within the conformal prediction framework to calibrate uncertainties output by an arbitrary probabilistic segmentation model. CONSIGN improves upon the existing literature in that it takes into account spatial correlations when outputting prediction sets with user-specified error guarantees. Prediction sets are derived from an SVD decomposition of the samples. The calibration involves an auxiliary constrained optimization step. The approach is demonstrated on 3 medical imaging datasets (M&Ms-2, LIDC and MS-CMR19) as well as two COCO subsets. The approach is tested on top of different segmentation frameworks across these applications: a dropout Unet, probabilistic Unet, and an ensemble networks strategy. The authors show qualitatively superior samples in the prediction sets compared to pixel-wise CP baselines and SACP, as well as report smaller prediction sets (in terms of Chao estimator and higher Pearson correlation between samples) at a fixed error-level, and better compliance to the specified error-level (sampled Empirical Coverage)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Significance and originality: The approach and the problem addressed are interesting, and this is ultimately what informed my choice of rating. There is potential for clear benefits from this type of approach as ignoring spatial correlations in segmentation uncertainties is problematic.\n\n2. Qualitative and quantitative results over several datasets and segmentation backbones are promising."}, "weaknesses": {"value": "1. It is not clear how alpha and beta are chosen across all applications (they differ for each application) and whether results generalize well to other values. Can the authors comment on these choices?\n\n2. The method makes an i.i.d. assumption on the calibration and test sets. This is a strong assumption. In practice, guarantees of validity of the prediction sets may silently fail to apply for images with artefacts and other distribution shifts (unseen pathologies, different image quality, etc.). Yet these are exactly the cases that one would like to be flagged by UQ.\n\n3. Overall readability/presentation could have been slightly improved (not a major concern however). \n\n4. See questions and minor weaknesses below."}, "questions": {"value": "5. It is not completely clear how Eq. 6 is derived and whether with this form, prediction sets have some guarantee of optimality. In particular as lambda is weighted by Sigma_k,k in Eq. 6, the range of values for A_k, B_k as a function of a_k,b_k is not completely clear. Sigma_k,k could also have appeared as a weight to c_k u_k(X) in the equation afterwards. Could the authors provide more details of derivations?\n\n6. Can the authors justify the following claim : \"In other words, even with a truncated PCA the prediction set will always include the ground truth, therefore we can use the standard CRC approach\" ? I would assume that in some failure cases, none of the segmentation samples generated by the segmentation backbone will cover the ground truth; hence any prediction sets derived from them will in turn not cover the ground truth. Can this have substantial effects on the outcome of the proposed method in some degenerate cases?\n\n7. Given that prediction sets for the proposed approach are derived with spatial awareness vs. pixel-wise for PW (RAPS), it is surprising that the estimated volume of prediction sets does not differ by more orders of magnitude in most experiments in Fig 2. Can the authors comment on this? The number of pixel-wise combinations should grow extremely fast compared to the number of spatially-consistent configurations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "a2vrunG16B", "forum": "pHF5CXB0YH", "replyto": "pHF5CXB0YH", "signatures": ["ICLR.cc/2026/Conference/Submission16852/Reviewer_jv9m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16852/Reviewer_jv9m"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761863566282, "cdate": 1761863566282, "tmdate": 1762926870387, "mdate": 1762926870387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an approach, CONSIGN, within the conformal prediction framework to calibrate uncertainties output by an arbitrary probabilistic segmentation model. CONSIGN improves upon the existing literature in that it takes into account spatial correlations when outputting prediction sets with user-specified error guarantees. Prediction sets are derived from an SVD decomposition of the samples. The calibration involves an auxiliary constrained optimization step. The approach is demonstrated on 3 medical imaging datasets (M&Ms-2, LIDC and MS-CMR19) as well as two COCO subsets. The approach is tested on top of different segmentation frameworks across these applications: a dropout Unet, probabilistic Unet, and an ensemble networks strategy. The authors show qualitatively superior samples in the prediction sets compared to pixel-wise CP baselines and SACP, as well as report smaller prediction sets (in terms of Chao estimator and higher Pearson correlation between samples) at a fixed error-level, and better compliance to the specified error-level (sampled Empirical Coverage)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Significance and originality: The approach and the problem addressed are interesting, and this is ultimately what informed my choice of rating. There is potential for clear benefits from this type of approach as ignoring spatial correlations in segmentation uncertainties is problematic.\n\n2. Qualitative and quantitative results over several datasets and segmentation backbones are promising."}, "weaknesses": {"value": "1. It is not clear how alpha and beta are chosen across all applications (they differ for each application) and whether results generalize well to other values. Can the authors comment on these choices?\n\n2. The method makes an i.i.d. assumption on the calibration and test sets. This is a strong assumption. In practice, guarantees of validity of the prediction sets may silently fail to apply for images with artefacts and other distribution shifts (unseen pathologies, different image quality, etc.). Yet these are exactly the cases that one would like to be flagged by UQ.\n\n3. Overall readability/presentation could have been slightly improved (not a major concern however). \n\n4. See questions and minor weaknesses below."}, "questions": {"value": "5. It is not completely clear how Eq. 6 is derived and whether with this form, prediction sets have some guarantee of optimality. In particular as lambda is weighted by Sigma_k,k in Eq. 6, the range of values for A_k, B_k as a function of a_k,b_k is not completely clear. Sigma_k,k could also have appeared as a weight to c_k u_k(X) in the equation afterwards. Could the authors provide more details of derivations?\n\n6. Can the authors justify the following claim : \"In other words, even with a truncated PCA the prediction set will always include the ground truth, therefore we can use the standard CRC approach\" ? I would assume that in some failure cases, none of the segmentation samples generated by the segmentation backbone will cover the ground truth; hence any prediction sets derived from them will in turn not cover the ground truth. Can this have substantial effects on the outcome of the proposed method in some degenerate cases?\n\n7. Given that prediction sets for the proposed approach are derived with spatial awareness vs. pixel-wise for PW (RAPS), it is surprising that the estimated volume of prediction sets does not differ by more orders of magnitude in most experiments in Fig 2. Can the authors comment on this? The number of pixel-wise combinations should grow extremely fast compared to the number of spatially-consistent configurations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "a2vrunG16B", "forum": "pHF5CXB0YH", "replyto": "pHF5CXB0YH", "signatures": ["ICLR.cc/2026/Conference/Submission16852/Reviewer_jv9m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16852/Reviewer_jv9m"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761863566282, "cdate": 1761863566282, "tmdate": 1763748326738, "mdate": 1763748326738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}