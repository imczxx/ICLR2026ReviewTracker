{"id": "DUtfVs1xxD", "number": 3236, "cdate": 1757383664330, "mdate": 1759898100696, "content": {"title": "Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of Prior-Informed Modeling for Online Vectorized HD Map Construction", "abstract": "Safety constitutes a foundational imperative for autonomous driving systems, necessitating maximal incorporation of accessible prior information. This study establishes that temporal perception buffers and cost-efficient high-definition (HD) maps inherently form complementary prior sources for online vectorized HD map construction. We present Uni-PrevPredMap, a unified prior-informed framework systematically integrating previous predictions with corrupted HD maps. Our framework introduces a tri-mode paradigm maintaining operational consistency across non-prior, temporal-prior, and temporal-map-fusion modes. This tri-mode paradigm simultaneously decouples the framework from ideal map assumptions while ensuring robust performance in both map-present and map-absent scenarios. Additionally, we develop a tile-indexed 3D vectorized global map processor enabling efficient 3D prior data refreshment, compact storage, and real-time retrieval. Uni-PrevPredMap achieves state-of-the-art map-absent performance across established online vectorized HD map construction benchmarks. When provided with corrupted HD maps, it exhibits robust capabilities in error-resilient prior fusion, empirically confirming the synergistic complementarity between temporal predictions and imperfect map data. Code is available in supplementary materials.", "tldr": "This paper introduces  a unified prior-informed framework to integrate two synergistic priors: previous predictions and corrupted HD maps.", "keywords": ["online vectorized HD map construction", "prior-informed modeling", "unified framework"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/615058bee4405c56879296d65ed182767a35c6b4.pdf", "supplementary_material": "/attachment/4b4107ccdbbbb30de2f7292e5e955a044208b21f.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a framework for online vectorized High-Definition (HD) map construction in autonomous driving systems. The main idea is to combine prior information from temporally previous predictions and cost-efficient HD maps in a prediction-driven temporal modeling architecture. The proposed Uni-PrevPredMap is derived from previous work of PrevPredMap with two core designs: tile-indexed 3D vectorized global map processor which enables efficient 3D prior updates, compact storage, and real-time retrieval, and a tri-mode paradigm which extends flexibility in handling different combination of prior information. Experiment shows that the proposed Uni-PrevPredMap achieves state-of-the-art performance on a set of public benchmarks including nuScenes and Argoverse2."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The setting of incorporating previous predictions and outdated HD maps prior for robust online HD map construction is reasonable for autonomous driving systems.\n2. The engineering design of tri-mode paradigm enables robust performance in both map-present and map-absent scenarios, which has practical values for real-world autonomous driving systems."}, "weaknesses": {"value": "1. While the motivation of the paper is clear, the experiment validation is not sufficient. The paper declares that previous time predictions and cost-efficient/corrupted HD maps obtained from less frequently updated HD maps and crowd-sourced HD maps are complementary priors for online HD map construction, but there is no experiment validation on using different kinds of corrupted HD maps with different level of corruptions.\n2. The performance improvement in map-absent scenario as stated in Table 1 is not very impressive, i.e the performance gap between MapTracker and Uni-PrevPredMap is only 0.9% in mAP. \n3. The ablation study in table 3 is not clear, from the table, the performance with '+ tile-indexed 3D vectorized global map processor' and '+ tri-mode paradigm' are both 74.0% under 'w/o map' setting, so what's the performance of adding both modules together?"}, "questions": {"value": "1. The paper mentioned that tile-indexed 3D global map processor stores and processes information in 3D, what is its computational cost and memory requirement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iO3bUriX4F", "forum": "DUtfVs1xxD", "replyto": "DUtfVs1xxD", "signatures": ["ICLR.cc/2026/Conference/Submission3236/Reviewer_uNTF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3236/Reviewer_uNTF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761441693177, "cdate": 1761441693177, "tmdate": 1762916619208, "mdate": 1762916619208, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the core requirement of autonomous driving safety: the problem of fusing prior information for online vectorized HD map construction. It points out that time-aware caching and low-cost HD maps are two complementary types of priors, but existing models can only handle one of them in isolation and overly rely on the ideal map assumption. To address this issue, the authors propose a unified prior framework, Uni-PrevPredMap, which addresses the aforementioned issues through the following core designs:\n1. During training, through layered sampling and instance-level map perturbations, the model eliminates its reliance on an ideal map while ensuring robustness in both mapped and unmapped scenarios.\n2. Efficient prior updates, compact storage, and real-time retrieval are achieved based on vehicle UTM coordinates, extending 2D methods to 3D scenarios.\n3. Experimental validation: On the nuScenes (2D) and Argoverse2 (3D) datasets, Uni-PrevPredMap (and its variant Uni-PrevPredMap*, which incorporates corrupted maps) achieves state-of-the-art performance in map-missing scenarios and exhibits strong tolerance to instance-level/frame-level map perturbations (such as displacements, rotations, and additions and deletions), demonstrating the synergistic and complementary nature of the two types of priors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper, for the first time, clearly demonstrates the complementary nature of time-aware caching and low-cost HD maps, demonstrating a strong academic innovation in its design approach.\n\n2. Comprehensive experimental design: Performance advantages are demonstrated on both 2D and 3D datasets, with results such as a mAP of 77.0 after 72 training epochs on nuScenes and 81.8 after integrating corrupted maps.\n\n3. Strong applicability: The framework meets the real-time demands of autonomous driving (inference speed of 11.5-12.2 FPS) and is compatible with low-cost, non-ideal HD maps, reducing the deployment cost of online map building and demonstrating its potential for migration to practical autonomous driving systems."}, "weaknesses": {"value": "1. The paper explicitly states that height data is used only for spatial filtering and does not participate in prior generation. It also mentions that the bottleneck of 3D voxelization exceeding 2D rasterization in computational overhead remains unresolved. This undermines the core value of 3D design (such as priors for distinguishing vertical scenes like elevated roads and tunnels), leaving a gap between the goal of extending the technology to 3D scenarios and requiring further technical exploration.\n\n2. Compared to existing methods, Uni-PrevPredMap's inference speed (11.5-12.2 FPS), while meeting real-time requirements, is lower than some methods (such as MapTRv2's 16.4 FPS and FastMap's 17.2 FPS). The paper mentions that \"parallelizing 3D filtering and rasterization can increase the speed to 14.2 FPS,\" but does not provide actual implementation results or analyze the speed-performance trade-off. Further verification is needed to verify its suitability for scenarios with higher real-time requirements, such as high-speed autonomous driving.\n\n3. The sampling ratio of the three-mode paradigm (non-prior: temporal prior: temporal-map fusion = 0.5:0.3:0.2) was verified to be optimal, but the reason why this ratio was optimal was not explained. For example, the specific impact of different ratios on the model's \"unmapped generalization\" and \"mapped tolerance\" was not explained, nor was the dependence of the ratio selection on dataset characteristics (such as the differences between nuScenes and Argoverse2). This resulted in a lack of support for the transferability of this design."}, "questions": {"value": "1. Regarding 3D information utilization: The paper mentions that height data is only used for spatial filtering. What is the specific reason for not participating in prior generation? Have attempts been made to incorporate height information (e.g., road slope, tunnel height) into prior features (e.g., through multi-dimensional feature concatenation using the BEV encoder)? If so, what are the core technical obstacles encountered (e.g., computational overhead, feature alignment)?\n\n2. Regarding the completeness of the method comparison: Existing comparisons focus on \"single-prior models\" (e.g., MapTracker, which uses only temporal priors, PriorMapNet, which uses only map priors). Are there any baseline methods in the same field that attempt to integrate two types of priors? If so, please provide additional comparisons with these methods to more clearly demonstrate the advantages of the Uni-PrevPredMap framework."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U6H0PTmK5c", "forum": "DUtfVs1xxD", "replyto": "DUtfVs1xxD", "signatures": ["ICLR.cc/2026/Conference/Submission3236/Reviewer_fBUh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3236/Reviewer_fBUh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761568383264, "cdate": 1761568383264, "tmdate": 1762916618786, "mdate": 1762916618786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Uni-PrevPredMap, a unified framework for online vectorized HD map construction that integrates two complementary prior sources: temporal perception buffers (previous predictions) and cost-efficient, potentially corrupted HD maps. The core contribution is a tri-mode paradigm (non-prior, temporal-prior, and temporal-map-fusion) that ensures operational consistency and robust performance in both map-present and map-absent scenarios. By training with instance-level perturbations on map priors, the model is decoupled from ideal map assumptions and demonstrates strong error-resilient fusion capabilities. The framework is supported by a tile-indexed 3D vectorized global map processor for efficient, real-time prior retrieval and refreshment. Uni-PrevPredMap achieves state-of-the-art performance on map-absent benchmarks and empirically confirms the synergistic benefit of fusing temporal predictions with imperfect map data."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The introduction of corrupted HD maps as an additional prior modality is interesting.\n2. The proposed method is empirically strong, achieving state-of-the-art performance on standard online vectorized HD map construction benchmark sets."}, "weaknesses": {"value": "1. The proposed method relies on heuristic design choices. For instance, the tri-mode paradigm is structured around specific training data types and requires manually tuning an optimal sampling ratio (as demonstrated in Table 7), which may not generalize easily across different datasets or environments.\n2. The paper's presentation could be improved for clarity. The three equations provided (Eq. 1-3) appear non-essential to the core idea and could be moved to the appendix. More importantly, the explanation of the core Refreshment and Retrieval mechanisms would benefit from a more intuitive, high-level explanation.\n3. The benefits of the temporal-prior are difficult to fully assess from static image results alone. The paper would be much stronger if it included supplementary videos to visually demonstrate the resulting temporal consistency and performance advantages.\n4. The paper lists experimental results while lacking deeper analysis. For example, it is noted that the tri-mode training does not degrade no map-prior (temporal prior) performance in Table 7. However, the paper provides no analysis of how the model avoids this potential performance trade-off while being trained on the additional map-fusion capability."}, "questions": {"value": "The paper proposes a unified framework for online map construction, demonstrating strong performance by incorporating a map prior modality. While the results are good, the overall contribution is undermined by several key issues. The proposed method, particularly the tri-mode paradigm, appears to be heavily based on heuristics design. The paper also suffers from a lack of in-depth analysis, often listing experimental findings without sufficiently exploring the underlying reasons for their outcomes. Finally, the paper's presentation needs significant improvement for clarity and impact."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "IevAB3ukNg", "forum": "DUtfVs1xxD", "replyto": "DUtfVs1xxD", "signatures": ["ICLR.cc/2026/Conference/Submission3236/Reviewer_1MpC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3236/Reviewer_1MpC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936604014, "cdate": 1761936604014, "tmdate": 1762916618396, "mdate": 1762916618396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a unified prior-informed framework for online vectorized HD map construction, Uni-PrevPredMap. This framework integrates two complementary prior sources — previous predictions and corrupted HD maps — to enhance temporal consistency. Uni-PrevPredMap operates under a tri-mode paradigm, which ensures consistent behavior across non-prior, temporal-prior, and temporal-map-fusion modes. This paper also proposes the tile-indexed 3D vectorized global map processor, to manage prior information.\nThe framework is tested with nuScenes and Argover2 datasets showing some improvements over SOTA methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper tackles an important challenge in online HD map construction by integrating temporal and prior information in a unified, adaptable framework.\n* The proposed tri-mode paradigm is conceptually interesting, as it provides operational flexibility between prior-free and prior-informed scenarios.\n* The empirical results suggest robustness to corrupted priors, demonstrating some progress in this specific research field."}, "weaknesses": {"value": "* (L071) It would be helpful to briefly describe the “idealized fidelity assumptions” of maps early in the paper. As written, readers must infer these assumptions from context. A short explanation would improve clarity and motivation.\n\n* The distinctions between non-prior, temporal-prior, and temporal-map-fusion modes remain somewhat unclear.\nIt would be useful to specify how each mode is derived or activated—for example, what features or signals determine which mode the system operates in.\n\n* The tile-indexed 3D vectorized global map processor appears conceptually similar to the memory buffer mechanism in MapUnveiler (Kim et al., 2025) and MapTracker (Chen et al., 2024). A clearer explanation of the main differences and any improvements introduced by Uni-PrevPredMap would help readers better understand the novelty.\n\n* The term “UTM coordinate” should be defined when first introduced. Not all readers may be familiar with it, and clarity here would avoid confusion.\n\n* Although the experimental results generally show improvements, the model still underperforms compared to some SOTA methods (Tab.1). This should not diminish the paper’s overall contribution, but it would strengthen the work to discuss potential reasons for these results—e.g., trade-offs between robustness and accuracy, or the effects of noisy priors."}, "questions": {"value": "Please refer to Weakness section.\nAlthough this paper starts with an interesting approach, I was not able to fully understand the key concept, tri-mode paradigm, due to lack of detailed explanations. Also, current version requires further clarifications of its contributions with prior arts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MQiVrS6rBs", "forum": "DUtfVs1xxD", "replyto": "DUtfVs1xxD", "signatures": ["ICLR.cc/2026/Conference/Submission3236/Reviewer_qRog"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3236/Reviewer_qRog"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975600144, "cdate": 1761975600144, "tmdate": 1762916617340, "mdate": 1762916617340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}