{"id": "IEDYctsolA", "number": 14940, "cdate": 1758245857276, "mdate": 1759897340255, "content": {"title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent", "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead to redundant retrievals, potential harmful knowledge conflicts, and increased inference latency. To address these limitations, an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric (internal) and retrieved (external) knowledge is in urgent need. This paper introduces the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge, resorting to external search only when internal knowledge is deemed insufficient. This is achieved using a novel knowledge-boundary aware reward function and a knowledge-boundary aware training dataset. These are designed for internal-external knowledge synergy oriented RL, incentivizing the model to deliver accurate answers, minimize unnecessary retrievals, and encourage appropriate external searches when its own knowledge is lacking. Evaluations across multiple knowledge reasoning tasks demonstrate that IKEA significantly outperforms baseline methods, reduces retrieval frequency significantly, and exhibits robust generalization capabilities.", "tldr": "", "keywords": ["Search Agent", "LLM Agent"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/66218ea43e55f71d9154be3470a34390fc2f7162.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses issues in existing RAG and RL-based LLM search agents—such as underused internal knowledge, redundant retrievals, knowledge conflicts, and high latency—by proposing IKEA, a reinforced reasoning agent.\nIKEA identifies its own knowledge boundaries, prioritizes internal knowledge, and uses external search only when internal knowledge is insufficient. It achieves this via a novel knowledge-boundary aware reward function and training dataset, which guide RL to balance accuracy, minimal unnecessary retrievals, and appropriate external searches.\nEvaluations show IKEA outperforms baselines on multiple knowledge reasoning tasks, reduces retrieval frequency, and has strong generalization."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Addresses a practical issue in Retrieval-Augmented Generation (RAG) systems: over-reliance on retrieval even when internal knowledge is sufficient, which leads to increased latency and potential knowledge conflicts.\nThe design of knowledge boundary-aware rewards is intuitive and reasonable, with clear hierarchical structure for behavioral preferences.\nEvaluated on multiple datasets, including both in-distribution and out-of-distribution tests."}, "weaknesses": {"value": "1. Limited technical innovation. Its reward shaping strategy for existing Reinforcement Learning (RL) methods essentially only adopts the \"Search-R1\" framework combined with reward function construction.\n2. The comparison scope for baseline model construction is limited and not fully expanded.\n3. The 1:1 ratio of easy-to-hard questions lacks theoretical basis, and no ablation experiments have been conducted under different ratios.\n4. Lacks a formal and rigorous definition of the \"knowledge boundary\".\n5. The classification of easy questions (Qeasy) and hard questions (Qhard) is overly simplified. The criterion of \"at least one correct answer in N samplings\" ignores the confidence gradient, and no tests have been conducted on multi-hop reasoning tasks with ambiguous knowledge boundaries."}, "questions": {"value": "1. Beyond in-context learning, what would be the effect of using other knowledge probing techniques?\n2. Conduct more comprehensive comparative experiments with baseline models.\n3. Evaluate performance on a wider range of tasks beyond question answering."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QGbO2ovVQj", "forum": "IEDYctsolA", "replyto": "IEDYctsolA", "signatures": ["ICLR.cc/2026/Conference/Submission14940/Reviewer_mATT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14940/Reviewer_mATT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761297418831, "cdate": 1761297418831, "tmdate": 1762925279856, "mdate": 1762925279856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the reinforcement learning framework IKEA, which enables large language models to adaptively balance the use of internal (parametric) knowledge and external (retrieval-based) knowledge.\nThe core idea is to train the model to recognize its knowledge boundary—to reduce retrieval when internal knowledge is sufficient and to trigger retrieval when it is not.\nThe authors design:\n- a knowledge-boundary-aware reward function that encourages the model to obtain correct answers with minimal retrieval, and\n- a mixed-difficulty training set that helps the model learn a dynamic balance between internal and external knowledge usage during reinforcement learning.\n\nOn datasets including NQ, PopQA, HotpotQA, and 2Wiki, IKEA maintains or improves accuracy while reducing the average number of retrievals by 35–50% compared to Search-R1."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Proposes a reinforcement-learning-based framework for internal–external knowledge synergistic reasoning.\n2. The reward function is well-designed, explicitly modeling the trade-off between retrieval cost and answer accuracy.\n3. Achieves stable performance improvements across multiple datasets."}, "weaknesses": {"value": "1. Limited generalization on Hard/OOD scenarios: Although IKEA aims to trigger retrieval when internal knowledge is insufficient, its improvements over Search-R1 on Hard/OOD datasets (e.g., PopQA and 2Wiki) are modest or even negative, suggesting that the model still tends to over-rely on internal knowledge in out-of-distribution settings.\n2. Mismatch between model scale and training data: Models of different sizes have distinct distributions of internal parametric knowledge.\nIf the same training data are used for all model scales, the “knowledge boundaries” learned by IKEA may not reflect the actual knowledge coverage of each model. It is recommended that the training data be separately sampled or adaptively constructed for different model sizes to ensure that boundary learning aligns with each model’s internal knowledge structure."}, "questions": {"value": "1. Do the Qwen-2.5-3B and 7B models use the same training data? How does model scale affect boundary-learning behavior?\n2. What are the main factors behind IKEA’s limited improvements on Hard/OOD tasks compared to Search-R1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K6hD0neKDa", "forum": "IEDYctsolA", "replyto": "IEDYctsolA", "signatures": ["ICLR.cc/2026/Conference/Submission14940/Reviewer_u7wK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14940/Reviewer_u7wK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912024920, "cdate": 1761912024920, "tmdate": 1762925279214, "mdate": 1762925279214, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which aims to optimize the reasoning capabilities of large-scale language models in knowledge-intensive tasks through reinforcement learning. The core innovation of IKEA lies in enabling the model to dynamically perceive its knowledge boundary, allowing it to intelligently decide when to rely on internal knowledge and when to perform external retrieval. By designing a refined reward mechanism, IKEA reduces redundant retrieval operations, maximizes the efficiency of internal knowledge usage, and ensures the effective supplementation of external knowledge."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Building upon previous methods such as Search-R1, this paper introduces an exploration of the balance between internal and external knowledge paths. This not only empowers the model with the ability to actively explore retrieval but also enables it to learn the boundary between its internal parametric knowledge and external knowledge.\n2. The baseline experimental comparison is thorough, and the writing is clear."}, "weaknesses": {"value": "1. The novelty of this paper is limited. It appears to merely integrate the exploration path strategy for balancing internal and external knowledge from DeepRAG into the Search-R1 framework. Essentially, it only designs a more complex reward function based on Search-R1, incorporating four different key behaviors, and is essentially an extension of DeepSearch-like works.\n2. The paper lacks appropriate experimental design to support the claim that its method is indeed more effective in learning the boundary between internal and external knowledge."}, "questions": {"value": "1. Does the baseline method, such as Search-R1 or DeepRAG, used for training align with the method proposed in this paper on the training data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zSWVkxMr5b", "forum": "IEDYctsolA", "replyto": "IEDYctsolA", "signatures": ["ICLR.cc/2026/Conference/Submission14940/Reviewer_jjGF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14940/Reviewer_jjGF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975083318, "cdate": 1761975083318, "tmdate": 1762925278734, "mdate": 1762925278734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "IKEA introduces (i) a knowledge-boundary–aware reward that pays more for correct answers with fewer searches and gently penalizes fruitless searches on wrong answers, and (ii) a balanced training set that mixes questions the model can already answer (Qeasy) with ones it likely cannot (Qhard). Together these push the policy to rely on internal knowledge first and retrieve only when necessary."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Directly optimizes “when to search.” The reward prefers “correct with fewer RT” over “correct with more RT,” and prefers “searched but wrong” over “did not search and wrong,” which encodes a clear ordering of behaviors (1>3>4>2 in the paper’s terms). This is a simple, targeted shaping for the retrieval timing problem rather than a classifier-gated or imitation-heavy approach. \n\n\n- Balanced difficulty splits (Qeasy/Qhard) are used not just for evaluation but as a training prior to keep the policy from drifting to extreme “always/never retrieve” strategies. The ablations show this matters. \n\n\n- This is not a new tool interface or planner; the novelty is in reward design + data curriculum that together teach knowledge-boundary awareness inside standard RLVR."}, "weaknesses": {"value": "- Hyperparameter sensitivity. The balance between accuracy and search frequency depends on RTmax, rkb+, and rkb−. Without concrete values and sweeps, it is hard to know how portable the setting is across model sizes and retrievers. \n\n\n- Labeling procedure. The Qeasy/Qhard split is defined by the base model’s own probe with N samples. This can drift with model choice and N; it would be helpful to report label distributions and sensitivity to N. \n\n\n- Corpus constraint. Experiments fix Wikipedia2018 and e5-base. Showing results with a web search API or a noisier corpus would better test robustness to non-curated text and long-tail entities. \n\n\n- Latency claim by proxy. The paper argues fewer searches mean lower latency, which is usually true, but wall-clock time is not reported. Reporting actual runtime improvements (including network/IO) would strengthen the efficiency claim.\n\n\n- Metric scope. EM is a strict measure. Including F1 or calibration/abstention metrics would help assess whether “no search” answers degrade gracefully."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "riKbE5TkKh", "forum": "IEDYctsolA", "replyto": "IEDYctsolA", "signatures": ["ICLR.cc/2026/Conference/Submission14940/Reviewer_KFrF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14940/Reviewer_KFrF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762246987283, "cdate": 1762246987283, "tmdate": 1762925277760, "mdate": 1762925277760, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a reinforcement learning framework that aims to train an adaptive search agent capable of balancing internal parametric knowledge and external retrieval when answering queries. The model is rewarded for preferring internal reasoning when sufficient and only invoking search when necessary, with the goal of improving both accuracy and efficiency. Experiments on several RAG-style QA datasets show reduced search calls and improved correctness compared to search-heavy baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses an important challenge in RAG systems: when to retrieve rather than how to retrieve.\n2. The reward formulation is intuitive and well-motivated, in that it attempts to explicitly model “knowledge boundary.”\n3. Results demonstrate that the proposed framework can reduce retrieval calls while maintaining or improving answer correctness.\n4. The paper is generally well-written and follows a clear structure."}, "weaknesses": {"value": "1.\tThe data construction pipeline (line 245) suggests a much simpler alternative:\nTrain a difficulty classifier to decide whether a question requires retrieval.\nThis is directly in line with Adaptive-RAG: Learning to Adapt Retrieval-Augmented LLMs through Question Complexity.\nSuch baselines are not included, leaving it unclear whether RL is actually necessary — or whether the same behavior can be achieved more simply and without retraining the model.\nIn particular, for practical deployment (e.g., Qwen DeepSearch-Agent), RL-based retraining introduces substantial cost, while a lightweight adaptive controller would not.\n\n\t2.\tThe experiments focus on datasets where retrieval depth and search horizon are relatively small.\nTo convincingly demonstrate the value of “adaptive search,” evaluation should include more complex multi-step environments, such as BrowserGym, WebArena, BC, or GAIA, where search depth and branching are significantly larger.\nWithout these evaluations, it remains unclear whether the proposed method provides benefits in realistic, long-horizon reasoning tasks.\n\n3.\tUnclear whether the model truly learns knowledge boundaries: The performance improvements may arise simply from data distribution differences, rather than from the model actually understanding when internal knowledge is sufficient.\nThe paper does not provide diagnostics showing that the model has learned a meaningful internal-external knowledge separation.\nSuggested analyses that are currently missing include:\n\t•\tCross-distribution generalization tests\n\t•\tBehavioral probes to evaluate reliance on parametric knowledge\n\t•\tVisualization of search decision patterns independent of dataset structure\nWithout these, the claimed “knowledge boundary learning” remains unsubstantiated."}, "questions": {"value": "1.\tCan the authors compare against a classifier-based gating approach that selects between direct answering and Search-R1-style reasoning?\n\t2.\tHow does the proposed method perform in long-horizon web/agent environments, where search planning is necessary beyond RAG retrieval?\n\t3.\tCan the authors provide behavioral evidence that the model learned knowledge boundaries rather than dataset heuristics?\n\t4.\tIs it possible to design an adaptive deepsearch mechanism that does not require RL training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sQDGbxPFO4", "forum": "IEDYctsolA", "replyto": "IEDYctsolA", "signatures": ["ICLR.cc/2026/Conference/Submission14940/Reviewer_P6Qj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14940/Reviewer_P6Qj"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762351394711, "cdate": 1762351394711, "tmdate": 1762925276658, "mdate": 1762925276658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}