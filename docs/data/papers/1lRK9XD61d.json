{"id": "1lRK9XD61d", "number": 6823, "cdate": 1757996978504, "mdate": 1763524244670, "content": {"title": "HARBOR: Hierarchical Abduction with Bayesian Orchestration for Reliable Probability Inference in Large Language Models", "abstract": "A central challenge in large-scale decision-making under incomplete information is the estimation of reliable probabilities. Prior work has employed Large Language Models (LLMs) to generate relevant factors and provide initial, coarse-grained probability estimates. These methods typically utilize an LLM for forward abduction to generate factors, with each factor constrained to two mutually exclusive attributes. A Naïve Bayes model is then trained on combinations of these factors to provide more accurate probabilities. However, this approach often yields a sparse factor space, resulting in \"unknown\" predictions where the model fails to produce an output. Naively increasing the number of factors to densify the space not only introduces statistical noise but also violates the Naïve Bayes independence assumption, ultimately compromising the stability and reliability of the estimates.\nTo address these limitations, we propose Harbor, a novel inference framework that orchestrates aggregated Bayesian inference over a hierarchically structured factor space. Harbor first constructs a dense, structured factor space through iterative generation and hierarchical clustering. It then performs context-aware mapping using retrieval and refinement operations on this hierarchy to reduce \"unknown\" predictions. Finally, Harbor extends Naïve Bayes by incorporating a Causal Bayesian Network to model latent dependencies, thereby relaxing the strict independence assumption. Experiments show that Harbor substantially reduces \"unknown'' predictions and yields more reliable probabilities than direct LLM baselines, achieving state-of-the-art performance with significantly reduced time and token overhead.", "tldr": "", "keywords": ["Probability Estimation", "Large Language Model"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/78e81d7f2555248a625979ea38a6d2fecf1b8800.pdf", "supplementary_material": "/attachment/675802ea02eef05ca45b1a6be2c646a9fd7292cb.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes HARBOR, a framework for rigorous Bayesian-like inference using LLMs in decision-making scenarios. Following BIRD (Feng et al. 2025), HARBOR similarly aims to generate factors that Bayesian decision-making needs, maps a downstream condition to these factors, and estimates conditional probability tables to compute a Bayesian-constrained probability for a decision to take under the downstream condition. Compared with BIRD, HARBOR proposes three main improvements. 1) HARBOR proposes an iterative and hierarchical factor generation step to acquire more comprehensive and non-overlapping factors. 2) HABOR proposes a factor mapping (from conditions) step using hierarchical retrieval, instead of the entailment setup in BIRD. Both changes aim to address the drawback in BIRD where many predictions are \"unknown\" due to failures in mapping factors. 3) HARBOR directly elicits conditional probabilities from LLMs instead of learning them based on strong entailments and uses an additional causal Bayesian network (CBN) to facilitate the decision. \n\nExperiments show that HARBOR largely resolves the \"unknown\" issue presented in BIRD, and outperforms BIRD in decision-making evaluation settings, while reducing the generation costs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem setup, following BIRD, is sound, and HARBOR addresses a main issue in BIRD, which is the failure in factor mapping. The proposed hierarchical factor generation could inspire future research and industrial applications. The empirical results are strong and support the main claims."}, "weaknesses": {"value": "While this paper is nicely executed, it essentially follows the BIRD setup for the general approach and evaluation. The main differences (as stated in the summary) do make a significant empirical difference, especially in coverage; however, they seem to be mostly engineering efforts that have limited contribution to future research. It seems to me that it was not BIRD's point to make every engineering effort, but to demonstrate the applicability and learnability of Bayesian-like inferences. \n\nAt the same time, I am not sure if some of the design choices are sound. For example, directly eliciting conditional probabilities from the LLMs defeats the purpose of having an external Bayesian inference in the first place, since we would be largely trusting the model's estimations of probabilities, and it is hard to tell if the gains are from more capable/calibrated models or from better inference approaches. At the same time, mapping factors from conditions using embedding-based retrieval may further decrease the trustworthiness of model inferences, especially when downstream performances are not the top priority in high-stakes setups (in other words, saying \"unknown\" or abstention may sometimes be preferred). \n\nThe authors could also better describe key differences with BIRD. The term \"reverse abduction\" is a little misleading since BIRD already employed somewhat of a \"reverse\" abduction in first generating scenarios, and then the factors."}, "questions": {"value": "1. It seems that the reported BIRD performances in Table 1 are lower than those reported in the original BIRD paper, especially since BIRD is re-implemented with a larger, more capable LLM. Could you please elaborate a little on what that is? I understand that the larger dataset and forcing factors could be a difference, but for the 72B version (99% coverage), should it be closer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zdjLcDxqlU", "forum": "1lRK9XD61d", "replyto": "1lRK9XD61d", "signatures": ["ICLR.cc/2026/Conference/Submission6823/Reviewer_NUoW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6823/Reviewer_NUoW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761190786602, "cdate": 1761190786602, "tmdate": 1762919087563, "mdate": 1762919087563, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce a framework for Bayesian inference making. They employ an LLM to abductively elicit latent factors, synthesize a causal Bayesian network of these factors, and use the estimated likelihoods of these factors to deliver calibrated probability estimates for competing hypotheses. Their method delivers stronger performance at lower LLM inference costs than baselines on a range of probabilistic reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The introduction of a causal graph between factors allows this approach to consider a wider space of factors without systematically degrading performance.\n\nThe approach delivers stronger performance than other probabilistic reasoning systems on a variety of datasets, while delivering higher coverage and lower token costs."}, "weaknesses": {"value": "The system appears to be intricately engineered, which could make it brittle to minor variations in the problem constructions or the LLM engines which power step-wise inferences. It is not clear whether it is possible to benchmark or optimize a LLM’s performance on a given sub-component of the pipeline.\n\nSome elements of the presentation were unclear or unpolished:\n\nLine 336-7: “We conduct all experiments with three models”, but four models are listed. It might be better to specify that these are three different *language* models, since “model’ is used elsewhere to describe probabilistic models\n\nCertain terms are defined for unclear reasons and do not make the formal description more clear, e.g. Φ(u)\n\nMy primary concerns are with the paper’s presentation / clarity, and I believe it would deserve a better score if these concerns / questions were addressed."}, "questions": {"value": "Why is the term Φ(u) = F*(u) introduced, when it is not referenced until the appendix? It does not make these expressions any more concise.\n\n\nWhy include the Naive Bayes model at all, if the causal Bayes Net is a more faithful formal representation of the questions that are being modeled? Is there an experiment that suggests this simpler model’s inclusion improves performance?\n\nWhat advantages of HARBOR make it more token efficient than BIRD? What datasets / conditions are the cost comparisons in Figure 3 made under?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NK4JUcLQ4g", "forum": "1lRK9XD61d", "replyto": "1lRK9XD61d", "signatures": ["ICLR.cc/2026/Conference/Submission6823/Reviewer_mzSy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6823/Reviewer_mzSy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761769593379, "cdate": 1761769593379, "tmdate": 1762919087257, "mdate": 1762919087257, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes `HARBOR`, a framework for generating reliable probability estimates from LLMs. It aims to solve two problems with _prior abductive_-Bayesian methods: 1) the creation of sparse factor spaces, which leads to \"unknown\" predictions, where the model abstains from making a prediction, and 2) the violation of the naïve Bayes independence assumption.\n\n1. The contribution is based on _\"reverse abduction\"_, which iteratively generates factors from sentences to build a dense and hierarchical factory space, which is then clustered. The idea is to reduce \"unknown\" (unmapped or low confidence) predictions.\n2. The context-aware mapping pipeline, which comprises multiple stages including hierarchical retrieval, filtering and self-refinement, is designed to match a specific condition to relevant factors.\n3. Finally, a probabilistic inference stage comprises two models: a standard naïve Bayes classifier and a Bayesian network, the latter modelling dependencies between factors that a naïve Bayes model would otherwise assume away. Parameters for both models are elicited from an LLM.\n\nExperiments on various benchmarks show that `HARBOR` improves coverage and outperforms baselines on preference-based evaluation (\\\\(F_1\\\\) score) and decisionmaking accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles a significant and practical problem: the unreliability and overconfidence of direct LLM probability estimates. The \"reverse abduction\" and hierarchical clustering approach to build a persistent, dense factor space is a novel and effective solution to the \"unknown\" prediction problem that plagued prior work.\n\nThe method is technically sound. The integration of a Causal Bayesian Network (CBN) to explicitly model latent dependencies is a principled way to relax the Naïve Bayes independence assumption, a common weakness in such models. The ablation study effectively demonstrates the necessity of each component.\n\nThe empirical results appear strong, at first glance (but see below). The framework virtually eliminates \"unknown\" predictions, improving coverage from 87.8% in the BIRD baseline to ~99.9%. This is accompanied by a significant boost in \\\\(F_1\\\\) score on the main preference-based benchmark. The method also shows strong performance on downstream decision-making tasks."}, "weaknesses": {"value": "The primary weakness is the lack of rigorous statistical analysis. The main results in Tables 1 & 2 only report point estimates with no uncertainty quantification (e.g. standard deviations or confidence intervals) over multiple experimental runs. LLMs are nondeterministic and so this is a major oversight.\n\nThe paper is mostly well presented, but tables and figures leave much room for improvement. Tables 1 & 2 are cluttered with horizontal lines and are difficult to read, with a chart probably being a better way of presenting these data. Figure 1 is not a clear illustration of either the method or the problem, and Figure 3 is also cluttered and difficult to interpret, with labels too small and excessive 'chart junk'. A dual-axis plot (right part of Fig. 3) contravenes data visualization best practice.\n\nThe paper would benefit from a clearer, self-contained motivating example; the one given in Figure 1 is not self-contained and is hard to follow; a better example on cooking noodles is unfortunately buried in the appendix (B.2) and a condensed version should be moved into the main paper to ground the framework for the reader.\n\nThe \"preference-based pairwise evaluation\" is analysed using \\\\(F_1\\\\) score. This seems like a missed opportunity for a more rigorous psychometric analysis, using methods from item response theory, such as the Bradley--Terry model, which are more appropriate for modelling paired comparison data (as well as any associated order or rater-level biases).\n\n_Minor point:_ check the spacing around parenthetical citations."}, "questions": {"value": "1. Please provide uncertainty estimates (e.g. standard deviation over \\\\(n\\\\) runs) for the main results in Tables 1 and 2.\n\n2. In the ablation study (Table 3), what do the $\\pm$ values reported in the 'Avg.' column represent?\n\n3. For the preference-based evaluation, did you consider using a more sophisticated statistical model, such as a Bradley-Terry model, to analyse the pairwise comparisons, rather than just the \\\\(F_1\\\\) score?\n\n4. The Bayesian network structure is learned by prompting an LLM to identify latent variables and partition factors. How sensitive is the final performance to this learned structure?\n\n5. The \"w/o pe-llm\" ablation replaces LLM-elicited parameters with fixed heuristic probabilities. This seems like it might be an overly weak baseline. Could you elaborate on why this was chosen over a more standard frequency-based estimation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GXUg6lffCm", "forum": "1lRK9XD61d", "replyto": "1lRK9XD61d", "signatures": ["ICLR.cc/2026/Conference/Submission6823/Reviewer_uGGc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6823/Reviewer_uGGc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839321559, "cdate": 1761839321559, "tmdate": 1762919086889, "mdate": 1762919086889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HARBOR, a inference framework that performs aggregated Bayesian reasoning over a hierarchically structured factor space using established clustering techniques and LLM-guided theming. It further models latent dependencies using a Causal Bayesian Network. The system then performs Context-Aware Mapping over variables and fuses the outputs into a single calibrated probability. The paper shows that HARBOR substantially reduces “unknown” predictions and produces more reliable probability estimates than direct LLM baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important issue: handling “unknown” cases in probabilistic reasoning, where an LLM must bridge between raw inputs and external structured inference tools.\n\nThe experiments are extensive and well-structured, with detailed ablation studies. The cost analysis in particular is intuitive and informative."}, "weaknesses": {"value": "The paper does not sufficiently justify the architectural choice of combining two probabilistic models (a Naive Bayes model and a Causal Bayesian Network). It remains unclear when each is necessary, how they complement each other.  The authors should add an ablation study for using  Causal Bayesian Network\n\nThe framework still relies on LLM-generated verbalized probabilities for fine-grained factor-level support and latent variable estimation (Figure 12 and Figure 14). Although the input structure is simple, the method could still vulnerable to LLM calibration bias."}, "questions": {"value": "1. How are the weights for the Linear Opinion Pool (LOP) designed or derived?\n\n2. There appears to be a typo or inconsistency in the assignment of θ_f between line 298 and line 304."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OY4loqwJFp", "forum": "1lRK9XD61d", "replyto": "1lRK9XD61d", "signatures": ["ICLR.cc/2026/Conference/Submission6823/Reviewer_Kue9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6823/Reviewer_Kue9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878433154, "cdate": 1761878433154, "tmdate": 1762919086556, "mdate": 1762919086556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}