{"id": "KjyQhJUobQ", "number": 16095, "cdate": 1758259920103, "mdate": 1759897262163, "content": {"title": "ProtFunAgent: Agentic LLM Cascades for Low-Resource Protein Function Gap-Filling via Homology RAG and Ontology-Constrained Decoding", "abstract": "Predicting protein function is a long-standing challenge, especially for poorly characterized sequences where homology transfer is unreliable and large language models (LLMs) produce fluent but biologically imprecise annotations. Existing approaches often fail to integrate critical priors such as Gene Ontology (GO) structure or homology evidence, limiting both recall and generalization. We present \\textbf{ProtFunAgent}, an agentic framework that couples LLM reasoning with biological constraints through three key innovations: (1) \\emph{homology-guided retrieval-augmented generation}, where top-$k$ sequence homologs inject functional priors; (2) \\emph{ontology-constrained decoding}, aligning predictions with the GO hierarchy via lexicon-aware filtering and pruning; and (3) a \\emph{synthesis-and-judging cascade} of LLMs, where multiple models collaborate and self-evaluate to refine candidate summaries. This design mirrors biocurator workflows while retaining the flexibility of generative models. On UniProt-derived benchmarks, ProtFunAgent outperforms single-LLM and heuristic baselines, delivering \\textbf{over $3\\times$ higher hierarchical F1} and nearly doubling recall while maintaining precision. Moreover, the framework \\textbf{closes more than half of the gap to oracle-level annotation}, demonstrating that embedding biological structure into agentic LLM pipelines enables scalable, ontology-faithful function prediction. ProtFunAgent provides a general blueprint for marrying symbolic constraints with generative reasoning, advancing automated protein annotation at scale.", "tldr": "Ontology-aware agentic LLM with homology RAG and GO-constrained decoding for grounded, low-resource protein function gap-filling.", "keywords": ["protein function prediction", "large language models", "ontology-aware decoding", "Gene Ontology", "homology retrieval", "retrieval-augmented generation", "BLAST", "constrained decoding", "agentic LLM cascades", "biological priors", "annotation refinement", "ontology-grounded prediction", "hierarchical F1", "recall improvement", "protein annotation", "computational biology", "knowledge integration", "function gap-filling"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5c98f2e6b89b7fbaf32106b314b39cb2d287f6db.pdf", "supplementary_material": "/attachment/076f69c5945b4f6f2792557a0c3085c4495bdf27.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes ProtFunAgent, an LLM-based agentic pipeline for protein function annotation. It introduces an RAG module to incorporate information from homogeneous proteins and multiple decoding strategies to extract hierachial GO annotations. Moreover, the framework introduces a multi-step proposer-judger workflow to generate and refine high-quality function descriptions. The work develops a benchmark derived from UniProt with several huerestic-based or LLM-based baselines and performs analysis with comprehensive metrics concerning GO accuracy, consistency, and text fidelity, successfully demonstrating the effectiveness of the proposed agentic pipeline."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper address a critical problem of existing LLMs in protein function interpretation: lack of biological grounding evidence from homologous proteins and awareness of GO hierachy.\n- A diverse set of evaluation metrics are introduced to comprehensively assess the accuracy, quality, and consistency of the generated annotations.\n- The experiment analysis on LLM variants, ensembling, and decoding temperature are comprehensive."}, "weaknesses": {"value": "- The technical designs are rather trivial and technically unsound. \n  - RAG with homologous proteins is a common practice in annotating protein databases [1]. I doubt if using only $k=3$ proteins with 30\\% identity is sufficient for function annotation, as protein structure prediction models like AlphaFold2 [2] typically use tens to thousands of MSAs. Besides, it appears that the RAG module cannot handle orphan proteins [3] or poorly annotated homologs mentioned in Lines 42-43 either.\n  - As shown in Algorithm 1 (Lines 7-33), since information from earlier attempts is not arranged into the context of further generation, the synthesis-and-judging workflow is simply an enumeration rather than a cascade. Moreover, the \"early accept\" operation compromises possible annotations with higher scores, and some of the models may rarely get used as the iteration of models is in the outer loop. I also doubt if the generations from the same model with a low temperature vary significantly.\n  - In GO inference, it seems the GO hierarchy is simply used for information extraction and post-processing rather than guiding LLMs for generating more accurate GOs. Moreover, GO annotations in UniProtKB typically comprise only the leaf nodes, since their ancestors can be easily calculated with upper closure. This makes the formulation of Ontology consistency questionable, as predicting ancestors is redundant.\n- The presentation of the methodology and experiments is unclear. See below:\n  - In lines 86-87, what's the definition of \"low-resource protein function gap-filling\"?\n  - What's the \"unchar\" set in Table 1 used for?\n  - What's the meaning of - in Equation 2?\n  - What's the data format of candidates $\\hat{s}$ in Section 2.4? Are they simply texts or comprise other metadata?\n  - What's the meaning of \"allowlist\" and \"anchors\" in Lines 216-217? How are they obtained?\n  - What's the meaning of \"per-aspect caps\" in Line 248?\n  - Where are the SCP results and K-sweep PR results mentioned in Lines 287-293?\n  - The main document does not direct readers to the implementation details of baselines.\n  - The settings of some critical hyperparameters like $L, T, \\tau$ are not reported.\n- The baselines and the adopted LLM variants are weak. For protein function description generation, multi-modal approaches like ProtLLM [4], ProteinGPT [5], and ProtChatGPT [6] should be compared. For GO prediction, deep learning models like DeepGO [7] and fine-tuned protein language models like ESM [8] should be compared. The strongest text model is GPT4o-mini, which \"serves as an upper-bound reference\", and the number of parameters of other LLMs does not exceed 8b. Considering the short context for each agent, I doubt if the cost of using API calls for stronger models like DeepSeek-V3.1 or GPT-5 is indeed unacceptable. The authors should at least provide comparisons of these models as their dataset is rather small, and justify that deploying open-sourced models with GPUs is more suitable than making API calls under \"low-resource scenarios\".\n\nRefs.\n\n[1] https://www.uniprot.org/help/automatic_annotation\n\n[2] Highly accurate protein structure prediction with AlphaFold\n\n[3] Structure prediction for orphan proteins\n\n[4] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training\n\n[5] ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding\n\n[6] ProtChatGPT: Towards Understanding Proteins with Large Language Models\n\n[7] DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier\n\n[8] Evolutionary-scale prediction of atomic-level protein structure with a language model"}, "questions": {"value": "My major concerns have been listed in the Weaknesses above. Here are some minor questions:\n- Why do authors choose only 10 widely-studied species for dataset construction? Will this lower the difficulty of the task? Do model performances vary across different species?\n- How frequently is the fallback agent called? How is the performance of this agent?\n- What are the precision and recall scores in GO prediction? What's the error mode of the model (e.g., mostly false positives or true negatives)?\n- Why do authors set 2% as the threshold for the consistency of GO prediction? Are there any biological insights behind this choice?\n- What are the ablation results by removing different agents?\n- The authors mentioned a trade-off between text quality and GO accuracy, which is counterintuitive, as a better function description may lead to more accurate GO annotations. Explanations are expected."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rfKxHE0z4I", "forum": "KjyQhJUobQ", "replyto": "KjyQhJUobQ", "signatures": ["ICLR.cc/2026/Conference/Submission16095/Reviewer_vcH7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16095/Reviewer_vcH7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761034987200, "cdate": 1761034987200, "tmdate": 1762926275718, "mdate": 1762926275718, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ProtFunAgent, an agentic LLM framework designed to improve protein function prediction, particularly in low-resource settings where homology transfer is unreliable and LLMs tend to hallucinate. The authors claim three key innovations of ProtFunAgent: (1) homology-guided RAG, which retrieves functional evidence from top-\\(k\\) sequence homologs; (2) ontology-constrained decoding, which aligns predictions with the Gene Ontology hierarchy via lexicon-aware filtering and pruning; and (3) a synthesis-judging cascade, where multiple LLMs collaborate and self-evaluate to refine candidate summaries. The system is evaluated on UniProt-derived benchmarks and is shown to outperform single-LLM and heuristic baselines, achieving over 3$\\times\\$ higher hierarchical F1 and nearly doubling recall while maintaining precision. The authors claim that ProtFunAgent closes more than half of the gap to oracle-level annotation, demonstrating that embedding biological structure into agentic LLM pipelines enables scalable, ontology-faithful function prediction."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The integration of agentic LLM cascades with structured biological priors (homology evidence, GO hierarchy) is a novel and promising direction for protein function prediction.\n\n2. The paper includes extensive experiments comparing ProtFunAgent against multiple baselines (single-LLM variants, heuristic lower bounds, oracle upper bounds) and ablations (synthesis backbones, judge selection, temperature). \n\n3. The work addresses a critical gap in automated protein annotation by combining generative flexibility with symbolic constraints, making it relevant for both computational biology and structured reasoning in LLMs."}, "weaknesses": {"value": "1. While the paper compares against single-LLM variants and oracles, it does not include strong non-LLM baselines (e.g., DeepGOPlus, deepNF, or TAWFN) in the main results table. This makes it difficult to assess whether the gains are due to the agentic design or simply the use of LLMs.\n2. The paper includes ablations on model backbones, judge selection, and temperature, but lacks a full component-wise ablation (e.g., removing RAG, removing ontology constraints, synthesis-judging cascade). The impact of the claimed three key innovations is not systematically ablated.\n3. The use of multiple LLM calls (cascades, judges, fallbacks) may be computationally expensive. The paper does not discuss runtime, cost, or scalability, which are important for real-world deployment.\n4. The paper lacks sections of Related Work and Conclusion. \n5. Key hyperparameters (e.g., BLAST thresholds \\(k=3\\), \\(\\theta_{\\text{id}}=30\\%\\), \\(\\theta_E=10^{-5}\\), temperature settings) are provided, though more details on model-specific settings (e.g., judge thresholds) would be helpful.\n6. The paper does not mention whether code will be released, which is critical for reproducibility given the complexity of the pipeline."}, "questions": {"value": "1. How does ProtFunAgent compare to prior state-of-the-art non-LLM protein function predictors (e.g., DeepGOPlus, deepNF, TAWFN) in terms of GO prediction accuracy and ontology consistency?\n2. Could you provide an ablation study that separately evaluates the contributions of the claimed three key innovations: Homology-RAG, ontology-constrained decoding, and the synthesis-judging cascade?\n3. The paper mentions using a “compact lexical allowlist” in the constrained synthesis regime. How is this allowlist constructed, and how sensitive is the model to its composition?\n4. What are the computational and latency costs of running the full ProtFunAgent pipeline, especially when using cascaded LLMs and multiple judge iterations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HspP37yufv", "forum": "KjyQhJUobQ", "replyto": "KjyQhJUobQ", "signatures": ["ICLR.cc/2026/Conference/Submission16095/Reviewer_rFao"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16095/Reviewer_rFao"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641012357, "cdate": 1761641012357, "tmdate": 1762926275284, "mdate": 1762926275284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposes ProtFunAgent, a framework for protein function prediction. The key components include homology-guided retrieval-augmented generation, ontology-constrained decoding, and a synthesis-and-judging cascade of LLMs. The method demonstrates promising performance in protein function annotation tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The topic is important and relevant to the protein modeling community.\n- Experimental results indicate that the proposed method achieves good performance on benchmark datasets."}, "weaknesses": {"value": "- The work relies entirely on existing publicly available LLMs; there is no methodological novelty in model architecture or training.\n- The contribution is mainly in system integration and application design, which lacks sufficient AI innovation for a top-tier AI conference."}, "questions": {"value": "What is the main algorithmic contribution of the manuscript beyond applying existing LLMs with domain-specific heuristics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aYwLZWer7c", "forum": "KjyQhJUobQ", "replyto": "KjyQhJUobQ", "signatures": ["ICLR.cc/2026/Conference/Submission16095/Reviewer_nFdy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16095/Reviewer_nFdy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660674830, "cdate": 1761660674830, "tmdate": 1762926274310, "mdate": 1762926274310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ProtFunAgent, a agentic framework for protein function annotation. It integrates homology-guided retrieval to provide sequence context, synthesis and judging agents to generate and filter functional summaries, and ontology-constrained decoding to ensure Gene Ontology (GO) consistency. Evaluated on UniProt-derived benchmarks, the system shows improve performance than single-model or heuristic baselines while maintaining strong ontology adherence. The study introduces additional metrics such as ontology consistency and support-calibrated precision to better capture biological validity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Integration of biological prior and llm reasoning:\nCombines homology retrieval, ontology constraints, and multi-stage agentic loop in a coherent framework for protein annotation.\n\n- Clear pipeline design:\nThe method is organized into well-defined stages (synthesis, judging, ontology decoding) that are easy to understand and replicate conceptually.\n\n- Promising performance gains:\nShows consistent improvements in GO prediction and recall compared to single-model and heuristic baselines.\n\n- New evaluation metrics:\nIntroduces ontology consistency and support-calibrated precision to assess structural accuracy more comprehensively.\n\n- Relevant application focus:\nTargets low-resource and poorly annotated proteins, making the approach useful for practical biological curation."}, "weaknesses": {"value": "- Data contamination risk: The benchmark is derived from UniProt, which overlaps with content likely included in LLM pretraining corpora. This makes it unclear whether ProtFunAgent is truly generalizing or simply recalling known annotations.\n\n- Lack of evaluation on novel or post-cutoff proteins: The test proteins are clustered by 60% identity to prevent within-split leakage, but there is no evaluation on proteins released after the LLMs' training cutoff or from truly novel metagenomes. This limits confidence in out-of-distribution generalization.\n\n- Lack of comparison against SoTA Models: Although DeepGOPlus, DeepGOZero, and TAWFN are cited as representative baselines, no quantitative results are reported. Without this, it is unclear how ProtFunAgent performs relative to the strongest baseline (supervised) predictors.\n\n- Reliance on homology retrieval (SwissProt): Because the retrieval database is SwissProt (also the benchmark source), homology overlap may introduce indirect label leakage, i.e.,  retrieved homolog summaries could already include the ground-truth GO annotations for the query protein.\n\n- Incomplete error analysis: While ontology consistency is measured, the paper lacks a breakdown of where errors occur, such as confusion between GO namespaces, hallucinated functions, or failures due to homolog scarcity.\n\n- Missing resource and running time reporting: Without these, scalability and efficiency are hard to assess (moreover, the method relies on BLASTP for homology search, which is often an expensive process for large databases).\n\n- Limited ablation on ontology-constrained decoding:  It would be important to isolate its contribution quantitatively since this component is central.\n\n- Lack of downstream task validation: the generated GO sets are not tested in downstream pipelines (e.g. enrichment analysis, PPI prediction etc.)."}, "questions": {"value": "- How do the authors ensure that ProtFunAgent's results are not influenced by potential UniProt data seen during LLM pretraining?\n\n- Can the authors provide runtime or computational cost measurements for this agentic pipeline?\n\n- Can the authors provide quantitative comparisons with supervised baselines like DeepGOPlus or DeepGOZero to clarify performance differences?\n\n- Have the authors considered validating the predicted functions through perturbation or motif-level analyses to confirm biological correctness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F53w5QAudv", "forum": "KjyQhJUobQ", "replyto": "KjyQhJUobQ", "signatures": ["ICLR.cc/2026/Conference/Submission16095/Reviewer_UeEK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16095/Reviewer_UeEK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993202506, "cdate": 1761993202506, "tmdate": 1762926273823, "mdate": 1762926273823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}