{"id": "eR7E4LMPtR", "number": 8113, "cdate": 1758064052378, "mdate": 1759897806616, "content": {"title": "Beyond Greedy: Towards Optimal Deep Classification Trees", "abstract": "Decision trees are central to interpretable machine learning but face severe scalability challenges. Existing global optimal methods are limited by binary feature selection and shallow tree depths, while traditional heuristic approaches often sacrifice accuracy. To overcome these limitations, this paper introduces a moving-horizon approximate branch-and-reduce method for constructing near-optimal deep classification trees on large-scale datasets with continuous features. This method is based on a bilevel optimization framework, where the upper-level problem is addressed using a branch-and-reduce method, while the lower-level problem is solved recursively. Although the underlying framework guarantees global optimality, we enhance its efficiency for deeper trees by introducing an approximate solution for the lower-level problem, which can be viewed as a lookahead rollout in reinforcement learning. The accuracy is further refined using a low-cost moving-horizon strategy. Extensive experiments demonstrate that the proposed method consistently outperforms existing heuristic baselines in testing accuracy, while maintaining scalability on large datasets compared to global optimal methods.", "tldr": "", "keywords": ["decision tree.+CART.+optimal classification trees"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dfdafffe811e15d836a513bc8284bbbb17bc4db5.pdf", "supplementary_material": "/attachment/7c49381eddbb42d60f4ed77f12b0914dd0d0a931.zip"}, "replies": [{"content": {"summary": {"value": "Authors propose a new heuristic decision tree induction algorithm supposidly bridging the gap between optimality and scalability. \nThe proposed MHABR iteratively refines an ABR global tree by calling ABR on sub-trees of the global tree. ABR computes a tree with a root node that is optimal w.r.t. its induced greedy sub-trees (obtained with CART). The idea of refinining an ABR tree is good. Performance guarantees and numerical performances are OK. The key weaknesses that justify my score are the lack of clarity of some section and some very subjective or wrong tables and figures, and above all the lack ok positioning w.r.t to the closest related work (DPDT). \nI would accept the paper if a core part of the experiments focuses on the optimality/runtime pareto front of DPDT and MHABR . Similarly you can also do the test accuracy/runtime pareto front of DPDT and MHABR. You can do so for a fixed large datasets when inducing trees of different depth. The idea of MHABR is good but authors ought to get their experiments to the highest standards of excellence (including hyperparameters search for example)."}, "soundness": {"value": 4}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "## The paper is well written\nThe introduction is clear and presents the problem clearly, \nThere is (almost) no missing related work except Blanc, et. al. Harnessing the power of choice in NeurIPS 2024, and Lookahead and Pathology in Decision Tree Induction. Murthy 1995.\nFigure 1 is great.\n\n## Analysis\nThere is a nice theoritical guarantee that the proposed ABR is >= CART and is optimal for depth 2 trees (c.f. Lemma 3.1).\nThere is an analysis of the complexity of MHABR. \n\nI would personally write the performances guarantees as theorems and the complexity as a proposition."}, "weaknesses": {"value": "## Subjectivity or lack of rigour.\nTable 1 is not very rigorous. First of all, of course that CART cannot deal with infinite depth or infinitely big datasets no physical system can. Still on table 1, the reported value for DPDT is incorrect: in the DPDT paper authors try a depth-10 decision tree on the KDD dataset (N= 5 million, p = 80) on table 3. In general, DPDT can be instantiated to be CART (from section 5.2 of the DPDT paper, last paragraph, DPDT with B=1 is CART, in python ```from dpdt import DPDTreeClassifier; clf = DPDTreeClassifier(cart_nodes_list(1,))``` is CART). Similarly, ABR, if the LLP problem is approximated from the root to the leaves, then ABR is CART. I would remove this table 1. \n\nIn Appendix A.5, figure 7 is not rigorous at all. For example, DPDT covers the whole pareto front of this subjective figure, and CART could also also returned the optimal tree if optimilaty is with respect to e.g. the depth-1 tree.\n\n## Typos\nLine 124: this sum only denotes the number of misclassif. if $l()$ is the 0-1 loss. \nIn general the trin induction problem is weirdly defined: in equation (1), V is an integer and not a tree. It would be better to have an argmin to show that you are look for a tree.\nLine 149 about the root node is interesting but needs more explanations and/or a reference.\n\n## Clarity\nSecond, section 3.3 is essentially null. The iterative refinement presented is not detailed: in figure 2, the schematics only shows that trees are recursive data structures but in no way does figure 2 nor sec. 3.3 present any new optimization problem nor algorithm.\n\nThe rest of section 3 helps *guess* what MHABR but it is very unclear: algorithms 1-3 are weird because algorithm 1, ABnR, is not defined in the text.\n\nMy educated guess, please correct me if I am wrong, is that MHABR is to run iteratively ABR on sub trees of a global ABR tree.\nSupposidly, this should refine the global ABR tree but could also degrade it because there is no guarantee that change a subtree of the global ABR tree will not render, e.g, the global root node, less performent.\n\nDespite the lack of clarity of section 3, I think the proposed MHABR is a good idea. It makes sense and the proof of theorem 3.2 is easy to follow: the complexity of MHABR is number of iteration of MH times complexity of ABR on the subtree.\n\n## Better positioning w.r.t DPDT\nIn general, I think your work should better situate w.r.t to DPDT as DPDT also tackles \"the urgent need for an advanced method that can deliver both high accuracy and scalability for deep decision trees on large-scale datasets.\" .\n\nUp until section 3.3, the proposed ABR is exactly the baseline DPDT with hyperparameters B=Np at d < 2 and B = 1 for d >= 2 (Kohler et. al 2025 section 5.6). Similarly, ABR² is DPDT with B=Np at d < 2 and B = 1 for d >= 3. \nTo convince yourself of that you could run:\n```python\nfrom dpdt import DPDTreeClassifier\nfrom sklearn.datasets import load_digits\n\nDEPTH = 5 # can be changed\nX, y = load_digits(return_X_y=True) # MNIST\nN, p = len(X), len(X[0])\nabr = DPDTreeClassifier(cart_nodes_list=(N * p, ), max_depth=DEPTH) # ABR\nabr.fit(X, y) # this should return the same tree as ABR with a max depth of DEPTH\nabr.score(X,y) # this should be the same optimality as ABR tree\n\nabr2 = DPDTreeClassifier(cart_nodes_list=(N * p, N * p, ), max_depth=DEPTH) # ABR2\nabr2.fit(X, y) # this should return the same tree as ABR2 with a max depth of DEPTH\nabr2.score(X,y) # this should be the same optimality as ABR2 tree\n```\nThe idea of line 276 of using CART to get approximated sub-trees for the LLP is from DPDT. Figure 1 is essentially the work of the DPDT paper. The real novely of the work starts from 3.4 onwards.\n\n## Experiments\nThe main weakness for the experiment is that authors use default hyperparameters for most baselines.\nTable 2 shows good train accuray at cheaper than optimal algs cost. This is essentially a property that bot CART and DPDT exhibits, with DPDT being the first algo that can really navigate the pareto front of optimality/scalability.\nIn appendix table 8, DPDT does not use parallel computation by default. \nA more thorough comparison of CART vs DPDT vs MHABR ought to be in the main paper with hyperparameter search."}, "questions": {"value": "- What do you mean by best outcome for alpha CART and alpha MHABR lines 390? Is it the best test accuracy or best train?\n- Can you run, for depths 2 --> 20 on a large dataset CART(max_depth = d, random_state=42), DPDT(cart_nodes_list=(Np, ), max_depth=d, random_state=42) # ABR, MHABR(max_depth = d, random_state=42)? Then you can plot a pareto front of runtimes vs test/train scores. \n- What are the techniques for light MHABR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "blpoYiMqOV", "forum": "eR7E4LMPtR", "replyto": "eR7E4LMPtR", "signatures": ["ICLR.cc/2026/Conference/Submission8113/Reviewer_nJuV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8113/Reviewer_nJuV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761565868894, "cdate": 1761565868894, "tmdate": 1762920093580, "mdate": 1762920093580, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a bi-level training framework and a branch-and-reduce method for constructing the optimal deep classification trees. The proposed method applies not only to binary features but also to continuous features. To enhance its efficiency for large datasets, this paper introduces an approximate solution for the sub-level problem within the branch-and-reduce framework. Compared with heuristic baselines, the proposed method achieves better accuracy; while compared with global optimal methods, the proposed method maintains scalability on large datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well written with clear method description and mathematical notation.\n\n2. This paper prove that the branch-and-reduce method converges to the global optimum of deep classification trees. This paper also introduces an approximate solution for the sub-level problem within the branch-and-reduce framework, which make it practical for large datasets. Thus, this paper strikes a balance between theoretical rigor and practical utility.\n\n3. The experiments are good and the source code is publicly available."}, "weaknesses": {"value": "1. The branch-and-reduce method converges to the global optimum. However, the authors don't provide the convergent speed or computational complexity of this method. Is the computational complexity the same as the brute-force search?\n\n2. Due to the branch nature of decision trees, the idea of branch and reducing (for building decision trees) is not difficult to think of. I’m afraid similar work may already exist, e.g. [1].\n\n[1] Branches: A Fast Dynamic Programming and Branch & Bound Algorithm for Optimal Decision Trees. \nArxiv 2406.02175"}, "questions": {"value": "Can this method extend to regression problems or more general objectives?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b3piaoWg1p", "forum": "eR7E4LMPtR", "replyto": "eR7E4LMPtR", "signatures": ["ICLR.cc/2026/Conference/Submission8113/Reviewer_iD6M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8113/Reviewer_iD6M"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762076480814, "cdate": 1762076480814, "tmdate": 1762920093118, "mdate": 1762920093118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper developed a hybrid approach to learning decision trees that attempts to bridge the gap between fast, greedy heuristics (like CART) and computationally intractable optimal methods (like MIP or full dynamic programming)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea is to use a branch-and-reduce framework for the top of the tree while approximating the value of deeper subproblems with a fast heuristic. I think this is clever and draws from well-established principles in optimization and control theory (approximate dynamic programming).\n\n2. The amount of experiments is sufficient and I think the authors have demonstrated some improvements over numerous baselines in terms of accuracy and scalability."}, "weaknesses": {"value": "1. The entire framework is built on the premise that you can approximate the \"optimal tail problem\" (the lower-level problem, LLP) using CART (Line 240). Yet, CART is the quintessential myopic, greedy heuristic that this entire line of research seeks to improve upon. How can a method that uses a demonstrably poor, one-step-optimal heuristic as its core value function for future states ever hope to achieve near-optimality for deep trees? Aren't you simply performing a more computationally expensive, one-step lookahead from the root, built upon the very same greedy foundation you criticize?\n\n2. Your Section 3.2 attempts to frame the approach from a RL perspective, referencing DPDT and describing your LLP approximation as a \"lookahead rollout\". I think this framing is superficial and it literatually adds little substance to the method. A rollout is a Monte Carlo simulation from a state, whereas you are simply replacing a value function $V^\\ast$ with a heuristic $V_\\text{heuristic}$. Is this not just standard approximate dynamic programming? What specific, novel insights or algorithmic components does the RL framing provide that are not already well-understood concepts from DP and heuristic search?\n\n3. One thing I think is not a good practice is that the authors repeatedly emphasizes the proposed ABR method \"guarantees global optimality for depth-2 trees\" (Lines 260-262) and highlights this in the contributions (Line 084). Given that CART itself is optimal for depth-1 trees, isn't it a trivial and expected outcome that a method performing a full branch-and-bound search at the root (ULP) and using an optimal depth-1 solver for the leaves (LLP) would be optimal for depth-2? How is this anything more than a basic sanity check of your framework, and why is it presented as a significant contribution?\n\n4. Your key efficiency gain comes from the \"branch-and-reduce\" method, which prunes the search space of split points. In the full BR method, this is sound because the lower bound is valid. However, in your approximate ABR method, you acknowledge that the continuity condition may not hold and the reduction strategy can be \"inaccurate\" (Lines 330-332), and in the limitations, you concede that \"unpredictable reduction errors...make formal guarantees...difficult to achieve\" (Lines 472-474). If the reduction step can erroneously prune branches that contain the true optimal split, what prevents your algorithm from catastrophic failure? I think this may lead to a solution that is arbitrarily bad, potentially even worse than CART?\n\n5. From my understanding, the proposed MHABR algorithm is a highly complex! It has multi-stage process involving a bilevel formulation, an outer loop of Moving Horizon iterations, and an inner loop of ABR, which itself contains branching, bounding, and reduction steps. While you demonstrate scalability improvements over exact methods, have you not simply created an enormously complicated and over-engineered heuristic that achieves only marginal gains over much simpler, state-of-the-art heuristics like DPDT or tuned versions of CART, especially when considering the significant implementation and computation overhead?"}, "questions": {"value": "See my comments in the Weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9XFa0mfaWN", "forum": "eR7E4LMPtR", "replyto": "eR7E4LMPtR", "signatures": ["ICLR.cc/2026/Conference/Submission8113/Reviewer_gxZq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8113/Reviewer_gxZq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762582566906, "cdate": 1762582566906, "tmdate": 1762920092770, "mdate": 1762920092770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents Moving-Horizon Approximate Branch-and-Reduce, a novel approach for near-optimal decision trees. It considers the learning of an optimal decision tree as a bi-level optimization problem and proposes a branch-and-reduce technique to solve the problem, and in particular an approximation of the low-level problem using CART, akin to a lookahead rollout in reinforcement learning. Experiments on 51 small datasets as well as 6 medium to large datasets show the proposed approach outperforms heuristic baselines and exhibits better scalability compared to globally optimal approaches."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Strengths:\n- Novel approach for near-optimal decision trees based on bi-level formulation with a branch-and-reduce solving technique and CART-based approximation of the low-level problem\n- The view of the low-level problem approximation as an lookahead rollout in reinforcement learning provides an interesting perspective on the approach\n- The numerical experiments show the proposed approach outperforms the heuristic approaches while remaining more scalable than globally optimal approaches."}, "weaknesses": {"value": "Weaknesses:\n- Framing of previous literature in the paper: the paper makes various claims about previous work that I do not believe to be accurate\n\t1. The paper claims that DP- and SAT-based approaches face inherent drawback due to the need to binarize features. However, recent DP-based and SAT-based approaches that do not require binarization and handle continuous features directly have been proposed and not cited: [1] for DP-based, and [2] for SAT-based.\n\t2. \"TAO remains restricted to optimizing threshold values of internal nodes while keeping feature selections fixed”: I don’t believe this is true. A full node (variable and threshold) is fit at every step. From the original paper: \"For axis-aligned trees, it can be solved exactly by enumeration over features and splits, just as in the CART algorithm to minimize the impurity\" [3].\n\t3. DPDT’s \"reliance on heuristic optimization severely limits its optimality”: I believe DPDT is using dynamic programming for optimization. It does use heuristic approach, specifically CART, to reduce the space of splits it considers (but, as described in the paper, it can be used with an exhaustive function which will maintain optimality). That seems very similar to the proposed approach’s use of CART, and similar to the proposed approach, DPDT is demonstrating “near-optimal” performance.\n\t4. I think Table 1 is somewhat misleading in terms of its designation of methods as “globally optimal in special cases”. I don't think being optimal only on binary data is similar to being optimal up to depth 2 (they are currently marked similarly in the table). Every dataset can be converted to a binary data without loss of optimality (but with a potentially very large number of features).\n- Missing highly-relevant works: there are various “near-optimal” recent approaches that are similar to the proposed approach in the sense of they are relaxation of optimal approaches. They should be cited and considered as baselines in the paper. Some important examples: [4] [5] [6].\n- Experimental evaluation:\n\t1. Not clear why hyper parameters were not tuned for other approaches like DPDT. In fact, I am concerned that the comparison is not really fair: we can see that DPDT finishes order of magnitude faster than MHABR, however DPDT can trade-off more run time for better optimality by considering more splits, meaning a much more extensive configuration could have been considered for DPDT to improve its performance while maintaining lower runtime compared to the proposed approach.\n\t2. Not clear why other non-greedy / near-optimal approaches are not considered like TAO, SPLIT, top-B, etc. (see list above). These are particular useful as they are the most relevant approaches to this paper and, similar to the proposed approach, tend to outperform heuristic baselines while remaining more scalable than globally optimal approaches.\n\t3. As the paper notes, much of the improvement in performance comes from the tuning of the regularization. Importantly, other optimal and near-optimal approaches allow for tuning a regularization parameter like GOSDT [7] and SPLIT [4], TAO [3], Branches [8], etc.\n\nMinor:\n- Eq. (1) - should be argmin? We would like to find the tree that minimizes the cost function\n- How is the complexity of trees (C) measured? Number of nodes?\n\n[1] Brița, C. E., van der Linden, J. G., & Demirović, E. (2025, April). Optimal Classification Trees for Continuous Feature Data Using Dynamic Programming with Branch-and-Bound. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 39, No. 11, pp. 11131-11139).\n\n[2] Shati, P., Cohen, E., & McIlraith, S. A. (2023). SAT-based optimal classification trees for non-binary data. Constraints, 28(2), 166-202.\n\n[3] Carreira-Perpinán, M. A., & Tavallali, P. (2018). Alternating optimization of decision trees, with application to learning sparse oblique trees. Advances in neural information processing systems, 31.\n\n[4] Babbar, V., McTavish, H., Rudin, C., & Seltzer, M. (2025). Near Optimal Decision Trees in a SPLIT Second. arXiv preprint arXiv:2502.15988.\n\n[5] Blanc, G., Lange, J., Pabbaraju, C., Sullivan, C., Tan, L. Y., & Tiwari, M. (2023). Harnessing the power of choices in decision tree learning. Advances in Neural Information Processing Systems, 36, 80220-80232.\n\n[6] Kiossou, H. S., Nijssen, S., & Schaus, P. (2025). A Generic Complete Anytime Beam Search for Optimal Decision Tree. arXiv preprint arXiv:2508.06064.\n\n[7] Lin, J., Zhong, C., Hu, D., Rudin, C., & Seltzer, M. (2020, November). Generalized and scalable optimal sparse decision trees. In International conference on machine learning (pp. 6150-6160). PMLR.\n\n[8] Chaouki, A., Read, J., & Bifet, A. (2024). Branches: Efficiently Seeking Optimal Sparse Decision Trees with AO. arXiv preprint arXiv:2406.02175."}, "questions": {"value": "See my questions and concerns under weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "axLOptNWOQ", "forum": "eR7E4LMPtR", "replyto": "eR7E4LMPtR", "signatures": ["ICLR.cc/2026/Conference/Submission8113/Reviewer_FhND"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8113/Reviewer_FhND"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762609047095, "cdate": 1762609047095, "tmdate": 1762920092442, "mdate": 1762920092442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}