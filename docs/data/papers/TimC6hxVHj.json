{"id": "TimC6hxVHj", "number": 14339, "cdate": 1758233025460, "mdate": 1759897376367, "content": {"title": "Hierarchical Entity-centric Reinforcement Learning with Factored Subgoal Diffusion", "abstract": "We propose a hierarchical entity-centric framework for offline Goal-Conditioned Reinforcement Learning (GCRL) that combines subgoal decomposition with factored structure to solve long-horizon tasks in domains with multiple entities.\nAchieving long-horizon goals in complex environments remains a core challenge in Reinforcement Learning (RL). Domains with multiple entities are particularly difficult due to their combinatorial complexity. GCRL facilitates generalization across goals and the use of subgoal structure, but struggles with high-dimensional observations and combinatorial state-spaces, especially under sparse reward. We employ a two-level hierarchy composed of a value-based GCRL agent and a factored subgoal-generating conditional diffusion model. The RL agent and subgoal generator are trained independently and composed post hoc through selective subgoal generation based on the value function, making the approach modular and compatible with existing GCRL algorithms. We introduce new variations to benchmark tasks that highlight the challenges of entity-centric domains, and show that our method consistently boosts performance of the underlying RL agent on image-based long-horizon tasks with sparse rewards, achieving over $150$% higher success rates on the hardest task in our suite and generalizing to increasing horizons and numbers of entities. Rollout videos are provided at: https://sites.google.com/view/hecrl.", "tldr": "We present a hierarchical entity-centric framework for offline goal-conditioned RL that produces entity-factored diffusion-generated subgoals for an RL agent, yielding consistent performance gains on long-horizon, image-based, sparse-reward tasks.", "keywords": ["Deep Reinforcement Learning", "Goal-conditioned Reinforcement Learning", "Object-centric Representations", "Diffusion Subgoal Generation"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c068522c989bdf0548c92326e3f18e2450481608.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper has proposed a novel hierarchical reinforcement learning approach, where the subgoals are entity-centric. In the proposed approach, the policies are implemented with the diffusion networks. The experiment results demonstrate that the proposed approach significantly outperforms the state-of-the-art hierarchical baselines. Beyond that, the entity-centric subgoals improve the explainability of the learned policies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe hierarchical learning problem is of great importance in the RL domain, which is promising for solving the long-horizon problems in real-world applications.\n\n2.\tThe proposed approach is extensively evaluated in the simulated robotic manipulation domain and has demonstrated impressive experimental performance."}, "weaknesses": {"value": "1.\tFigure 2 is confusing. The goals are represented with small squares. It is unclear what the difference is between the factored squares and the unfactored squares, and even how they influence the learning process.\n\n2.\tThe authors are encouraged to show more about the learned subgoals, and the goal-conditioned policies. It is unclear what goal-conditioned policies are learned which leads to the superior task performance."}, "questions": {"value": "1.\tWhat is the difference between entities and objects?\n2.\tDoes the paper assume that the collection of entities in Line 129 is given before learning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MNmq9K9udl", "forum": "TimC6hxVHj", "replyto": "TimC6hxVHj", "signatures": ["ICLR.cc/2026/Conference/Submission14339/Reviewer_pQXN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14339/Reviewer_pQXN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761558808530, "cdate": 1761558808530, "tmdate": 1762924762428, "mdate": 1762924762428, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an offline Goal-Conditioned Reinforcement Learning (GCRL) framework to enhance learning efficiency and generalization in long-horizon goal-reaching tasks within complex environments featuring multiple entities. The authors employ a hierarchical structure comprising a diffusion model for generating entity-factored subgoals and a value-based GCRL agent."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "While hierarchical structures have been explored in prior work, utilizing diffusion models to generate subgoals that incorporate information from multiple entities stands out as a novel approach. Additionally, modifying the experimental environments to highlight the advantages of the proposed method and comparing it against baselines strengthens the paper's contributions."}, "weaknesses": {"value": "The paper would benefit from more detailed explanations of model design choices, along with ablation studies to justify them. Although the use of diffusion for subgoal generation is innovative, it remains unclear whether this component is essential for the performance gains. There is a concern that filtering subgoals—generated via the unused value function during diffusion model training—might play a more critical role than the diffusion process itself."}, "questions": {"value": "1. As mentioned in the Weakness section, an ablation study on subgoal filtering using value functions would be helpful. It would be useful to compare scenarios where subgoals generated by diffusion are used directly, or where multiple subgoal candidates are randomly sampled and then filtered, against the current selection method.\n2. I am curious about the impact of hyperparameters K and N, as described in Section 3.2, on performance.\n3. The algorithm indicates that the current subgoal g' is an input, but this is not explicitly addressed in the description. What role does the current subgoal play?\n4. Is it feasible to compare against a baseline that directly applies the EC-IQL method to HIQL?\n5. According to Table 1, HIQL achieves a 0 success rate in PPP-Cube (image) and Stack-Cube (state). What explains this lower performance compared to the cube environment in OGBench? Is it due to the increased number of cubes that need to be manipulated?\n6. Why is only the Stack-Cube (state) environment included, while the Stack-Cube (image) version is omitted?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BnG52cMaBM", "forum": "TimC6hxVHj", "replyto": "TimC6hxVHj", "signatures": ["ICLR.cc/2026/Conference/Submission14339/Reviewer_K6LA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14339/Reviewer_K6LA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905964008, "cdate": 1761905964008, "tmdate": 1762924761770, "mdate": 1762924761770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Hierarchical Entity-Centric RL (HECRL), composed of a value-based GCRL and a factored subgoal-generating diffusion model to address long-horizon tasks in domains with multiple entities. In addition, the authors introduce a new version of benchmark problems that highlight the challenges of entity-centric tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper is well written, well-constructed and easy to follow. In particular, its pictorial illustration, such as Figure 2, was very helpful in understanding the overall idea. The proposed method effectively addressed challenging long-horizon multiple-entity tasks."}, "weaknesses": {"value": "The proposed components are based on existing methodologies, such as entity-factored subgoals and subgoal diffuser, so the novelty of the approach itself may be limited. However, the meaningful combination of these components has yielded strong performance. Please see others in questions."}, "questions": {"value": "**Questions**\n\nQ. What is the major difference between the proposed model and EC-diffuser?\n\nQ. What is the key difference from the previously proposed method, which utilizes a diffusion model to generate a subgoal? Is it modularity that enables test-time subgoal selection with the value function?\n\nQ. Sensitivity study with respect to $K$ and $T_{sg}$ is missing.\n\nQ. What is the meaning of boldface numbers in Table 2? There are multiple numbers of boldface numbers. The essential explanation seems to be missing or at least not highlighted enough to check. \n\n**Minor Comments**\n\nC. An explicit definition of the entity-centric environment would be helpful.\n\nC. In Figure 1, DLP is presented without a proper definition. Please at least use Deep Latent Particles (DLP) \\cite{xx}."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2aWpxXLb1P", "forum": "TimC6hxVHj", "replyto": "TimC6hxVHj", "signatures": ["ICLR.cc/2026/Conference/Submission14339/Reviewer_q4dk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14339/Reviewer_q4dk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920425833, "cdate": 1761920425833, "tmdate": 1762924761380, "mdate": 1762924761380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a two part hierarchical reinforcement learning framework that targets environments with multiple entities and sparse reward. Their framework (HECRL) is composed of 1. Subgoal diffuser: a high-level diffusion model that generates immediate subgoal, and 2. a value based Goal Conditioned Reinforcement Learning agent that does test-time subgoal selection. \n\nThe work tackles non-stationarity and instability in off-policy hierarchical RL (the issue of reward error propagation in long horizon tasks) by producing immediate subgoal that is reachable and provides clear learning signal to the policy learning agent. This is done by enforcing a value based reachability constraint at test time. \n\nExperiments on several continuous-control benchmarks (Reacher, Pusher, Point Maze, Ant Maze variants, Ant Fall) show improved sample efficiency and final success rates over strong HRL baselines such as HIRO, HRAC, HIGL, SAGA, and HLPS, as well as smaller gaps between generated and actually reached subgoals, and ablations indicate that both diffusion and GP components contribute to the gains"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Originality: The framework is modular, compatible with various value-based GCRL algorithms. Existing hierarchical diffusers diffuse over global subgoals without explicit entity factorization. EC-Diffuser uses entity-centric diffusion but for behavior cloning rather than subgoal generation. Hence, the proposed combination of conditional diffusion model over entity-factored subgoals with a value-based GCRL agent  is novel. The paper also make it clear that their framework builds directly on two mature lines of work — hierarchical diffusion for subgoals and entity-centric RL, and that their contribution is meaningful but compositional, rather than a completely new paradigm. \n\n2. Significance: The contribution is more than a minor architectural tweak. Using GP prior over the high-level mapping as a separate surrogate distribution provides explicit predictive means and variances over subgoals: this defines a hybrid selection rule that mixes diffusion-sampled subgoals with the GP mean. The paper also shows theoretical justification beyond heuristics. \n\n3. Quality: The benchmarks used includes a reasonably broad suite of continuous-control HRL benchmarks using both sparse and dense rewards, and compared against several strong and closely related HRL baselines (HIRO, HRAC, HIGL, SAGA, HLPS). The learning curves show consistent gains. Additional metrics such as distances between generated and reached subgoals are also reported. \n\n4. Clarity: The related work section clearly states prior subgoal methods and how their framework relate to them (e.g. HIRO, HRAC, HIGL),  making clear that this paper moves from deterministic or adversarial subgoal generators and GP-only models to a more expressive diffusion-GP hybrid with explicit uncertainty-guided selection. Compared to the authors’ previous work, the framework in this paper changes both the generative family (diffusion instead of adversarial or simple parametric models) and the way uncertainty is integrated (GP acting both as regularizer and as a competing proposal). The experimental results demonstrate stronger performance on harder tasks."}, "weaknesses": {"value": "1. Figure quality and readability:\nThe figures are difficult to read in their current form. In Figure 1, the circles and arrows are thin and low-contrast, and the text labels are very small and faint. As a result, it is hard to discern the structure and details of the illustration. Given that this is the first figure of the paper and is meant to convey the main idea, it should be redesigned with larger fonts, clearer icons, and higher contrast to make the diagram easy to understand for the readers. \n\n2. Insufficient discussion of sensitivity analysis: \nThe framework in this paper is much more complex than most baselines (e.g., HIRO, HRAC, HIGL). There should be a more discussion on the complexity, overhead and practicality measurement such as sensitivity to replay-buffer size and number of inducing points and memory usage to discuss ability/limitation to scale to larger benchmarks. Moreover, the paper could elaborate on the sensitivity analysis of the number of choices HIDI depends on: the HIRO-style relabeling scheme, the GP's kernel form and hyperparameters, number and placement of inducing points, and the mixing probability/schedule between diffusion-sampled subgoals and GP mean. \n\n3. Limitation in the complexity of experiments:\nAll reported experiments seem to be on relatively low-dimensional MuJoCo-style state spaces (Reacher, Pusher, maze-like Ant tasks, Ant Fall). The evaluation could include more pixel-based or complex multi-entity/object-centric environments to demonstrate more clearly whether the additional complexity is strictly necessary and meaningful in those settings, and show how well the GP prior and sparse-GP approximation scale with dimensionality. \n\n4. Limited practical impact of the theoretical guarantees: \nThe proofs are built upon rather ideal assumptions: that the diffusion subgoal policy to be already “near-optimal” and certain regularity conditions holds. Under these assumptions, the paper only proves single-step regret and single-step policy-improvement bounds. However, it does not extend or discuss these guarantees in long-horizon setting, where performance depends on multiple sequential decisions made under function-approximation error, stochastic optimization, and model mismatch. There are no results or discussion on cumulative regret, stability over time, or convergence of the overall learning process. Although the mathematical analysis is helpful to build intuition and to justify the framework’s design, it is insufficient to provide strong guarantees about the behavior of the full end-to-end hierarchical system."}, "questions": {"value": "1. Lack of a clear high-level framework diagram.\nThe paper could include a high-level illustration of the framework to show how the different components (high-level policy, diffusion model, GP module) interact and how information flows between them. At present, the description is quite text-heavy and the existing figures are not sufficiently clear to understand how the components add together. Having a high level figure of the framework helps reader understand how the framework builds on top of existing frameworks and make the novel parts of the framework more explicit, which is currently difficult to see from the text-heavy description. \n\n2. Insufficiently clear description of ablation variants.\nThe paper could explain more clearly what each ablation variant changes and how it corresponds to the conceptual components of the method (pure diffusion, GP-only, hybrid selection)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5v2mBsYGSP", "forum": "TimC6hxVHj", "replyto": "TimC6hxVHj", "signatures": ["ICLR.cc/2026/Conference/Submission14339/Reviewer_m4Xk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14339/Reviewer_m4Xk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762801331078, "cdate": 1762801331078, "tmdate": 1762924761055, "mdate": 1762924761055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}