{"id": "TW8ps0YirX", "number": 13930, "cdate": 1758225394451, "mdate": 1759897402789, "content": {"title": "XYZ-IBD: Benchmarking Robust 6D Object Pose Estimation under Real-World Industrial Complexity", "abstract": "We introduce XYZ-IBD, a bin-picking benchmark for 6D pose estimation that captures real-world industrial complexity, including challenging object geometries, reflective materials, severe occlusions, and dense clutter. The dataset reflects authentic robotic manipulation scenarios with millimeter-accurate annotations. Unlike existing datasets that primarily focus on household objects, which approach saturation, XYZ-IBD represents the unsolved vision problems in the real-world application. The dataset features metallic and mostly symmetrical objects of varying shapes and sizes. These objects are heavily occluded and randomly arranged in bins with high density, replicating the challenges of industrial bin-picking.\nXYZ-IBD was collected using two high-precision industrial cameras and one commercially available camera, providing RGB, grayscale, and depth images. It contains 75 multi-view real-world scenes with around 273k annotated object instances, along with a large-scale synthetic dataset rendered under simulated bin-picking conditions. We employ a meticulous annotation pipeline that includes anti-reflection spray, multi-view depth fusion, and semi-automatic annotation, achieving millimeter-level pose labeling accuracy required for industrial manipulation. Quantification in simulated environments confirms the reliability of the ground-truth annotations.\nWe benchmark state-of-the-art methods on 2D detection and 6D pose estimation tasks on our dataset, revealing significant performance degradation in our setups compared to current academic household benchmarks. By capturing the complexity of real-world bin-picking scenarios, XYZ-IBD introduces more realistic and challenging vision problems for future research.", "tldr": "A High-precision Benchmark for Robust 6D Object Pose Estimation under Real-World Industrial Complexity", "keywords": ["Dataset and Benchmarks", "6D Pose Estimation", "Multi-instance 2D detection", "Industrial Bin-picking", "Clutter Scenes"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1fed25939f79274dad2f5efe11631b497b8bbee2.pdf", "supplementary_material": "/attachment/6576004b7374b684b4b22afe6d19f2d3ae66cd67.zip"}, "replies": [{"content": {"summary": {"value": "The authors introduce a new dataset for benchmarking 6DOF pose estimation methods. The dataset focuses on industrial objects, with realistic contexts, such as objects are cluttered, densely stacked. Experiments are performed and compared with other benchmarks for a number of SOTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- I fully agree with the authors that more realistic, more challenging benchmarks are relevant for research in industrial applications.\n- The dataset seems valuable, is well documented and should have a positive impact on the research field\n- Recent SOTA methods are evaluated on the benchmark, and compared with existing benchmarks."}, "weaknesses": {"value": "- The paper is poorly written and needs some extra attention, see below for more detailed feedback.\n- As I said, I think this is very relevant research, but I doubt the fit with the ICLR venue. I think the scope of the dataset is too narrow and too applied."}, "questions": {"value": "- Please use \\citep (parentheses)\n- The bright red and green for resp. citations and fig. referencing is hard to read. I suggest to use darker colors, or black.\n- The XYZ-IBD acronym is not explained in the abstract. What does the XYZ stand for? It seems redundant.\n- Abstract: \"which approach saturation\", unclear what this means exactly.\n- line 37: \"segment and estimate\"\n- Fig.2 is a bit unclear, provide more context in the caption\n- line 214: \"sizes (\"\n- inconsistent use of spaces between number and unit (e.g. line 232)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b9jmL0SyGo", "forum": "TW8ps0YirX", "replyto": "TW8ps0YirX", "signatures": ["ICLR.cc/2026/Conference/Submission13930/Reviewer_9ZYz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13930/Reviewer_9ZYz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13930/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761818203966, "cdate": 1761818203966, "tmdate": 1762924435966, "mdate": 1762924435966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the XYZ-IBD dataset for 6D object pose estimation in industrial bin-picking scenarios. The work aims to capture challenging industrial conditions including reflective materials, severe occlusions, and dense clutter. The dataset construction shows effort, and the multi-sensor setup integrating RGB, grayscale, and depth modalities is reasonable. The work addresses a practical scenario that could be relevant for robotics applications."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The dataset construction demonstrates considerable effort and technical competence. The multi-sensor data acquisition setup integrating RGB, grayscale, and depth modalities is well-designed and provides diverse data modalities that could benefit future research in industrial pose estimation. The semi-automatic annotation pipeline with multiple validation steps shows careful attention to data quality. The high annotation accuracy of 0.99mm, while validated through simulation, represents a notable achievement for industrial applications requiring millimeter-level precision.\nThe work addresses a practical industrial scenario that appears underrepresented in existing benchmarks. Bin-picking with industrial objects presents real challenges including reflective materials, severe occlusions, and dense clutter, which are relevant for robotics applications. The dataset includes both real-world and synthetic data, providing training resources for the research community.\nThe benchmarking effort with multiple state-of-the-art methods provides baseline results that could serve as useful references. The inclusion of both seen and unseen object evaluation protocols demonstrates consideration of different use cases."}, "weaknesses": {"value": "First, the paper does not clearly establish what makes XYZ-IBD uniquely valuable compared to existing industrial datasets such as T-LESS, ROBI, and IPD. The core challenges addressed have been partially covered by these prior works. The distinction from recent work like IPD 2024, which also employs multi-sensor approaches for similar scenarios, remains unclear. While XYZ-IBD achieves higher annotation accuracy, this appears to be an engineering improvement rather than a conceptual advance.\nSecond, the experimental validation appears limited. The benchmarking includes only a constrained set of mainstream methods and lacks comparisons with industrial-specific pose estimation frameworks. The performance degradation observed is not attributed to specific factors. The results would benefit from error analysis categorizing failures by object type, occlusion level, and material properties.\nThird, key technical details are not sufficiently documented. The specific implementation of multi-view depth fusion and ICP refinement in the annotation pipeline is not clearly described. The synthetic dataset generation process, particularly how physics-based interactions are simulated, lacks detail needed for reproducibility. The validation method relying on simulated environments may have limitations due to domain gaps with reality.\nFourth, the use of anti-reflection spray during data collection raises concerns about whether the dataset truly represents unmodified industrial environments. This practice fundamentally alters optical properties and cannot be applied in real industrial testing scenarios, which undermines the practical utility of the benchmark.\nFourth, the discussion of limitations is brief. The paper mentions constraints on working distance and object scale but does not explore how these affect applicability to other industrial scenarios. Potential biases in data collection are not adequately analyzed."}, "questions": {"value": "(1)\tCompared to existing industrial datasets such as T-LESS, ROBI, and IPD, how does XYZ-IBD uniquely address unmet challenges through its object selection, scene design, and annotation accuracy?\n(2)\tWhy were only a limited number of mainstream methods selected for benchmarking? How might results differ if compared with industrial-specific frameworks optimized for reflective and texture-less objects?\n(3)\tCould you provide detailed implementation details of multi-view depth fusion and ICP refinement to ensure reproducibility?\n(4)\tWhat measures were taken to mitigate biases during data collection? How might fixed lighting conditions and object arrangement affect model generalizability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uh7hdFCfgM", "forum": "TW8ps0YirX", "replyto": "TW8ps0YirX", "signatures": ["ICLR.cc/2026/Conference/Submission13930/Reviewer_WsAo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13930/Reviewer_WsAo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13930/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918943190, "cdate": 1761918943190, "tmdate": 1762924435477, "mdate": 1762924435477, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents XYZ-IBD, a new benchmark dataset for 6D pose estimation in industrial bin-picking scenarios. The dataset aims to capture the visual and geometric complexity of real-world industrial settings, which are not well represented in existing benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a contribution through the introduction of a new benchmark, XYZ-IBD, designed specifically for realistic industrial bin-picking scenarios. It addresses a domain that existing household-oriented datasets fail to capture. The authors combine RGB, grayscale, and depth modalities from multiple industrial-grade sensors while the data collection and annotation pipeline is of high quality which could be observed from the supplementary materials provided. The work is overall well-written and well-organized."}, "weaknesses": {"value": "The paper should provide more baselines such as MegaPose which has recently emerged as a strong generalizable baseline trained on massive synthetic datasets with extensive domain randomization, designed precisely for cross-domain and industrial-level robustness. Given that XYZ-IBD explicitly aims to test generalization to real-world industrial conditions, the absence of such a model makes it difficult to assess whether the benchmark truly challenges state-of-the-art generalizable pipelines. Incorporating it would provide a more comprehensive performance landscape and help quantify whether industrial failures are due to dataset complexity or method generalization limits.\n\nThe current paper clearly motivates the need for industrial realism but does not explicitly articulate the scientific questions or hypotheses that XYZ-IBD aims to test. As a result, the benchmarkâ€™s intended research contribution is somewhat implicit rather than formally defined. One format is that \"RQ1: Can synthetic data augmentation (e.g., BlenderProc) sufficiently bridge the domain gap for reflective, texture-less objects?\""}, "questions": {"value": "The paper should compare with DTTD[1] & DTTD2[2] which aims for industrial indoor scenarios using commercial and iPhone sensors.\n\n[1] Feng, Weiyu, et al. \"Digital twin tracking dataset (dttd): A new rgb+ depth 3d dataset for longer-range object tracking applications.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n[2] Huang, Zixun, et al. \"Robust 6DoF Pose Estimation Against Depth Noise and a Comprehensive Evaluation on a Mobile Dataset.\" Proceedings of the Computer Vision and Pattern Recognition Conference. 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LSpAtprhyS", "forum": "TW8ps0YirX", "replyto": "TW8ps0YirX", "signatures": ["ICLR.cc/2026/Conference/Submission13930/Reviewer_Z2mu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13930/Reviewer_Z2mu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13930/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969576738, "cdate": 1761969576738, "tmdate": 1762924434704, "mdate": 1762924434704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new benchmark dataset named XYZ-IBD for 6D object pose estimation, specifically for industrial bin-picking applications. It provides both RGB and depth data. It uses a semi-automatic annotation pipeline. It also provides physics-based simulations to generate synthetic data. It also provides benchmarking of several SOTA 6D pose estimation methods to show that their performance will significantly drop compared to other 6D object pose estimation benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper addresses a real industrial problem of bin picking of a large number of objects in the same shape. The problem exhibit sufficient occlusion, reflective surface, and clutter which are challenging for robotic perception.\n- The authors argued a <1mm annotation accuracy, which is impressive.\n- The benchmarking of several SOTA methods shows bad results. It means that the dataset maybe have introduced an unsolved challenging problem that previous datasets were not able to address."}, "weaknesses": {"value": "- The annotation process is in extremely high cost. The annotators need to manually align 3D CAD models to each object instance in the image via a GUI which is very slow and costly. This is probably the main reason that this dataset is limited in scale.\n- It is unsure how the authors measures the average annotation error correctly, especially when the depth is generated by projected pattern deformation analysis. The depth generation process involves a lot of complex steps and it is hard to judge if the error measurement is correct.\n- The authors applied anti-reflection spray to the objects before collecting the data. This is not OK in my opinion. Anti-reflection spray is indeed good for capturing depth on which the pose annotation relies. However, in real applications, there is no anti-reflection spray applied. The depth sensor signal will be very different, meaning that all the pose data collected with anti-reflection spray will be meaningless. On the other hand, without anti-reflection spray, there is no way to accurately annotate the pose data.\n- The main data for high-precision annotation is collected by industrial-grade high-precision scanners. This limits the application scope of this dataset, since not everyone has the same scanner in their lab as the authors. Though Intel Realsense cameras are also used to collect data, however, I highly doubt if the Realsense is enough to provide sensing signal sufficiently accurate for pose estimation of these small objects. This is probably the reason why the SOTA methods show bad results."}, "questions": {"value": "The authors can respond to the \"Weakness\" section of my review."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "y3sGvu7OdK", "forum": "TW8ps0YirX", "replyto": "TW8ps0YirX", "signatures": ["ICLR.cc/2026/Conference/Submission13930/Reviewer_DE1B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13930/Reviewer_DE1B"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13930/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762086066368, "cdate": 1762086066368, "tmdate": 1762924434230, "mdate": 1762924434230, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}