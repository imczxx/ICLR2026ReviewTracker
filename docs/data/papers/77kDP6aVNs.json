{"id": "77kDP6aVNs", "number": 13837, "cdate": 1758223484503, "mdate": 1759897409391, "content": {"title": "Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive Learning", "abstract": "Supervised contrastive learning has achieved remarkable success by leveraging label information; however, determining positive samples in multi-label scenarios remains a critical challenge. In multi-label supervised contrastive learning (MSCL), multi-label relations are not yet fully defined, leading to ambiguity in identifying positive samples and formulating contrastive loss functions to construct the representation space. To address these challenges, we: (i) systematically formulate multi-label relations in MSCL, (ii) propose a novel Similarity-Dissimilarity Loss, which dynamically re-weights samples based on similarity and dissimilarity factors, (iii) further provide theoretical grounded proofs for our method through rigorous mathematical analysis that supports the formulation and effectiveness, and (iv) offer a unified form and paradigm for both single-label and multi-label supervised contrastive loss. We conduct experiments on both image and text modalities and further extend the evaluation to the medical domain. The results show that our method consistently outperforms baselines in comprehensive evaluations, demonstrating its effectiveness and robustness. Moreover, the proposed approach achieves state-of-the-art performance on MIMIC-III-Full.", "tldr": "", "keywords": ["multi-label supervised constrastive learning; supervised representation learning; contrastive loss"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d01dad23e32146c0e817115bf9f910562c2a00ed.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the fundamental challenge of defining positive samples and contrastive loss in Multi-label Supervised Contrastive Learning (MSCL). Its main contributions are: (i) a systematic formulation of multi-label relations for MSCL, (ii) a novel Similarity-Dissimilarity Loss that dynamically weights samples, supported by (iii) theoretical analysis, and (iv) a unified framework for both single and multi-label contrastive learning. The method is empirically validated across image, text, and medical domains, achieving SOTA on MIMIC-III-Full. The work is well-motivated, provides a solid theoretical grounding, and demonstrates strong empirical performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1）It offers a clear and systematic formalization of multi-label relationships using set theory, providing a rigorous foundation for the field. \n2) The proposed Similarity-Dissimilarity loss is both simple and interpretable, with a mathematically bounded design that facilitates stable training and analysis.\n3)  A major strength is the comprehensive theoretical proof, which grounds the method's properties and moves beyond mere empirical tuning. \n3) The extensive cross-modal and cross-domain validation, particularly the state-of-the-art results on the challenging MIMIC-III-Full benchmark, convincingly demonstrates the method's practical utility and robustness."}, "weaknesses": {"value": "1. Although this paper innovates in the definition of relations and the design of the S–D loss, existing work (e.g., [ref 1] using set operations to synthesize multi-label samples in feature space; [ref 2] proposing label-aware contrastive weighting; and [ref 3] integrating label hierarchies into supervised contrastive) has also explored leveraging label relations to improve representation learning at different levels. Authors are advised to clearly and concisely explain the differences between this work and the new contributions of this paper in the introduction or related works.\n[ref 1] Alfassy, A., Karlinsky, L., Aides, A., Shtok, J., Harary, S., Feris, R., ... & Bronstein, A. M. (2019). Laso: Label-set operations networks for multi-label few-shot learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition(pp. 6548-6557).\n[ref 2] Suresh, V., & Ong, D. C. (2021). Not all negatives are equal: Label-aware contrastive loss for fine-grained text classification. arXiv preprint arXiv:2109.05427.\n[ref 3] Chi Lok U, S., He, J., Gutierrez Basulto, V., & Pan, J. Z. (2023). Instances and labels: Hierarchy-aware joint supervised contrastive learning for hierarchical multi-label text classification.\n2. The paper primarily compares ALL, ANY, and MulSupCon (Zhang & Wu, 2024). While these three are directly relevant baselines, several new methods have emerged in the past two years (≥2023–2025) in multi-label/multi-label contrastive learning and ICD encoding (including those based on hierarchical relationships, graph/knowledge injection, sample/label resampling, or meta-learning for long-tail processing), which may be more representative or powerful comparisons. The paper does not compare with these recent/relevant strong baselines (particularly in the areas of medical ICD encoding and LLM-based fine-tuning), which reduces the empirical persuasiveness.\n3. Although the paper claims that the loss function is generalizable, it is not validated on more emerging tasks (such as multimodal multi-label and few-shot multi-label), nor is it tested on larger or more challenging datasets.\n4. More empirical evidence on long-tail and small-sample scenarios: The paper claims that S-D has advantages in long-tail scenarios, but only provides macro- and micro-average metrics and overall explanations. It lacks quantitative comparisons and statistical tests (e.g., macro-F1 improvements per frequency band) by label frequency (head, medium, and tail). This weakens the conclusion that it \"significantly improves the long-tail problem.\""}, "questions": {"value": "1. Have the authors reviewed and compared the work [ref 1] that focuses on label set manipulation/synthesis, and the highly related label-aware/hierarchy-aware contrastive learning work [ref 2-3]? If so, please clearly identify the key differences between the two types of work in the main text or appendix. If not, please provide a comparison in the revised manuscript and explain the added significance and advancement of this work. \n2. Baseline Selection and \"State-of-the-Art\" Comparison:Why only compare with ALL, ANY, and MulSupCon (Zhang & Wu, 2024)? Can you add representative recent work (2022–2025) in the areas of multi-label contrastive learning, multi-label reweighting, long-tail multi-label classification, and ICD encoding for comparison?\n3. The authors claim that the loss is uniform across single-label and multi-label scenarios (Equation 17). Can you demonstrate the numerical behavior of this loss in few-shot, multi-task, or extremely sparse label scenarios (1–2 labels per example)? For example, do state-of-the-art models such as ViT and Llama 3.2 also benefit from this loss?\n4. Can you further analyze the improvement of this method on tail categories in extremely long-tail scenarios (such as MIMIC-III-Full)? Can you compare it with methods such as Focal Loss and Balanced Contrastive Learning? Please provide additional grouping results for the head/medium/tail frequency bands (e.g., for MIMIC and MS-COCO) and provide a significance test (p-value or bootstrap CI) to demonstrate substantial improvement on long-tail labels."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6FOong8mHe", "forum": "77kDP6aVNs", "replyto": "77kDP6aVNs", "signatures": ["ICLR.cc/2026/Conference/Submission13837/Reviewer_Wexk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13837/Reviewer_Wexk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761182852911, "cdate": 1761182852911, "tmdate": 1762924360300, "mdate": 1762924360300, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper categorizes five fundamental multi-label relations (R1, R2, R3, R4, R5) in MSCL. Furthermore, it proposes a Similarity–Dissimilarity Loss to address the limitation of the prior method (Multi-label supervised contrastive learning), where the ANY relation fails to distinguish between R2 and R5."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper provides a well-structured and comprehensive categorization of label relations in multi-label contrastive learning.\n2.\tThe writing is clear and adheres to academic conventions."}, "weaknesses": {"value": "1.\tThe paper tackles a relatively minor issue in multi-label contrastive learning—the inability to distinguish between R2 and R5—and existing multi-label contrastive methods can already address this. The prior work “Contrastive Learning for Multi-Label Classification” presents a conceptually similar solution: like the proposed similarity–dissimilarity factors, it operates by increasing the denominator of the positive-pair term.\n2.\tThe Lemma 1 presented in the paper is not applicable to multi-label contrastive learning."}, "questions": {"value": "The works cited in Lemma 1 pertain to single-label learning, so the resulting conclusion may be incorrect; accordingly, the stated equality may not hold. Moreover, it is unclear why this equality is derived, since you later write, “It is evident that R2, R3, R4 and R5 represent fundamentally distinct relations, each characterized by different labels and semantic information.” The logical connection between these statements is not evident."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HHUxTUj1Du", "forum": "77kDP6aVNs", "replyto": "77kDP6aVNs", "signatures": ["ICLR.cc/2026/Conference/Submission13837/Reviewer_R4KG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13837/Reviewer_R4KG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761534051402, "cdate": 1761534051402, "tmdate": 1762924359521, "mdate": 1762924359521, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper try to address a critical challenge in MSCL: how to define and distinguish positive samples. The authors argue that current methods, which either require exact label matches (ALL) or treat any label overlap as equally positive (ANY, MulSupCon), fail to capture the rich semantic relationships between multi-label sets.\nTo solve this, the paper discusses based on five relation patterns and propose a novel similarity-dissimilarity Loss:\nIt introduces 5 relations R1-R5 to formally categorize the relationship between an anchor and a sample (e.g., disjoint, exact match, partial overlap, subset, superset).\nIt proposes the loss function which dynamically re-weights positive pairs within the contrastive loss. This re-weighting is based on two intuitive, parameter-free factors: a similarity factor that rewards the proportion of shared labels and a dissimilarity factor that penalizes the number of extraneous labels in the positive sample.\nThe authors provide a theoretical analysis to prove their loss function is bounded why it works. Experiments across image, text, and complex medical datasets demonstrate that SimDis-Loss consistently outperforms baselines. The method is presented as a low-cost, drop-in replacement for existing MSCL losses."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear problem and challenging definition: The paper clearly shows the challenges in MSCL problems and illustrate the weakness of baseline methods. Using the five-relation taxonomy is a clear way to demonstrate the problem. \n\n2. Loss Function: The proposed loss function is a intuitive and proven to be effective both via theoretic proofing and experimental results. The core idea of separately accounting for similarity and dissimilarity is a novel and powerful concept. It directly addresses the identified flaw in baseline methods: MulSupCon, which the authors correctly identify as only considering the similarity (intersection) component.\n\n3. Strong results compared to baseline methods: they show a consistent improvement compared to the baseline."}, "weaknesses": {"value": "1. Insufficient Results & Analysis in Main Paper: The experimental validation in the main paper (Section 3) is too brief and lacks sufficient detail. The most critical comparison, the SOTA benchmark on MIMIC-III-Full (Table 6), is relegated to the appendix. The main paper should contain the strongest evidence of the method's efficacy, including key SOTA comparisons, to allow a reader to assess its performance without hunting through the appendix.\n\n2. Limited Novelty: The paper's novelty appears to be limited. The core idea of re-weighting positives in a contrastive loss based on label overlap is not new. This work feels like an incremental improvement that combines existing concepts (contrastive learning + set-theoretic weighting) rather than a foundational new contribution.\n\n3. Lack of Deep Analysis for the Loss Function: The paper fails to provide a deep justification for its core component, the dissimilarity function $\\mathcal{K}^d = 1 / (1 + x)$. Why this specific form? The penalty is non-linear. The paper also relies on the strong, unproven assumption that any increase in the number of extraneous labels necessarily and consistently means the sample is \"less positive.\" This intuition is not fully explored or validated.\n\n4. Overstated Theoretical Contribution: The theoretical analysis (Section 2.6) feels overwrought. Theorems 1-5 are largely intuitive and immediate consequences of the definitions of $\\mathcal{K}^s$ and $\\mathcal{K}^d$; they are straightforward to prove and do not provide deep new insights. This space (nearly a full page) could have been more effectively used to provide the deeper loss function analysis or to move the critical experimental results from the appendix into the main paper.\n\n5. Unclear Figures: The data visualization needs improvement. Figure 2a, in particular, is not an effective way to show a comparison. The stacked-bar \"Improvement\" chart obscures the direct comparison between the proposed method and the most relevant baseline (MulSupCon). A simple grouped bar chart, or even just including the raw data in Table 1, would be much clearer and more transparent."}, "questions": {"value": "1. Asymmetric Definition: The current weighting factor $\\mathcal{K}^s \\mathcal{K}^d$ is asymmetric. It penalizes extraneous labels in the positive sample ($\\mathcal{T} \\setminus \\mathcal{S}$) but not in the anchor ($\\mathcal{S} \\setminus \\mathcal{T}$). This directly leads to R4 and R5 having different weights. What is the strong semantic justification for this? Have you experimented with a symmetric formulation (e.g., one based on the Jaccard index for similarity and a symmetric difference for dissimilarity)?\n\n2. Embedding Visualization: The central claim is that your loss function learns to cluster samples based on the 5 relations. To provide strong qualitative evidence for this, could you please add an embedding visualization (e.g., t-SNE) of the learned feature space, with points colored by their relation (R1-R5) to a chosen anchor class?\n\n3. Code Availability: The link to the code in the appendix is an anonymous placeholder and is not functional. Will a working repository be provided for reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ERBLnnSduS", "forum": "77kDP6aVNs", "replyto": "77kDP6aVNs", "signatures": ["ICLR.cc/2026/Conference/Submission13837/Reviewer_YWGu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13837/Reviewer_YWGu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875063666, "cdate": 1761875063666, "tmdate": 1762924358832, "mdate": 1762924358832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript system defines five kinds of multi-label relationships (R1-R5), and proposes Similarity-Dissimilarity Loss, which dynamically weights samples by similarity factor (label intersection ratio) and difference factor (extra label penalty). At the same time, it provides strict mathematical proofs (five theorems) to verify its rationality and boundary, and realizes a unified paradigm of single/multi-label supervision and comparison loss."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "In this paper, a dynamic weighted loss function integrating similarity factor and difference factor is constructed to realize the unified paradigm of single/multi-label supervision and comparative loss, and the theoretical design has clear problem pertinence and academic value. \nCovering the multimodal data of \"image-text-medical treatment\" and considering variables such as \"long tail distribution\" in the medical field (MIMIC series), the experimental dimensions are comprehensive."}, "weaknesses": {"value": "The selection basis of loss function superparameter is missing: the document sets the temperature parameter τ=0.07, but it does not explain why this value is suitable for multi-modal (image, text, medical) data, nor does it provide the sensitivity analysis of τ, so it is impossible to verify the robustness of superparameter selection. \nThe ablation experiment is missing, and the value of key modules is not verified: the proposed loss function contains two core modules: similarity factor and difference factor, but the ablation experiment is not designed, so it is impossible to quantify the contribution of a single module to performance, and it is impossible to prove that the necessity of \"dynamic weighting\" mechanism is better than that of fixed weighting scheme. \nMissing key chart information: Figure 1 (five examples of multi-label relationships) only shows the one-hot vector representation of labels, but does not label the sample semantics corresponding to each relationship, which is poor in readability; Table 4 and Table 5 (the results of data sets such as MIMIC-III-50) have confusing typography (such as \"AUC Macro Micro”“F1 Macro Micro Micro\"), which affects the interpretation of the results. The data in the table was not analyzed."}, "questions": {"value": "In the experiment of medical field, the manuscript only compares ALL, ANY and MulSupCon, and does not include the SOTA method for medical multi-label classification in recent years, and does not explain the reasons for excluding these baselines, why?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TDS2X6iLFL", "forum": "77kDP6aVNs", "replyto": "77kDP6aVNs", "signatures": ["ICLR.cc/2026/Conference/Submission13837/Reviewer_5y7b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13837/Reviewer_5y7b"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13837/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762327677927, "cdate": 1762327677927, "tmdate": 1762924358296, "mdate": 1762924358296, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}