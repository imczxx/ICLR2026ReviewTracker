{"id": "IwSvhHAQcL", "number": 10248, "cdate": 1758165078506, "mdate": 1763187284419, "content": {"title": "Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents", "abstract": "Long-horizon robotic manipulation poses significant challenges for autonomous systems, requiring extended reasoning, precise execution, and robust error recovery across complex sequential tasks. Current approaches, whether based on static planning or end-to-end visuomotor policies, suffer from error accumulation and lack effective verification mechanisms during execution, limiting their reliability in real-world scenarios. We present Agentic Robot, a brain-inspired framework that addresses these limitations through Standardized Action Procedure (SAP)--a novel coordination protocol governing component interactions throughout manipulation tasks. Drawing inspiration from Standardized Operating Procedures (SOPs) in human organizations, SAP establishes structured workflows for planning, execution, and verification phases. Our architecture comprises three specialized components: (1) a large reasoning model that decomposes high-level instructions into semantically coherent subgoals, (2) a vision-language-action executor that generates continuous control commands from real-time visual inputs, and (3) a temporal verifier that enables autonomous progression and error recovery, ensuring timely subtask termination to avoid redundant execution and enable smooth subgoal transitions. This SAP-driven design supports dynamic self-verification without external supervision. On the LIBERO benchmark, Agentic Robot achieves competitive performance, with a clear advantage in the average success rate of 79.6\\%, outperforming SpatialVLA by 6.1\\% and OpenVLA by 7.4\\% on long-horizon tasks.  These results demonstrate that SAP-driven coordination between specialized components enhances both performance and interpretability in sequential manipulation, suggesting significant potential for reliable autonomous systems.", "tldr": "We present Agentic Robot, a brain-inspired agentic framework that integrates reasoning-based planning, reactive execution, and visual verification for long-horizon manipulation", "keywords": ["Brain-inspired", "Vision-Language-Action models", "Embodied agents", "Standardized action procedure"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/e7120c92ce6ba9f21e3feeb88469a10bf01ee1e6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Agentic Robot, a brain-inspired embodied manipulation framework integrating planning, execution, and verification via a Standardized Action Procedure (SAP). The approach outperforms prior methods on the LIBERO benchmark (79.6% success), with ablation studies confirming the benefits of subgoal decomposition and visual verification."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper features a clear modular design: the planner–executor–verifier loop is explicitly defined and highly interpretable, drawing a meaningful analogy to biological and cognitive systems.\n2. The paper is clearly organized and well written, making it easy to follow the methodology and key ideas."}, "weaknesses": {"value": "1. The novelty of the work is limited. Each module is built on existing systems, and the main contribution lies in their integration rather than model-level innovation. Much of the work focuses on prompt engineering and system composition. The overall pipeline is very similar to many existing agent-based frameworks, showing little distinction from prior work [1,2,3].\n2. A key limitation is the lack of real-world validation. All experiments are performed in simulation, while physical robot deployment is only mentioned conceptually without empirical demonstration.\n3. The evaluation is restricted to LIBERO, and generalization to other domains or unseen settings remains untested.\n\n[1] Wang, Zihao, et al. \"Describe, explain, plan and select: interactive planning with large language models enables open-world multi-task agents.\" Proceedings of the 37th International Conference on Neural Information Processing Systems. 2023.\n\n[2] Yao, Shunyu, et al. \"React: Synergizing reasoning and acting in language models.\" The eleventh international conference on learning representations. 2022.\n\n[3] Du, Yuqing, et al. \"Vision-Language Models as Success Detectors.\" Conference on Lifelong Learning Agents. PMLR, 2023."}, "questions": {"value": "1. See weaknesses above.\n2. In addition to its effect on overall task success rate, it would be helpful to include a quantitative evaluation of the verifier’s accuracy in assessing whether a task has been successfully completed.\n3. The recovery mechanism is rather simplistic, consisting mainly of lifting and retrying. According to the results, this leads to a 59.7% success rate, representing only a 1.9% change—an effect that is marginal and inconsistent with the claimed advantage of the proposed recovery strategy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WhSmYdRuLb", "forum": "IwSvhHAQcL", "replyto": "IwSvhHAQcL", "signatures": ["ICLR.cc/2026/Conference/Submission10248/Reviewer_SuHz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10248/Reviewer_SuHz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761026146903, "cdate": 1761026146903, "tmdate": 1762921604811, "mdate": 1762921604811, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "jSpjRR21tU", "forum": "IwSvhHAQcL", "replyto": "IwSvhHAQcL", "signatures": ["ICLR.cc/2026/Conference/Submission10248/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10248/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763187283648, "cdate": 1763187283648, "tmdate": 1763187283648, "mdate": 1763187283648, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Agentic Robot, a brain-inspired control framework for long-horizon manipulation built around a Standardized Action Procedure (SAP) that coordinates three modules: an LRM-based planner that decomposes tasks into subgoals, a VLA executor, and a VLM verifier for periodic success checking and recovery. Experiments on LIBERO report an average success rate of 79.6%, with the largest gains on LIBERO-Long"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear modularity and interpretability. SAP defines explicit interfaces and a closed perception–planning–execution–verification loop, making component roles and information flow easy to reason about. \n- Verification as a control signal. The periodic VLM verifier enables early error detection, retries, and subgoal-level termination, which is well-motivated for long horizons."}, "weaknesses": {"value": "- Limited technical novelty. The core contribution is a coordination protocol that combines existing ingredients (LLM/LRM planner, VLA executor, VLM verifier) rather than introducing new learning algorithms or model architectures; much of the lift comes from structuring the pipeline. \n- Baselines skew toward end-to-end VLAs. Comparisons largely pit SAP against executor-only policies; the paper lacks head-to-head evaluations versus hierarchical planner + skill/executor systems (e.g., code-as-policies / voxel-value-map styles or recent cognition–execution bridges). This makes it hard to attribute gains specifically to SAP versus generic hierarchical decomposition. \n- Magnitude of improvements is uneven. Average performance is competitive but only modestly above strong VLAs on non-long suites; the main benefits are concentrated in LIBERO-Long. A deeper analysis of where SAP helps (failure modes, horizon length) would strengthen the case. \n- No real-robot validation. Results are simulation-only; the paper itself acknowledges challenges for physical deployment and domain shift, leaving sim-to-real efficacy untested."}, "questions": {"value": "- Comparative scope. Can you include baselines that combine a high-level planner with a low-level executor/skills (not just end-to-end VLAs), to isolate the effect of SAP’s verification/coordination versus generic hierarchy? (Even a re-implementation with simple rule-based termination would be informative.)\n- Verifier reliability & overhead. What are the verifier’s false-positive/negative rates, and how sensitive is performance to the verification frequency? Any ablation on adaptive scheduling or computational footprint under different intervals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YyFhIJMpKv", "forum": "IwSvhHAQcL", "replyto": "IwSvhHAQcL", "signatures": ["ICLR.cc/2026/Conference/Submission10248/Reviewer_PSLS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10248/Reviewer_PSLS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761059813029, "cdate": 1761059813029, "tmdate": 1762921604327, "mdate": 1762921604327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Agentic Robot, a brain-inspired framework for long-horizon robotic manipulation that coordinates planning, execution, and verification via a Standardized Action Procedure (SAP). On the LIBERO benchmark, Agentic Robot attains a 79.6% average success rate, outperforming SpatialVLA by 6.1% and OpenVLA by 7.4% on long-horizon tasks. The approach improves both performance and interpretability by making subgoal-level monitoring and recovery explicit."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Originality: The paper introduces a clearly defined coordination protocol—Standardized Action Procedure (SAP)—that operationalizes a brain-inspired perception–planning–execution–verification loop for embodied agents. Unlike prior sequential planners or end-to-end VLAs, SAP formalizes subgoal-level verification and recovery as first-class components, yielding a modular and enforceable protocol that goes beyond ad-hoc prompting or implicit success checks.\n\n- Quality: The framework is carefully engineered with three specialized, interoperable modules (LRM planner, VLA executor, VLM verifier).  The temporal verifier design (sliding buffer, two-stage assessment/diagnosis, recovery) is well-motivated and empirically supported, showing robust gains on long-horizon tasks."}, "weaknesses": {"value": "- The evaluation is overly simple and limited: it relies solely on the LIBERO benchmark and includes no real-world experiments. \n- It omits comparisons with stronger open-source baselines, such as pi0.5."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f3cs8qlhLD", "forum": "IwSvhHAQcL", "replyto": "IwSvhHAQcL", "signatures": ["ICLR.cc/2026/Conference/Submission10248/Reviewer_hZvB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10248/Reviewer_hZvB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761627210980, "cdate": 1761627210980, "tmdate": 1762921603893, "mdate": 1762921603893, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Agentic Robot, a brain-inspired framework designed to improve long-horizon robotic manipulation through structured coordination among specialized components. The central idea is the Standardized Action Procedure (SAP), a protocol inspired by Standardized Operating Procedures (SOPs) used in human organizations, which formalizes the workflow across planning, execution, and verification phases. The framework integrates three key modules: a large reasoning model for task decomposition, a vision-language-action executor for continuous control, and a temporal verifier for self-monitoring and error recovery. This design enables dynamic self-verification and robust subgoal transitions without external supervision. Experiments on the LIBERO benchmark show that Agentic Robot achieves competitive results, attaining a 79.6% average success rate and outperforming prior systems such as SpatialVLA and OpenVLA, particularly on long-horizon tasks. The findings suggest that structured inter-component coordination can enhance both the reliability and interpretability of autonomous robotic systems."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Overall, this is a well-written paper with good motivation and experiment validation.\n\n2. A lot of details are shown in the appendix."}, "weaknesses": {"value": "1. No real-world deployment experiments.\n\n2. More datasets and baselines should be included like VLABench, Cot-VLA, COA-VLA, pi 0.5, Groot, etc.\n\nhttps://openaccess.thecvf.com/content/ICCV2025/papers/Li_CoA-VLA_Improving_Vision-Language-Action_Models_via_Visual-Text_Chain-of-Affordance_ICCV_2025_paper.pdf\n\nhttps://arxiv.org/pdf/2501.15830\n\nhttps://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_CoT-VLA_Visual_Chain-of-Thought_Reasoning_for_Vision-Language-Action_Models_CVPR_2025_paper.pdf\n\nhttps://arxiv.org/pdf/2508.07917\n\nhttps://arxiv.org/pdf/2503.14734\n\n3. Some of the related work should be discussed. The subtask planning and self-reflection for long-term tasks are well explored and should be discussed.\n\nhttps://arxiv.org/abs/2411.18279\n\nhttps://arxiv.org/abs/2311.15649\n\nhttps://arxiv.org/abs/2403.03186\n\nhttps://arxiv.org/abs/2508.10146\n\nhttps://arxiv.org/abs/2504.16054"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YE20PcKQFO", "forum": "IwSvhHAQcL", "replyto": "IwSvhHAQcL", "signatures": ["ICLR.cc/2026/Conference/Submission10248/Reviewer_fqQc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10248/Reviewer_fqQc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725850463, "cdate": 1761725850463, "tmdate": 1762921603531, "mdate": 1762921603531, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}