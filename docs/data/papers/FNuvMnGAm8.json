{"id": "FNuvMnGAm8", "number": 13113, "cdate": 1758213717177, "mdate": 1763517012560, "content": {"title": "Load Balancing Mixture of Experts with Similarity Preserving Routers", "abstract": "Sparse Mixture of Experts (MoE) models offer a scalable and efficient architecture for training large neural networks by activating only a subset of parameters (“experts”) for each input. A learned router computes a distribution over these experts, and assigns input tokens to a small subset. However, without auxiliary balancing mechanisms, routers often converge to using only a few experts, severely limiting model capacity and degrading performance. Most current load balancing mechanisms encourage a distribution over experts that resembles a roughly uniform distribution of experts per token. During training, this can result in inconsistent routing behavior, resulting in the model spending its' capacity to learn redundant knowledge. We address this by introducing a novel load balancing loss that preserves token-wise relational structure, encouraging consistent expert choices for similar inputs during training. Our experimental results show that applying our loss to the router over a popular load balancing loss results in 35% faster convergence and lower redundancy, while removing balancing hyper-parameters completely.", "tldr": "We replace traditional balancing losses that enforce uniform sequence-wise usage with a new loss, improving performance.", "keywords": ["mixture of experts", "experts", "routing", "moe", "large language models", "llm", "load balancing", "language models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/86dc79879aeb8eb354e8d17065627e6295dfcd9f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposed SIMBAL which uses a router orthogonalization loss that is believed to encourage expert specialization. The authors claim significant improvements over the traditional auxiliary load balancing loss, and claim that it removes balancing hyper-parameters completely."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The authors claim significant improvements over the traditional auxiliary load balancing loss.\n2. The authors claim that it removes balancing hyper-parameters completely.\n3. The author provides much analysis."}, "weaknesses": {"value": "1. The central idea of an orthogonality loss on the router weights is conceptually similar to the \"router orthogonalization loss\" in the ERNIE 4.5 technical report. It would be beneficial to cite this parallel and frame the work's distinct contributions.\n2. The orthogonality of router does not necessarily leads to different expert routing behavior. Suppose R=BQ（Q^TQ = I_E, B\\in R^{DxD}）, one can easily apply B^{-1} to input x (e.g. absorb into the former layers' mlp), so that any router's behaviour equals to an orthogonal router on a routed input.\n3. I doubt the gain comes from the scale constraint rather than the constraint on direction. It may affect the logits size so as to affect the loss."}, "questions": {"value": "1. I suggest some experiments may be done to address point3 in weakness.\n2. Explanation on point2 in weakness is welcome."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "icWfaNCFtv", "forum": "FNuvMnGAm8", "replyto": "FNuvMnGAm8", "signatures": ["ICLR.cc/2026/Conference/Submission13113/Reviewer_JVb3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13113/Reviewer_JVb3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835004210, "cdate": 1761835004210, "tmdate": 1762923839501, "mdate": 1762923839501, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of redundancy and inconsistent routing in MoE models. The authors argue that standard load-balancing losses, which enforce a uniform distribution of tokens to experts, are inefficient. To solve this, they propose SIMBAL, that encourages the router's weight matrix (R) to be orthogonal by penalizing the difference between its Gram matrix (R^T R) and the identity matrix (I_E)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The idea of \"similar tokens should be routed similarly\" to preserve semantic consistency, is interesting. However, the methodology and computation cost are questionable."}, "weaknesses": {"value": "Please see the question block."}, "questions": {"value": "As mentioned in the abstract and throughout the paper: the goal of this model is to preserve the pairwise angles of the inputs (this means if two input $h_1$ and $h_2$ are similar, their routing should also be similar). This is achieved by promoting orthogonality in the router weights, because orthogonal matrices are dot-product ... preserving ....\n\nHowever, preserving the dot product of the D_M-dimensional inputs require the router R to satisfy R R^T = I_{D_M}.  But, this seems weird for me, as R is a  $D_M \\gg E$ matrix, (where the input dimension D_M is much larger than the number of experts E). Also the proposed loss  ||R^T R - I_E||_1, is a standard regularization that enforces orthogonality on the columns of $R$, encouraging diversity among experts.  So, it’s not clear how enforcing this diversity aligns with the goal of preserving input similarity. I think there is some mismatch and needs clarification. \n\nThe paper says the proposed PES requires less computation and is highly scalable. again in the same paragraph states that calculating PES requires inference once with the full model parameter, through all experts (a multiplier of 3.6-4.9x FLOPs in our case). Indeed,  4-5x increase in FLOPs is not cheap or scalable. Running all experts for a single token is computationally expensive.\n\nPES (Eq. 6) measures cos(f_i(x), f_j(x)), the similarity between the outputs of all $N$ experts for the same token $x$. But again, this requires dense computation for all experts for every input. \n\nOptional suggestion: In table 5, the baselines used for comparison are from 2018-2019. I understand the paper aims to improve upon earlier models, but incorporating recent baselines for the comparison can provide a meaningful evaluation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ij5a66XMU2", "forum": "FNuvMnGAm8", "replyto": "FNuvMnGAm8", "signatures": ["ICLR.cc/2026/Conference/Submission13113/Reviewer_D18y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13113/Reviewer_D18y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951730336, "cdate": 1761951730336, "tmdate": 1762923838955, "mdate": 1762923838955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SIMBAL, an auxiliary router loss for Mixture-of-Experts models that preserves token-wise relational structure by softly encouraging orthogonality of the router. The motivation is that angle-preserving routers produce more consistent expert choices for similar inputs, reducing redundancy and speeding training. The authors define a computationally cheap orthogonality loss, propose Pairwise Expert Similarity (PES) as a scalable metric of expert redundancy, and show empirical gains over the standard Load Balancing Loss on two model scales: faster convergence during training, lower PES, and better final perplexity and downstream benchmarks."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The idea is clear and intuitive. A code snippet is also provided in the appendix, showing the simplicity of the implementation. Moreover, the auxiliary loss hyperparameter is not sensitive to tuning, which makes this method easily integratable into existing architectures.\n\nThe empirical gains are strong: training convergence is significantly faster with SIMBAL loss, and the final perplexity and benchmark scores are also better for MoE trained with SIMBAL.\n\nNew metric for expert redundancy that quantifies the similarity of experts without requiring much computation\n\nEvaluation on a diverse set of pretraining benchmarks, with consistent improvements across all of them."}, "weaknesses": {"value": "The authors mention that stronger benchmark performance is realized when training on significantly more data than the datasets used in the paper. If possible, it would be good to see some results on how the SIMBAL method performs when training on these larger datasets, compared to traditional MoE.\n\nThe paper motivates orthogonality as angle preserving, but a more formal connection between router orthogonality and reduced redundancy / improved specialization (maybe via an analysis of routing variance or router saturation) would improve the justification of this approach.\n\nThe authors mention the loss calculation is cheap but it would be more convincing to see the comparison of training throughput between this method and standard MoE (if there is a difference)."}, "questions": {"value": "Can you compare the training throughput of standard MoE and SIMBAL? Is there a noticeable difference with SIMBAL loss or is it negligible? \n\nHow do the improvements depend on number of experts, and number of active experts? Does the performance change if the MoE is more or less sparse?\n\nWhat happens if you combine SIMBAL and LBL? Can they work together or do they conflict with each other?\n\nPES is computed over 4M sampled tokens, how does the measurement vary over different token samples? Can you report the variance across samples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zAOShr8Ud1", "forum": "FNuvMnGAm8", "replyto": "FNuvMnGAm8", "signatures": ["ICLR.cc/2026/Conference/Submission13113/Reviewer_H3da"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13113/Reviewer_H3da"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961372036, "cdate": 1761961372036, "tmdate": 1762923838446, "mdate": 1762923838446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a simple strategy to regularize the MoE router to avoid some issues with load-balancing loss (LBL) which is commonly used. The LBL encourages uniform routing to prevent expert collapse and token dropping, but as a result may create redundancy and lack of specialization among the experts. Intuitively, it is desirable that the routing decisions are similar for similar inputs, but this may be suppressed by LBL. To explicitly encourage this, the authors attempt to constraint the router to be orthogonal via a soft-regularization penalty. This penalty is simply the l1 distance of the router gram matrix to the identity. Adding the penalty does not add significant overhead per step and is able to reach a given target loss in fewer steps than LBL."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The authors provide a simple and principled approach to regularizing an MoE router in order to promote expert regularization and mitigate the redundancies in traditional load balancing loss approaches. This appears to substantially speed up MoE training. The empirical evidence is thorough and convincing."}, "weaknesses": {"value": "Minor: The term load-balancing loss for SIMBAL seems slightly incorrect."}, "questions": {"value": "The observed balance (high SEU) appears to be emergent, and is not guaranteed. It’s not obvious why orthogonality prevents collapse, can the authors comment on this?\n\nIf per-token entropy decreases but SEU remains high (Table 3), what exactly is being balanced?\n\nHow helpful is this approach when using a shared expert?\n\nCould excessive orthogonality reduce beneficial expert overlap?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ahwkBQIxeY", "forum": "FNuvMnGAm8", "replyto": "FNuvMnGAm8", "signatures": ["ICLR.cc/2026/Conference/Submission13113/Reviewer_CzLF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13113/Reviewer_CzLF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762111745467, "cdate": 1762111745467, "tmdate": 1762923838118, "mdate": 1762923838118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}