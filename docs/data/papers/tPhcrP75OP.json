{"id": "tPhcrP75OP", "number": 15742, "cdate": 1758254751013, "mdate": 1759897284987, "content": {"title": "FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding", "abstract": "Recent studies in long video understanding have harnessed the advanced visual-language reasoning capabilities of Large Multimodal Models (LMMs), driving the evolution of video-LMMs specialized for processing extended video sequences. However, the scalability of these models is severely limited by the overwhelming volume of visual tokens generated from extended video sequences. To address this challenge, this paper proposes FLoC, an efficient visual token compression framework based on the facility location function, a principled approach that swiftly selects a compact yet highly representative and diverse subset of visual tokens within a predefined budget on the number of visual tokens. By integrating the lazy greedy algorithm, our method achieves remarkable efficiency gains by swiftly selecting a compact subset of tokens, drastically reducing the number of visual tokens while guaranteeing near-optimal performance. Notably, our approach is training-free, model-agnostic, and query-agnostic, providing a versatile solution that seamlessly integrates with diverse video-LLMs and existing workflows. Extensive evaluations on large-scale benchmarks, such as Video-MME, MLVU, and LongVideoBench, demonstrate that our framework consistently surpasses recent compression techniques, highlighting not only its effectiveness and robustness in addressing the critical challenges of long video understanding, but also its efficiency in processing speed.", "tldr": "", "keywords": ["large multimodal model", "visual token compression", "long video understanding"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/521d82dc062c0ef23cb2f5c967cb675b2ce68942.pdf", "supplementary_material": "/attachment/414047547b5ddcda6abe0d2fe3a2221c58df1b97.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces FLoC, a training-free and model-agnostic visual token compression framework for long video understanding. By using a facility location function and a lazy greedy algorithm, FLoC efficiently selects a compact and representative subset of visual tokens, significantly reducing token volume while maintaining near-optimal performance. Extensive experiments show that FLoC outperforms recent compression methods on large-scale benchmarks in both effectiveness and processing speed."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The objective of the paper is well-motivated and clearly stated.\n\n2. The proposed method achieves state-of-the-art performance and efficiency in nearly all cases.\n\n3. The authors conduct comprehensive experiments across multiple benchmarks and baseline MLLMs."}, "weaknesses": {"value": "1. The authors should evaluate throughput, inference speed, and GPU memory usage to further highlight the efficiency of the proposed method compared to existing approaches.\n\n2. In the comparison experiments, it is surprising that PruneVid performs worse than random selection, given that PruneVid employs both clustering and a query-aware selection algorithm. Some discussion or analysis of this result would be helpful."}, "questions": {"value": "1. As shown in Table 3, basic clustering methods already achieve comparable performance. Does this suggest that sophisticated or complex designs may not be necessary?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BfOZ0w4OFq", "forum": "tPhcrP75OP", "replyto": "tPhcrP75OP", "signatures": ["ICLR.cc/2026/Conference/Submission15742/Reviewer_kqKm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15742/Reviewer_kqKm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814035904, "cdate": 1761814035904, "tmdate": 1762925981275, "mdate": 1762925981275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a facility-location-based efficient visual-token compression framework named FLoC for long video understanding. Specifically, FLoC includes two core modules: a Visual Token Selection Module and a Compressed Embedding Module, optimized through a lazy-greedy algorithm. The Visual Token Selection Module tokenizes videos into visual tokens, leverages the submodular facility-location function to measure token representativeness and diversity, and compresses them into compact embeddings. The Compressed Embedding Module concatenates the selected token embeddings with text prompts and feeds them into video-LMMs for downstream tasks. The entire process is guided by the greedy selection strategy, ensuring semantic fidelity and efficient compression without fully decoding the video.\n\nThe experimental evaluation in this paper assessed the performance of the proposed FLoC across three compression ratios and three video understanding benchmarks, comparing it with state-of-the-art baselines. The results indicate that the proposed FLoC achieves superior accuracy while reducing sequence length, thereby providing computational and memory efficiency gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The compression process does not rely on specific model architectures, nor is it tailored to particular queries or tasks; a single compression can support multiple downstream applications.\n- A visualization video of the lazy-greedy algorithm is provided in the supplementary material, making it more persuasive.\n- The experiments are sufficient, with the method’s performance verified on multiple models and benchmarks."}, "weaknesses": {"value": "- The method performs diversity selection within individual blocks, with no information interaction between blocks. Therefore, the choice of hyper-parameter T is crucial: a T that is too large may cause redundant computation, while a T that is too small may lead to redundant similar tokens across blocks. In Tab. 4, the optimal T differs under different compression rates, making it difficult to select an appropriate T across settings with different models, compression rates, and benchmarks.\n- FLoC aims for “global coverage,” which may cause extremely sparse but important tokens (e.g., a key object appearing in only one frame) to contribute very little to the total sum and risk being discarded, thereby affecting performance on needle-in-a-haystack tasks.\n- There is no comparison with graph-based video LLM compression methods such as FastVID or LLaVA-Scissor.\n- Only computation times of FLoC and traditional algorithms are compared; FLOPs and actual benchmark latency versus other compression methods are not reported."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QUy3S7AymY", "forum": "tPhcrP75OP", "replyto": "tPhcrP75OP", "signatures": ["ICLR.cc/2026/Conference/Submission15742/Reviewer_nG1P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15742/Reviewer_nG1P"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843123190, "cdate": 1761843123190, "tmdate": 1762925980855, "mdate": 1762925980855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FLoC (Facility Location-Based Efficient Visual Token Compression), a novel framework designed to tackle the scalability limits of video-Large Multimodal Models (LMMs) when processing long video sequences. The core challenge addressed is the overwhelming volume of visual tokens generated from extended videos, which makes end-to-end processing computationally infeasible given the limited context lengths of most LLM-based architectures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Submodular Optimization via Facility Location: FLoC is the first visual token compression algorithm based on the facility location function and submodular optimization for long video understanding. This interprets token selection as maximizing a utility (or coverage) function that rewards tokens for preserving the essential information and diversity of the entire visual token set within a strict budget constraint (K).\n2. Targeting Rare Information Loss: The facility location framework is specifically motivated to overcome a key limitation of clustering methods: their tendency to fail in capturing rare but important tokens (e.g., small objects like car keys) because they focus on densely populated regions in the feature space. FLoC explicitly optimizes for both representativeness and diversity simultaneously.\n3. Lazy Greedy Efficiency: The implementation utilizes the lazy greedy algorithm to efficiently approximate the optimal NP-hard solution. This approach significantly reduces computational overhead by postponing the update of marginal gains until necessary, offering a novel and practical way to handle massive token sets."}, "weaknesses": {"value": "1. The primary operational weakness of FLoC is the reliance on the empirical determination of a single hyperparameter: the block length ($T$). The paper explicitly states that the choice of T involves a critical trade-off that impacts both performance and computational efficiency. The optimal setting for the block length is acknowledged to be content-dependent; for instance, a static video (e.g., a lecture) benefits from a longer block length, while a highly dynamic video requires a shorter one.\n2.  FLoC is designed as a query-agnostic and model-agnostic solution. While this offers advantages in memory efficiency (performing compression once) and flexibility, it fundamentally limits the model's performance in real-time, query-specific tasks or dynamic interactive environments. Query-aware compression methods, which FLoC contrasts itself against, \"can effectively reduce the search space by focusing on what is deemed important\" to the user.\n3. FLoC utilizes the lazy greedy algorithm to approximate the maximization of the facility location function, which is NP-hard. While this is significantly faster than naive greedy and traditional clustering methods (e.g., 10× faster than K-Means in compression time), the complexity remains dependent on both the initial number of tokens ($n$) and the budget ($K$), scaled as $O(n⋅K)$.\n4. The facility location function relies on the cosine similarity between token embeddings ($sim(v,u)$) as its similarity measure. Cosine similarity effectively measures angular distance, focusing on the direction of feature vectors, which is suitable for abstract feature space coverage. However, it may not perfectly capture complex perceptual differences or contextual relationships that could be better represented by other distance metrics."}, "questions": {"value": "See weakness above, please."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZitFAe1RUj", "forum": "tPhcrP75OP", "replyto": "tPhcrP75OP", "signatures": ["ICLR.cc/2026/Conference/Submission15742/Reviewer_9yVb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15742/Reviewer_9yVb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977661562, "cdate": 1761977661562, "tmdate": 1762925980330, "mdate": 1762925980330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FLoC, which is a training-free, model-agnostic, and query-agnostic algorithm, for efficient visual token compression. Specfically, it aims to find the optimal token subset which maximizes the submodular objective function. To this end, it uses lazy greedy algorithm. Experimental results show that the proposed algorithm achieves good performance on Video-MME, MLVU, and LVBench."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation is solid and the paper is easy to follow.\n- The proposed algorithm achieves the good performance on various benchmarks such as Video-MME, MLVU, and LVBench."}, "weaknesses": {"value": "- The citation is mis-formatted across the entire paper. For example, in L124-125, \\citep should be used in the LaTeX.  \n- In addition to Algorithm 1, a more detailed explanation of the optimal subset search should also be provided in the main text. \n- I think the novelty of the proposed method is somewhat limited. Sampling a token subset is not a new idea, and simply applying the well-known lazy greedy algorithm for this sampling seems to offer only a modest contribution. If there are additional aspects of novelty that I might have missed, I would appreciate clarification.\n- It would also be helpful to include a comparison of experimental results with the following papers.\n[1] Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs, ICCV2025\n[2] LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs (optional)\n- It would be good to include experimental results on datasets commonly used in this field, such as Next-QA or EgoSchema.\n- typo\n\t- L193: arg   max -> argmax"}, "questions": {"value": "Please see the weakness section for my concerns. My main concern is about the novelty of the proposed method. If this concern is well addressed through the rebuttal, I would be willing to increase my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MhgLR4yrnd", "forum": "tPhcrP75OP", "replyto": "tPhcrP75OP", "signatures": ["ICLR.cc/2026/Conference/Submission15742/Reviewer_nZDL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15742/Reviewer_nZDL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992474249, "cdate": 1761992474249, "tmdate": 1762925979960, "mdate": 1762925979960, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}