{"id": "R8gHv5xgPN", "number": 7190, "cdate": 1758011060294, "mdate": 1759897867653, "content": {"title": "PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction", "abstract": "Pedestrian trajectory prediction is crucial for autonomous driving and robotics. While existing point-based and grid-based methods expose two main limitations: insufficiently modeling human motion dynamics, as they fail to balance local motion details with long-range spatiotemporal dependencies, and the time representations lack interaction with their frequency components in jointly modeling trajectory sequences. To address these challenges, we propose PatchTraj, a dynamic patch-based framework that integrates time-frequency joint modeling for trajectory prediction. Specifically, we process trajectories through parallel time and frequency branches, and employ dynamic patch partitioning for multi-scale segmentation, capturing hierarchical motion patterns. Each patch undergoes adaptive embedding with scale-aware feature extraction, followed by hierarchical feature aggregation to model both fine-grained and long-range dependencies. The outputs of the two branches are further enhanced via cross-modal attention, facilitating complementary fusion of temporal and spectral cues. The resulting enhanced embeddings exhibit strong expressive power, enabling accurate predictions even when using a vanilla Transformer architecture. Extensive experiments on ETH-UCY, SDD, NBA, and JRDB datasets demonstrate that our method achieves state-of-the-art performance. Notably, on the egocentric JRDB dataset, PatchTraj attains significant relative improvements of 26.7% in ADE and 17.4% in FDE, underscoring its substantial potential in embodied intelligence.", "tldr": "", "keywords": ["trajectory prediction", "representation learning", "dynamic patch"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6321da7817520c92fed6a1a7177e9de72b53200b.pdf", "supplementary_material": "/attachment/1c1b866640d9df812227b62694d85601d40bd9c7.zip"}, "replies": [{"content": {"summary": {"value": "PatchTraj introduces a dynamic patch-based framework for pedestrian trajectory prediction that jointly models time and frequency domains. It adaptively segments trajectories into semantically coherent spatiotemporal patches, enabling hierarchical feature learning across multiple scales. The model employs expert-inspired multi-scale embeddings, deformable patch attention for cross-scale fusion, and cross-domain attention to integrate temporal and spectral cues."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This study faithfully followed the experimental protocols of existing human trajectory prediction models. It utilized major benchmark datasets (JRDB, NBA, SDD, ETH-UCY) and adopted standard evaluation metrics (e.g., ADE, FDE), with results effectively visualized.\n\n- Compared to prior methods, it achieved state-of-the-art performance and enhanced credibility by providing the implementation code in the supplementary materials. Additionally, extensive ablation studies on model architecture, loss functions, and the number of experts demonstrated the robustness and versatility of PatchTraj."}, "weaknesses": {"value": "- While the paper compares PatchTraj with general human trajectory prediction methods, it lacks comparative experiments with conceptually or methodologically similar approaches. The authors mention TimesNet in line 145, yet no comparison is made with other models that also learn in the frequency domain (e.g., those based on FFT). Including such experiments would help validate the logical rationale for employing the Discrete Cosine Transform (DCT).\n\n- Furthermore, the study provides insufficient in-depth comparisons with existing trajectory prediction methods. Although the reported results show generally superior performance, there is no detailed analysis comparing PatchTraj against point-based or grid-based methods from the Figure 1. Such experiments could reveal in which specific scenes or scenarios PatchTraj performs better, and why these advantages arise.\n\n- The proposed approach appears somewhat naive and lacks strong technical novelty. The authors claim contributions through time–frequency hybridization, dynamic patch mechanisms, and multi-scale feature fusion, yet these techniques largely appear to be combinations of existing methods. Even if such integration is meaningful, the paper does not clearly explain 1) why these specific techniques were chosen over other similar approaches (and why others were not suitable), and 2) what modifications were made to adapt them to the human trajectory prediction domain (and what challenges arise when applying existing methods directly). Only the DPAttn module provides such clarification."}, "questions": {"value": "- The authors mention the limitations of point-based and grid-based methods in the abstract, yet no clear empirical or conceptual evidence is provided. Please include supporting experiments or scenario-specific analyses to substantiate these claims.\n\n- Are there any comparative experiments with prior point-based and grid-based approaches? Adding such comparisons would clarify the technical distinctions between PatchTraj and existing methods, thereby strengthening the paper’s contribution and justification.\n\n- In line 45, the authors refer to “periodic patterns (e.g., gait cycles).” What specific periodic patterns does this work address? Are these patterns interpretable at a human-perceptible level (like gait cycles), or are they latent patterns beyond human interpretation?\n\n- The paper employs the Discrete Cosine Transform (DCT) for time–frequency representation. What motivated this specific choice? Could other frequency transformation methods serve the same purpose, and if so, why was DCT preferred?\n\n- While DCT is used to handle frequency information, there are no visual analyses demonstrating its effect. Including qualitative visualizations in the frequency domain would help readers verify that the model effectively learns and utilizes frequency features.\n\n- The description of the MSPE module remains abstract. Please elaborate on its technical implementation, specifying how it differs from prior Mixture-of-Experts approaches and what these differences imply in the context of PatchTraj.\n\n- According to Figure 2, the Time and Frequency branches share an identical structure. Are there visualizations showing what distinct representations each branch learns during training?\n\n- In line 189, the term “contextual information” is ambiguous. Does it refer to the image scene at a given timestamp, or some other form of contextual data? Please clarify what this information specifically represents from an implementation perspective."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The dataset used in this study does not raise any ethical concerns."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fOOxLHfAj6", "forum": "R8gHv5xgPN", "replyto": "R8gHv5xgPN", "signatures": ["ICLR.cc/2026/Conference/Submission7190/Reviewer_TXzp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7190/Reviewer_TXzp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760967135482, "cdate": 1760967135482, "tmdate": 1762919345708, "mdate": 1762919345708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PatchTraj, and its core idea combines both the time domain and the frequency domain, and enhances the embedding so that the prediction can benefit from the fused knowledge. The good performance across multiple datasets validates the effectiveness of this framework. The key issue is the writing and presentation."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The model achieves state-of-the-art performance on four diverse datasets, outperforming recent baselines like NMRF (2025). It's interesting to see that both the ADE/FDE and the JADE/JFDE are reported for some dataset.\n2. A detailed ablation study systematically evaluates the contribution of each major component of their proposed architecture, and the paper discusses the effect of K and joint loss variants.\n3. The motivation to better unify local and global context and to explore the underutilized frequency domain is sound."}, "weaknesses": {"value": "1. The presentation needs a lot of improvement. \n\nE.g., in Figure 1, it's really difficult to understand the proposed Dynamic patching. What are s1, s2, and sM? What's the meaning of different rectangles?\n\nIn row 083, what is DPAttn? The author should at least show the full name of the module when using it for the first time. \n\nFigure 2 is inconsistent; it is very difficult to understand how the two proposed branches are used in the right high-level architecture. \n\nWhat is the dynamic patch in this figure? Overall, I think the author should clearly explain or define 'patch' in the very beginning. \n\n2. Overclaimed contribution. \n\nThe authors claimed their time-frequency approach enables \"noise-robust trajectory modeling\". This is an empirical claim that is never tested. The paper lacks experiments about robustness against noise. For instance, adding synthetic noise to input trajectories to demonstrate that PatchTraj is more robust than time-domain-only baselines.\n\nAlso, the contribution about  'significantly outperforms previous state-of-the-art methods on four real-world datasets' is overstated, since the improvements of minFDE on NBA/SDD/ETH-UCY are not 'significant'."}, "questions": {"value": "What is the inference speed of this model? Reporting the inference time or latency will make it more practical for applications."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7AycSRhWgq", "forum": "R8gHv5xgPN", "replyto": "R8gHv5xgPN", "signatures": ["ICLR.cc/2026/Conference/Submission7190/Reviewer_yTNa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7190/Reviewer_yTNa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761233531040, "cdate": 1761233531040, "tmdate": 1762919344717, "mdate": 1762919344717, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "PatchTraj is a trajectory-prediction framework that represents motion jointly in time and frequency and replaces fixed windows with adaptive “patches”. It splits each input into a raw time-domain sequence and a DCT-based sequence, then a network groups the sequence into variable-length patches that better match motion segments. Each patch is embedded with a Mixture-of-Experts layer. Multi-scale features are aggregated, and the time and frequency branches exchange information through cross-modal attention. Then, a Transformer encoder–decoder predicts future timesteps. The authors claim that their method keeps fine local detail while modeling long-range dependencies and reduces noise sensitivity that affects pure time-domain methods."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly written. The problem statement, motivation and solution are explained well.\n\n- The core idea is novel. The experimental setup is described clearly and organized coherently. \n\n- Hyperparameter choices and implementation details are provided in the appendix, which, together with the released code, supports reproducibility."}, "weaknesses": {"value": "- The authors claim that incorporating frequency data improves long-term dependency modeling, yet the FDE gains from adding the F-branch (Table 2) are limited compared to this claim.\n\n- The paper emphasizes noise robustness, but this is not evaluated.\n\n- More ablations would be beneficial: variants that (i) assign patch sizes randomly and (ii) restrict to a small set of reasonable patch sizes."}, "questions": {"value": "- How is the number of retained coefficients chosen, and is performance sensitive to this choice?\n\n- Does padding with the last observed position ever bias the frequency branch toward “stopped” motion?\n\n- Do different patch scales actually activate different experts in practice, or does the gate collapse to a few experts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XNbgSLRavv", "forum": "R8gHv5xgPN", "replyto": "R8gHv5xgPN", "signatures": ["ICLR.cc/2026/Conference/Submission7190/Reviewer_mnwd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7190/Reviewer_mnwd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926315399, "cdate": 1761926315399, "tmdate": 1762919344316, "mdate": 1762919344316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PatchTraj, a pedestrian trajectory forecasting framework that jointly models time and frequency domains using dynamic patching. It splits each trajectory into multi-scale patches, and fuses them after encoding. Across multiple datasets, PatchTraj shows state-of-the-art accuracy. Ablation study shows each module’s contribution."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of fusing time and frequency is well motivated and intuitive. \n2. The architecture is clearly presented and well motivated.\n3. The results across multiple datasets are strong and state of the art."}, "weaknesses": {"value": "1. The method put together several known ideas into one large system, laying out this multi-module pipeline. It’s more like a comprehensive engineering package than an innovative idea.\n2. The ablation study shows additive gains as each module is turned on. It doesn’t show which subset has better accuracy per cost tradeoff. If we add more modules, would the performance be even better? In this sense, we’d like to understand how much additional cost, e.g. inference latency, the pipeline incurs relative to the baseline. \n3. The paper claims it learns to group trajectory points into semantically meaningful patches based on motion dynamics, but the method section defines non-overlapping fixed patch sizes chosen from a set S. There is no learning involved."}, "questions": {"value": "There are many typos or grammar mistakes. To list a few:\n1. Line 062 to Line 070 is not a complete sentence.\n2. Line 081: “where learns” → “which learns”.\n3. Line 905 to Line 907: “We also conduct … our method.” are two sentences. Also “investigate” → “investigates”."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WgcnyPtbkl", "forum": "R8gHv5xgPN", "replyto": "R8gHv5xgPN", "signatures": ["ICLR.cc/2026/Conference/Submission7190/Reviewer_nDtp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7190/Reviewer_nDtp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973438383, "cdate": 1761973438383, "tmdate": 1762919343852, "mdate": 1762919343852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}