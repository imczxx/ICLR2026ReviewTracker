{"id": "fObtmKj0Ok", "number": 9135, "cdate": 1758112469592, "mdate": 1759897741517, "content": {"title": "Model Merging beyond Image Classification: A Reality Check", "abstract": "Efficiently merging several models fine-tuned for different tasks, but stemming from the same pre-trained base model, is of great practical interest. Despite extensive prior work, most evaluations of model merging in computer vision focus on image classification using CLIP, where different sets of labels define different classification tasks. This paper ventures model merging into the more challenging setup where the different tasks operate in different output spaces and thus rely on different trainable decoders. This renders exhaustive hyperparameter search impractical. To address this, we introduce the task alignment score, and show how it can be used to i) speed up hyperparameter selection by orders of magnitude and ii) generalize proxy-based hyperparameter selection to any task. We also find in our setting several recent models fail and show it is largely due to some fine-tuned models being significantly further-away from the base than others, leading to a strong unbalance. More importantly, we demonstrate that, thanks to our contributions, model merging remains effective and can improve the performance of a state-of-the-art multi-task vision model.", "tldr": "We evaluate merging on diverse 2D and 3D vision tasks and propose TAS, a score that any merging method can use for selecting merging hyperparameters at a fraction of the cost.", "keywords": ["model merging", "task arithmetic", "visual representation learning", "human mesh recovery", "mast3r", "semantic segmentation", "mapfree challenge", "depth", "adamerge", "hyperparameter selection"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/61ab7b12d7062ce96dab1ab0f229c3e3f40ad2dd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the performance of weight-space arithmetic merging in more realistic and diverse visual tasks beyond CLIP image classification. The authors extend their research from the previously common CLIP-classification benchmark to the DUNE benchmark, which includes heterogeneous tasks such as semantic segmentation, depth estimation, and 3D human mesh reconstruction and relocalization. They point out that in such scenarios, evaluating the merging model requires fine-tuning the decoders for each task after merging, making hyperparameter search-based methods very expensive. To address this issue, the authors propose a Task Alignment Score (TAS)—calculating the distance between the merged encoder and each task-specific encoder in the feature space based on unlabeled data. This serves as a proxy for the final task performance, significantly reducing the cost of hyperparameter selection. The authors use TAS to guide various merging methods and achieve state-of-the-art results in multi-task merging."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The writing is quite easy to read and it was well-written\n2. The motivation is important and pragmatic: shifting model-merging research from inexpensive and evaluable CLIP-classification scenarios to real-world multi-task vision settings that require training task-specific decoders is a natural and practically meaningful extension.\n3. The method is generalizable. The authors demonstrate how to embed TAS into different methods such as AdaMerging and AdaMMS, thereby extending proxy methods that were originally only applicable to classification/generation to any vision task."}, "weaknesses": {"value": "1. The number and diversity of benchmark tasks remain limited: Although DUNE itself includes 4 heterogeneous tasks, the conclusions are not yet fully conclusive on larger-scale tasks and on the robustness of the model.\n2. The description of the sensitivity to TAS design details is insufficient: Although the Appendix mentions robustness to distance metrics and sample size, a more granular ablation on the impact of selecting which layer would be appreciated.\n3. The time taken by the hyperparameter method in the table, which is >14 days, is an estimate based on sequential evaluation. However, in real-world deployments, multiple configurations can be evaluated in parallel, or a more intelligent search method can be used. Therefore, the assertion that it is \"infeasible\" needs further clarification."}, "questions": {"value": "1. As a plug-and-play approach, this paper compares a limited number of methods. I wonder if this approach can lead to sustained improvements when applied to some of the latest state-of-the-art methods, such as wudi-merging[1], iso-merging[2].\n2. TAS requires an unlabeled sample set Dt. Please explain whether this set of samples is part of the training set or comes from a domain different from the training distribution. How will the performance of TAS change if the sampling distribution is shifted?\n3. Methods such as wudi merging do not require excessive hyperparameter searching. So, how does the performance of wudi merging[1] compare to that of tas under the settings in this paper?\n\n[1] Whoever Started the Interference Should End It: Guiding Data-Free Model Merging via Task Vectors\n\n[2] Task Left Behind: Isotropic Model Merging with Common and Task-Specific Subspaces\n\nIf the author can solve the question and the weakness well, i will raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "msWtoiffOj", "forum": "fObtmKj0Ok", "replyto": "fObtmKj0Ok", "signatures": ["ICLR.cc/2026/Conference/Submission9135/Reviewer_K4ar"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9135/Reviewer_K4ar"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738851781, "cdate": 1761738851781, "tmdate": 1762920826302, "mdate": 1762920826302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the performance of weight-space arithmetic merging in more realistic and diverse visual tasks beyond CLIP image classification. The authors extend their research from the previously common CLIP-classification benchmark to the DUNE benchmark, which includes heterogeneous tasks such as semantic segmentation, depth estimation, and 3D human mesh reconstruction and relocalization. They point out that in such scenarios, evaluating the merging model requires fine-tuning the decoders for each task after merging, making hyperparameter search-based methods very expensive. To address this issue, the authors propose a Task Alignment Score (TAS)—calculating the distance between the merged encoder and each task-specific encoder in the feature space based on unlabeled data. This serves as a proxy for the final task performance, significantly reducing the cost of hyperparameter selection. The authors use TAS to guide various merging methods and achieve state-of-the-art results in multi-task merging."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The writing is quite easy to read and it was well-written\n2. The motivation is important and pragmatic: shifting model-merging research from inexpensive and evaluable CLIP-classification scenarios to real-world multi-task vision settings that require training task-specific decoders is a natural and practically meaningful extension.\n3. The method is generalizable. The authors demonstrate how to embed TAS into different methods such as AdaMerging and AdaMMS, thereby extending proxy methods that were originally only applicable to classification/generation to any vision task."}, "weaknesses": {"value": "1. The number and diversity of benchmark tasks remain limited: Although DUNE itself includes 4 heterogeneous tasks, the conclusions are not yet fully conclusive on larger-scale tasks and on the robustness of the model.\n2. The description of the sensitivity to TAS design details is insufficient: Although the Appendix mentions robustness to distance metrics and sample size, a more granular ablation on the impact of selecting which layer would be appreciated.\n3. The time taken by the hyperparameter method in the table, which is >14 days, is an estimate based on sequential evaluation. However, in real-world deployments, multiple configurations can be evaluated in parallel, or a more intelligent search method can be used. Therefore, the assertion that it is \"infeasible\" needs further clarification."}, "questions": {"value": "1. As a plug-and-play approach, this paper compares a limited number of methods. I wonder if this approach can lead to sustained improvements when applied to some of the latest state-of-the-art methods, such as wudi-merging[1], iso-merging[2].\n2. TAS requires an unlabeled sample set Dt. Please explain whether this set of samples is part of the training set or comes from a domain different from the training distribution. How will the performance of TAS change if the sampling distribution is shifted?\n3. Methods such as wudi merging do not require excessive hyperparameter searching. So, how does the performance of wudi merging[1] compare to that of tas under the settings in this paper?\n\n[1] Whoever Started the Interference Should End It: Guiding Data-Free Model Merging via Task Vectors\n\n[2] Task Left Behind: Isotropic Model Merging with Common and Task-Specific Subspaces\n\nIf the author can solve the question and the weakness well, i will raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "msWtoiffOj", "forum": "fObtmKj0Ok", "replyto": "fObtmKj0Ok", "signatures": ["ICLR.cc/2026/Conference/Submission9135/Reviewer_K4ar"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9135/Reviewer_K4ar"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738851781, "cdate": 1761738851781, "tmdate": 1763031375354, "mdate": 1763031375354, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies model merging that combines encoders fine-tuned on individual downstream tasks into a single model, aiming to maintain performance while reducing deployment cost. It points out that prior advances in model merging have been largely confined to CLIP-based image classification, and extends the study to encoder-sharing yet decoder-specialized vision tasks, such as segmentation, depth estimation, 3D pose relocalization, and multi-human 3D mesh recovery."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies the limitation of prior CLIP-focused evaluations of model merging and extends the assessment to heterogeneous DUNE tasks, covering both 2D and 3D tasks. This broadening of scope offers a more realistic tested for studying model merging.\n\n2. The authors introduce TAS, a label-free and inference-only proxy that measures the feature distance between the merged encoder and each task’s fine-tuned encoder. Across the 4 DUNE tasks, TAS exhibits a strong negative correlation with downstream performance, making it a useful signal for hyperparameter selection.\n\n3. Using TAS-guided selection, the workflow trains the decoders once under the chosen setting, which substantially reduces search cost on DUNE while surpassing the DUNE baseline in overall performance.\n\n4. To investigate why merging that works well for CLIP classification is more challenging on DUNE, the paper quantifies task-vector magnitudes and directions across CLIP and DUNE, focusing larger and more imbalanced changes on DUNE that help explain the increased difficulty.\n\n5. Ablations show that TAS is robust to the choice of distance metric (L1/L2/cosine produce similar curves) and that only a small number of unlabeled samples is sufficient to obtain a stable signal."}, "weaknesses": {"value": "1. All core experiments and the TAS performance correlation analysis were evaluated only on the four DUNE tasks. Because the performance comparisons are conducted only on DUNE, to the best of my reading there are no results on other multi-task backbones or downstream tasks; consequently, the claim “We show that merging can improve state-of-the-art multi-task models” reads as DUNE-specific. Evaluation across additional backbones, decoders, and datasets would be necessary to support generalization.\n\n2. To the best of my reading, while the paper claims to move beyond image classification, in the CLIP classification setting it only compares task-vector norms and distributions across downstream tasks and does not apply or evaluate TAS itself. It is true that TAS is not designed to solve CLIP classification itself; however, given the stated aim of extending beyond classification, a minimal evaluation on standard CLIP benchmarks, showing how TAS-guided hyperparameter selection performs relative to established methods, would have more convincingly supported the generality of the proposal.\n\n3. This work stands in contrast to a key advantage emphasized in model merging methods such as Model Soups, Task Arithmetic, and TIES-Merging merging, which emphasize merging in weight space without additional training. In CLIP classification, the text encoder remains fixed, and the vision encoder is merged and evaluated, which enables training-free composition. By contrast, in the present setting the approach structurally depends on decoder retraining after merging.\n\n4.  TAS is a useful label-free and inference-only proxy that reduces search cost by selecting promising hyperparameters, but it is not a merging algorithm that directly improves encoder-decoder alignment. Consequently, the work reads more as a cost reduction strategy within a merging and decoder training pipeline than as a conceptual advance in model merging itself. Framed this way, the extension beyond image classification lies primarily at the level of evaluation and practical tuning, which limits the scope of the claimed extension."}, "questions": {"value": "1. Could you report additional experiments on at least one other multi-task backbone/decoder/dataset to test whether TAS performance correlation and TAS guided gains replicate beyond DUNE?\n \n2. Although CLIP-based image classification tasks are not the primary focus, could you provide a minimal, compute-normalized evaluation on CLIP benchmarks to enable a precise comparison between TAS guided hyperparameter selection and existing model merging methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YbYOPh5l7Q", "forum": "fObtmKj0Ok", "replyto": "fObtmKj0Ok", "signatures": ["ICLR.cc/2026/Conference/Submission9135/Reviewer_CpmB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9135/Reviewer_CpmB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912901317, "cdate": 1761912901317, "tmdate": 1762920825885, "mdate": 1762920825885, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the problem of merging vision models fine-tuned on heterogeneous tasks, extending beyond the typical CLIP-based image classification scenario currently dominating the model merging literature. Through empirical studies on the DUNE benchmark across four diverse tasks, the authors identify computational bottlenecks in prior methods due to the need for retraining task-specific decoders after merging. To address this, the paper introduces the Task Alignment Score (TAS), a feature-based proxy for guiding hyperparameter selection efficiently in general multitask merging scenarios. The results show that TAS closely aligns with actual performance, making merging methods practical for more diverse task settings. Extensive experimental analysis highlights strengths and failure modes of various merging algorithms, with particular attention to task vector norm imbalance as a core challenge in multitask merging."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a clear gap by moving the conversation around model merging away from CLIP-style image classification toward true multitask settings with diverse output structures. This reveals both practical relevance and non-trivial technical issues that prior work sidestepped.\n2. The introduction of TAS is a significant methodological addition, addressing the key bottleneck of hyperparameter search in costly non-classification scenarios. As demonstrated in Figure 3 and Figure 4, TAS shows a strong correlation with performance, especially in the presence of retrained, trainable decoders.\n3. Through clear analysis of task vector norm imbalance, the paper challenges assumptions made by previous merging methods and provides evidenced explanations for why some sophisticated methods fail against basic weight averaging."}, "weaknesses": {"value": "1. Despite arguing for generalization, experiments are restricted to DUNE’s four tasks. There is no sufficient evidence presented that TAS or the observed failures/successes generalize beyond this curated set.\n2. A notable limitation is the absence of experiments on large-scale models. The scalability and effectiveness for contemporary foundation models, particularly LLMs and VLMs, have not been investigated."}, "questions": {"value": "1. Are there regimes (task types, model types) where TAS would fail as a proxy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Mfex6hoT9z", "forum": "fObtmKj0Ok", "replyto": "fObtmKj0Ok", "signatures": ["ICLR.cc/2026/Conference/Submission9135/Reviewer_ue9Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9135/Reviewer_ue9Q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957810436, "cdate": 1761957810436, "tmdate": 1762920824923, "mdate": 1762920824923, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies arithmetic model merging for computer vision beyond the usual CLIP-based classification setting. Using DUNE as a base encoder, the authors fine-tune four task-specific encoders and then merge only the encoders and re-train task-specific decoders for evaluation. They introduce a task-agnostic Task Alignment Score, which is the feature-space distance between a merged encoder and each task’s fine-tuned encoder. It is used as a cheap proxy to select merging hyperparameters or as a loss for learning-based merging. TAS correlates with downstream performance and enables efficient selection, making costly hyperparameter searching unnecessary. Empirically, several closed-form and proxy-based methods perform competitively, and experimental results show that AdaMerging+TAS improves over the base multi-task DUNE."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The setting in this paper more closely matches practical multi-task settings. In the manuscript, the authors Identified why exhaustive sweeps are infeasible in this regime.\n2. TAS shows effectiveness and efficiency with empirical support. The design is label-free, task-agnostic and easy to follow. Merging cost results in Tab, 1 show that the method improves cost-effectiveness. The authors generalize AdaMerging with TAS and enable task-agnostic optimization of $\\lambda$ .\n3. Task-vector imbalance reveals some insights. The measurement shows norms are highly unbalanced across tasks, biasing average vectors. This work compares NormAvg and MetaGPT, then dissects how weighting by norms amplifies biases."}, "weaknesses": {"value": "1. Limited breadth of tasks and datasets. Only four tasks from DUNE bench are studied and this limits external validity. Evidence of robustness is also mostly on the chosen benchmark. Providing cross-architecture evidence beyond the adopted size of ViT maybe more convinced.\n2. The paper defines the merging goal. However, the evaluation protocol states that task-specific decoders are fine-tuned after the encoder is merged and frozen. This implies that $\\mathcal{L}_t(\\theta)$ is not a simple loss, but rather a nested optimization problem for the final expected performance. This is not made explicit, making the formal objective ambiguous to some extent."}, "questions": {"value": "1. For merging cost calculation of hyperparameter methods, please provide more details.\n2. which features of the adopted model are taken into account in $f(x;\\theta)$ and being compared?\n3. Other related questions please refer to the Weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rWY9kWeaOq", "forum": "fObtmKj0Ok", "replyto": "fObtmKj0Ok", "signatures": ["ICLR.cc/2026/Conference/Submission9135/Reviewer_6Kqn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9135/Reviewer_6Kqn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989074262, "cdate": 1761989074262, "tmdate": 1762920824248, "mdate": 1762920824248, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Most model-merging work has focused on simple CLIP-based classification setups. This paper evaluates merging in more challenging vision settings where each task has its own task-specific decoder. The authors introduce a Task Alignment Score (TAS) to accelerate hyperparameter search and to generalize proxy-based tuning methods. They also argue that disparities in task-vector norms explain why some “advanced” merging techniques underperform simpler baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) Broader evaluation scope. Moving beyond CLIP-only classification to the DUNE setting makes the evaluation more realistic and practically relevant. Unsurprisingly, several prior approaches appear overfit to the CLIP regime.\n\n(2) Insightful analysis. The study surfaces how task-vector norms and scaling coefficients affect merged-model performances and favour models with higher norm. This insight could help develop better merging and fine-tuning strategies for merging."}, "weaknesses": {"value": "(1) Limited task diversity. While the DUNE setting is much more challenging than the CLIP Setting, the evaluation includes just four tasks and relies solely on this single setting for both evaluation and analysis, making generalisation uncertain. It would strengthen the paper to also include prior CLIP-style suites (e.g., up to 20 tasks).\n\n(2) The idea of reducing the difference in feature representation between the merged model and the finetuned models represents the typical distillation objective and is not very novel.\n\n(3) Attribution of norm effects. The work states that differences in the task-vector norm favour tasks with a higher norm, such as Bedlam, it is important to check if this is strictly due to the differences in norm or due to the nature of the task. To test this, one could regularise models to have a similar norm during training and check if such models merge in a more balanced manner. \n\n(4) Modal coverage. Extending experiments to NLP—where model merging is widely used—would substantially increase the work’s relevance."}, "questions": {"value": "(1) Feature definition in Eq. (2). Are the “features” the model’s output probabilities/logits or intermediate representations?\n\n(2) Decoder retraining during tuning.  It is unclear why the decoders need to be trained for each hyperparameter selection during hyperparameter tuning, which leads to a significant increase in compute cost. It is typical to leave the layers not involved in merging as frozen during hyperparameter tuning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VFzfNxAprO", "forum": "fObtmKj0Ok", "replyto": "fObtmKj0Ok", "signatures": ["ICLR.cc/2026/Conference/Submission9135/Reviewer_PciQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9135/Reviewer_PciQ"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission9135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998146676, "cdate": 1761998146676, "tmdate": 1762920823882, "mdate": 1762920823882, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}