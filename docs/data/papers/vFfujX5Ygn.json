{"id": "vFfujX5Ygn", "number": 3121, "cdate": 1757338183136, "mdate": 1763631425471, "content": {"title": "Revisiting Nonstationary Kernel Design for Multi-Output Gaussian Processes", "abstract": "Multi-output Gaussian processes (MOGPs) provide a Bayesian framework for modeling non-linear functions with multiple outputs, in which nonstationary kernels are essential for capturing input-dependent variations in observations. However, from a spectral (dual) perspective, existing nonstationary kernels inherit the inflexibility and over-parameterization of their spectral densities due to the restrictive spectral–kernel duality. To overcome this, we establish a generalized spectral–kernel duality that enables fully flexible matrix-valued spectral densities — albeit at the cost of quadratic parameter growth in the number of outputs. To achieve linear scaling while retaining sufficient expressiveness, we propose the multi-output low-rank nonstationary (MO-LRN) kernel: by modeling the spectral density through a low-rank matrix whose rows are independently parameterized by bivariate Gaussian mixtures. Experiments on synthetic and real-world datasets demonstrate that MO-LRN consistently outperforms existing MOGP kernels in regression, missing-data interpolation, and imputation tasks.", "tldr": "", "keywords": ["Nonstationary kernel", "Multi-ouput Gaussian Process", "Bayesian non-parametric"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c76148d09e63adda6a1e80beb8a9df16152550a4.pdf", "supplementary_material": "/attachment/13ce4fb107c5036ea63194f66dcc7c057c6f2d71.zip"}, "replies": [{"content": {"summary": {"value": "I applaud the authors for revisiting multi-task GPs through non-stationary kernels. I fully agree with the paper's motivation. The manuscript is well written and a delightful, helpful read. My comments and questions mainly seek clarification."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper proposes a new, very flexible kernel for multi-task GPs, which is an important area of research\n- The manuscript is well-written and comprehensible without too much effort.\n- Sound theory.\n- A reasonable number of test cases.\n- A good choice of competitor methods."}, "weaknesses": {"value": "- Some extra implementation details would be good. I found it hard to reproduce the kernel from Definition 1. For instance, one could describe typical bounds for the hyperparameter."}, "questions": {"value": "- Are there restrictions or bounds on the m_ij, z_ij, S_ij^(q), and other hyperparameters? \n- What is the reasoning behind the choice of competitor methods?  \n- Why is there no comparison to a baseline coregionalization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5KBtXZHPuE", "forum": "vFfujX5Ygn", "replyto": "vFfujX5Ygn", "signatures": ["ICLR.cc/2026/Conference/Submission3121/Reviewer_ZUMe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3121/Reviewer_ZUMe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3121/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761590256379, "cdate": 1761590256379, "tmdate": 1762916560162, "mdate": 1762916560162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a multi-output version of the next-gen SM kernel from Yang (2025)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The proposed kernel gives an elegant solution to the problem.\n* The method has good results."}, "weaknesses": {"value": "* The appendix contains the hyperparameter values, but only for MO-LRN, not for the other kernels.\n  * The appendix also specifies how the kernel was optimized for MO-LRN (500 iterations of Adam), but not for the other kernels. Is the same procedure used for all kernels?\n  * It is not clear how the hyperparameters like learning rate were chosen.\n* The source code is not released (yet)"}, "questions": {"value": "* Table 2: \"$I$ denotes the index in the LMC summation over latent processes, with $I < V$.\"\n   Should this be $I \\le V$?\n * Table 2: what does \"Expressive kernel\" mean?\n * Eq (1) is missing parentheses around the 4 terms in the integral.\n * \"When ω_1 = ω_2, this theorem reduces to Bochner’s theorem.\"\n    ω are not parameters of the theorem, so this statement makes no sense. Do you mean to say that the theorem reduces to Bochner's theorem when u(ω_1,ω_2)=δ(ω_1-ω_2)u(ω), so when u is non-zero only when ω_1 = ω_2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sAmvjw02UZ", "forum": "vFfujX5Ygn", "replyto": "vFfujX5Ygn", "signatures": ["ICLR.cc/2026/Conference/Submission3121/Reviewer_Ls9o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3121/Reviewer_Ls9o"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3121/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761846576010, "cdate": 1761846576010, "tmdate": 1762916559654, "mdate": 1762916559654, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript presents a novel formulation of a multi-output non-stationary spectral kernel. A low rank approximation is adopted in order to maintain a manageable number of trainable parameters. The model is benchmarked against synthetic and real world data, and shown to be competitive for point prediction tasks. The approach also demonstrates favourable computational efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The manuscript is well written and clearly presented\n\nThe approach is a novel solution to tackling a challenging problem in the literature.\n\nThe experimental results are clearly presented along with a suitably broad selection of benchmarks and a good set of baselines."}, "weaknesses": {"value": "My primary concern with this work is the absence of quantitative probabilistic performance metrics. The metrics shown, such as MAE and RMSE, test only the quality of the point predictions of the model. But here we are working with probabilistic models, so without metrics such as NLPD to verify the uncertainty calibration, it is difficult to recommend acceptance. This concern would hold for any probabilistic model, but is particularly acute here where we have many degrees of freedom (due to non-stationarity and multi-output), as it becomes more challenging to regulate the full posterior.\n\nIt is unclear what we are sacrificing when moving to the low rank setting. \n\nScalability remains a significant concern that is only briefly discussed in the Appendix. For multi-output datasets that are long enough to reveal detectable non-stationary features, we quickly hit the upper limits of Figure 4, where the computational cost becomes prohibitive."}, "questions": {"value": "Under what conditions should we expect this formalism to fail? It might be helpful to construct a somewhat adversarial synthetic example where we know the model cannot reproduce the cross-covariances, and see how it performs. \n\nAs pointed out in 4.1, spectral kernels tend to be highly sensitive to the initialisation strategy, but it was not clear to me what initialisation is used for MO-LRN? And how should practitioners decide on a suitable configuration such as Q for a given dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tuMAtyppJl", "forum": "vFfujX5Ygn", "replyto": "vFfujX5Ygn", "signatures": ["ICLR.cc/2026/Conference/Submission3121/Reviewer_kt5w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3121/Reviewer_kt5w"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3121/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991762432, "cdate": 1761991762432, "tmdate": 1762916559445, "mdate": 1762916559445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the Multi-Output Low-Rank Nonstationary  kernel for multi-output Gaussian processes. By introducing a generalized spectral–kernel duality and modeling the matrix-valued spectral density via a low-rank Gaussian mixture, MO-LRN achieves linear scalability and superior expressiveness, outperforming existing MOGP kernels on regression and imputation benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s strengths lie in its clear theoretical and practical contributions.\n\n1 It establishes a new spectral–kernel duality that removes conventional restrictions and enables fully flexible matrix-valued spectral densities for multi-output Gaussian processes.\n\n2 This paper introduces the MO-LRN kernel, a parameter-efficient yet expressive nonstationary kernel that reduces parameter growth from quadratic to linear through a low-rank spectral density with independent Gaussian-mixture factors. I really like this idea.\n\n3 Extensive experiments validate  its effectiveness and scalability in modeling complex multi-output, nonstationary processes."}, "weaknesses": {"value": "I really enjoy reading this paper but I am not an expert in GP. From a general perspective, I cannot find obvious flaw in this paper. I will read other reviewers' comments along with authors' feedback and ajust my score."}, "questions": {"value": "I do not have quetions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5Xs6qHs7x9", "forum": "vFfujX5Ygn", "replyto": "vFfujX5Ygn", "signatures": ["ICLR.cc/2026/Conference/Submission3121/Reviewer_5TkQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3121/Reviewer_5TkQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3121/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762093547925, "cdate": 1762093547925, "tmdate": 1762916559278, "mdate": 1762916559278, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Dear Reviewers,\n\nWe are submitting the revised version of our manuscript and have addressed all reviewer comments. For ease of review, all modifications within the manuscript have been highlighted in blue.\n\nSincerely,\n\nAuthors of Paper 3121"}}, "id": "RrdYP65mqv", "forum": "vFfujX5Ygn", "replyto": "vFfujX5Ygn", "signatures": ["ICLR.cc/2026/Conference/Submission3121/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3121/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission3121/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763632378247, "cdate": 1763632378247, "tmdate": 1763632493355, "mdate": 1763632493355, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}