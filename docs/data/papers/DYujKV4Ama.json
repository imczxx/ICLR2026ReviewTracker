{"id": "DYujKV4Ama", "number": 10649, "cdate": 1758178475927, "mdate": 1763729513281, "content": {"title": "Your Discriminative Model is Secretly a Generative Model", "abstract": "Although discriminative and generative models are fundamentally equivalent in understanding data distributions, bridging these paradigms -- especially transforming off-the-shelf discriminative models into generative ones -- remains challenging. In this paper, we introduce a universal framework that unlocks the generative potential of any discriminative model by directly leveraging the data manifold encoded in its parameter space. Drawing inspiration from the score function used in diffusion models, which measures the distance between a sample and the data manifold in probability space, we generalize this concept to the functional domain. \nTo achieve this, we introduce the Discriminative Score Function (DSF), which quantifies the functional distance between a sample and the data manifold by mapping both into a shared functional space using the Loss Tangent Kernel (LTK), a variant of the Neural Tangent Kernel.\nOur framework is architecture- and algorithm-agnostic, as evidenced by various architectures such as ViT, ResNet, and DETR on tasks including object detection, classification, and self-supervised learning (\\eg, CLIP and DINO). Additionally, our approach extends to applications in image editing, inpainting, and explainable AI (XAI).Finally, we demonstrate the promising potential of DSF by adopting diffusion model techniques for enhanced generation quality.", "tldr": "We show Discriminative models can serve as Generative model.", "keywords": ["Neural Tangent Kernel", "Generative model"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ef36fe41b6439fc9eda18e2ad945cc390b84e266.pdf", "supplementary_material": "/attachment/5832160d0c3388319ab5bed7f92816667e570460.pdf"}, "replies": [{"content": {"summary": {"value": "This paper introduces the Discriminative Score Function (DSF), a principled framework that enables any off-the-shelf discriminative model (e.g., ResNet, ViT, DETR, DINO, CLIP) to perform generative tasks without architectural changes or retraining.\nBy leveraging the Loss Tangent Kernel (LTK)—a variant of the Neural Tangent Kernel that incorporates loss gradients—the authors reinterpret the functional space of a trained discriminative model as an implicit representation of the data manifold.\nThey show that gradient-based updates in this functional space can mimic the behavior of score-based diffusion models, effectively turning discriminative models into generators.\nThe approach supports unconditional and conditional image generation, editing, inpainting, and even explainable AI (XAI) visualization. Experiments demonstrate impressive qualitative results across multiple architectures and datasets (ImageNet, COCO, LVD-124M)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- Novel conceptual framework bridging discriminative and generative paradigms through kernelized functional mapping.\n- Architecture-agnostic and requires no retraining or modification, an elegant practical feature.\n- Demonstrates broad applicability (classification, detection, self-supervision).\n- Qualitative results (Figs. 3–8) are surprisingly strong for a method derived from non-generative networks.\n- Provides interpretability and XAI potential, revealing biases and feature entanglements in pretrained models.\n- Theoretical formulation draws an interesting connection to score matching and diffusion modeling."}, "weaknesses": {"value": "- Lack of quantitative evaluation: No FID, IS, or precision/recall metrics, making it difficult to assess generation fidelity.\n- Limited theoretical rigor: The equivalence between DSF and diffusion score functions is stated rather than proved; convergence properties are untested.\n- Experimental depth: All results are qualitative; the method’s computational cost, convergence behavior, and sensitivity to hyperparameters are unexplored.\n- Clarity: Mathematical notations are nonstandard, and derivations in Sec. 4 are hard to follow.\n- Ablation studies (e.g., with vs. without LTK, or different surrogate losses) are missing, which limits interpretability of where the generative capability arises.\n- Comparisons with other classifier-based generation approaches (DeepInversion, Energy-Based Models) are mostly descriptive, not empirical."}, "questions": {"value": "1. Can you provide quantitative metrics (e.g., FID, IS, or perceptual distance) to substantiate DSF’s generation quality?\n2. How stable is the iterative generation process with respect to step size (ϖₜ) and initial noise distribution?\n3. Does DSF generalize beyond vision tasks—e.g., to language models or reinforcement learning—as suggested in Sec. 7?\n4. How sensitive is DSF to the choice of surrogate loss (augmentation invariance)? Would other unsupervised losses (e.g., contrastive) yield similar results?\n5. Can you clarify the computational complexity compared to a standard diffusion sampling process?\n6. Is DSF guaranteed to converge to the data manifold, or can it produce divergent artifacts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "im77IKtzqm", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Reviewer_SzrC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Reviewer_SzrC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801412694, "cdate": 1761801412694, "tmdate": 1762921903403, "mdate": 1762921903403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The authors propose a new general method for turning discriminative models into generative models. The method uses their discriminative score function (DSF), a novel distance which leverages loss tangent kernels to quantify the distance between a sample and the empirical data manifold. From DSF, samples can be generated through a diffusion-like process (by using DSF as a score function). In addition, the authors show that by modifying the loss function used in the kernel, their methods allows for unconditional generation as well.\n- Experimentally, the authors show their method works on large commonly used discriminative models including DINOv2 and LVD-124M on various datasets, for both unconditional and conditional generation. While the generated images are full of artifacts, the underlying objects are identifiable.\n- Finally, the authors show that the use of diffusion techniques improve generation quality substantially and that their method allows for increased interpretability of these discriminative models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The method is novel and has advantages over existing methods (particularly with respect to unconditional generation)\n- The paper shows experiments on multiple large-scale commonly used models, demonstrating the method's ability to scale\n- The results are interesting, the qualitative difference between the models, particularly between the SSL methods and image classification/ImageNet ones, is notable\n- The ability to use techniques from diffusion models (and their apparent efficacy) offers an interesting direction for future work"}, "weaknesses": {"value": "- Several parts of the paper were unclear to me, I had many\n- The experimental evidence could be more convincing. There are no quantitative evaluations, just a fe generated images for each experiment.\n- The paper would benefit from further comparisons to existing work.\n- The method relies on using a loss function in the LTK that could be justified further\n   - \"We select augmentation invariance loss as it naturally decreases during training, mirroring label dependent loss behavior\" isn't fully convincing.\n   - Have additional ablations been run on different choice of loss functions?\n\n\n\n### Writing\n- The writing in the paper needs to be substantially improved. There are many unsubstantiated/unclear statements, especially in the introduction\n\t- \"Discriminative and generative models are theoretically equvalent as they both aim to understand the true data distribution.\" What does this mean?\n\t- \"They learn data distributions implicitly, causing their distributional knowledge to become entangled with training objectives.\" This is unclear.\n\t- \"on generation that incorporates these training objectives.\" Should be elaborated further\n- There are also many typos (e.g. even in the first sentence \"equvalent\"),  weird capitalization, poor grammar and informal language (e.g. \"its shape is very curvy\", \"turns the impossible to possible\", \"The answer to the question turned out to be ‘yes’.\").\n- The paper could motivate earlier the value of this line of research (e.g. what's done in \"Position of our paper\")."}, "questions": {"value": "- How computationally expensive is the generation procedure?\n- Are the displayed images cherry-picked or randomly selected from the generated images.\n- Have you tested on any robust classification methods? Would this perhaps reduce some of the visual artifacts?\n- Could you explain further the last part of the derivation of Eq.7-10. It seems the removal of the summation is crucial for the scaling of this method.\n- For conditional generation, is there a reason the discriminative model is not used to guide generation?\n- The global explanation part seems interesting. Do you have more thorough evidence (e.g. multiple images of the clocks)?\n- Do you have any quantitative metrics for evaluating the resulting generative models?\n- (Lee et al., 2024) seems to get similar qualitative results. How different is their method and how fundamental is its limitation that it can only do conditional generation?\n- If you just used the original loss in the LTK, would this be equivalent to any existing methods?\n\nUltimately, I am on the fence for this paper. I believe the idea and results are interesting but the paper and especially the writing need significant work. I am willing to increase my score if my questions (particularly the last two) are answered and the authors demonstrate the writing has been noticeably improved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HHOCiiYyEd", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Reviewer_tjrt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Reviewer_tjrt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877074899, "cdate": 1761877074899, "tmdate": 1762921902949, "mdate": 1762921902949, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "[C1] Explainability & Bias Detection"}, "comment": {"value": "**Question:** How can DSF substantiate its claims about explainability and interpretability in real-world scenarios, such as detecting dataset/model biases?\n\n\nWe substantiate our claims by demonstrating how DSF visualizes the \"inductive biases\" and \"data priors\" inherent in the model's training objective through two complementary mechanisms:\n\n**1. Visualizing Inductive Biases via Generated Artifacts:**\n\nBy observing the generated samples (Fig. 3), we can infer how the model processes data:\n- **Object-Centric Bias:** Images generated from DETR (Object Detection) and ResNet (Classification) exhibit a strong bias towards centered, single objects with consistent scales, reflecting the nature of their training objectives.\n- **Scale Invariance:** In contrast, samples from DINO (Self-Supervised Learning) show diverse scales and cluttered scenes, revealing that the self-supervised objective learns a more global, scale-invariant representation.\n\n**2. Quantitative Analysis of Dataset Bias:**\n\nBy analyzing just 400 uncurated generated images, we can gain substantial intuition about the underlying data distribution. Examining the population of generated samples reveals inherent biases in the training data:\n- **Animal Distribution:** Cats and dogs appear most frequently, while rare species are significantly underrepresented.\n- **Architecture Distribution:** Christian architecture (churches) dominates, followed by parks and similar structures.\n\nSince DINOv2's training dataset (LVD-142M) is primarily constructed by retrieval from ImageNet-22k and Google Landmarks [1], these patterns directly inherit the compositional biases of these source datasets—ImageNet-22k's heavy concentration of common domestic animals over rare species, and Google Landmarks' predominance of churches as the most frequent category, followed by parks and museums [2]. This observation suggests that the model's learned representations faithfully reflect—and potentially amplify—the categorical imbalances present in the curated seed datasets, particularly favoring common Western-centric visual concepts over underrepresented categories.\n\n[1] Oquab et al., \"DINOv2: Learning Robust Visual Features without Supervision,\" TMLR 2024.  \n[2] Weyand et al., \"Google Landmarks Dataset v2,\" CVPR 2020."}}, "id": "MbQjL0LDD5", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763728420869, "cdate": 1763728420869, "tmdate": 1763729537272, "mdate": 1763729537272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the generative potential of discriminative models by investigating how to convert them into generative models. Inspired by the use of score functions in diffusion models to measure the distance between samples and the data manifold, they propose a criterion for estimating this distance within the functional space of discriminative models. Based on this criterion, they develop a corresponding iterative generation process, demonstrating theoretical innovation. Experimental results confirm the proposed model's capabilities in both unconditional and conditional generation, and showcase its applications in image inpainting and editing. However, the experimental outcomes are not particularly outstanding."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper presents a novel method for converting discriminative models into generative models. The approach is architecture- and algorithm-agnostic, it is simple to implement and requires no modifications or additional training. Its versatility, demonstrated across multiple practical applications, offers valuable guidance for future research."}, "weaknesses": {"value": "It fails to provide a complexity analysis of the proposed method.\nThe experimental results lack quantitative metrics and sufficient comparative analysis against existing baselines.\nThe evaluation of the method's effectiveness across various applications is inconclusive.\nThe writing also suffers from formatting issues."}, "questions": {"value": "1. How is the generalization from the training to the test distribution, as stated in relation to Eq. (3), ensured? Furthermore, is the method limited by the i.i.d. assumption and thus inapplicable under domain shift?\n2. Regarding Eq. (11), it would be more appropriate to swap the positions of x_t and A(x_t). Have you considered making this change?\n3. Regarding Eq. (12): calculation based on the gradient for all model parameters appears computationally intensive. Could you clarify if the gradient with respect to x propagates through the entire network f(x_t;θ)?\n4. What is the required number of timesteps t for the generation process? what's the effect of t on the final performance?\n5. How does the choice of initial noise x0 affect output diversity? Can similar or close noise vectors generate distinct images?\n6. The manuscript lacks quantitative evaluation of the proposed method.\n7. The presented applications (e.g., inpainting, editing) fail to demonstrate a clear advantage over existing methods or articulate the method's practical value.\n8. Formatting issues are present (e.g., Line 432)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZE4T9tYB8d", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Reviewer_EMNs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Reviewer_EMNs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762093028887, "cdate": 1762093028887, "tmdate": 1762921902462, "mdate": 1762921902462, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "[C2] Initial Noise Sensitivity"}, "comment": {"value": "**Question:** How does the choice of initial noise $x_0$ affect output diversity? Is the generation process stable with respect to the initial noise distribution?\n\n\nThe specific choice of initial noise has **negligible impact** on convergence because DSF is a gradient-based optimization process that operates on a well-defined distance metric.\n\n**Why Initial Noise Choice is Irrelevant:**\n\nFrom Eq. (12), our generation process follows:\n$$x_{t+1} = x_t - \\eta_t \\nabla_x d(\\nabla_\\theta f(x_t; \\theta)\\lambda, -\\theta)$$\n\nThis is a standard gradient descent process where:\n1. **Any starting point provides valid gradients**: Whether $x_0$ is Gaussian noise, uniform noise, or any other distribution, we can compute $\\nabla_x d(\\cdot)$ to obtain the descent direction toward the manifold.\n2. **The manifold is the attractor**: The optimization objective (minimizing distance to the trained model in functional space) naturally pulls any initial point toward the data manifold, regardless of where we start.\n3. **Local properties don't matter globally**: While different initializations start at different distances from the manifold, the gradient descent process ensures convergence to the manifold as long as the distance metric is well-behaved (which it is, as the LTK-based distance is continuous).\n\n**Source of Diversity:**\n\nThe diversity in generated outputs comes not from initial noise, but from the **stochastic augmentation operator** $\\mathcal{A}(x_t)$ in Eq. (11). During each optimization step, random augmentations (flips, crops, color jitter) are applied, and this stochasticity introduces variation in the trajectory. Even with identical initial noise, different random seeds for augmentations will produce different final outputs.\n\n**Empirical Evidence:**\n\n- **Starting from meaningful images** (Figure 5): When initialized with real images, the optimization preserves overall semantics while adjusting details, demonstrating that the process respects the initialization when it's already near the manifold.\n- **Starting from pure noise**: Different random seeds lead to diverse outputs without mode collapse, confirming that the manifold contains rich structure that can be explored from various starting points.\n\nIn summary, initial noise simply determines the starting distance from the manifold, but the gradient-based optimization and augmentation stochasticity determine the final output, making the method robust to initialization."}}, "id": "JW9SxjPV3c", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763728462948, "cdate": 1763728462948, "tmdate": 1763728495017, "mdate": 1763728495017, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper proposes a way to **project any noisy input (potentially any input)** onto the **learned manifold of any discriminative model**.\n- The core idea is to obtain a **score-function-like quantity**, called the **Discriminative Score Function (DSF)**, from a discriminative model. This DSF can then be used as a score function to sample the closest image on the manifold—i.e., refine noise until it lies on the manifold.\n- The DSF is defined based on the **Loss Tangent Kernel**, where the “distance to the manifold” is computed as a sum over all training data points in the form\n    \n    $\\sum_i \\text{kernel(current, data}_i)$\n    \n    - The projection is performed by minimizing this distance metric.\n    - A beautiful contribution of this paper is how it simplifies this **non-parametric distance** (slow to evaluate) into a **parametric form** (fast to compute).\n    - A major advantage of this definition is that it’s **purely derived from the model itself**, requiring fewer external regularizations (such as blurring or frequency constraints).\n    - In practice, however, some augmentations (at least horizontal flipping) are still used during optimization.\n- The applications are similar to **DeepDream-like feature visualizations**, but this method appears to work **unconditionally**, whereas previous methods required label information.\n- The results are **comparable to DeepDream-style methods**—perhaps not strikingly so to an untrained eye—but the approach comes with **nice theoretical justification**.\n- However, direct quantitative comparisons to prior methods are lacking."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "*(Note: my background is neither in NTK nor feature visualization; I read this paper from an outsider’s point of view.)*\n\n- I like how the paper connects **NTK (specifically the Loss Tangent Kernel)** to feature visualization. Although some doubts remain (see Weaknesses), this connection feels **fundamental** and well-motivated within the rich NTK literature. Feature visualization has long relied on external regularizations to work; since NTK is an intrinsic property of the network, it provides a **plausible and principled justification** for defining such a distance metric.\n- From a quick literature check, I tend to agree with the paper’s claim that this is the **first method demonstrating unconditional projection/generation**, which is a nontrivial achievement.\n- The unconditional generation quality is **reasonable**, given that it’s a gradient-based visualization method with minimal generative priors.\n- By casting the projection operation as a **score function**—hence the name *DSF*—the method conceptually aligns with **diffusion and flow models**, potentially enabling future extensions.\n    - This connection is **ingenious**, allowing seamless integration with **conditional generation** (Sec. 5.2), including **CLIP-guided results**. These outputs, while not state of the art, look impressive.\n    - Section 6.4 introduces sampling tricks that seem promising, though still underexplored.\n- Overall, I genuinely **learned something new** from this paper—specifically, how NTK can be used as a distance measure to project arbitrary points onto a learned manifold."}, "weaknesses": {"value": "- Since optimization appears to start from $\\mathcal{N}(0, I)$, it’s unclear whether the proposed distance metric is **well-defined everywhere** consider that most discriminative models never train on noisy inputs and may behave in an arbitrary manner under such inputs. The paper doesn’t discuss this, and I think it deserves attention.\n- Currently, an augmentation (at least flipping) is required to obtain the objective function (Eq 11). To make this method truly universal, we should also the case where the model isn’t trained with any augmentation. How can one justify using such augmentation in the objective function?\n- The paper claims relevance to **explainable AI**, but the evidence provided is weak. While the visualizations are interesting, the claim isn’t substantiated in real-world scenarios. For example, one could test whether DSF helps uncover known dataset or model biases, and quantitatively measure how well it reveals them.\n- From an untrained eye, the visual improvement over **DeepDream-style** results isn’t very clear. The comparison in Appendix Fig. 11 doesn’t use the same model/dataset across methods, making cross-method evaluation impossible.\n- The visualization quality is still **inferior to methods using generative priors**—though this might not be a real drawback, as DSF deliberately avoids such priors and thus remains “truer” to the discriminative model.\n- The paper fails to convey **intuition behind the DSF metric**—what does “close” or “far” mean under this metric? What kind of image changes correspond to those distances? A section probing the **properties of the DSF metric** would be helpful.\n    - For instance, how does changing the initial noise condition affect the final output? Does colored (biased) noise lead to colored outputs?\n    - How diverse are the outputs DSF can produce? Some **qualitative or t-SNE-like visualizations** would be helpful to show coverage and variability.\n- Overall, the paper makes a **solid and original contribution**, but falls short in **discussion and interpretability**.\n\n### **Minor Suggestions**\n\n- Line 34: “*as we cannot claim to understand what we cannot create*.” — This isn’t a factual statement. Consider changing the tone or adding quotation marks.\n- Include an **algorithm block** summarizing the full projection process to make replication easier.\n- Clearly list **which augmentations** are used (is it only flipping?)."}, "questions": {"value": "- Is the distance metric introduced by the paper well-defined everywhere, especially when optimization starts from a random initialization (e.g., $\\mathcal{N}(0, I)$)?\n- How can the paper substantiate its claims about explainability or interpretability in real-world scenarios (e.g., detecting dataset/model biases) better?\n- Can the paper include visualization comparisons on the same model/dataset for easy comparison against other methods?\n- What is the intuition behind the DSF metric?\n    - What does it mean for two points to be “close” or “far” under this metric?\n    - What kind of mental picture should readers have when trying to understand DSF geometrically or perceptually?\n    - How does changing the initial noise condition affect the final projected output?\n- How diverse or mode-covering are the outputs that DSF can produce?\n- What role do augmentations perform during optimization?\n    - Is there a way to generalize this method to models that are not trained with augmentations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lBMx2whQC5", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Reviewer_YWkD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Reviewer_YWkD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118590895, "cdate": 1762118590895, "tmdate": 1762921901830, "mdate": 1762921901830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "[C3] Quantitative Evaluation"}, "comment": {"value": "**Why Direct Comparison is Impossible:**\n\nTo demonstrate this infeasibility empirically, we evaluated existing discriminative inversion methods using Q-align [1], a unified image quality assessment metric. As shown in Table A1:\n\n- **Discriminative Inversion Methods:** Existing methods (MTT: 0.00097, Energy-Based: 0.00376, Robust Classifier: 0.02398) produce outputs with near-zero quality scores, indicating they generate noise-like artifacts rather than recognizable images at high resolution ($256 \\times 256$).\n\n- **DSF (Ours):** Achieves a quality score of 0.0678, demonstrating that it successfully generates **recognizable, semantically meaningful images** from discriminative models—something no prior method has achieved at this scale.\n\n**Position Relative to Generative Models:**\n\nFor reference, we also include dedicated generative models (StyleGAN: 0.4790, DDPM: 0.3389). While DSF does not match the quality of models explicitly trained for generation, this comparison is fundamentally different:\n- Generative models are **trained** with generative objectives\n- DSF is **zero-shot** from off-the-shelf discriminative models\n\n**Our Contribution:**\n\nThe value of DSF lies not in outperforming dedicated generative models, but in **unlocking generative capabilities from discriminative models without any retraining**—a capability that existing discriminative inversion methods fail to provide at high resolution.\n\n| Method | Architecture | Dataset | Paper | Quality Score |\n|--------|-------------|---------|-------|---------------|\n| **Discriminative Inversion Methods** |\n| MTT | ResNet18 | TinyImageNet | Dataset Distillation (CVPR 2022) | 0.00097 |\n| JEM | WideResNet 28-10 | CIFAR10 | Energy-Based (NeurIPS 2020) | 0.00376 |\n| Robust Classifier | WideResNet 28-10 | CIFAR10 | Discriminative Generation (NeurIPS 2019) | 0.02398 |\n| **DSF (Ours)** | ViT | LVD-142M | This work | **0.0678** |\n| **Reference: Dedicated Generative Models** |\n| StyleGAN | - | - | CVPR 2019 | 0.4790 |\n| DDPM | - | - | NeurIPS 2020 | 0.3389 |\n\n**Table A1:** Quantitative comparison using Q-align quality scores. The quality metric is derived from Q-align [1], which allows for a unified quality score to be measured across different datasets. Existing discriminative inversion methods (rows 1-3) produce near-zero quality scores, indicating noise-like outputs at high resolution. DSF achieves recognizable image generation from discriminative models (0.0678), while dedicated generative models (StyleGAN, DDPM) achieve higher scores as expected for models explicitly trained for generation. Visual samples are shown in Appendix.\n\n[1] Wu et al., \"Q-Align: Teaching LMMs for Visual Scoring via Discrete Text-Defined Levels,\" ICML 2024."}}, "id": "ZVMlJQuA3O", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763728564737, "cdate": 1763728564737, "tmdate": 1763728581906, "mdate": 1763728581906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "[C4] Computational Complexity"}, "comment": {"value": "**Question:** How computationally expensive is the DSF generation procedure? How does it compare to standard diffusion sampling?\n\n**Response:**\n\nThe generation process is **computationally efficient and practical**, with costs comparable to standard diffusion models.\n\n**Specific Metrics:**\n- **Wall-Clock Time:** Generating a single $$256 \\times 256$$ image takes approximately **36 seconds** on a single NVIDIA RTX A6000 GPU.\n- **Iterations:** We typically use $T \\approx 200$ iterations per image.\n- **Comparison:** This is comparable to the inference time of standard diffusion models with similar sampling steps, confirming that our method is viable for research and application.\n\n**Per-Step Complexity:**\n\nOne iteration of DSF involves a forward and backward pass through the network, making it roughly $2\\times$ the cost of a standard inference step. The theoretical cost is $O(D \\times P)$, where $D$ is the dimension of the generative candidate and $P$ is the parameter size.\n\n**Optimization for Efficiency:**\n\nCrucially, we do not necessarily need to compute gradients for all parameters. For deep models like DINOv2 (ViT), we found that backpropagating through only the **initial subset of layers** (e.g., the last few transformer blocks) is sufficient to obtain meaningful gradients for the input pixels. This \"partial gradient\" approach significantly reduces memory and computation costs without sacrificing generation quality."}}, "id": "0sVwg5vCEU", "forum": "DYujKV4Ama", "replyto": "DYujKV4Ama", "signatures": ["ICLR.cc/2026/Conference/Submission10649/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10649/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission10649/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763728640095, "cdate": 1763728640095, "tmdate": 1763728640095, "mdate": 1763728640095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}