{"id": "nwkiK8vNd1", "number": 19420, "cdate": 1758296102347, "mdate": 1763633626882, "content": {"title": "Online Minimization of Polarization and Disagreement via Low-Rank Matrix Bandits", "abstract": "We study the problem of minimizing polarization and disagreement in the Friedkin–Johnsen opinion dynamics model under incomplete information. Unlike prior work that assumes a static setting with full knowledge of users' innate opinions, we address the more realistic online setting where innate opinions are unknown and must be learned through sequential observations. This novel setting, which naturally mirrors periodic interventions on social media platforms, is formulated as a regret minimization problem, establishing a key connection between algorithmic interventions on social media platforms and theory of multi-armed bandits. In our formulation, a learner observes only a scalar feedback of the overall polarization and disagreement after an intervention.\nFor this novel bandit problem, we propose a two-stage algorithm based on low-rank matrix bandits. The algorithm first performs subspace estimation to identify an underlying low-dimensional structure, and then employs a linear bandit algorithm within the compact dimensional representation derived from the estimated subspace.\nWe prove that our algorithm achieves an $\\widetilde{O}(\\sqrt{T})$ cumulative regret over any time horizon $T$. Empirical results validate that our algorithm significantly outperforms a linear bandit baseline in terms of both cumulative regret and running time.", "tldr": "We present the first online framework for minimizing polarization and disagreement in the Friedkin–Johnsen model, using a two-stage low-rank matrix bandit algorithm with guarantees and strong empirical gains over linear bandits.", "keywords": ["bandits", "online learning", "opinion dynamics", "social media platforms"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/101077ebc448eed2595bbf61587fd05e28d19685.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles minimizing polarization plus disagreement in the Friedkin–Johnsen model with online bandit feedback, observing one noisy scalar per intervention. It runs two phases: a low rank trace regression estimates a rank one matrix and its top direction to rotate and compress arm features to linear in the number of nodes, then a standard linear bandit such as OFUL operates on the reduced features; the authors prove phase one recovery and an overall regret that scales with the square root of time and network size, and validate empirically."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1/ The subject is highly relevant and important.\n\n2/ The approach is clearly presented with an exemplary writing.\n\n3/ The authors cleverly adapt classical bandit strategies to their specific setting."}, "weaknesses": {"value": "Summary\n\nWhile the paper has the merit of carefully deriving the technical aspects and adapts classical bandit concepts (a preconditioning phase followed by OFUL), it does not clearly justify the online formulation over prior offline formalisms (or a BAI formalisms) and omits state-of-the-art baselines in the experiments.\n\nMajor concerns\n\n1/ Please compare with additional baselines (e.g., Chaitanya et al., 2024) and with the subspace Oracle in a sample-based evaluation. Using the same arm set and sample budget, plot the minimum polarization plus disagreement obtained versus the number of observed intervention outcome pairs (learning-curve style). For your method and the Oracle also report the mean polarization plus disagreement of the best arm selected after T = number of samples.\n\n2/ Please justify the online regret minimization (vs. offline periodic updates and a BAI setting for example). Explain why interventions are sequential and interim loss matters a real case, and add a brief disscussion on the comparison to batched/BAI baseline in this aspect.\n\nMinor comments\n\n1/ Consider restricting the regret plot to the first 2,000 iterations and use a logarithmic x-axis/y-axis to better expose the early hinge between Phase-1 and Phase-2.\n\n2/ There are numerous typos, for example: \"which which we term\", \"problem reduces to a low-rank matrix bandits\", \"existing analyzes\", etc\n\n3/ In the supplementary material, expand the ethics/impacts discussion (potential misuse, beneficiaries vs. risks, etc). Also add a plain-language note on the meaning in real life of the mean-centered innate opinions assumption.\n\nGrading explanation\n\nThe paper is clear and technically strong, yet key SOTA baselines are missing (and the motivation for the setting is not clear)."}, "questions": {"value": "1/ Why choosing a regret setting and not BAI setting in your case?\n\n2/ Could you detail how the candidate arms are generated for the real-data experiments?"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "The paper proposes an outcome-agnostic intervention that can steer collective opinions, posing risks of suppressing dissent or critical views (\"Manufacturing Consent\"); I’m not qualified to assess this and recommend an expert ethics/broader-impacts review."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xOkSaJjiL3", "forum": "nwkiK8vNd1", "replyto": "nwkiK8vNd1", "signatures": ["ICLR.cc/2026/Conference/Submission19420/Reviewer_jpz5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19420/Reviewer_jpz5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19420/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994948012, "cdate": 1761994948012, "tmdate": 1762931338954, "mdate": 1762931338954, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles minimizing polarization plus disagreement in the Friedkin–Johnsen model with online bandit feedback, observing one noisy scalar per intervention. It runs two phases: a low rank trace regression estimates a rank one matrix and its top direction to rotate and compress arm features to linear in the number of nodes, then a standard linear bandit such as OFUL operates on the reduced features; the authors prove phase one recovery and an overall regret that scales with the square root of time and network size, and validate empirically."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1/ The subject is highly relevant and important.\n\n2/ The approach is clearly presented with an exemplary writing.\n\n3/ The authors cleverly adapt classical bandit strategies to their specific setting."}, "weaknesses": {"value": "Summary\n\nWhile the paper has the merit of carefully deriving the technical aspects and adapts classical bandit concepts (a preconditioning phase followed by OFUL), it does not clearly justify the online formulation over prior offline formalisms (or a BAI formalisms) and omits state-of-the-art baselines in the experiments.\n\nMajor concerns\n\n1/ Please compare with additional baselines (e.g., Chaitanya et al., 2024) and with the subspace Oracle in a sample-based evaluation. Using the same arm set and sample budget, plot the minimum polarization plus disagreement obtained versus the number of observed intervention outcome pairs (learning-curve style). For your method and the Oracle also report the mean polarization plus disagreement of the best arm selected after T = number of samples.\n\n2/ Please justify the online regret minimization (vs. offline periodic updates and a BAI setting for example). Explain why interventions are sequential and interim loss matters a real case, and add a brief disscussion on the comparison to batched/BAI baseline in this aspect.\n\nMinor comments\n\n1/ Consider restricting the regret plot to the first 2,000 iterations and use a logarithmic x-axis/y-axis to better expose the early hinge between Phase-1 and Phase-2.\n\n2/ There are numerous typos, for example: \"which which we term\", \"problem reduces to a low-rank matrix bandits\", \"existing analyzes\", etc\n\n3/ In the supplementary material, expand the ethics/impacts discussion (potential misuse, beneficiaries vs. risks, etc). Also add a plain-language note on the meaning in real life of the mean-centered innate opinions assumption.\n\nGrading explanation\n\nThe paper is clear and technically strong, yet key SOTA baselines are missing (and the motivation for the setting is not clear).\n\nEdit:\nRaised score from 4 (weak reject) to 8 (accept)"}, "questions": {"value": "1/ Why choosing a regret setting and not BAI setting in your case?\n\n2/ Could you detail how the candidate arms are generated for the real-data experiments?"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "The paper proposes an outcome-agnostic intervention that can steer collective opinions, posing risks of suppressing dissent or critical views (\"Manufacturing Consent\"); I’m not qualified to assess this and recommend an expert ethics/broader-impacts review."}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xOkSaJjiL3", "forum": "nwkiK8vNd1", "replyto": "nwkiK8vNd1", "signatures": ["ICLR.cc/2026/Conference/Submission19420/Reviewer_jpz5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19420/Reviewer_jpz5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19420/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994948012, "cdate": 1761994948012, "tmdate": 1763738531651, "mdate": 1763738531651, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies an online learning problem involving the Friedkin-Johnsen (FJ) opinion dynamics model. The model describes a discrete-time dynamical system over the expressed opinions of users connected by an interaction graph, which also depends on some innate opinions of the finitely many users, which initializes the system. The system is known to converge to an equilibrium (fixed-point), at which one can measure polarization (variance of the equilibrium opinion distribution) and disagreement (essentially some notion of smoothness of the equilibrium distribution as given by its quadratic form under the graph Laplacian). The authors study the fundamental question of whether, without knowledge of the initial, innate opinion distribution of the users, one can choose interaction graph structures to minimize polarization and disagreement. This is formulated as an online learning problem where, at each time step, the user chooses an interaction graph structure and receives bandit feedback on an objective function encoding the polarization and disagreement of the resulting FJ dynamics at equilibrium. The problem is motivated by social media platforms implementing interventions (via changes to user interaction structure) to minimize polarization and disagreement.\n\nFor this problem, the authors obtain a sublinear regret bound scaling like O(|V| \\sqrt{T}) (where |V| is the number of users) using an explore-then-commit approach: first, using some uniform exploration phase to learn a low-rank subspace in the interaction graph space, and then to run a no-regret linear bandit algorithm on the set of actions in the learned, lower-dimensional representation. The result of the two-phase approach is an improved linear dependence on |V| in the final regret bound, as opposed to a quadratic dependence if one naively runs a standard linear bandit algorithm from the initial round. One of the core technical novelties of the work is the design of the initial subspace estimation phase, which is specialized to the particular discrete structure of the problem setting and departs from prior works on dimensionality reduction in matrix bandits. \n\nThe authors additionally show the effectiveness of the proposed method experimentally."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Overall, the paper is very clearly written and presented, and the new subspace estimation technique used in the main algorithm seems novel."}, "weaknesses": {"value": "Several assumptions made in the paper could be discussed further: \n* One assumption is that the intervention space (action space) is comprised of a fixed set of K admissible graph Laplacians, but it is not discussed how the regret of the algorithm scales with K (in particular if the action set contains all graph Laplacians). \n* A second assumption is that the user observes an estimate of the polarization/disagreement objective at equilibrium under the FJ dynamics, but it is not discussed how fast the FJ dynamics actually converges to this equilibrium.\n\nNote that the main body of the paper also exceeds 9 pages by several lines (but after communication with a PC representative, this is OK)."}, "questions": {"value": "Regarding the assumptions mentioned under Weaknesses:\n* Are you assuming the intervention space is a priori finite and fixed due to some exogenous problem constraints (e.g., a platform can only choose certain network structures given privacy/connection constraints between users)? In principle, this set could be exponentially large in |V| (since each graph Laplacian corresponds to a different adjacency matrix). How does the final regret bound of Theorem 4.1 depend on the size of the intervention space K? \n* Is it known how quickly the FJ dynamics converges to equilibrium (c.f., the comment regarding asymptotic convergence in L126-L127)? In other words, at what timescale with respect to the FJ dynamics does the outer OPD-Min-ESTR algorithm operate, since it is assumed that the learner receives bandit feedback on the objective function for the dynamics at equilibrium."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GoLdnOxlDb", "forum": "nwkiK8vNd1", "replyto": "nwkiK8vNd1", "signatures": ["ICLR.cc/2026/Conference/Submission19420/Reviewer_zipZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19420/Reviewer_zipZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19420/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762076643714, "cdate": 1762076643714, "tmdate": 1762931336460, "mdate": 1762931336460, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of minimizing polarization and disagreement under the *Friedkin–Johnsen (FJ) opinion dynamics model* when there is incomplete information about the innate opinions. By defining actions as constructing different forest matrices $X = (I + L)^{-1}$, where $L$ is the Laplacian matrix of the graph, the authors formulate the minimization of polarization and disagreement as a multi-armed bandit problem. By sequentially intervening on the network graph, the algorithm aims to minimize the cumulative regret—the sum of expressed polarization and disagreement—over a finite horizon $T$.\n\nThe proposed method consists of two stages. Stage 1 performs uniform sampling over the action set to learn about the opinion subspace. Stage 2, using the noisy loss observations collected in Stage 1, performs dimensionality reduction and maps the linear bandit problem onto the reduced subspace. The proposed algorithm achieves a regret bound of  $\\tilde{O}(|V|\\sqrt{T})$, \nwhere $|V|$ denotes the number of nodes in the graph.\n\nThe paper further compares the proposed algorithm with two baselines:  (1) applying OFUL directly on the full high dimensional space $R^{\\mid V\\mid ^2}$; (2) the oracle case where the true subspace is known, serving as a lower bound. By learning the subspace first, the proposed algorithm achieves substantially lower regret and faster convergence compared to performing OFUL on the full space."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This paper advances the study of polarization and disagreement minimization in the following ways:  (1) it assumes no prior knowledge about the innate opinion information; (2) it reformulates the minimization of polarization and disagreement under the FJ model within a multi-armed bandit framework.  The technical contribution of this paper lies in adapting previous MAB algorithms, which typically assume a continuous action space (e.g., Gaussian random matrices), to a setting where the action space is discrete, highly structured, and induced by the graph Laplacian. The paper provides a novel theoretical analysis of the regret bound that used the Restricted Strong Convexity (RSC) condition for the defined action set. The authors show that the RSC condition holds when performing uniform sampling over their specific action set. Furthermore, in the experimental section, the proposed algorithm’s performance closely matches the empirical lower bound corresponding to the oracle case, which has access to the true subspace $\\Theta^*$.  \n\nI have skimmed through the proofs for the subspace reduction and regret analysis, and I do not see any obvious issues with them. However, since I am not very familiar with the RSC condition, I will refrain from commenting further on that aspect.  \n\nOverall, this paper is clearly written, and the notations are well defined and consistent."}, "weaknesses": {"value": "1. Although it might be a common assumption in the FJ opinion dynamics model, this paper assumes that the innate opinion $s$ is static over time, and only the expressed opinion $z_t$ evolves. I am somewhat skeptical about this assumption, as innate opinions could also be influenced by the expressed opinions of neighbors. However, since this work explicitly follows the assumptions of the standard FJ model, this limitation may not significantly undermine the overall validity of the paper.\n\n2. The rationale for why the action space is discrete is not clearly explained, nor is it entirely clear whether this assumption is reasonable within the given problem setting. (See Question 1.)"}, "questions": {"value": "1. It is not very clear why the action space is assumed to be discrete in the problem setup. By definition, the action is given as  $X_w = (I + L_w)^{-1}$, where $L_w = D - A_w$ is the Laplacian matrix of a graph. Since $A_w$ is the adjacency matrix of the graph $G$ with edge weights $w$, and these weights could form a continuous but constrained vector, it is not immediately obvious why the action space cannot be treated as continuous.\n\n2. I would recommend revising the definition in line 287 to clarify that the subscript $t$ refers to $t \\in T_1$ and that $[\\cdot]_t$ denotes an entry of the vector. This notation was somehow unclear upon first reading."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4GSwDSNiBw", "forum": "nwkiK8vNd1", "replyto": "nwkiK8vNd1", "signatures": ["ICLR.cc/2026/Conference/Submission19420/Reviewer_M4wL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19420/Reviewer_M4wL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19420/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762722309308, "cdate": 1762722309308, "tmdate": 1762931335361, "mdate": 1762931335361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}