{"id": "6NPGwIRyrk", "number": 7032, "cdate": 1758005601633, "mdate": 1759897877068, "content": {"title": "Adaptive Graph Convolutional Network with Attention Fusion for Multivariate Time Series Forecasting with Variable Missing", "abstract": "Multivariate time series forecasting (MTSF) plays a vital role in diverse applications such as traffic prediction, weather research, and energy management. However, missing subset variable forecastinh has emerged as a critical challenge in MTSF due to factors such as sensor failures and maintenance. Variable incompleteness severely hinders the ability of forecasting models to capture intrinsic inter-variable relationships. Existing approaches either suffer from severe error accumulation, lack flexible mechanisms for handling missing data, or overly rely on local spatiotemporal correlations. To address these limitations, we propose VMPredictor, a novel end-to-end framework that effectively models spatiotemporal dependencies among incomplete variables for accurate forecasting. VMPredictor incorporates two key components: (1) the Adaptive Missing Filling and Enhancement Layer , which introduces learnable embeddings to adaptively fill missing positions and dynamically refine incomplete representations during training; and (2) the Spatiotemporal Dependency Mining Layer, built upon a Dynamic Graph Convolution Layer-Normalized Gated Recurrent Unit, where dynamic graph convolution adaptively reconstructs spatial correlations and replaces all fully connected layers in GRU to capture synchronized spatiotemporal dependencies. Together, these innovations endow VMPredictor with robust missing-data handling and precise spatiotemporal relation modeling. Extensive experiments on five real-world datasets under varying missing rates demonstrate the superiority of our approach over existing baselines. Codes can be found at https://anonymous.4open.science/r/Code-A216/.", "tldr": "", "keywords": ["MTSF+Missing Variable-Subset+Spatiotemporal Dependency+Dynamic Graph Convolution"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b1dffb8b6c7d04be4133532b6935410f7e5afa0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes VMPredictor, a novel end-to-end framework for multivariate time series forecasting (MTSF) under variable-missing scenarios. Unlike conventional two-stage imputation–forecasting methods, VMPredictor directly learns to model incomplete variables through adaptive representation learning. The framework integrates: (1) Adaptive Missing Filling and Enhancement Layer (AMFE Layer). (2) Embedding Layer: injects temporal and spatial embeddings. (3) Spatiotemporal Dependency Mining Layer (STDMLayer. (4) Multi-Head Temporal Self-Attention Layer (MHTSA): captures global temporal context for final prediction.\n\nComprehensive experiments on five real-world datasets (PEMS04/08, METR-LA, PEMS-BAY, China AQI) show that VMPredictor consistently outperforms 10+ SOTA baselines, especially at high missing rates (75%–90%)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction of learnable missing embeddings allows dynamic representation of incomplete data, effectively reducing bias from fixed-value imputation. This design significantly improves robustness against missing patterns.\n2. The combination of dynamic graph convolution and layer-normalized GRU enables simultaneous learning of temporal dynamics and spatial correlations. This achieves more precise inter-variable modeling compared to static GCN or vanilla GRU baselines.\n3. The multi-head temporal self-attention layer captures long-range dependencies, while the SE-based enhancement layer adaptively reweights important channels and timestamps, leading to balanced local-global feature fusion.\n4. The proposed method demonstrates consistent SOTA performance across diverse domains (traffic and air quality) and under severe missing conditions. Ablation and sensitivity analyses further confirm the effectiveness and interpretability of the design."}, "weaknesses": {"value": "1. The introduction is somewhat disjointed. The authors could provide a deeper analysis of the core challenges in multivariate time series forecasting with variable missing data before introducing how the proposed method addresses these challenges.\n2. The core technical innovation seems to lie mainly in the embedding layer, while the rest of the framework is similar to mainstream STGNNs. The authors are encouraged to further emphasize how the proposed embedding layer specifically mitigates existing problems, such as error accumulation in current methods.\n3. The ablation experiment can consider directly removing all the additional embeddings. This will further demonstrate the effectiveness of the core technical contribution of this paper and its significance in this task.\n4. It would be beneficial to conduct additional experiments in more widely used missing-data scenarios [1] to further verify the robustness of VMPredictor.\n5. There are some formatting errors, such as the “Table ??” on page 13, line 684, and page 17, line 888.\n\n[1] Graph-based Forecasting with Missing Data through Spatiotemporal Downsampling"}, "questions": {"value": "1. I’m curious whether the proposed model can be transferred to random missing or block missing tasks.\n2. Is the superior performance of the proposed method mainly attributed to the model architecture or to the specifically designed embedding layer?\n3. If the proposed embedding method is transferred to other backbones, will it be able to improve their performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VQk0pcVcHE", "forum": "6NPGwIRyrk", "replyto": "6NPGwIRyrk", "signatures": ["ICLR.cc/2026/Conference/Submission7032/Reviewer_Fmme"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7032/Reviewer_Fmme"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761557110515, "cdate": 1761557110515, "tmdate": 1762919233466, "mdate": 1762919233466, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **FedTRL**, a federated learning framework designed to train **time series foundation models (TSFMs)** under **bi-level heterogeneity** — both inter-domain and intra-domain differences across clients.\nIt introduces a **dual-level optimization** strategy combining adversarial local regularization and domain-aware global aggregation to achieve domain-invariant and temporally coherent representations.\nExtensive experiments across in-domain, full-shot, and zero-shot forecasting tasks show that FedTRL achieves **state-of-the-art performance**, outperforming both centralized and existing federated baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper proposes **FedTRL**, a federated learning framework designed to train **time series foundation models (TSFMs)** under **bi-level heterogeneity** — both inter-domain and intra-domain differences across clients.\nIt introduces a **dual-level optimization** strategy combining adversarial local regularization and domain-aware global aggregation to achieve domain-invariant and temporally coherent representations.\nExtensive experiments across in-domain, full-shot, and zero-shot forecasting tasks show that FedTRL achieves **state-of-the-art performance**, outperforming both centralized and existing federated baselines."}, "weaknesses": {"value": "The paper proposes **FedTRL**, a federated learning framework designed to train **time series foundation models (TSFMs)** under **bi-level heterogeneity** — both inter-domain and intra-domain differences across clients.\nIt introduces a **dual-level optimization** strategy combining adversarial local regularization and domain-aware global aggregation to achieve domain-invariant and temporally coherent representations.\nExtensive experiments across in-domain, full-shot, and zero-shot forecasting tasks show that FedTRL achieves **state-of-the-art performance**, outperforming both centralized and existing federated baselines."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iishQAC3KE", "forum": "6NPGwIRyrk", "replyto": "6NPGwIRyrk", "signatures": ["ICLR.cc/2026/Conference/Submission7032/Reviewer_PhTa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7032/Reviewer_PhTa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892386097, "cdate": 1761892386097, "tmdate": 1762919232892, "mdate": 1762919232892, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper attempts to resolve the challenge of variable incompleteness in time series forecasting by proposing VMPredictor, a model that effectively captures spatiotemporal dependencies among incomplete variables to improve forecasting accuracy. Specifically, VMPredictor incorporates two key modules: the Adaptive Missing Filling and Enhancement Layer, which imputes and refines incomplete variables, and the Spatiotemporal Dependency Mining Layer, which captures both intra- and inter-series dependencies. Extensive experiments on five benchmark datasets demonstrate that the proposed model achieves state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper proposes a one-stage framework for time series forecasting with variable missing.\n- It introduces a learnable embedding to alleviate learning bias caused by fixed fill-in values.\n- Experimental results demonstrate that the proposed model achieves superior performance, even at high missing rates."}, "weaknesses": {"value": "- This paper aims to address the problem of variable missing in time series forecasting. However, the proposed method lacks specific mechanisms or designs that explicitly target this issue, leading to a misalignment between the stated motivation and the model design. The author should clarify the rationale for introducing the squeeze-excitation module and the Dynamic Graph Convolution Layer-Normalized Gated Recurrent Unit, and explain how these components contribute to handling variable missing problems. Moreover, the proposed model primarily integrates existing modules, and its overall novelty appears limited. The author should more clearly highlight the unique contributions or theoretical insights beyond this integration.\n\n-  Several arguments require clarification. For example, how does the learnable embedding $E_X \\in \\mathbb{R}^{T\\times N\\times d}$ alleviate parameter bias? How is $A_s$ defined for datasets that lack a predefined graph structure? In Eq. 14, the definitions of $\\alpha$, $\\beta$, and $\\gamma$ are unclear. In line 271, the author states that 'where $W_v$, $W_n$, $b_v$, and $b_n$ are all trainable parameters', but these variables are not introduced or defined earlier in the paper. \n\n- The hyperparameter settings require clarification. Specifically, the values of $d$, $d_s$, and $K$ vary across different datasets. Could the authors explain the rationale behind these choices and provide guidance on how to select appropriate values for new datasets?"}, "questions": {"value": "- There are numerous grammatical and stylistic errors in this paper. For example, the forecasting window size is inconsistently denoted as $F$, $H$, and $T$ in lines 157, 161, 315, and 316.  In Eq. 4, subscript notations are used inconsistently (1:T and 1:t). In addition, there are several typographical and capitalization errors, such as forecastinh (line 16), ': ,' (line 353), ', ,' (line 761), and 'Table ??' (lines 685 and 889). These issues significantly affect the readability and professionalism of the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2vz6sBenFt", "forum": "6NPGwIRyrk", "replyto": "6NPGwIRyrk", "signatures": ["ICLR.cc/2026/Conference/Submission7032/Reviewer_wwt7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7032/Reviewer_wwt7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986990631, "cdate": 1761986990631, "tmdate": 1762919232476, "mdate": 1762919232476, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose VMPredictor, an end-to-end framework that addresses key challenges in missing subset variable forecasting, including severe error accumulation, the lack of flexible mechanisms for handling missing data, and the overreliance on local spatiotemporal correlations in existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1. The adaptive missing-data imputation and enhancement layer introduces learnable embeddings to adaptively fill missing positions and dynamically refine incomplete representations during training.\n\nS2. The spatiotemporal dependency mining layer is built upon a dynamic graph convolutional gated recurrent unit, where dynamic graph convolution adaptively reconstructs spatial correlations and replaces all fully connected layers in the GRU to capture synchronized spatiotemporal dependencies."}, "weaknesses": {"value": "W1. The definition and role of $E_p$ in Equation (11) are unclear. The author should clarify its purpose, explain how it relates to $E_a$, and elaborate on their connections with $E_{day}$ and $E_{week}$. \n\nW2. There are several typographical errors, such as “Table ??” in Line 889 and “forecastinh” in Line 015.\n\nW3. The author randomly masks a fixed proportion of data; therefore, results from multiple random seeds should be reported to demonstrate the stability of the proposed method. Furthermore, sufficient implementation details should be provided to facilitate code reproducibility.\n\nW4. The author does not specify the source of the “China AQI” dataset. While it appears to refer to air quality index data, which is dynamically computed based on multiple pollutant concentrations, the author should clarify which specific pollutant was used to ensure consistency with the characteristics of other datasets."}, "questions": {"value": "See W1-4."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1mORFc2G01", "forum": "6NPGwIRyrk", "replyto": "6NPGwIRyrk", "signatures": ["ICLR.cc/2026/Conference/Submission7032/Reviewer_rmYy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7032/Reviewer_rmYy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762184591390, "cdate": 1762184591390, "tmdate": 1762919232064, "mdate": 1762919232064, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}