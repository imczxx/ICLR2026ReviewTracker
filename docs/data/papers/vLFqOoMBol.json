{"id": "vLFqOoMBol", "number": 21915, "cdate": 1758323532764, "mdate": 1759896896462, "content": {"title": "Every Language Model Has a Forgery-Resistant Signature", "abstract": "The ubiquity of closed-weight language models with public-facing APIs has generated interest in forensic methods, both for extracting hidden model details (e.g., parameters) and identifying models by their outputs. One successful approach to these goals has been to exploit the geometric constraints imposed by the language model architecture and parameters. In this work, we show that a lesser-known geometric constraint‚Äînamely that language model outputs lie on the surface of a high-dimensional ellipse‚Äîfunctions as a signature for the model, which be used to identify which model an output came from. This ellipse signature has unique properties that distinguish it from existing model-output association methods like language model watermarks. In particular, the signature is hard to forge: without direct access to model parameters, it is practically infeasible to produce logprobs on the ellipse. Secondly, the signature is naturally occurring, since all language models have these elliptical constraints. Thirdly, the signature is self-contained, in that it is detectable without access to the model input or full weights. Finally, the signature is exceptionally redundant, as it is independently detectable in every single logprob output from the model. We evaluate a novel technique for extracting the ellipse on small models, and discuss the practical hurdles that make it infeasible for production-size models, making the signature hard to forge. Finally, we use ellipse signatures to propose a protocol for language model output verification, which is analogous to cryptographic symmetric-key message authentication systems.", "tldr": "We show that all language models impose elliptical constraints on their outputs, which can be used as a hard-to-fake signature to identify a model from its outputs.", "keywords": ["fingerprint", "watermark", "language model", "signature", "accountability", "cryptography", "forgery", "security"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2f09ed39319c16836f70a5d8606078686771f3a8.pdf", "supplementary_material": "/attachment/c445ce95055af8b676dfe265ad497757580b8267.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel method for verifying the output attribution of closed-weight LMs, termed the \"Ellipse Signature.\" The authors build upon a key geometric observation: due to the normalization layer (mapping hidden states to a sphere) and the subsequent linear layer (an affine transform) at the end of modern LM architectures, the model's outputs (logits) are strictly constrained to lie on the surface of a high-dimensional hyperellipsoid.The paper's core contribution is demonstrating that this \"naturally occurring\" signature is highly \"forgery-resistant\". In sharp contrast to prior work on \"linear signatures\", which are easy to forge (requiring only $O(d)$ queries), the authors theoretically and experimentally argue that \"extracting\" the ellipse signature is computationally prohibitive. It requires $O(d^2)$ API queries to acquire sufficient points and $O(d^6)$ computational time to fit the ellipsoid parameters. For a large model like Llama-3-70B, this is shown to be practically infeasible (estimated at over $16 million in cost and 16,167 years of compute). Finally, the authors frame this mechanism as a naturally occurring Message Authentication Code (MAC) system, where the ellipse parameters act as a \"secret key,\" providing a powerful tool for model forensics and accountability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The derivation of ellipsoid constraints from normalization geometry is direct and relies on realistic architectural assumptions.  \n\n2. Sample and computational complexity analysis shows that reconstructing the ellipsoid from API outputs is practically infeasible for large models.  \n\n3. Experiments demonstrate that outputs of the target model have significantly smaller distances to their own ellipsoid compared to other models, confirming discriminative power.  \n\n4. Framing the approach as a MAC-like verification mechanism helps conceptualize how providers might share or authenticate model signatures securely."}, "weaknesses": {"value": "1. Real-world APIs typically expose only top-$k$ log probabilities or apply noise. The paper primarily uses full logits and small models. It should evaluate whether the detection remains reliable under top-k truncation, temperature sampling, quantization, mixed precision, or the $\\varepsilon$-smoothing effects that shift points inside the ellipsoid. Although $\\varepsilon$ and alternative fitting methods are discussed, they do not cover large models or diverse normalization types.  \n\n2. The analysis assumes static base models. In Model-as-a-Service (MaaS) settings, providers often fine-tune models (e.g., via SFT or LoRA). The signature is described as fragile, suggesting any parameter change may alter the ellipsoid. The paper does not analyze the sensitivity of the ellipsoid to such updates‚Äîwhether a small LoRA change yields a distinct or slightly perturbed ellipsoid. This limits practical use since results only show separability between different base models, not versions or fine-tunes of the same model. The paper also omits discussion of robustness to quantization, distillation, or post-training modifications.\n\n3. The paper does not seem to add the usage of large language models section, which is required by this year's submission requirements."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qSfQ96YLoD", "forum": "vLFqOoMBol", "replyto": "vLFqOoMBol", "signatures": ["ICLR.cc/2026/Conference/Submission21915/Reviewer_pMYU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21915/Reviewer_pMYU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761411290959, "cdate": 1761411290959, "tmdate": 1762941980854, "mdate": 1762941980854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper uses the geometric constraint that language model outputs lie on a high-dimensional ellipse (ellipse signature) to identify source models. The signature is hard to forge, inherent to all models, self-contained, and compact. It evaluates ellipse extraction from small models, addresses scalability issues, and proposes an output verification protocol, advancing beyond methods like language model fingerprints."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper identifies and formalizes the ellipsoid constraint as a forensic signature, which is novel and interesting.\n\nThe derivation explaining why model outputs lie on high-dimensional ellipsoids‚Äîarising from the interaction between normalization layers and linear transformations‚Äîis theoretically sound and well-supported by comprehensive mathematical proofs, demonstrating strong theoretical innovation."}, "weaknesses": {"value": "The paper lacks both quantitative and qualitative comparisons with existing black-box fingerprinting methods [R1, R2].\n\nThe O(d^6) fitting complexity makes the method computationally infeasible for modern large-scale models.\n\nA key requirement for fingerprinting techniques is robustness, meaning that the fingerprint should remain invariant even after slight model modifications (e.g., LoRA fine-tuning). Evaluating the proposed ellipsoid-based approach under such conditions appears challenging for large models, though it may be feasible for smaller ones."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c6MBH6RmEN", "forum": "vLFqOoMBol", "replyto": "vLFqOoMBol", "signatures": ["ICLR.cc/2026/Conference/Submission21915/Reviewer_Cfrc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21915/Reviewer_Cfrc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761565173640, "cdate": 1761565173640, "tmdate": 1762941980335, "mdate": 1762941980335, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ellipse signature for language model forensics. The core concept is that due to the final normalization and linear layers in modern language models, their output logits (e.g. log-probabilities) are constrained to lie on the surface of a high-dimensional ellipse specific to the model. The authors identify four distinctive properties: difficult to forge, intrinsic in current LM architectures, self-contained, and abundant. The paper presents an algorithm to extract a model's ellipse parameters from output samples and shows that, for large models, this extraction (and thus forgery of the signature) is computationally prohibitive. Furthermore, the authors propose an analogy to cryptographic message authentication."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of leveraging the intrinsic geometric constraint (the ellipsoid) imposed by standard model architecture as a signature is intuitive. The paper also shows a promising scenario for the practical application of the proposed signature.\n- The authors identify four distinctive properties and provide theoretical/empirical evidences, especially for the forgery resistance that is the core concept of the paper.\n- The authors keep comparing the ellipse signature with a wide range of existing methods throughout the paper, which gives readers a clear context to language model fingerprinting literature."}, "weaknesses": {"value": "- Although the authors provide clear evidence for the distinctive properties of ellipse signature, they only analytically compare the ellipse signature to existing methods without any contrastive experiments, which makes readers hard to grasp the practical superiority of the ellipse signature.\n- Both the concept of ellipse signature and the fitting algorithm are directly adopted from the prior work of Carlini et al, 2024. The contribution is somewhat limited since the paper mainly interprets the advanced properties of an existing method.\n- While the ellipse signature is hard to forge shown in Figure 6, the paper does not show the trend with different scales of computation resources. Readers might concern that an adversary with sufficient resources might still extract the ellipse or generate on-ellipse outputs, given the polynomial-time complexity.\n- Minor qualms: The references style is somewhat disordered. The authors are suggested to use a regular retrieval library and update the publishment for some accepted preprint literature."}, "questions": {"value": "- The authors mention that the memory requirements of ellipse fitting makes GPU acceleration infeasible for ''sufficiently large models''. Can we use GPUs to accelerate smaller models (e.g. 1-10M) without surpassing the memory limitation? \n- What is the actual resource requirements for the fitting algorithm run with CPUs and GPUs, respectively?\n- Can the authors evaluate and discuss the trade-offs between the fitting algorithm and some alternative approximation methods mentioned in Section 3.3 ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "edlZBtPxLG", "forum": "vLFqOoMBol", "replyto": "vLFqOoMBol", "signatures": ["ICLR.cc/2026/Conference/Submission21915/Reviewer_nUfp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21915/Reviewer_nUfp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901696374, "cdate": 1761901696374, "tmdate": 1762941979076, "mdate": 1762941979076, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper observes that logits output by a typical LLM lie on a high-dimensional ellipse. They argue that this ellipse serves as a sort of \"signature\" that uniquely identifies the model."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The idea of using the ellipse signature as an identifier for a model is very cool!\nEven though I don't really see any applications (see the issues below with the ones they suggest), I think that the observation itself is interesting."}, "weaknesses": {"value": "See \"Questions\" for more details.\n\n1. It isn't a watermark at all, because one can't detect it from samples from the LLM. One would need to query the model to see if it is the given one, making it a totally different thing.\n\n2. They make bold and misleading claims about the hardness of forging the signature. I shouldn't need to say that presenting a particular algorithm with high complexity does not mean that the problem is hard.\n\n3. They never say what they actually mean by \"forgery.\" I am highly suspicious of whether the ellipse signature is hard to forge at all. They \"argue\" that the signature is hard to *learn*, not hard to forge. These are very different. For instance, it could be possible to use a few samples from the ellipse to compute a new sample that is far from the others (which is presumably what they mean by \"forgery\"), even if it is hard to learn the parameters of the entire ellipse."}, "questions": {"value": "1. I think that it's misleading to talk about this as a \"watermark\" without explaining the serious shortcoming of the method for that purpose: That this method requires access to the logits. If you want to use this for watermarking, you would need to be able to detect the signal in text. Maybe you can by just estimating logits from enough text samples, but that would presumably require an absurd amount of text that in particular contained many repeated tokens...\nFor example, you say In contrast [to watermarking papers], ellipse-based verification requires no changes on the provider side, and each generation step of the model independently bears the model‚Äôs signature, meaning that a generation of length 1 is sufficient to identify the source model.\" This is *completely false* because an actual token output by the model is not sufficient to detect the ellipse!\n\n2. You repeatedly say that you \"show\" or \"find\" that the ellipse is unforgeable. This is ridiculous: When someone builds a new cryptosystem from a *standard, well-studied assumption*, even then they typically say that they \"prove security under assumption X.\" You don't even state your actual computational assumption anywhere! It's just sort of implicit. This would be fine, except that you kind of masquerade as a cryptography result.\n\n3. I found one place where you reference the difference between learning and forging, but I think it is incorrect. You say that \"In fact, in the worst case Œ©(ùëë^2) samples are required to find even a single new (not in the set of samples) point on the ellipse, since if the samples are in general position then for every point not in the samples there is an ellipse that includes the samples but not the point.\" But given just 2 samples in general position, I can learn the entire projected 1d ellipse containing those two points, and therefore forge a 3rd point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7lfF3dvTGy", "forum": "vLFqOoMBol", "replyto": "vLFqOoMBol", "signatures": ["ICLR.cc/2026/Conference/Submission21915/Reviewer_3e9D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21915/Reviewer_3e9D"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762177899967, "cdate": 1762177899967, "tmdate": 1762941978707, "mdate": 1762941978707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper observes that logits output by a typical LLM lie on a high-dimensional ellipse. They argue that this ellipse serves as a sort of \"signature\" that uniquely identifies the model."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The idea of using the ellipse signature as an identifier for a model is very cool!\nEven though I don't really see any applications (see the issues below with the ones they suggest), I think that the observation itself is interesting."}, "weaknesses": {"value": "See \"Questions\" for more details.\n\n1. It isn't a watermark at all, because one can't detect it from samples from the LLM. One would need to query the model to see if it is the given one, making it a totally different thing.\n\n2. They make bold and misleading claims about the hardness of forging the signature. I shouldn't need to say that presenting a particular algorithm with high complexity does not mean that the problem is hard.\n\n3. They never say what they actually mean by \"forgery.\" I am highly suspicious of whether the ellipse signature is hard to forge at all. They \"argue\" that the signature is hard to *learn*, not hard to forge. These are very different. For instance, it could be possible to use a few samples from the ellipse to compute a new sample that is far from the others (which is presumably what they mean by \"forgery\"), even if it is hard to learn the parameters of the entire ellipse."}, "questions": {"value": "1. I think that it's misleading to talk about this as a \"watermark\" without explaining the serious shortcoming of the method for that purpose: That this method requires access to the logits. If you want to use this for watermarking, you would need to be able to detect the signal in text. Maybe you can by just estimating logits from enough text samples, but that would presumably require an absurd amount of text that in particular contained many repeated tokens...\nFor example, you say In contrast [to watermarking papers], ellipse-based verification requires no changes on the provider side, and each generation step of the model independently bears the model‚Äôs signature, meaning that a generation of length 1 is sufficient to identify the source model.\" This is *completely false* because an actual token output by the model is not sufficient to detect the ellipse!\n\n2. You repeatedly say that you \"show\" or \"find\" that the ellipse is unforgeable. This is ridiculous: When someone builds a new cryptosystem from a *standard, well-studied assumption*, even then they typically say that they \"prove security under assumption X.\" You don't even state your actual computational assumption anywhere! It's just sort of implicit. This would be fine, except that you kind of masquerade as a cryptography result.\n\n3. I found one place where you reference the difference between learning and forging, but I think it is incorrect. You say that \"In fact, in the worst case Œ©(ùëë^2) samples are required to find even a single new (not in the set of samples) point on the ellipse, since if the samples are in general position then for every point not in the samples there is an ellipse that includes the samples but not the point.\" But given just 2 samples in general position, I can learn the entire projected 1d ellipse containing those two points, and therefore forge a 3rd point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7lfF3dvTGy", "forum": "vLFqOoMBol", "replyto": "vLFqOoMBol", "signatures": ["ICLR.cc/2026/Conference/Submission21915/Reviewer_3e9D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21915/Reviewer_3e9D"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762177899967, "cdate": 1762177899967, "tmdate": 1763305292205, "mdate": 1763305292205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}