{"id": "M0n3gtwHNg", "number": 22989, "cdate": 1758337869004, "mdate": 1763751939551, "content": {"title": "Efficient Multi-objective Prompt Optimization via Pure-exploration Bandits", "abstract": "Prompt engineering has become central to eliciting the capabilities of large language models (LLMs). At its core lies prompt selection - efficiently identifying the most effective prompts. However, most prior investigations overlook a key challenge: the inherently multi-faceted nature of prompt performance, which cannot be captured by a single metric. To fill this gap, we study the multi-objective prompt selection problem under two practical settings: Pareto prompt set recovery and best feasible prompt identification. Casting the problem into the pure-exploration bandits framework, we adapt provably efficient algorithms from multi-objective bandits and further introduce a novel design for best feasible arm identification in structured bandits, with theoretical guarantees on the identification error in the linear case. Extensive experiments across multiple LLMs show that the bandit-based approaches yield significant improvements over baselines, establishing a principled and efficient framework for multi-objective prompt optimization.", "tldr": "", "keywords": ["Multi-objective prompt optimization; multi-objective bandits; best feasible arm identification; fixed-budget pure exploration"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9e7911f05653b8d3b97e8f2070e668b881e584c5.pdf", "supplementary_material": "/attachment/ce45267b514cbcf0100b51c0173fc0a524c859cb.zip"}, "replies": [{"content": {"summary": {"value": "The paper frames multi-objective prompt selection as a pure-exploration bandit problem under a fixed evaluation budget, with two tasks: best feasible prompt identification and Pareto prompt set identification. It introduces two round-based frameworks: GENSEC for the constrained task and GENPSI for the Pareto task, and in the linear shared-feature case provides a bound where the misidentification probability decays with budget and the dependence on the number of prompts improves from cubic to logarithmic, given specific choices of scheduler, allocation design, and estimator. Experiments are conducted on summarization tasks (XSum and CNN/DailyMail), using ROUGE-L F1 as utility and a brevity score as the second objective. After generating candidate prompts, filter them and down-sample the remainder into pools of size 100, 50, or 30. In practice the paper evaluates instantiated variants: for the constrained task, CSR and MLP-CSR as reductions of GENSEC; for the Pareto task, EGE and MLP-EGE as reductions of GENPSI. Figures report average soft-constrained reward versus per-arm budget and hypervolume recovery versus per-arm budget."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem setup shows meaningful originality: framing multi-objective prompt selection under a fixed budget and then applying established bandit-style methods to this setting is practical and likely useful in real evaluation pipelines.\n2. The theoretical analysis is solid, with clearly stated assumptions, a clean proof structure, and a bound that is easy to interpret within the stated setting.\n3. The paper is well written and organized; the problem, algorithms, and evaluation protocol are presented clearly and are easy to follow."}, "weaknesses": {"value": "1. Experimental scope and objectives are too narrow. All experiments are on summarization only, and every result uses just two objectives: ROUGE-L for utility and a brevity score for length control. There are no tasks beyond summarization (for example QA, dialogue, style transfer, code, safety-critical instruction following), and no additional objectives that typically motivate multi-objective selection in practice (for example safety, factuality, latency, monetary cost). Because both chosen objectives are summary-specific and tightly coupled to output length, the evidence does not establish that the approach generalizes to broader prompt-selection settings or to richer multi-objective trade-offs.\n2. Method-level novelty is limited; evaluated variants are reductions of existing algorithms. In the constrained setting the implementation reduces to CSR; in the Pareto setting it reduces to EGE (and related elimination variants in the linear case). The paper’s contribution is therefore mainly a problem framing and a unifying wrapper, rather than a new selection algorithm. The linear-case theory is helpful but tied to specific design choices and is not shown to drive the practical wins in the non-linear instantiations.\n3. Missing ablation on elimination margin and thresholding. The paper fixes both the constrained elimination margin and the soft-constraint factory. Without a sensitivity study of these choices, it is unclear whether the observed gains are robust or driven by a particular margin/threshold setting.\n4. In the Pareto experiments, hypervolume gains over uniform are small and inconsistent, which weakens the claim that shared structure or the framework provides broad advantage. In the “maximize task utility under a prescribed brevity constraint” experiments, uniform cannot purposefully satisfy the brevity threshold and therefore predictably underperforms any elimination method that can focus on constraint-satisfying prompts; this makes the superiority of CSR unsurprising and less persuasive as evidence of algorithmic merit. These results would be more convincing with strict feasibility curves, violation rates, and comparisons to stronger multi-objective baselines (for example evolutionary multi-objective prompt search) under the same candidate pool and budget.\n5. In the first paragraph of Section 3, the text says “Let a be a prompt,” but throughout the paper prompts are denoted by x, while a denotes the reference answer in input pairs (q, a)."}, "questions": {"value": "1. Can you add at least one non-summarization task and one additional objective (e.g., safety, factuality, latency or cost)? If not, justify why summarization with two metrics is representative.\n2. Please ablate elimination margin and thresholding: compare variants of the constrained elimination margin; sweep the soft-constraint factor instead of fixing it."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Th317UA6Lq", "forum": "M0n3gtwHNg", "replyto": "M0n3gtwHNg", "signatures": ["ICLR.cc/2026/Conference/Submission22989/Reviewer_i6FQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22989/Reviewer_i6FQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22989/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761056627048, "cdate": 1761056627048, "tmdate": 1762942466319, "mdate": 1762942466319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses multi-objective prompt optimization for large language models (LLMs) by formulating it as a pure-exploration multi-objective bandits problem. The authors study two fundamental settings: (1) best feasible prompt identification, where one objective is maximized subject to constraints on others, and (2) Pareto prompt set identification, where the goal is to recover all non-dominated prompts. They propose two general algorithms, GENSEC and GENPSI, which can exploit shared structure among prompts via feature representations. For the linear reward case, they provide theoretical guarantees showing exponentially decaying error probability with improved dependency on the number of prompts K (from K³ to log K). Experiments on XSum and CNN/DailyMail summarization benchmarks with LLaMA-3 and Gemma models demonstrate superior performance over uniform baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper makes a valuable connection between multi-objective prompt selection and the multi-objective bandits framework, which is the first systematic attempt to leverage bandit algorithms for multi-criteria prompt optimization.\n2. The paper provides theoretical analysis for the linear reward setting, which is a significant theoretical improvement.\n3. The work addresses a real and important problem in prompt engineering where multiple conflicting objectives (e.g., accuracy vs. brevity, coherence vs. faithfulness) need to be balanced."}, "weaknesses": {"value": "1. Once prompts are mapped to feature vectors (e.g., using GPT-X embeddings), the problem proposed in this paper becomes a standard gradient-free optimization problem (aka hyperparameter optimization - HPO). The authors apply one of gradient free optimization methods (multi-objective bandit) to this vectorized representation and record theoretical and empirical analysis. While such application papers have value, they require much more extensive empirical validation to justify publication.\n2. In empirical evaluation, authors compares against random/uniform pulling. For a fair evaluation, the method must be compared with other prompt optimization engines (e.g., InstructZero, ZOPO, EMO-Prompts, InstOptima) under the same fixed evaluation budget (number of examples per forward pass).\n3. Testing on only 30-100 prompts is very small - one could simply evaluate all prompts exhaustively at this scale. Real-world prompt selection involves choosing from thousands or tens of thousands of candidates and it is important to show the method works in this setting.\n\nMinor weaknesses:\n-  Gap between theoretical linear case and practical MLP implementation not well explained\n- Missing discussion on scalability with number of objectives m > 2\n- Prompt generation via LLM + manual filtering introduces selection bias"}, "questions": {"value": "1. Can you provide experiments with 1000+ initial prompts to demonstrate the method's effectiveness when exhaustive evaluation is infeasible?\n2. What specific advantages does the bandit formulation provide over off-the-shelf HPO methods like Bayesian optimization for this problem?\n3. Can you demonstrate the method on real safety or fairness constraints?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gOoiQtPEBr", "forum": "M0n3gtwHNg", "replyto": "M0n3gtwHNg", "signatures": ["ICLR.cc/2026/Conference/Submission22989/Reviewer_pHhY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22989/Reviewer_pHhY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22989/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847021837, "cdate": 1761847021837, "tmdate": 1762942465958, "mdate": 1762942465958, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper frames multi-criteria prompt selection as pure-exploration multi-objective bandits, targeting both best feasible prompt and Pareto set recovery. It proposes two elimination frameworks GENSEC and GENPSI respectively. In the linear case, the paper proves an exponentially decaying misidentification bound with only logarithmic dependency in K. Experiments on XSum and CNN/DailyMail with Llama-3-8B-Instruct and Gemma-7B-IT show consistent gains over a uniform baseline."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper moves beyond single-metric prompt selection to an explicit multi-objective setup, which is well motivated for practical problem. \n\nThe paper provide theoretical error bound for linear rewards."}, "weaknesses": {"value": "In experiments, comparisons are largely to a uniform allocator,  there is no multi-objective prompt optimization baselines, such as weighted sums with single-objective BAI or recent evolutionary multi-objective prompt optimizers mentioned in sec. 2. \n\nHV is “normalized by the ground-truth Pareto set,” but the procedure to obtain that ground truth is not fully specified. \n\nTypo: in line 128, should be  \"Let $x$ be a prompt\""}, "questions": {"value": "How exactly is the “ground-truth Pareto set” computed for normalization?\n\nCan you add weighted sum +BAI, and evolutionary multi-objective prompt optimizer as baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "HiGMXWi42j", "forum": "M0n3gtwHNg", "replyto": "M0n3gtwHNg", "signatures": ["ICLR.cc/2026/Conference/Submission22989/Reviewer_BAtQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22989/Reviewer_BAtQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22989/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761855213951, "cdate": 1761855213951, "tmdate": 1762942465547, "mdate": 1762942465547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the multi-objective prompt selection problem under two settings: Pareto prompt set recovery and best feasible prompt identification. The authors treat the prompt selection problem as a bandit problem and develop a multi-objective bandit algorithm. The experimental results demonstrate that the proposed method outperforms baseline methods on two tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Focusing on multiple evaluation criteria in prompt selection is convincing, as it reflects practical scenarios better than single-objective settings.\n- The experimental evaluation demonstrates that the proposed method outperforms baseline methods on two tasks."}, "weaknesses": {"value": "- The proposed method requires a pre-defined candidate prompt set, and its performance is limited by the quality of the candidate prompt set. However, how to construct a good candidate prompt set is not discussed in this paper.\n- In the experiment, the candidate prompt pool is up to 100, which seems relatively small. It is unclear whether the proposed method works well when the candidate prompt pool is large.\n- The budget $B$ considered in the experiment is small (up to 10). How is the performance of the proposed method when the budget and candidate prompt pool size are large?\n- The experimental comparison is conducted only with a simple baseline and the variants of the proposed method. Comparison with existing prompt optimization methods may be helpful in clarifying the absolute effectiveness of the proposed method.\n- Only two datasets (XSum and CNN/DailyMail) are considered in the experiment. It would be better to include more datasets to verify the effectiveness of the proposed method."}, "questions": {"value": "- How is the performance of the proposed method when the budget and candidate prompt pool size are large?\n- Could you explain the reason that the current experimental settings are chosen (e.g., datasets and baselines)?\n- Please describe a practical use case where the proposed method is more effective than other existing prompt optimization (generation) methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YOlwB3VQMI", "forum": "M0n3gtwHNg", "replyto": "M0n3gtwHNg", "signatures": ["ICLR.cc/2026/Conference/Submission22989/Reviewer_NCGw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22989/Reviewer_NCGw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22989/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762188393712, "cdate": 1762188393712, "tmdate": 1762942465180, "mdate": 1762942465180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}