{"id": "cYZkZp3m8F", "number": 12001, "cdate": 1758205138161, "mdate": 1763646129683, "content": {"title": "Understanding Multimodal Learning: A Loss Landscape Smoothness Perspective", "abstract": "A surge of recent advancements has consistently highlighted the superiority of multimodal learning over unimodal approaches across a variety of tasks.\nHowever, the theoretical foundations elucidating this advantage remain underexplored: existing theoretical analyses are often constrained by tight assumptions, and lack empirical validation.\nIn this paper, we bridge this gap by proposing a novel theoretical framework grounded in convolutional smoothing, offering a new perspective on how multimodal learning contributes to a smoother loss landscape compared to unimodal learning.\nBuilding upon this theoretical foundation, we introduce a simple yet effective distributional training strategy based on stochastic modality pairing instead of a fixed pairing; thus, further promoting a flatter landscape via convolutional smoothing. \nOur empirical results across various multimodal datasets demonstrate that multimodal models not only achieve higher performance but also exhibit flatter loss landscape, which represent better generalization and robustness.", "tldr": "We propose a theoretical framework showing that multimodal learning not only outperforms unimodal approaches but also achieves a flatter minima for better generalization.", "keywords": ["Learning Theory", "Multimodal Learning", "Loss Landscape Smoothness", "Robustness"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bd4cde71cc9537dc617438a6ab4a3af7d62a208f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose that multimodal learning leads to better performance than unimodal learning due to the presence of label-dependent variance that smooths the loss landscape and leads to flatter minima. They argue this theoretically by proving that the multimodal loss can be expressed as a convolution of the unimodal loss with a \"scaled-shift kernel\" derived from the second modality, which guarantees a smoother loss landscape. This motivates a very simple training procedure which shuffles the pairs of inputs which belong to the same level. This procedure leads to consistent and sometimes significant improvements on multiple multimodal benchmark datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Distributed Multimodal Learning (DML) is extremely simple to implement, introduces no hyperparameters, and performs well empirically across a diverse set of multimodal datasets.\n* The choice of datasets spans three pairs of modalities: audio/vision, image/audio, image/text. This makes the conclusions much more general and believable compared to e.g. just considering multiple image/text datasets.\n* DML consists of shuffling pairs of inputs which correspond to the same label. This introduces a label-conditioned variance, which is consistent with the authors' theory."}, "weaknesses": {"value": "* The experimental results can be made more robust by comparing across at least two architectures for each dataset.\n* The datasets and network architectures are relatively small-scale, and it would be interesting to see whether DML improves results on e.g. larger image/text datasets with larger vision and text encoders."}, "questions": {"value": "Do you think the assumption of conditional independence between the inputs given the target is reasonable? Your empirical results seem to suggest so, but I would be interested to see this discussed in the paper. There is previous work in the literature that suggests the opposite conclusion, which is that the inter-modal dependency is precisely why multimodal learning is advantageous over unimodal learning [1].\n\n[1] Jointly Modeling Inter- & Intra-Modality Dependencies for Multi-modal Learning, Madaan et al, NeurIPS 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3yKixUy8Ef", "forum": "cYZkZp3m8F", "replyto": "cYZkZp3m8F", "signatures": ["ICLR.cc/2026/Conference/Submission12001/Reviewer_Hoxa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12001/Reviewer_Hoxa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722622732, "cdate": 1761722622732, "tmdate": 1762922992319, "mdate": 1762922992319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examines multimodal learning from the perspective of landscape smoothness in loss functions. First, it points out that while multimodal learning has significant empirical advantages, its theoretical foundation is weak (existing theories rely on strong assumptions and lack empirical verification). Then, it proposes a theoretical framework based on convolutional smoothing. By defining notations for modal input, encoder, and fusion function, and combining the two assumptions of \"approximate translation invariance of the fusion function\" and \"conditional independence of modalities under given labels,\" it derives the theorem that multimodal expected loss is the convolution of single-modal loss and scale-shifted kernel (Theorem 1), and the theorem that multimodal loss results in a smoother landscape (Theorem 2, reflected in the upper bound of the Hessian spectral norm and the effect of low-pass filtering in the frequency domain). Based on this theory, the paper further proposes a Distributional Multimodal Learning (DML) strategy, replacing traditional fixed-point pairing (SML) with random modal pairing within the same label space to enhance the convolutional smoothing effect. Finally, the results are validated on four multimodal datasets, including Kinetics-Sounds and AVMNIST. The results show that DML has superior performance (e.g., Kinetics-Sounds accuracy). The DML method outperforms SML and unimodal methods in several aspects,"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear and convincing.\n\n2. This paper fills the theoretical gap in multimodal learning; a rigorous \"convolutional smoothing\" framework is constructed.\n\n3. The proposed DML is simple and easy to follow."}, "weaknesses": {"value": "1. The assumption 2 of conditional independence seems impossible in multimodal learning. The multimodal data capture from the same object is naturally dependent. Especially, the multimodal image data, such as RGB and IR, when the position of the object in the RGB changes, it will also change in the IR image. Similarly, in video-audio data, where the visual action and sound are highly synchronized, a strong dependency still exists even after a label is given.\n\n2. Besides, the ATI assumption holds only in shallow fusion architectures such as additive fusion and simple splicing + MLP, and its \"approximate translation invariance\" is difficult to satisfy for current mainstream architectures with stronger nonlinearity such as attention fusion and cross-modal Transformer.\n\n3. The performance gains of DML are counterintuitive. If intra-class random perturbation can bring performance gains, then there is no need to collect matching multimodal data. Just collect arbitrary unimodal data, classify it, and then randomly match within the same class.\n\n4. How to extend DML to the task with three modalities?"}, "questions": {"value": "See the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lvChjGWYPi", "forum": "cYZkZp3m8F", "replyto": "cYZkZp3m8F", "signatures": ["ICLR.cc/2026/Conference/Submission12001/Reviewer_EYm2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12001/Reviewer_EYm2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830838977, "cdate": 1761830838977, "tmdate": 1762922991682, "mdate": 1762922991682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examines multimodal learning from the perspective of **loss landscape smoothness**. The authors argue that combining modalities implicitly produces a *convolutional smoothing* effect on the loss surface, leading to flatter minima and improved generalization. They formalize this intuition through two theorems showing that multimodal losses can be expressed as convolutions of unimodal losses and that the resulting Hessian has a smaller spectral norm. Building on this idea, they propose **Distributional Multimodal Learning (DML)**, which randomly pairs modalities within the same class to further enhance smoothness. Experiments on several small- to medium-scale multimodal datasets (Kinetics-Sounds, AVMNIST, CREMA-D, and UPMC-Food101) show modest improvements in both accuracy and flatness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Section 3.2 presents interesting and well-grounded theoretical results showing that multimodal losses tend to be smoother than unimodal ones. The argument is supported by clear intuition in the frequency domain and effectively summarized in Figure 2.  \n2. The experimental setup includes multiple datasets and evaluation metrics, demonstrating the benefits of multimodal training over unimodal baselines and, additionally, of DML over standard multimodal learning (SML).  \n3. The main practical contribution — the DML framework — appears to be novel despite its conceptual simplicity. It provides a straightforward and elegant form of data augmentation that is easy to implement and intuitively well motivated."}, "weaknesses": {"value": "## Major  \n1. **Weak connection between theory and method.**  \n   Sections 3.2 and 3.3 feel somewhat disconnected. If DML is designed to improve the smoothness of the loss, this connection should be made more explicit. At present, it is unclear *why* random pairing within a class should theoretically enhance smoothness. Providing further intuition or a formal link between the proposed theory and the DML formulation would considerably strengthen the paper.  \n\n2. **Limited baseline comparison.**  \n   While the experimental setup covers several datasets and metrics, the baseline selection is relatively narrow. It would be important to compare against well-established methods known to improve generalization or flatness, such as:  \n   - **Stochastic Weight Averaging (SWA)** [1]  \n   - **Sharpness-Aware Minimization (SAM)** [2]  \n   - Regularization approaches like **Dropout** [3] or **Label Smoothing** [4]  \n   Including these would provide a stronger empirical foundation for the claims about smoothing and generalization.  \n\nI find the theoretical perspective and the overall idea of the paper both interesting and promising. However, the work needs to improve in terms of formal rigor—particularly by addressing the two key methodological issues mentioned above: (i) establishing a clearer connection between the theoretical analysis and the proposed DML method, and (ii) providing stronger comparisons against well-known baselines. These aspects are pivotal for ensuring the coherence and credibility of the contribution. If these limitations are addressed, I would be willing to increase my rating.\n\n---\n\n## Minor  \n1. *Assumption 1* is effectively a **definition**, though it is presented as an assumption. The wording should reflect this distinction more clearly.  \n2. In Table 1, the title should read **“Classification accuracy on multimodal datasets”** rather than “Classification results on multimodal datasets.”"}, "questions": {"value": "1. Would combining DML with some of the baseline methods mentioned above (e.g., SAM, SWA, Dropout, or Label Smoothing) further improve performance?  \n2. Do you believe that DML’s improvements primarily stem from enhanced smoothing, or could they be explained simply as a stronger form of data augmentation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uOj4j14kiP", "forum": "cYZkZp3m8F", "replyto": "cYZkZp3m8F", "signatures": ["ICLR.cc/2026/Conference/Submission12001/Reviewer_LpsV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12001/Reviewer_LpsV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831167824, "cdate": 1761831167824, "tmdate": 1762922991244, "mdate": 1762922991244, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel theoretical perspective explaining why multimodal learning (MML) typically outperforms unimodal learning. The authors' core argument is that multimodal learning introduces a **“Convolutional Smoothing”** effect, leading to a flatter loss landscape, which correlates with improved generalization and robustness.\n\nBuilding on this theory, the paper further proposes a training strategy called **“Distributional Multimodal Learning” (DML)**. This approach avoids fixed modality pairings during training, instead performing random pairings within the same hypothesis space.\n\nExperimental results across multiple datasets (e.g., Kinetics-Sounds, AVMNIST) demonstrate that multimodal learning (MML) indeed yields a flatter loss landscape than unimodal learning, while DML achieves an even flatter landscape than MML, delivering higher performance and robustness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Establishing a link between MML and loss landscape smoothness, and attempting to provide a mathematical explanation through **“convolutional smoothing”** (Theorem 1 and Theorem 2) offers a novel perspective.\n\n2. The paper provides substantial experimental evidence (performance, robustness, loss visualization, Hessian eigenvalues) supporting its core claim: MML → smoother landscape → better performance.\n\n3. DML is a simple, intuitive, and effective strategy that consistently outperforms standard SML (fixed pairing) across all experiments."}, "weaknesses": {"value": "1. The paper's theoretical foundation rests on overly strong assumptions. Its theory is based on the **Assumption 1 (Approximate Translation-Invariance of Fusion Networks)**. In Appendix C.2, the authors themselves acknowledge that this assumption is only a first-order Taylor approximation for non-linear MLPs and may not hold for attention mechanisms. This could render the theoretical framework fundamentally inapplicable to current state-of-the-art fusion models based on Transformers and Cross-Attention.\n\n\n2. Suspected paste error on page 7, lines 351-352: “...we additionally report the ratio between **thewe also report the ratio between the** largest a”\n\n3. Bold formatting in Table 2 is confusing: some rows have both Modality i and Modality j with bolded values (**CREMA-D**), while others do not. Notably, for **UPMC-Food101**, the value for **λ∗ under Modality j** is 1.4935, which is the best in its column but is not bolded."}, "questions": {"value": "1. The proposed DML (Random Pairing) is analogous to a data augmentation technique. The improved results from DML may stem from the data augmentation effect of random pairing, which significantly increases the number of training pairs, rather than the theoretical mechanism of distributional alignment.\n\n2. **Assumption 2** requires xi and xj to be conditionally independent given y. Under this independence, SML and DML should sample from the same distribution. SML samples from the true joint conditional probability distribution p(x_i,x_j|y), while DML independently samples from the marginal conditional probability distributions p(x_i|y) and p(x_j|y). If **Assumption 2** holds, then p(x_i|y)p(x_j|y)=p(x_i,x_j|y), meaning the sampling distributions are identical. If SML and DML share the same distribution, their results should be similar. However, experiments show DML significantly outperforms SML. This suggests the conditional independence assumption may not hold in practice, which could challenge the theoretical framework."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3j6EG0qatt", "forum": "cYZkZp3m8F", "replyto": "cYZkZp3m8F", "signatures": ["ICLR.cc/2026/Conference/Submission12001/Reviewer_9cP9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12001/Reviewer_9cP9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009595878, "cdate": 1762009595878, "tmdate": 1762922990817, "mdate": 1762922990817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overview of Manuscript Revisions"}, "comment": {"value": "Dear Reviewers,\n\nWe truly appreciate your constructive and insightful feedback. We have carefully revised the original paper based on your thoughtful comments. All revised text in the manuscript has been marked in $\\textcolor{teal}{\\textbf{teal}}$ for the clarity:\n\n### **For Reviewer 9cP9**\n\n- We have updated $\\textcolor{teal}{\\textbf{Table 11}}$ to justify Assumption 1 and added a section on Cross-Attention to demonstrate linearity in complex networks. This content has been relocated from Appendix C.2 to $\\textcolor{teal}{\\textbf{Appendix D.1}}$. (**Weakness 1**)\n- We have added $\\textcolor{teal}{\\textbf{Appendix D.2}}$ to include a discussion regarding Assumption 2. (**Question 2**)\n- We have corrected typos in $\\textcolor{teal}{\\textbf{lines 351-352}}$ and $\\textcolor{teal}{\\textbf{Table 2}}$. (**Weaknesses 2, 3**)\n- We have added a section on Data Augmentation (DA) in $\\textcolor{teal}{\\textbf{Appendix C.2}}$. (**Question 1**)\n\n### **For Reviewer LpsV**\n\n- We have addressed **Weakness 1: Weak connection between theory and method** in an *Official Comment*.\n- We have added $\\textcolor{teal}{\\textbf{Appendix C.3}}$ to include a comprehensive comparison between flatness-aware approaches and DML. (**Weakness 2 and Question 1**)\n- We have added our discussion on Data Augmentation in $\\textcolor{teal}{\\textbf{Appendix C.2}}$. (**Question 2**)\n\n### **For Reviewer EYm2**\n\n- We have provided an *Official Comment* regarding the concern on **Weakness 3: Intra-class random perturbation**.\n- We have added $\\textcolor{teal}{\\textbf{Appendix D.2}}$ for a detailed discussion on the validity of Assumption 2. (**Weakness 1**)\n- We also updated $\\textcolor{teal}{\\textbf{Appendix D.1}}$ (previously Appendix C.2) to provide justification for Assumption 1. (**Weakness 2**)\n- We have added $\\textcolor{teal}{\\textbf{Appendix C.4}}$ to present the performance results on datasets with three modalities. (**Weakness 4**)\n\n### **For Reviewer Hoxa**\n\n- We have addressed the primary concerns regarding **Weakness 1 and Weakness 2** in an *Official Comment*, referencing relevant sections of our manuscript.\n- We have included a detailed analysis and justification for Assumption 2 in $\\textcolor{teal}{\\textbf{Appendix D.2}}$. (**Question 1**)\n\n\n&nbsp;\n\nAgain, we sincerely thank all reviewers for the constructive discussions and insightful comments. We truly appreciate your efforts, and we believe these feedbacks and discussions have significantly strengthened this work."}}, "id": "EQLjM6umD0", "forum": "cYZkZp3m8F", "replyto": "cYZkZp3m8F", "signatures": ["ICLR.cc/2026/Conference/Submission12001/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12001/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission12001/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763650542734, "cdate": 1763650542734, "tmdate": 1763650542734, "mdate": 1763650542734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}