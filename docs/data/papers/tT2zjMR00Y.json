{"id": "tT2zjMR00Y", "number": 3056, "cdate": 1757323841846, "mdate": 1763731207547, "content": {"title": "Binding Mode Matters: Residue-Guided Drug Discovery via Explorative Preferences", "abstract": "The discovery of novel hit or lead molecules requires navigating a vast chemical space to identify compounds with optimal binding modes, which are typically unknown beforehand. Despite various generative approaches, they have predominantly relied on optimizing a monolithic scalar docking score to guide generation, masking the distinct contributions of key binding determinants.\nIn this work, we introduce a paradigm shift by formulating target-based drug design as a multi-objective exploration task, where each objective explicitly corresponds to enhancing interactions with a specific key residue. To this end, we introduce **BindMol**, a novel generative framework that integrates a fragment-based generator with a customized multi-objective reinforcement learning algorithm. By incorporating explorative preferences during training, our approach efficiently uncovers molecules with distinct and desirable binding profiles.\nEmpirical evaluations demonstrate that **BindMol** facilitates the discovery of structurally novel, high-affinity compounds across five protein targets and establishes new state-of-the-art records on the multi-property optimization tasks in GuacaMol benchmarks, thereby providing a versatile paradigm for goal-directed drug discovery.", "tldr": "", "keywords": ["fragment-based drug discovery", "reinforcement learning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fb8dd4b4cfe02cb79996919964bf741034b4c631.pdf", "supplementary_material": "/attachment/165c1d881311330392af4bba8ba50dc0f121dcb8.zip"}, "replies": [{"content": {"summary": {"value": "Through this paper, the authors propose BindMol, a fragment-based molecule generation framework using a multi-objective RL algorithm. Specifically, the authors newly propose incorporating explorative preferences during training. The experiments show that BindMol can discover molecules with good binding profiles."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The authors provided the codebase.\n- The proposed formulation that views target-based drug discovery as a multi-objective optimization problem, with each objective corresponding to a key residue within the binding pocket, is interesting and reasonable.\n- The proposed BindMol shows good performance on various benchmarks."}, "weaknesses": {"value": "Weaknesses\nI will combine the *Weaknesses* section and the *Questions* section. My concerns are as follows:\n- The main weakness of this paper is its weak novelty. As the authors mentioned in lines 56~58, the BindMol framework consists of three key components: action space, reward function, and the RL algorithm. For the action space, BindMol adopts FREED [1]. Section 4.1 actually should actually be placed in Preliminaries section and is not an invention of this work. BindMol's reward function design (Section 4.3) is a heuristic that relies on the PLIP tool and docking scores, and it cannot be considered a significant contribution from an ML perspective. The only main contribution of this work is Envelope SAC, a multi-objective RL algorithm that defines a preference-aware Bellman operator and a vectorized Q-function (Section 4.2). However, the central idea is to integrate the envelope-based update mechanism is very similar to MORL [2]. Overall, I am not convinced that this work provides a new approach compared to previous methods in the domain.\n- In the GuacaMol MPO experiment (Section 5.2, Table 4), SOTA molecular optimization baselines such as GenMol [3] and Genetic GFN [4] are missing. Comparisons with these baselines are necessary for the results to be considered meaningful.\n\n---\n\n**References:**\n\n[1] Yang et al., Hit and lead discovery with explorative rl and fragment-based molecule generation, NeurIPS, 2021.\n\n[2] Yang et al., A generalized algorithm for multi-objective reinforcement learning and policy adaptation, NeurIPS, 2019.\n\n[3] Lee et al., GenMol: A Drug Discovery Generalist with Discrete Diffusion, ICML 2025.\n\n[4] Kim et al., Genetic-guided GFlowNets for Sample Efficient Molecular Optimization, NeurIPS 2024."}, "questions": {"value": "Please see the *Weaknesses* section for my main concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "39lMoGYgaf", "forum": "tT2zjMR00Y", "replyto": "tT2zjMR00Y", "signatures": ["ICLR.cc/2026/Conference/Submission3056/Reviewer_dzp3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3056/Reviewer_dzp3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619739059, "cdate": 1761619739059, "tmdate": 1762916532343, "mdate": 1762916532343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "Dear Reviewers and Chairs,\n\nWe would like to thank all reviewers very much for their extensive reviews and constructive critiques, which are invaluable for improving our manuscript. We are encouraged that reviewers highlight several positive aspects of our work, including the conceptual novelty of our problem formulation (Reviewers `zauj`, `HeNm` and `dzp3`), the breadth and competitiveness of our empirical evaluation (Reviewers `Utui`, `dzp3` and `zauj`), and the technical contribution of our proposed RL algorithm (Reviewer `Utui`). \n\nHowever, we notice that the novelty and contribution have not been fully captured, leading to potential misunderstandings of some reviewers. We therefore take this opportunity to clearly articulate the core innovations of **BindMol**.\n\n **(1) Novel problem formulation.**\nTo the best of our knowledge, BindMol is the first molecular generation framework that explicitly accounts for the *diverse binding modes between ligands and a target*. This is a biologically grounded phenomenon repeatedly validated in drug discovery practice, where ligands with distinct binding poses may exhibit differentiated functional, selectivity, and developability profiles [1]. Existing molecular generation approaches typically overlook this intrinsic diversity and instead assume a single binding configuration. By contrast, **our formulation treats binding-mode diversity as a *first-class modeling objective***, which opens up a new direction for structure-based molecule design. We believe this conceptual shift itself constitutes a significant and underexplored innovation.\n\n[1] Differential glp-1r binding and activation by peptide and non-peptide agonists. Molecular Cell, 2020.\n\n**(2) First integretion of vectorized MORL in molecular generation.**\n Current multi-objective molecular generation approaches predominantly rely on Bayesian optimization or on scalarization heuristics that reduce multiple objectives to a single weighted score. Our work is, to our knowledge, the first to explore a principled integration of *vectorized multi-objective preference signals directly within an RL framework* for molecular generation. This enables fine-grained preference-aware optimization and avoids the limitations of fixed scalarization, thereby introducing a new paradigm for controllable multi-objective molecule design.\n\n**(3) Technical novelty of the Envelope SAC algorithm.**\n We would also like to clarify the misunderstanding that Envelope SAC is merely a combination of the envelope update and SAC. The original envelope operator was developed in the context of value-based deep Q-learning, where the policy is implicit and no explicit actor is optimized. Extending this concept to an actor–critic setting is fundamentally non-trivial: both the critic and the policy must be preference-aware, and naïve adaptation leads to inconsistent optimization objectives. Our approach proposes **a unified framework that jointly optimizes *multi-preference-aware critics and actors*, and introduces an exploration mechanism tailored for preference diversity.** \n\nWe acknowledge that our initial writing placed substantial emphasis on prior work that inspired certain components, which may have unintentionally conveyed an impression of incremental improvement. In the `Section 1` of revised version, we have refined and highlighted the specific conceptual and technical contributions to avoid such ambiguity. \n\nFinally, we appreciate all your helpful comments that strengthen the quality and clarity of our work. We also provide detailed point-to-point response to other concerns and questions in the following responses. And we look forward to engaging in an active and productive discussion with the reviewers. If you have any other questions, please feel free to let us know.\n\nBest regards,\n\nThe Authors"}}, "id": "jVtTnP3JIk", "forum": "tT2zjMR00Y", "replyto": "tT2zjMR00Y", "signatures": ["ICLR.cc/2026/Conference/Submission3056/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3056/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3056/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763731804101, "cdate": 1763731804101, "tmdate": 1763731804101, "mdate": 1763731804101, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BindMol, a fragment based molecular generation framework for structure guided drug design that treats binding as a multi objective reinforcement learning problem. Instead of optimizing a single docking score, the method defines residue level rewards that capture interactions with individual protein residues and trains a policy using an Envelope Soft Actor Critic algorithm to explore diverse binding preferences. The approach constructs molecules by sequentially attaching fragments and leverages a dynamic vocabulary to expand chemical space during training. Experiments on five protein targets and multi property GuacaMol benchmarks show improved hit rates, docking scores, and chemical diversity compared to strong baselines, indicating that residue guided rewards can promote diverse binding modes and high affinity candidates"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces a biologically motivated multi objective formulation for structure based molecular generation, where residue level interaction signals replace a single scalar docking score, providing a more interpretable and controllable reward structure.\n- The Envelope SAC algorithm with preference based exploration is a technically novel component that extends entropy regularized RL to vector valued rewards and empirically improves Pareto frontier coverage in binding mode space.\n- Experimental evaluation is broad and competitive, covering five protein binding tasks and seven GuacaMol multi property benchmarks, and demonstrating consistent state of the art performance in affinity, novelty, and diversity metrics."}, "weaknesses": {"value": "- The connection between the scalar reward definition in Section 4.3 and the multi-objective formulation in Section 4.2 remains ambiguous. It is not clearly explained how the final scalar reward integrates into the Envelope SAC optimization process.\n- The residue-based reward design merely counts the number of interactions without reflecting residue-specific importance or interaction strength. This simplification may limit the model’s ability to capture nuanced biochemical factors in binding.\n- Several mathematical symbols and operators (e.g., ω*, Hα, Qθ) are introduced without full contextual definition or consistent usage, which may hinder the theoretical clarity and reproducibility of the proposed method.\n- Although experiments support that multi-residue optimization improves diversity, the paper does not clearly justify why interacting with more residues should yield better ligand quality or affinity. The underlying biochemical rationale remains underexplored.\n- The Envelope SAC algorithm involves solving an additional optimization (arg max over ω) during training, but the paper does not quantify the resulting computational overhead or its impact on convergence time.\n- In the experimental section, it is not described how the preference vector ω is set during inference, leaving unclear how the model’s multi-objective nature is actually utilized when generating final molecules."}, "questions": {"value": "- The reward function counts PLIP-detected interactions equally across residues. Do the authors observe cases where increasing the number of weak or geometrically marginal interactions leads to inflated reward? Have they considered weighting interaction types by estimated energetic contribution?\n- The model relies on static docking poses to compute residue-level interactions. How do the authors mitigate the risk that suboptimal or strained docking poses lead to spurious interactions being rewarded?\n- The dynamic fragment vocabulary is introduced as a novelty. To isolate its contribution, could the authors provide ablation results comparing a fixed-vocabulary variant with identical reward shaping?\n- Multi-objective RL methods often face challenges with instability as the number of objectives grows. The paper cites settings with five to thirty residues. Could the authors report performance as a function of the number of objectives, or provide guidance on stability and hyperparameter sensitivity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wvBXmiwqMb", "forum": "tT2zjMR00Y", "replyto": "tT2zjMR00Y", "signatures": ["ICLR.cc/2026/Conference/Submission3056/Reviewer_Utui"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3056/Reviewer_Utui"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894819173, "cdate": 1761894819173, "tmdate": 1762916531917, "mdate": 1762916531917, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors introduce BindMol, a novel framework for multi-objective RL in structure-based drug design. Unlike traditional generative models that optimize a single scalar docking score, BindMol decomposes the reward into residue-level objectives, encouraging the generation of molecules with diverse binding modes to the same protein target. The model uses a fragment-based molecular generator and a new RL algorithm called Envelope SAC, which learns a convex envelope over vectorized Q-values to balance multiple interaction objectives efficiently.\n\nContributions:\n\nReformulates target-based molecular design as a multi-objective optimization problem focused on residue-level interactions.\n\nProposes Envelope SAC, a preference-aware RL algorithm for optimizing multiple objectives jointly.\n\nIntegrates PLIP-based residue-level rewards with docking scores for richer feedback.\n\nDemonstrates good performance across five protein targets and seven GuacaMol benchmark tasks, with improved hit rates, diversity, and binding affinity compared to prior RL and generative models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Originality:\nThe paper introduces a conceptually novel formulation of target-based drug design as a multi-objective optimization problem over residue-level interactions rather than a single docking score, and a novel Envelope SAC algorithm.\n\nQuality:\nThe methodology is technically sound and well-motivated. The empirical validation is in alignment with other studies in molecular generation domain. \n\nClarity:\nThe paper is clearly written and logically structured and generally easy to follow."}, "weaknesses": {"value": "The technical novelty of the proposed Envelope SAC algorithm, from the perspective of the ICLR machine learning audience, appears somewhat limited. A more thorough discussion of prior work in multi-objective reinforcement learning including established formulations and optimization strategies would help contextualize the contribution. Furthermore, benchmarking against existing multi-objective RL methods would strengthen the paper’s empirical claims and clarify the specific advantages introduced by the proposed operator. Finally, it would be valuable to know whether the authors have compared their hit rates (Tables 1–3) with recent results such as Pandey et al., “Pretraining Generative Flow Networks with Inexpensive Rewards for Molecular Graph Generation,” arXiv:2503.06337 (2025), which reports strong performance on molecular design tasks for the same targets as considered by the authors. Such comparisons could provide a clearer assessment of BindMol’s relative progress over recent generative paradigms."}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0GOkqYe1x1", "forum": "tT2zjMR00Y", "replyto": "tT2zjMR00Y", "signatures": ["ICLR.cc/2026/Conference/Submission3056/Reviewer_HeNm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3056/Reviewer_HeNm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935412404, "cdate": 1761935412404, "tmdate": 1762916531246, "mdate": 1762916531246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents BindMol, a new reinforcement learning framework for structure-based drug design that reformulates molecule generation as a multi-objective optimization problem. Instead of optimizing a single scalar docking score, BindMol defines residue-level rewards based on protein–ligand interaction counts (via PLIP) and introduces Envelope Soft Actor-Critic (Envelope SAC) to explore trade-offs among multiple objectives (binding residues). Experiments on five protein targets and the GuacaMol multi-property benchmark demonstrate that BindMol achieves state-of-the-art performance, generating novel and diverse compounds with improved docking scores and Pareto coverage."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper clearly identifies the limitation of scalar docking-based RL and reframes drug discovery as a multi-objective exploration problem, aligning with the biological reality of residue-specific interactions.\n- BindMol consistently outperforms a wide range of strong baselines across multiple targets, with substantial gains in both novel hit ratio and binding diversity.\n- The use of explorative preferences effectively improves the coverage of chemical space and encourages multiple binding modes, as supported by hypervolume and case study visualizations."}, "weaknesses": {"value": "- The integration with fragment-based generation and residue-level rewards, while well motivated, combines existing ideas rather than introducing a clearly novel modeling mechanism.\n- The maximization over ω′ in Equation (8) requires either dense sampling or approximation; the paper does not explain how ω⋆ is computed efficiently or whether it introduces bias.\n- The dynamic fragment vocabulary update may leak information from test targets if not strictly separated"}, "questions": {"value": "- How does the computational efficiency of BindMol compare to other baseline methods, particularly in terms of training time and docking evaluation cost?\n- Since per-residue interaction rewards may incentivize generating larger molecules to form more contacts, how does the molecular weight distribution of samples produced by BindMol compare to those of the baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nc71vNGT4q", "forum": "tT2zjMR00Y", "replyto": "tT2zjMR00Y", "signatures": ["ICLR.cc/2026/Conference/Submission3056/Reviewer_zauj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3056/Reviewer_zauj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762366283685, "cdate": 1762366283685, "tmdate": 1762916530839, "mdate": 1762916530839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}