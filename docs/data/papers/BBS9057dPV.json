{"id": "BBS9057dPV", "number": 1392, "cdate": 1756879250270, "mdate": 1759898211098, "content": {"title": "SteinDiff: Resolving the Contractivity Trap via Reference-free Stein Regularization", "abstract": "A fundamental tension arises when accelerating diffusion-based generative models via their deterministic probability flow ordinary differential equation (PF-ODE)  paths, which we formally identify as the *contractivity trap*: efficient inference requires large step sizes, but stable convergence demands strong contractivity that limits model expressiveness. This results in error accumulation in inference as contractivity weakens. In this work, we propose a principled inference approach, called *SteinDiff*, that relaxes the contractivity constraints through reference-free Stein adaptive regularization. Specifically, drawing on Krasnosel'skiƒ≠-Mann theory, we reformulate the ODE update to interpolate between predictions and current states.  Importantly, we contribute closed-form optimal regularization parameters via Stein's identity,  which is theoretically grounded in the continuous SDEs theory of  diffusion models. Our analytical approach eliminates the need for ground truth data to adapt to the local geometry of the data distribution while preserving the expressiveness of the vanilla model. Theoretically, our approach not only relaxes the strict contractivity requirements for robust convergence but also reveals a principle behind the stability of state-of-the-art (SOTA) pre-conditioned parameterizations. Practically, we offer a reference-free solution that reduces the risk of mode collapse in large-step inference. Extensive experiments validate our theoretical framework and demonstrate significant gains in generative inference.", "tldr": "We resolve the fundamental tension between stability and expressiveness in accelerating diffusion models by introducing a principled method, SteinDiff, that leverages closed-form adaptive regularization to achieve accurate and robust generation.", "keywords": ["Contractivity Trap; Reference-free Regularization; Stein's Identity; Closed-Form Optimization"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d9657b24fffbe0121b7b149f87431e97b708214b.pdf", "supplementary_material": "/attachment/dfdf975137dc1d3a800f5640551939ed660848d8.pdf"}, "replies": [{"content": {"summary": {"value": "The paper addresses a fundamental limitation in diffusion model inference known as the contractivity trap. This trap arises from the tension between efficiency (large integration steps), expressiveness (complex score networks), and stability (the need for contractive updates in ODE-based sampling). While contractivity is a sufficient condition for convergence, this assumption fails for expressive modern diffusion models, leading to instability and degraded sample quality at low step counts. To overcome this, they propose SteinDiff, a new inference algorithm that enforces convergence guarantees leveraging Krasnosel‚Äôskiƒ≠‚ÄìMann fixed-point theory. Specifically, the update rule is re-expressed as a regularization of the standard ODE step with parameters being computed in closed form by leveraging the Stein Identity.  Experiments on standard benchmarks (CIFAR-10, ImageNet 64√ó64) show consistent improvements in FID and FD-DINOv2 scores under low-NFE conditions, with modest computational overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) Replacing the Banch theorem with Krasnosel‚Äôskiƒ≠‚ÄìMann to enable larger step sizes and improved convergence speed is novel and well motivated\n(2) Deriving a closed-form adaptive regularization parameters by leveraging the Stein Identity is really nice\n(3) The experiments show meaningful gains (e.g., FID improvements) in low-NFE (number of function evaluations) regimes on standard benchmarks such as CIFAR-10 and ImageNet."}, "weaknesses": {"value": "(1) Motivation and Illustration: To strengthen the motivation, consider adding plots that illustrate how a large Lipschitz constant constrains the step size on Cifar10 or ImageNet. Such visualizations would clarify the ‚Äúcontractivity trap‚Äù and emphasize why small steps are necessary for stability.\n(2) Experimental Scope: Most experiments are limited to CIFAR-10 and ImageNet-64√ó64. These datasets are relatively small; extending evaluations to higher-resolution or larger-scale settings would significantly reinforce the paper‚Äôs claims about generality and scalability.\n(3) Scalability and Clarity: The closed-form expression for Œ≥ (Eq. 12) depends on the trace approximation of \\nabla u_k, estimated via the Hutchinson method (Algorithm 1). This approach may face scalability issues in high dimensions since only a limited number of probe vectors ùë£ are used. Moreover, several symbols in Algorithm 1 appear without prior definition in the text‚Äîthese should be clearly introduced for readability.\n(4) Formatting: conclusion should show on page 9"}, "questions": {"value": "(1) Could the authors provide plots illustrating that current diffusion models exhibit large Lipschitz constants restricting the allowable step size and leading to instability?\n\n(2) Given the limited scalability of the \\gamma solution due to the trace approximation, wouldn't this approach be more suited for latent diffusuion models? Can you show results on large scale datasets? When does the approach break because of this approximation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OdjzL7wfbm", "forum": "BBS9057dPV", "replyto": "BBS9057dPV", "signatures": ["ICLR.cc/2026/Conference/Submission1392/Reviewer_iXw4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1392/Reviewer_iXw4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760865621583, "cdate": 1760865621583, "tmdate": 1762915758846, "mdate": 1762915758846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper attributes inference errors in diffusion models to the contractive assumption (Lipschitz constant < 1) imposed on the discretization operator. This assumption arises from constructing the operator via the Banach‚ÄìPicard theorem. To address this limitation, the authors propose a regularized discretizer based on Krasnosel‚Äôskii‚ÄìMann theory, which removes the need for contraction. However, the regularized formulation introduces the challenge of selecting an optimal interpolation weight. By casting this as an optimization problem, the authors show that the optimal weight admits a closed-form solution when applying Stein‚Äôs identity. The resulting algorithm is termed SteinDiff."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a rigorous and well-structured critique of the so-called contractivity trap in DM inference.\n - The adoption of the Krasnosel‚Äôskii‚ÄìMann (KM) framework provides a theoretically sound justification for why the approach by Karras et al. (2022) performs well.\n - The paper offers comprehensive error analysis, convergence results, and compelling empirical evidence supporting the proposed method.\n\nOverall, I found the paper technically solid and enjoyable to read."}, "weaknesses": {"value": "It is not clear that relaxing the operator from contractive ($L<1$) (from Banach‚ÄìPicard theorem) to nonexpansive ($L \\leq 1$) in Theorem 4.4 is sufficient to accommodate the Lipschitz constant of the data predictive function. Further clarification or justification of this transition would strengthen the argument.\n\n#### Minor Comments\n\n- Several symbols are undefined, including $\\alpha$ and $\\sigma_t$ (and by extension $\\sigma_k$ and $\\sigma_s$). A notation section in the appendix would fix this if space is a problem.\n- The term non-expansive mapping is not formally defined.\n- The acronym DM is first introduced in Section 2 but used earlier in Section 1.\n- Figures 2 and 3 require more descriptive captions, as they are difficult to interpret based on the current text.\n- Line 215 is missing a \"to\" as in \"we shift to the design\" and a \"the\" before contractive trap."}, "questions": {"value": "* Why does the relaxation from $L < 1$ to $L \\leq 1$ suffice to guarantee convergence of DM inference under the update of Eq. (7) with $Œ≥^*$ from Eq. (12)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F4IXEgoVrI", "forum": "BBS9057dPV", "replyto": "BBS9057dPV", "signatures": ["ICLR.cc/2026/Conference/Submission1392/Reviewer_XG3j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1392/Reviewer_XG3j"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761231943495, "cdate": 1761231943495, "tmdate": 1762915758740, "mdate": 1762915758740, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Stable convergence for ODE flow methods during inference/generation for diffusion models typically requires taking small enough step sizes so that the maps are contractive, which increases computation time. The authors refer to this as the \"contractivity trap\". Can one speed up inference without in spite of this? The authors propose SteinDiff, which allows fast inference without inheriting the problems of non-contractive maps, by interpolating with the previous iterate (as suggested by Krasnosel‚ÄôskiÀòƒ±-Mann theory). Practically, the authors provide a way to compute the optimal parameters for this regularization from data using Stein's identity. Experiments on show that it improves image generation in the low NFE (Number of Function Evaluations) regime on CIFAR-10 and ImageNet."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Speeding up diffusion models while preserving generation quality is an important question. The algorithm is easy to implement, and is a purely inference-time modification. It shows improvements on experiments in a low NFE regime."}, "weaknesses": {"value": "In general, the conceptual explanations/discussions are loose and don't seem supported by theory. In particular, it is not clear to me how the mathematical theory presented (Theorem 4.4 based on KM theory) justifies the actual algorithm, which calls the method into question. The connection between the theory and the actual algorithm is missing. See my key question below."}, "questions": {"value": "The update operator $T_\\theta$ implicitly depends on the start and end time $s$ and $t$ (which is unfortunately suppressed in the notation), so during inference, a sequence of these operators which are *different* are composed with each other. However, the theorems about convergence to a fixed point relies on a *fixed* map $T$, so it is unclear to me how they apply. This is a major confusion for me. Please detail carefully in which parts you are considering different $T$'s, and which part you are considering the same $T$, because it is not valid to apply fixed-point theory when the map is changing.\n\nIt is unclear what the authors mean by \"expressiveness\", and especially by the claim that higher expressiveness requires large Lipschitz constant in the T map. This appears to me to be a misunderstanding resulting from conflating a step of discretization (where we want the added update to have Lipschitz constant <1) with the entire map itself (which can have large Lipschitz constant even though all updates are small). Please clarify.\n\nMinor: \nIn Algorithm 1, the $u_k$ are not defined.\nAppendix A: \"Detailed\" -> \"Details\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0tsLGDNrlB", "forum": "BBS9057dPV", "replyto": "BBS9057dPV", "signatures": ["ICLR.cc/2026/Conference/Submission1392/Reviewer_ubxb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1392/Reviewer_ubxb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933051919, "cdate": 1761933051919, "tmdate": 1762915758627, "mdate": 1762915758627, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}