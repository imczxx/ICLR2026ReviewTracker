{"id": "K8TEFs6aFn", "number": 21679, "cdate": 1758320486639, "mdate": 1759896909079, "content": {"title": "A Random Matrix Perspective on the Consistency of Diffusion Models", "abstract": "Diffusion models trained on different, non-overlapping subsets of a dataset often produce strikingly similar outputs when given the same noise seed. We trace this consistency to a simple linear effect: the shared Gaussian statistics across splits already predict much of the generated images. To formalize this, we develop a random matrix theory (RMT) framework that quantifies how finite datasets shape the expectation and variance of the learned denoiser and sampling map in the linear setting. For expectations, sampling variability acts as a renormalization of the noise level through a self-consistent relation $\\sigma^2 \\mapsto \\kappa(\\sigma^2)$, explaining why limited data overshrink low-variance directions and pull samples toward the dataset mean. For fluctuations, our variance formulas reveal three key factors behind cross-split disagreement: \\textit{anisotropy} across eigenmodes, \\textit{inhomogeneity} across inputs, and overall scaling with dataset size. Extending deterministic-equivalence tools to fractional matrix powers further allows us to analyze entire sampling trajectories. The theory sharply predicts the behavior of linear diffusion models, and we validate its predictions on UNet and DiT architectures in their non-memorization regime, identifying where and how samples deviates across training data split. This provides a principled baseline for reproducibility in diffusion training, linking spectral properties of data to the stability of generative outputs.", "tldr": "We show that diffusion model consistency across data splits arises from shared Gaussian statistics. Random matrix theory gives sharp predictions for linear diffusion and explains where deep models diverge.", "keywords": ["random matrix theory", "diffusion model", "flow matching", "probability flow ode", "deterministic equivalence", "Balakrishnan identity", "consistency", "bias variance"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b61478205ae5ec3694e8fbf10dad666cd4268d1a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the consistency of linear (Gaussian) denoisers across distinct training datasets, that is: how close will be samples generated using the same latent seed by the different models. The analysis is done through the lens of spectral theory of Bach (2024), where denoisers are treated as operators acting on the sample space. It is shown that the expected denoiser converges to the true denoiser in some weak sense (where both dimension and number of samples tend to $\\infty$), where noise scale is re-noarmalized to absorb random fluctuations, regardless of the training data split. The conclusion is that linear components with small eigenvalues are pulled towards the true data mean. The *variance* of this desnoiser is decomposed into an \"anisotropic\" component depending on the eigenvector direction and an \"inhomogeneous\" part depending on initial sample deviation from center. It is then claimed that deep diffusion models exhibit the same behavior: as number of samples grows, models trained on distinct split of the training set produce similar samples."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The presentation is sufficient for a rather technical subject. Presenting results for \"one-step\" denoisers (Sec. 4) is an easy to follow introduction to the results in Sec. 5 for the Wiener filter.\n\n2. The results for linear regressors (Sec.4) although adopted from Bach(2024) seems to yield novel and non-trivial theoretical contributions (Propostions 1 and 2). \n\n3. The results in Sec 5. are novel as well."}, "weaknesses": {"value": "Overall, I think that the contribution to linear theory alone could be substantial enough to approve acceptance. However, I find the general claims about diffusion models (starting with the title), arguably, not convincing enough. More specifically:\n\n1. Starting with  the \"MOTIVATING EMPIRICAL OBSERVATION\" part, (Sec.3, Fig.1) is not quite a good case in my opinion for the following reasons: (A) The authors claim that \"Strikingly, the linear Gaussian predictor ... already accounts for much of this behavior\" (l.159). I disagree about how *striking* this outcome is. Linear models such as PCA, ICA or Factor analysis  [R1, Sec. 12.2.4] are used for decades for generating samples from a low-dimensional latent space. This is especially true for structured data such as face images [R2]. It is no wonder then that on such a dataset general solutions will act similar to linear ones. Thus, a demonstration on \"faces\" dataset is not a sufficient test case. (B) Even on faces data, `linear' theory does not always produce quality samples as can be seen on Fig. 5.  (C) I suspect that for less structured data (such as natural images) a demonstration similar to Fig.1 could not work.\n\n2. The same concern applies to \"VALIDATING PREDICTIONS ON DEEP NETWORKS\" (Sec.6): (A) Three of the demonstrated datasets consist again of face images. (B) On the CIFAR dataset (10 or 100 classes? authors do not specify...), the authors do not present the visual overcomes of models (deep or linear) which are crucial in order to asses the trained models quality. Whenever the model fails to catch the data distribution, consistency can be an an undesirable feature. For one (trivial) example, a model producing 0-images is very consistent but at the expanse of low-quality samples. (C) overall, it seems that the presented visual results are cherry-picked.\n\nIf the above weaknesses could be adequately addressed I will be happy to raise the score and recommend acceptance. \n\n\n[R1] Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning,\nvolume 4. Springer, 2006.\n\n[R2] Turk, Matthew, and Alex Pentland. \"Eigenfaces for recognition.\" Journal of cognitive neuroscience 3.1 (1991): 71-86."}, "questions": {"value": "1. Since $\\kappa (\\sigma^2)$ is a key identity in the paper, I think it would be better to present it explicitly in the text rather only in the Appendix.\n\n2. In line 255, what is the definition of $S_D(x)$?\n\n3. Could you provide results on datasets with more diverse classes of data, and visual samples from models trained on such datasets. As I mentioned above, an assessment of sample quality would be crucial (using e.g. FID or similar score).\n\n4. Specifically, please provide visual results (similar to Fig.1 and 5) for CIFAR experiment.  \n\n5. Also, state how many classes of the CIFAR datatset were used in the experiment.\n\n6. minor/typos: l.438: double 'linear'"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SfSZNX3Wlk", "forum": "K8TEFs6aFn", "replyto": "K8TEFs6aFn", "signatures": ["ICLR.cc/2026/Conference/Submission21679/Reviewer_7EKG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21679/Reviewer_7EKG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809580487, "cdate": 1761809580487, "tmdate": 1762941887217, "mdate": 1762941887217, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work studies the consistency phenomenon observed in diffusion models, that is, trained models on nonoverlapping data splits learn similar noise-to-image mappings. They observe same consistency phenomenon occurs in the linear diffusion model, which is fully characterized by mean and covariance of the underlying data distribution. With the help of random matrix theory, the authors characterize the variance of empirical linear diffusion models compared to the population one, discovering the 'shrinkage along eigen mode' effects. Several predictions based on the theory are made."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The analysis is rigorous and valid, accurately predicting the behaviors of linear models.\n\n2. The discussion about \"magic\" noise is interesting and can inspire further research."}, "weaknesses": {"value": "1. Previous work [1] has already attributed the consistency of diffusion models to the similarity of empirical covariances among data splits. This work sharpens this argument with rigorous analysis, but is still limited to the linear case. It remains unknown what else besides linear structures contribute to the observed consistency. \n\n2. Similar to the first point, the key theoretical results that characterize the variance caused by the empirical splits may not extend beyond linear model.\n\n3. It is unclear how the theory in this paper can guide us design better diffusion models.\n\n[1] Li, Xiang, Yixiang Dai, and Qing Qu. \"Understanding generalizability of diffusion models requires rethinking the hidden gaussian structure.\" Advances in neural information processing systems 37 (2024): 57499-57538."}, "questions": {"value": "1. How does your analysis extend beyond linear models?\n\n2. It is mentioned in discussion, 'magic noise' should not be aligned with directions that disagree among data splits. Why this is the case? Is it possible that although the directions do not align across data splits, they still capture meaningful structure of the data and making the initial noise align with them can produce high quality images? What properties do you think a good initial noise should have such that the generated samples have higher quality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "P2OQ9a9BCD", "forum": "K8TEFs6aFn", "replyto": "K8TEFs6aFn", "signatures": ["ICLR.cc/2026/Conference/Submission21679/Reviewer_1ATX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21679/Reviewer_1ATX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881559262, "cdate": 1761881559262, "tmdate": 1762941887028, "mdate": 1762941887028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses consistency in diffusion models through the lens of random matrix theory. The observation under study is that diffusion models trained on disjoint splits of the dataset produce outputs with similar results for the same input noise. The authors suggest that this arises from shared Gaussian statistics in the sub-datasets. The authors make use of a linear denoiser, and proceed to show what effects beyond Gaussian statisstics can be learned from random matrix theory and demonstrate that linear denoisers on varying dataset sizes share a combination of renormalization, anisotropy, and inhomogeneity. The authors conclude by pointing out some of these effects in trained diffusion models"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- I think this is a really interesting way to analyze diffusion and a fascinating phenomenon that I have not heard a good answer to. I am excited to see work that tries to address these questions in this way\n- While the theory relies on a very strong assumption (see also weaknesses), I thoroughly enjoyed the depth with which the authors explored the topics.\n- Interpretations are given throughout the paper to help the reader understand the math."}, "weaknesses": {"value": "- While the authors have done a great job in presenting the work, its complexity still makes this a difficult paper to follow, since a lot of concepts are uncommon in diffusion models. I understand this is a difficult topic to write about, and the authors have done quite a good job, but I do still think the high bar of entry of this paper is overall a weakness.\n- In general, the results seem to be very dependent on the linear denoiser assumption. The authors do make an effort to include experiments and give broader interpretations, but the bulk of the work remains focused on this narrow setting.\n- There are a few grammar errors floating around in the text, these would be easily captured with a pass trough a language model."}, "questions": {"value": "- In the motivating example, the authors suggest that because the only thing the linear model captures are Gaussian statistics, and that because the two linear model results give the same, and are also similar to the DiT and Unet outputs, similarity arises because of shared Gaussian statistics. It would be great to see a more direct proof of this assertion, which could quite easily be done by reducing the dataset into smaller and smaller chunks until the Gaussian statistics start to differ. This should coincide with a change in visual features if the authors hypothesis is correct. Have the authors considered such an experiment?\n- It seems as if the similarity in the rightmost column in Fig 5A is much less pronounced than in Fig 1A., while to the best of what I can find out these experiments should match. Can the authors comment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HOaN3pxp75", "forum": "K8TEFs6aFn", "replyto": "K8TEFs6aFn", "signatures": ["ICLR.cc/2026/Conference/Submission21679/Reviewer_qP44"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21679/Reviewer_qP44"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957335561, "cdate": 1761957335561, "tmdate": 1762941886779, "mdate": 1762941886779, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the surprising consistency of diffusion models trained on different, non-overlapping subsets of the same dataset: even when trained on distinct splits, models produce very similar outputs for the same noise seed. The authors trace this phenomenon to a linear Gaussian effect, showing that much of the generated signal can already be explained by the shared dataset statistics. To formalize this intuition, the paper develops a Random Matrix Theory (RMT) framework for linear diffusion models, quantifying how finite dataset size affects both the expectation and variance of learned denoisers and sampling maps. Key mechanisms include renormalization of noise scale, variance decomposition, and full trajectory analysis. Finally, the paper validates these RMT predictions empirically on UNet and DiT architectures, confirming that the same principles explain inhomogeneous consistency across data splits even beyond the linear regime."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**1.Principled theoretical framework using RMT:** The paper provides a rigorous Random Matrix Theory (RMT) framework to analyze the consistency of diffusion models across different data splits. By quantifying both the expectation and variance of linear denoisers under finite-sample effects, it offers clear insights into how dataset statistics and sample size shape generative outputs, establishing a strong theoretical baseline for understanding cross-split reproducibility.\n\n**2. Empirical validation on diffusion models:** Despite focusing on linear theory, the paper demonstrates that its predictions hold qualitatively for practical deep models, including UNet and DiT architectures. The validation highlights phenomena such as overshrinkage of low-variance modes, anisotropy across eigenmodes, and inhomogeneity across inputs, bridging the gap between theory and practice and providing actionable insights for understanding model stability."}, "weaknesses": {"value": "**1. Only focus on the linear denoiser.** The theoretical analysis in the paper is primarily restricted to linear denoisers, which makes the mathematical derivations tractable via Random Matrix Theory. While this provides valuable insight into the role of dataset statistics and finite-sample effects, it does not fully capture the behavior of real-world diffusion models, which are highly nonlinear and overparameterized (e.g., UNet and DiT architectures). As a result, the direct applicability of the theoretical results to practical settings is limited.\n\n**2. Inconsistent notation:** In several places, the manuscript uses inconsistent formatting for mathematical symbols, which can confuse readers about whether a symbol represents a scalar, vector, or matrix. For example, in Lines 132â€“136, the population mean $\\mu$ and $\\hat{\\mu}$ are written in plain font. Typically, vectors and matrices are written in boldface to distinguish them from scalars in the paper. The inconsistency makes it harder to follow derivations and can lead to ambiguity, especially in formulas involving differences between the population and empirical quantities."}, "questions": {"value": "**Q1.** The theoretical framework focuses on linear denoisers, but most practical diffusion models are highly nonlinear. How well do the RMT predictions quantitatively carry over to nonlinear architectures like UNet or DiT? Could the authors provide insights or bounds on when the linear approximation breaks down, or suggest extensions of their framework to account for nonlinearity?\n\n**Q2.** The analysis assumes Gaussian-like statistics in the data. How sensitive are the predictions to deviations from this assumption, such as strongly non-Gaussian or structured datasets (e.g., natural images with heavy tails, multimodality, or complex correlations)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "EJr7UX0Avu", "forum": "K8TEFs6aFn", "replyto": "K8TEFs6aFn", "signatures": ["ICLR.cc/2026/Conference/Submission21679/Reviewer_uvP7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21679/Reviewer_uvP7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762142509035, "cdate": 1762142509035, "tmdate": 1762941886548, "mdate": 1762941886548, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}