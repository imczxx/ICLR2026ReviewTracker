{"id": "TI7Y58vE06", "number": 13577, "cdate": 1758219361959, "mdate": 1759897427357, "content": {"title": "MIMIC-VQA: COMPILING AGENTIC REASONERS INTO EFFICIENT DOCUMENT VQA MODELS", "abstract": "Document Visual Question Answering systems face a fundamental architectural dichotomy: modular agentic frameworks decompose problems into interpretable sub-tasks but incur prohibitive inference latency through sequential tool orchestration, while monolithic end-to-end models achieve computational efficiency at the cost of reasoning transparency and spatial grounding capabilities. We present MIMIC-VQA, a knowledge distillation framework that transcends this trade-off by compiling the procedural reasoning of expert agents into efficient neural architectures. Our approach operates through a two-phase paradigm: first, a teacher pipeline orchestrated by Llama 4 Scout generates 102,447 Chain-of-Thought reasoning traces that explicitly encode multi-step problem decomposition, contextual retrieval, and deterministic spatial grounding; second, these traces train a pruned 9B-parameter student model derived from Gemma 3-27B to replicate the complete reasoning process—including intermediate steps and bounding box coordinates—within a single autoregressive generation. This procedural distillation enables the student to internalize the teacher's tool-based reasoning methodology while eliminating runtime dependencies on external components. Empirically, MIMIC-VQA achieves state-of-the-art performance across DocVQA (89.7 ANLS), VisualMRC, FUNSD, and CORD benchmarks, demonstrating 20-30 point improvements in spatial grounding (mAP@IoU) over existing methods while operating 5.3× faster than the teacher system. The framework maintains 98.3% of teacher accuracy despite 66% parameter reduction, validating that complex multi-agent reasoning can be successfully compiled into compact neural representations. By treating sophisticated agentic systems as data generators rather than deployment models, MIMIC-VQA establishes a practical paradigm for scaling document understanding capabilities without prohibitive infrastructure costs. The dataset of reasoning traces and the official implementation are publicly available at: https://anonymous.4open.science/r/MIMIC-B5DF.", "tldr": "", "keywords": ["Document Visual Question Answering", "VLM", "Document Understanding"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/db0d13bbafbca4afa2368c0f6e7e1cb51afb126f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes MIMIC-VQA, a knowledge distillation framework for Document Visual Question Answering that aims to \"compile\" the reasoning process of a modular agentic system into an efficient neural network. The approach operates in two phases: (1) a teacher pipeline orchestrated by Llama 4 Scout generates 102,447 Chain-of-Thought reasoning traces with spatial grounding, and (2) these traces are used to train a student model derived from Gemma 3-27B, pruned to 9B parameters, to replicate the complete reasoning process including bounding box coordinates in a single autoregressive generation. The authors report state-of-the-art results on DocVQA (89.7 ANLS), VisualMRC, FUNSD, and CORD benchmarks with 5.3× inference speedup."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Novel conceptual contribution: The idea of \"compiling\" procedural knowledge from a multi-step agentic system into a single efficient model through distillation is interesting and addresses a real trade-off in the field.\n\nComprehensive evaluation: The paper evaluates on multiple established benchmarks (DocVQA, VisualMRC, FUNSD, CORD, SROIE) with both answer accuracy and spatial grounding metrics.\n\nDetailed methodology: The appendix provides extensive implementation details including hyperparameters, pruning schedules, and dataset generation procedures.\n\nImportant ablation study: Table 3 demonstrates that Chain-of-Thought reasoning is critical for spatial grounding performance, which is a valuable finding.\n\nFocus on spatial grounding: The emphasis on both answer accuracy and localization is appropriate for document understanding applications."}, "weaknesses": {"value": "Methodological Contradictions\n\na) OCR Dependency vs. End-to-End Claims:\n\nSection 3.3 describes \"optional constrained decoding\" that requires \"lightweight OCR preprocessing\" (adding 45ms latency)\n\nAppendix B emphasizes training for \"visual-spatial reasoning WITHOUT text detection\"\n\nBut the teacher explicitly uses OCR (Algorithm 1, line 5) and deterministic ANLS matching (Algorithm 2)\n\nHow can the student learn OCR-free spatial grounding when the teacher fundamentally relies on OCR? This contradiction is never resolved.\n\nb) Inference Process Unclear:\n\nIs constrained decoding always used or truly optional?\n\nTable 2 shows separate results for \"+ Constrained Decoding\" suggesting it's optional\n\nBut Section 3.3 states it \"ensures robust coordinate outputs\" - when is it not used?\n\nWhat happens to spatial grounding quality without it?\n\nMissing Critical Technical Details\n\nBounding Box Tokenization:\n\nHow exactly are coordinates like \"(450, 80, 120, 25)\" tokenized?\n\nAre these separate number tokens? Single composite tokens? How large is the vocabulary?\n\nAlgorithm 1 line 13 shows \"Location: BA\" but the actual format isn't specified\n\nThe format \"x y w h\" appears in examples but is this (x,y,w,h) or (x1,y1,x2,y2)? Page 4 line 211 shows both formats.\n\n\nInsufficient Baselines and Comparisons\n\na) Teacher Comparison:\n\nTable 2 doesn't show the Teacher Agent results, but Table 3 does (90.2 ANLS, 78.4 mAP)\n\nWhy is the teacher not included as a baseline in the main results table?\n\nThe student achieves 88.7 ANLS vs teacher's 90.2 - this is 98.3% retention, but for spatial grounding it's 69.1 vs 78.4 mAP (88.1%) - why \nthe larger degradation?\n\nb) Alternative Distillation Methods:\n\nNo comparison with standard knowledge distillation (logit matching)\n\nNo comparison with other model compression techniques\n\nNo comparison with simply using the base Gemma 3-27B model\n\nc) Fairness Concerns:\n\nCompared models (DocLayLLM, LayoutLLM, etc.) don't use CoT or extensive spatial reasoning traces\n\nIs it fair to compare a model trained on 102k expert-generated reasoning traces against models trained on standard datasets?\n\nExperimental Rigor Issues\n\na) Statistical Significance:\n\nAppendix A.5 mentions 5 runs with different seeds, but Table 2 shows no error bars or confidence intervals\n\nNo significance testing reported\n\nGiven that improvements like 88.7→89.7 ANLS are claimed as contributions, statistical significance is essential\n\nb) Data Leakage Potential:\n\nHow was the 102,447 generated dataset split?\n\nWere test set images used to generate teacher traces?\n\nThis could lead to train/test contamination\n\n6. Questionable Claims\n\na) \"Compiling\" Metaphor:\n\nThe paper claims to \"compile\" multi-step reasoning, but the student still generates the full CoT at inference\n\nTrue compilation would eliminate the intermediate steps, but here they're still generated (and add tokens/latency)\n\nThe speedup comes from model size reduction, not from compilation\n\nb) Spatial Grounding Performance:\n\n20-30 point mAP improvements claimed, but DLaVA baseline may be weak\n\nNo comparison with specialized grounding models or object detection baselines\n\nThe teacher's deterministic grounding (Algorithm 2) isn't a learned capability being transferred"}, "questions": {"value": "How is spatial grounding achieved without OCR? Resolve the contradiction between OCR-free claims and OCR-dependent implementation.\nWhat is the exact coordinate tokenization scheme? Provide concrete examples."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OVyaeVH0fB", "forum": "TI7Y58vE06", "replyto": "TI7Y58vE06", "signatures": ["ICLR.cc/2026/Conference/Submission13577/Reviewer_BBK6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13577/Reviewer_BBK6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760756515431, "cdate": 1760756515431, "tmdate": 1762924172655, "mdate": 1762924172655, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a two-phase paradigm for document visual question answering. First, a teacher pipeline generates CoT reasoning traces. Second, a student model completes the rest of the reasoning. Results demonstrate faster inference speed."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The reviewer loves the idea of using a student model to do further explanations, trained based on teacher expert data. This could be insightful to other VQA applications as well.\n\n2. The reviewer appreciated the visual examples of Figure 2, but the reviewer still has some questions (see below).\n\nAlthough this paper has weaknesses, its conceptual motivation is clear and potentially impactful."}, "weaknesses": {"value": "1. Writing and formatting issues.\nThe manuscript has notable presentation problems that obscure the technical content. Examples include:\n\n(1) Ln 83-86 is a repeat of Ln 87. \n\n(2) Ln 88, \"compiled\" should be changed to ``compiled'', which applies to all quotation marks。\n\n(3) Resulting numbers should be highlighted in the introduction, while the last paragraph of the introduction should be removed.\n\n(4) In related works, citation formats are wrong.\n\n(5) Ln 380-384, the format is wrong, and it looks like LLMs again.\n\n(6) Ln 440, imparts -> impacts.\n\n2. Limited algorithmic novelty and fairness of comparison.\n\nThe reported 5.3× speedup seems largely due to using a smaller model rather than a new algorithm. The student’s performance is also notably below the teacher’s in mAP. Speed comparisons should include similar 7 B-scale models such as LayTextLLM for fairness.\n\nThe speed testing should be conducted against similar 7B model, such as LayTextLLM.\n\n3. Unclear conceptual framing. The teacher–student design is fairly standard, and it is unclear why the framework is termed “agentic.” The paper would benefit from stronger justification or ablation demonstrating agent-like reasoning behavior."}, "questions": {"value": "1. In the second example of Figure 2, why are other numbers not marked?\n\n2. Is mAP a good metric? If it's a grounding task, the reviewer would expect other metrics such as mIoU. Also, an analysis of the interpretability of the results is missing. \n\n3. Why was this framework called agentic?\n\n4. So, the outcome of this paper is only a student model? The speedup isn't a strong claim for an ICLR paper, and it's not due to the algorithmic design.\n\n5. Why does SROIE not have an mAP result? Is it because of unavailable ground truth?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RebCs49BY7", "forum": "TI7Y58vE06", "replyto": "TI7Y58vE06", "signatures": ["ICLR.cc/2026/Conference/Submission13577/Reviewer_Exva"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13577/Reviewer_Exva"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760799257497, "cdate": 1760799257497, "tmdate": 1762924172342, "mdate": 1762924172342, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MIMIC-VQA, which tackles the latency-interpretability trade‑off in document VQA by distilling the multi‑step reasoning of a modular, tool‑using teacher into a single student VLM. The teacher pipeline is used to produce ~102k CoT traces with bounding‑box supervision. The student model (pruned 9B from 27B) is trained to generate the reasoning, answer, and bbox in one forward pass. An optional constrained‑decoding step restricts coordinate tokens using a lightweight OCR vocabulary at inference. Empirically, the student approaches teacher ANLS while running ~5× faster and shows large mAP gains for grounding on DocVQA, VisualMRC, FUNSD, and CORD. Ablations argue that CoT is critical for spatial grounding."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly written and easy to understand.\n- Convincing ablations showing CoT is crucial for spatial grounding\n- The paper presents an efficient version of the model which could be deployed in real-time scenarios."}, "weaknesses": {"value": "- Teacher description is contradictory. In the main paper, the Teacher is an OCR‑based Llama Scout/Gemma pipeline; however, in Appendix B.2.1, the Generation Model (Teacher) is described as Gemini with GPT‑5 validation. This undermines the central claim because the nature of procedural knowledge being distilled is unclear.\n- The paper methodology has a lot of similarities with the \"AURELIA\" [1] which also distills reasoning information into VLMs via an agentic pipeline at test-time. Therefore, the methodology of the proposed cannot be tagged as novel. Also the comparison of proposed method with AURELIA like pipelines must be reported in the paper as it presents a crucial baselines for testing reasoning distillation with finetuning vs without finetuning.\n- Authors mentioned using mAP@IoU; however, the metric is missing in almost every reported baseline in all tables. This raises concerns regarding the effectiveness of the proposed method making it difficult to assess whether improvements hold against strong OCR‑based contemporaries under the same metric settings\n- The GPU compute used to run the experiments is unclear. Main paper (section 4.2) mentions using A100 GPUs, while Appendix A reports H100 GPUs being used. This will lead to reproducibility issues.\n- Appendix Table 4 reports the usage of LoRA for training student architecture, however, there is no mention of LoRA in Main paper. The details on self‑consistency are also missing.\n- While the pruning recipe is described, it lacks an ablation showing accuracy vs sparsity and the contribution of pruning independent from distillation.\n- In the main paper, the generated bbox has the format <x,y,h,w>; however in Appendix (page 16), the generated bbox has the format <x1,y1,x2,y2>, this raises questions about how the model is trained to emit boxes and how parsing errors are penalized.\n\n\nReferences\n\n[1] Chowdhury, S., Gani, H., Anand, N., Nag, S., Gao, R., Elhoseiny, M., ... & Manocha, D. (2025). Aurelia: Test-time reasoning distillation in audio-visual llms. ICCV 2025."}, "questions": {"value": "- Which teacher actually produced the 102,447 traces? Please reconcile the OCR‑based Llama/Gemma pipeline (Sec. 3–4 main paper) with the Gemini+GPT‑5  pipeline (Appendix B).\n- Box parameterization: Is the student trained to output <x, y, w, h> or <x1, y1, x2, y2>?\n- Why are mAP scores omitted for the majority of cases?\n- How is “coordinate hallucination” defined and measured for the claimed 73% reduction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eweC8qa1Zu", "forum": "TI7Y58vE06", "replyto": "TI7Y58vE06", "signatures": ["ICLR.cc/2026/Conference/Submission13577/Reviewer_Ui6F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13577/Reviewer_Ui6F"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761605672978, "cdate": 1761605672978, "tmdate": 1762924171966, "mdate": 1762924171966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how to resolve the fundamental trade-off between inference latency and reasoning transparency in document VQA, that modular agentic systems are often good at reasoning transparency but suffer from high latency, while end-to-end models are good at efficiency but suffer from lack of interpretability. The authors propose MIMIC-VQA, a knowledge distillation method for document VQA that distills not only the final answer but also the complete step-by-step reasoning process from a larger multi-agent teacher system into a single autoregressive generation by a smaller student system. The authors perform experiments on 5 benchmarks and demonstrate state-of-the-art performance on 4 of them, with the student model achieving 98.3% of teacher accuracy while operating 5.3× faster.\n\nOverall, this is an interesting paper that addresses a practical problem. However, the main contribution, the distillation approach, largely applies well-established knowledge distillation techniques that have been widely studied in modern LLMs. Nevertheless, in the document VQA area, it still demonstrates promising results in the experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Great motivation for optimizing both inference latency and performance while maintaining reasoning transparency, addressing a genuine practical need in document AI deployment with significant infrastructure cost reductions (from 88.9 to 16.7 hours per 100K queries).\n- The method is technically sound and the experimental results are strong, achieving state-of-the-art performance on 4 out of 5 benchmarks with substantial improvements in spatial grounding (20-30 mAP point gains over existing methods). The ablation studies effectively demonstrate the critical importance of Chain-of-Thought distillation, showing catastrophic degradation in spatial grounding (14-point mAP drop) when CoT is removed.\n- The 102,447 Chain-of-Thought reasoning traces dataset represents a substantial contribution to the research community, providing high-quality procedural reasoning annotations for document VQA that could foster further research in this important area."}, "weaknesses": {"value": "### Major\n- The major concern is that this work essentially applies well-established knowledge distillation techniques, which are widely used in LLMs, to the document VQA domain using vision-language models. While the application is competent and the \"procedural distillation\" framing is useful, the core methodological contribution is incremental rather than genuinely innovative.\n- The experiments are limited to only one teacher-student combination (Llama 4 Scout + Gemma 3-27B/9B). It would significantly strengthen the evidence for this method's effectiveness to test whether other model combinations would achieve similar gains, particularly given the authors' claim about the general applicability of the approach.\n\n### Minor\n\n- Line 397: Claims \"achieves state-of-the-art performance across all five benchmarks\" but actually achieves SOTA on only 4 out of 5 benchmarks.\n- Lines 269 vs. 290: There are two instances of \"Step 4: Answer Grounding\" which creates confusion in the methodology description.\n- The nearly full-page pseudocode on page 5 (Algorithm 1) doesn't seem to add much value beyond the textual description and hurts the presentation efficiency of the paper, in my opinion."}, "questions": {"value": "- How can you better justify the overall effectiveness of this approach since it's only tested with one teacher-student model configuration? What about other model selections such as larger/smaller teacher models or different student architectures? This is crucial for establishing the method's generalizability beyond the specific Llama 4 Scout + Gemma 3-27B/9B combination.\n\n- What about the data efficiency of the teacher data generation process? Could you provide more details on how the 102,447 number was determined? If the ratio of CoT reasoning traces to the original number of data points in the source datasets is too high, it could cause significant distribution shift, potentially leading to overfitting on synthetic reasoning patterns rather than genuine document understanding capabilities."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BIgiB8Q1dk", "forum": "TI7Y58vE06", "replyto": "TI7Y58vE06", "signatures": ["ICLR.cc/2026/Conference/Submission13577/Reviewer_kTC2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13577/Reviewer_kTC2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968644661, "cdate": 1761968644661, "tmdate": 1762924171563, "mdate": 1762924171563, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}