{"id": "wyucYNGPiW", "number": 4334, "cdate": 1757664254405, "mdate": 1759898038944, "content": {"title": "Attack-Resistant Watermarking for AIGC Image Forensics via Diffusion-based Semantic Deflection", "abstract": "Protecting the copyright of user-generated AI images is an emerging challenge as AIGC becomes pervasive in creative workflows. Existing watermarking methods (1) remain vulnerable to real-world adversarial threats, often forced to trade off between defenses against spoofing and removal attacks; and (2) cannot support semantic-level tamper localization. We introduce PAI, a training-free inherent watermarking framework for AIGC copyright protection, plug-and-play with diffusion-based AIGC services. PAI simultaneously provides three key functionalities: robust ownership verification, attack detection, and semantic-level tampering localization. Unlike existing inherent watermark methods that only embed watermarks at noise initialization of diffusion models, we design a novel key-conditioned deflection mechanism that subtly steers the denoising trajectory according to the user key. Such trajectory-level coupling further strengthens the semantic entanglement of identity and content, thereby further enhancing robustness against real-world threats. Moreover, we also provide a theoretical analysis proving that only the valid key can pass verification. Experiments across 12 attack methods show that PAI achieves 98.43\\% verification accuracy, improving over SOTA methods by 37.25\\% on average, and retains strong tampering localization performance even against advanced AIGC edits. Our code is available at \\url{https://anonymous.4open.science/r/PAI-423D}.", "tldr": "", "keywords": ["AIGC copyright protection; Image watermark; Diffusion model"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a7ad7cbf8e8856cdb534f993e6be2b4e77026255.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a training-free, plug-and-play AIGC image copyright protection framework called PAI. PAI injects watermarks through a two-stage generation process: in the initialization stage, the user key and timestamp are embedded into the initial noise through the Box-Muller transform to ensure its compatibility with the diffusion model; in the denoising stage, a new key-conditioned deflection is introduced to guide the denoising trajectory.\n\nThe main contributions include: 1. A training-free inherent watermark framework PAI is proposed to improve robustness. 2. A relatively complete theoretical analysis and proof are provided. 3. The contradiction between existing methods in defending against removal attacks and spoofing attacks is successfully resolved. 4. Effective localization of semantic-level tampering caused by AIGC tools is achieved."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. In terms of originality, the paper's two-stage approach to watermark injection, using denoising trajectories to guide the generation process, is a relatively novel perspective. \n\n2. In terms of quality, the paper is comprehensive and provides theoretical analysis to further support the rationale of the proposed method. The experimental design is comprehensive, covering multiple datasets, multiple baselines, and various attack types, and the results clearly demonstrate the advantages of the method. \n\n3. In terms of clarity, the paper's overall structure is clear, and the charts and graphs are intuitive. \n\n4. In terms of importance, the problem addressed in the paper is of practical significance, and as a plug-and-play method, it also has strong generalizability."}, "weaknesses": {"value": "1. Regarding sampler selection: The paper primarily conducts a series of analyses and experiments based on the DDIM sampler, lacking analysis of the compatibility and generalization performance of other samplers.\n\n2. Regarding hyperparameter sensitivity analysis in the experimental section: The paper lacks analysis of the intensity of hyperparameter deffection.\n\n3. In the theoretical analysis, an idealized assumption is made for the diffusion model. Is this analysis still applicable under real-world non-ideal conditions?"}, "questions": {"value": "1. In the sampler selection section, comparative experiments with other samplers could be added to analyze the generalization performance of the model on these samplers.\n\n2. Add hyperparameter ablation analysis experiments.\n\n3. Regarding the idealized assumptions in the theoretical analysis, the applicability under real-world conditions could be discussed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jZJ1MioW6p", "forum": "wyucYNGPiW", "replyto": "wyucYNGPiW", "signatures": ["ICLR.cc/2026/Conference/Submission4334/Reviewer_wY8c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4334/Reviewer_wY8c"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761035330986, "cdate": 1761035330986, "tmdate": 1762917304555, "mdate": 1762917304555, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PAI (Provenance-Aware Inherent watermarking), a novel training-free, inherent watermarking framework designed for copyright protection and forensics of images generated by diffusion models. The authors identify two critical flaws in existing methods: (1) a forced trade-off between robustness to watermark removal attacks and spoofing attacks, often stemming from reliance on 1D verification metrics, and (2) an inability to perform semantic-level tamper localization, which is crucial for detecting edits made by other AIGC tools."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The idea of moving inherent watermarking beyond static noise initialization to active, key-conditioned \"deflection\" of the denoising trajectory is a significant conceptual leap. It creates a much deeper and more complex entanglement between the secret key and the final image semantics.\n\n- The most original and impactful contribution is the verification method. Correctly identifying the 1D scalar metric as the root cause of the removal/spoofing trade-off is a key insight. Replacing it with a high-dimensional vector (the initialization bias) and analyzing its directional properties in a latent PCA space is a brilliant and effective solution to this long-standing problem. This single mechanism's ability to unify verification, attack detection, and localization is elegant.\n\n- This work presents a practical, training-free, and robust 3-in-1 system for AIGC forensics. By decisively solving the removal/spoofing trade-off and enabling, for the first time, robust semantic localization for an inherent watermark, this paper sets a new standard for AIGC copyright protection. This is a significant contribution to the field of AI safety and provenance."}, "weaknesses": {"value": "The deflection intensity $\\gamma=0.1$ and the application of deflection for only the first five steps are presented without extensive ablation. The appendix (A.6.3) only ablates the number of steps (5, 10, 15), showing that 5 is sufficient. However, the intensity $\\gamma$ is a critical parameter that presumably balances image quality against robustness. An ablation study on $\\gamma$ would provide a more complete picture of the method's properties and trade-offs."}, "questions": {"value": "The overall provenance framework is built on the deterministic invertibility of multi-step sampling DDIM. What would happen if one-step or diffusion sampling mechanism is taken (like DPM-solver or flow-matching)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wvzXDv78Cp", "forum": "wyucYNGPiW", "replyto": "wyucYNGPiW", "signatures": ["ICLR.cc/2026/Conference/Submission4334/Reviewer_h8d5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4334/Reviewer_h8d5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727431941, "cdate": 1761727431941, "tmdate": 1762917304258, "mdate": 1762917304258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Attack-Resistant Watermark (ARW), a robust watermarking framework designed to enhance resistance to generative model attacks, particularly diffusion-based removal and regeneration. ARW employs a dual-domain embedding strategy that combines frequency- and spatial-domain features with an adaptive noise calibration mechanism, ensuring watermark persistence after heavy editing, compression, or diffusion regeneration. A key innovation is the Attack Simulation Module (ASM), which imitates various diffusion or enhancement operations during training, improving generalization to unseen attacks. Extensive experiments on ImageNet and Stable Diffusion–based editing tasks show ARW significantly improves watermark survival rates and retrieval accuracy compared to recent methods like StegaStamp, RivaGAN, and TreeRing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel robustness design: This paper integrates attack simulation directly into training, improving resilience against diffusion and regeneration attacks.\n\n2. Comprehensive experiments test under multiple real-world generative attacks and shows consistent superiority.\n\n3. Good balance of fidelity and robustness: watermark imperceptibility maintained with strong retrieval accuracy.\n\n4. Well-structured ablation studies: This paper clearly isolate the contributions of dual-domain embedding and ASM."}, "weaknesses": {"value": "1. Limited theoretical analysis lacks a formal framework or justification for robustness improvements beyond empirical results.\n\n2. The evaluation of this paper focuses on diffusion-based attacks. Some adversarial or large semantic edits such as instructpix2pix should be included in the experiments.\n\n3. Computational cost of dual-domain embedding and ASM could hinder deployment in high-throughput systems. Costing 7950.59ms for watermarking an image seems too long. \n\n4. Generalization uncertainty: unclear performance on unseen generative models (such as some DiT-based methods) or video data, limiting broader applicability and disscusion."}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UPjQ2fU3nj", "forum": "wyucYNGPiW", "replyto": "wyucYNGPiW", "signatures": ["ICLR.cc/2026/Conference/Submission4334/Reviewer_fR5j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4334/Reviewer_fR5j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977977544, "cdate": 1761977977544, "tmdate": 1762917303883, "mdate": 1762917303883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PAI (Provenance-Aware Intelligence), an attack-resistant watermarking and forensic framework for AI-generated images. By leveraging a diffusion-based semantic deflection mechanism, the method embeds and verifies watermarks at the semantic level rather than in pixel space, making them robust against degradation, removal, spoofing, and tampering attacks. The system integrates ownership verification, attack detection, and tampering localization through DDIM inversion. Experimental results demonstrate that PAI achieves superior robustness and functionality compared to existing watermarking methods, offering a promising solution for reliable provenance tracking and authenticity verification in AIGC image forensics."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a novel semantic deflection mechanism within diffusion processes, embedding watermarks in the semantic space rather than pixel space — a creative and technically sound idea that improves robustness against diverse attacks.\n\n2. The proposed PAI framework integrates watermark generation, verification, attack detection, and tampering localization into a unified pipeline, demonstrating both conceptual coherence and practical applicability for real-world AIGC scenarios.\n\n3. Extensive experiments compare PAI with multiple state-of-the-art methods (e.g., EditGuard, Tree-Ring, Stable Signature), showing consistently superior performance across robustness and functionality metrics.\n\n4. The paper goes beyond simple watermark verification by achieving semantic-level localization of edited or tampered regions, which adds significant forensic and interpretability value to the method."}, "weaknesses": {"value": "1. The experimental validation mainly focuses on standard diffusion-based AIGC models and common attack types. The generalization of PAI to non-diffusion models (e.g., GAN-based generators or real-world edited images) remains unclear.\n\n2. Although the authors claim imperceptibility of watermarks, no formal perceptual metrics or human evaluations are provided to verify that the embedded signals do not degrade visual quality or introduce detectable artifacts.\n\n3. The framework is exclusively designed for diffusion-based AIGC models, with no compatibility testing or adaptation for GAN-based or transformer-based image generation systems.\n\n4. The ablation study only varies the number of deflection steps and clean sample size, neglecting to investigate the impact of critical hyperparameters (e.g., γ, DDIM steps) on robustness and image quality."}, "questions": {"value": "Please refer to the Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sOSzmD1mf3", "forum": "wyucYNGPiW", "replyto": "wyucYNGPiW", "signatures": ["ICLR.cc/2026/Conference/Submission4334/Reviewer_Rgem"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4334/Reviewer_Rgem"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979420262, "cdate": 1761979420262, "tmdate": 1762917303659, "mdate": 1762917303659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}