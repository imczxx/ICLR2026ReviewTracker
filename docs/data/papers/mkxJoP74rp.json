{"id": "mkxJoP74rp", "number": 8897, "cdate": 1758101668598, "mdate": 1759897755749, "content": {"title": "Feature Modulating for Diffusion Models", "abstract": "We propose Feature Modulating (FM), a training-free approach that enables image quality improvement and better text-image alignment in text-to-image diffusion models. Rather than relying on additional input information, our heuristic FM module directly modulates latent features during the denoising steps. The modulation alters the feature distribution, leading to differences in the generated images. To explore the impact of feature modulation, we introduce a channel-wise monotonic modulation function that adjusts feature values using a single parameter, facilitating the obtainment of high quality images. The FM module is architecture-agnostic and can be integrated into existing diffusion models. Extensive experiments across multiple benchmarks demonstrate the ability of our feature modulation to enhance image quality, semantic fidelity and realism.", "tldr": "We propose Feature Modulating (FM), a training-free approach that enables image quality improvement and better text-image alignment in text-to-image diffusion models.", "keywords": ["Diffusion models", "Text to Image", "Generative models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/588e9c05aa8c14a1461f13734473d1a3f2b874b5.pdf", "supplementary_material": "/attachment/9ef513a72b2bfea80cca44a945496a43a48acd6b.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a training-free method to enhance the image quality and text-image alignment of text-to-image diffusion models. The core contribution is a feature modulation technique that operates in a channel-wise manner on the internal features of the diffusion model, requiring no additional training or auxiliary inputs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method is training-free, which is a good advantage. This makes it computationally efficient, versatile, and easy to integrate into existing pre-trained diffusion models without incurring expensive training costs.\n- The approach is straightforward and self-contained, operating directly on the model's features without the need for external training of modules or auxiliary inputs beyond the standard text prompt."}, "weaknesses": {"value": "- The experiments are confined to Stable Diffusion. To demonstrate the generalizability and robustness of the proposed method, it is crucial to evaluate its performance across a broader range of modern T2I architectures, such as Flux, SANA, or Qwen-Image. This would strengthen the paper's claims.\n- The method's performance appears highly sensitive to the hyperparameter $\\alpha$, as shown in the ablation study. However, the paper provides no clear guidance on how to select an optimal value for $\\alpha$. This raises concerns about the method's practical usability, as users might need to perform extensive trial-and-error to achieve good results. A more thorough analysis of $\\alpha$'s behavior or a proposed strategy for its selection is needed.\n- The paper omits comparisons with other relevant training-free methods that aim to improve generation quality, such as FreeU (which is referred in the related work section). A quantitative and qualitative comparison against such established baselines is essential to properly contextualize the proposed method's contributions and effectiveness.\n- (minor) The figure reference seems to be wrong. In the sentence in line 82-84, the Figure seems to be Fig. 1 rather than Fig. 2."}, "questions": {"value": "- Could the authors perform experiment regarding the applicability of this method to different model architectures?\n- The results in Figure 8 show that the optimal value for $\\alpha$ varies significantly across different samples (e.g., $\\alpha=0.1$ is best for the first row, while negative values are better for the second). How should a user determine the best $\\alpha$ for an arbitrary prompt? Have the authors considered any dynamic or sample-adaptive techniques for setting this value automatically?\n- The evaluation relies heavily on an LLM-based assessment. While insightful, it would be beneficial to supplement this with other widely-used metrics for text-image alignment. Have the authors considered reporting metrics such as CLIP score or VQA score to provide a more comprehensive quantitative evaluation?\n- Additionally, the paper's claim of enhancing image quality is not substantiated by quantitative analysis. Could the authors provide an evaluation using widely-used metrics, for example, CLIP image similarity or DINO scores, to measure the degree of improvement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v4mSriPWnn", "forum": "mkxJoP74rp", "replyto": "mkxJoP74rp", "signatures": ["ICLR.cc/2026/Conference/Submission8897/Reviewer_rTb9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8897/Reviewer_rTb9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761290409434, "cdate": 1761290409434, "tmdate": 1762920652887, "mdate": 1762920652887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a training‑free, channel‑wise feature modulation (FM) module that is inserted into the denoising steps of text‑to‑image diffusion models. After per‑channel min–max normalization, a monotone quadratic mapping $f(z) = z + \\alpha z(1-z)$ is applied and then rescaled back; only the top‑$\\gamma$ channels by mean activation are modulated. The method is intentionally simple (single scalar $\\alpha$ and selection ratio $\\gamma$), architecture‑agnostic, and is demonstrated on SD2.1 (U‑Net), SDXL (U‑Net), and SD3.0 (DiT)."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "+ Simple, training‑free mechanism that can be dropped into existing denoisers; no model updates or auxiliary inputs are required. The block diagram and per‑step placement are clear and easy to read.\n\n+ Works on various models such as SD2.1, SDXL and SD3.0; the visuals in Figs. 6–7 (pp. 6–7) illustrate consistent qualitative gains on integrity, counts, and missing parts."}, "weaknesses": {"value": "+ The core quantitative claim relies on a GPT‑4o prompt protocol (Table 1, 2 on p. 8). While the prompt is carefully designed and validated on a small annotated set, this remains non‑standard and potentially brittle to prompt choices. The CLIP‑score plots in Appendix C show only modest improvements and are not tied to the large‑scale improvement rates. A rigorous evaluation should include human A/B preference studies and automatic, task‑specific measures (e.g., count accuracy via detectors or segmentation; text‑image alignment with multiple metrics; robustness over seeds). This is the largest reason my score is conservative.\n\n+ The method is training‑free, but the paper grid‑searches some $\\alpha$ per prompt (Sec. 4.3, Table 2) and the Reproducibility Statement admits per‑case hyperparameter tuning is often needed. Yet the Conclusion claims “without incurring any additional computational costs.” These statements conflict so please quantify the overhead (extra function evaluations / wall‑clock) on to get the results in your benchmarks.\n\n+ The paper cites FreeU, RB‑Modulation, Attend‑and‑Excite, etc., but does not systematically compare against them on the same prompts/metrics. Without such baselines the significance of FM is hard to judge.\n\n+ For SD3.0, FM “crashes” earlier blocks and only works reliably at the last MM‑DiT block (Appendix J). This narrows the claim of being architecture‑agnostic; please analyze why and whether lighter‑weight normalizations or mixed‑precision clamps mitigate this."}, "questions": {"value": "+ How many extra samples per prompt are needed on average to find a good $\\alpha$? Please report compute overhead and win‑rate vs. cost trade‑off. Could you provide one‑shot heuristics (e.g., function of layer norms, prompt length, CFG scale) that pick reasonably good $\\alpha$ without search?\n\n+ Can you add side‑by‑side comparisons with FreeU, RB‑Modulation, Attend‑and‑Excite (or similar training‑free methods) on the same prompts using both the LLM judge and conventional metrics?\n\n+ How stable are improvements across random seeds and samplers (DDIM/DPMSolver/etc.)?\n\n+ Why does early‑layer modulation “crash” SD3.0? Any explanation that adjusting $gamma$ or adding per‑feature clipping avoids divergence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NOtW2cGXpV", "forum": "mkxJoP74rp", "replyto": "mkxJoP74rp", "signatures": ["ICLR.cc/2026/Conference/Submission8897/Reviewer_sVfQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8897/Reviewer_sVfQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761745402669, "cdate": 1761745402669, "tmdate": 1762920652420, "mdate": 1762920652420, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a simple channel-wise feature modulation approach to improve the generated image quality in latent diffusion models. The experiments are carried out on stable diffusion models and show the effectiveness by using a heuristic parameter with mean-based channel selection. Results are also validated with GPT-4o as a judge."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed modulation method is training-free and finding the parameter $\\alpha$ is heuristic. Therefore, the proposed method is efficient.\n- From the results in the paper, the generated images are significantly improved after the proposed modulation.\n- The paper leverages GPT-4o for feasible evaluation."}, "weaknesses": {"value": "- Finding the good enough $\\alpha$ takes multiple tries and the most optimal $\\alpha$ may not be guaranteed.\n- The paper does not make a comparison with other modulation methods.\nFor example, the following works also propose feature modulation methods, although the focus is towards high-resolution images.\n\n[1] https://arxiv.org/pdf/2411.18552\n\n[2] https://www.nature.com/articles/s41598-025-94381-8\n\n[3] https://openreview.net/forum?id=OIqOpdyhTd\n\n- Section 2, related work, does not explain how it is related to the proposed work or how it differs from the proposed method.\n\nMinor:\n- The paper does not follow the ICLR template for tables. Table captions are supposed to be at the top.\n\n- Writing should be improved. For example, there is a grammatical mistake in line 091, \"are struggle with\" should be \"struggle with\".\n\n- Fig. 1 is not referenced in the main paper, but it is from the supplementary material.\n\n- Table 1 spacing should be improved.\n\n- Line 446, generally, it is better to use Figure at the beginning of the sentence rather than Fig.\n\n- Section 4.1, implementation details are more like an experimental setup. It does not explain how the proposed method is implemented."}, "questions": {"value": "- What is the resolution of the images in the experiments?\n- What is the performance of FM if the resolution varies?\n- What is the performance comparison with other modulation methods in terms of the criteria used in the paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SrukKkHn7d", "forum": "mkxJoP74rp", "replyto": "mkxJoP74rp", "signatures": ["ICLR.cc/2026/Conference/Submission8897/Reviewer_usGn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8897/Reviewer_usGn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806205682, "cdate": 1761806205682, "tmdate": 1762920652104, "mdate": 1762920652104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **Feature Modulation** (FM), a training-free and architecture-agnostic approach for improving the qualitative fidelity and text–image alignment in text-to-image diffusion models. FM introduces a lightweight, deterministic transformation of selected feature maps during inference, without modifying model parameters. Qualitative evaluations demonstrate consistent improvements in object integrity, completeness, and numerical accuracy compared to the baseline models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Architecture-agnostic and training-free:**  \n   The proposed approach is architecture-agnostic, training-free, and easy to implement.  \n   It can, in principle, be integrated into any text-to-image diffusion model that provides access to intermediate feature maps during inference (e.g., in U-Net- or Transformer-based frameworks).\n\n2. **Clarity and reproducibility:**  \n   The method is clearly described in Section 3 and can be easily understood and implemented based on the provided explanation.\n\n3. **Comprehensive experimental coverage:**  \n   The experiments evaluate three Stable Diffusion models (SD 2.1, SDXL, SD 3.0), spanning two architectural families (U-Net and DiT), and three prompt datasets (DrawBench, COCO, and a small custom set). Results are primarily qualitative, based on an LLM-based evaluation, showing improvement rates between 57 % and 73 % with a very low degradation rate (< 2 %). The LLM evaluation was validated beforehand with approximately 88 % agreement with human judgments. Prompt dependency and the influence of the modulation parameter $\\alpha$ were systematically analyzed in an ablation study."}, "weaknesses": {"value": "1. **LLM-based evaluation:**  \n   The evaluation relies exclusively on qualitative, GPT-4o-based judgments without quantitative metrics in the main paper.  \n   CLIP score results provided in the appendix show small but consistent gains (at fixed $\\alpha$), indicating that parameter tuning may not be strictly necessary. However, these results lack scale information and statistical significance testing, and should therefore be interpreted with caution.\n\n2. **Hidden computational cost:**  \n   The best qualitative results require a grid search over the modulation parameter $\\alpha$, which weakens the claim of achieving improvements “without incurring any additional computational cost.”\n\n3. **Lack of comparison with related training-free methods:**  \n   No comparisons are provided to other training-free enhancement approaches (e.g., FreeU). It also remains unclear whether FM can be combined with these techniques or if they interfere with each other.\n\n4. **Lack of theoretical analysis:**  \n   The paper provides no mathematical analysis of how the quadratic modulation function affects the denoising field. The motivation remains purely heuristic.\n\n5. **Limited reproducibility:**  \n   Since evaluation depends on GPT-4o, the reported results are only partially reproducible."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nCZHkKp1L4", "forum": "mkxJoP74rp", "replyto": "mkxJoP74rp", "signatures": ["ICLR.cc/2026/Conference/Submission8897/Reviewer_D6bC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8897/Reviewer_D6bC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835443752, "cdate": 1761835443752, "tmdate": 1762920651673, "mdate": 1762920651673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Feature Modulating (FM), a training-free method designed to enhance image quality and text–image alignment in text-to-image diffusion models. Instead of using extra inputs or retraining, FM directly modulates latent features during the denoising process. The authors design a channel-wise monotonic modulation function controlled by a single parameter to adjust feature values efficiently. This modulation alters the internal feature distribution, leading to improved generation quality. The proposed FM module is architecture-agnostic and can be easily integrated into existing diffusion frameworks. Experiments on multiple benchmarks show consistent improvements in image quality, semantic fidelity, and realism."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is well-structured and easy to follow.\n\n2. The proposed feature modulating approach appears novel."}, "weaknesses": {"value": "1. The authors propose a quadratic modulation strategy that reshapes the feature distribution while preserving the monotonic ordering of feature values. The modulation effect is formalized in the lemma. Could the authors provide a simulation experiment or distribution example to intuitively illustrate this modulation effect?\n\n2. In Lines 212–213, it is stated that “negative $\\alpha$ values can potentially help pull back out-of-distribution features.” What exactly are out-of-distribution features in this context? Please describe their impact and underlying mechanism in detail.\n\n3. For the experiments on SD2.1 and SDXL, which layer is selected to apply the FM module?\n\n4. For the experiments on SD2.1 and SDXL, $\\gamma$ is set to 0.1, and for SD3.0, $\\gamma$ is set to 0.5. How was the optimal $\\gamma$ determined? Was it chosen based on quantitative experimental observation? Please include ablation studies on $\\gamma$ to support this choice.\n\n5. As mentioned, “the optimal setting of $\\alpha$ is highly image-dependent and varies significantly across different cases.” On average, how many search steps are required for each image generation? Please provide ablation studies on $\\alpha$.\n\n6. Could the authors provide practical guidance or a recommended range of $\\alpha$ values for different generation tasks to facilitate reproducibility and application?"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l2cVbiRuR9", "forum": "mkxJoP74rp", "replyto": "mkxJoP74rp", "signatures": ["ICLR.cc/2026/Conference/Submission8897/Reviewer_M9ec"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8897/Reviewer_M9ec"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895358682, "cdate": 1761895358682, "tmdate": 1762920651234, "mdate": 1762920651234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a training-free Feature Modulation (FM) method designed to enhance the performance of diffusion models. The proposed method first selects a fraction $\\gamma$ of feature channels exhibiting the highest mean activations. These selected channels are then modulated by a quadratic function, which is controlled by a parameter $\\alpha$. Experiments on both UNet and DiT-based diffusion models demonstrate that the proposed method improves integrity, numerical accuracy, completeness, and visual refinement."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is training-free, requiring no extra training or fine-tuning, and is shown to be effective across both UNet and DiT architectures.\n2. The writing is clear and easy to follow."}, "weaknesses": {"value": "1. As mentioned in Line 384, the modulation parameter $\\alpha$ appears to require careful tuning for each specific case, which may introduce additional computational overhead and inconvenience in practice.\n2. Most of the ablation studies (including Section 4.4, Appendix I and J) relies on empirical visualizations, which may only reflect a limited set of cases. It would be better to include statistical or quantitative analyses to support broader, more generalizable conclusions."}, "questions": {"value": "1. Are the modulation be applied to all timesteps throughout the sampling process? Is it possible to use different $\\alpha$ for different timesteps?\n2. In the first row of Figure 8, both increasing and decreasing $\\alpha$ increase the number of generated dogs. Could the authors clarify why both positive and negative $\\alpha$ values lead to similar effects in this example?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Gmupps8AEY", "forum": "mkxJoP74rp", "replyto": "mkxJoP74rp", "signatures": ["ICLR.cc/2026/Conference/Submission8897/Reviewer_hMb4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8897/Reviewer_hMb4"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission8897/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991667239, "cdate": 1761991667239, "tmdate": 1762920650894, "mdate": 1762920650894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}