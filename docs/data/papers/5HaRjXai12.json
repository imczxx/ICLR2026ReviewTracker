{"id": "5HaRjXai12", "number": 1940, "cdate": 1756969041040, "mdate": 1763705441355, "content": {"title": "Trinity: An Evolved LLM Coordinator", "abstract": "Combining diverse foundation models is promising, but weight-merging is limited by mismatched architectures and closed APIs. **Trinity** addresses this with a lightweight coordinator that orchestrates collaboration among large language models (LLMs). The coordinator, comprising a compact language model ($\\approx 0.6$B parameters) and a lightweight head ($\\approx 10$K parameters), is optimized with an evolutionary strategy for efficient and adaptive delegation. **Trinity** processes queries over multiple turns, where at each turn the coordinator assigns one of three roles (*Thinker*, *Worker*, or *Verifier*) to a selected LLM, effectively offloading complex skill acquisition from the coordinator itself. Extensive experiments demonstrate that **Trinity** consistently outperforms individual models and existing methods in various tasks, including coding, math, reasoning, and domain knowledge, while robustly generalizing to out-of-distribution tasks. On established benchmarks, **Trinity** achieves state-of-the-art performance, including a new record of $86.2\\%$ on LiveCodeBench. Theoretical and empirical analyses highlight two key factors driving this success: (1) the coordinator’s hidden-state representations provide rich contextualization of inputs, and (2) under high dimensionality and strict budget constraints, the separable Covariance Matrix Adaptation Evolution Strategy algorithm provides substantial advantages over RL, imitation learning, and random search, leveraging potential block-$\\varepsilon$-separability.", "tldr": "A 0.6B coordinator whose ES-evolved 10k-param head reads the penultimate token to pick agents and assign worker/thinker/verifier roles—beating single models/routers without SFT or RL.", "keywords": ["evolutionary strategies", "multi-agent LLM systems", "role-based delegation", "logits-to-agent mapping"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7820a28a53d997e44c7c7e9a138e4a31ba983f45.pdf", "supplementary_material": "/attachment/d94206289ca4369033fc1126c983eba66891fea8.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a three-stage framework by calling LLMs to collaboratively solve a problem. Their method, Trinity, interacts with several LLMs by assigning one of three roles (thinker, worker, and verifier). They demonstrate consistent improvements over individual frontier LLMs on a variety of math, code, and reasoning benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The paper achieves good performance on benchmarks (to the best of my knowledge, 86.2% is indeed state of the art on LiveCodeBench). \n* To the best of my knowledge, this is the first work I have seen that applies LLM routing to a multi-turn setting, so I think this approach is novel. \n* The study is comprehensive, with ablation studies for different design choices, and interpretability study to demonstrate the effectiveness of delgating tasks to different LLMs."}, "weaknesses": {"value": "I am concerned about the organization of the paper. Some notes:\n* Section 2 (problem formulation) feels very short. Some notation is not properly introduced: what is the definition of $B_{turn}$? how is it related to turns $T$? what is $B_{env}$, and what does it mean for the budget to be atomic?\n* Figure 2 could have better presentation - it is not immediately obvious that the penultimate output token is a part of the input text (which is my understanding) \n* Section 3.2: too many important details are moved to the appendix. For example,when you move the empirical analysis to the appendix, it seems like it is more of an afterthought rather than properly trying to motivate the use of evolutionary strategies. \n* Figure 3 is hard to follow, not enough visual prominence to show your method over others\n\nThe choice of singular-value finetuning for the coordinator head seems a bit strange. To my understanding, the method is using so as to make the number of learnable parameters extremely small. Yet in appendix A.3.2 you show that linear fine-tuning (e.g. just applying a full-rank matrix head) has the best performance. I am a little bit confused by the story here; in my mind, given the coordinator model is already quite small (0.6B), I would rather have full-power finetuning on the head to maximize performance than to save a few learnable parameters."}, "questions": {"value": "* I would like to have further discussion on the ablation study for removing the tri-role selection. I assume that you mean instead of assigning three roles, you directly route the query to one LLM and have it solve the problem (so essentially only 1 role). My question is what happens if you have only two (e.g. merge the thinker and worker together, and one verifier)? In Figure 1 it looks like the worker is simply following the instructions of the thinker, so couldn't we merge the two and get similar results (and also reduce the number of calls you need to make)? \n\n* I am still unsure on why the SLM needs to be trained via RL (again, why I think section 2 is too short). I am sure it works, but why wouldn't it be sufficient to train on simple (state, action) pairs, where the action is just the choice of picking one LLM over another?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1HgKoxwggz", "forum": "5HaRjXai12", "replyto": "5HaRjXai12", "signatures": ["ICLR.cc/2026/Conference/Submission1940/Reviewer_bpif"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1940/Reviewer_bpif"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761628712215, "cdate": 1761628712215, "tmdate": 1762915964181, "mdate": 1762915964181, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Trinity, a lightweight coordinator that selects appropriate LLMs and assigns specific roles for the selected LLM to solve the given query in multiple turns. The coordinator, which comprises a 0.6B SLM and a lightweight head, is optimized with sep-CMA-ES, a high efficient strategy for this problem. Experiments indicate that Trinity improves the overall performance on both in-distribution and out-of-distribution benchmarks in several tasks, and the sep-CMA-ES strategy significantly outperforms RL and RS for the optimization of the coordinator."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The Trinity framework is lightweight and concise, which facilitates the cooperation of multiple state-of-the-art LLMs to solve user queries. It also has a good generalization on several tasks including math, coding, reasoning and domain knowledge, indicating the potential of application on different tasks.\n2. The sep-CMA-ES strategy significantly outperforms the RL and RS methods for optimizing the coordinator, demonstrating its high efficiency."}, "weaknesses": {"value": "1. The effectiveness of the Trinity framework is limited compared to single-model baselines. As shown in Figure 3 and Table 1, compared with Gemini Pro 2.5, Trinity only brings an improvement about 1%-3% on all the in-distribution and out-of-distribution benchmarks except LiveCodeBench (where it outperforms GPT-5 for merely 3%). Considering the cost of training a coordinator and multi-turn interaction for selecting models, it shows limited effectiveness compared with simply selecting LLMs according to their adept tasks (e.g. select GPT-5 for coding tasks while Gemini Pro 2.5 for others).\n2.  The necessity of LLM selection is not demonstrated in the ablation study. It is unclear whether the performance will degrade when the Tri-role selection process in the Trinity framework is applied on a fixed single-model baseline instead of a selected LLM."}, "questions": {"value": "1. In Section 4.6, how does the separability of different tasks in representation space affect the performance of the coordinator?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z5vpVCzUHE", "forum": "5HaRjXai12", "replyto": "5HaRjXai12", "signatures": ["ICLR.cc/2026/Conference/Submission1940/Reviewer_Ev8j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1940/Reviewer_Ev8j"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835212627, "cdate": 1761835212627, "tmdate": 1762915963841, "mdate": 1762915963841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TRINITY, a novel framework for coordinating multiple, diverse foundation models (LLMs) at test-time. Instead of merging models at the weight level or using a large model for orchestration, TRINITY employs a highly lightweight coordinator. This coordinator consists of a small language model (SLM) (approx. 0.6B parameters) and an extremely small trainable head. The core mechanism involves a multi-turn protocol where the coordinator reads the full conversation history, extracts a contextual representation from the SLM's hidden state (specifically, the penultimate token's) , and then makes two decisions: (1) which LLM from the pool to select, and (2) which of three predefined roles—Thinker, Worker, or Verifier—that LLM should perform. A key technical contribution is the training methodology. The authors posit that standard reinforcement learning (RL) is ill-suited for this high-dimensional, budget-constrained optimization task. Instead, they successfully optimize the coordinator's lightweight head using a derivative-free evolutionary strategy, separable CMA-ES (sep-CMA-ES). The authors demonstrate that this approach is highly effective, achieving state-of-the-art (SOTA) performance on multiple benchmarks and setting a new record of 86.2% pass@1 on LiveCodeBench."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper's empirical results are its strongest asset. TRINITY consistently outperforms all individual baseline models (including powerful ones like GPT-5 and Gemini-2.5-Pro) and existing multi-agent routing methods across a wide range of tasks.\n2. The paper's central claim—that a tiny coordinator with fewer than 20K learnable parameters  can effectively orchestrate a pool of powerful LLMs—is a significant and non-obvious finding."}, "weaknesses": {"value": "1. The paper’s central claim of the \"lightweight\" coordinator's efficacy is insufficiently supported because it lacks comparisons to two of the most critical alternative coordinator designs. The authors never compare TRINITY to a system where a powerful LLM (e.g., GPT-4 or Gemini-2.5-Pro) is prompted to act as the coordinator. Such a baseline would use prompting to select the next agent and role. Its omission leaves a key question unanswered: is the 0.6B SLM's lightweight nature a genuine advantage (proving coordination is a simple task), or is it a limitation (acting as an understanding bottleneck that a stronger coordinator could overcome)? The paper’s comparison of training algorithms (ES vs. RL vs. RS)  is incomplete. A more standard and powerful baseline for training a router is SFT via behavioral cloning. The authors could have used their \"Per-Question-Best\" oracle data  to generate a dataset of expert decisions and then trained the 10K head. By omitting SFT, the claim that sep-CMA-ES is the superior optimization choice for this problem is not fully substantiated\n\n2. A significant weakness lies in the rigid design of the \"tri-role\" protocol (Thinker, Worker, Verifier). These three roles are not dynamic but are hard-coded into the coordinator's head architecture, which has a fixed output dimension. This design severely limits the system's flexibility. As the authors note in their conclusion, the system cannot yet act on plans involving tools. To add a new, necessary role like a \"Tool-User\" or \"Code-Executor,\" one cannot simply use a prompt; one would have to modify the model architecture and retrain the entire system from scratch. This makes the framework difficult to adapt to new capabilities or complex problems that do not fit neatly into the predefined tri-role schema."}, "questions": {"value": "see my comments on Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "24xEWHmiBe", "forum": "5HaRjXai12", "replyto": "5HaRjXai12", "signatures": ["ICLR.cc/2026/Conference/Submission1940/Reviewer_3SKS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1940/Reviewer_3SKS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902655737, "cdate": 1761902655737, "tmdate": 1762915963509, "mdate": 1762915963509, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TRINITY, which uses a lightweight coordinator to orchestrate multiple diverse LLMs at test time without modifying their weights. The coordinator consists of a compact SLM (≈0.6B) and a small decision head, and trained via sep-CMA-ES (diagonal covariance CMA-ES). Experiments on in-domain and out-domain benchmarks show consistent gains over single-model and routing/scaffolding baselines. And the ablation studies support the design choices of TRINITY's modules."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Motivation and Practicality: If substantiated, TRINITY offers a practical path to leverage strong closed and open models without retraining, with promising performance-to-cost potential. Additionally, the tri-role design and hidden-state routing signal could influence future multi-model systems.\n\n2. Originality: TRINITY leverages the hidden states of small LMs to capture the optimal models and roles for current inference states. Specifically, the explicit tri-role protocol is a clean and practical abstraction. Using penultimate-token hidden states (instead of generated text) to drive coordination decisions is also a thoughtful and effective (revealed by the ablations) design. And the choice of sep-CMA-ES and its theoretical explanations about block-ε-separability perspective are interesting optimization angles for noisy binary rewards and high evaluation cost.\n\n3. Clarity: The paper is well-written and easy to follow. Specifically, the method is well-defined, with clear problem formulation and a compact parametrization. The multi-turn protocol and role-specific prompting are coherent. Ablations and representation separability analyses support the claim that a linear head over SLM hidden states can be effective."}, "weaknesses": {"value": "The main weaknesses are in baseline settings. Addressing these would substantially strengthen the paper.\n\n1. The paper sets per-call max generation (4096 tokens) and turn limit (K=5) but does not report actual token usage of TRINITY and other baselines.\n2. See the left three baselines (Gemini2.5 / GPT-5 / Claude) in Figure 3. They are set to generate 4k or 20k within a SINGLE turn while TRNITY adopts multi-turn designs (thinker, worker, verifier). And any parallel TTS techniques are not considered as well. I think it is necessary to evaluating simple parallel strategies (like major@5) or more complicated ones towards a more fair comparison."}, "questions": {"value": "Please see the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "uT9cMjt2m2", "forum": "5HaRjXai12", "replyto": "5HaRjXai12", "signatures": ["ICLR.cc/2026/Conference/Submission1940/Reviewer_vdHP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1940/Reviewer_vdHP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971361399, "cdate": 1761971361399, "tmdate": 1762915963267, "mdate": 1762915963267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Message to all reviewers and AC"}, "comment": {"value": "We thank the reviewers for their insightful and constructive feedback. Your comments have allowed us to clarify ambiguities and further improve the paper. We have revised our paper to reflect these clarifications and improvements, with all changes highlighted in blue for your convenience. The following is a summary of our revision.\n\n* For **reviewer vdHP** we have\n    1. Added detailed token-usage tables for TRINITY, all collaboration baselines, and all single-model configurations under 5× self-reflection, 5× context, and default context, and discussed how TRINITY is typically more token-efficient than other agents coordination methods while remaining comparable to strong single models;\n    2. Incorporated parallel-strategy baselines, in particular majority-vote@5 on MMLU, and clarified their scope by showing that while such methods can be strong on multiple-choice benchmarks, TRINITY remains competitive there and, importantly, continues to apply effectively to open-ended coding, math, and reasoning tasks where simple parallel voting is not directly applicable.\n\n* For **reviewer 3SKS** we have\n    1. Implemented an “LLM-as-coordinator” baseline where Gemini-2.5-Pro is prompted to choose both model and role each turn, and found that this prompted coordinator underperforms the trained TRINITY coordinator and even some individual agents, suggesting that prompting alone is insufficient to robustly learn agent characteristics;\n    2. Added a supervised fine-tuning / behavioral cloning baseline trained on oracle agent selection labels, and shown that although SFT is competitive and stronger than REINFORCE and random search, sep-CMA-ES consistently performs best and avoids the prohibitive label-generation cost inherent to SFT in multi-turn coordination;\n    3. Clarified that our tri-role scheme encodes workflow stages (Thinker/Worker/Verifier) rather than hardcoded capabilities, so new skills such as tool use or code execution can be introduced by adding tool-enabled agents and prompting them appropriately under the Worker role without changing the architecture.\n\n* For **reviewer Ev8j** we have\n    1. Quantified the cost–effectiveness of training the coordinator and shown that, averaged over in-distribution tasks, TRINITY achieves non-trivial gains over the best single-model setups, including substantial relative error reductions in the high-accuracy regime (e.g., 11.76% on MATH500);\n    2. Added ablations that disable agent selection by forcing all queries to a fixed LLM (Claude-only, Gemini-only, or GPT-5–only) while retaining role selection, which consistently lowers average performance and isolates the benefit of adaptive agent coordination;\n    3. Significantly expanded the analysis of representation space separability with per-task linear SVM accuracies and a controlled synthetic study, showing a positive correlation between separability in the SLM’s representation space and the coordinator’s performance.\n\n* For **reviewer bpif** we have\n    1. Improved organization and clarity by refining Section 2’s notation, making the penultimate-token head input explicit in Figure 2, and restoring the key empirical analysis to the main text with a clearer explanation of our choice of sep-CMA-ES;\n    2. Clarified the coordinator parametrization by distinguishing singular value fine-tuning on selected backbone layers from full training of the head, and added a parameter-count table to quantify how lightweight each component is;\n    3. Expanded the tri-role ablations, including two-role and no-tri-role variants, showing that merging or removing roles reduces performance and highlighting the importance of a dedicated Thinker and the full tri-role protocol;\n    4. Added a supervised (state, action) SFT baseline based on oracle per-question-best labels, comparing it to sep-CMA-ES, REINFORCE, and random search, and discussing why SFT is both slightly weaker and much less scalable in the multi-turn setting due to label-generation cost."}}, "id": "ACa2iG2Dvd", "forum": "5HaRjXai12", "replyto": "5HaRjXai12", "signatures": ["ICLR.cc/2026/Conference/Submission1940/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1940/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission1940/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763706079383, "cdate": 1763706079383, "tmdate": 1763706079383, "mdate": 1763706079383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}