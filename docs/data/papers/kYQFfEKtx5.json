{"id": "kYQFfEKtx5", "number": 10513, "cdate": 1758174351312, "mdate": 1763726464214, "content": {"title": "C-Voting: Confidence-Based Test-Time Voting without Explicit Energy Functions", "abstract": "Neural network models with latent recurrent processing, where identical layers are recursively applied to the latent state, have gained attention as promising models for performing reasoning tasks.\nA strength of such models is that they enable test-time scaling, where the models can enhance their performance in the test phase without additional training. \nModels such as the Hierarchical Reasoning Model (HRM) and Artificial Kuramoto Oscillatory Neurons (AKOrN) can facilitate deeper reasoning by increasing the number of recurrent steps, thereby enabling the completion of challenging tasks, including Sudoku, Maze solving, and AGI benchmarks. \nIn this work, we introduce confidence-based voting (C-voting), a test-time scaling strategy designed for recurrent models with multiple latent candidate trajectories. \nInitializing the latent state with multiple candidates using random variables, C-voting selects the one maximizing the average of \\text{top-1} probabilities of the predictions, reflecting the model’s confidence. \nAdditionally, it yields $4.9\\\\%$ higher accuracy on Sudoku-hard than the energy-based voting strategy, which is specific to models with explicit energy functions.\nAn essential advantage of C‑voting is its applicability: it can be applied to recurrent models without requiring an explicit energy function. \nFinally, we introduce a simple attention-based recurrent model with randomized initial values named ItrSA++, and demonstrate that when combined with C-voting, it outperforms HRM on Sudoku-extreme ($95.2\\\\%$ vs. $55.0\\\\%$) and Maze ($78.6\\\\%$ vs. $74.5\\\\%$) tasks.", "tldr": "We introduce confidence-based voting (C-voting), a simple test-time strategy that boosts recurrent models’ reasoning reasoning ability.", "keywords": ["reasoning", "test-time scaling", "voting", "recurrent models"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d7f216b59e935d9339fc06378764a2891b4e205e.pdf", "supplementary_material": "/attachment/6215b15a205ef1283c5e3563247ad807e5dc8b72.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces C-voting, a model-agnostic test-time voting strategy for recurrent neural models used in complex reasoning tasks. Unlike previous methods like E-voting, C-voting does not require an explicit energy function. Instead, it generates multiple candidate solutions from random initializations and selects the one with the highest \"confidence,\" defined as the average top-1 probability across all prediction outputs. The authors also propose ItrSA++, a simple 3M-parameter recurrent attention model. Experiments show C-voting is effective: it boosts the performance of HRM on Sudoku-extreme (55.0% to 71.2%), outperforms E-voting on the AKOrN model (94.4% vs 89.5%), and, when combined with ItrSA++, achieves new state-of-the-art results on Sudoku-extreme (95.2%) and Maze-hard (78.6%)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, clearly organized, and effectively motivates the work. It pinpoints the limitation of E-voting (its reliance on an explicit energy function) and proposes a logical, general solution.\n2. The core contribution, C-voting, is intuitive and model-agnostic. Using the average top-1 probability as a proxy for confidence is a clean and effective way to extend test-time voting to a broader class of recurrent models that lack energy functions.\n3.  The results demonstrate the method's effectiveness. C-voting outperforms specialized E-voting on the AKOrN model. Furthermore, when combined with the new lightweight ItrSA++ model, it achieves promising performance on difficult reasoning benchmarks like Sudoku-extreme and Maze-hard."}, "weaknesses": {"value": "1.  The paper's core contribution, C-voting, hinges on defining confidence as the average of top-1 probabilities. This is a plausible choice, but it is one of many possible uncertainty metrics. It would be helpful to  compare this choice to other common metrics (e.g., negative entropy, sum of log probabilities). Without this comparison, it might be unclear if the chosen metric is optimal or simply one that works well for Sudoku, limiting the understanding of why C-voting is effective.\n\n2.  The paper introduces both a new voting method (C-voting) and a new model (ItrSA++). The SOTA results (e.g., 95.2% on Sudoku-extreme) are achieved by combining them. But it seems hard to disentangle the contributions. How much of the performance gain comes from the strong baseline architecture of ItrSA++ itself, and how much is added by C-voting? It would be helpful to provide the baseline (K=1) performance of ItrSA++ on all tasks to isolate and quantify the true benefit of C-voting. Furthermore, the design choices for ItrSA++ (Cross-Attention, SwiGLU, etc.) are not well-justified with ablation studies."}, "questions": {"value": "Please refer to above Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "3Jgs5af9ch", "forum": "kYQFfEKtx5", "replyto": "kYQFfEKtx5", "signatures": ["ICLR.cc/2026/Conference/Submission10513/Reviewer_aCB1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10513/Reviewer_aCB1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997272253, "cdate": 1761997272253, "tmdate": 1762921798011, "mdate": 1762921798011, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "### Summary\n\nThis paper introduces C-voting (Confidence-based Voting), a test-time scaling strategy for recurrent neural networks that enables performance improvements without additional training. Unlike existing energy-based voting (E-voting) methods that require explicit energy functions, C-voting works by:\n- Sampling multiple random initial latent states\n- Running the recurrent model from each initialization\n- Selecting the trajectory with the highest average top-1 prediction probability (confidence)\n\n### Main contributions:\n\n- C-voting method: A model-agnostic voting strategy applicable to any recurrent model with randomized initialization, not just those with explicit energy functions\n- Integration with HRM: Demonstrates that C-voting improves HRM's Sudoku-extreme accuracy from 55.0% to 71.2%\n- Comparison with E-voting: Shows C-voting outperforms E-voting on AKOrN for Sudoku-hard (94.4% vs 89.5%)\n- ItrSA++: Introduces a simple attention-based recurrent model (~3M parameters) that achieves state-of-the-art results when combined with C-voting: 95.2% on Sudoku-extreme, 94.4% on Sudoku-hard, and 78.6% on Maze-hard\n\nThe paper evaluates on three reasoning benchmarks (Sudoku-hard, Sudoku-extreme, Maze-hard) and shows that C-voting provides effective test-time scaling through parallelizable sampling rather than sequential depth increases. The method's effectiveness is attributed to selecting trajectories based on model confidence, which serves as a proxy for prediction accuracy in well-calibrated models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper identifies a genuine problem with E-voting (requires explicit energy functions) and proposes a model-agnostic alternative that can be applied to broader classes of recurrent models like HRM and recurrent transformers.\n- C-voting is simple to understand along with the theoretical justification provided in the paper of how selecting the most confident trajectory could be seen as searching for the optimal solution in Sudoku. The method itself is easy to implement and integrate into existing models without architectural changes. \n- Shows positive results across multiple models (HRM, AKOrN) and tasks, with substantial gains (e.g., HRM: 55.0% → 71.2% on Sudoku-extreme; AKOrN: 89.5% → 94.4% on Sudoku-hard). Although the paper doesn't report performance of all models across all the benchmark."}, "weaknesses": {"value": "- C-voting vs. E-voting is only shown on Sudoku-hard (Figure 3), despite the authors having trained AKOrN models and evaluating on three datasets total. This makes the claim that \"C-voting outperforms E-voting\" (Section 6.3) inadequately supported. A complete comparison on all benchmarks is needed to validate this central claim.\n- Figure 2's comparison seems misleading. it shows HRM's original performance as a flat line while scaling only C-voting's sample count. A fair comparison would show HRM's native test-time scaling method (increasing recurrence depth) vs. C-voting on a compute-normalized x-axis. The paper claims that the performance can saturate with increasing recurrence depth. However, the same is applicable for increasing the same count for C-voting and it's not clear whether C-voting would reach higher test-time optimized accuracy than HRM.\n- Evaluation is restricted to three small reasoning tasks (1,000 test samples each), all involving constraint satisfaction puzzles. HRM had evaluations on the ARC-AGI task while AKOrN had evaluations on image segmentation tasks, along with the Sudoku which provided further empirical grounding to their claims on generalization. The authors could have picked another evaluation in a different domain like ARC-AGI for further empirical grounding."}, "questions": {"value": "- Why is the C-voting vs. E-voting comparison (Figure 3) only shown on Sudoku-hard? You have trained AKOrN models and evaluate on Sudoku-extreme and Maze-hard elsewhere. Can you provide the C-voting vs. E-voting comparison on all three benchmarks to support the claim that C-voting outperforms E-voting more generally?\n- How well-calibrated are your models, and when does this assumption break down? Equation 14's justification assumes model calibration. Can you provide calibration curves (e.g., reliability diagrams) for your models? Figure 6 suggests Maze-hard has poor calibration - what are the conditions under which C-voting fails?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4RvXGIfwHt", "forum": "kYQFfEKtx5", "replyto": "kYQFfEKtx5", "signatures": ["ICLR.cc/2026/Conference/Submission10513/Reviewer_zXk5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10513/Reviewer_zXk5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762080951960, "cdate": 1762080951960, "tmdate": 1762921797613, "mdate": 1762921797613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this submission, the authors present C-Voting, a new method to readout from recurrent neural network-based reasoning models that uses prediction confidence. The proposed method starts with stochastically initializing the first state of an RNN with K candidate states. The RNN architecture is applied to map each of the candidate states to prediction logits. Based on average confidence, the final response of the RNN is chosen to be the output corresponding to that initial state which produces the largest prediction confidence. The authors empirically show that C-Voting outperforms previously proposed methods like E-Voting on a couple of standard reasoning benchmarks (Sudoku and Maze solving). In addition, the authors also propose ItrSA++ -- a new RNN architecture that works effectively with C-Voting and is notably simpler than prior art (HRM and AKOrN)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strengths:\n- The proposed approach is a straightforward, simple intervention to reading out task responses from RNNs. C-Voting is broadly applicable to RNNs applied to reasoning problems with a classification head, as the approach doesn't make any further restrictive assumptions on the network's architecture or training method. \n- Empirically, C-Voting outperforms E-Voting (although some key figures lack estimates of statistical significance) on challenging versions of both Mazes and Sudoku.\n- The paper is quite well-written, the explanation of C-Voting and ItrSA++ are accessible to the average reader."}, "weaknesses": {"value": "Weaknesses:\n- A weakness of C-Voting is that the approach might not work effectively when multiple random initializations of an RNN state don't yield  outputs with significantly varied confidence estimates. It is likely that such behavior might arise when training RNNs on increasingly challenging / high-dimensional reasoning problems. Can the authors comment on whether their experiments have explored such a failure mode of C-Voting, and how they intend to circumvent this issue?\n- Figures 2-4 showing comparison of C-Voting with other baselines doesn't show performance variance. The authors should report the statistical significance of differences observed between the baselines compared."}, "questions": {"value": "NA. Please refer to my above review."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gD7Scwzs6s", "forum": "kYQFfEKtx5", "replyto": "kYQFfEKtx5", "signatures": ["ICLR.cc/2026/Conference/Submission10513/Reviewer_8TRX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10513/Reviewer_8TRX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762134527979, "cdate": 1762134527979, "tmdate": 1762921797084, "mdate": 1762921797084, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes C‑voting, a test‑time voting strategy for recurrent models that generates multiple candidate trajectories by sampling random initial states and then selects the trajectory with the highest average top‑1 probability across all positions. Unlike energy‑based voting (E‑voting), C‑voting does not require an explicit energy function, making it applicable to recurrent models such as HRM and AKOrN. To verify its effectiveness, the paper also proposes a simple attention‑based recurrent architecture, ItrSA++. Empirically, the authors report sizeable gains: HRM with C‑voting improves on Sudoku‑extreme (from 55.0% to 71.2%), C‑voting surpasses E‑voting on Sudoku‑hard when many samples are used (e.g., 94.4 ± 0.1% vs. 89.5 ± 2.5% at 4096 candidates), and ItrSA++ with C‑voting outperforms HRM/AKOrN on Sudoku‑extreme and Maze‑hard. The paper also analyzes how C-voting can fail due to poor calibration of the recurrent model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The proposed method is straightforward and easy to use. The voting rule is model-agnostic and only requires per-position class probabilities. It should combine easily with other improvements to recurrent models and yield even better results.\n* The proposed method enables a new dimension of test-time scaling. Existing approaches mainly scale the number of iteration steps, which can saturate at large step counts. Here, multiple random initializations provide an orthogonal axis of improvement, and should be easy to be made parallel. Consequently, the proposed method should be able to make good use of the increasing compute power. \n* The reported empirical gains are impressive."}, "weaknesses": {"value": "* The effectiveness of C-voting relies on the model's calibration , which is not always satisfactory, especially when data are limited.\n* The experimental coverage seems to be selective, or at least the design of experiments is not fully explained. Only Sudoku-extreme and Sudoku-hard results are reported for Fig. 2 and 3, respectively. One would typically expect all of Sudoku, Sudoku-hard, Sudoku-extreme and Maze-hard to be included across Fig. 2-4.\n* Fig. 2 and 3 report the results from prior works. As the results in DL research can be highly sensitive to implementation details, it can be hard to tell if the improvements actually come from the proposed method.\n* Ablations on the effectiveness of ItrSA++ are absent. It is not impossible that the improvements actually come from a better design or implementation of the model rather than C-voting.\n* The idea of sampling multiple reasoning paths at test time for better output is long-standing in LLM research, such as [1] and [2]. Given the similarity, the novelty of the method is not significant."}, "questions": {"value": "* In Fig. 2, why is HRM with C-voting performs exactly identical with random samples from 2 to 16?\n* To mitigate calibration issues, I recommend the authors to consider standard calibration techniques. For example, temperature scaling [3] introduces a single scalar temperature for the output logits, which is calibrated on a separate validation set.\n\n[3] Guo, Chuan, et al. \"On calibration of modern neural networks.\" ICML 2017"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gCTN9Lnb8U", "forum": "kYQFfEKtx5", "replyto": "kYQFfEKtx5", "signatures": ["ICLR.cc/2026/Conference/Submission10513/Reviewer_exsu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10513/Reviewer_exsu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762246336422, "cdate": 1762246336422, "tmdate": 1762921796559, "mdate": 1762921796559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General comments"}, "comment": {"value": "We sincerely thank all reviewers for their constructive and detailed feedback.\nWe have revised the manuscript to address the raised concerns.\nRevised sentences are marked in red. For added and revised figures and tables, the captions are in red.\n\nMajor update includes\n1. Visualization of the calibration (Fig. 5): We added reliability diagrams for several temperatures and the relationship between ECE and accuracy. When varying the temperature, the ranking of the probability for each position remains unchanged, while the average confidence slightly changes, allowing candidate rankings to fluctuate a little. The calibration in each cell merely changes the ranking of average of confidence across positions. We need to consider a calibration that can take into account the relationships between positions, but it is probably better to tune the model instead.\n2. Correction of HRM+C-voting implementation (Fig. 4): We discovered that our modified HRM inference code unintentionally ignored the sampled initial latent states, which led to overly optimistic performance curves in the original submission. We have corrected the implementation and re-ran all HRM experiments. The revised results accurately reflect HRM’s behavior under randomized initialization, and show that the benefit of C-voting for HRM is more limited than previously reported. This issue was specific to HRM and does not affect any other model.\n3. Ablation study for ItrSA++ (Appendix D): We report ablations on\n- SwiGLU → GELU-FFN,\n- cross-attention → linear projection,\n- removing EMA/GT (training collapses).\n4. Additional experiments on AKOrN: We report C-voting vs. E-voting on Sudoku-extreme (Fig. 2(b)), which shows that C-voting overcomes E-voting for the Sudoku-extreme task. On the other hand, the test board accuracy of AKOrN for Maze-hard is 0."}}, "id": "a9tTxxh0oq", "forum": "kYQFfEKtx5", "replyto": "kYQFfEKtx5", "signatures": ["ICLR.cc/2026/Conference/Submission10513/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10513/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10513/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763725683469, "cdate": 1763725683469, "tmdate": 1763725683469, "mdate": 1763725683469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}