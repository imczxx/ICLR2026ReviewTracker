{"id": "tdF9DjCMjd", "number": 15641, "cdate": 1758253499536, "mdate": 1759897291523, "content": {"title": "Dual-Route Mental Imagery for Robust VLM-based Medical Image Diagnosis", "abstract": "Despite rapid progress of large vision-language models (VLMs), their diagnostic predictions in medical imaging remain brittle and often clinically inconsistent. Inspired by how radiologists rely on prototype-based mental imagery, we propose Dual-Route Mental Imagery, the first framework that formalizes prototype-conditioned reasoning for VLMs. Our method conditions diagnosis on (patient, prototype) pairs, instantiating two complementary reasoning routes—healthy and diseased—that yield interpretable reference-level traces and expose uncertainty when the two routes conflict. On chest X-ray benchmarks, our approach delivers substantial gains: on the Kermany dataset, it achieves 92.6% accuracy, on par with the expert-designed network LungConVT-Net, and further improves to 95.9% with uncertainty handling, while substantially outperforming single-image VLM inference. These results demonstrate that prototype-guided dual-route mental imagery not only enhances the robustness and accuracy of VLM-based diagnosis, but also provides a novel bridge between cognitive science and AI for healthcare.", "tldr": "We propose Dual-Route Mental Imagery, a prototype-conditioned reasoning framework that enhances VLM-based chest X-ray diagnosis with greater robustness and accuracy, achieving up to 95.9% accuracy and rivaling expert-designed networks.", "keywords": ["Vision-Language Models", "Medical Image Diagnosis", "Mental Imagery", "Chest X-ray", "Cognitive-inspired AI"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0879bdd25538fabe0a7ca55fad0dd1e4969b6a99.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for prototype-guided VLM X-ray diagnosis. They first form a database of healthy and pneumonia patient’s chest X-rays and cluster those.\nDuring training they pair images with prototypes of the same and opposite class, and perform cross-entropy based learning of the class prediction.\nDuring inference the model is prompted to compare the image with prototypes of the same and opposite class, rank how similar they are and predict the class. To reach a final prediction the per pair predictions are aggregated and weighted by the similarity of the pair. \nThey compare their method against a few baselines and evaluate effects of different hyperparameters."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper introduces a new method for prototype supported VLM diagnosis with decent clinical motivation and grounding.\n- The paper is well structured."}, "weaknesses": {"value": "1. ##### **Missing ablation of the effect of prototype inclusion**\n\n   The core claim that the prototype-supported reasoning improves performance is not experimentally validated. The proposed method finetunes the Bagel model for the diagnosis of Pneumonia in addition to all the prototyping pipeline. What is the performance of Bagel if you simply finetune it for Pneumonia classification without including prototypes? What is the performance if you also add ensembling of multiple generations as is done in the proposed method. Currently, the paper only compares with baselines that are not finetuned on that dataset and do not use ensembling.  \n2. **Unsupported claims of contrastive signal**  \n   The paper claims that through their cross entropy training of the class label, the model also learns a contrastive signal. This is not clearly the case and I am not convinced. The model might as well ignore the prototype image and just learn to diagnose Pneumonia based on the patient image. There is no evaluation if the model becomes better at identifying similar images  \n3. **Unintuitive method**  \n   I am not sure if this method would improve the trustworthiness. For example it is not clear and rather counter-intuitive to me why a prediction of an image as “healthy” should be weighted stronger the more similar it is to an image of a pneumonia patient as would be the case following the formulas in 3.4 (3) and (4)."}, "questions": {"value": "It is unclear to me how the model is actually trained. Is the loss calculated on the final prediction of the system? If yes, how are gradients routed to the language model? Or is the loss calculated on the VLM output? If yes, how is the reasoning and similarity prediction handled? Are they precomputed, masked, or also somehow supervised?\n\nThe work is built on Bagel but it is never cited."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ScSTdOagop", "forum": "tdF9DjCMjd", "replyto": "tdF9DjCMjd", "signatures": ["ICLR.cc/2026/Conference/Submission15641/Reviewer_9B3u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15641/Reviewer_9B3u"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15641/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760976424271, "cdate": 1760976424271, "tmdate": 1762925902594, "mdate": 1762925902594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes the Dual-Route Mental Imagery (DRMI) framework, which integrates prototype-conditioned reasoning for medical image diagnosis using vision-language models (VLMs). By conditioning the diagnosis process on pairs of patient images and prototypical exemplars (healthy and diseased), the method emulates a cognitive process similar to how radiologists compare new cases against prototype images. This approach not only improves diagnostic robustness but also provides interpretability and exposes uncertainty in cases where the two reasoning routes (healthy and diseased) diverge. The method is evaluated on chest X-ray datasets, demonstrating strong performance and improvement over standard VLM-based methods, with enhanced accuracy, specificity, and sensitivity, especially when uncertainty handling is integrated."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Innovative framework: Introduces a novel prototype-conditioned dual-route reasoning approach, drawing inspiration from cognitive science and radiologists' decision-making processes.\n\n- Improved interpretability and robustness: Provides transparent reasoning and uncertainty estimation, addressing common challenges in VLM-based medical image analysis.\n\n- Strong experimental results: Achieves competitive results on chest X-ray benchmarks (Kermany and Kaggle datasets), outperforming standard VLMs and even expert-designed networks in certain metrics."}, "weaknesses": {"value": "- Incremental innovation: The idea of prototype-conditioned reasoning and dual-route inference is conceptually interesting, but it closely follows the pattern of previous research in medical imaging, making the contribution seem more incremental than groundbreaking.\n\n- Limited scalability discussion: There is little analysis on how the proposed framework scales to more complex or larger datasets, or how it would handle more diverse medical imaging tasks.\n\n- Lack of comprehensive ablation study: While the paper evaluates different prototype retrieval settings, the contributions of individual components (e.g., uncertainty handling, prototype retrieval depth) are not fully dissected, making it difficult to assess the impact of each."}, "questions": {"value": "- How would this method perform on other medical imaging tasks, such as tumor detection or organ segmentation, where more detailed anatomical features are critical?\n\n- Can the dual-route framework be adapted to work with more complex VLMs or multi-modal medical data that includes text reports or lab results in addition to images?\n\n- What would the performance be on datasets with more diverse or noisy data, particularly in the presence of significant domain shifts or out-of-domain test data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "D63XhWyX93", "forum": "tdF9DjCMjd", "replyto": "tdF9DjCMjd", "signatures": ["ICLR.cc/2026/Conference/Submission15641/Reviewer_dy2H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15641/Reviewer_dy2H"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15641/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946571096, "cdate": 1761946571096, "tmdate": 1762925901960, "mdate": 1762925901960, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Dual-Route Mental Imagery (DRMI), a framework that integrates prototype-conditioned reasoning into Vision-Language Models (VLMs) for medical image diagnosis.  Inspired by how radiologists use mental imagery to compare current cases with prototypical healthy and diseased examples, the authors design a dual-route process:  \n- The Healthy Route compares the input image with healthy prototypes.  \n- The Diseased Route compares it with disease prototypes.  \n\nThe two routes jointly produce structured reasoning traces and uncertainty signals based on their agreement or divergence.  \nExperiments on the Kermany and Kaggle Chest X-ray datasets demonstrate that DRMI can improve interpretability and uncertainty awareness without architectural changes.  \n\nOverall, the paper presents a conceptually interesting idea—mimicking human diagnostic reasoning via dual prototype-conditioned routes—but the methodological novelty (the underlying mechanisms—prototype retrieval, contrastive pairing, and score fusion, closely resemble established retrieval-augmented or prototype-based learning methods) and scientific rigor (absence of standard deviations, statistical tests) may fall short of ICLR’s main-track expectations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**1. Conceptual originality and cognitive grounding**  \nThe dual-route design (Healthy Route vs. Diseased Route) is intuitive and cognitively interpretable, drawing inspiration from human mental imagery in clinical reasoning.\n\n**2. Method simplicity**  \nThe method enhances reasoning ability without modifying the VLM architecture or introducing complex losses.  \nPerformance improvement is achieved purely through structured input (patient–prototype pairs) and dual-route aggregation.\n\n**3. Relevance to clinical deployment**  \nThe paper explicitly emphasizes interpretability, uncertainty control, and clinical safety, making it relevant to real-world diagnostic applications."}, "weaknesses": {"value": "**Weaknesses**\n\n**1. Limited methodological novelty**  \nWhile the notion of “mental imagery” is appealing, the underlying mechanism closely resembles existing prototype learning or retrieval-augmented reasoning paradigms. The main innovation seems lie in task framing and input formulation.\n\n**2. Lack of statistical significance and uncertainty validation**  \nThe reported metrics (accuracy, F1) are presented as single averages without variance or confidence intervals.  \nNo statistical tests (e.g., paired t-test, bootstrap CI) are provided, making it difficult to assess the reliability of the improvements.\n\n**3. Computational cost and efficiency not discussed**  \nThe dual-route reasoning requires retrieving top-M prototypes  for each test sample and running the VLM 2M times,  increasing inference cost.  \nIt would strengthen the paper to include analysis of how prototype pool size affects accuracy and computational efficiency.\n\n**4. Scalability and generalization beyond binary classification**  \nThe framework is only evaluated on binary pneumonia vs. normal classification.  \nIt remains unclear whether DRMI can scale to multi-label or multi-disease settings, or how prototype diversity impacts computational and memory requirements.\n\n---\n\n**Minor Issues**\n\n1. Terminology inconsistency — “Dual-Route Mental Imagery” and “Prototype-Conditioned Reasoning” are used interchangeably and should be unified or clarified.  \n2. Fusion weights α=β=1.0 appear fixed; the paper does not evaluate alternative combinations.  \n3. In Figure 1(c), the arrow pointing to “Final Prediction” is unclear and should be revised.  \n4. In Table results, the Acc@C column under the tie→P configuration is marked “–”; clarification is needed on whether this metric was omitted or uncomputed."}, "questions": {"value": "**1. Methodological novelty and conceptual clarity**  \nThe paper’s central idea is compelling, but the algorithmic innovations beyond task framing remain unclear.\n\n> **Questions:**  \n> - Beyond task framing, what is the core algorithmic novelty of Dual-Route Mental Imagery (DRMI)?   In what precise mathematical or operational terms does DRMI differ from prototype learning, retrieval-augmented reasoning, or case-based VLM frameworks?  \n\n---\n\n**2. Experimental design and statistical rigor**  \nReported gains  are provided without measures of dispersion, limiting conclusions about reliability.\n\n> **Questions:**  \n> - Were all experiments repeated with multiple random seeds?  \n> - Please report mean ± standard deviation or confidence intervals, and indicate whether the improvements are statistically significant.  \n> - How sensitive are results to prototype selection and retrieval randomness?\n\n---\n\n**3. Computational and practical efficiency**  \nDual-route reasoning scales inference cost linearly with the number of prototypes, requiring 2M VLM invocations per image.\n\n> **Questions:**  \n> - What is the runtime and memory overhead relative to single-image Bagel inference under the same hardware and batch size?  How does latency change as M increases, and what is the accuracy–latency trade-off?  \n---\n\n**4. Scalability and generalization**  \nEvaluation is limited to binary pneumonia vs. normal classification, leaving questions about broader applicability.\n\n> **Questions:**  \n> - How would the dual-route mechanism extend to multi-class or multi-label settings?   Does performance degrade as the number/diversity of disease prototypes grows?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wZP8ZikaAV", "forum": "tdF9DjCMjd", "replyto": "tdF9DjCMjd", "signatures": ["ICLR.cc/2026/Conference/Submission15641/Reviewer_rTww"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15641/Reviewer_rTww"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15641/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762137099958, "cdate": 1762137099958, "tmdate": 1762925901282, "mdate": 1762925901282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}