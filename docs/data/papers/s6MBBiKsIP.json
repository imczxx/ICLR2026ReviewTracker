{"id": "s6MBBiKsIP", "number": 16396, "cdate": 1758264209140, "mdate": 1759897242991, "content": {"title": "Adaptive Quality-Diversity Trade-offs for Large-Scale Batch Recommendation", "abstract": "A core research question in recommender systems is to propose batches of highly relevant and diverse items, that is, items personalized to the user's preferences, but which also might get the user out of their comfort zone. This diversity might induce properties of serendipidity and novelty which might increase user engagement or revenue. However, many real-life problems arise in that case: e.g., avoiding to recommend distinct but too similar items to reduce the churn risk, and computational cost for large item libraries, up to millions of items. First, we consider the case when the user feedback model is perfectly observed and known in advance, and introduce an efficient algorithm called B-DivRec combining determinantal point processes and a fuzzy denuding procedure to adjust the degree of item diversity. This helps enforcing a quality-diversity tradeoff throughout the user history. Second, we propose an approach to adaptively tailor the quality-diversity tradeoff to the user, so that diversity in recommendations can be enhanced if it leads to positive feedback, and vice-versa. Finally, we illustrate the performance and versatility of B-DivRec in the two settings on synthetic and real-life data sets on movie recommendation and drug repurposing.", "tldr": "An efficient and flexible algorithm is introduced for large-scale batch recommandation, which adaptively tunes the quality-diversity tradeoff based on user interaction.", "keywords": ["recommender system", "determinantal point processes", "online learning", "diversity", "serendipity"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/44ed46f0aadbe3ac3a201e485c72ed2659ec69d9.pdf", "supplementary_material": "/attachment/09a005b679a575f2152d03a0b28a57aa51ba34d0.zip"}, "replies": [{"content": {"summary": {"value": "B-DivRec aims to maximize both individual- and aggregate-level diversity of an existing model by post-processing while maintaining accuracy.\nIn this process, users provide feedbacks for their recommendation lists.\nB-DivRec modifies DPP and introduces hyperparameters to control trade-off between accuracy and diversity."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* B-DivRec targets both individual- and aggregate-level diversity in sequential recommendation.\n* Authors provide well-packaged experimental code for reproducibility."}, "weaknesses": {"value": "* The paper is hard to follow.\nFor instance, the problem definition is scattered across the Notation and Metric sections, and the proposed method is mixed with existing works, making it difficult to clearly distinguish the contributions.\n* Problem definition is unclear.\nI assume that the problem is to maximize both individual and aggregate diversity while maintaining accuracy by post-processing an existing model for a series of users where they provide feedbacks for each item in the recommendation.\nYet, some details are still unclear such as how users provide their feedback, and how does the feedback model predicting those exist.\n* The paper reviews only DPP and MMR for previous works and compares the proposed method with only DPP and its variants.\nHowever, both aggregately and individually diversified recommendations are deeply studied topics so that authors should compare their work with other existing methods.\n* The novelty of the proposed method appears insufficient.\nAs I understand it, the main idea of B-DivRec is:\n(1) introducing a trade-off hyperparameter $\\lambda$ to balance the contributions of the rating matrix and the similarity matrix in the DPP kernel, and\n(2) filtering similar items using a threshold hyperparameter $\\alpha$.\nCompared to the conventional DPP framework, this approach seems incremental, as it mainly involves adding a few hyperparameters and performing hyperparameter tuning.\nFurthermore, the paper does not clearly explain what specific challenges this idea aims to address, nor why introducing these hyperparameters is an effective way to tackle them.\n* Proposed metric seems highly sensitive to the threshold $\\tau$, which may lead to unfair experimentation.\n* Experiments are performed mainly on synthetic datasets rather than real datasets.\n* Backbone recommendation models are not clearly specified.\n* Performance improvement of the proposed method is marginal."}, "questions": {"value": "* Please refer to weakneses above.\n* How does the recommender system receive the user feedback for the recommendation results during the experiments?\nReal-world datasets such as MovieLens contain user feedback for only interacted items which are very little, so most recommended items would not be interacted with the user.\nMoreover, if duplicate recommendations of items seen in the training dataset are not allowed as usual, conducting such experiments would have been more challenging."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3K0Qmd0prH", "forum": "s6MBBiKsIP", "replyto": "s6MBBiKsIP", "signatures": ["ICLR.cc/2026/Conference/Submission16396/Reviewer_sw7v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16396/Reviewer_sw7v"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906710324, "cdate": 1761906710324, "tmdate": 1762926518798, "mdate": 1762926518798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a unified DPP-based framework that cleanly separates quality and diversity with an explicit weight $\\lambda$, subsuming prior DPP variants. Building on this, B-DivRec introduces a “fuzzy denuding” step that filters items too close to a user’s history in feature space, enabling scalable global diversity with linear-in-N computation via Nyström and fast MAP/ $\\alpha$ -DPP routines. An adaptive $\\lambda$ procedure (AdaHedge-style) tunes the quality-diversity balance per user online. Experiments on synthetic datasets up to 15M items, MovieLens, and a drug repurposing benchmark show competitive or superior trade-offs compared to conditional DPP and MMR; notably, B-DivRec is strong on PREDICT while MMR dominates on MovieLens, and adaptive $\\lambda$ improves relevance in some settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents a unified DPP-based formulation with an explicit trade-off parameter $\\lambda$, providing a clear theoretical foundation that encompasses several existing diversity-aware recommendation methods such as conditional DPP and MMR.  \n- The proposed B-DivRec approach combines a denuding operation in feature space with Nystrom approximation, achieving linear scalability and enabling large-scale batch recommendation with explicit control over both global and local diversity.  \n- The adaptive update of $\\lambda$ per user is conceptually appealing, allowing personalized control of the quality–diversity balance and offering a promising direction for user-adaptive recommendation systems."}, "weaknesses": {"value": "* Despite its theoretical elegance, the paper does not demonstrate consistent empirical superiority of the proposed method. On the MovieLens benchmark, MMR achieves higher relevance scores than B-DivRec; the explanation (history-vector collinearity) is qualitative and lacks deeper quantitative analysis.\n* The overall effectiveness of B-DivRec appears dataset-dependent, strong on PREDICT but weaker on MovieLens, raising questions about robustness and generality across domains with different diversity characteristics.\n* The experimental evaluation includes only classical baselines and omits stronger modern re-ranking or diversification methods (e.g., xQuAD, deep DPPs, intent-aware models), so the practical advantage remains unclear.\n* The adaptive  $\\lambda$ update lacks formal guarantees (e.g., convergence or regret bounds) and is tested only under clean, noise-free feedback, limiting confidence in real-world, noisy environments.\nλ update lacks formal guarantees (e.g., convergence or regret bounds) and is tested only under clean, noise-free feedback, limiting confidence in real-world, noisy environments."}, "questions": {"value": "* Could you provide quantitative analysis for why MMR outperforms B-DivRec on MovieLens (e.g., effects of popularity bias, embedding collinearity, or limited intrinsic diversity), and how B-DivRec might be adapted to mitigate these factors?\n* Would B-DivRec improve on MovieLens with richer embeddings (e.g., hybrid content–collaborative features) or with per-cluster tuning of $\\alpha$ and $\\lambda$?\n* Can the adaptive $\\lambda$ be evaluated under noisy/implicit feedback (clicks, exposure bias) to assess robustness and practicality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "KaLxV6bx9P", "forum": "s6MBBiKsIP", "replyto": "s6MBBiKsIP", "signatures": ["ICLR.cc/2026/Conference/Submission16396/Reviewer_r1zz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16396/Reviewer_r1zz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929898592, "cdate": 1761929898592, "tmdate": 1762926518306, "mdate": 1762926518306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates a scalable approach that considers the relevance-diversity trade-off in recommender systems.\nAlthough the proposed framework is simple, the authors provide a detailed discussion of the implementation (especially in the appendices) to account for practical scalability.\nWhile it lacks theoretical contributions such as regret bounds, the paper's rich discussion on practical aspects makes it valuable to the recommender systems community.\nOn the other hand, the numerical experiments on execution time are limited to small-scale settings (e.g., $B=3$), and the method does not appear to be faster than existing methods (Tables 10-14).\nTherefore, the superiority of the proposed method is not sufficiently demonstrated."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper addresses a highly complex yet practical problem: incorporating diversity in a setting where the item set/batch is recommended sequentially to a user.\n2. This paper provides comprehensive discussions covering both theory and implementation."}, "weaknesses": {"value": "1. The experimental results lack persuasiveness. Specifically, the paucity of comparisons regarding execution time with existing methods undermines the paper's main claim of scalability.\n2. Although the paper uses theoretical notation, its theoretical contribution is limited. For example, it mentions regret but does not discuss an algorithmic regret bound or similar rigorous analysis.\n3. The assumption of noiseless feedback (Assumption 3.4) appears highly unrealistic. In the context of recommender systems, there are few practical scenarios where the expected reward can be directly observed.\n4. In my opinion, addressing the relevance-diversity trade-off is a means to an end, and the authors should have prioritized a proper problem formulation. Framing the problem using a model like rotting bandits [a] might have enabled a more robust discussion of concepts such as regret.\n\n\n[a] Rotting bandits, N Levine, K Crammer, S Mannor - Advances in neural information processing systems, 2017"}, "questions": {"value": "1. What were the results of the numerical experiments on execution time when varying the batch size?\n2. How is the proposed method intended to be executed in scenarios where the expected reward cannot be observed, such as with binary feedback (e.g., clicks)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XdnCfYTH9F", "forum": "s6MBBiKsIP", "replyto": "s6MBBiKsIP", "signatures": ["ICLR.cc/2026/Conference/Submission16396/Reviewer_SNoM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16396/Reviewer_SNoM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000144593, "cdate": 1762000144593, "tmdate": 1762926517953, "mdate": 1762926517953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}