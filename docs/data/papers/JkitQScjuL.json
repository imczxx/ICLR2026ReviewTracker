{"id": "JkitQScjuL", "number": 10401, "cdate": 1758170072404, "mdate": 1759897653100, "content": {"title": "On the Alignment Between Supervised and Self-Supervised Contrastive Learning", "abstract": "Self-supervised contrastive learning (CL) has achieved remarkable empirical success, often producing representations that rival supervised pre-training on downstream tasks. Recent theory explains this by showing that the CL loss closely approximates a supervised surrogate, Negatives-Only Supervised Contrastive Learning (NSCL), as the number of classes grows. Yet this loss-level similarity leaves an open question: {\\em Do CL and NSCL also remain aligned at the representation level throughout training, not just in their objectives?}\n\nWe address this by analyzing the representation alignment of CL and NSCL models trained under shared randomness (same initialization, batches, and augmentations). First, we show that their induced representations remain similar: specifically, we prove that the similarity matrices of CL and NSCL stay close under realistic conditions. Our bounds provide high-probability guarantees on alignment metrics such as centered kernel alignment (CKA) and representational similarity analysis (RSA), and they clarify how alignment improves with more classes, higher temperatures, and its dependence on batch size. In contrast, we demonstrate that parameter-space coupling is inherently unstable: divergence between CL and NSCL weights can grow exponentially with training time.\n\nFinally, we validate these predictions empirically, showing that CL–NSCL alignment strengthens with scale and temperature, and that NSCL tracks CL more closely than other supervised objectives. This positions NSCL as a principled bridge between self-supervised and supervised learning.", "tldr": "", "keywords": ["Representation alignment", "self-supervised learning", "contrastive learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/37bd88f600ea804b5be768302972223a40875582.pdf", "supplementary_material": "/attachment/130227dce19513f0cac79f458f308b7a0fc6de76.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies whether self-supervised contrastive learning (CL) and a supervised counterpart, Negatives-Only Supervised Contrastive Learning (NSCL), produce similar representations during the training process. The authors theoretically prove that CL and NSCL maintain close alignment in their representation spaces under realistic conditions. They provide probabilistic bounds for alignment metrics such as centered kernel alignment (CKA) and representational similarity analysis (RSA), showing that representation similarity improves with larger numbers of classes, higher temperature, and certain batch size conditions. Empirical results confirm the theory: CL and NSCL representations become increasingly aligned as model scale and temperature grow, with NSCL tracking CL more closely than other supervised objectives."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe theoretical proofs and analysis are thorough and well-founded, providing a clear explanation of the differences between contrastive learning and negative-only supervised learning.\n2.\tThere is a strong alignment between the theoretical and empirical results.\n3.\tThe paper is well-written, with a clear and accessible logic flow that is easy to follow"}, "weaknesses": {"value": "1.\tMy primary concern is the lack of clear practical insights derived from the theoretical analysis in this paper. For instance, [1] identifies that downstream classification performance depends on labeling errors and the connectivity of the augmentation graph, while [2] and its follow-up works analyze the role of negative samples in contrastive learning. However, in this paper, what practical benefits can we gain from the theoretical relationship between CL and NSCL, especially considering that we have no access to labeled data in self-supervised learning? In other words, what real-world applications or improvements in contrastive learning can be derived from the theoretical framework presented here?\n2.\tI'm uncertain whether the theoretical analysis offers additional advantages over existing work. Specifically, [2] also characterizes the training process of contrastive learning and establishes guarantees between contrastive loss (even when it is not optimal) and supervised downstream loss. The authors note that prior works often rely on restrictive assumptions, but several follow-up works have relaxed these assumptions, including the conditional independence assumption. It would be helpful to further discuss how the theoretical analysis in this paper improves to the existing body of work.\n3.\tAnother weakness is the lack of connection between the terms in the theoretical bounds and the design choices in contrastive learning. For example, while the paper shows there is still a gap between CL and NSCL, it is unclear which specific terms in the bounds contribute to this gap. Additionally, how might we modify these terms to close the performance gap between the two methods?\n4.\tThe empirical results show that the performance of CL and NSCL is still significantly below that of supervised contrastive learning, particularly on datasets like ImageNet. This raises the question of whether focusing only on supervised information in negative pairs limits the potential of the analysis. For instance, [3] directly compares the gap between contrastive learning and supervised contrastive learning. Besides, it is impractical to only use NSCL if we have access to supervised information.\n\n[1] HaoChen J Z, Wei C, Gaidon A, et al. Provable guarantees for self-supervised deep learning with spectral contrastive loss[J]. Advances in neural information processing systems, 2021, 34: 5000-5011.\n\n[2] Saunshi N, Plevrakis O, Arora S, et al. A theoretical analysis of contrastive unsupervised representation learning[C]//International conference on machine learning. PMLR, 2019: 5628-5637.\n\n[3] Cui J, Huang W, Wang Y, et al. Rethinking weak supervision in helping contrastive learning[C]//International Conference on Machine Learning. PMLR, 2023: 6448-6467."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XMGc6uHf5m", "forum": "JkitQScjuL", "replyto": "JkitQScjuL", "signatures": ["ICLR.cc/2026/Conference/Submission10401/Reviewer_nMEv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10401/Reviewer_nMEv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761283146513, "cdate": 1761283146513, "tmdate": 1762921717798, "mdate": 1762921717798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper asks whether the objective-level affinity between contrastive learning (CL) and negatives-only supervised contrastive learning (NSCL) holds to the representation trajectories. Specifically, the authors bound the discrepancy between the cosine similarity matrices induced by CL and NSCL under shared randomness, and then derive bounds for CKA and RSA. Experiments with ResNet-50 support the predicted dependencies on the number of classes $C$, batch size $B$, and temperature $\\tau$. In particular, CL aligns much more closely with NSCL than with SCL or cross-entropy."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A technically sound similarity-space analysis of representations. This is an incremental contribution over recent connections between CL and NSCL [2].\n1. For large $B$ and $C$, the main high-probability result is simplified to\n    $$\n        \\|\\Sigma^{\\mathrm{CL}}-\\Sigma^{\\mathrm{NSCL}}\\|_F =  \\tilde O\\left(\\frac{1}{\\sqrt{B}}\\left(\\frac{1}{C} + \\frac{1}{\\sqrt{B}}\\right)\\right),\n    $$\n    ignoring the explicit dependence on $\\tau$ and $T$. This in turn gives bounds on representation similarity for CL and NSCL. The empirical trends in $C$, $B$, and $\\tau$ match the theory, and the CL-NSCL pair consistently shows stronger alignment than CL-SCL or CL-CE."}, "weaknesses": {"value": "1. Appendix D explains why the proposed \"similarity-descent\" mirrors small-step gradient descent on parameters. Additional remark of that argument in the main text would help follow the logic from SGD updates to similarity dynamics.\n1. The theory assumes class-balanced sampling. It would be useful to discuss how class imbalance alters the bound, for example by replacing $1/C$ with empirical class priors and indicating the resulting rate.\n1. Prior work reports a non-trivial CKA between SimCLR and supervised ResNet-50 trained independently [1]. It would be great to have additional discussions on the extension of the current theoretical results to a broader class of supervised learning algorithms.\n1. A comment on the tightness of the upper bound for $\\|\\Sigma^{\\mathrm{CL}} - \\Sigma^{\\mathrm{NSCL}}\\|_F$ would be helpful.\n\n**Minor Comments**\n\n1. Line 308: replace \"GPUs\" with \"GPU\".\n1.  \"ImageNet-1K\" (line 84) vs \"ImageNet-1k\" (Figure 3 lower right)\n1. The per-anchor CL and NSCL loss definitions would be improved for clarity.\n1. Move the ``Additional notation for high-probability factors'' so it appears immediately before Theorem 1.\n\n[1] Grigg, T. G., Busbridge, D., Ramapuram, J., \\& Webb, R. (2021). Do self-supervised and supervised methods learn similar visual representations? arXiv:2110.00528.\n\n[2] Luthra, A., Yang, T., \\& Galanti, T. (2025). Self-Supervised Contrastive Learning is Approximately Supervised Contrastive Learning. arXiv:2506.04411."}, "questions": {"value": "1. How does the analysis extend to class-imbalanced sampling? \n1. Is the bound for $\\|\\Sigma^{\\mathrm{CL}}-\\Sigma^{\\mathrm{NSCL}}\\|_F$ tight?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zSZ1ixxVFp", "forum": "JkitQScjuL", "replyto": "JkitQScjuL", "signatures": ["ICLR.cc/2026/Conference/Submission10401/Reviewer_DFRi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10401/Reviewer_DFRi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794327587, "cdate": 1761794327587, "tmdate": 1762921717258, "mdate": 1762921717258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work provides an in-depth theoretical analysis of the alignment between Self-supervised Contrastive Learning (CL) and Negative-only Supervised Contrastive Learning (NSCL). In particular, a bound is derived coupling the CL and NSCL similarity dynamics, demonstrating the CL-NSCL behavioral alignment. Several experiments are also conducted to empirically validate the findings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Leveraging similarity-space dynamics, this paper bridges CL and NSCL behavior in a theoretically rigorous manner. Empirical verifications are also done thoroughly, with near real-world scale datasets like tiny-ImageNet. Empirical results support theoretical findings."}, "weaknesses": {"value": "As the authors stated in the conclusion/limitation section, the proposed bounds can be loose under large-scale settings due to the exponential factors on cumulative step size.\n\nMore importantly, please see my question below regarding the discrepancy between similarity-based dynamics and parameter-based dynamics, which I think is a very important step in the derivation of the proposed bound. It perhaps deserves a more detailed explanation."}, "questions": {"value": "In line 1054 (Appendix D), the authors stated that \"the difference between the two trajectories stays small when the step sizes are not too aggressive.\" However, Eq. (9) contains an exponential term on cumulative learning rate—does this really guarantee that the trajectories stay close even if the step sizes are not aggressive? Even so, how is this effect accounted for in Thm. 1, while practical algorithms perform parameter-GD instead of similarity-GD?\n\nIntuitively, the similarity-GD and parameter-GD differ significantly as shown in Eq. (5) ($P_t := J_t J_t^\\top$). The update delta of each similarity entry, when trained via parameter-GD, can vary depending on the network gradient evaluated at different input points. I find it somewhat counter-intuitive that the results on similarity-GD can be applied to algorithms utilizing parameter-GD. Therefore, It would be glad to hear the authors' responses on this matter (or please correct me if I misunderstood anything)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xdoXlURSyB", "forum": "JkitQScjuL", "replyto": "JkitQScjuL", "signatures": ["ICLR.cc/2026/Conference/Submission10401/Reviewer_Dkwy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10401/Reviewer_Dkwy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985476912, "cdate": 1761985476912, "tmdate": 1762921716661, "mdate": 1762921716661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "While contrastive learning and negatives-only supervised contrastive learning have similar objectives, this does not necessarily imply that they will learn similar representations through training. Using CKA and RSA, the authors analyze this alignment's emergence in various conditions to provide a better understanding of the similarities between such methods.\nThis is complemented by clear theoretical results that provide intuition on each parameter's influence on this alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Beyond training objective similarity, the authors provide an analysis of representation similarity through training, providing better insights in similarities between CL and NSCL.\n\n- On top of the thorough experiments, the authors prove clear theoretical results that help guide empirical analysis.\n\n- The detailed explanation of the bound obtained in Theorem 1 lines 246-262 is greatly appreciated to provide more practical intuitions in the result.\n\n- The overall work strengthens our understanding of similarities and differences between CL and related supervised learning algorithms.\n\n- Experiments are done at a good practical scale (up to ImageNet using a resnet 50) which helps yield more practically relevant insights."}, "weaknesses": {"value": "1) My main issue is that it is unclear whether alignment is beneficial in practice. Having CL be more aligned with a **fixed** high performing NSCL model is most likely good in practice. However in the scenarios where alignment increases, it is possible that performance suffers as well. It would be interesting to have more data points regarding alignment vs performance potential tradeoffs.\n\n2) While alignment is studied in the general case, it seems that it can get worse in practical settings.\nLine 415-146 “Alignment increases with higher values of $\\tau$”. Usually for CL temperatures used tend to be low, with performance decreasing as it is increases, suggesting that increasing alignment through temperature comes at a practical cost.\n\n3) Line 079: $C$ is discussed but not introduced yet (I assume it is the number of classes from line 125). It would be good to have its meaning be clear when first discussed."}, "questions": {"value": "1) In Figure 2 there seems to be a dynamics change around 10-100 epochs when looking at SCL and CE, any intuition as to why ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GJmMouu39Z", "forum": "JkitQScjuL", "replyto": "JkitQScjuL", "signatures": ["ICLR.cc/2026/Conference/Submission10401/Reviewer_SXMf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10401/Reviewer_SXMf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011222646, "cdate": 1762011222646, "tmdate": 1762921716119, "mdate": 1762921716119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}