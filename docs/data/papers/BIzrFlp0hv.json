{"id": "BIzrFlp0hv", "number": 10487, "cdate": 1758173375912, "mdate": 1763303948690, "content": {"title": "PRO-MOF: Policy Optimization with Universal Atomistic Models for Controllable MOF Generation", "abstract": "Generating physically stable and novel metal-organic frameworks (MOFs) for inverse design that meet specific performance targets is a significant challenge. Existing generative models often struggle to explore the vast chemical and structural space effectively, leading to suboptimal solutions or mode collapse. To address this, we propose PRO-MOF, a hierarchical reinforcement learning (HRL) framework for controllable MOF generation. Our approach decouples the MOF design process into two policies: a high-level policy for proposing chemical building blocks and a low-level policy for assembling their 3D structures. By converting the deterministic Flow Matching model into a Stochastic Differential Equation (SDE), we enable the low-level policy to perform compelling exploration. The framework is optimized in a closed loop with high-fidelity physical reward signals provided by a pre-trained universal atomistic model (UMA). Furthermore, we introduce a Pass@K Group Relative Policy Optimization (GRPO) scheme that effectively balances exploration and exploitation by rewarding in-group diversity. Experiments on multiple inverse design tasks, such as maximizing CO2 working capacity and targeting specific pore diameters, show that PRO-MOF significantly outperforms existing baselines, including diffusion-based methods and genetic algorithms, in both success rate and the discovery of top-performing materials. Our work demonstrates that hierarchical reinforcement learning combined with a high-fidelity physical environment is a powerful paradigm for solving complex material discovery problems.", "tldr": "", "keywords": ["metal-organic framework", "material generation", "AI for science", "physical modeling"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/849d5d05e7daa05c05383b53f35397aede4d09fd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents PRO-MOF, a framework using hierarchical reinforcement learning to generate new, stable molecules. It breaks down the design process into two components: chemical building block design and 3D structural design. It also incorporates various components to help stabilise the optimisation process, such as using a reward annealing strategy. The experimental results show good improvement on success rate and diversity preservation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written and presented with clear writing and illustrations. The components of the framework are separated into different categories and explained well on how they can address the shortcomings of the current methods. The use of a hierarchical reinforcement learning framework and dividing into a chemical design and a 3D structural design are novel. The practical aspect of considering stability and diversity as the aim in this work is also important to transit theoretical molecular design into real life synthesizability."}, "weaknesses": {"value": "While it is not a weakness in itself, the results achieved on this framework might be dependent on which pre-selected building blocks used (described in the first section of Preliminaries). Therefore it can limited the results within the exploration space or the molecule generated made possible by these building blocks."}, "questions": {"value": "How is this framework scaled to more complex and bigger molecules? (in terms of performance and computational needed)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZNk4ECSW16", "forum": "BIzrFlp0hv", "replyto": "BIzrFlp0hv", "signatures": ["ICLR.cc/2026/Conference/Submission10487/Reviewer_dK3i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10487/Reviewer_dK3i"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667061296, "cdate": 1761667061296, "tmdate": 1762921777398, "mdate": 1762921777398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a hierarchical generative model for generating Metal-Organic Frameworks. They optimize their model with GRPO with a bi-level policy. The high-level policy generates SMILE strings representing the sequence structure. The geometric features of the generated structure are then computed using the low-level flow-matching policy. The authors point out that a limitation of existing methods is mode collapse, in which the model converges to a locally optimal solution that does not span the space of potential MOF structures. They address this by generating multiple solutions to evaluate and improve the policy's exploration. The experiments suggest that the design choices the authors make result in measurable improvements in generating diverse new MOFs."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written and addresses a complex search problem using a hierarchical RL solution. It was easy to understand the problem the authors were addressing (mode collapse in MOF generation), and the solutions were easy to identify. The author's experiments confirm the benefits of the proposed modifications and offer a solution that can advance the identification of new MOFs using AI."}, "weaknesses": {"value": "Overall, the paper delivers on its promise. The author's solution improves performance for the target task (generating MOFs), and sufficient experiments are reported to justify the design decisions. I don't think there are any significant methodological contributions in this paper — the authors propose sampling more potential candidates before calculating reward as a substantial contribution (Pass @ K), and the SDE formulation is from prior research — but because they solve a seemingly significant problem, this isn't necessarily a major issue."}, "questions": {"value": "> Have the authors considered other methods to avoid mode collapse? For example, adding an entropy bonus to the reward signal? \n\n> Equation 4: For clarification, is the major takeaway that for each discrete structure generated by the higher-level policy, instead of generating one example, you generated K examples? So, if you have 10 potential structures instead of 10 evaluations, if K = 10, there would now be 100 evaluations?\n\n> Were any ablation experiments conducted to justify the reward annealing scheme? We could not find any, and consider this a significant limitation of the author's work. \n\n> Line 485 (limitations): What are the potential consequences of a \"truly end-to-end\" approach? The authors seem to suggest this could be better, but do not explain why"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "oyc7dc5RqI", "forum": "BIzrFlp0hv", "replyto": "BIzrFlp0hv", "signatures": ["ICLR.cc/2026/Conference/Submission10487/Reviewer_EaC4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10487/Reviewer_EaC4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945536421, "cdate": 1761945536421, "tmdate": 1762921776825, "mdate": 1762921776825, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PRO‑MOF, a hierarchical reinforcement‑learning framework that co‑optimizes composition (an autoregressive “chemist” policy that proposes metal clusters and linkers) and geometry (a conditional flow‑matching “structural engineer” policy that assembles 3D structures) for de novo MOF generation. Rewards come from a universal machine‑learned interatomic potential (UMA) used as a high‑fidelity surrogate environment. \nTo enable exploration with flow matching (normally deterministic), the low‑level policy’s ODE sampler is turned into an SDE, and Group Relative Policy Optimization with Pass@K rewards is used to balance exploration and exploitation and mitigate diversity collapse.  \nOn inverse‑design tasks (maximize CO₂ working capacity; target pore‑limiting diameter; minimize formation energy), PRO‑MOF improves success rate and Top‑1 outcomes over MOFDiff latent optimization, MOFFlow‑2 sample‑and‑filter, and a GA+UMA baseline under equal UMA budget; ablations show both Pass@K and the UMA environment are critical"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Separating a high‑level chemical policy from a low‑level geometric policy (with hierarchical credit assignment using the max over k structures for the chemistry reward) is a clean way to handle the combinatorial chemistry space and continuous geometric space jointly. \n\nCombining flow‑matching and online RL is promising for many chemistry and materials tasks that combine discrete sampling problems (choosing atoms, functional groups, aminoacids, etc etc) with the continuous problem of placing these discrete entities in 3D space . Converting the probability‑flow ODE to an SDE (Flow‑GRPO‑style) provides needed stochasticity for exploration. The Pass@K GRPO scheme explicitly rewards within‑group diversity and empirically prevents mode collapse (Fig. 3a), while maintaining or improving rewards. This is a practical inference‑time training trick that maps cleanly onto structure discovery"}, "weaknesses": {"value": "The design rewards are unclear. Where is the CO2 binding coming from ? A simulation ? A surrogate model? Does making the biggest possible pore win in the CO2 binding task? \n\nPass@k seems like an interesting innovation, but if since that's not a new contribution and this paper merely borrows it for this particular task, it's a missed opportunity to look into pass@k for other problems with sparse rewards in chemistry. This is not MOF paper for folks that know about MOFs, (or not a convincing one anyway)  but as an AI paper it's not doing a good job of presenting what could be a cool generalizable trick for inverse design tasks. What abou comparisons against offline RL / preference optimization / reweighting baselines (e.g., likelihood‑ratio reweighting of samples using UMA Why not apply UMA-post hoc to all the other models ? Are they just missing a local relaxation ? Again a bit of scope shift. Is the help coming from RL+Pass@k or just from getting relaxed geometries ? \n\nThe fact that a GA+UMA is so close, is spooky (since it's halloween!) I think error bars/uncertainty across models would help to get a sense for the difference ranking between models. Also the computational budget ! Although UMA‑call budgets are equalized (10k), online RL with SDE sampling (k=16) can be expensive. Reporting wall‑clock, GPU cost, and UMA eval throughput would help practitioners gauge practicality relative to sample‑and‑filter and GA baselines\n\nPulling building blocks from a list defeats the purpose of a generative model, to a large degree. How big is the space of metals and linkers? It definitely defeats the \", the combinatorial explosion of possible building blocks and topologies creates a design space of astronomical scale\" sentence in the intro. \n\nThe use of a Tanimoto‑like fingerprint distance for “Diversity” can conflate small geometric tweaks with genuine topology changes. Add RCSR net detection/topology clustering, building‑block novelty statistics, and pore‑network diversity to quantify structural exploration more meaningfully for MOFs."}, "questions": {"value": "Fig 5 caption. Visualizations of samples generated by PRO-MOF are novel and innovative.\" How the figure justifies the sentence is unclear. I don't think this is an obvious statement just arising from visual inspection."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NkFDWRWskS", "forum": "BIzrFlp0hv", "replyto": "BIzrFlp0hv", "signatures": ["ICLR.cc/2026/Conference/Submission10487/Reviewer_e1DE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10487/Reviewer_e1DE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762108232921, "cdate": 1762108232921, "tmdate": 1762921776395, "mdate": 1762921776395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the challenge of generating physically realistic and property-controllable metal–organic frameworks (MOFs) using generative models, addressing the issue that existing generative models can generate unstable structures. The authors propose PRO-MOF, a hierarchical online RL framework that integrates a high-level chemist policy for selecting chemical building blocks and a low-level structural engineer policy—a flow-matching model converted into a stochastic differential equation—to assemble 3D structures. Both policies are iteratively optimized with group-relative policy optimization (GRPO) guided by a universal atomistic model (UMA) that provides fast physical evaluations, and a Pass@K sampling strategy to preserve structural diversity. Experiments on CO2 capacity maximization, pore-diameter targeting, and energy minimization tasks show that PRO-MOF significantly outperforms diffusion, genetic, and sample-and-filter baselines, achieving higher success rates, improved physical plausibility, and greater diversity of generated MOFs within the same evaluation budget."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method effectively resolves the unstable structure issue of the generative models and the mode collapse issue of RL methods.\n\n2. Experiments on three different generation tasks demonstrate the generalizability of the proposed method.  \n\n3. The authors conduct a comprehensive ablation study to demonstrate the necessity of the different components."}, "weaknesses": {"value": "1. The experiments and methodology rely heavily on the universal interatomic potential UMA but not DFT validation."}, "questions": {"value": "The core motivation of this work is that existing generative models often produce physically unstable structures, and the authors address this by using reinforcement learning (RL) to post-train the models with rewards generated by UMA. While the paper compares PRO-MOF against a MOFFlow-2 baseline that leverages UMA for sample-and-filter evaluation, could the authors clarify why UMA was not used to relax the generated structures instead of only providing scalar rewards? How would a MOFFlow-2 (Relaxation) baseline perform in comparison to the proposed method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "u1HW7S5u5N", "forum": "BIzrFlp0hv", "replyto": "BIzrFlp0hv", "signatures": ["ICLR.cc/2026/Conference/Submission10487/Reviewer_ZD7o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10487/Reviewer_ZD7o"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150796293, "cdate": 1762150796293, "tmdate": 1762921775977, "mdate": 1762921775977, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}