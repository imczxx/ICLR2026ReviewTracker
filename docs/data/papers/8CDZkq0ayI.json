{"id": "8CDZkq0ayI", "number": 706, "cdate": 1756775404518, "mdate": 1762955623518, "content": {"title": "UCD: Unconditional Discriminator Promotes Nash Equilibrium in GANs", "abstract": "Adversarial training turns out to be the key to one-step generation, especially for Generative Adversarial Network (GAN) and diffusion model distillation. Yet in practice, GAN training hardly converges properly and struggles in mode collapse. In this work, we quantitatively analyze the extent of Nash equilibrium in GAN training, and conclude that \\textit{redundant shortcuts by inputting condition in $D$ disables meaningful knowledge extraction}. We thereby propose to employ an unconditional discriminator (UCD), in which $D$ is enforced to extract more comprehensive and robust features with no condition injection. In this way, $D$ is able to leverage better knowledge to supervise $G$, which promotes Nash equilibrium in GAN literature. Theoretical guarantee on compatibility with vanilla GAN theory indicates that UCD can be implemented in a plug-in manner. Extensive experiments confirm the significant performance improvements with high efficiency. For instance, we achieved $\\textbf{1.47 FID}$ on the ImageNet-64 dataset, surpassing StyleGAN-XL and several state-of-the-art one-step diffusion models. The code will be made publicly available.", "tldr": "We propose to employ an unconditional discriminator to promote Nash equilibrium during GAN training and thus synthesis performance.", "keywords": ["Generative models", "generative adversarial networks"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8f14dfda3d0b10f58b09c5f3f7f950096ac07d5e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The submission proposes to improve convergence in conditional GANs by having the discriminator predict the conditioning-category instead of being fed the category. It is also further suggested to encourage more comprehensive feature learning by multi-tasking a self-supervised DINO loss on the discriminator as well.\n\nExperiments on ImageNet 64 x 64 show competitive performance relative to other GAN variants and diffusion models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* The submission is mostly easy-to-read and follow. \n\n* The method proposed seems to be effective, leading to decent samples."}, "weaknesses": {"value": "* The ideas in the submission are not very original, being quite related to past works such as AC-GAN [1] and Self-Supervised GANs [2], works which have had a lot of follow-up in the literature. In fact, the submission itself seems to use the AC-GAN implementation to add the auxiliary head in their implementation.\n\n* The presentation does not make it very explicit that this is specifically about conditional GANs, which was confusing at times. The fact that only the category-specific head of the discriminator is used makes this entirely a conditional framework, with auxiliary losses.\n\n* The experiments are too small in scale -- image generation has come a long way, and typical comparisons are on much higher resolutions and larger scales.\n\n[1] Conditional Image Synthesis with Auxiliary Classifier GANs, Odena et al., ICML 2017\n\n[2] Self-Supervised GANs via Auxiliary Rotation Loss, Chen et al., CVPR 2019"}, "questions": {"value": "No additional questions"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6XPmwXgwYY", "forum": "8CDZkq0ayI", "replyto": "8CDZkq0ayI", "signatures": ["ICLR.cc/2026/Conference/Submission706/Reviewer_Qgo2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission706/Reviewer_Qgo2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760821392882, "cdate": 1760821392882, "tmdate": 1762915586690, "mdate": 1762915586690, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "nWDnSY3oy1", "forum": "8CDZkq0ayI", "replyto": "8CDZkq0ayI", "signatures": ["ICLR.cc/2026/Conference/Submission706/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission706/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762937929271, "cdate": 1762937929271, "tmdate": 1762937929271, "mdate": 1762937929271, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This article concludes that redundant shortcuts by inputting conditions in D disable meaningful knowledge extraction. Therefore, they propose to employ an unconditional discriminator (UCD), in which D is enforced to extract more comprehensive and robust features with no condition injection. Theoretical guarantee on compatibility with vanilla GAN theory indicates that UCD can be implemented in a plug-in manner. Extensive experiments confirm the significant performance improvements with high efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The article provides a theoretical guarantee that training a GAN with an unconditional discriminator (UCD) alongside an additional classifier can converge to the Nash equilibrium. Additionally, the authors utilize a DINO loss and confirm that it can empirically enhance the diversity of synthesized samples."}, "weaknesses": {"value": "The article presents several issues, which I have outlined below: \n\n1. The theoretical proof has some shortcomings. In Section A.1, how does the author justify that Eq.(s4) equals 0 under all conditions? They only discuss the scenario where \\( i \\neq c \\) and \\( d(x)=0 \\), but do not provide further analysis for the case where \\( i=c \\) and \\( d(x)=1 \\). \n\n2. The DINO loss has not been included in the theoretical proof, making its introduction in the article seem abrupt. Furthermore, the exact formulation of the DINO loss is not provided, which complicates the reader's understanding of its impact on the training of the UCD. \n\n3. The datasets used to validate the effectiveness of the method are limited in scope. The authors should incorporate more datasets with varying resolutions and at least include higher-resolution datasets, as well as a broader range of scene datasets, to verify the generalizability of the UCD. \n\n4. The visualization of the training process is inadequate. The authors should include visualization results that illustrate the effects of the DINO loss, helping readers understand its role in the training of UCD. Additionally, more visualizations from an ablation study addressing how \"redundant shortcuts by inputting conditions into D disable meaningful knowledge extraction\" should be provided. \n\n5. Due to the aforementioned issues, the theoretical and empirical results do not sufficiently validate the effectiveness of the method."}, "questions": {"value": "1. Please refer to the weakness section.\n\n2. I recommend that the authors expand their analysis regarding the claim that \"redundant shortcuts by inputting conditions in D disable meaningful knowledge extraction\" from an empirical perspective. Theorem 10 only establishes that an additional discriminator can converge to the Nash equilibrium, but it does not demonstrate that redundant shortcuts impede meaningful knowledge extraction. \n\n3. I suggest that the authors provide more empirical results on the integration of the UCD into a wider variety of GAN models to confirm its plug-and-play capability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lM34pJ8ZE2", "forum": "8CDZkq0ayI", "replyto": "8CDZkq0ayI", "signatures": ["ICLR.cc/2026/Conference/Submission706/Reviewer_vdPG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission706/Reviewer_vdPG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760867461091, "cdate": 1760867461091, "tmdate": 1762915586557, "mdate": 1762915586557, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies why conditional GANs often fail to reach Nash equilibrium and argues that feeding the condition $c$ into the discriminator $D$ creates “shortcuts” that bias feature extraction and hurt training stability. It proposes a model- and loss-agnostic proxy to quantify proximity to Nash equilibrium by using $D$ as a classifier over conditions and tracking top-k accuracy during training, based on the observation that an optimal $D^*$ should identify the true condition from $x$ when equilibrium is nearly reached, and should reject unrelated conditions (Eq. 7). It introduces UCD, an “unconditional” discriminator that does not receive as input but is trained with an auxiliary classification loss over label logits $d(x)$, with a theorem claiming compatibility with vanilla GAN optimality (Eqs. 8–10; Theorem 1) , and adds a DINO-style self-distillation regularizer on $D$ to improve robustness (Config C; Eq. 11) . On ImageNet-64, the method reports FID 1.47 with Config C, competitive with or better than several one-step baselines, with small overhead relative to R3GAN."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Originality. The paper reframes discriminator design and the notion of monitoring equilibrium, beyond prior discriminator-auxiliary tasks that tended to be costly, and is presented as a plug-in change.\n\nQuality: The core claim is backed by a stated theorem. The appendix provides a derivation under common losses. Empirically, UCD improves FID on ImageNet-64.\n\nClarity: The paper walks through vanilla conditional GAN equilibrium (Eqs. 3–4), defines the equilibrium proxy (Eq. 7) with assumptions stated, and visualizes it (Fig. 1).\n\nSignificance. On ImageNet-64, UCD (Config C) reaches FID 1.47 and is competitive with or better than several one-step baselines, even surpassing StyleGAN-XL while not relying on classifier priors."}, "weaknesses": {"value": "1. The proxy assumes that for an “unrelated” class $c'$, $q(x|c')=0$, which is a very strong assumption for natural images with shared structure across classes . More importantly, after adding the classification head in UCD, the metric (top-k accuracy of $D$ over labels) directly aligns with the added loss, so improvements could partly reflect better supervised classification rather than better adversarial equilibrium per se, despite the “model-/loss-agnostic” claim.\n\n2. While the specific “remove $c$ from $D$ + auxiliary classification” combination is neat, the space of discriminator-auxiliary tasks (e.g., AC-GAN-style heads, contrastive/auxiliary tasks) is well explored (the paper itself cites several such lines) . The contribution may be seen as an incremental design choice rather than a fundamentally new objective.\n\n3. Results are on ImageNet-64 only; no evaluation on higher resolutions, other datasets, or non-class labels. The authors acknowledge incompatibility with text-conditioning and gesture at CLIP-based extensions as future work.\n\n4. Ablations show a non-trivial dependence on $\\lambda_1$ and $\\lambda_2$ (e.g., performance degrades when $\\lambda_1$ is too large), suggesting some tuning fragility that should be characterized more fully across seeds and setups."}, "questions": {"value": "1. Given that UCD explicitly optimizes a label-classification head, how do you decouple gains in the top-k equilibrium metric from gains in supervised classification? Could you report an alternative diagnostic independent of $D$'s classification head (e.g., train a frozen, external probe on $D$’s penultimate features or use a separate pretrained classifier for the top-k check)? Please also discuss the practical validity of the assumption $q(x|c')=0$ for unrelated $c'$ and any violations you observe on ImageNet classes.\n\n2. In Appendix A.1, the argument effectively drives non-$c$ components to zero to reduce the classification term and recovers the vanilla objective for the $c$-th component. Does this rely on separability or support assumptions on $q$ and $p_g$? Can you outline conditions under which the joint optimization over $d(\\cdot)$ does not interfere with the adversarial signal (e.g., when $\\lambda_1$ is finite)?\n\n3. Without feeding $c$ into $D$, how do you ensure that $D$ still provides condition-aware gradients to $G$ (beyond the classification head)? Could you report per-class precision/recall (already partially provided) stratified by class frequency and qualitative failure cases where class alignment goes wrong?\n\n4. Can you include evaluations on at least one additional dataset (e.g., CIFAR-10 or ImageNet-128/256) to test whether UCD’s gains hold beyond ImageNet-64? Also, do Config B/C help unconditional GANs?\n\n5. Please add: (a) sensitivity curves over $\\lambda_1$ and $\\lambda_2$ with multiple seeds; (b) an ablation that keeps condition injection into $D$ but adds the same classification loss, to isolate the effect of “unconditionalizing” $D$; (c) capacity/architecture ablations for the label head; (d) early-training stability metrics beyond FID (e.g., recall trajectory).\n\n6. You note incompatibility with text-to-image and suggest CLIP-based losses as future work; do you foresee any obstacles to making the equilibrium metric work when conditions are continuous text embeddings rather than discrete labels?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z3IW7aEqdm", "forum": "8CDZkq0ayI", "replyto": "8CDZkq0ayI", "signatures": ["ICLR.cc/2026/Conference/Submission706/Reviewer_arjD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission706/Reviewer_arjD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761250152327, "cdate": 1761250152327, "tmdate": 1762915585898, "mdate": 1762915585898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces UCD (Unconditional Discriminator), a method designed to promote \"good\" Nash equilibrium in Generative Adversarial Networks (GANs). Its contributions are as follows:\n\n1- Quantitative evaluation of Nash equilibrium – The authors propose a new, model- and loss-agnostic metric that measures the degree of Nash equilibrium during GAN training, based on the discriminator’s classification accuracy across conditions.\n\n2- Identification of conditional shortcut effects – Through analysis, the paper argues that injecting conditioning signals into the discriminator introduces redundant shortcuts that hinder effective feature extraction and equilibrium convergence.\n\n3- Unconditional Discriminator (UCD) framework – The paper proposes removing condition inputs from the discriminator to encourage broader and more robust feature learning, while maintaining compatibility with standard GAN theory. This design can be implemented in a plug-in manner without additional computational cost.\n\n4- Robustness enhancement with a DINO-inspired loss – A DINO-like self-supervised loss is incorporated to further stabilize training and strengthen discriminator feature representations.\n\n5- Empirical validation on ImageNet-64 – Experiments show consistent improvements in image synthesis quality across several GAN baselines, achieving a Fréchet Inception Distance (FID) of 1.47, surpassing prior GAN and one-step diffusion distillation models.\n\n6- Theoretical guarantee – The paper provides a proof that the proposed unconditional discriminator setup preserves the optimality of standard GAN training and converges to the same Nash equilibrium conditions."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clarity: \nWhile the paper is clearly written overall. There are a few points that should be improved to facilitate reading: Including an expression of Dino's loss and stating the assumptions on which thm 1 implicitly depends.\n\n\n- Quality of the experimental evaluation:\nThe authors made a fair amount of experiments to compare with the other sota methods. Their approach yields improved results. The reasons behind these improvements are unclear to me (see weaknesses)\n\n- Originality: I like the idea of introducing simple modifications such as classification loss or Dino's loss, which appears to be effective and original. But I think the paper currently does not do a good job in motivating these modifications (see weaknesses)."}, "weaknesses": {"value": "**Soundness 1** The main claim of the paper does not appear to be supported by evidence: \"Condition signal encourages D highly concentrate on condition-related features while neglecting others which are potentially more meaningful to adversarial training. That is to say, D becomes overfitted and sub-optimal.\" Throughout the paper, I see no evidence for this claim, or how the proposed approach addresses this effect. In fact the \"unconditional discriminator\" appears to be conditional. What's more: any \"conditional discriminator\" can be expressed in their \"unconditional form\" as discussed below:\n\n- The authors propose an \"unconditional discriminator\", yet their discriminator is in fact conditional: it is of the form D(x,c)=  d(x)^{\\top}One_hot(c). It just has a particular structure: the conditioning appears by taking the c'th coordinate of the vector d(x). Moreover, since the authors are considering finite/discrete conditions, any discriminator of the form D(x,c) can be represented as a scalar product between some vector d(x) of dim C with a one hot encoding of the class c. Perhaps the details of the discriminator are different, but there is no evidence in the paper explaining how these details are matter: ex: parameter sharing. \n\n - The results of figure 1 show an improved classification accuracy for the proposed method, however this is not surprising because they are explicitly trained to distinguish between the classes. This does not necessarily mean the learned discriminator is better at discriminating. (section 3.2 suggests that but it relies on the assumption that the classes are well separated, which is unrealistic).\n\n\n\n**Soundness of thm 1**: The proof of thm 1 appears to rely implicitly on each class being separated (i.e. each sample x can come only from one class c_0 with p(x|c)=0 for any c\\neq c_0.). While this is stated earlier in the text L152, it should appear explicitly in the statement of thm 1. Without such assumption, there is no reason the optimal discriminator takes the for form in eq 3 as stated by the theorem.  Consequently, it is unclear what the objective does when this assumption fails to hold, which is likely to happen in practice. The ablation studies confirm that: larger values of the classification hyper-parameter degrades performance. This should not be an issue, if the loss really preserved the same equilibria as unregularized loss.\n\n\n**Reasons behind the empirical improvements.** The paper proposes two main modifications to GAN training (with conditional generator): the form of the discriminator and some regulaization losses. The first modification is unconvincing as discussed earlier (in theory equivalent to conditional formulation). The second modification might change the equilibria hence, it is unclear what it does in theory. However, some empirical improvements are shown in the experiments. It remains unclear at this stage to what they are attributed.  \n\nI suggest the following ablations/experiments to clarify the effect of each modification:\n\t\t\t- Training a vanilla conditional GAN architecture (vanilla discriminator) using the additional classification loss and/or dino loss: this would show whether the proposed architectural modification really has any effect (I am not convinced it should, but if it does, it is certainly not due to the reasons explained in the paper and more precise explanations should be provided)\n\t\t\t- How generic are the improvements: current experiments are only based on a single experimental setup (Huang et al 2024). But are these observations consistent with other architectural choices, other losses?\n                       \n**Rethinking the contributions**: It appears to me that the main novelty is to introduce a classification loss (and a dino objective), which is interesting on its own, but the conceptual reasons of these improvements remain unclear to me. I suggest that the authors refocus the paper on explaining why these losses are useful."}, "questions": {"value": "See the weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fSpzzfRbQO", "forum": "8CDZkq0ayI", "replyto": "8CDZkq0ayI", "signatures": ["ICLR.cc/2026/Conference/Submission706/Reviewer_AYFe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission706/Reviewer_AYFe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761491406552, "cdate": 1761491406552, "tmdate": 1762915585634, "mdate": 1762915585634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}