{"id": "1lLWZzikiT", "number": 25300, "cdate": 1758366369239, "mdate": 1759896726094, "content": {"title": "Multi-objective Hyperparameter Optimization in the Age of Deep Learning", "abstract": "While Deep Learning (DL) experts often have prior knowledge about which hyperparameter settings yield strong performance, only few Hyperparameter Optimization (HPO) algorithms can leverage such prior knowledge and none incorporate priors over multiple objectives. As DL practitioners often need to optimize not just one but many objectives, this is a blind spot in the algorithmic landscape of HPO. To address this shortcoming, we introduce PriMO, the first HPO algorithm that can integrate multi-objective user beliefs. We show PriMO achieves state-of-the-art performance across 8 DL benchmarks in the multi-objective _and_ single-objective setting, clearly positioning itself as the new go-to HPO algorithm for DL practitioners.", "tldr": "We propose to use multi-objective expert priors to make hyperparameter optimization for expensive deep learning workloads feasible and show our algorithm PriMO achieves state-of-the-art performance in the multi-objective and single-objective setting.", "keywords": ["Hyperparameter Optimization", "Multi-objective", "Deep Learning"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6f91078d016ee60ed80b3df8a88af7363fef73c3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a multi-objective hyperparameter optimization method named PriMO that leverages expert prior knowledge. The approach integrates multi-objective expert priors into Bayesian optimization and utilizes cheap approximate surrogate models for initial design. Experimental results demonstrate that the method outperforms baseline approaches in both multi-objective and single-objective settings, while maintaining robustness to different prior strengths."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The integration of expert prior knowledge with multi-objective optimization in hyperparameter tuning, as presented in this paper, represents a beneficial endeavor.  \n- The proposed method, PriMO, demonstrates superior performance in experiments, outperforming baseline methods in both multi-objective and single-objective settings.  \n- PriMO exhibits strong robustness to different prior strengths, and ablation studies confirm the effectiveness of each component of the framework."}, "weaknesses": {"value": "- The description of the proposed method, PriMO, is relatively brief and lacks sufficient detail.  \n- The baseline methods used for comparison in the experiments are somewhat outdated (ranging from 2006 to 2021).  \n- There is a lack of case studies in real-world scenarios."}, "questions": {"value": "*  Can the proposed method be applied to the fine-tuning or training of current popular LLMs?\n*  How does the runtime efficiency of the proposed method compare to other approaches?\n*  How is the expert knowledge introduced in this method defined, and can it be generalized to broader domains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JxUV7hwrfE", "forum": "1lLWZzikiT", "replyto": "1lLWZzikiT", "signatures": ["ICLR.cc/2026/Conference/Submission25300/Reviewer_kZX4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25300/Reviewer_kZX4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875565106, "cdate": 1761875565106, "tmdate": 1762943392701, "mdate": 1762943392701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a specific issue in HPO, how to utilize prior knowledge in multi-objective HPO. It proposes a Bayesian optimization algorithm, PriMO, that integrates an initial design strategy and prior weights in BO steps. Experiments show that PriMO performs well in different cases, including all-priors-good, mixed-priors, and all-priors-bad."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- Utilizing prior knowledge in multi-objective HPO is a good, under-explored topic. \n\n- Results exhibit good performance, whether the priors are good or bad."}, "weaknesses": {"value": "- The title is too exaggerated in my eyes. HPO for deep learning faces numerous challenges, while the topic in this paper is only a very small one. Besides, it is not clear how the work addresses specific issues for deep learning.\n\n- In practice, prior knowledge should be scarce and diverse. There is a lack of assumptions about the priors that this paper considers.\n\n- The paper claims that priors can be good or bad. I wonder if it is a rigorous problem definition. How can you differentiate which ones are good or bad? If you cannot, how do you handle them differently?\n\n- Figure 2 can not explicitly exhibit the motivation. First, it is not clear how to add prior on MOASHA or RS. Second, the advantages of adding prior in all-priors-good and MOASHA in all-priors-bad demonstrate the importance of how to differentiate good or bad priors, instead of the weakness of the naive method for adding priors.\n\n- The main contribution comes from Eq. 4 and Algorithm 1. However, there is doubt that they are addressing issues related to the priors. \n\n- Experiments are limited due to the diversity of the benchmark."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4OmYf91kb2", "forum": "1lLWZzikiT", "replyto": "1lLWZzikiT", "signatures": ["ICLR.cc/2026/Conference/Submission25300/Reviewer_VfcQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25300/Reviewer_VfcQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877130447, "cdate": 1761877130447, "tmdate": 1762943392270, "mdate": 1762943392270, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the lack of HPO algorithms capable of incorporating multi-objective expert priors. While single-objective prior-informed optimization has received attention, extending this to multi-objective settings is both conceptually and technically nontrivial due to the need to reason over Pareto frontiers and conflicting objectives. The authors approach this issue starting from practical considerations in deep learning, looking at tradeoffs between accuracy, latency, cost, and fairness are common. The proposed PriMO framework provides a unified approach to integrate prior beliefs and cheap approximations while retaining robustness to misspecified priors."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The experimental section is definitive. The authors benchmark PriMO against a wide spectrum of baselines, ranging from classical multi-objective evolutionary algorithms to multi-fidelity optimizers (MOASHA, Hyperband) to Bayesian approaches. They also construct custom baselines (e.g., MOASHA+Prior, πBO+RW) to isolate the benefits of priors in the multi-objective context. PriMO consistently outperforms across eight deep learning benchmarks (image classification, translation, and language modeling) in both anytime and final performance metrics. It is rare in optimization to see such unilateral gains, which goes to show how underdeveloped the multi-objective HPO literature is and adds to the impact of this paper.\n\n2. The authors keep practical considerations close to heart throughout the paper, which leads to very thorough investigation of relevant quantities like training cost and hypervolumes. This is very different from other approaches to multi-objective optimization, which tend to be either very theoretical and/or very complicated and engineered."}, "weaknesses": {"value": "1. While the authors' acquisition function in Equation (4) works well empirically, the paper lacks a theoretical analysis of its properties. Ideal results would describe under what conditions we get convergence to the true Pareto frontier, or how the exploration parameter interacts with uncertainty estimation in BO. It is hard to know what the *secret sauce* of this choice is. I think this work would be stronger if there were some clear and simple example to have in mind that demonstrates the issue in multi-objective bilevel optimization which your approach solves/mitigates. I see that your algorithm looks reasonable and appears to do well, but in my opinion the most convincing results (and the ones that continue to hold at scale) are the ones with a clear \"we unlock the ability to solve something other approaches completely fail at\". Without knowing where to expect improvement to come from, it can make it very hard to refine and scale things.\n\n2. It would be nice to have a more clear runtime analysis to understand exactly where the computation goes and how hyperparameters affect it. There is a lot of emphasis on wall-clock time improvement; the authors do well to demonstrate the improvement here, but in general it is good to have a theoretical asymptotic behavior to expect and aim to match/improve on."}, "questions": {"value": "1. How do you envision practitioners specifying multi-objective priors? Would you consider incorporating structured or hierarchical priors for related tasks and subtasks?\n2. I am naturally curious in all the theoretical properties: convergence to optimality, rates, robustness to noise, robustness to a bad prior, generalization to related problems, etc.. What do the authors expect based on the empirical anecdotal observations? What are the apparent strengths, weaknesses, and so on?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tg8sPnpBWJ", "forum": "1lLWZzikiT", "replyto": "1lLWZzikiT", "signatures": ["ICLR.cc/2026/Conference/Submission25300/Reviewer_PZA5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25300/Reviewer_PZA5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963425338, "cdate": 1761963425338, "tmdate": 1762943391715, "mdate": 1762943391715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PriMO, a prior-informed multi-objective hyperparameter optimization algorithm that extends Bayesian optimization with expert priors and a multi-fidelity initial design. The authors clearly motivate the gap that, while prior-based HPO methods exist for single objectives, no existing method supports multi-objective settings that are common in deep learning. PriMO introduces an ε-greedy acquisition strategy that balances prior guidance and exploration, and integrates a MOASHA-based warm-start to exploit cheap approximations. Extensive experiments across eight deep-learning benchmarks show strong anytime and final performance, outperforming state-of-the-art multi-objective and prior-based baselines."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is very well written: definitions, algorithms, and experiments are presented cleanly and logically, making the work easy to follow. Multi-objective HPO is an important and practical topic for modern deep-learning workflows; addressing the lack of prior-aware solutions fills a real methodological gap. The proposed combination of prior-weighted acquisition with ε-greedy scheduling and a multi-fidelity initialization is conceptually coherent and empirically justified. The evaluation covers multiple domains, both surrogate and realistic, with clear ablation and robustness analyses that support the authors’ claims. Component-wise behaviors (e.g., prior strength, noise robustness, and early-stage acceleration) are analyzed in detail, giving the paper strong empirical credibility."}, "weaknesses": {"value": "1. Beyond the Pareto-front visualizations, the paper could include more case-level examples or qualitative comparisons to help readers connect the optimization behavior with real task utility and model performance trade-offs.\n\n2. In Algorithm 2 (the BO step), the parameter η is listed but seems unused—clarifying whether it affects fidelity scheduling or is inherited from the initialization stage would improve completeness.\n\n3. A brief theoretical or intuitive discussion about how PriMO behaves when priors are highly correlated or partially redundant could further strengthen the understanding of its robustness."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GhsbewQf6U", "forum": "1lLWZzikiT", "replyto": "1lLWZzikiT", "signatures": ["ICLR.cc/2026/Conference/Submission25300/Reviewer_Bve8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25300/Reviewer_Bve8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762022616278, "cdate": 1762022616278, "tmdate": 1762943391481, "mdate": 1762943391481, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}