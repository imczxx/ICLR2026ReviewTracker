{"id": "IYJKOBJeui", "number": 19415, "cdate": 1758296049000, "mdate": 1763715278137, "content": {"title": "Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation", "abstract": "We present Subject Fidelity Optimization (SFO), a novel comparative learning framework for zero-shot subject-driven generation that enhances subject fidelity. Existing supervised fine-uning methods, which rely only on positive targets and use the diffusion loss as in the pre-training stage, often fail to capture fine-grained subject details. To address this, SFO introduces additional synthetic negative targets and explicitly guides the model to favor positives over negatives through pairwise comparison. For negative targets, we propose Condition-Degradation Negative Sampling (CDNS), which automatically produces synthetic negatives tailored for subject-driven generation by introducing controlled degradations that emphasize subject fidelity and text alignment without expensive human annotations. Moreover, we reweight the diffusion timesteps to focus fine-tuning on intermediate steps where subject details emerge. Extensive experiments demonstrate that SFO with CDNS significantly outperforms recent strong baselines in terms of both subject fidelity and text alignment on a subject-driven generation benchmark.", "tldr": "We propose the comparison-based fine-tuning strategy with synthetic negative data  for improving subject fidelity in zero-shot subject-driven TTI.", "keywords": ["text-to-image", "subject-driven-tti"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/45df499a9aa89988f2e30d517cba1fa772b5d6b5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a method for enhancing the subject fidelity of the subject-driven image generation task via a negative-target-augmented strategy. The approach builds upon a diffusion-DPO-style algorithm and techniques for generating negative cases. Extensive experiments are carried out to prove the authors' motivation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly formatted and well-organized, making it easy for readers to follow the methodology, experimental setup, and results. The exposition is concise and accessible.\n- The use of negative targets as auxiliary supervision during training is a sensible design choice. By explicitly modeling undesirable outputs, the method has the potential to avoid common failure modes in fine-tuned generation."}, "weaknesses": {"value": "- The proposed framework closely follows the formulation of Diffusion-DPO and ultimately operates within the now-common SFT+DPO paradigm. As such, the methodological novelty is limited, and the contribution seems incremental.\n- As shown in Figure G in Appendix, several generated samples exhibit noticeable fidelity degradation. For instance, distorted text on \"can\" and malformed shapes of \"tea pot\".\n- All visual results are drawn from the Dreambooth benchmark. The exclusive reliance on this narrow domain raises concerns about the model’s generalization to more diverse or complex real-world inputs."}, "questions": {"value": "- How does the method perform on inputs outside the Dreambooth setting, particularly on uncurated, real-world images?\n- From a foundational perspective, Diffusion-DPO is inspired by reinforcement learning through self-exploration, where both win and lose cases should ideally be generated by the policy (i.e. the model) itself. However, like many recent works, this paper uses ground-truth images as the win case, which deviates from the original principle. Has the authors conducted analysis on the implications of this design choice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ElPPzLtoki", "forum": "IYJKOBJeui", "replyto": "IYJKOBJeui", "signatures": ["ICLR.cc/2026/Conference/Submission19415/Reviewer_ajgK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19415/Reviewer_ajgK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761404914456, "cdate": 1761404914456, "tmdate": 1762931331258, "mdate": 1762931331258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Subject Fidelity Optimization (SFO), a comparative learning framework for zero-shot subject-driven text-to-image generation. By introducing synthetic negative targets through a Condition-Degradation Negative Sampling (CDNS) strategy and reweighting diffusion timesteps, SFO explicitly guides the model to prefer high-fidelity subjects over degraded ones. Experiments show that SFO significantly improves subject fidelity and text alignment compared to existing supervised fine-tuning methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Comparative fine-tuning formulation:** The paper formalizes a pairwise optimization framework (SFO) that introduces explicit comparison between positive and negative targets, aligning with recent trends in preference-based optimization for diffusion models.\n\n- **Automatic negative construction:** The proposed CDNS procedure provides a simple yet systematic way to synthesize negative samples by degrading visual and textual conditions, avoiding the need for manual annotation.\n\n- **Comprehensive experiments:** The authors conduct quantitative, qualitative, and ablation analyses on standard benchmarks (e.g., DreamBench) under the FLUX backbone, illustrating the design choices and providing empirical observations of the method’s behavior."}, "weaknesses": {"value": "**Lack of Novelty:** The proposed SFO framework lacks clear novelty, as applying DPO-style preference optimization to diffusion models has already been explored in prior works such as Wallace (2024) and related studies. The current formulation does not introduce fundamentally new theoretical insights or algorithmic mechanisms beyond these existing diffusion-based DPO approaches. The paper should clarify how SFO differs from and improves upon these earlier methods.\n\n**Limited Performance:** Although the proposed SFO slightly improves DINO scores, the gain is marginal and not substantial enough to demonstrate a clear advantage in subject fidelity. Moreover, its CLIP-I and CLIP-T results remain below the state-of-the-art, suggesting that SFO provides limited overall improvement and may still struggle to balance subject fidelity with semantic and text–image alignment.\n\n**Lack of Generalization Evidence:** The evaluation is limited to a single base model (FLUX) and one benchmark, making it unclear whether SFO generalizes to other diffusion backbones (e.g., SD-XL, Imagen) or broader subject-driven generation settings. Without cross-model validation, the claimed effectiveness of SFO may be dataset- or architecture-specific."}, "questions": {"value": "- **Q1.** The paper shows that the negative samples generated by CDNS exhibit lower DINO similarity compared to those produced by the self-play method. Why does lower DINO similarity lead to better performance?\n\n- **Q2.** What are the main differences between SFO and previous works such as Wallace (2024) and related studies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J2nO48EIrN", "forum": "IYJKOBJeui", "replyto": "IYJKOBJeui", "signatures": ["ICLR.cc/2026/Conference/Submission19415/Reviewer_3v7S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19415/Reviewer_3v7S"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761533815264, "cdate": 1761533815264, "tmdate": 1762931330716, "mdate": 1762931330716, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on enhancing subject fidelity in the field of subject-driven generation. It first identifies the inherent limitations of training under the supervised fine-tuning (SFT) framework, and accordingly proposes the Subject Fidelity Optimization (SFO) training framework. Concomitantly, it introduces the condition-degradation negative sampling (CDNS) strategy for generating negative samples. Both qualitative and quantitative experiments demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper is well-written and easy to follow.\n- The method proposed in the paper is model-agnostic, meaning it can be applied for post-training on any base model to enhance subject fidelity."}, "weaknesses": {"value": "- The CDNS presented in this paper demonstrates the ability to generate \"negative\" samples with significantly degraded quality. However, this raises concerns. As shown in Figure 3, some negative samples exhibit an excessive discrepancy in fidelity compared to the reference images and show little to no relevance to the text prompt. Such \"positive-negative\" samples may not provide effective learning signals for the model. This issue warrants further investigation.  \n- The proposed SFO training framework bears strong similarities to the diffusion-DPO method, and its novelty appears to be limited.\n- Since the model is based on the OminiControl base model and fine-tuned through reinforcement learning, it would be beneficial to include comparisons with other reinforcement learning-based methods in the experimental section to provide a more comprehensive evaluation of its performance."}, "questions": {"value": "- What are the differences between the proposed SFO method and the traditional DPO approach?\n- Are there any other benchmarks in this field besides DreamBench? How does the method presented in this paper perform on these alternative benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jKImAc2jPI", "forum": "IYJKOBJeui", "replyto": "IYJKOBJeui", "signatures": ["ICLR.cc/2026/Conference/Submission19415/Reviewer_TuuX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19415/Reviewer_TuuX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761621554165, "cdate": 1761621554165, "tmdate": 1762931329941, "mdate": 1762931329941, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the subject fidelity problem in zero-shot subject-driven generation and makes the following contributions:\n(1) Subject Fidelity Optimization (SFO) guides the model to favor positive samples over negatives through pairwise comparison.\n(2) Condition-Degradation Negative Sampling (CDNS) synthesizes negative targets tailored for subject-driven generation in a controlled setting.\n\nThrough these contributions, the proposed method demonstrates strong results in improving subject fidelity."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Well-written and easy to read and follow.\n\nA simple, well-designed, and effective method pipeline — particularly, the Condition-Degradation Negative Sampling pipeline is a strong design choice.\n\nStrong experimental results."}, "weaknesses": {"value": "Testing on more benchmarks could further strengthen the evidence for the method’s effectiveness.\nNo other clear weaknesses."}, "questions": {"value": "Suggestions:\nThe color scheme of some figures could be further optimized for better readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hFACew8cyV", "forum": "IYJKOBJeui", "replyto": "IYJKOBJeui", "signatures": ["ICLR.cc/2026/Conference/Submission19415/Reviewer_68io"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19415/Reviewer_68io"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762005681965, "cdate": 1762005681965, "tmdate": 1762931329527, "mdate": 1762931329527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}