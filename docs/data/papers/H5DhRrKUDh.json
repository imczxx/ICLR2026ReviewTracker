{"id": "H5DhRrKUDh", "number": 4632, "cdate": 1757730584813, "mdate": 1759898022584, "content": {"title": "MedAlign: Clinician-Centered Federated Meta-Learning for Medical IoT with Privacy and Interpretability Guarantees", "abstract": "We propose a resource-aware federated meta-learning framework for medical Internet of Things (IoT) scenarios characterized by pronounced data heterogeneity, strict privacy demands, and constrained device resources. MedAlign enables collaborative model optimization across distributed edge nodes, while supporting personalized adaptation to diverse clinical environments. A lightweight adaptive gating controller dynamically orchestrates module activation in response to real-time computational, energy, and latency constraints, ensuring efficient inference and update on heterogeneous hardware. The architecture integrates ontology-driven feature selection, multimodal fusion of physiological and network signals, and prototype-consistent representation learning to maintain robust diagnostic boundaries across institutions. Privacy is rigorously protected via a formally calibrated aggregation protocol that injects controlled noise, providing quantifiable confidentiality guarantees without degrading clinical utility. Extensive experiments on intensive care and wearable health datasets demonstrate consistent improvements in detection accuracy, training efficiency, and resource utilization compared to existing approaches.", "tldr": "MedAlign is a privacy-preserving federated meta-learning framework that improves interpretability and efficiency for clinician-centered AI in medical IoT.", "keywords": ["Federated Learning", "Representation Learning", "Medical IoT", "Edge Intelligence", "Resource-Aware Optimization", "Adaptive Gating", "Differential Privacy", "Multimodal Fusion"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f23bfdc20d7f58ac01ed1c0437346305d6b2a711.pdf", "supplementary_material": "/attachment/8f6c560ea4cf3672eb54c62a6ee6a65f3deaa726.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents MedAlign, a comprehensive framework that integrates federated meta-learning, adaptive resource control, and differential privacy for medical IoT environments. The system introduces multiple synergistic modules—Context-Aware Feature Weighting (CAFW), Clinical Dependency Encoder (CDE), Prototype-Consistent Representation Learning (PCRL), and RL-based adaptive gating—to jointly optimize clinical diagnostic performance under device and privacy constraints. The design claims to balance personalization, multimodal fusion, and formal privacy guarantees through a multi-stage optimization and hierarchical clustering procedure. Experiments on three large-scale datasets (ICU, geriatric, cardiac) demonstrate superior diagnostic accuracy (+2%), 63% lower communication overhead, and quantifiable privacy guarantees."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is notable for its system-first perspective, combining realistic clinical constraints (bandwidth, latency, IRB compliance) with architectural innovations. The integration of graph-based semantic modeling and reinforcement-driven dynamic gating represents a creative attempt to bridge theory and deployment. The experimental section is unusually detailed for a systems paper, including real-world six-month deployment and ablation tables that reveal non-trivial module interdependencies. The formal derivation of the privacy guarantee (Gaussian mechanism with calibrated sensitivity) and the introduction of prototype-consistent representation alignment further strengthen the methodological depth. From a representation-learning standpoint, MedAlign pushes federated learning toward joint optimization of interpretability, privacy, and energy efficiency—a rare combination in existing work."}, "weaknesses": {"value": "Despite its breadth, the framework risks being over-engineered: each module (CAFW, CDE, PCRL, RL-Gating, DP aggregation) is described as critical, yet the interactions among them are primarily demonstrated empirically rather than theoretically. The meta-learning layer lacks a clear definition of task distribution or adaptation dynamics beyond cluster-based aggregation; without formal convergence analysis under non-IID sampling, the claimed generalization robustness remains qualitative. The reinforcement gating design—though motivated by resource constraints—relies on dense state vectors and a transformer policy whose learning stability on embedded devices is uncertain. The ontology-driven feature weighting assumes access to structured clinical ontologies on-device, which may not generalize to new sensors or hospitals. Moreover, interpretability claims are supported only by saliency and prototype alignment visualizations, without clinician-validated explanations. Finally, privacy calibration (ϵ = 1.0, δ = 10⁻⁵) is presented as “formally verified,” but no sensitivity analysis is shown for alternate privacy budgets or correlated updates—issues critical to federated healthcare deployment."}, "questions": {"value": "1: You describe hierarchical personalization via angular-similarity clustering (Eq. 1–2). Can you formally prove that this step yields a tighter generalization bound than standard model-agnostic meta-learning (MAML) when client tasks are correlated but non-IID? What are the assumptions on task relatedness required for this bound to hold?\n\n2: The RL-based gating module optimizes energy–accuracy trade-offs using policy gradients. Given that device states are partially observable and delayed (e.g., intermittent connectivity), how do you ensure policy convergence without violating the Lipschitz assumption invoked in Eq. 23?\n\n3: Equation 28 defines an SNR-based criterion for maintaining diagnostic accuracy under differential privacy noise. Can this be derived directly from an upper bound on mutual information leakage? If so, what distributional assumptions on gradient statistics are necessary?\n\n4: CAFW depends on ontology-based feature relevance. How would the framework behave if the ontology were incomplete or misaligned with empirical feature importance? Could the weighting module be adversarially manipulated to bias diagnosis under structured ontology errors?\n\n5: The PCRL module aligns prototypes across sites to enforce diagnostic consistency. However, alignment may obscure legitimate subpopulation differences. How do you distinguish between harmful prototype drift and clinically meaningful heterogeneity, and could the model unintentionally “erase” rare but critical disease phenotypes?"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GtVdamlmTr", "forum": "H5DhRrKUDh", "replyto": "H5DhRrKUDh", "signatures": ["ICLR.cc/2026/Conference/Submission4632/Reviewer_a9kn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4632/Reviewer_a9kn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4632/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805125150, "cdate": 1761805125150, "tmdate": 1762917480051, "mdate": 1762917480051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MedAlign, a comprehensive federated meta-learning framework designed for medical Internet of Things (IoMT) environments. The system addresses the challenges of data heterogeneity, strict privacy requirements, and resource constraints in distributed medical edge devices. The framework integrates five main components: (1) Context-Aware Feature Weighting (CAFW) for ontology-driven feature selection, (2) Clinical Dependency Encoder (CDE) using graph attention networks, (3) Prototype-Consistent Representation Learning (PCRL) for maintaining diagnostic boundaries across institutions, (4) Reinforcement Learning-based dynamic gating for resource-aware computation, and (5) Formally calibrated differential privacy mechanisms. The authors validate their approach through extensive experiments on three medical IoT datasets and a six-month real-world deployment across twelve healthcare institutions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The six-month deployment across twelve healthcare institutions provides valuable empirical evidence of practical viability\n2. Three datasets with comprehensive ablation studies and comparison against 18 baseline methods"}, "weaknesses": {"value": "1. The system integrates too many components, making it difficult to understand individual contributions and potentially limiting practical adoption\n2. Key details about baseline implementations are missing; it's unclear if comparisons are fair given different design objectives"}, "questions": {"value": "Can you provide evidence that all five components are necessary? What happens with a simpler subset of 2-3 components?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "IvjNvFsJY6", "forum": "H5DhRrKUDh", "replyto": "H5DhRrKUDh", "signatures": ["ICLR.cc/2026/Conference/Submission4632/Reviewer_d8zL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4632/Reviewer_d8zL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4632/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813601376, "cdate": 1761813601376, "tmdate": 1762917479753, "mdate": 1762917479753, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MedAlign, a clinician-centered federated meta-learning framework for Medical IoT that combines (i) ontology-guided Context-Aware Feature Weighting and cross-modal fusion, (ii) a Clinical Dependency Encoder with graph attention, (iii) Prototype-Consistent Representation Learning for cross-site alignment, (iv) RL-based adaptive gating for energy/latency constraints, and (v) a “formally calibrated” DP aggregation protocol. Reported results claim very high accuracy across multiple clinical datasets, reduced energy/latency/communication, a six-month 12-site deployment, and resistance to adversarial/backdoor settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper sensibly enumerates clinical constraints (non-IID data, resource limits, confidentiality) and maps them to modules; the workflow/algorithms are laid out clearly.    \n- The DP aggregation is at least specified (norm clipping + Gaussian noise) with standard formulae; a semi-honest threat model is written down.    \n- The RL-gating objective and state/action design are described; the system section reports latency/energy/communication reductions on edge hardware."}, "weaknesses": {"value": "- Deployment claims lack verifiable detail (and contain inconsistencies). The “six-month, 12-site” deployment states local updates every 48 hours and global aggregation biannually, which would be only twice per year—at odds with FL training and with the later performance/latency claims. No audit logs, site lists, or concrete clinical endpoints (alarm reduction definitions, prospective vs. retrospective) are provided.  \n- DP and privacy accounting are incomplete. The paper presents the single-round Gaussian mechanism \\sigma=\\sqrt{2\\ln(1.25/\\delta)}/\\epsilon but does not specify an accountant (e.g., RDP/zCDP/moments) for multi-round training, participant subsampling, or per-tier budgets claimed later. The SNR>=18 dB heuristic is empirical and not tied to a specific privacy composition.  \n- Security model vs. robustness results are misaligned. The threat model is semi-honest, yet the “extended validation” reports low backdoor success (4.1%) with 30% malicious clients, without describing any Byzantine-robust aggregation, anomaly filtering, or certified defenses—DP noise alone can degrade, not guarantee, robustness. Methodological details are absent.    \n- Ablations and system metrics show internal tensions. The text claims RL-gating reduces energy by ~23% and 86 ms latency on a Pi 4, plus 128 KB peak memory, which are ambitious. The ablation table mixes accuracy/energy/latency changes in ways that are hard to reconcile with the qualitative narrative (e.g., removing representation modules sometimes reduces energy and latency substantially). Precise measurement setups (load, batch size, window length) are missing.    \n- “Formally verified aggregation” is overstated. The section title suggests formal verification, but the body reproduces the standard Gaussian mechanism with a brief theorem sketch; there’s no mechanized proof, proof artifacts, or code-level verification. The algorithmic step called “secure aggregation” is simply DP-noise addition—not the cryptographic secure aggregation expected in FL deployments.    \n- Dataset/task reporting is insufficient. Datasets are named and pre-processing listed, but task definitions, label provenance, prevalence, and class imbalance are under-specified. Cross-site splits, per-site cohort stats, and missing-data patterns (crucial in clinical IoT) are not detailed, limiting reproducibility.  \n- Breadth over depth. The paper integrates many modules (CAFW, CDE, PCRL, RL-gating, DP), but the novelty over prior FL/FML/graph-encoding/prototype-learning work is mostly incremental; stronger head-to-head comparisons and surgical ablations isolating each module’s causal effect (beyond aggregate tables) are needed."}, "questions": {"value": "1. Please clarify the training cadence (global rounds vs. “biannually”), participating institutions, endpoints evaluated prospectively, and whether clinicians were in-the-loop. Provide logs or an audit protocol.  \n2. What accountant (RDP/zCDP/moments) and sampling rates were used across T rounds? Report composed \\epsilon per data tier (ICU vs. wearable) matching the “hierarchical budgeting” claim.  \n3. How is the 4.1% backdoor success achieved under 30% malicious clients? Which robust aggregation or anomaly detection is in place (beyond DP noise)? Show attack details and transferability tests.  \n4. Specify the evaluation harness for energy/latency (window sizes, sampling, device states), the policy training regime (on-device vs. server), and ablate gating on/off under matched workloads.    \n5. If cryptographic secure aggregation is used, provide the protocol details (e.g., Bonawitz-style) and failure handling; otherwise, please avoid labeling DP-only as “secure aggregation.”    \n6. Provide per-site class distributions, missingness patterns, and precise task definitions (e.g., episode-level anomaly detection vs. continuous prediction), plus patient-level splits and IRB scope.  \n7. The dual-path explanation framework is intriguing—please add clinician-rated studies or case-based evaluations to assess utility and failure modes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iaze2RPsbx", "forum": "H5DhRrKUDh", "replyto": "H5DhRrKUDh", "signatures": ["ICLR.cc/2026/Conference/Submission4632/Reviewer_kqaA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4632/Reviewer_kqaA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4632/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892930059, "cdate": 1761892930059, "tmdate": 1762917479290, "mdate": 1762917479290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for cross-device federated learning for medical applications."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. FL in the medical domain problems is interesting and important.\n2. The paper has reported performance numbers on a real RPi device, which is great to see."}, "weaknesses": {"value": "1.  The method includes many components without detailing any of them. The current version of the paper is insufficient to understand them and measure their quality and novelty. The paper does not justify the selected components or provide insights into why they are necessary in this context.\n2. Authors should cite relevant literature that inspired different components. The paper claims to have a differentially private mechanism, but never explains it. Though there are some results on this, it is unclear what is being protected. It mentions Explainability as one of three gaps in the literature and says it addresses it (section 2.3), but I can't find where.\n3. Figure 1 is confusing. For example, the black arrow on the right seems to be in the opposite direction. It uses too many acronyms, including the ones that are never used again in the main text (AFO).\n4. The writing style is odd, with almost every paragraph in the introduction having a separate subsection. This hinders readability.\n5. The experiments section needs to have more clarity. Is the on-device experiment run on all edge devices in a dataset, such as 1800 devices in the M-IoT-Env dataset? What are the models being used? There is no confidence interval for Tables 1 and 2."}, "questions": {"value": "As above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hcuilkpEHv", "forum": "H5DhRrKUDh", "replyto": "H5DhRrKUDh", "signatures": ["ICLR.cc/2026/Conference/Submission4632/Reviewer_rAF4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4632/Reviewer_rAF4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4632/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958717996, "cdate": 1761958717996, "tmdate": 1762917479067, "mdate": 1762917479067, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}