{"id": "FA5gun3gmm", "number": 10687, "cdate": 1758179598567, "mdate": 1763373854938, "content": {"title": "Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space", "abstract": "The increasing complexity of large-scale language models has amplified concerns regarding their interpretability and reusability. While traditional embedding models like Word2Vec and GloVe offer scalability, they lack transparency and often behave as black boxes. Conversely, interpretable models such as the Tsetlin Machine (TM) have shown promise in constructing explainable learning systems, though they previously faced limitations in scalability and reusability. In this paper, we introduce Omni Tsetlin Machine Autoencoder (Omni TM-AE), a novel embedding model that fully exploits the information contained in the TM's state matrix, including literals previously excluded from clause formation. This method enables the construction of reusable, interpretable embeddings through a single training phase. Extensive experiments across semantic similarity, sentiment classification, and document clustering tasks show that Omni TM-AE performs competitively with and often surpasses mainstream embedding models. These results demonstrate that it is possible to balance performance, scalability, and interpretability in modern Natural Language Processing (NLP) systems without resorting to opaque architectures.", "tldr": "A novel interpretable embedding model, Omni TM-AE, that leverages all Tsetlin Machine literals to create reusable, scalable embeddings in a single training phase, achieving competitive performance with black-box models.", "keywords": ["machine learning", "tsetlin machine", "word embedding", "interpretable ai", "explainable ai"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8683692bb02e6e1cd1625e2d23e9d1945af55d74.pdf", "supplementary_material": "/attachment/5624ec088a2d3ba74a70835d451054486b3309ea.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Omni TM-AE, a variant of Tsetlin Machine–based autoencoder models that constructs word-level embedding vectors by aggregating both active and previously excluded literals through a signed aggregation mechanism. The authors argue this design enhances interpretability while maintaining competitive embedding quality. The model is assessed on several word similarity datasets and downstream document classification and clustering tasks by averaging word embeddings to form sentence or document representations. The results are compared to standard static baselines such as Word2Vec, GloVe, and FastText."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The design encourages traceability: because each dimension corresponds directly to literal states, the model allows users to track how reward and penalty signals contribute to the final embedding. This kind of mechanistic interpretability is not common in standard neural embedding approaches.\n\n2. The empirical coverage is reasonably broad, spanning similarity, clustering, and classification settings. The inclusion of implementation details and code facilitates reproducibility, even if the benchmark scope itself is somewhat limited."}, "weaknesses": {"value": "1. The proposed approach is limited to word-level representations. Sentence and document vectors are derived through simple averaging, a composition strategy that lags behind the richer contextual embedding techniques now standard in practice (e.g., SBERT-like models). Importantly, the method is not evaluated on the MTEB benchmark, which has become the principal standard for embedding model comparisons across retrieval, STS, reranking, clustering, and classification tasks. This omission weakens the paper’s empirical positioning.\n\n2. Baseline selection is narrow. The paper focuses on static embeddings and a few TM variants but omits widely recognized interpretable or sparse embedding methods (such as SPINE, Word2Sense, ultradense embeddings, or analytical approaches). Without these, it’s difficult to meaningfully situate the work in the interpretability space or quantify its comparative advantages.\n\n3. Although the approach provides literal-level transparency, it largely encodes bag-of-words associations rather than contextual or conceptual meaning. It lacks the semantic structure that other interpretable embedding frameworks attempt to model, limiting its explanatory depth.\n\n4. The contribution is incremental rather than transformative: incorporating excluded literals and simplifying the training pipeline extends the TM-AE line but doesn’t constitute a conceptual shift in representation learning. The paper would benefit from a stronger articulation of why this specific modification matters in a broader embedding context."}, "questions": {"value": "1. Do the authors intend to explore more expressive sentence-level composition functions or benchmark against MTEB to make the work more competitive with contemporary embedding methods?\n\n2. Why were interpretable or sparse embedding baselines omitted? Including SPINE, Word2Sense, or ultradense methods would provide a more complete interpretability comparison.\n\n3. How might the proposed approach be adapted to move beyond literal-level signals toward richer, concept-level semantics?\n\n4. How do the authors view their contribution in terms of novelty relative to the prior TM-AE work, and how might this design scale to more competitive benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gLFnJhSrW9", "forum": "FA5gun3gmm", "replyto": "FA5gun3gmm", "signatures": ["ICLR.cc/2026/Conference/Submission10687/Reviewer_iBFj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10687/Reviewer_iBFj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761208223833, "cdate": 1761208223833, "tmdate": 1762921932886, "mdate": 1762921932886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We respectfully request the withdrawal of our submission. After discussing this matter with all co-authors, we collectively decided to retract the paper at this time. Thank you for your consideration."}}, "id": "5Y2dtCnUzO", "forum": "FA5gun3gmm", "replyto": "FA5gun3gmm", "signatures": ["ICLR.cc/2026/Conference/Submission10687/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10687/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763373853650, "cdate": 1763373853650, "tmdate": 1763373853650, "mdate": 1763373853650, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Desk reject due to author names appearing in the title page and not following ICLR style."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "I have not conducted a technical review of this paper because of its style and anonymity violations."}, "weaknesses": {"value": "I have not conducted a technical review of this paper because of its style and anonymity violations."}, "questions": {"value": "I have not conducted a technical review of this paper because of its style and anonymity violations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1tluiwnWuM", "forum": "FA5gun3gmm", "replyto": "FA5gun3gmm", "signatures": ["ICLR.cc/2026/Conference/Submission10687/Reviewer_JjEy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10687/Reviewer_JjEy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761771816588, "cdate": 1761771816588, "tmdate": 1762921932516, "mdate": 1762921932516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Omni TM-AE, an interpretable embedding model based on the Tsetlin Machine framework. Unlike previous TM-based autoencoders, Omni TM-AE fully uses the TM’s entire state matrix. This design allows the model to capture richer contextual information and produce embeddings in a single training phase. The authors evaluate Omni TM-AE across semantic similarity, sentiment classification, and document clustering tasks, showing competitive results compared to established embedding baselines such as Word2Vec, FastText, and GloVe. The method retains the transparency of TM-based reasoning while improving scalability and reusability."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Leveraging the full TM state space (including excluded literals) is conceptually innovative and practically impactful, addressing both interpretability and reusability. \n- Results across diverse datasets show that Omni TM-AE can exceed traditional embeddings, particularly in tasks involving semantic similarity."}, "weaknesses": {"value": "### W1. Limited task coverage\nThe method produces only word-level embeddings, with sentence/document representations obtained by simple averaging. It's shallow compared to modern contextual or sentence-level embeddings (e.g., SBERT, SimCSE) used in real-world retrieval and classification pipelines. Extending experiments to sentence-level benchmarks (e.g., MTEB) would clarify scalability and real-world utility.\n\n### W2. Missing interpretability baselines.\nComparisons are limited to black-box and prior TM variants. The paper omits interpretable or sparse embedding baselines (e.g., sparse autoencoders, dictionary-based or concept-factor models), weakening claims of interpretability and generality.\n\n### W3. Mechanistic rather than semantic interpretability\nInterpretability is confined to tracing literal states rather than uncovering human-understandable semantic features. No quantitative or human-centered evaluation supports the interpretability claim.\n\n### W4. Incremental contribution within existing TM-AE models\nThe main technical novelty, folding excluded literals into embeddings through signed state aggregation, extends the earlier TM-AE work but remains a modest refinement.\n\n### W5. Missing ablation and sensitivity analyses\nThe paper lacks ablations isolating the contribution of excluded literals and does not discuss sensitivity to key hyperparameters such as clause number or threshold."}, "questions": {"value": "- Can you quantify how excluded literals improve embedding quality (e.g., via ablation)?\n\n- How sensitive is the model to hyperparameters such as clause count and threshold?\n\n- Could user studies verify whether the model’s literal-based associations align with human-understandable semantics?\n\n- How does Omni TM-AE generalize to contextual or sentence-level embedding tasks? Could the single-phase mechanism scale to larger or dynamic corpora?\n\n- How does it compare to interpretable embedding approaches in performance and interpretability trade-offs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QRvWO411uy", "forum": "FA5gun3gmm", "replyto": "FA5gun3gmm", "signatures": ["ICLR.cc/2026/Conference/Submission10687/Reviewer_1C8W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10687/Reviewer_1C8W"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762005713521, "cdate": 1762005713521, "tmdate": 1762921932179, "mdate": 1762921932179, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}