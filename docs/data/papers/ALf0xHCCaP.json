{"id": "ALf0xHCCaP", "number": 21047, "cdate": 1758313203907, "mdate": 1763755844907, "content": {"title": "Task-Level Insights from Eigenvalues across Sequence Models", "abstract": "Although softmax attention drives state-of-the-art performance for sequence models, its quadratic complexity limits scalability, motivating linear alternatives such as state space models (SSMs). While these alternatives improve efficiency, their fundamental differences in information processing remain poorly understood. In this work, we leverage the recently proposed dynamical systems framework to represent softmax, norm and linear attention as dynamical systems, enabling a structured comparison with SSMs by analyzing their respective eigenvalue spectra. Since eigenvalues capture essential aspects of dynamical system behavior, we conduct an extensive empirical analysis across diverse sequence models and benchmarks. We first show that eigenvalues influence essential aspects of memory and long-range dependency modeling, revealing spectral signatures that align with task requirements. Building on these insights, we then investigate how architectural modifications in sequence models impact both eigenvalue spectra and task performance.  This correspondence further strengthens the position of eigenvalue analysis as a principled metric for interpreting, understanding, and ultimately improving the capabilities of sequence models.", "tldr": "This paper shows that eigenvalues offer a metric for memory retention and selective forgetting in sequence models, guiding model design choices to meet task requirements.", "keywords": ["Sequence models", "dynamical systems", "memory dynamics"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ef15be1e4ca44ec34adb76dbbbb5e30448f4997c.pdf", "supplementary_material": "/attachment/a34ab7106844c8b1974675fdf300085c394ec367.pdf"}, "replies": [{"content": {"summary": {"value": "This paper studies sequence models (SSMs and masked attention) through a **dynamical-systems lens** and argues that **task requirements are reflected in the spectrum of state-transition eigenvalues**. Using the DSF formulation, causal attention is written as a recurrence, so eigenvalue magnitudes capture how much the past state is retained (near 1) or forgotten (near 0). The authors empirically profile eigenvalue distributions across architectures (S4, LRU, Mamba-2; softmax, linear, norm attention), layers, and tasks (ListOps, IMDb, CIFAR-10, MQAR, WikiText).\n\nMain findings are:\n\n* **Spectral signatures align with task needs.** Long-memory tasks concentrate mass near 1; tasks needing selective forgetting show peaks near 0.\n* **Architectural choices shift spectra in intuitive ways.** Adding explicit **gates** reduces the need for implicit gating in the dynamics; adding **convolution** offloads local context and shifts mass toward 0; **normalization** choices in norm attention trade retention vs selectivity; making **Mamba-2 pseudo-LTI** (constant discretization) yields S4-like spectra and helps ListOps.\n* The spectrum can therefore serve as a **diagnostic/design tool** to steer models toward retention or selectivity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* **Unifying perspective.** A clear DSF view that lets attention and SSMs be compared apples-to-apples through the same spectral metric.\n* **Comprehensive empirics.** Multi-task, multi-model, per-layer analyses with ablations (gating, conv, normalization, depth, pseudo-LTI). This breadth gives credibility to the main trend claims.\n* **Actionable insights.** Concrete “design → spectrum → behavior” links (e.g., conv shifts mass to 0; constant discretization moves Mamba-2 toward retention). Practitioners can use this to target spectra for a task.\n* **Clarity of interpretation.** The near-0 vs near-1 story is intuitive and connects to long-standing control/SSM theory, helping demystify why models succeed or fail on LRA-style tasks."}, "weaknesses": {"value": "* **Incremental novelty.** Much of the narrative (poles near the unit circle ↔ long memory; selective forgetting ↔ small eigenvalues) echoes prior SSM/RNN work; S5 and related papers already emphasize spectral placement for retention and task performance. The contribution is more **systematization** than new theory.\n* **Limited quantification.** The link between spectra and performance is presented mostly as qualitative alignment. No formal predictive model (e.g., correlation between “mass in [0.9,1]” and accuracy/perplexity) or causal intervention is provided.\n* **Coarse metric.** Binning only by **magnitude** discards **phase** information of complex eigenvalues (oscillations) and ignores distributional shape beyond coarse buckets. This may hide important structure.\n* **Scale and controls.** It’s unclear how sensitive results are to model size, parameter budget, or training recipe. Using one head for plots can mask head-to-head variance; significance tests across seeds are limited in the main text.\n* **Scope.** Benchmarks are mostly small/medium. It remains uncertain how well these spectral diagnostics extrapolate to large-scale language models."}, "questions": {"value": "1. **Quantification.** Can you report correlations (or simple regressions) between task performance and spectral mass in specific bins (e.g., ([0.9,1]) vs ([0,0.1])) across runs/layers? This would strengthen the predictive value of the metric.\n2. **Dynamics over training.** Do spectra evolve monotonically toward the final pattern? Showing trajectories (epochs vs mass in each bin) could clarify causality.\n3. **Complex phases.** Did you analyze the angles of complex eigenvalues (oscillatory modes)? Any task where phase structure matters?\n4. **Head and seed variance.** The appendix includes more heads; could you summarize variance across heads/seeds with statistical testing?\n5. **Capacity control.** When comparing architectures, are parameter counts and FLOPs matched closely? If not, can you add matched-capacity comparisons?\n6. **When spectra mislead.** Are there counterexamples where spectra look favorable but performance lags (or vice versa)? Understanding failure modes would bound the tool’s applicability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sdQE2PXsaH", "forum": "ALf0xHCCaP", "replyto": "ALf0xHCCaP", "signatures": ["ICLR.cc/2026/Conference/Submission21047/Reviewer_8FeC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21047/Reviewer_8FeC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760657588001, "cdate": 1760657588001, "tmdate": 1762940623208, "mdate": 1762940623208, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "### Summary\n\n1. Extends Eigenvalue Analysis to LPV Models:\n\n   The paper builds on earlier work that analyzed eigenvalues in Linear Time-Invariant (LTI) State Space Models, where eigenvalues capture memory, stability, and selectivity. Eigenvalues near 1 mean good long-term memory, while those near 0 indicate forgetting or gating. \n\n   The authors extend this idea to Linear Parameter-Varying (LPV) systems using the Dynamical Systems Framework (DSF), which writes models like Attention and Mamba-2 as dynamical systems:\n   \n   $h_i = \\Lambda_i h_{i-1} + B_i u_i, \\quad y_i = C_i h_i + D_i u_i$\n\n   Here, the parameters change with input, allowing a similar eigenvalue analysis across model types.\n\n2. Analysis:\n\n   On memory, authors show the intuitive result that models that remember well keep eigenvalues close to 1. On language modeling (WikiText), the authors find that “gating” or eigenvalues near zero help model selectively store tokens.\n\n3. Architectural Modifications Based on the Analysis:\n\n   The paper tries to use these insights to improve models with changes including: Gating, Short Convs, Varying the number of layers etc"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper’s central idea, that is extending eigenvalue analysis from LTI SSMs to LPV systems and attention, is natural and easy to follow.\n2. The connection between eigenvalues and memory retention/selectivity is intuitive and aligns with established understanding.\n3. The paper conducts experiments across a breadth of models (S4, Mamba-2, Self-Attention, Linear Attention etc) and tasks (LRA, MQAR, WikiText)"}, "weaknesses": {"value": "### Weaknesses\n\n1. **On memory tasks**\n\n   1. The analysis of memory is intuitive and largely reiterates known understanding—that eigenvalues near one preserve information and those near zero lead to forgetting.\n   2. The attention results, though potentially interesting, are underexplained. The paper attributes attention’s poor performance on LRA to having both very low and very high eigenvalues, but I suspect this explanation may be correlational rather than causal. Attention is known to perform strongly on other memory-intensive retrieval tasks (e.g., NIAH [1]). It would have been useful if the paper discussed this discrepancy and explored why attention struggles on LRA despite its well-documented ability to retain long-term information in other settings.\n\n2. **On gating/selectivity tasks**\n\n   1. The interpretation that “gating” corresponds to zeroing out eigenvalues in WikiText models like Mamba-2 is reasonable but not novel as it directly follows from the Mamba-2's design of selection mechanism.\n   2. The follow-up “add gate” experiment on attention has a conceptual mismatch---The gating mechanism used in the experiments differs from Mamba-2’s within-sequence gating, and is instead applied per-token AFTER sequence mixing, making the analogy weak.\n   3. The task choice and conclusions seem inconsistent: gating is shown to help on IMDb, a memory-heavy task where (if i understand correctly) it should theoretically hurt (or at-least not help). Furthermore, ListOps, which is also memory intensive, unexpectedly develops gating, which remains unexplained. \n\n       I expected to see a gating-improved task, like WikiText, show improvement when gating is added to attention.\n\n3. **On convolution and varying number of layers**\n\n   1. These experiments are not motivated by eigenvalue analysis and are instead motivated from Mamba-2's strong performance which feels disconnected from the main argument.\n   2. The claim that short convolutions “take over long-range memory” seems to be incorrect—short convolutions are \"short\" (of size 4) and cannot provide such capacity. The paper employs this argument to justify why a one layer attention model with convolution could solve MQAR. I believe this justification is incorrect. Prior work [1] has shown that MQAR performance requires \"induction-head formation\": first sequence mixer mixes keys and values and the second sequence mixer retrieves the correct value. Convolution helps because it performs the first task, not because it replaces long-range retrieval.\n\n4. **On evaluation scope**\n\n   1. For the proposed architectural changes, the experiments are limited to small-scale settings and on synthetic tasks.\n   2. It would be more convincing to test these modifications on language modeling and downstream evals at across multiple scales (e.g., 125M, 350M, 750M, 1.3B) to assess their importance.\n\n5. **On scope and completeness**\n\n   1. The paper briefly mentions that eigenvalues evolve during training, suggesting potential task-dependent initialization, but this idea is never explored.\n   2. The architectural additions should be tested on language modeling for validation.\n   3. Overall, the paper reads as an incremental extension of prior DSF analyses, with several unexplained experimental results.\n\n-------\n[1]: Mechanistic evaluation of Transformers and state space models. Aryaman Arora, Neil Rathi, Nikil Roashan Selvam, Róbert Csordás, Dan Jurafsky, Christopher Potts"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QsCkLROH9C", "forum": "ALf0xHCCaP", "replyto": "ALf0xHCCaP", "signatures": ["ICLR.cc/2026/Conference/Submission21047/Reviewer_N9x6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21047/Reviewer_N9x6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762122283750, "cdate": 1762122283750, "tmdate": 1762940622778, "mdate": 1762940622778, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes using a unified dynamical systems framework (DSF) to analyze and compare the behavior of various sequence models, including SSMs (S4, LRU, Mamba-2) and different attention mechanisms (softmax, linear, norm). The core idea is to represent these models as dynamical systems and study their eigenvalue spectra to find \"spectral signatures\" that correlate with specific task requirements, such as long-term memory or selective forgetting. The authors conduct an empirical study across several benchmarks (LRA, MQAR, WikiText) to support their claims."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The primary strength of this work is the application of the DSF to provide a common ground for analyzing seemingly disparate architectures like SSMs and attention. The goal of finding a unified principle to understand their internal dynamics is valuable and timely.\n-  The paper includes an extensive set of experiments across multiple model classes and a diverse set of tasks."}, "weaknesses": {"value": "- The authors frame their work as a novel application of eigenvalue analysis of sequential models. However, the paper fails to cite or engage with a crucial body of literature on analyzing non-linear dynamical systems using linear operators. The work misses key papers such as [1]. This is particularly relevant, as it explicitly analyzes the eigenspectrum of the Koopman operator to model the non-linear dynamics of sequence models. This paper's core method—using the DSF to derive a linear-like state transition matrix $\\Lambda_i$ and analyzing its spectrum—is conceptually similar. The paper would be significantly stronger if it contextualized its approach within this existing work or compare with it.\n\n- The paper notes that linear attention retains its initialization's spectral shape, “raising the question of the potential importance of a task-dependent initialization.” This question remains unaddressed. The paper poses this as an open question but fails to engage with significant, recent work that directly addresses it. The work [2] (and related works) demonstrates that the initialization of weights (e.g., from a pre-trained model) can significantly improve the performance of softmax attention-based models on the LRA benchmark—the same benchmark used in this paper. This is a critical omission. It strongly suggests that a \"good\" spectral initialization is vital for success. The paper misses a key opportunity to connect its analysis to this important line of work and investigate, for example, how the initial eigenvalues of a pre-trained model compare to the random initializations used in this study.\n\n- The analysis of architectural modifications in Section 5 only partially demonstrates the framework's explanatory power, leaving the overall contribution and utility of the method in question (for this application).\n\n\n[1] \"An operator theoretic approach for analyzing sequence neural networks\", Naiman et al. (AAAI23)\n\n[2] \"Never Train from Scratch: Fair Comparison of Long Sequence Models Requires Data-Driven Priors\", Amos et al. (ICLR 2024)"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tMmILJK9RL", "forum": "ALf0xHCCaP", "replyto": "ALf0xHCCaP", "signatures": ["ICLR.cc/2026/Conference/Submission21047/Reviewer_T1HT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21047/Reviewer_T1HT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762161635446, "cdate": 1762161635446, "tmdate": 1762940622143, "mdate": 1762940622143, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes eigenvalue analysis as a principled metric for understanding the capabilities of sequence models. This work first uses an existing framework to formulate softmax, norm, and linear attention as dynamical systems, and then compare the eigenvalues of these models with SSMs, which are naturally based on dynamical systems. Experiments show that the eigenvalue spectra of these models are task-dependent, capturing the long-range modeling capability of these models under various long-memory tasks. Furthermore, empirical results demonstrate how changing model architectures can change the eigenvalue spectra and in turn the task performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper has interesting experimental results on the shifting roles of sequence mixing operators such as convolution, attention, and SSMs. \n2. The paper evaluates a comprehensive set of models on representative long-range tasks. \n3. The paper is clearly written."}, "weaknesses": {"value": "1. Novelty and technical difficulty: the paper's contribution is mainly conceptual rather than technical, and in my view the conceptual contribution appears somewhat limited. The dynamical system parameterization of transformers is from an existing work, and eigenvalues are known to be important and a central object of study in SSMs. \n2. For LPV systems, the eigenvalues are different across time steps, what's the time step corresponding to the eigenvalues in the plots?\n3. Even though Section 5 has very interesting insights, there are no concrete proposals for new architectures.\n4. In Section 5, the analysis of the effects of gating the convolution doesn't seem to apply to ListOps, indicating that the effectiveness of such analysis depends on each task. Can the authors give a characterization of the kind of tasks such analysis would apply to? Where would the analysis break down? Moreover, since ListOps requires all input information, I would expect no gating behavior to occur in SSMs. However, both LRU and Mamba 2 have small eigenvalues. Could the authors explain why that might be the case?\n\nMinor: the plot on page 5 can use different shades to indicate value, instead of different colors."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8lO5Z9BgYJ", "forum": "ALf0xHCCaP", "replyto": "ALf0xHCCaP", "signatures": ["ICLR.cc/2026/Conference/Submission21047/Reviewer_93S6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21047/Reviewer_93S6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762231883720, "cdate": 1762231883720, "tmdate": 1762940621343, "mdate": 1762940621343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We would like to thank all the reviewers for investing their time in carefully reading and evaluating our paper, and for providing thoughtful and constructive feedback. In order to address the concerns that were shared, we would like to provide the following clarifications: \n\n- **Summary of the approach:**\nWe pursue two lines of reasoning to demonstrate the usefulness of our metric. First, in the ablation study, we draw conclusions about the eigenvalue spectra that are favorable for a specific task and how they relate to the insights about eigenvalue placement from classical control systems theory. This analysis yields stronger conclusions for those tasks on which at least one of the investigated models performs well. Second, in Section 5, given a spectrum assumed to be favorable for a specific task, we aim to show the correlation between specific architectural changes, their effect on the spectral changes, and thereby also the performance. \n- **On novelty:** We agree that the importance of eigenvalues for SSMs is well understood, particularly concerning initialization. The novelty of our study lies in transferring this concept to attention-based frameworks, i.e., linear, norm, and softmax attention, creating a uniform observation tool for memory preservation investigation. Furthermore, our work investigates how task requirements are reflected in the eigenvalue spectra of high-performing models. Thereby, the analysis shows a clear correlation of eigenvalue placement with specific task requirements such as information retention and selective forgetting. Finally, we also investigated how these spectra adapt to and motivate architectural changes, showing that the analysis can become a principled tool for architectural design [93S6, T1HT, N9x6, 8FeC]. \n- **On applicability:** If the performance of a task-model combination is significantly lower than that of other task-model combinations, we would argue that the task has not yet been solved successfully using the corresponding model, and its eigenvalue spectra might not be favorable for the task at hand. Therefore, understanding whether the eigenvalue placement is favorable is mainly possible when there is a well-performing model with which we can compare the eigenvalue spectra. However, if this is not the case (e.g., LISTOPs for all the investigated models, with the worst performance for attention-based models), the obtainable insights from the eigenvalue spectra are potentially limited [93S6,T1HT,N9x6]. \n- **On model size:** The sizes chosen for the investigated models and tasks are limited by the resources available to the authors. For a detailed overview of parameter count per task, we refer the reviewers to the newly added Table 2 in Appendix B, illustrating our effort to keep them comparable across models [N9x6,8FeC].   \n \nFurthermore, we did the following modifications: \n\n- **On quantifyability:** To make our results more quantifiable, we added correlation plots of bin percentages against performance to Appendix C, in Figures 30 and 31. Furthermore, in addition to presenting varying head and seed plots next to each other, we provide Figures 25 to 28, which show these distributions, but averaged over seeds/heads [T1HT,N9x6,8FeC].\n- **On complex eigenvalues:** For completeness of our presentation, we added plots of the eigenvalues in the complex plane for models with complex eigenvalues in Figure 34 in Appendix C [8FeC]. \n- **On transition during training:**  We extended Appendix C with an additional visualization of the movement of eigenvalues during training in Figures 32 and 33 [8FeC]. \n\nMore individual concerns are addressed and further details are provided in reviewer-specific responses below. Furthermore, we kindly ask all reviewers to have a look at our changes in the main part of the paper, as well as the appendix, which are indicated in blue. **The improved version of our paper can be found in the supplementary material**."}}, "id": "YjjrYducrH", "forum": "ALf0xHCCaP", "replyto": "ALf0xHCCaP", "signatures": ["ICLR.cc/2026/Conference/Submission21047/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21047/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21047/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763757061073, "cdate": 1763757061073, "tmdate": 1763757061073, "mdate": 1763757061073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}