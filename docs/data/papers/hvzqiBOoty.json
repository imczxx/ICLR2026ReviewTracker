{"id": "hvzqiBOoty", "number": 14042, "cdate": 1758227506182, "mdate": 1759897394084, "content": {"title": "Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences", "abstract": "Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursion expressions modeling the evolution of uncertainty through client-server interactions, and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. Moreover, we define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. More importantly, our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating the dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference. These results enable robust root-cause analysis in safety-critical privacy-constrained and distributed infrastructures.", "tldr": "", "keywords": ["Federated Learning", "Granger Causality", "Uncertainty Propagation", "State-Space Model", "Dynamical Systems", "Internet-of-Things"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/483fed6120f34eeca0fb00819e74ce231583c01d.pdf", "supplementary_material": "/attachment/9fa1af69847b34e38e3b67b3a4667af9d357e454.zip"}, "replies": [{"content": {"summary": {"value": "1.The manuscript puts forward a systematic classification scheme for uncertainty sources in federated causal learning, which effectively distinguishes between the impacts of data noise and model variability—a foundational step for clarifying uncertainty components in this paradigm.\n\n2.It successfully derives closed-form propagation expressions that trace how uncertainties propagate through client-server, server-client communication channels, and internal processing paths of both entities. Notably, these expressions uncover four previously unrecognized cross-covariance terms, which reveal the coupling relationships between data and parameters within the FedGC framework.\n\n3.The authors establish spectral-radius-based convergence conditions that ensure the convergence of all covariance recursions. This not only provides theoretical guarantees for uncertainty evolution stability but also enables the derivation of explicit solutions for the steady-state variances of server-side global models and client-side local models.\n\n4.Theoretical analyses on convergence yield a key finding: the steady-state variance of the FedGC framework relies exclusively on the raw data statistics of clients, thereby eliminating the influence of initial epistemic uncertainty priors—a result that simplifies practical uncertainty quantification."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper identifies a meaningful gap in existing FedGC research and links it to real-world consequences, highlighting the problem’s practical relevance.\n\n2.It provides a systematic classification of uncertainty sources in FedGC and derives closed-form recursions for uncertainty propagation, which could serve as a baseline for future work on linear FedGC systems.\n\n3.The use of both synthetic and real-world industrial datasets is a strength, as it grounds theoretical claims in practical scenarios relevant to the paper’s target domain."}, "weaknesses": {"value": "1.The paper’s core convergence results depend on strict stationarity of client data and zero process noise. In practice, industrial time-series data are often non-stationary and contain process noise. The paper’s brief discussion of relaxing stationarity is insufficient—no formal bounds on convergence or experimental validation of non-stationary data are provided, limiting the theory’s real-world applicability.\n\n2.Without comparing to centralized GC, vanilla FedGC, or Bayesian FedGC methods, the paper cannot prove that its uncertainty modeling improves performance. For example, it is unclear whether the observed “faster variance decay with higher aleatoric noise” is unique to the proposed method or a general property of FedGC.\n\n3.Real-world experiments focus on parameter variance and L2 error but omit metrics critical for causal inference. This makes it impossible to assess if uncertainty quantification actually enhances “reliability and interpretability” in practice.\n\n4.Synthetic experiments use only 2 clients with fixed pm=2 and dm=8 . Scalability studies only vary dm, failing to validate the method for large federated systems, a key use case for FedGC.\n\n5.The paper’s “novel cross-covariance components” are a natural extension of covariance propagation in federated systems. There is no new algorithmic innovation that distinguishes it from prior work."}, "questions": {"value": "1.Your convergence results depend on strict data stationarity. For non-stationary industrial data, how would your uncertainty recursions behave? Do you have formal bounds on convergence or experimental results for non-stationary data to support the claim that steady-state variances remain independent of initial priors?\n\n2.Why did you not compare your method to baseline approaches? Without these comparisons, it is impossible to determine if your uncertainty modeling provides unique value. For example, could vanilla FedGC with simple variance estimation achieve similar or better performance?\n\n3.Appendix D.4 proposes a Gaussian mechanism for DP, but no experimental results are provided. What ε,δ values did you use, and how did DP noise affect: (a) Steady-state variances of server/client parameters; (b) Accuracy of causal link detection? Do you have evidence that your method balances privacy and utility better than existing DP-FedGC approaches?\n\n4.Your synthetic experiments use 2 clients, and scalability studies only vary dm​. For federated systems with 50+ clients, how does the computational complexity of your covariance propagation scale? Do you have plans to optimize this?\n\n5.You claim your method enables “robust root-cause analysis”. Can you provide experimental results for a simulated fault scenario where your uncertainty-aware FedGC outperforms vanilla FedGC in: (a) Detecting the fault’s root cause; (b) Providing early warnings via confidence intervals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WwowQ9n81m", "forum": "hvzqiBOoty", "replyto": "hvzqiBOoty", "signatures": ["ICLR.cc/2026/Conference/Submission14042/Reviewer_4bfG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14042/Reviewer_4bfG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761558194207, "cdate": 1761558194207, "tmdate": 1762924529761, "mdate": 1762924529761, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel and rigorous theoretical framework for quantifying and propagating uncertainty within Federated Granger Causality (FedGC). The authors systematically classify uncertainty sources (aleatoric/epistemic) and derive closed-form recursions for their propagation through client-server interactions, identifying key cross-covariance terms. A significant theoretical contribution is proving that the steady-state uncertainties depend solely on client data statistics, not initial priors. The work is technically sound, addresses a clear gap in the literature, and is supported by synthetic and real-world experiments. However, it seems that some simplified assumptions are used in this paper. It is better the authors can explain the practical relevance of such assumptions or the reason why the analytical insights under such assumptions are helpful for advancing the development of your field."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novelty and Significance: This is the first work, to the best of this reviewer's knowledge, to rigorously formalize uncertainty propagation in a federated causal learning setting. The problem is well-motivated by real-world needs in safety-critical systems (e.g., the 2003 blackout example), and the solution represents a substantial contribution beyond deterministic FedGC methods.\n\n- Theoretical Rigor: The paper is exceptionally strong on theory. The derivation of propagation recursions for variances and cross-covariances (Theorems 6.7, 6.8) is meticulous. The convergence analysis (Section 7) is a key highlight, demonstrating that the influence of initial epistemic priors vanishes at steady-state, a non-trivial and valuable result that enhances the method's robustness.\n\n- Comprehensive Formulation: The systematic breakdown of uncertainty sources and their propagation paths (client-to-server, server-to-client, within-client, within-server) is clear and insightful. The identification of the four cross-covariance terms (Ω, Λ, Γ, Ψ) elegantly captures the complex coupling between data and model uncertainties in a federated system.\n\n- Empirical Validation: The experiments on both synthetic and real-world (HAI, SWaT) datasets validate the theoretical claims. The results convincingly show how uncertainty evolves and converges, and how it is affected by aleatoric and epistemic noise, aligning with the theoretical predictions."}, "weaknesses": {"value": "- It is better if the authors can explain the following assumptions:\n\n   - Linearity and LTI: The core model is a Linear Time-Invariant (LTI) state-space system. While Appendix E briefly discusses extensions to EKF and GPs, these remain conceptual and lack empirical validation. Many real-world dynamical systems exhibit strong non-linearities.\n\n   - Stationarity (A4): The assumption of weakly stationary client data is often violated in practice (e.g., due to system faults, operational changes, or trends). The paper acknowledges this limitation and shows in Fig. 1(e-f) that mean shifts cause performance degradation, but the proposed framework does not inherently handle non-stationarity.\n\n   - No Process Noise (A5): Assuming Q=0 (no process noise) is a significant simplification. In real systems, the underlying state evolution is often noisy, and this omission may lead to an underestimation of total uncertainty.\n\n- Scalability and Computational Complexity: The analysis in Appendix D.5 acknowledges that a naive implementation has a computational cost of O(p_m² d_m²) per client per round. While the proposed structural optimizations are noted, their efficacy is not demonstrated empirically. For high-dimensional client data (d_m large), this could be a severe bottleneck, potentially rendering the method impractical without further approximations.\n\n- Limited Discussion on Practical Utility: The paper excellently shows that uncertainty can be quantified, but could do more to discuss how this uncertainty should be used in practice by a system operator.\n\n   - How should one set thresholds on the predictive confidence intervals for actionable alerts?\n\n   - Could the uncertainty estimates be used for active learning or to guide resource allocation among clients? A more concrete discussion on the operational decision-making pipeline enhanced by these uncertainty estimates would strengthen the impact."}, "questions": {"value": "- How robust is the convergence and performance of the method when the stationarity assumption (A4) is mildly violated? Could the framework be combined with online change-point detection to reset the uncertainty estimates?\n- It is better if the authors can also introduce some other related works:\n\n   - FedCSL: a scalable and accurate approach to federated causal structure learning\n   - Enhancing causal discovery in federated settings with limited local samples"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jGDZjxP8ds", "forum": "hvzqiBOoty", "replyto": "hvzqiBOoty", "signatures": ["ICLR.cc/2026/Conference/Submission14042/Reviewer_3TSK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14042/Reviewer_3TSK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803708152, "cdate": 1761803708152, "tmdate": 1762924529292, "mdate": 1762924529292, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper adds uncertainty awareness to federated Granger causality. It classifies uncertainties (the primary contributors), derives how they propagate through the federated loop (client→server messages, server→client gradients, and local updates), identifies four key cross‑covariances that couple them, and proves that with stable updates, uncertainties converge to values determined by data noise rather than initial beliefs. Empirically, the method’s uncertainty measures track noise levels and provide confidence intervals around causal links, which is crucial for risk‑aware operations in distributed, privacy‑constrained systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The first framework rigorously quantifies uncertainty and its propagation within federated Granger causality frameworks.\n2. In federated platforms, the paper explores and characterizes the source of uncertainty, how propagation recursions occur, and estimates the impact of uncertainty.\n3. Theoretically complete and comprehensive experience."}, "weaknesses": {"value": "1. The assumption is a linear time‑invariant state‑space model, Gaussian noise, and (for tractability) in places where all randomness enters via measurement noise (no process noise). Real systems can be nonlinear and non‑Gaussian. \n2.  While formulas are closed‑form, implementing full covariance and cross‑covariance tracking adds engineering complexity compared to point‑estimate FedGC.\n3. For the section 5 source of uncertainty, Aleatoric and Epistemic uncertainty is the intrinsic one, right? There is no specific algorithm to identify the main contributors, right?\n4. Double comma in Line 263\n5. What is the causal structure before estimating the cumulative effect of uncertainties?"}, "questions": {"value": "Same as weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "c4q9wLn2HG", "forum": "hvzqiBOoty", "replyto": "hvzqiBOoty", "signatures": ["ICLR.cc/2026/Conference/Submission14042/Reviewer_pVDz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14042/Reviewer_pVDz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761853635344, "cdate": 1761853635344, "tmdate": 1762924528856, "mdate": 1762924528856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the first theoretical framework for uncertainty quantification in Federated Granger Causality (FedGC) learning. The authors systematically classify uncertainty sources into aleatoric (data noise) and epistemic (model variability) components, derive closed-form recursion expressions for uncertainty propagation through client-server interactions, and identify four novel cross-covariance terms coupling data and model parameters. Key theoretical contributions include spectral-radius-based convergence conditions and proofs that steady-state variances depend exclusively on client data statistics, eliminating dependence on initial epistemic priors."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This is the first work to quantify uncertainty propagation in federated Granger causality systematically.\n2. The proof that steady-state variances depend only on client data statistics (independent of initial epistemic priors) is both theoretically elegant and practically valuable. This robustness property ensures that poor initialization doesn't permanently affect uncertainty estimates, a crucial property for deployment in safety-critical systems.\n3. The paper validates theoretical predictions through well-designed experiments on synthetic data with varying noise regimes, demonstrating that uncertainty evolution matches theoretical predictions."}, "weaknesses": {"value": "1. The entire theoretical framework is limited to linear time-invariant (LTI) systems. While Appendix E discusses extensions to EKF and GP, these remain sketchy and lack rigorous convergence guarantees. Many real-world causal systems exhibit significant nonlinearity, severely limiting applicability.\n2. The assumption of weakly stationary data with time-invariant moments is quite restrictive. Real-world industrial systems often exhibit distribution shifts, seasonal patterns, and non-stationary dynamics. Figure 1(e-f) shows performance degradation during mean shifts, but the paper provides insufficient guidance on handling non-stationarity beyond acknowledging it as a limitation.\n3. What is the wall-clock time overhead of tracking uncertainties compared to vanilla FedGC? Table 2-3 show trace values but not runtime comparisons.\n4. How does your method compare quantitatively to simpler approaches like: (a) ensemble-based uncertainty estimation, (b) Monte Carlo dropout in a federated setting, or (c) treating each client's parameter variance independently without cross-covariance terms?\n5. In the 2003 blackout example (Introduction), you mention monitoring variance widening. What thresholds or decision rules would you recommend for triggering alarms based on uncertainty estimates?"}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4JrXmvT1FH", "forum": "hvzqiBOoty", "replyto": "hvzqiBOoty", "signatures": ["ICLR.cc/2026/Conference/Submission14042/Reviewer_qSyr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14042/Reviewer_qSyr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762092706286, "cdate": 1762092706286, "tmdate": 1762924528461, "mdate": 1762924528461, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}