{"id": "UeQ4aw25Sw", "number": 12964, "cdate": 1758212183575, "mdate": 1759897473856, "content": {"title": "DENSE-RAG: Measuring and Improving Context Understanding for Consistent Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) has significantly advanced LLM performance in knowledge-intensive tasks. \nHowever, when LLMs misinterpret retrieved content, they often revert to pre-trained parametric knowledge or generate hallucinated responses, undermining RAG effectiveness. \nThis highlights the need to assess LLMs’ understanding of the retrieved context, since effective measurement is essential for evaluating and improving RAG performance.\nIn this work we try to explore this problem by proposing DEgree-based uNcertainty with Semantically Equivalent contexts (DENSE), a training-free and model-agnostic method to evaluate LLM understanding of retrieved documents. \nDENSE constructs semantically equivalent context and introduces a degree-based entropy to quantify response semantic uncertainty. \nBuilding on DENSE, we further introduce DENSE-RAG, which includes two training-free DENSE-guided modules: adaptive semantic chunking and iterative context refinement.\nExtensive experiments on open-book QA datasets show that higher DENSE uncertainty correlates with lower QA performance, validating DENSE as a reliable indicator of LLM understanding measurement. \nDENSE-RAG also achieves performance competitive with state-of-the-art baselines approaches without introducing additional model or fine-tuning.", "tldr": "We propose an unsupervised method DENSE to evalaute LLM's understanding of context in RAG, and DENSE-RAG to improve RAG performance on Open book QA task according to the DENSE evaluation.", "keywords": ["Retrieval-augmented-generation;Large Language Model;Open-book QA"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/35e68f4aa8cab04e22214950d4bfbc56801a6a8e.pdf", "supplementary_material": "/attachment/77e03463b59f0744f28d3372487741a1e25fa867.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose DENSE, a training-free and model-agnostic method that uses semantically equivalent contexts and degree-based entropy to quantify semantic uncertainty. They further extend it to DENSE-RAG, which enhances RAG through adaptive chunking and context refinement using the DSE metrics, achieving competitive performance without additional training."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a practical metric to measure LLM's understanding of a given context, which can be directly applied to downstream RAG applications\n- Extensive experiments and ablation studies support the effectiveness of the proposed metrics"}, "weaknesses": {"value": "- The foundation of the work is weak. What is the formal definition of the semantic space $\\mathcal{S}$ and the mapping function $\\pi$? The paper does not explain how $\\pi$ is calculated/approximated. The work relies on the assumption $\\pi(q, C) = \\pi(q, C')$, but this assumption is not clearly defined. In Section 4.1, the authors claim $\\pi(c') = \\pi(c)$, where $c'$ is generated by the LLM, but it is unclear how this equality is ensured in practice. This claim also does not align with the statement of Property 1 since we don't know if $\\pi(q, c) = \\pi(q, c')$. Moreover, the authors aim to evaluate the LLM’s understanding of the given context, yet they simultaneously rely on the LLM’s understanding to generate the rephrasing. \n- Is it possible to completely rely purely on the retrieved context when generating the responses during DSE calculation without any parametric knowledge? Since it is not feasible to separate parametric and retrieved knowledge, the response might be grounded to the parametric knowledge rather than the retrieved knowledge."}, "questions": {"value": "Address the above questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TEA0qgX7v1", "forum": "UeQ4aw25Sw", "replyto": "UeQ4aw25Sw", "signatures": ["ICLR.cc/2026/Conference/Submission12964/Reviewer_hLFs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12964/Reviewer_hLFs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12964/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701396062, "cdate": 1761701396062, "tmdate": 1762923721083, "mdate": 1762923721083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper asks a simple question: “Does the model actually understand the stuff we retrieved?” The authors create several rephrased versions of each retrieved chunk, run the LLM on these semantically equivalent contexts with greedy decoding, and then measure how much the answers’ meanings wobble; more wobble ⇒ poorer context understanding. They turn that idea into a metric (DSE) and a plug-in pipeline that first measures uncertainty and then, only when needed, fixes the context via semantic chunking and an iterative prune-and-refill step."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. DSE is a nice graph view of semantic agreement across answers; skipping clustering and using degree over an entailment matrix makes the signal straightforward to compute and attribute back to specific chunks. \n\n\n2. The paper shows a consistent pattern that higher DSE aligns with worse QA, which gives DSE a real “thermometer” feel for context understanding rather than just another heuristic."}, "weaknesses": {"value": "1. The pipeline uses an LLM to rephrase chunks and another LLM to judge entailment between answers; this makes the measurement depend on two models’ quirks, so I’d like to see robustness when swapping the NLI judge or using a lightweight supervised NLI model.\n\n2. “Semantically equivalent” is enforced by a prompt rather than a guarantee; please show automatic checks (e.g., NLI on chunk pairs) that the rephraser didn’t drop constraints, especially on math, dates, and entity coreference.\n\n3. Greedy decoding is tidy for measurement, but production RAG often samples; if decoding changes, does DSE still track understanding, or does sampling noise blur the signal.\n\n4. Single-chunk edits help attribution but miss cross-chunk interactions (e.g., a coreference in chunk A that only makes sense with chunk B), which could inflate DSE for the wrong reason."}, "questions": {"value": "1. How do you verify that chunk rephrasings preserve constraints (numbers, negations, entity links) beyond qualitative checks; any automated guardrails before a rephrased chunk enters DENSE.\n\n2. If we replace the LLM-as-NLI with a small supervised NLI (e.g., DeBERTa) or a cosine-semantic scorer, does DSE rank examples similarly and still predict failure; please report rank correlation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xCfQ86qtlk", "forum": "UeQ4aw25Sw", "replyto": "UeQ4aw25Sw", "signatures": ["ICLR.cc/2026/Conference/Submission12964/Reviewer_EmPP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12964/Reviewer_EmPP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12964/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990888296, "cdate": 1761990888296, "tmdate": 1762923720642, "mdate": 1762923720642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method called DENSE to assess whether a given LLM \"understand\" the retrieved set of chunks, i.e., context, and risks generating an incorrect answer. The method consists in prompting the target LLM several times with several paraphrases (rephrased sub-chunks) and gather the set of generated answers; if there is variation in the collected answer set then there is uncertainty otherwise not (the authors define a DENSE score and a threshold for it).  In addition, the paper proposes two ways to use DENSE to improve retrieval augmented QA. One is incremental chunk extension that iteratively adds sentences to initially retrieved chunks. The other one is using DENSE to analyse chunks in the set as certain or uncertain, and this last as necessary/unnecessary. Then the set of chunks is refined by removing and adding new chunks as necessary."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Determining uncertainty via chunk paraphrasing and answer variation is an interesting alternative (though not completely new)."}, "weaknesses": {"value": "- The proposed approach seems to be rather expensive, both the context understanding (uncertainty detection) and QA performance improvement methods. Several passes over the chunks are required. It would be useful if the authors could add a discussion and report the number of calls the approach requires.\n\n- The DENSE approach for context understanding evaluation should be compared to uncertainty estimation approaches (e.g., Perplexity, [Kuhn et al., 2023] see for a comprehensive library [1]). \n\n[1] https://arxiv.org/abs/2406.15627\n\n- The incremental sentence  extension of chunks seems to work well but is not clear how the documents used are obtained.  \n\n- The comparisons with existing methods in Table 2 seem weak. AmbigQA has only one reported value. Also, what retrieval source are these previous work using? Unfortunately, different paper often use different corpora (e.g.,  gold+distractors of the original dataset, different Wikipedia dumps, different retrievers). So it would be useful to have this clarified for each of the reported systems. Also, it would be useful to have a discussion of the chosen comparison method and how it compares to the proposes in the paper."}, "questions": {"value": "- Line 021, what is \"degree-based\" entropy? Line 221, what is the \"degree\" of a response. It is not clear what the authors mean by degree.\n\n- Section 4.2, what is the difference between degree-based uncertainty and [Kuhn et al., 2023]? The explanation at paragraph starting at Line 203 is not clear. Perhaps an example would help.\n\n- How many paraphrases are generated for each chunk to determine an answer set? Which model is used for paraphrasing?\n\n- Adaptive semantic chunking (Section 5.1) is not clearly explained. At Line 249, \"we merge all documents\", which documents are these? From what does the iterative aggregation of sentences starts? Each initially retrieved chunk is augmented with sentences iteratively?\n\n- The context refinement step is similar to re-ranking, maybe it should be compared with re-ranking methods specifically, e.g., baseline ones like retrieving a large number of chunks and the using NLI."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iN5jooMjQN", "forum": "UeQ4aw25Sw", "replyto": "UeQ4aw25Sw", "signatures": ["ICLR.cc/2026/Conference/Submission12964/Reviewer_esQU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12964/Reviewer_esQU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12964/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762026062587, "cdate": 1762026062587, "tmdate": 1762923720123, "mdate": 1762923720123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DENSE (Degree-based Semantic Entropy), a training-free, model-agnostic estimator of contextual understanding in RAG systems. DENSE measures semantic uncertainty by generating responses under semantically equivalent (rephrased) contexts and computing a graph-based degree score over pairwise NLI entailments between responses. Building on this signal, the paper proposes DENSE-RAG, which (i) selectively switches from fixed-size to semantic chunking for uncertain questions (Adaptive Semantic Chunking), and (ii) performs Iterative Context Refinement by classifying retrieved chunks into certain/necessary/unnecessary and pruning/refilling accordingly. Experiments on TriviaQA, NQ, AmbigNQ, and 2WikiQA (and a preliminary CNN/DM study) show strong correlation between DENSE and accuracy and competitive or superior performance to several SOTA methods without any finetuning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. DENSE-RAG introduces a lightweight, plug-and-play uncertainty estimation framework that requires no additional training or fine-tuning, making it practical for real-world black-box LLMs.\n2. Strong evidence that higher DENSE values correlate with reduced QA accuracy across datasets and model sizes, validating it as a reliable proxy for contextual understanding.\n3. Includes detailed ablations, sensitivity tests, runtime analysis, and clear pseudocode, improving reproducibility and interpretability."}, "weaknesses": {"value": "1. The same LLM is used for rephrasing, inference, and entailment, which risks internal bias and inflates semantic agreement.\n2. The paper reports runtime complexity but lacks cost comparisons against strong fine-tuned baselines (e.g., RankRAG, RAG-DDR), leaving efficiency claims incomplete.\n3. Experiments focus mostly on QA tasks with preliminary summarization results; effectiveness on other domains or structured reasoning tasks remains unclear."}, "questions": {"value": "1. Which NLI model and thresholds were used for entailment evaluation, and how sensitive are the results to changing the NLI backbone?\n2. How does DENSE perform under non-greedy decoding settings (e.g., temperature sampling) where response variance is higher?\n3. Can DENSE-RAG be adapted for multi-turn or conversational RAG settings, and how would uncertainty accumulation across turns be handled?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JSKYfV2hYd", "forum": "UeQ4aw25Sw", "replyto": "UeQ4aw25Sw", "signatures": ["ICLR.cc/2026/Conference/Submission12964/Reviewer_XtSK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12964/Reviewer_XtSK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12964/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762055703798, "cdate": 1762055703798, "tmdate": 1762923719552, "mdate": 1762923719552, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}