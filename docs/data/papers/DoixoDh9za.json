{"id": "DoixoDh9za", "number": 9537, "cdate": 1758126723358, "mdate": 1759897713450, "content": {"title": "Deep Variational Inference Symbolic Regression", "abstract": "A Bayesian inference approach to symbolic regression offers a combination of two powerful interpretability properties.\nOn its own, symbolic regression offers explainable, unconstrained, closed-form expressions.\nHowever, combined with Bayesian inference, symbolic regression provides probability distributions over these interpretable models, accounting for real-world, limited, noisy data.\nDeep Symbolic Regression (DSR) is an algorithm that uses neural networks to perform symbolic regression; however, it aims to locate a single expression that best fits the data, rather than to calculate posteriors.\nIn this work, we introduce Deep Variational Inference Symbolic Regression (DVISR).\nDVISR extends DSR into a fully Bayesian approach to symbolic regression by replacing the reward function used to train the network with the inner part of the expectation of the evidence lower bound.\nDVISR also modifies the architecture of the network to output probability distributions over constants within the expressions.\nThis architectural modification enables the computation of the posterior distributions over both the expression trees and the constants contained within them.\nWe show that DVISR can recover the true posterior distribution in simple settings and demonstrate scaling properties as the expression sizes get larger.", "tldr": "A deep variational inference approach to symbolic regression", "keywords": ["variational inference", "symbolic regression", "bayesian statistics", "neural networks"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dad3da8e41c5b7eb0f6c5989c309dda02e6fdcd8.pdf", "supplementary_material": "/attachment/918b636be162dc9012fc55ffa7099f7bf4a7bea4.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a new algorithm, termed Deep Variational Inference Symbolic Regression (DVISR), for conducting Bayesian inference for symbolic regression. The algorithm leverages recursive neural networks (RNNs) to learn a distribution over the expression tree of mathematical expressions. DVISR is able to learn a distribution over both the constants, as well as, the expression structure. Empirical results are demonstrated on a small set of synthetic datasets coming from known mathematical expressions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "There is a growing interest in symbolic expression and developing methods that ensure that we can capture the uncertainty of the expression structure in addition to the parameter certainty seems worthwhile. The paper in general is well written and the method well motivated."}, "weaknesses": {"value": "There are two primary weaknesses which cause me to recommend rejection at this stage: 1) weak empirical validation of DVISR, and 2) insufficient discussion of related work/consideration of relevant work.\n\n**Weak Empirical Evaluation**\n\nThe empirical evaluation of this algorithm is limited solely to synthetic datasets with a maximum of 11 data points and data generated from very simple expressions.  The Section 3.1.1 experiment only considers 4 candidate expressions for which we can analytically compute the posterior, therefore this problem setting doesn't require a very complex algorithm in the first place. Section 3.1.2 considers more candidate expressions but as far as I can tell there is no evidence that the algorithm actually converges on the true expression. The final experiment in Section 3.2 is the only experiment that considers doing inference over both the form of the expression and the constants within the expression, but this section only considers 7 candidate expression.\n\n*Overall, there is no experiment which tests the algorithm on real-world data, no experiment that could not be feasibly solved with a naive brute-force approach and, in general, no comparison to existing baselines.* While the paper explicitly mentions the experimental validation as a weakness of the paper, the current evaluation provides me with very little useful evidence of whether I would actually want to use this algorithm on a real-world dataset.\n\n**Insufficient discussion of existing work**\n\nThe research field of probabilistic programming has a wide history of deriving general purpose Bayesian inference algorithms for arbitrary probabilistic programs, sometimes referred to as universal probabilistic programming [1,2]. The symbolic regression problem can be framed as inference in a universal probabilistic program and there is a wealth of papers with empirical results for the task of symbolic regression, also sometimes referred to as function induction or program synthesis [2,3,4,5,6] (this is not necessarily an exhaustive list). In general, the algorithms have been shown to scale to be able to do inference in 100s or even 1000s of expression tree while also inferring the constants and applying the algorithms to real-world data. Many of these algorithms are based on ideas from variational inference [2,3,8,9,10,11], so they could be used as relevant baselines to compare DVISR against. Overall, the probabilistic programming algorithms aim to solve a more general inference problem formulation than the symbolic approach, so I definitely see scope for deriving inference algorithms specifically targeted towards symbolic regression. However, the paper should at least discuss how the DVISR approach compares against these more general algorithms. \n\n\n[1] Van De Meent, Jan-Willem, et al. \"An introduction to probabilistic programming.\" arXiv preprint arXiv:1809.10756 (2018).\n\n[2] Le, Tuan Anh, Atilim Gunes Baydin, and Frank Wood. \"Inference compilation and universal probabilistic programming.\" Artificial Intelligence and Statistics. PMLR, 2017.\n\n[3] Reichelt, Tim, Luke Ong, and Thomas Rainforth. \"Rethinking variational inference for probabilistic programs with stochastic support.\" Advances in Neural Information Processing Systems 35 (2022): 15160-15175.\n\n[4] Reichelt, Tim, Luke Ong, and Tom Rainforth. \"Beyond Bayesian Model Averaging over Paths in Probabilistic Programs with Stochastic Support.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2024.\n\n[5] Zhou, Yuan, et al. \"Divide, conquer, and combine: a new inference strategy for probabilistic programs with stochastic support.\" International Conference on Machine Learning. PMLR, 2020.\n\n[6] Saad, Feras A., et al. \"Bayesian synthesis of probabilistic programs for automatic data modeling.\" Proceedings of the ACM on Programming Languages 3.POPL (2019): 1-32.\n\n[7] Saad, Feras, et al. \"Sequential Monte Carlo learning for time series structure discovery.\" International Conference on Machine Learning. PMLR, 2023.\n\n[8] Becker, McCoy R., et al. \"Probabilistic programming with programmable variational inference.\" Proceedings of the ACM on Programming Languages 8.PLDI (2024): 2123-2147.\n\n[9] Ritchie, Daniel, Paul Horsfall, and Noah D. Goodman. \"Deep amortized inference for probabilistic programs.\" arXiv preprint arXiv:1610.05735 (2016).\n\n[10] Harvey, William, et al. \"Attention for inference compilation.\" arXiv preprint arXiv:1910.11961 (2019).\n\n[11] Baydin, Atilim Güneş, et al. \"Etalumis: Bringing probabilistic programming to scientific simulators at scale.\" Proceedings of the international conference for high performance computing, networking, storage and analysis. 2019."}, "questions": {"value": "None."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b9yj0Soqx8", "forum": "DoixoDh9za", "replyto": "DoixoDh9za", "signatures": ["ICLR.cc/2026/Conference/Submission9537/Reviewer_fEfd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9537/Reviewer_fEfd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9537/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761500357456, "cdate": 1761500357456, "tmdate": 1762921100198, "mdate": 1762921100198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Deep Variational Inference Symbolic Regression (DVISR), a Bayesian extension of Deep Symbolic Regression (DSR) that aims to approximate the posterior distribution over symbolic expressions. The idea of combining variational inference with neural-guided symbolic regression is novel and promising. However, the experimental evaluation is currently limited to simple, synthetic cases, which raises significant concerns about the method's scalability, practical utility, and advantages over existing approaches. The following points detail these concerns."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The core idea of formulating symbolic regression as a variational inference problem is a significant contribution. By redefining the training objective to maximize the Evidence Lower Bound (ELBO), the authors shift the goal from finding a single best-fit expression (as in DSR) to approximating the full posterior distribution over expressions."}, "weaknesses": {"value": "**1. Lack of Evaluation on Standard Benchmarks and Real-World Data​**\n\nThe experimental validation is conducted exclusively on minimalistic synthetic datasets (e.g., y=x0**2, y=x0) with very small expression sizes (up to 10 tokens). The absence of tests on established symbolic regression benchmarks (e.g., SRBench, AI Feynman datasets) or any real-world datasets makes it impossible to assess the method's performance in practical, challenging scenarios. The claim of \"demonstrating scaling properties\" is not fully convincing without comparison to standard baselines on complex problems.\n\n**​2. Insufficient Demonstration of Predictive Accuracy​**\n\nThe experiments successfully demonstrate that the learned variational distribution q_ϕ(f)converges to the true posterior p(f∣X,y)in controlled settings. However, symbolic regression is ultimately about finding accurate models for data. The paper fails to show that a higher posterior probability correlates with a higher fit accuracy (e.g., lower NMSE on a test set). Symbolic regression is a combinatorial optimization problem where local optimality (high probability under the policy) does not guarantee global optimality (the best-fitting expression). The evaluation should connect posterior probability to actual predictive performance.\n\n​**3. Lack of Comparative and Ablative Analysis​**\n\nAs an extension of DSR, it is crucial to benchmark DVISR against DSR and other contemporary symbolic regression methods (e.g., GP, transformer-based approaches). The absence of such comparisons leaves the reader questioning the practical benefit of the proposed Bayesian framework.\n\nFurthermore, the paper introduces two key modifications: a new reward function based on the ELBO and an enhanced network architecture (adding the previous token and constant values as input). An ablation study is necessary to disentangle the individual contribution of each modification to the overall performance. Without it, it is unclear which component drives any potential improvement.\n\n**​4. Questionable Utility of Constant Prediction​**\n\nDVISR introduces the prediction of constants within expressions, which dramatically expands the search space to be infinite. While the simple experiments show convergence of the posterior over expression trees q_ϕ(z), the paper does not adequately justify why this added complexity is beneficial. Does predicting constants alongside the expression structure lead to the discovery of more accurate or meaningful expressions compared to methods that optimize constants as a separate downstream step (like DSR)? The significant increase in search difficulty must be justified by a clear and demonstrated advantage."}, "questions": {"value": "The questions are described in the \"Weakness\" section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QWsuCycCBQ", "forum": "DoixoDh9za", "replyto": "DoixoDh9za", "signatures": ["ICLR.cc/2026/Conference/Submission9537/Reviewer_8taT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9537/Reviewer_8taT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9537/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645813815, "cdate": 1761645813815, "tmdate": 1762921099614, "mdate": 1762921099614, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Deep Variational Inference Symbolic Regression (DVISR), a novel method that extends Deep Symbolic Regression (DSR) into a fully Bayesian framework. The key innovation is the reformulation of the training objective to maximize the Evidence Lower Bound (ELBO), enabling the model to approximate the full posterior distribution over symbolic expressions rather than finding a single point estimate. The authors provide convincing evidence on small-scale, controlled problems that DVISR can successfully recover the true posterior distribution for both expression structure and constants."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The core strength of this work is its novel and well-motivated conceptual framework, which effectively combines the interpretability of symbolic regression with the uncertainty quantification of Bayesian inference, as a direct improvement of the DSR method. The theoretical grounding adds significant depth and credibility to the methodological claims."}, "weaknesses": {"value": "The primary weakness is the limited scale and scope of the experimental validation, which only demonstrates efficacy on very small synthetic problems with minimal expression complexity and no noise. The paper does not show that the method scales to problems of practical interest or performs competitively against existing symbolic regression algorithms on standard benchmarks. Furthermore, the comparison to related work, especially other Bayesian symbolic regression approaches, is relatively superficial."}, "questions": {"value": "1. What is the core advantage of using Bayesian probability modeling? Can you summarize its key strengths?\n2. Was any ablation study conducted to evaluate the contribution of the specific architectural change, such as providing the previous token as input?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5dsEAssEmg", "forum": "DoixoDh9za", "replyto": "DoixoDh9za", "signatures": ["ICLR.cc/2026/Conference/Submission9537/Reviewer_EHVz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9537/Reviewer_EHVz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9537/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897087740, "cdate": 1761897087740, "tmdate": 1762921099149, "mdate": 1762921099149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper extends DSR by replacing its heuristic reward with the ELBO, training the policy with REINFORCE so that maximizing reward corresponds to variational inference over expressions. It also has the network output distributions for constants, yielding posteriors over both trees and parameters. Experiments are toy-scale: tiny libraries and depths (with and without constants), where the authors can compute the evidence exactly (or via controlled quadrature) and show ELBO→log-evidence and KL→0; a scaling study shows degradation as maximum expression length grows."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clear probabilistic objective. Casting the policy objective exactly as the ELBO (not risk-seeking) makes the optimization/probabilistic story coherent and checkable. \n\nPosteriors over constants and structures. The architecture outputs distributions for constants, so the method produces joint posteriors instead of doing separate constant fitting downstream. \n\nPositioning vs. VI literature. The paper distinguishes DVISR from earlier VI-style SR that were limited (polynomials only, partial parameter sets)."}, "weaknesses": {"value": "Novelty vs. prior neural-policy SR is limited. Using an RL-trained neural policy to sample expression tokens is well-trod (DSR/Neural-guided GP/PhySO/FEX). The paper’s main delta is the VI objective and constant distributions. Please delineate algorithmic differences and where VI yields tangible gains beyond conceptual neatness (e.g., better calibrated uncertainty, improved exploration, or sample efficiency), ideally with head-to-head ablations against DSR/PhySO/FEX/PySR.\n\nNo runtime/efficiency comparisons. Claims of amortization aren’t backed by wall-clock or budgeted comparisons. Add training time, sample counts, and hardware vs. DSR, PhySO, PySR, FEX on standard suites (Feynman, SRBench), and report accuracy/recovery vs. time curves.\n\nScaling limits left unresolved. The scaling study shows KL grows with expression size; the paper itself lists decreased performance as a key limitation. Provide architectural ablations (e.g., transformers or PPO/GRPO objectives the authors mention) and demonstrate whether they actually improve scaling on the same search spaces. \n\nEvaluation scope is narrow. Current tests are tiny and noiseless (except simple cases), with evidence computable only because the model space is tiny or integrals are defined carefully. Add real datasets (noisy data, physics with units) and report posterior calibration metrics (coverage, NLL, PIT histograms), not just convergence to an analytic posterior in toy settings. \n\nUse of priors not compared to alternatives. If structural/physical priors are used (even lightly), compare to grammar/units prior baselines and show contribution via +prior/−prior ablations.\n\nPresentation gap: ELBO pieces vs. practical likelihood. The likelihood assumes fixed σ and i.i.d. Gaussian noise; real-world SR often needs heteroscedasticity/robust losses. Consider likelihood sensitivity ablations: different σ, Student-t, or learned noise heads, and show how the posterior shifts."}, "questions": {"value": "Where is VI strictly better than risk-seeking/heuristic rewards? Provide a controlled comparison showing improved uncertainty calibration, exploration diversity, or sample efficiency when optimizing ELBO vs. a standard DSR-style reward. \n\nRuntime and budgets. What are the wall-clock times and numbers of sampled expressions to reach a given recovery/accuracy on Feynman or SRBench? Any evidence of amortization paying off vs. per-candidate constant fitting?\n\nPosterior quality. Do you measure calibration (e.g., coverage at nominal levels) or report NLL/CRPS on held-out data? If not, please add.\n\nScaling mitigation. Of the proposed fixes (transformers, PPO/GRPO), which have you prototyped, and what empirical gains do they bring on the same scaling benchmark? \n\nConstants posterior expressivity. You currently use Gaussians; do mixtures/flows help capture multimodality without exploding variance-reduction needs? Any results? \n\nEvidence computation in “with constants.” The appendix adopts a special handling of integrals over constants not in a given tree. Please clarify the definition and numerics; can you validate it on slightly larger constant sets with importance sampling or nested quadrature? \n\nComparisons to Bayesian SR (MCMC/EM). Include a Bayesian baseline (e.g., BSR/MCMC) on the exact same toy settings to show that VI reaches comparable posteriors much faster—or explain why not."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ur6sPHiqeS", "forum": "DoixoDh9za", "replyto": "DoixoDh9za", "signatures": ["ICLR.cc/2026/Conference/Submission9537/Reviewer_Y6CD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9537/Reviewer_Y6CD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9537/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974135848, "cdate": 1761974135848, "tmdate": 1762921098829, "mdate": 1762921098829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}