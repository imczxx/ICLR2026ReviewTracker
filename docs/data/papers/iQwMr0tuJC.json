{"id": "iQwMr0tuJC", "number": 8864, "cdate": 1758100308489, "mdate": 1759897758601, "content": {"title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "abstract": "Large language models (LLMs) have recently been extended beyond traditional text generation to serve as interactive agents capable of using external tools based on user intent. \nHowever, current LLM agents still show limited ability to handle \\textit{goal-oriented} queries, which require decomposing a high-level objective into multiple interdependent API calls with correct planning and execution.\nCurrent approaches mainly rely on zero-shot evaluation due to the absence of training data. While proprietary closed-source models such as GPT-4 demonstrate strong reasoning abilities, smaller open-source models struggle to perform complex tool use effectively.\nThus, we propose a novel training framework GOAT, which enables fine-tuning of LLM agents in a human annotation-free setting. GOAT automatically constructs synthetic datasets of goal-oriented API execution tasks directly from given API documents, equipping models with the ability to reason over interdependent calls and generate coherent responses.\nThrough extensive experiments, we show that GOAT-trained agents achieve state-of-the-art performance across multiple existing goal-oriented benchmarks. In addition, we introduce GOATBench, a new goal-oriented API execution benchmark, and demonstrate that agents trained with GOAT also excel in this setting.\nThese results highlight GOAT as a practical path toward building robust open-source LLM agents capable of complex reasoning and tool use.", "tldr": "We introduce GOAT, a framework that automatically builds synthetic goal-oriented API datasets from API documentation to fine-tune LLM agents without human annotation.", "keywords": ["Large Language Models", "LLM Agents", "Tool Learning", "Reasoning", "Synthetic Data Generation", "Benchmark Consturction"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/46e2f1038db0ce4f8f82d3cfcc65495e09b60c25.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper identifies a challenge in developing tool-using LLM agents: open-source models struggle with \"goal-oriented\" queries that require complex planning and multiple, interdependent API calls. The authors attribute this to a lack of suitable training data.\n\nTo solve this, they propose GOAT (Goal-Oriented Agent with Tools), a training framework that automatically generates synthetic, goal-oriented training data from API documentation without human annotation. The core of GOAT is a three-stage pipeline:\n1.  API Dependency Graph Construction: It parses API documents and builds an initial graph of all possible input-output connections.\n2.  Graph Refinement: This graph is progressively filtered for feasibility using three steps: embedding similarity, LLM-based semantic checking, and finally, validation via actual API call execution.\n3.  Data Generation: The framework samples connected subgraphs (valid API sequences) and uses a \"call-first\" strategy. It first executes the API sequence, then generates corresponding sub-queries, and finally generates a high-level user query and a final response based on the execution trace.\n\nThe authors demonstrate that fine-tuning open-source models on this GOAT-generated data improves performance on several goal-oriented benchmarks, including RestBench, API-Bank, and a new benchmark introduced in this paper, GOATBench."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1.  Sensible \"Call-First\" Design: The \"call-first\" generation strategy (Section 3.1.3) is a sound design choice. Generating a natural language query from a concrete, executable API path is a much more constrained and reliable task for an LLM than the reverse (generating correct API calls from a vague query), likely leading to higher-fidelity training data.\n\n2.  Contribution of a New Benchmark: The introduction of GOATBench, a human-verified benchmark for goal-oriented tasks, is a useful contribution to the community, which currently lacks diverse and challenging evaluation sets for this specific problem."}, "weaknesses": {"value": "1.  Outdated and Weak Baselines in Key Comparisons: The experimental setup is undermined by the use of outdated models and weak baselines in key comparative tables.\n    * In Table 2, the comparisons are against text-davinci-003 (a 2022 model) and open-source models like Llama2-13B and Vicuna-13B. These are not competitive backbones for a paper dated late 2025.\n    * Similarly, Table 3's baselines (Alpaca-7B, Llama-7B) are obsolete.\n    * The paper lacks a crucial comparison: training a model using data generated by another framework (like ToolFlow) and evaluating it on GOATBench, which would be a true test of GOAT's data generation superiority.\n    \n2.  Limited Methodological Novelty: The paper's core pipeline (build a dependency graph, filter it, sample paths, and generate data) is not new. The related work section and Table 1 already cite several highly similar, contemporaneous works (e.g., ToolFlow, Magnet, ToolDial) that also use graph-based methods to synthesize agent data. The 3-stage filtering pipeline (SBERT -> LLM check -> Execution) is a pragmatic engineering workflow, not a fundamental research contribution. The \"call-first\" strategy is also a known approach. The paper's primary contribution seems to be the application of this existing template to single-turn \"goal-oriented\" queries, which feels incremental.\n  \n3. The author didn't open-source GOATBench."}, "questions": {"value": "Please solve the weakness provided."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "00v5D69eTB", "forum": "iQwMr0tuJC", "replyto": "iQwMr0tuJC", "signatures": ["ICLR.cc/2026/Conference/Submission8864/Reviewer_Gkbm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8864/Reviewer_Gkbm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761544876065, "cdate": 1761544876065, "tmdate": 1762920627953, "mdate": 1762920627953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GOAT (Goal-Oriented Agent with Tools), a human annotation-free training framework designed to enhance the capability of open-source large language models (LLMs) on goal-oriented tool-use tasks. In such tasks, the model must autonomously decompose a high-level user goal, plan a multi-step API call chain, reason about inter-API parameter dependencies, and generate a final natural-language response."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The work targets the realistic and highly challenging setting of goal-oriented tool use, clearly identifying the key bottleneck for open-source models: the lack of training data for multi-step, interdependent API calls. This addresses a clear practical need.\n- GOAT-trained agents consistently outperform zero-shot and existing fine-tuned baselines across multiple benchmarks, including RestBench, API-Bank, and the newly introduced GOATBench.\n- The paper provides detailed prompt templates, hyperparameters, and data examples in the appendix, significantly supporting reproducibility."}, "weaknesses": {"value": "- The method assumes that API documentation contains clear natural language descriptions of parameters and outputs. However, in practice, many real-world APIs—especially internal or niche services—have poor-quality, incomplete, or unstructured documentation. Under such conditions, the API dependency graph construction would likely fail. The authors do not evaluate robustness under low-quality or unstructured documentation.\n- The framework supports only DAG-structured API sequences with up to 4 nodes, and cannot handle cyclic dependencies, conditional branching (e.g., if-else), or error recovery. Moreover, the inference process follows a static plan-then-execute paradigm and does not integrate iterative reasoning (e.g., ReAct-style reflection) or mechanisms for handling API call failures.\n- The three-stage filtering pipeline—especially the API call execution validation step—involves numerous real API invocations and LLM inferences, which could incur significant time and monetary costs when scaling to large API sets.\n- The definition of “goal-oriented” is ambiguous, and the boundary with multi-step instruction tasks is unclear. For example, generated queries like *“Can you help me find a hotel near the Flixbus stations in Paris?”* already imply a task structure (first locate stations, then find hotels), resembling implicit multi-step instructions. The distinction from prior work like API-Bank may thus reflect only a difference in phrasing granularity, rather than a fundamental innovation."}, "questions": {"value": "- Is the superiority of the “call-first” strategy empirically validated? The authors claim this approach avoids the self-reinforcing bias of instruction-first methods, but no ablation or comparative experiment is provided (e.g., training on instruction-first vs. call-first data using the same APIs and model).\n- GOATBench’s “unseen” split only involves unseen tool compositions within the same domains (finance, food, entertainment, travel). Can the framework generalize to entirely new domains (e.g., healthcare or legal APIs) that were absent during training?\n- Are the retriever (SBERT) and LLM (LoRA) jointly fine-tuned end-to-end, or trained separately? If trained in separate stages, could error propagation (e.g., incorrect API retrieval leading to failed planning) undermine overall performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PmQwlIRVZ6", "forum": "iQwMr0tuJC", "replyto": "iQwMr0tuJC", "signatures": ["ICLR.cc/2026/Conference/Submission8864/Reviewer_Bw8H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8864/Reviewer_Bw8H"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761708566133, "cdate": 1761708566133, "tmdate": 1762920627478, "mdate": 1762920627478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limitations of large language model (LLM) agents in handling goal-oriented tool-use tasks—specifically, the lack of annotated training data and poor performance of open-source models. The authors propose GOAT, a human-annotation-free training framework that automatically constructs synthetic datasets for goal-oriented API execution tasks from API documents. GOAT first builds a refined API dependency graph via a three-stage filtering pipeline (embedding similarity, LLM reasoning, and real API execution), then samples connected subgraphs to generate task samples (including user queries, interdependent API sequences, and final responses). Additionally, the authors introduce GOATBench, a new benchmark for goal-oriented tasks. Experiments show that GOAT-trained open-source models (e.g., Llama3-8B) achieve state-of-the-art performance on RestBench, API-Bank, and GOATBench, with some metrics even approaching closed-source models like text-davinci-003. The core contributions include: (1) an automatic data generation pipeline for goal-oriented tasks; (2) consistent performance gains across diverse LLMs and benchmarks; (3) the new GOATBench to facilitate future evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**\nThis work demonstrates originality in two folds: (1) the authors proposes to generate training data of tool using sequences based on a refined API dependency Graph. The graph construction consists of three stages of filtering which ensures the correct dependencies in the graph. (2) GOAT achieves comparable performance with closed-source models in tool use by finetuning small-scale open-source models with synthetic data. \n\n**Quality & Clarity**\nThe framework is well-structured, with clear mathematical and procedural descriptions for the main components including API dependency Graph construction, Goal-Oriented API Execution Data Construction. Experiments cover three benchmarks (RestBench, API-Bank, GOATBench) and six LLMs, with both in-domain and out-of-domain evaluations are included. Examples on the synthetic dependency graph and prompt designs details are adequately illustrated in appendices.  \n\n**Significance**\nThis work addresses a critical and practical problem —building cost-effective tool-use agents. The proposed method could enable adaptation of LLM agents to domain-specific APIs (e.g., financial, travel) at low cost without human annotations."}, "weaknesses": {"value": "1. As for the API Dependency Graph construction, unclear about the accuracy of the constructed graph node and edges since the authors proposed to enhance the correctness of the dependency by several strategies. Quantitative analysis on the correctness and noise of dependency graph is expected. \n\n2. The \"call-first\" strategy fills the API with plausible value at each filed as introduced in Section 3.1.3. However, enumerating all plausible values for every field of each API would constitute a huge mount of data sets. The authors used all the possible data points or they just select/utilize a small portion? There are no detailed discussions on this detail and no experiments to exam how does the selection influence the overall performance.\n\n3. There could be obvious discrepancy between the synthetic training data and the real-world tool use cases. Connected subgraphs are collected to form the synthetic training data as introduced in Section 3.1, but in practice there could be tool calling trajectory on a subgraph with much more nodes (5+ steps v.s. 4 API nodes in this work) and even more some query could involve multiple subgraphs.   \n\n4. Lack of comparison with recent closed-source models like GPT-4o or Claude 4 sonnet. Given that GPT-4o has strong zero-shot tool-use capabilities, omitting this comparison weakens the claim that GOAT-trained open-source models are \"competitive with closed-source systems.\"\n\n5. Missing technical details such as the cost of API calls, number of training data points for LLM fine-tuning and number of query-document pairs for SBERT training.\n\n6. Section 3.1.3 seems like discussion on related works, then it would be better to move this paragraph to section 2."}, "questions": {"value": "Several questions and concerns are raised in \"Weaknesses\" part. I would be willing to change my recommendation according to the authors' response."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yRkJhuV0PK", "forum": "iQwMr0tuJC", "replyto": "iQwMr0tuJC", "signatures": ["ICLR.cc/2026/Conference/Submission8864/Reviewer_4MzE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8864/Reviewer_4MzE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903997566, "cdate": 1761903997566, "tmdate": 1762920627056, "mdate": 1762920627056, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GOAT, a human annotation-free training framework for large language model (LLM) agents operating in goal-oriented tool-use scenarios, specifically for planning and executing interdependent API calls given only API documentation.  The approach consists of automatically generating synthetic datasets by parsing API docs, constructing and refining API dependency graphs, sampling realistic interdependent API task sequences, and fine-tuning LLM agents and retrievers on these synthetic tasks.  The paper introduces a new benchmark, GOATBench, and empirically demonstrates that models trained with GOAT achieve strong, often state-of-the-art, performance on multiple goal-oriented benchmarks, sometimes surpassing closed-source models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes a comprehensive, multi-stage, and meticulous automatic data generation method for constructing goal-oriented API execution datasets from unlabeled API documentation. The entire process is carefully decomposed into multiple stages—embedding-based similarity filtering, LLM semantic verification, and real API call execution—significantly improving the reliability of the dependency graph while maintaining computational feasibility.\n2. A novel benchmark is proposed: GOATBench is a human-validated, non-trivial benchmark set for goal-oriented tool use, covering multiple domains, and specifically designed to test the generalization ability of models on combinations of seen and unseen APIs."}, "weaknesses": {"value": "1. Additional scaling experiments could be included, and all current experiments appear to have been run only once without reporting standard deviations or confidence intervals, which limits statistical reliability.\n2. Although GOATBench is described as a comprehensive goal-oriented benchmark, its construction pipeline is largely reused from the training process, raising potential risks of data leakage or overfitting to generation biases, particularly for the “seen” API compositions.\n3. The introduction of GOATBench is a valuable contribution, and Appendix D provides useful implementation details. However, the paper does not sufficiently describe the data characteristics and distribution, nor does it relate GOATBench to existing benchmark efforts in this area. The authors are encouraged to enrich Appendix D with a more detailed comparison and statistical summary, referencing representative benchmark papers for context."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HpfkrlYZT6", "forum": "iQwMr0tuJC", "replyto": "iQwMr0tuJC", "signatures": ["ICLR.cc/2026/Conference/Submission8864/Reviewer_e8gR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8864/Reviewer_e8gR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931269139, "cdate": 1761931269139, "tmdate": 1762920626601, "mdate": 1762920626601, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}