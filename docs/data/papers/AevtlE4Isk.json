{"id": "AevtlE4Isk", "number": 10725, "cdate": 1758180485226, "mdate": 1759897633333, "content": {"title": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels", "abstract": "Open-Set Domain Generalization (OSDG) aims to enable deep learning models to recognize unseen categories in new domains, which is crucial for real-world applications. Label noise hinders open-set domain generalization by corrupting source-domain knowledge, making it harder to recognize known classes and reject unseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL) using hyperbolic prototype-guided meta-learning, they struggle to bridge domain gaps, especially with limited clean labeled data. In this paper, we propose Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first introduce an unsupervised two-stage evidential loss clustering method to promote label reliability awareness. Then, we propose a residual flow matching mechanism that models structured domain- and category-conditioned residuals, enabling diverse and uncertainty-aware transfer paths beyond interpolation-based augmentation. During this meta-learning process, the model is optimized such that the update direction on the clean set maximizes the loss decrease on the noisy set, using pseudo labels derived from the most confident predicted class for supervision. Experimental results show that EReLiFM outperforms existing methods on OSDG-NL, achieving state-of-the-art performance. The source code is available at https://anonymous.4open.science/r/ERELIFM-CBCB/.", "tldr": "", "keywords": ["Open-Set Domain Generalization", "Label Noise Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d0543ceee31d20ce31623ccc94e3fc5e5b844abc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses Open-Set Domain Generalization under Noisy Labels (OSDG-NL), where models must recognize unseen categories in new domains while training data contains label noise. The authors propose EReLiFM, which consists of three main components: (1) Unsupervised Two-Stage Evidential Loss Clustering (UTS-ELC) to separate clean from noisy samples using evidential loss trajectories, (2) Domain and Category Conditioned Residual Flow Matching (DC-CRFM) to generate diverse transfer paths across domains and categories, and (3) a meta-learning framework that trains on clean/augmented data and cautiously incorporates noisy samples with pseudo-labels. Experiments on PACS, DigitsDG, and TerraINC show improvements over the baseline HyProMeta."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Important problem**: OSDG-NL is a relevant and challenging problem combining multiple realistic constraints.\n\n2. **Comprehensive experiments**: The paper evaluates on multiple datasets, noise types (symmetric/asymmetric), and noise ratios (20%/50%/80%).\n\n3. **Consistent improvements**: Results show improvements across most settings, though statistical significance is unclear.\n\n4. **Thorough ablations**: Table 7 provides ablations of major components, though clarity could be improved."}, "weaknesses": {"value": "1. **Weak theoretical justification**: Why should evidential loss trajectories be better than standard loss for clean/noisy separation? The paper provides intuition but no theoretical analysis or proof.\n\n2. **Computational overhead**: Adding DiT (129.6M params) during training significantly increases computational cost. The paper doesn't analyze whether simpler augmentation strategies could achieve similar results.\n\n3. **Failure mode analysis**: What happens when UTS-ELC fails (as suggested by 52-56% accuracy in Table 17)? How does error propagate through the pipeline?\n\n4. **Limited domain diversity**: PACS has only 4 domains with similar image statistics. More diverse domains (e.g., natural images → medical images) would better validate the approach.\n\n5. **Hyperparameter sensitivity**: No analysis of sensitivity to key hyperparameters (N_e, number of GMM components, meta-learning rates, etc.).\n\n6. **Comparison fairness**: Some baselines (TCL, NPN, BadLabel) are not designed for OSDG, making comparisons less meaningful. More fair comparisons would be against other meta-learning or domain generalization methods adapted for noisy labels."}, "questions": {"value": "1. **UTS-ELC failure modes**: Given the low separation accuracy (~55%) under high noise, how does the method remain robust? Can you provide analysis of what happens when clean samples are misclassified as noisy?\n\n2. **Flow matching vs. MixUp**: Can you provide theoretical or empirical evidence that learning residuals via flow matching provides fundamentally different augmentations than MixUp? Visualizations of generated samples would help.\n\n3. **Ablation details**: Please clarify the exact difference between \"w/o UTS-ELC in RFM\" and \"w/ UTS-LC in RFM\" in Table 7.\n\n4. **Cross-dataset generalization**: How does a model trained on PACS with DC-CRFM perform when directly tested on DigitsDG without retraining?\n\n5. **Hyperparameter selection**: How were hyperparameters (especially N_e=10) chosen? Is this consistent across datasets and noise levels?\n\n6. **Statistical significance**: Can you provide error bars or significance tests for the main results?\n\n7. **Pseudo-label quality**: What is the accuracy of pseudo-labels y_pseudo in the meta-test stage? How does this correlate with final performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6ixG4GiNeu", "forum": "AevtlE4Isk", "replyto": "AevtlE4Isk", "signatures": ["ICLR.cc/2026/Conference/Submission10725/Reviewer_Xk5Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10725/Reviewer_Xk5Q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761207574855, "cdate": 1761207574855, "tmdate": 1762921954177, "mdate": 1762921954177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of open-set domain generalization under noisy labels. The proposed method consists of two modules: denoising (dataset separation) and training. In the denoising stage, the authors use Evidential Learning to estimate the uncertainty of samples, then apply a clustering algorithm to divide them into a clean set (low uncertainty clusters) and a noisy set (high uncertainty clusters). Training is conducted within a meta-learning framework, where the meta-train data come from the original and flow-model-augmented clean set, while the meta-test data are derived from the noisy set with pseudo-labels. Experimental results demonstrate the effectiveness of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clear and easy to understand.\n2. The application of Evidential Learning, though rarely seen in open-set recognition，seems reasonable.\n3. Experimental results demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The choice to use the clean set for meta-training and the noisy set for meta-testing appears odd. Performance gains can often be achieved through various tuned meta-learning strategies—whether traditional sampling from the same distribution or MEDIC’s domain-class sampling. Therefore, the authors should provide stronger justification that their approach offers unique advantages. Moreover, the meta-learning experiments should include comparisons across different meta-learning strategies, rather than only ablation studies (e.g., removing the pseudo-labeling module), since it is somewhat obvious that pseudo-labeling would help.\n2. The proposed dataset separation strategy always produces a clean set and a noisy set. However, on a completely clean dataset, this could have adverse effects: if the noisy set is small, there would be insufficient meta-test data; if it is large, many correct samples could be incorrectly assigned pseudo-labels.\n3. The paper repeatedly emphasizes the advantage of the flow model over Mixup interpolation, yet the evidence is limited to accuracy comparisons. Given the emphasis placed on this claim, more qualitative or intuitive analyses are needed to substantiate it. Furthermore, Mixup is not the only data augmentation approach worth comparing.\n4. The studies cited in lines 104–105 are flow matching, and some studies referenced in lines 386–388 are close set domain generalization. They are not open set domain generalization."}, "questions": {"value": "1. Please see weaknesses.\n2. What is the motivation for studying open set domain generalization and noisy labels simultaneously? Do the authors assume that either open set domain generalization or domain generalization under noisy labels has already been well-studied?\n3. How is y_a chosen in the algorithm?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qM0EURXhbc", "forum": "AevtlE4Isk", "replyto": "AevtlE4Isk", "signatures": ["ICLR.cc/2026/Conference/Submission10725/Reviewer_FcXz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10725/Reviewer_FcXz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972174667, "cdate": 1761972174667, "tmdate": 1762921953809, "mdate": 1762921953809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EReLiFM, a three-stage pipeline for Open-Set Domain Generalization (OSDG) under noisy labels. The approach: (i) separates clean from noisy samples via UTS-ELC (Unsupervised Two-Stage Evidential Loss Clustering), (ii) enriches the training data using DC-CRFM (Domain- and Category-Conditioned Residual Flow Matching), and (iii) optimizes a meta-learning objective that decouples clean and noisy supervision. Experiments demonstrate strong performance on PACS, DigitsDG and TerraINC datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Well-motivated pipeline. The experimental results demonstrate substantial improvements over existing baselines across multiple benchmarks."}, "weaknesses": {"value": "1. The presentation is kind of poor. Instead of spending a whole page (i.e., page 3) presenting the motivation for all components, I think it is better to present a high-level framework, e.g.:\n\n    - separates clean from noisy samples\n    - enriches the training data\n    - optimizes a meta-learning objective that decouples clean and noisy supervision\n\n   Then, within each subsequent section for individual components, describe the specific motivation and highlight key differences from previous works. This structure may help readers grasp the overall strategy before exploring component-level details.\n\n2. Meta-learning step relies heavily on plain text description. Provide explicit mathematical formulations showing the inner/outer loop objectives, gradient flows, and how clean vs. noisy samples are weighted.\n\n3. Since the proposed method incorporates many existing techniques (Finch clustering, GMM, residual flow matching), adding a Background/Preliminaries subsection that concisely explains these foundational methods would make the paper accessible to readers less familiar with these techniques.\n\n4. Experiments: Rather than relying solely on percentage improvements (which readers can see in the tables), consider including:\n\n    - t-SNE or UMAP plots demonstrating UTS-ELC's ability to separate clean from noisy samples\n    - Sample quality comparisons or interpolation visualizations showing DC-CRFM-generated data quality and diversity\n\n5. Acronym introduction. UTS-ELC and DC-CRFM are used before being introduced (lines 64 and 66)."}, "questions": {"value": "Please see the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GlTEBQakkX", "forum": "AevtlE4Isk", "replyto": "AevtlE4Isk", "signatures": ["ICLR.cc/2026/Conference/Submission10725/Reviewer_WyRZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10725/Reviewer_WyRZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983224237, "cdate": 1761983224237, "tmdate": 1762921953384, "mdate": 1762921953384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper attempts to tackle the problem of Open-Set Domain Generalization under Noisy Labels (OSDG-NL). The authors proposed an approach based on evidential loss and residual flow, named Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). EReLiFM includes two modules, named UTS-ELC and DC-CRFM, respectively. UTS-ELC promotes better clean/noise separation across domains. DC-CRFM could augment more data with structured residuals. Subsequently, these two modules are integrated within a meta-learning framework. Experiments demonstrates that EReLiFM could enhance the performance of noise diagnosis and data augment for OSDG-NL."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "[+] The detail of the method and experiment is well described.\n\n[+] The related work is detailed.\n\n[+] The experiments conducted are extensive."}, "weaknesses": {"value": "Major weakness:\n\n[-] The authors propose UTS-ELC to better separate clean and noisy samples using evidential loss. Please clarify the mechanism and explain its advantage in achieving more reliable separation compared to state-of-the-art methods such as HyProMeta. In addition, please provide visualizations or other metrics to demonstrate this claimed advantage.\n\n[-] The authors propose DC-CRFM to expand clean data with structured diversity. However, there is a lack of visual results illustrating the advantage of DC-CRFM in enhancing diversity compared to existing augmentation methods (e.g., MixStyle [1] and FACT [2]).\n\n[-] The benchmarks used appear limited. Can the proposed approach consistently achieve better performance on commonly used domain generalization datasets such as OfficeHome and VLCS? \n\n[1]. Domain Generalization with MixStyle. ICLR, 2020.\n\n[2]. A Fourier-based Framework for Domain Generalization. CVPR, 2021.\n\nMinor weakness:\n\n[-] The manuscript requires further refinement in details to improve readability. For instance, \"DirectFM\" in Table 7 is not defined."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "XEFXiDby6t", "forum": "AevtlE4Isk", "replyto": "AevtlE4Isk", "signatures": ["ICLR.cc/2026/Conference/Submission10725/Reviewer_HVGE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10725/Reviewer_HVGE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059895961, "cdate": 1762059895961, "tmdate": 1762921952886, "mdate": 1762921952886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel reliability-aware meta-learning framework called EReLiFM,  that combines evidential loss–based clean/noisy data separation with domain- and category-conditioned residual flow matching. It aims to improve open-set domain generalization under noisy labels by filtering clean samples, expanding them through structured residual flows, and recycling noisy data with evidential pseudo-labeling. Experiments on DG benchmarks show that it achieves SOTA performance, outperforming prior methods across multiple noise settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a novel integration of evidential uncertainty modelling and residual flow matching, effectively addressing noisy labels for open-set domain generalization task.\n\n2. It has proposes a novel framework, EReLiFM that demonstrates strong and consistent performance improvements across multiple benchmarks, showing robustness to different noise levels and backbone architectures."}, "weaknesses": {"value": "1. See questions\n2. Below papers are needed to be cited.\n\n[1] Towards Multimodal Open-Set Domain Generalization and Adaptation through Self-supervision, ECCV 2024\n[2] OSLoPrompt: Bridging Low-Supervision Challenges and Open-Set Domain Generalization in CLIP, CVPR 2025"}, "questions": {"value": "(1) Why are the evidential loss trajectories preferred over the feature-space embeddings for clean/noisy sample separation?\n\n(2) What is the reason behind separating clean data for meta-train and noisy data for meta-test rather than mixing them?\n\n(3) Is it possible to check the sensitivity of separating clean and noisy samples with other unsupervised clustering methods like K-means and DBSCAN ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PL2kBeGMfe", "forum": "AevtlE4Isk", "replyto": "AevtlE4Isk", "signatures": ["ICLR.cc/2026/Conference/Submission10725/Reviewer_UAWs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10725/Reviewer_UAWs"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission10725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762155534495, "cdate": 1762155534495, "tmdate": 1762921952388, "mdate": 1762921952388, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}