{"id": "5AuN6RD072", "number": 14062, "cdate": 1758227841986, "mdate": 1759897392796, "content": {"title": "Sparse Autoencoders Reveal Interpretable Features in Single-Cell Foundation Models", "abstract": "Single-cell foundation models (scFMs) hold promise for applications in cell type annotation and data integration, but their internal mechanisms remain poorly understood. We investigate the structure of these models by training sparse autoencoders (SAEs) on the hidden representations of two widely used scFMs, scGPT and scFoundation. \nThe learned features reveal diverse and complex biological and technical signals, which emerge even in pre-trained models.\nWe also observe that the encoding of this information differs between scFMs with distinct training protocols and architectures. Further, we find that while many features capture the information about cell types across several studies, they often fall short of unifying it into a single generalized representation. Finally, by intervening on SAE features, we can reduce unwanted technical effects while steering model outputs to preserve the core biological signal. These findings provide a path toward more interpretable and controllable single-cell foundation models.", "tldr": "We use sparse autoencoders to interpret single-cell foundation models, revealing that they capture diverse biological signals but fragment cell type information, and demonstrate that targeted feature interventions can improve batch integration.", "keywords": ["single-cell foundation models", "sparse autoencoders", "interpretability", "steering"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/655d42365f7d161d8e844b25f61e2ca3ab069c12.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes sparse autoencoders (SAEs) to learn sparse features from layers of two single-cell foundation models (scFMs), specifically scGPT and scFoundation. The SAEs are tested on multiple single-cell datasets, showing improved data integration performance at hand of the scIB metrics compared to scFMs without SAEs-steering."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper addresses a relevant topic: The reliability issue of single-cell foundation models and the assessment which biological concepts are being represented by large models. Applying SAEs to such a problem is a reasonable approach and to my knowledge new."}, "weaknesses": {"value": "My two main concerns are (1) strong unsubstantiated claims and (2) formally unclean statements. \n\n(1) The paper suggests that SAEs learns biologically meaningful concepts, specifically that 26 cell type, 2 batch features, 29 “biological processes”, 7 gene sets, 36 uncategorized concepts. However, these claims are not explained. Design choices such as “We used layer 10 (out of 12 total layers) for feature analysis, as we expected features at this depth to be less abstract and more interpretable than those in earlier layers.” remain unmotivated and unstudied. Other choices seem engineered and not meaningful, e.g., “applied thresholds to classify cells as positive or negative for each feature”. Overall, the sensitive question which concepts are learned at which positions in large, complex foundation models, is not answered reliably.\n\n(2) The paper contains several unclean passages which warrant further polishing. For example, distinguishing “drug response prediction” and “perturbation response prediction”, “Despite their growing utility in single-cell analysis, many single-cell foundation models remain difficult to interpret” why should there be a relationship between utility and interpretability? “They tend to be outperformed by linear models in [...]” this strongly simplifies an active debate in the field, while it is true that simple models have outperformed scFMs in certain settings, other settings seem to show scFMs outperforming linear models. There are further such unclear passages, overall the submission lacks a quality of claims.\n\nOverall, the paper proposes a feature selection / disentanglement method without proper comparison to the breadth of existing methods addressing this challenge for single-cell data. The claims are strong and unsubstantiated and the paper contains several unclean passages."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "094d386J1Y", "forum": "5AuN6RD072", "replyto": "5AuN6RD072", "signatures": ["ICLR.cc/2026/Conference/Submission14062/Reviewer_mVCw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14062/Reviewer_mVCw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731045626, "cdate": 1761731045626, "tmdate": 1762924544406, "mdate": 1762924544406, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for interpretating single-cell foundation models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The idea of interpretating single-cell foundation models is interesting."}, "weaknesses": {"value": "Although the authors try to interpret single-cell foundation models, they lack several important details in the method development as well as the result presentation. Moreover, their result is also not very reliable. I have several questions that might help authors improve the manuscript.\n\n1. The motivation is not very straightforward and meaningful. Several benchmarks in papers have shown that this kind of Foundation model is not powerful enough, and the motivation for interpreting them cannot improve their performance. Therefore, we do not have an urgency to use an interpretable method to extract features and conduct biological reasoning based on the features. It seems that these features are not reliable. How to defend your discovery if the models are not good?\n\n2. It seems that the authors simply propose an over-parameterized auto-encoder (https://www.pnas.org/doi/10.1073/pnas.2005013117, https://www.nature.com/articles/s41467-022-35233-1), which has been widely studied in single-cell data analysis. Therefore, what is the novel setting here? \n\n3. The results in Table 2 are confusing. What is the contribution of the proposed auto-encoder for performing batch effect correction? Why do the authors only include scVI but not other baselines here? scVI is not set for over-parameterization, and the batch effect correction with only a single-cell foundation model is also not interesting.\n\n4. Followed by Q3, I have a new question. We must utilize a new model to interpret the results. Can we just utilize some general explainability method, such as SHAP or IG? Will the results become different or not? \n\n5. Why do the authors only have baselines for batch effect correction, but not cell-type annotation? If the baseline method performs better in the given task and focuses on different features, how can we trust the features from scFMs?\n\n6. The authors only investigate scGPT and scFoundation, which misses much of the related work. The authors should also investigate other models, such as Geneformer and UCE, to get general conclusions. Also, how to ensure that the testing data are not trained with these foundation models?"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "NXeo6WYNaF", "forum": "5AuN6RD072", "replyto": "5AuN6RD072", "signatures": ["ICLR.cc/2026/Conference/Submission14062/Reviewer_9wXY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14062/Reviewer_9wXY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761784362903, "cdate": 1761784362903, "tmdate": 1762924543815, "mdate": 1762924543815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper applies sparse autoencoders (SAEs) to intermediate token activations of two single-cell foundation models (scGPT, scFoundation) to extract interpretable features that reflect biological and technical signals. The authors\n (i) report gene-specific and cell-specific features, \n(ii) show that encoding is different across model architectures/training, (iii) argue many cell-type concepts do not unify across studies, and (iv) introduce “feature steering” (by clamping batch-correlated SAE features) to reduce batch effects. while largely preserving biological structure. They introduce also an Embedding Recovery Score as a proxy for SAE reconstruction utility and they benchmark steering against baselines (PCA, scVI) on Pancreas, Lung, and Immune datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- I like the new interpretability angle, through probing token-level residual stream features (not just final cell embeddings) and revealing gene-family/process concepts (e.g., ribosomal, HLA, cell cycle).\n- The paper performs a cross-model comparison by ontrasting scGPT vs scFoundation and ties differences to design choices (e.g., expression binning vs continuous values, masking/downsampling).\n- The authors also provide some relaxed causal evidence via steering. particularly by deactivating batch-associated features showing that improves batch-integration metrics, especially for fine-tuned scGPT, and sometimes outperforms scGPT’s DAR objective.\n- The paper is clearly written."}, "weaknesses": {"value": "- While steering helps, scVI still leads on some totals; steering requires identifying high-AMI features and setting an arbitrary clamp value (−2). There’s little guidance on selecting the number of features, preventing over-steering, or ensuring invariance .\n- The “lack of unified cell-type concepts across studies” may partly reflect SAE dictionary size/architecture, not necessarily the underlying scFM representations, and thus more exhaustive sensitivity analysis would be usefu ."}, "questions": {"value": "-How well does Embedding Recovery Score track downstream task quality (annotation accuracy, perturbation prediction) across datasets and SAE configs? Any Spearman/Pearson correlations to established metrics?\n\n-Why layer 10 for analysis and layer 5 for steering? Please include a layer-by-layer sweep interpretability .\n\n-How sensitive are results to BatchTopK’s k and to the clamp magnitude (−2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VdrfjeAjJZ", "forum": "5AuN6RD072", "replyto": "5AuN6RD072", "signatures": ["ICLR.cc/2026/Conference/Submission14062/Reviewer_sFEh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14062/Reviewer_sFEh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942579053, "cdate": 1761942579053, "tmdate": 1762924543399, "mdate": 1762924543399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper trains sparse autoencoders (SAEs) on intermediate activations of two single-cell foundation models (scGPT and scFoundation) and shows the SAEs uncover interpretable, sparsely activated features that map to gene families, biological processes (e.g., cell cycle, immune pathways), cell types, and even technical artifacts like sequencing protocols. It finds the two models encode information differently (e.g., scGPT’s expression binning yields stronger high-expression and more diverse cell-type features), and many cell-type features don’t fully generalize across studies, suggesting scFMs often learn study-specific rather than unified concepts. By “steering” batch-correlated SAE features (clamping them during inference), the authors causally alter model behavior to reduce batch effects while largely preserving biology"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. It is interesting to see that SAEs can recover biologically and technically meaningful concepts (cell types, pathways, sequencing protocols) from scGPT/scFoundation internals. \n\n2. “Steering” batch-correlated features improves batch correction while largely preserving biology (e.g., pancreas total score 0.69 for steered fine-tuned scGPT vs 0.65 for DAR).\n\n3. The paper explains encoding differences (e.g., scGPT binning  -> stronger high-expression & more diverse cell-type features)."}, "weaknesses": {"value": "1. steering isn’t yet a practical batch-correction method. scVI still wins on integration totals.\n\n2. Other State-of-art FM Models like geneformer, cellPLM, Tabula are missing\nTabula: https://openreview.net/forum?id=Vk2sfKAdeu&referrer=%5Bthe%20profile%20of%20Jiliang%20Tang%5D(%2Fprofile%3Fid%3D~Jiliang_Tang1)"}, "questions": {"value": "1. How about other Models like geneformer, cellPLM, Tabula\n\n2. Does the parameter size of scFoundation and scGPT impacts the gene embeddings? \nscFoundation: 100 million parameters\nscGPT: 53 million parameters"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kpHIJqZuuh", "forum": "5AuN6RD072", "replyto": "5AuN6RD072", "signatures": ["ICLR.cc/2026/Conference/Submission14062/Reviewer_JLT6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14062/Reviewer_JLT6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762212466100, "cdate": 1762212466100, "tmdate": 1762924543021, "mdate": 1762924543021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}