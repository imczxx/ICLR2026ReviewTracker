{"id": "20PqWPr4aL", "number": 19478, "cdate": 1758296584084, "mdate": 1759897036772, "content": {"title": "Learning Generalized Hamiltonian Dynamics with Stability from Noisy Trajectory Data", "abstract": "We propose a unified framework for learning generalized Hamiltonian dynamics from noisy, sparse phase-space observations via variational Bayesian inference. Modeling conservative, dissipative, and port-Hamiltonian regimes with a single architecture is challenging because each induces distinct phase-space behavior from similar initial energies. To address this, we extend sparse symplectic Gaussian processes with random Fourier features to build a probabilistic surrogate of the Hamiltonian landscape. Our approach supports all three regimes through a generalized formulation of Hamiltonian dynamics. To ensure physical correctness and stability, we softly enforce conservation and Lyapunov-style constraints. With this relaxation, we recast the original constrained optimization problem as a hyperparameter-balanced multi-term loss trained end-to-end. Experiments on standard Hamiltonian benchmarks show improved long-horizon forecasting, stronger short-term prediction accuracy, and higher physics conformity compared with state-of-the-art methods.", "tldr": "We present a method of probabilistic learning of different classes of Hamiltonian dynamics using a balanced multi-term loss function for conservation and stability.", "keywords": ["Hamiltonian dynamics", "machine learning", "Gaussian processes", "stability"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/770cbc3e2b705cda89f4c315964ed97ea4fc6daf.pdf", "supplementary_material": "/attachment/e2ce2a93bbb9b23b47ae9f72e1db8a06c01ddeee.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a Gaussian process–based learning algorithm for generalized Hamiltonian systems. The method incorporates three soft constraints—on energy conservation, volume preservation, and Lyapunov stability—to better capture the physical structure and stability properties of the system. Experiments on multiple dynamical systems show that the proposed approach achieves superior accuracy and robustness compared to existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The authors propose a learning algorithm based on Gaussian processes for the generalized Hamilton systems and introduce three soft constraints to make learning more effective. This aspect appears to be novel.\n- The authors verify the effectiveness of the proposed method in multiple dynamical systems, demonstrating its robustness particularly in long-term prediction."}, "weaknesses": {"value": "- The proposed learning process merely adds three regularization terms representing physical constraints to the conventional SSGP method, and thus appears to offer no significant technical contribution.\n- The experimental results are encouraging, but a more thorough analysis is required, including consideration of uncertainties."}, "questions": {"value": "- The motivation for introducing three soft constraints needs to be clarified. SSGP is learned to follow Hamilton's equations. Since SSGP  represent Hamilton vector fields, they guarantee at least energy and volume conservation. Therefore, soft constraints on these properties (at least energy and volume) may not be necessary when modeling vector fields. On the other hand, considering learning from trajectory data, cumulative errors due to numerical integration are introduced. Soft constraints may be effective in absorbing this error. Please add the above discussion to clarify the motivation for the proposal.\n- After learning, what values did the terms in equation (11) and the hyperparameters take?\n- One of the advantages of Gaussian processes is their ability to handle uncertainty, so it would be better to demonstrate their effectiveness in this regard through experiments.\n- Please define J and D."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8XUgQPtMBd", "forum": "20PqWPr4aL", "replyto": "20PqWPr4aL", "signatures": ["ICLR.cc/2026/Conference/Submission19478/Reviewer_piGu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19478/Reviewer_piGu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761536593549, "cdate": 1761536593549, "tmdate": 1762931387387, "mdate": 1762931387387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified and probabilistic framework for learning generalized Hamiltonian dynamics (conservative, dissipative, and port-Hamiltonian) from noisy and sparse trajectory data. The core of the method is to model the Hamiltonian function as a probabilistic surrogate using a sparse Gaussian Process approximated with Random Fourier Features (RFF). To ensure physical plausibility and improve long-term stability, the authors introduce a multi-term loss function that combines the standard evidence lower bound (ELBO) for data-fitting with soft regularization terms enforcing energy conservation, phase-space volume conservation, and Lyapunov-style stability. A key contribution is the use of a Gradient Descent-Ascent (GDA) algorithm to automatically balance the weights of these loss terms, treating it as a min-max optimization problem. Experiments on several benchmark Hamiltonian systems demonstrate that the proposed method achieves superior performance in both short-term accuracy and, most notably, long-horizon forecasting compared to state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Principled and Unified Framework: The paper presents a unified approach to a complex problem. By parameterizing the three distinct classes of Hamiltonian dynamics within a single RFF-based GP framework, the authors provide a systematic way to tackle a broad range of physical systems. The probabilistic nature of the model is well-justified and naturally handles the challenges of noisy and sparse observations.\n\n- Novel Automated Loss Balancing: The use of GDA to automatically learn the Lagrangian multipliers (λ) is a significant contribution. Balancing multiple, often competing, loss terms is a notoriously difficult hyperparameter tuning problem. The proposed min-max optimization framework offers a principled and automated solution, which enhances the method's practicality and robustness. This is a valuable technique that could be adopted in other multi-task or physics-informed learning settings.\n\n- Comprehensive Experimental Validation: The authors conduct a thorough empirical evaluation across all three classes of Hamiltonian systems. The comparison with strong baselines (HNN variants, SSGP) is fair and clearly highlights the benefits of the proposed method. The ablation studies on noise levels and individual loss components further strengthen the paper's claims and provide valuable insights into the model's behavior."}, "weaknesses": {"value": "- Scalability Concerns: While RFFs improve the scalability of GPs, the experiments are conducted on relatively low-dimensional systems (1D or 2D position spaces). It is unclear how the computational cost and performance of the method, particularly the GDA optimization, would scale to higher-dimensional phase spaces (e.g., many-body systems) or datasets with very long trajectories. A discussion on the computational complexity with respect to the phase space dimension d and the number of RFF features M would be beneficial.\n\n- Stability and Nuances of GDA: The GDA for min-max optimization can be notoriously tricky to train and may not always converge to a desirable equilibrium. The paper mentions this but could benefit from a more in-depth discussion. For instance, in Table 1, the \"Ours (Equal)\" variant sometimes slightly outperforms the \"Ours (GDA)\" variant. This raises a question about the stability and reliability of the GDA optimization. Is it sensitive to learning rates or initialization? When and why might a simpler weighting scheme be sufficient or even better?\n\n- Assumptions on D and F(t): The framework makes simplifying assumptions about the structure of the dissipation matrix D (diagonal, only affecting p) and the external force F(t) (also only affecting p). While reasonable for the chosen benchmarks, this limits the generality of the approach. A brief discussion on how the framework could be extended to handle more complex, unknown, or state-dependent dissipation and forcing structures would strengthen the paper."}, "questions": {"value": "- Regarding the GDA balancing: Could you comment on the training dynamics and stability of the GDA approach? As noted in the weaknesses, the equally-weighted version sometimes outperforms the GDA-balanced one in Table 1. Does this suggest that the GDA optimization is sometimes getting stuck in a suboptimal local minimum, or that for some tasks, a simpler balance is more effective?\n\n- Regarding the choice of constraints: The paper applies the same set of regularizers (Energy, Vol, Lyap) across all system types, though their physical meaning changes (e.g., energy is conserved in one case and dissipated in others). The implementation detail \"the conservative laws can be enforced by integrating the conservative part only\" is key. Could you elaborate on this in the main text? How exactly is L_Energy (Eq. 8) adapted for dissipative and port-Hamiltonian systems, where the total energy is not expected to be conserved? Is it applied only to the J∇H component of the flow?\n\n- Regarding the Lyapunov loss (L_Lyap, Eq. 10): The paper states that for Hamiltonian settings, you can take V=H and α=0. However, the loss term ReLU(d/dt H(x(t))) penalizes any increase in energy. For a port-Hamiltonian system with external energy input, the energy H is expected to increase. How is this apparent contradiction handled? Does the GDA mechanism learn to down-weight this loss term (λ_1 -> 0) in such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VtRLGnuczp", "forum": "20PqWPr4aL", "replyto": "20PqWPr4aL", "signatures": ["ICLR.cc/2026/Conference/Submission19478/Reviewer_nvZF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19478/Reviewer_nvZF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909684249, "cdate": 1761909684249, "tmdate": 1762931386839, "mdate": 1762931386839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors propose a probabilisitic framework for learning generalized Hamiltonian dynamics from noisy trajectory data. The method is based on symplectic Gaussian processes with random Fourier features and trained with variational Bayesian inference, where the training loss is augmented by regularizations for enforcing soft physical constraints such as energy conservation, volume conservation and Lyapunov stability and can be solved numerically via gradient descent-ascent (GDA). Experiments demonstrate that the method outperforms prior approaches on a few basic Hamiltonian systems including conservative, dissipative and externally-forced ones."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The learning of dissipative and externally forced Hamiltonian systems within a probabilistic framework is novel to my knowledge."}, "weaknesses": {"value": "1. The main novelty of the proposed method compared to prior works such as Tanaka et al. (2022) and Ross and Heinonen (2023) seems to lie in the several penalty terms for softly enforcing the respective physical constraints, together with a min-max formulation of the optimization problem for balancing the different loss terms. It is a bit limited for a publication in ICLR, in my opinion.\n\n2. Does the energy conservation constraint actually make sense when we consider dissipative and externally-forced Hamiltonian systems?\n\n3. My understanding of port-Hamiltonian systems is that they usually refer to interconnected networks of subsystems with force exchanges, which are different from what the authors consider in this paper. It may be clearer to name them as \"forced\" or \"externally-forced\" Hamiltonian systems instead.\n\n4. The presentation of the paper, including the quality of the figures, can be improved. The analysis of the experiment results is also rather limited compared to prior works such as Tanaka et al. (2022)."}, "questions": {"value": "See item 2 in the weakness section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CuKjvKw44K", "forum": "20PqWPr4aL", "replyto": "20PqWPr4aL", "signatures": ["ICLR.cc/2026/Conference/Submission19478/Reviewer_PVTK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19478/Reviewer_PVTK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944876851, "cdate": 1761944876851, "tmdate": 1762931386492, "mdate": 1762931386492, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Gaussian process framework for learning different kinds of non-conservative Hamiltonian systems. The main idea is to use a relaxed Hamiltonian framework, and control the model by regularisation towards conservation and stability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is sufficiently original by consider generalised Hamiltonian systems. However, the GP methodology is quite basic, and the overall Hamiltonian GP approach has already been established in earlier works.\n\nThe clarity of the paper is overall good, and the paper is easy to follow.\n\nThe results show superior performance over baselines, which is a good achievement."}, "weaknesses": {"value": "The math presentation could be improved. The ELBO and the joint distribution is quite oddly presented: the joint distribution has no connection between x_ij and x_0, or any connection between W and x. There is also no theta. I don't think this notation is sufficiently rigorous.\n\nThe paper oddly shows no system fits in the main paper, which makes it quite difficult to get a good intuition on what is happening, how much data is used, or what do the predictions look like. In appendix there are visualisations, which seems to show quite different picture from the tables. Figs 4-6 all show that the there is basically no difference between SSGP and the proposed method (!), and the GP methods make really strange and really strong error patterns. I suspect that there is something wrong in the implementation of this method, or there are some serious misidentification issues in these models. \n\nFinally, it's difficult to see in what ways the proposed method is significant. There is no \"real-world\" usecase, and all the experiments are small-dimensional simple systems that we probably could model better by conventional means."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KXkpPAyqh5", "forum": "20PqWPr4aL", "replyto": "20PqWPr4aL", "signatures": ["ICLR.cc/2026/Conference/Submission19478/Reviewer_iCCD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19478/Reviewer_iCCD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762465165284, "cdate": 1762465165284, "tmdate": 1762931386016, "mdate": 1762931386016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}