{"id": "6PzGc6bWPc", "number": 13978, "cdate": 1758226415617, "mdate": 1759897398791, "content": {"title": "Sensitivity Analysis for Diffusion Models", "abstract": "Training a diffusion model approximates a map from a data distribution $\\rho$ to the optimal score function $s_t$ for that distribution. Can we differentiate this map? If we could, then we could predict how the score, and ultimately the model's samples, would change under small perturbations to the training set before committing to costly retraining. We give a closed-form procedure for computing this map's directional derivatives, relying only on black-box access to a pre-trained score model and its derivatives with respect to its inputs. We extend this result to estimate the sensitivity of a diffusion model's samples to additive perturbations of its target measure, with runtime comparable to sampling from a diffusion model and computing log-likelihoods along the sample path. Our method is robust to numerical and approximation error, and the resulting sensitivities correlate with changes in an image diffusion modelâ€™s samples after retraining and fine-tuning.", "tldr": "We derive a tractable closed-form expression for a score function's sensitivity to perturbations to its target measure.", "keywords": ["diffusion models", "sensitivity analysis", "influence functions"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2fa8dbe1e2696591c68e74a71cbbcf55bb9965fe.pdf", "supplementary_material": "/attachment/988fd8214f0f08d642fab0631db4369143aff60f.zip"}, "replies": [{"content": {"summary": {"value": "This article introduces a method for computing the sensitivity of diffusion models, modeled as the directional derivative of both the learned scores and the generated samples. The computation requires only the pre-trained score estimator and its spatial derivatives. Experiments on synthetic and real-world datasets validate the method's effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Originality**: The core idea of quantifying the influence of training distribution perturbations is novel.\n\n- **Quality**: The motivation for the sensitivity calculation is well-justified, and the mathematical deductions are both clear and sound.\n\n- **Clarity**: The paper is well-structured; the theory is presented logically and is easy to follow.\n\n- **Significance**: Sensitivity analysis is highly significant for ensuring the safety and reliability of diffusion models in real-world applications."}, "weaknesses": {"value": "- The practical use of this sensitivity study is not well presented. \n- The numerical comparison is limited. In particular, the baseline method used for the real-world data experiments (from 2013) is outdated and does not convincingly demonstrate superiority over modern techniques.\n- Some descriptions are not necessary. For example:\n  - Equation 1, which formulates the optimal score, is not strongly correlated with the core content and could be removed to improve focus.\n  - In Sec. 3.3, there is no need to illustrate the reason for choosing $\\tilde{t}_{1} < t_{1}$ since it is not strongly correlated to the content. \n  - For explaining how to compute the perturbation in score and samples, an algorithm could be more illustrative than just sentences in Sec. 3.3 and Sec. 4.1."}, "questions": {"value": "- What is the application scenario of this study? How does it apply to the safety of deploying diffusion models?\n- In Figure 4, why does the first-order approximation seem to fail for $\\bar{\\eta} = 10^{-6}$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9vw17ze4hw", "forum": "6PzGc6bWPc", "replyto": "6PzGc6bWPc", "signatures": ["ICLR.cc/2026/Conference/Submission13978/Reviewer_xkKn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13978/Reviewer_xkKn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761670697988, "cdate": 1761670697988, "tmdate": 1762924477377, "mdate": 1762924477377, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work derives closed-form directional derivatives of score functions w.r.t. data distributions given another external distribution, which characterizes certain input sensitivity of diffusion models. The results are also extended to the solution path case (sensitivity ODEs) when sampling (with probability flow ODEs or certain SDEs). This helps to predict changes in model samples after retraining and fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written and clearly organized, which is fluent to read. \n2. The sensitivity problem of diffusion models is novel, and quite different from that of general neural networks due to the dynamic formulation of diffusion models. This work takes an initial step towards this direction. \n3. The derived theoretical result is clean and insightful. \n4. Numerical verifications are consistent, with meticulous robustness studies covering main components of the proposed calculation method."}, "weaknesses": {"value": "1. It would be clearer to add a dedicated algorithm of the proposed calculation method (e.g. Thm. 3.1). \n2. Following 1, how can we compute score functions *accurately* in Eq. (2) in detail? How can we compute probability densities in Eq. (2) *efficiently* beyond neural ODEs? It would be better to include self-contained algorithms regarding them. \n3. Following 1, I also suggest to formulate in-paragraph discussions in Sec. 3.3 as separate algorithms. \n4. For Eq. (1): It is just the score function of $Z_t$, right? What is the meaning of \"optimal solution to this problem (score-matching)\" (Line 107)?\n5. What are the computation and memory complexity of Eq. (2) and Eq. (3) w.r.t. time steps & data dimensions? \n6. It would be more readable to provide self-contained supports in former references for key quantities (at least in appendices), e.g. CCoV, sensitivity equations, and entropic optimal transport (OT) coupling. \n7. Experiments are mainly conducted on MNIST and CelebA datasets. How about the performance on standard Cifar (more diversity) and the efficiency on large-scale ImageNet datasets? \n8. Can authors provide more detailed instructions on how the correlation is calculated in e.g. Fig. 6? \n- Although the proposed calculation method outperforms OT (baseline), it is still far away from 1. What are potential sources of this gap? \n- It is not clear why the correlation is better for larger datasets like CelebA instead of smaller MNIST?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lF1qe8uB1n", "forum": "6PzGc6bWPc", "replyto": "6PzGc6bWPc", "signatures": ["ICLR.cc/2026/Conference/Submission13978/Reviewer_WTVj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13978/Reviewer_WTVj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761867192504, "cdate": 1761867192504, "tmdate": 1762924476784, "mdate": 1762924476784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the differentiablity of the diffusion model training map, that is the map that assigns a score function to a dataset.\nAn algorithm is proposed, which allow studying the sensitivity of the diffusion model to addition or removal of dataset points (images).\nThis is then exploited to define sample sensitivity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The main strength of the paper is to establish Theorem 3.1.\n* Original problem"}, "weaknesses": {"value": "I don't see where the term \"sample sensitivity\" is clearly defined? I understand that this is the derivative involved in Eq (4) as confirmed by Fig. 10 caption, but this is not clear from the text.\n\nTheorem 3.1 suppose bounding support but all examples use mixture of Gaussians. A comment on that point seems necessary.\n\n**Experiments:**\n* Section 4.1: Why use $d=100$ with mixture of isotropic Gaussians. This looks like to poor a model.\n* Section 4.2: As explained in Section C.1.2, here the work is done in $d=10$ with a bimodal Gaussian mixture. This is a very simple model to learn with a network. \n* Sections 4.2 and 4.3: Why is it enough to measure the experiment by only requiring better correlations? How is this computation stable since for most images/points the output should be very close to zero?\n* Figure 6: The OT baseline is based on empirical OT between samples. This could be replaced by a parameterized transport map trained on the whole dataset (see eg Korotin et al ICLR 2023 and references therein).\n* Figure 8: What is displayed in figure 8, \n\nMinor remarks:\n* No hyperlink on cross-references"}, "questions": {"value": "See questions regarding experiments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MrFwmB5sdb", "forum": "6PzGc6bWPc", "replyto": "6PzGc6bWPc", "signatures": ["ICLR.cc/2026/Conference/Submission13978/Reviewer_DS2B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13978/Reviewer_DS2B"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921308738, "cdate": 1761921308738, "tmdate": 1762924476102, "mdate": 1762924476102, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Diffusion models and the mathematical objects that define them (the score function and the learned distribution) are functions of training data. This means that, if the model were trained on additional data, or some training example were removed from the training set, these mathematical objects would be different, and hence generated samples would be different. How different would they be? How sensitively does a given diffusion model depend on one of its training examples?\n\nThis is the question the authors seek to address in their paper. They formalize the question mathematically in terms of the Frechet derivative of a perturbation map, use this formalization to motivate a specific numerical approach to measuring sensitivity to training data, and then show that their method works in a number of experiments. They also place their work in the context of related machine learning work, e.g., related to influence functions."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Overall, I really like this paper. There is a clear goal---How do we formalize and measure the extent to which a diffusion model depends on small perturbations to its training set?---along with math, an algorithmic approach, and experiments to back it up. The paper is also reasonably well-written and clear throughout. \n\nLots of details seem to have been carefully attended to. I also like how the sequence of figures shown slowly build up the ideas of the paper, and gradually show that the method works."}, "weaknesses": {"value": "I think my overall complaints are minor. One of them is that a lot of space is dedicated to showing that the approach yields sensible results (e.g., Figs. 4-7), but not much space is dedicated to showing what the sensitivity results actually are and what we learn from them. Some SI figures show a bit of this (Figs. 9 and 10); I think the paper would be better if some of these were moved to the main text.\n\nRelatedly, some material currently in the main text could probably be moved to SI. For example, Eq. 1 doesn't seem to be used anywhere, and doesn't say anything interesting. The proof that the method is reasonable is belabored a bit, and maybe some of the details of Sec. 4 could be moved to SI. \n\nThe figures could be improved slightly. Many of the figures have small text or labels, and would be improved by making those things bigger (Figs. 4-7 especially). In Figure 8, it would be helpful to also include (i) the perturbation, and (ii) the images pre-perturbation, as opposed to just the sensitivities and post-perturbation images. It's hard to parse the figure without this extra info."}, "questions": {"value": "1. Can the authors say more about the 'optimal transport baseline' in the main text? I didn't understand that part.\n\n2. Are there interesting things worth sharing about what we learn from measuring a bunch of sensitivities? Are certain kinds of data points (e.g., outliers) more influential than others (e.g., non-outliers)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5rGSxs4MDa", "forum": "6PzGc6bWPc", "replyto": "6PzGc6bWPc", "signatures": ["ICLR.cc/2026/Conference/Submission13978/Reviewer_abcK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13978/Reviewer_abcK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951068847, "cdate": 1761951068847, "tmdate": 1762924475247, "mdate": 1762924475247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}