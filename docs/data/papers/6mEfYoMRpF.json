{"id": "6mEfYoMRpF", "number": 7085, "cdate": 1758007142385, "mdate": 1763041682637, "content": {"title": "In-depth Robustness Analysis for Vision-Language-Action Models", "abstract": "Visual–Language–Action (VLA) models report impressive success rates on robotic manipulation benchmarks, yet these results may mask fundamental weaknesses in robustness. We perform a systematic vulnerability analysis by introducing controlled perturbations across seven dimensions: objects layout, camera viewpoints, robot initial states, language instructions, light conditions, background textures and sensor noise. We comprehensively evaluated multiple state-of-the-art models and revealed consistent brittleness beneath apparent competence. Our analysis exposes critical weaknesses: models exhibit extreme sensitivity to perturbation factors including camera viewpoints and robot initial states, with performance dropping from 95\\% to below 30\\% under modest perturbations. Surprisingly, models are largely insensitive to language variations, with further experiments revealing that models tend to ignore language instructions completely. Our findings challenge the assumption that high benchmark scores equate to true competency and highlight the need for evaluation practices that assess reliability under realistic variation.", "tldr": "", "keywords": ["Vision–language–action model", "Robustness", "Analysis"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/bf4411a9941dccca2977e464f53188af2a03a6d3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents an extensive empirical study, in LIBERO, evaluating the robustness of VLAs across seven axes of variation, e.g., camera viewpoint, lightning, initial state, etc. The authors demonstrate that VLAs are extremely brittle to changes in viewpoint and initial conditions. Moreover, current VLAs have poor language-following capabilities, often ignoring the instruction entirely and relying on other cues to infer task details. To facilitate a more rigorous evaluation, the authors introduce LIBERO-Pro, a new benchmark to assess generalization. They demonstrate that by training on LIBERO-Pro, models can improve robustness by up to 11.5%."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "First, the quality of the simulation study is high. The authors are commended for evaluating numerous open-source VLAs and performing a systematic analysis on each against a diverse and well-structured set of environmental perturbations. \n\nSecond, the paper highlights the poor language-following abilities of current VLAs. While this fact is often apparent to practitioners, it is not often highlighted in academic works. The finding that many VLAs attempt to infer the task from visual cues alone is often an under-appreciated fact. By providing evidence of this short-coming, this paper challenges the community to look beyond success rates and develop more robust methods for policy evaluation. \n\nIntroduction of the LIBERO-Pro benchmark is a great addition for the field to bootstrap off of."}, "weaknesses": {"value": "Exclusive reliance on simulation: this work's most fundamental limitation is the lack of real-world demonstrations. The manuscript implicitly makes claims that hold in simulation (LIBERO) and assume they transfer to the real-world, but it is well known that existing simulators are only proxies for real-world deployment. Therefore, it is a significant leap to claim that failure in LIBERO equate to fundamental flaws in the models themselves, especially when many of them are not trained on LIBERO data. This methodological choice weakens the paper's main claims. While a large-scale real-world study is often infeasible, some smaller-scale validation is necessary for the claims to hold. \n\nLimited novelty: The paper's main takeaway, that existing VLAs are brittle to variations in the environment, is a well-established concern within the robot learning community. While the systematic nature of the analysis presented herein is a strength, the novelty is rather limited.\n\nQuestionable experimental choices: some specific experimental choices are difficult to interpret. For example, applying a mask to all visual inputs (Figure 2) seems less like a perturbation and more of an entire modality ablation. It is not clear what insight is gained from this beyond confirming that vision is necessary for these tasks."}, "questions": {"value": "Do the authors have an preliminary evidence to suggest that the trends from LIBERO hold in real robot deployment? While simulations can provide initial correlative evidence of downstream performance, its a leap to claim that trends which hold in simulation are guaranteed to transfer. A small-scale real-world study validating even one or two of the key perturbation axes would improve the conclusions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8zhb1j1Pgj", "forum": "6mEfYoMRpF", "replyto": "6mEfYoMRpF", "signatures": ["ICLR.cc/2026/Conference/Submission7085/Reviewer_iq9G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7085/Reviewer_iq9G"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760985005740, "cdate": 1760985005740, "tmdate": 1762919265974, "mdate": 1762919265974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "Thank you very much for all reviewers' careful review and valuable comments on our paper. After team discussion, we believe that our current method requires more comprehensive ablation studies to verify the effectiveness and necessity of each module. To ensure the rigor and completeness of our research work, we have decided to withdraw this submission. We will continue to improve our work and look forward to contributing to the community in the future."}}, "id": "5djrLp3C1C", "forum": "6mEfYoMRpF", "replyto": "6mEfYoMRpF", "signatures": ["ICLR.cc/2026/Conference/Submission7085/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7085/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763041681480, "cdate": 1763041681480, "tmdate": 1763041681480, "mdate": 1763041681480, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper conducts a large-scale empirical study on the robustness of current VLA models under various simulated perturbations. The authors systematically test multiple open VLA baselines (e.g., OpenVLA, SpatialVLA, $\\pi$0 variants) across the LIBERO benchmark and introduce a new extension called LIBERO-Pro, claiming to provide a more diverse and challenging evaluation. They further analyze robustness under compositional perturbations and explore how models use (or fail to use) language information."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors clearly put substantial effort into evaluating multiple VLA models under diverse perturbations (lighting, camera, robot initialization, etc.). The results are detailed and reproducible, providing a useful community reference.\n\n2. The finding that many models are insensitive to language perturbations (i.e., rely purely on vision) is interesting and aligns with anecdotal community observations.\n\n3. The attempt to measure performance drop under combined perturbations (as opposed to single-axis changes) is a valuable direction for future diagnostic benchmarks."}, "weaknesses": {"value": "**1. Outdated and limited benchmark choice.**\n\nThe entire study is built on LIBERO and its in-house variant, which are low-complexity simulation environments. These benchmarks are already saturated (90–95% success across baselines), meaning further “performance drops” mostly reflect overfitting to the simulator rather than meaningful generalization failures. More modern or realistic benchmarks, e.g., COLOSSEUM [1], RoboTwin [2], would provide stronger evidence.\n\nAs it stands, the paper tests “robustness to LIBERO perturbations,” not “robustness to real-world change.”\n\n**2. The most important one: No sim-to-real or physical validation.**\n\nThe core motivation is to test robustness, but the entire work remains in simulation. ***The real problem that robot VA/VLA faces is not how high performance we could achieve in the simulation, but its generalization ability in the real world.***\nThere is no attempt to correlate the measured robustness with real robot performance under even small-scale trials. Without that bridge, it’s totally unclear whether the measured fragilities actually matter for real deployment.\n\n**3. Perturbations lack external validity.**\n\nThe perturbations (lighting, background, camera pose) are synthetic and easy to simulate. Real-world degradation, like dirty cameras, HDR shifts, physical calibration drift, deformables, and dynamic occlusion, is far more complex. The current perturbations test algorithmic sensitivity, not embodied robustness.\n\n**4. Over-claiming in the “language is ignored” conclusion.**\n\nThe claim that VLAs “ignore language” is overstated. In LIBERO’s single-goal scenes, tasks can often be solved purely visually. The experiments do not isolate cases where language must disambiguate similar visuals. Thus, the evidence supports “conditional language use,” not “complete language neglect.”\n\n\n**5. Compositionality analysis remains descriptive.**\n\nThe Section 5 analysis (pairwise perturbation interactions) produces pretty matrices but provides little mechanistic understanding. It lacks representation-level or causal analysis and no baseline comparisons. The section is more diagnostic than explanatory.\n\n**6. Benchmark extension is useful, but the experiments are self-serving.**\n\nI do think the idea of extending LIBERO toward robustness evaluation has community value: it’s helpful to remind people that existing VLAs are overly benchmark-driven and often brittle under visual or positional shifts. In that sense, creating LIBERO-Pro could have been a good contribution.\n\nHowever, the way it’s executed makes the experiment somewhat circular. LIBERO itself is already almost “solved”: most recent VLAs hit near-perfect success (over 95%). Now, the authors take that same benchmark, add synthetic “robustness” perturbations, and then pretrain the model exactly on those perturbations. Of course the model performs best on the new benchmark; that outcome is basically guaranteed.\n\nSo while the intention is good, the result feels self-fulfilling rather than genuinely diagnostic. It doesn’t necessarily prove that the model is more robust in general — only that it’s optimized for the very disturbances the authors defined. To make this truly convincing, the paper would need to show transfer to unseen perturbations or to a different real-world setup, rather than succeeding on a benchmark built in its own image.\n\n---\n\n*References:*\n\n[1] THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation. RSS 2024.\n\n[2] RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation. 2025"}, "questions": {"value": "I acknowledge the contribution of this work to the robotics community, and I appreciate the effort of this work with extensive experiments. However, there still exist many weaknesses at this stage.\n\nPlease see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zWTWtLHpBP", "forum": "6mEfYoMRpF", "replyto": "6mEfYoMRpF", "signatures": ["ICLR.cc/2026/Conference/Submission7085/Reviewer_PA3w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7085/Reviewer_PA3w"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816489800, "cdate": 1761816489800, "tmdate": 1762919265407, "mdate": 1762919265407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper gives a broad overview of the performance of the popular VLA models across a series of well-designed tasks that control either 1-dim of variation or multiple dimensions of variation. The evaluation results bring some important conclusions about the weakness of the generalizability of current VLAs, and thus lead to some potential instructions for improvements."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation is clear, and the paper is easy to follow.\n2. The experiments are good and reveal some substantial problems of current VLAs.\n3. The paper provides a nice benchmark LIBERO-Pro that helps evaluate the VLA more comprehensively."}, "weaknesses": {"value": "1. While the paper provides a systematic analysis of the modern VLAs,  the scale of performance degradation in some dimension is a common problem for all VLAs. It would be better if the author could give a deeper analysis of this, for example, is this because the high-level, network structure of these VLAs is similar etc.\n2. According to the experiments, the language part plays a less important role than vision part in modern VLAs. However, in Table 2, with IMPROVE GENERALIZATION training strategy, it seems the improvement on Language is actually larger than other vision aspects, such as Light and Background, can the author explain this?"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "a7goRw2Nun", "forum": "6mEfYoMRpF", "replyto": "6mEfYoMRpF", "signatures": ["ICLR.cc/2026/Conference/Submission7085/Reviewer_W94C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7085/Reviewer_W94C"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875677760, "cdate": 1761875677760, "tmdate": 1762919264802, "mdate": 1762919264802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a robustness analysis of Vision-Language-Action (VLA) models. The paper’s core contributions are:\n\n- An analysis of current VLA models through systematic parameter variation.\n- A diagnostic framework for identifying and quantifying the impact of perturbations on model performance.\n- An analysis of the potential mismatch between claimed multimodal capabilities and actual understanding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper does an excellent job of robust perturbation analysis of VLA models. This work comprehensively studies disturbances for each of the modalities of VLA models and shows the relative vulnerabilities of state-of-the-art VLA models across modalities.\n- The paper is overall well-written, with some issues (see weaknesses) on the key findings."}, "weaknesses": {"value": "- Dependence on a Single Simulation Benchmark: A major weakness is the potential lack of generality—the observed brittleness might be an artifact of LIBERO and may not generalize to real-world systems or other simulation platforms.\n- Realistic Perturbations: Some of the perturbations for vision may not be that realistic or may be overly synthetic. In the real world, there might be all kinds of visual problems, i.e. partial obstructions of the camera or loose camera, etc.\n- Limited Analysis of Language Findings: Previous work (https://arxiv.org/pdf/2411.18676) has shown that models are sensitive to language variations, so claiming that the models may ignore language instructions completely seems like an incorrect claim.\n- Focus on Single-Dimensionality: Almost all real-world scenarios often involve changes across multiple axes of modality, i.e. a different background and different lighting, in addition to changes in task instructions. Conclusions associated with single variable changes are somewhat useful for understanding VLA performance, but such limited perturbations may be incomplete or overly optimistic in comparison with real-world environments."}, "questions": {"value": "- Are the findings specific to the LIBERO dataset or does this generalize to other benchmarks?\n- Are the vision-based perturbations really comprehensive or have the authors considered other forms of visual perturbations, as mentioned in the “Weaknesses” section?\n- How can the authors claim that VLA models are largely insensitive to language perturbations? Prior work has shown that VLA models (e.g. OpenVLA) are very sensitive to language perturbations.\n- What happens if more than two of the axes of modality vary? Can the authors comment on the conclusions in such environments, which may be closer to real-world systems with multi-dimensional disturbances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WH1ShJrJJ8", "forum": "6mEfYoMRpF", "replyto": "6mEfYoMRpF", "signatures": ["ICLR.cc/2026/Conference/Submission7085/Reviewer_ephY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7085/Reviewer_ephY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954837462, "cdate": 1761954837462, "tmdate": 1762919264425, "mdate": 1762919264425, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}