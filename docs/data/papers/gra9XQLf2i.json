{"id": "gra9XQLf2i", "number": 15164, "cdate": 1758248478043, "mdate": 1759897323924, "content": {"title": "Dynamics-Informed Weight Diffusion for Generalizable Prediction of  Complex Systems", "abstract": "Data-driven methods offer an effective equation-free solution for predicting physical dynamics. However, predictive models often fail to generalize to unseen environments due to varying dynamic behaviors. In this work, we introduce DynaDiff, a novel generative meta-learning framework to enable efficient, test-time adaptation. Instead of tuning a pre-trained model or context, DynaDiff directly generates a complete, high-performance expert model from scratch, conditioned on a short observation sequence from a new target environment. Specifically, we first finetune a base model on various source environments to efficiently construct a model zoo of expert predictors. Subsequently, we leverage a weight graph representation and train a conditional diffusion model to learn the underlying distribution of expert weights, capable of generating new models from a given dynamic behavior. To effectively capture the dynamic context from the observation sequence, we design a dynamics-informed prompter that explicitly models the relationship between the system's state and its temporal evolution, providing a highly informative prompt for the generative process. Extensive experiments demonstrate that our method can generate expert models with strong generalization for new environments, conditioned on limited observations.", "tldr": "We propose a novel generative meta-learning method for generalizable prediction of  complex systems.", "keywords": ["Dynamical system", "Multi-environment learning", "Diffusion"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c749325fc28090eba72a450b1de89cba65106284.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel weight-space learning in combination with diffusion models for generalisable physical systems.  The authors list 3 main limitations (structure of the weigh-space, its high-dimensionality, and data scarcity), each of which is elegantly tackled with original approaches. Specifically, they explicitly model the joint distribution of environments and weights, and argue that this generative adaptation is fundamentally suited for data-scarce scenarios where finetuning is impractical. The resulting framework, DynaDiff, shows excellent results across synthetic and real-world datasets, even outperforming One-Per-Env in certain settings."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper present a set of original ideas, is clearly written, and significant going forward. The care and intuitive explanation for the concepts (e.g. functional loss) is incredibly valuable.\n\nThe weight-graph construction is smart and insightful. It does appear to be a new and original formalism by the authors, and I think it could be used for a wide variety of other problems. It is important to see weight-space featured represented like this. Additionally, not having to retain potentially large and costly environment-shared components during adaptation is massively useful. (Although this is a slightly contentious point since these environment-shared parameters are encapsulated in the Prompter, Denoiser, and VAE Decoder).\n\nConcerning the experiments, I find them complete and well analysed."}, "weaknesses": {"value": "1) Figure 2 presents a complex pipeline, involving many different architectures at different stages of the Training and Testing processes. Although ablation studies are mostly conducted, it would be interesting to see a version of this framework stripped to its core. \n2) While the authors claim the cost of fine-tuning is eliminated, we still pay it in terms of one-time exorbitant training when constructing a weight zoo. Despite the strategic meta-learning techniques used to generate this zoo. It would be useful for users to see this cost clearly reported.\n3) The meta-learning approach to obtaining the model zoo is intuitive, but also very similar to Dupont et al. 2022. You should cite it. \n4) Weight graphs are limited to linear layers and convolution layers. Although you've extended this (e.g. skip connections), these are quickly being replaced in the literature by other forms of layers (e.g. Attention, etc.). Implementing these weight graphs would significantly increase the value of this work for the ICLR community.\n\n\n### Minor issues:\n- L161: \"a dynamics-informed diffusion model\" \n- L323: \"adaptation\"\n\n### References\nDupont et al. \"From data to functa: Your data point is a function and you can treat it like one\", ICML 2022"}, "questions": {"value": "1) L50: \"from a model weight perspective, the essence of these methods only permit adaptation within a small, expert-specified subset of weights.\" Is there evidence or reference for this ?\n2) L188: You mention heterogenous node features. Does this mean nodes of some layers would have different number of features ($D_{in}$+1) compared to other layers in, say, a MLP ? How do you deal with that ?\n3) L259: Is the ground-truth environmental condition $e$ indispensable to training the prompter? Ablation studies should evaluate this, especially since some baselines do not require this supervisory signal?\n4) Concerning this weight zoo generation approach. Why do you add noise to one layer only? Is it only that layers that is fine-tuned, while other layers are left intact ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3RB3wkbkYk", "forum": "gra9XQLf2i", "replyto": "gra9XQLf2i", "signatures": ["ICLR.cc/2026/Conference/Submission15164/Reviewer_TiFY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15164/Reviewer_TiFY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15164/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761480314214, "cdate": 1761480314214, "tmdate": 1762925475860, "mdate": 1762925475860, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a generative meta-learning framework for cross-environment generalization in physical dynamics prediction. The method generates complete model weights for a new environment using a conditional diffusion model guided by a short observed trajectory. It learns a latent weight space via a VAE. A dynamics-informed prompter extracts physical and spectral-temporal cues from trajectories to condition the diffusion."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The method finds a sweet spot between meta-learning and in-context learning, combining the adaptability of the former with the data efficiency of the latter.\n- It generates model weights in a latent space via conditional diffusion, effectively exploiting the diffusion model’s ability to model complex and multimodal weight distributions.\n- The approach shows better generalization to unseen environments compared to both meta-learning methods and adapted foundation models, while remaining lightweight and computationally efficient when adapting to test-time environments."}, "weaknesses": {"value": "- In Section 4.6, the time and memory usage comparison omits contextual meta-learning baselines, making it unclear how DynaDiff compares to other adaptive approaches.  \n- It is questionable whether it is fair to exclude the generator’s parameter count when comparing with meta-learning methods. The diffusion model is also part of the overall meta-learning process, as well as in both training and test time, yet it contains significantly more parameters than typical meta-learning frameworks with a shared base model.  \n- The paper lacks clarity on test-time procedures for baseline models, specifically how context-based or environment-adaptive models are used during evaluation.  \n- Presentation issues:  \n  - The VAE description is underspecified: the \"node attention-based VAE\" architecture is not clearly explained, and the section should be made more self-contained with details on the encoder–decoder design and attention mechanism.  \n  - The notation is inconsistent and sometimes undefined (e.g., missing definitions for $E$, $D$; unclear distinction between bold $\\mathbf{w}$ and $w$; the symbol $x$ is reused with different meanings across sections), which hinders readability. A thorough revision of the notation is recommended.  \n  - Presentation order: the prompter is presented in a separate section from the diffusion model, even though it is an essential component of it. This separation breaks the logical flow and makes the method harder to follow."}, "questions": {"value": "- Please improve the writing and presentation throughout the paper.  \n- Precisely describe the important components of the method and the experimental settings, as mentioned in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aYMr97uKin", "forum": "gra9XQLf2i", "replyto": "gra9XQLf2i", "signatures": ["ICLR.cc/2026/Conference/Submission15164/Reviewer_6pFj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15164/Reviewer_6pFj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15164/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761792056073, "cdate": 1761792056073, "tmdate": 1762925475512, "mdate": 1762925475512, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DynaDiff, a generative meta-learning framework that addresses cross-environment generalization in physics prediction by directly generating complete expert model weights conditioned on short observation sequences, rather than tuning pre-trained models. The method organizes weights as structure-preserving graphs, learns their distribution via a functional VAE with output-consistency-based loss, and trains a conditional diffusion model guided by a dynamics-informed prompter. Experiments on multiple PDE systems and real-world data show that lightweight generated models (1M parameters) outperform large foundation models (500-600M parameters) by 10.78% on average, with zero gradient computation at test time. This work presents a fundamentally different adaptation paradigm by treating model weights as a generative modality, offering improved efficiency and generalization for scientific machine learning in data-scarce scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents a fresh perspective by framing cross-environment adaptation as generative modeling of complete weight distributions p(θ|e), rather than tuning parameter subsets. This approach is theoretically principled and particularly suited for data-scarce scenarios where gradient-based finetuning is impractical or infeasible.\n\n- Each component addresses specific challenges—the weight graph preserves architectural connectivity and generalizes across architectures, the functional loss insightfully recognizes that functionally equivalent models can have different parameters, and the dynamics-informed prompter cleverly combines domain knowledge with data-driven features to extract meaningful information from as few as 1-10 observation frames.\n\n- The evaluation is comprehensive, spanning 4 PDE systems and real-world ERA5 data with consistent improvements (10.78% average). The finding that generated weights can occasionally surpass individually-trained models provides promising evidence of capturing meaningful weight manifolds rather than merely overfitting to training distributions"}, "weaknesses": {"value": "- Training the dynamics-informed prompter requires the auxiliary loss L_aux, which depends on knowing the ground-truth environmental condition e. This is a very strong assumption, as knowing e even at the training stage may not be realistic in many practical scenarios. Clarifying the prompter's capability without known e would strengthen the practical applicability of the framework\n\n- DynaDiff has several sophisticated components such as the weight graph, the weight VAE, and the conditioned diffusion. It is not clear how these components improve over simpler approaches where the weight parameters of a model can be simply generated by a hypernetwork from the embeddings obtained from context data. Necessary ablation studies are missing. Furthermore, 3.1.3 is quite unclear: is the diffusion generation the latent codes z which is then decoded to the weight parameters via the weight VAE? Please clarify. While the weight graph and weight VAE is conceptually interesting, it seems like there is not much graph information being utilized in the encoding/decoding process of the VAE. The benefit of this component is not clear (compared to a simple VAE generating weight parameters as vectors).\n\n- DynaDiff requires environment-specific weights (model zoo) to be available, which seems to be a significant resource requirement (and a unique advantage to DynaDiff that other baselines do not necessary have). As the ablation results show that DynaDiff’s performance drops significantly when the number of environments are limited at training time, which is a major drawback of the method.\n\n- The introduction and related work sections omit relevant meta-learning approaches that also achieve adaptation without finetuning. For example, https://openreview.net/pdf?id=7C9aRX2nBf2 propose sequential latent variable models for few-shot time-series forecasting that similarly avoid gradient-based adaptation at test time. More generally, meta-learning via hypernetworks is closely related to the presented work (e.g., https://arxiv.org/pdf/1805.09921). The paper should provide a more comprehensive review of such methods and clearly articulate how DynaDiff's weight generation paradigm differs from or improves upon these existing finetuning-free meta-learning approaches. \n\n- For many of the results presented in Table 1 (Lambda-Omega, Kolmogorov Flow), the gain in average is one decimal point smaller than the standard deviation or similar; howing the statistical significance of the improvements is important.\n\n- The observation length L=10 may be too short for adequately capturing complex dynamics. More importantly, the paper lacks critical details about metric calculation (RMSE and SSIM)—specifically, whether the metrics are computed on the same observation sequence X_L or on another sequence within the same environment. Additionally, the paper should provide results on longer time-domain predictions, reporting metrics over extended horizons (e.g., L to 2L or beyond) to demonstrate whether generated models can sustain accurate predictions over longer rollouts."}, "questions": {"value": "- The paper should demonstrate how the model performs when trained without e, relying solely on observation sequences X_L. Additionally, it warrants further investigation whether the prompter can still achieve strong correlation with true environmental parameters (as shown in Figure 10) when trained without L_aux. \n\n- Please provide better clarifications as well as ablation results to demonstrate the contributions of weight VAE and conditioned diffusion over much simpler alternatives that generates weight parameters via a hypernet work.\n\n- Provide stronger evidence for the statistical significance of the improvements obtained.\n\n- Provide better clarifications on the metrics calculated. For a test time series on which the RMSE and SSIM are calculated, what is the portion that is provided as the input to the model (i.e., what is the prediction horizon vs. observation horizon at test time)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HS6ZU2pQ2i", "forum": "gra9XQLf2i", "replyto": "gra9XQLf2i", "signatures": ["ICLR.cc/2026/Conference/Submission15164/Reviewer_PwKE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15164/Reviewer_PwKE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15164/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864947350, "cdate": 1761864947350, "tmdate": 1762925475037, "mdate": 1762925475037, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DynaDiff, a generative meta-learning framework for cross-environment generalization in physical dynamics prediction. Instead of fine-tuning, it directly generates complete expert model weights conditioned on short observation sequences from new environments. At the training phase, A model zoo of expert predictors is built for seen environments via domain-adaptive initialization. These weights are organized into graph representations (preserving network topology) and encoded by a graph-based VAE. The VAE uses a functional loss that measures weight similarity based on model behavior rather than raw values. A conditional diffusion model then learns to generate latent weight representations. For a new environment, a dynamics-informed prompter extracts features from few observations.The output is provided to the diffusion model to generate a latent code, which the VAE decodes into complete expert weights ready for immediate prediction. Experiments on 4 PDE systems and 1 real-world dataset demonstrate the effectiveness of the approach comapred to SOTA framework."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* The paper introduces a fundamentally different paradigm for adaptation in dynamics prediction. Rather than adjusting a subset of parameters (meta-learning) or scaling to massive models (foundation models), DynaDiff models the joint distribution to generate complete expert weights.\n* The technical contributions of the paper are good : the idea of weight graph  representation based on the topology of the network is novel and well designed for this application; the use of a functionnal loss for this graph representation is also a well designed contribution. \n* The experiments (on 5 datasets) show consistent improvements for the proposed framework."}, "weaknesses": {"value": "* Scalability Concerns: Given the model architecture and presented experiments, there are significant doubts about scalability to more complex physical systems (e.g., 3D problems) requiring substantially more parameters. All experiments are limited to small models (~1M parameters) on 2D systems with modest resolutions (64×64 grids). The novelty of applying diffusion models to weight graph representations makes it difficult to assess the scaling potential, and the substantial computational cost of model zoo construction (100 experts per environment, up to 18GB storage) raises questions about practical applicability to large-scale problems.\n* The experiments show very similar performance across all models between in-domain and out-domain settings (Table 1), suggesting the test environments may not be sufficiently challenging. Since all presented SOTA algorithms perform domain adaptation, it is difficult to assess the actual difficulty of the generalization task. Including a baseline without domain adaptation (e.g., a single model trained on all environments without any adaptation mechanism) would help quantify the genuine difficulty of cross-environment generalization and better contextualize the improvements.\n* While the method performs well when test environments lie within the convex hull of training environments (interpolation), extrapolation performance degrades significantly (Table 5: RMSE increases from 0.059 to 0.228 when 50% of parameter space is unseen). The minimal in-domain/out-domain gap suggests the method primarily learns to interpolate in weight space rather than capturing fundamental physical principles, limiting its applicability to truly novel environmental conditions. Those experiments do not include other Env Adaptative SOTA algorithms, only One-For-All algorithms, which do not allow to understand how much the performances are degraded."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2epujdzyZS", "forum": "gra9XQLf2i", "replyto": "gra9XQLf2i", "signatures": ["ICLR.cc/2026/Conference/Submission15164/Reviewer_dDA3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15164/Reviewer_dDA3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15164/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762531837586, "cdate": 1762531837586, "tmdate": 1762925474518, "mdate": 1762925474518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}