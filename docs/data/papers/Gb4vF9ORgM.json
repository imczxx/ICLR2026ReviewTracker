{"id": "Gb4vF9ORgM", "number": 13436, "cdate": 1758217815257, "mdate": 1759897437718, "content": {"title": "CAViAR: Critic-Augmented Video Agentic Reasoning", "abstract": "Video understanding has seen significant progress in recent years, with models' performance on perception from short clips continuing to rise. Yet, multiple recent benchmarks, such as LVBench, Neptune, and ActivityNet-RTL, show performance wanes for tasks requiring complex reasoning on videos as queries grow more complex and videos grow longer. In this work, we ask: can existing perception capabilities be leveraged to successfully perform more complex video reasoning? In particular, we develop a large language model agent given access to video modules as subagents or tools. Rather than following a fixed procedure to solve queries as in previous work such as Visual Programming, ViperGPT, and MoReVQA, the agent uses the results of each call to a module to determine subsequent steps. Inspired by work in the textual reasoning domain, we introduce a critic to distinguish between instances of successful and unsuccessful sequences from the agent. We show that the combination of our agent and critic achieve strong performance on the previously-mentioned datasets.", "tldr": "CAViAR achieves strong video reasoning capabilities via an LLM agent adaptively invoking video modules with a critic to select good reasoning paths.", "keywords": ["video", "reasoning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/caf483689df2eed6a29bc2188d3b61e899a9032c.pdf", "supplementary_material": "/attachment/cd28d1fd18c9d5b3854d7051120cdba9dbba256b.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes CAViAR (Critic-Augmented Video Agentic Reasoning), a training-free framework for video understanding. It uses an LLM as a reasoning agent that iteratively builds/executes short programs, leveraging many video tools (e.g., temporal grounding, retrieval+QA, ASR understanding), and then uses the LLM as a critic to select among multiple reasoning traces/strategies. On video QA benchmarks, including LVBench, Neptune, and ActivityNet-RTL, CAViAR reports improvements over direct inference and various baselines; ablations show that most of the improvements come from the critic and from agent multi-step reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Sound framework. A simple yet working training-free agent framework that uses an LLM agent to generate/execute code with many tools for video understanding.\n\n- Good results. The CAViAR system achieves strong results across multiple video QA benchmarks, including LVBench, Neptune, and ActivityNet-RTL.\n\n- Useful ablations. The paper clearly ablates the effects of the critic and multi-step reasoning on the final video QA performance."}, "weaknesses": {"value": "- Limited novelty. Training-free, agentic frameworks for video understanding have already been explored (e.g., VideoAgent, VideoTree). Programmatic tool use has likewise been studied (e.g., ViperGPT). This paper primarily combines an agent framework with code execution. Given the limited novelty, the work would benefit from deeper analysis, e.g., when code execution helps, when it fails, and guidelines for effective system design.\n\n- Missing baselines. Several relevant training-free agentic systems are absent from the comparisons, notably VideoAgent and VideoTree. Including these (ideally under a shared backbone and context budget) would strengthen the empirical case.\n\n- Additional benchmarks. The evaluation focuses largely on older video-QA datasets. It would be valuable to include more recent and challenging benchmarks such as VideoMME, MovieChat, and NextQA."}, "questions": {"value": "See weaknesses. \n\nCan you also report average #tool calls, tokens, latency, and $/query for LVBench/Neptune/RTL (distribution helps)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yCDQYg3Psy", "forum": "Gb4vF9ORgM", "replyto": "Gb4vF9ORgM", "signatures": ["ICLR.cc/2026/Conference/Submission13436/Reviewer_wZWB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13436/Reviewer_wZWB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761349726389, "cdate": 1761349726389, "tmdate": 1762924060341, "mdate": 1762924060341, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to All Reviewers"}, "comment": {"value": "We thank all reviewers for their thoughtful feedback. We appreciate that reviewers recognized our contribution as a “sound framework” (Reviewer wZWB) with “clear methodological originality” (Reviewer kQk1) and “strong empirical gains” (Reviewers 2td3, kQk1, wZWB). \n\n\n\n## 1. CAViAR Generalizes to Other Strong MLLMs\n\nMultiple reviewers pointed out that the paper would benefit from experiments across different base LLMs. We agree with this point and have conducted preliminary quantitative experiments beyond Gemini-Flash. We implemented CAViAR with GPT-4o-mini as a base model and applied it to the recent, challenging LVBench benchmark.\n\n| Method           | Accuracy (%) ↑ |\n|------------------|----------------|\n| Direct Inference (GPT-4o-mini) | 43.2           |\n| **CAViAR (GPT-4o-mini)**       | **49.0**       |\n\n(These results are obtained on a 25% subset of the total benchmark due to time, cost, and query limit considerations, but could be extended for the final submission.) We observe a substantial improvement in performance. We also explored using open-source models, but this suggested they are thus far not capable of the reasoning beyond simple video QA required for agentic approaches. We expect that as open models rapidly improve, CAViAR will work with these models as well. \n\n## 2. Inference Compute Considerations \n\nReviewers also asked for additional insight into the inference overhead incurred with the agentic approach. This is an important consideration. We find each video typically requires 3-5 agent steps per strategy times 3 strategies = 9-15 total API calls. This is within the range of existing tool-based video reasoning methods: MoReVQA requires 4 reasoning calls plus perception tools per query, Video-of-Thought uses 5-6+ calls with verification re-execution, and AVIS performs 2-10+ dynamic calls with 8% requiring backtracking. Token consumption varies with video length but scales linearly with the number of frames processed in each window. While this increases compute compared to single-pass methods, the significant performance gains (15% on LVBench) justify the cost for accuracy-critical applications, consistent with the compute-accuracy tradeoffs seen across modern multi-step reasoning systems.\n\n## 3. Comparison to VideoAgent, VideoTree, ViperGPT and Novelty\n\nWe would like to clarify the positioning of CAViAR relative to the related works the reviewers point out. While the identified works – namely, VideoAgent, VideoTree, and ViperGPT – are indeed closely related, CAViAR has key differences to each that lead to significant performance gains over prior art, as we show in our ablations.\n\nVideoAgent follows a fixed iterative procedure (caption, retrieve, check confidence, repeat) rather than dynamically choosing tools based on reasoning needs. CAViAR's agent adaptively selects tools based on intermediate results, making it fundamentally different from VideoAgent's rigid pipeline. The primary similarity lies in how both methods terminate: CAViAR ends trajectories based on the agent choosing a tool indicating completion, then selects the most promising with the critic, while VideoAgent asks the base LLM used how confident it is in the final answer, terminating when confident.\n\nWe compare with VideoAgent through the ablation in Table 5, which implements VideoAgent's key confidence-based iteration mechanism. Our results show the VideoAgent self-confidence based approach actually hurts performance (39.9% vs 47.1% for the agent alone) while our critic enhances it (62.0%).\n\nWe also compare to the single-program approach – equivalent to ViperGPT – in Table 4, finding this baseline  yields a 20% drop in performance relative to the agent alone and a 35% drop compared to the agent and critic together, highlighting the importance of the core contributions of CAViAR.\n\nVideoTree focuses on frame selection rather than general video reasoning with diverse tools. A direct comparison would require reimplementing our full tool suite within their frameworks, i.e., using their frame selection approach as part of our agentic pipeline, which is beyond scope but an interesting direction for future work.\n\nCAViAR is thus the first work to demonstrate success for agentic reasoning in video as it is commonly defined for current LLM agents: using tools sequentially to achieve a goal until choosing to stop. While there has been prior work also working towards modular, training-free systems, we consider this a paradigm in its own right given the breadth of potential approaches it entails."}}, "id": "C5A1TPbzbr", "forum": "Gb4vF9ORgM", "replyto": "Gb4vF9ORgM", "signatures": ["ICLR.cc/2026/Conference/Submission13436/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13436/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13436/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763419832935, "cdate": 1763419832935, "tmdate": 1763419832935, "mdate": 1763419832935, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "CAViAR is a training-free agentic system for long-video reasoning that introduces a two-stage approach: an LLM planner/executor generates multiple programmatic strategies using vision and audio tools (frame retrieval, temporal localization, ASR analysis, etc.), and a separate critic LLM compares the resulting execution traces to select the best answer.\n\nA distinct **trace-level selection** step: a separate LLM **critic** compares multiple *executed* tool programs (with timestamps, ASR spans, intermediate rationales) and **chooses** the best evidence chain—going beyond single-run self-confidence or answer-only voting. The contribution is a **preference-over-programs** formulation that operationalizes cross-trajectory comparison as the decision rule, turning tool-grounded reasoning traces themselves—not just final answers—into the object of evaluation and selection.\n\n\n\nKey contributions:\n\n* Multi-strategy execution + cross-trace selection: Unlike prior video agents that rely on single-trace self-evaluation, CAViAR generates diverse reasoning paths and uses a critic to compare them—crucial for handling noisy tool outputs in long videos\n* Strong empirical gains: Achieves 62.0% on LVBench (+14-35pts over baselines), 77.2% on Neptune, and 32.3 mIOU on ActivityNet-RTL, outperforming both direct inference and supervised methods"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Separates planning/execution from a selection stage where a critic LLM compares multiple evidence-bearing traces and picks the winner—more robust than single-trace self-confidence or fixed pipelines (clear methodological originality).\n* Consistent, large gains across diverse long-video settings: strong, training-free improvements on vision-only QA, audio-augmented QA (via ASR tool), and temporal localization, with clean ablations isolating the critic’s contribution (high empirical quality)."}, "weaknesses": {"value": "* **Novelty**: limited. Meny works explore utilizing LLMs with Video-LMMs in agentic frameworks. The difference is the utilization of two distinct LLMs for generating programs and as a critic.\n- **Insufficient benchmark coverage**: Skips Video-MME, LongVideoBench, and MLVU (temporal ordering/counting—Neptune's known failure modes). Doesn't report Neptune's own GEM metric for evidence grounding.\n- **No open-model validation**: Zero replication on open LMMs & LLMs despite claiming \"training-free portability.\" Open model results are important to see if OS models can be utilized in this framework."}, "questions": {"value": "* Your paper's core claim rests on the superiority of a separate critic over other selection methods. While the ablation in Table 5 convincingly shows the critic outperforms a confidence-based self-evaluation module, it omits a comparison to simpler ensemble methods\n* The evaluation is limited to LVBench, Neptune, and ActivityNet-RTL, omitting other critical long-video benchmarks like Video-MME and MLVU\n* The paper claims the framework is \"general\" and enables performance scaling \"with no additional training,\" yet all primary results depend on a single proprietary model, Gemini 1.5 Flash. Please include more base models to make sure method generalizes"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tMLUonViyB", "forum": "Gb4vF9ORgM", "replyto": "Gb4vF9ORgM", "signatures": ["ICLR.cc/2026/Conference/Submission13436/Reviewer_kQk1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13436/Reviewer_kQk1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761443726433, "cdate": 1761443726433, "tmdate": 1762924060008, "mdate": 1762924060008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a multi-agent model named CAViAR for video understanding. The model introduces two types of agents: a reasoning agent and a critic. The reasoning agent generates multiple reasoning strategies, while the critic acts as a verifier, ranking these strategies and selecting the most appropriate one. When the critic is incorporated, experimental results show that the model achieves improved performance on several popular benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proposes CAViAR, a multi-agent–based video understanding algorithm. The method appears to be training-free, utilizing existing LLMs (Large Language Models) as agents, and designs a modular system where each agent plays a different role through prompting.\n\n\n- The framework includes two types of agents: a program-generating agent and a critic. The program-generating agent interprets the video and proposes multiple reasoning strategies, while the critic ranks these strategies to determine the most appropriate one. This design enhances the model’s robustness in handling complex reasoning tasks.\n\n\n- Unlike existing methods such as visual programming, which rely on a fixed reasoning procedure, the proposed algorithm allows the reasoning process to adapt dynamically based on the critic’s feedback."}, "weaknesses": {"value": "- Lack of Novelty in the Modular System\n\n\n   - As a natural limitation of this type of work, constructing a modular system purely through prompting in a training-free manner appears to lack visible novelty in terms of model architecture or training framework. Therefore, additional experiments or analyses are needed to compensate for this limitation.\n\n\n- Experiments Across Diverse LLMs\n\n\n   - It would be valuable to evaluate the proposed method not only with Gemini-Flash, but also with other closed-source models (e.g., ChatGPT, Claude, etc.) and open-source models, to verify whether the approach remains equally effective across different LLMs.\n\n\n- Comparison of Time Consumption and Token Usage with Baselines\n\n\n   - Since the proposed approach employs a multi-agent setup, it is expected to incur higher time consumption and token usage compared to baseline methods. A more detailed and quantitative analysis of these aspects is necessary."}, "questions": {"value": "Please provide your responses with reference to the weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rnLWPKEzOa", "forum": "Gb4vF9ORgM", "replyto": "Gb4vF9ORgM", "signatures": ["ICLR.cc/2026/Conference/Submission13436/Reviewer_2td3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13436/Reviewer_2td3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837842878, "cdate": 1761837842878, "tmdate": 1762924059706, "mdate": 1762924059706, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}