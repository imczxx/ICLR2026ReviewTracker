{"id": "LfoCvfHhz9", "number": 11864, "cdate": 1758204331271, "mdate": 1762960505357, "content": {"title": "P-LoRA: Posterior Knowledge Enables Training-Free Fusion of Subject and Style LoRAs", "abstract": "Recent studies have explored the combination of multiple LoRAs to simultaneously generate learned subjects and styles. However, most existing approaches fuse LoRA weights directly based on their statistical properties, which deviates from the original intent of LoRA, namely learning additional features to adapt to diverse functions. To address this limitation, we introduce \\P-LoRA, a fresh training-free fusion paradigm that leverages posterior knowledge from fine-tuned features, fundamentally shifting the fusion process from weight-level heuristics to representation-conditional decisions. Specifically, at each LoRA-applied layer, we compute the KL divergence between the original features and the features generated by subject and style LoRAs, respectively, to adaptively select the most appropriate weights for fusion. Furthermore, objective metrics such as CLIP and DINO scores, which reflect alignment and semantic consistency, are employed as posterior knowledge to dynamically adjust denoised embeddings during the generation process. By incorporating posterior knowledge into the fusion pipeline, P-LoRA effectively preserves the most representative subject and style characteristics without requiring retraining. Extensive experiments across diverse subject-style combinations demonstrate that P-LoRA consistently outperforms existing methods, achieving superior results both qualitatively and quantitatively.", "tldr": "we introduce P-LoRA, a fresh training-free fusion paradigm that leverages posterior knowledge of fine-tuned features, fundamentally shifting the fusion process from weight-level heuristics to representation-aware decisions.", "keywords": ["Training-Free LoRA Fusion", "Subject and Style LoRAs", "Image Generation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/0087e78443e166a0b4a8edf4474c22a399ef07c5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces P-LoRA, a training-free method for fusing subject and style LoRAs in diffusion-based image generation. Unlike prior fusion techniques that rely on weight-level heuristics (e.g., ZipLoRA, B-LoRA, K-LoRA), P-LoRA leverages posterior knowledge derived from both fine-tuned features and objective metrics to guide the fusion process adaptively."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Moves from weight-based to feature- and metric-based LoRA fusion, grounded in a clear motivation that aligns better with LoRA’s original design philosophy.\n2. Avoids retraining or fine-tuning, yet achieves superior results through posterior guidance.\n3. The use of multiple evaluation settings (Stable Diffusion XL, FLUX, and public LoRAs) strengthens reproducibility and generality."}, "weaknesses": {"value": "1. Although “training-free,” the method introduces extra computation (e.g., feature divergence calculation), with no runtime or memory analysis provided.\n2. Benchmarks focus on synthetic subject-style datasets; results on more challenging or real-world domains (e.g., multiple styles or compositional generalization) would strengthen the claim of generality.\n3. Relying on CLIP/DINO guidance ties the approach to specific pretrained models and could bias outputs toward their embedding spaces.\n4. The paper lacks a formal justification for using KL divergence as the optimal criterion for feature fusion and for the gradient-based metric guidance step."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KIGzUVKptb", "forum": "LfoCvfHhz9", "replyto": "LfoCvfHhz9", "signatures": ["ICLR.cc/2026/Conference/Submission11864/Reviewer_WzzB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11864/Reviewer_WzzB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760582726885, "cdate": 1760582726885, "tmdate": 1762922883642, "mdate": 1762922883642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "g6mbB805I0", "forum": "LfoCvfHhz9", "replyto": "LfoCvfHhz9", "signatures": ["ICLR.cc/2026/Conference/Submission11864/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11864/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762960504584, "cdate": 1762960504584, "tmdate": 1762960504584, "mdate": 1762960504584, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces P-LoRA, a training-free framework for fusing subject LoRAs and style LoRAs in text-to-image diffusion models. Unlike previous LoRA fusion methods (e.g., K-LoRA, ZipLoRA, B-LoRA), which directly combine weights using heuristics or statistical properties, P-LoRA proposes to leverage posterior knowledge derived from: Posterior Feature Knowledge (PFK): Selecting, at each layer, the LoRA (subject or style) that induces larger KL divergence between original and fine-tuned features, under the assumption that greater feature divergence implies higher importance. Posterior Metrics Knowledge (PMK): Using external objective metrics (CLIP, DINO) as posterior signals to guide the denoising process via gradient-based updates. The authors claim this approach allows training-free, adaptive, and input-conditional fusion of LoRAs, achieving better content–style preservation without retraining. Experiments on Stable Diffusion XL and FLUX models show improvements over baselines (K-LoRA, ZipLoRA, B-LoRA) in CLIP and Style Similarity metrics, as well as higher human and MLLM (GPT-4o, Qwen2.5-VL) preference rates."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-written, logically organized, and the figures (especially Figure 2 and Figure 5) help illustrate the dynamic layer-wise fusion and guidance mechanisms.\n- The mathematical derivations (Eq. 1–7) are clear enough for reproduction, despite some heuristic assumptions."}, "weaknesses": {"value": "- The benchmarks are narrow: all experiments use subject–style combinations from DreamBooth and StyleDrop datasets. There are no experiments on compositional or multi-object scenarios (e.g., Mix-of-Show, CustomDiffusion setups).\n- Conceptually, P-LoRA extends K-LoRA by replacing weight magnitude selection with feature divergence selection, which is an incremental improvement rather than a fundamental paradigm shift.\n- There is no discussion of why posterior guidance based on image-level metrics (CLIP/DINO) should interact stably with denoising updates, nor any analysis of gradient stability."}, "questions": {"value": "- How was the relevant LoRA list obtained? Were the LoRA weights sourced from open repositories, or were they retrained by the authors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "BaCG9t23kg", "forum": "LfoCvfHhz9", "replyto": "LfoCvfHhz9", "signatures": ["ICLR.cc/2026/Conference/Submission11864/Reviewer_orLy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11864/Reviewer_orLy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843897756, "cdate": 1761843897756, "tmdate": 1762922883218, "mdate": 1762922883218, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present P-LoRA, a novel representation-conditioned fusion mechanism for image stylization. The approach has two parts, the first relying on KL-divergence to select subject and style LoRA features and the second part that integrates metrics-based feedback into the diffusion process. The specific metrics are CLIP and DINO. The authors present a number of experiments, comparing P-LoRA to other LoRA variants, finding they outperform these variants in terms of CLIP and DINO. They also present the results of a user study and an evaluation with GPT-4o and Qwen2.5-VL. In all cases, their approach outperforms the baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "In terms of originality, the approach essentially combines the usage of KL-divergence, CLIP, and DINO simultaneously. While other approaches have used these measures individually, this is the first (to my knowledge) to incorporate them together. \n\nIn terms of quality, the work is of fairly high quality. I have concerns about the same metrics being used to guide the diffusion process (CLIP and DINO) as then used in the experiments (since Style Sim is also CLIP-based). However, the user study and the other LLM evaluations help address this concern. \n\nIn terms of clarity, the paper is overall well-written. However, there are still aspects that could be better clarified (see weaknesses below). \n\nIn terms of significance, I anticipate this work to have a significant impact on image stylization/style transfer communities and applications."}, "weaknesses": {"value": "The major weaknesses, as addressed above come from the somewhat low originality (the approach is essentially a fusion of approaches from prior work), the potential quality concerns around the experiment metric and dataset choices, and lacking clarity on several points. There's not more to be said about the originality, so I'll leave that there. \n\nFor the quality, I recognize that there's no learning based on the selected metrics, but these metrics are still involved in the diffusion process and then appear again in the experiments. As such, it's follows naturally that P-LoRA would outperform the methods that do involve use both metrics. It's unclear the value this experimental result has. On a lesser note, while I recognize that these datasets are commonly used, they're relatively small, and comparisons with other, larger datasets would have been useful.\n\nFor the clarity concerns, I would have appreciated more detail on the user study methodology. There is a bit more methodological detail in the appendix but that still doesn't include information about user study population demographics or inter-rater reliability. Similarly, it's unclear whether images in the paper are selected at random or chosen by the authors. It would also be beneficial for the authors to clarify why there's a discrepancy between Table 2 (where P-LoRA soundly beats out the baselines) and Table 1 (where it's much closer)."}, "questions": {"value": "1. Did the authors try their approach on other datasets? \n2. What were the demographics and inter-rater reliability for the user study?\n3. Were the images picked randomly or cherry picked?\n4. Can the authors explain the difference in results from Table 1 to Table 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sbWpOu3dWn", "forum": "LfoCvfHhz9", "replyto": "LfoCvfHhz9", "signatures": ["ICLR.cc/2026/Conference/Submission11864/Reviewer_h8ek"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11864/Reviewer_h8ek"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882464538, "cdate": 1761882464538, "tmdate": 1762922882866, "mdate": 1762922882866, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the problem of how to combine two LoRAs in image generation tasks. Previous methods adjusted the combination by modifying the weight ratios of each LoRA within the injected layers. In contrast, this work further considers the KL divergence between the features of different LoRAs and those of the original DiT, using it as a criterion for selection. Additionally, extra modulation is applied at the model’s output stage."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is simple, intuitive, and easy to reproduce.\n\n2. The idea of using a metric based on the divergence between LoRA-generated features and the original DiT features seems reasonable.\n\n3. The paper provides appropriate comparisons with relevant counterparts and includes both MLLM-based and human evaluation results."}, "weaknesses": {"value": "1. The paper emphasizes that its approach is training-free, yet the metric requires fine-tuned features. Does this fine-tuning process need to be performed for every LoRA? If so, the method’s flexibility would be quite limited.\n\n2. The experimental section lacks clarity. Do the types of LoRAs used in the evaluation also appear during the fine-tuning stage?\n\n3. What would happen if the metric were computed directly from the LoRA output features without performing any fine-tuning?"}, "questions": {"value": "Please see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XcAn2cC1r8", "forum": "LfoCvfHhz9", "replyto": "LfoCvfHhz9", "signatures": ["ICLR.cc/2026/Conference/Submission11864/Reviewer_7tAr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11864/Reviewer_7tAr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959818958, "cdate": 1761959818958, "tmdate": 1762922882305, "mdate": 1762922882305, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}