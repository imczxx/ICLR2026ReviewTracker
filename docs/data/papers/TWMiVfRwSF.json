{"id": "TWMiVfRwSF", "number": 4640, "cdate": 1757732634273, "mdate": 1759898022082, "content": {"title": "Dynamic Parametric Retrieval Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by injecting externally retrieved documents into the input context. It significantly increases inference costs and introduces knowledge conflicts, primarily caused by the lack of corresponding parametric knowledge in LLMs. Recently, Parametric RAG (PRAG) proposed to overcome these limitations by embedding symbolic documents into LLMs parameters, effectively reducing the inference costs and conflicts through offline training. However, PRAG needs to convert all documents into parameters in advance, which incurs high training and storage costs and renders it difficult to generalize to unseen documents. To address these challenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that leverages a lightweight parameter translator model to efficiently convert symbolic documents into parametric knowledge online. Specifically, the parameter translator employs several linear layers to convert document embeddings into LoRA modules of feed-forward networks of LLMs directly. DyPRAG achieves test-time parametric knowledge enhancement by dynamically generating the requisite parameters, which not only reduces the inference cost and mitigates knowledge conflicts inherent in RAG, but also lowers the training and storage overhead of PRAG. Extensive experiments on multiple datasets demonstrate the effectiveness and generalization capabilities of DyPRAG. Furthermore, the combination of contextual knowledge with test-time generated parametric knowledge offers a practical and more powerful RAG paradigm which updates parametric knowledge adaptively, enables superior knowledge fusion and alleviates knowledge conflicts in real-world applications. Our code is available at https://anonymous.4open.science/r/DyPRAG_ICLR.", "tldr": "", "keywords": ["Retrieval Augmented Generation", "Hypernetwork", "Test-time Parametric Knowledge Enhancement"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e62a9aa3b4425f269725cdab6976c0f919804fa9.pdf", "supplementary_material": "/attachment/ec88f29cd2345de4f7e4a10ef9b87c5b13ae6ca8.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents Dynamic Parametric RAG (DyPRAG), a revision to Parametric RAG that generates parametric knowledge dynamically during test time. Given a set of retrieved documents relevant to the query, a trainable parameter translator will generate the corresponding parametric representation as dynamic LoRA for each retrieved document. Then, the summation of all the dynamic LoRA will be applied to the LLM to generate the final outcome. Experimental results on 2WikiMultihopQA, HotpotQA, PopQA, and ComplexWebQuestions show the effectiveness of the proposed method compared with PRAG, pure RAG and other baseline."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* An interesting revision to the PRAG framework. \n\n* The current experiments show the improvement of performances from the proposed method."}, "weaknesses": {"value": "* In experiments, only BM25 is used as the retrieval model, and the size of retrieval documents is fixed at 3. However, the performance of the baseline RAG could be dramatically different with a dense retrieval model and/or more reference documents. The pure sparse RAG is simplistic and efficient. A fair comparison could be made by fixing the computation cost. For example, the performances of pure RAG with more reference documents and even with dense retrieval could be reported. At the same level of computation cost, can the proposed method outperform the RAG or PRAG? \n\n* In addition to the statement in Section 3.3 and Appendix A, empirical runtime in the inference stage could be measured and compared with other methods. In particular, the runtime of the best-performing setting, DyPRAG-Combine, should be reported and analyzed. Without the efficiency information, the practical usefulness of the proposed method is still unclear. \n\n* This work claims that the traditional PRAG requires retraining when new documents added. As shown in Table 6, the performance of the proposed method in the OOD setting is very close to baseline RAG. RAG could possibly outperform the proposed method with a different settings (e.g., more reference documents, a different retrieval models).\n\n* Figure 1, which is very important to this paper, could be better presented. The scale is too small in the current version."}, "questions": {"value": "* Did you try different number of retrieved documents in the baseline RAG?\n\n* How does the retrieval model affect the performance of the DyPRAG?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cv6XzUpy4z", "forum": "TWMiVfRwSF", "replyto": "TWMiVfRwSF", "signatures": ["ICLR.cc/2026/Conference/Submission4640/Reviewer_ncDL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4640/Reviewer_ncDL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4640/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840282977, "cdate": 1761840282977, "tmdate": 1762917483272, "mdate": 1762917483272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DyPRAG, a novel framework that dynamically generates parametric knowledge adapters (LoRA modules) conditioned on retrieved documents during inference. Instead of statically training one LoRA per knowledge source as in PRAG, DyPRAG trains a parameter translator that maps document embeddings to LoRA weights, thereby enabling lightweight and flexible knowledge injection at runtime. The paper is well-organized, easy to follow, and clearly written, with a comprehensive set of experiments across multiple QA benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is well written and easy to understand. The motivation, method, and experimental setup are clearly explained, and figures are intuitive.\n\n2. The idea of dynamically generating LoRA parameters from retrieved documents is fresh and interesting. It extends the RAG and PRAG paradigms in a meaningful way and shows the potential for a more adaptive integration between retrieval and parametric memory.\n\n3. The authors evaluate DyPRAG across multiple QA datasets, ablation studies, and analyses, demonstrating solid empirical results."}, "weaknesses": {"value": "1. It appears that DyPRAG requires training a parameter generator (translator) specifically for each backbone model (e.g., LLaMA, Mistral). This design makes it model-dependent, limiting its generality and practicality compared with standard RAG approaches, which can be easily applied to any model without retraining. A discussion or experiment on cross-model generalization (e.g., training the translator on one model and transferring to another) would make the work stronger\n\n2. The experiments are conducted on relatively weak LLMs, which might exaggerate the benefits of parameter injection. For stronger models (e.g., Qwen3-8B/14B） that already have rich contextual understanding, explicit parameter injection might not be necessary. It would be valuable to see results on stronger models to test whether DyPRAG still brings improvements.\n\n3. The paper mainly focuses on the parametric side but uses a single retriever setup. Since DyPRAG injects parameters conditioned on retrieved documents, errors in retrieval could directly amplify hallucinations, as incorrect LoRA weights may reinforce wrong knowledge. It would strengthen the work to include experiments with different retrievers (e.g., dense vs. hybrid, or advanced ones like Contriever, ColBERT, or Qwen retrievers) to analyze robustness to retrieval errors.\n\n4. All metrics are reported as F1 scores, which can fluctuate significantly and are often sensitive to surface-level formatting differences (e.g., phrasing or extra explanations). F1 may yield high scores for semantically incorrect answers and thus is not fully reliable for evaluating generative models. I suggest adding LLM-as-a-judge evaluations (e.g., GPT-5-based scoring) as a complementary measure to verify consistency and correctness."}, "questions": {"value": "The paper shows that DyPRAG-Combine achieves better performance than DyPRAG alone, but it is unclear why additional combination is needed if LoRA injection already encodes knowledge. Does this imply that the parametric generation is incomplete or that LoRA captures only partial information? A deeper analysis or explanation of why combining improves performance would be helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "quMnCKvdbM", "forum": "TWMiVfRwSF", "replyto": "TWMiVfRwSF", "signatures": ["ICLR.cc/2026/Conference/Submission4640/Reviewer_kQ2T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4640/Reviewer_kQ2T"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4640/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908277939, "cdate": 1761908277939, "tmdate": 1762917482790, "mdate": 1762917482790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Dynamic Parametric RAG (DyPRAG), a retrieval-augmented generation framework that dynamically converts retrieved documents into lightweight LoRA adapters during inference, eliminating the need for storing per-document parameters like in PRAG or handling long contexts as in RAG. A parameter translator learns to map document embeddings to LoRA weights, enabling on-the-fly parameter generation for unseen documents. This design significantly reduces storage and computation costs while improving retrieval-based reasoning and mitigating knowledge conflicts. The authors also propose DyPRAG-Combine, which fuses dynamic parameter injection with contextual retrieval for enhanced factuality and consistency. Experiments across QA benchmarks demonstrate DyPRAG’s superior efficiency, generalization, and performance compared to both PRAG and traditional RAG methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper targets the high training and inference cost of parameter-injection RAG methods and proposes a learnable neural network (Translator) that generates LoRA parameters from documents, writing document knowledge into LoRA.\n\n2) DyPRAG-Combine achieves the best performance and improves over RAG, suggesting that LoRA generated and injected by the Translator helps alleviate conflicts between parametric knowledge and external evidence.\n\n3) The experimental comparisons are relatively comprehensive; without per-document LoRA training, the method still maintains a small gap from PRAG."}, "weaknesses": {"value": "1) Using only the “last token’s final-layer hidden state” as the document vector may limit representation capacity.\n\n2) The Translator architecture is relatively simple, and there is a lack of systematic analysis on its model size and parameter configuration.\n\n3) The paper provides only a partial and qualitative analysis of inference latency; end-to-end latency measurements are missing."}, "questions": {"value": "1) When documents are long or key information is sparse, can the last-token hidden state still effectively represent the whole document?\n\n2) In Table 1, DyPRAG outperforms RAG, but in the OOD results of Table 2, DyPRAG is clearly worse than RAG. What causes this \ndiscrepancy? Does it indicate insufficient generalization of the Translator’s document-to-parameter mapping?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Vw0ZAwGuo8", "forum": "TWMiVfRwSF", "replyto": "TWMiVfRwSF", "signatures": ["ICLR.cc/2026/Conference/Submission4640/Reviewer_WGwD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4640/Reviewer_WGwD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4640/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965544609, "cdate": 1761965544609, "tmdate": 1762917482421, "mdate": 1762917482421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DyPRAG to solve the problems of efficiency of PRAG (Parametric RAG). Instead of generating a set of versions for a document and parametrize them at inference time in PRAG, DyPRAG trains a small hypernetwork to encode a documentfrom its original embedding (last layer of transformer). It uses the same process to generate training data as in PRAG. The hypernetwork is trained to match the document representation in the training set. By doing so, DyPRAG does not need to store the encoded document embedding but can generate it efficiently. It is claimed that the training time is also reduced.\nThe experiments show that DyPRAG can lead to effectiveness close to PRAG, and outperforms other RAG approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets an important problem in PRAG - that of efficiency. It proposes an efficient solution to create document representation online, thus save the storage space. The proposed method encodes a document by a trained parameter translator based on the same training data as PRAG. The time complexity is comparable. What is faster is the online inference time: document representation can be obtained through the parameter translator, without the costly generation of multiple versions and their encoding. \n\n2. The experimental results show that DyPRAG can achieve a performance close to PRAG in some cases.\n\n3. The paper contains many analyses, showing the impact of different components in the training loss function, the complexity, generalizability, and the impact of different hyperparameters. The analyses are informative."}, "weaknesses": {"value": "1. As DyPRAG does not need to generate multiple versions for a document at inference time, but generates a representation directly from the encoded embedding and the parameter translator, it is unclear if the created representation can benefit from the implicit expansion effect in PRAG through the multiple versions of document. This aspect has not been analyzed. This cannot be seen directly from the global effectiveness measures. that are quite variable.\n\n2. One weakness of PRAG is that the document representation is created independently of the query. It is uncertain that the information relevant to the query is always included in the representation. DyPRAG inherits the same weakness. It would be better to consider the query when creating document representation.\n\n3. The experimental results are not consistent when comparing DyPRAG with others (namely PRAG). DyPRAG often needs to be combined with in-context injection to be competitive. However, the combination will reduce its efficiency, making it a less interesting solution to RAG."}, "questions": {"value": "1. Have you analyzed the quality of the generated document representation, in comparison to PRAG? The analysis would be interesting to understand if the creation of multiple versions of a document is necessary. If representations of similar quality can be obtained in DyPRAG and PRAG, then there is indeed no need to create multiple versions of the document, and this can be done through parameter translator."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "sM7bmVHTxq", "forum": "TWMiVfRwSF", "replyto": "TWMiVfRwSF", "signatures": ["ICLR.cc/2026/Conference/Submission4640/Reviewer_cWye"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4640/Reviewer_cWye"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4640/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973643311, "cdate": 1761973643311, "tmdate": 1762917482199, "mdate": 1762917482199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}