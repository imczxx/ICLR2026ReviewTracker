{"id": "JnhahbMvRE", "number": 12856, "cdate": 1758210974498, "mdate": 1763691705570, "content": {"title": "HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models", "abstract": "Fine-tuning large language models (LLMs) on a mixture of diverse datasets poses challenges due to data imbalance and heterogeneity. Existing methods often address these issues across datasets (globally) but overlook the imbalance and heterogeneity within individual datasets (locally), which limits their effectiveness. We introduce Hierarchical Balancing Optimization (HBO), a novel method that enables LLMs to autonomously adjust data allocation during fine-tuning both across datasets (globally) and within each individual dataset (locally). HBO employs a bilevel optimization strategy with two types of actors: a Global Actor, which balances data sampling across different subsets of the training mixture, and several Local Actors, which optimizes data usage within each subset based on difficulty levels. These actors are guided by reward functions derived from the LLM's training state, which measure learning progress and relative performance improvement. We evaluate HBO on three LLM backbones across nine diverse tasks in multilingual and multitask setups. Results show that HBO consistently outperforms existing baselines, achieving significant accuracy gains. Our in-depth analysis further demonstrates that both the global actor and local actors of HBO effectively adjust data usage during fine-tuning. HBO provides a comprehensive solution to the challenges of data imbalance and heterogeneity in LLM fine-tuning, enabling more effective training across diverse datasets.", "tldr": "", "keywords": ["Large Language Models", "Fine-Tuning", "Multilingual", "Multitask"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/27925e5bfa4a540ad163c83351d12951e8edd6ae.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Hierarchical Balancing Optimization (HBO), a novel framework designed to address data imbalance and heterogeneity challenges in fine-tuning LLMs. HBO employs a bilevel optimization strategy with two key components: a Global Actor for balancing data sampling across datasets and Local Actors for optimizing sampling within individual datasets based on difficulty levels. The paper demonstrates HBO’s effectiveness across three LLM architectures on multilingual and multitask setups, showing consistent performance improvements over existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The hierarchical optimization framework with global and local balancing is novel and addresses a critical gap in LLM fine-tuning.\nThe experiments are extensive and well-designed, covering multiple models, tasks, and evaluation metrics. The ablation studies and sensitivity analyses provide deep insights into the effectiveness of HBO.\nThe paper is clearly written, with detailed explanations of the methodology and results. Figures and tables are well-designed and enhance understanding.\nThe proposed method is broadly applicable and demonstrates consistent performance gains, making it a valuable contribution to the field."}, "weaknesses": {"value": "While HBO demonstrates strong performance improvements, the additional 15% training overhead may limit its applicability in resource-constrained environments. The authors could provide more discussion on strategies to mitigate this overhead.\n\nAlthough the paper evaluates different reward functions, the focus is primarily on L2 norm and perplexity ratio. Exploring alternative reward mechanisms (e.g., task-specific metrics) could further enhance HBO’s applicability.\n\nThe experiments are conducted on sampled datasets (e.g., 20% of total data). It would be helpful to discuss how HBO scales to larger datasets and whether the performance gains remain consistent."}, "questions": {"value": "Have the authors considered task-specific reward functions or alternative optimization techniques for the global and local actors? If so, how do these compare to the current design?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AVcPjZbwoi", "forum": "JnhahbMvRE", "replyto": "JnhahbMvRE", "signatures": ["ICLR.cc/2026/Conference/Submission12856/Reviewer_9Boj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12856/Reviewer_9Boj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761690076224, "cdate": 1761690076224, "tmdate": 1762923650429, "mdate": 1762923650429, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Hierarchical Balancing Optimization (HBO), a bilevel optimization framework designed to mitigate data imbalance and heterogeneity when fine-tuning LLMs. HBO introduces two interacting components, i.e., a Global Actor that adjusts sampling probabilities across datasets and several Local Actors that manage sampling within datasets based on difficulty levels. Both actors are guided by rewards derived from the LLM's training state: gradient norms for global balancing and perplexity ratios for local balancing. The authors evaluate HBO on three model backbones (Llama-3.1-8B, Qwen2.5-7B, EuroLLM-9B) and nine tasks across multilingual and multitask setups, reporting consistent performance improvements over both heuristic and dynamic baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets an important problem, i.e., data imbalance and heterogeneity in LLM fine-tuning,which is relevant to current multi-task and multilingual training paradigms.\n2. The hierarchical bilevel optimization formulation is conceptually interesting and provides a unified framework for global and local data balancing.\n3. The paper is well-written and easy to follow."}, "weaknesses": {"value": "I have the following concerns. *If the authors could properly address them during the rebuttal phase, I am willing to raise my score.*\n1. The technical novelty is somewhat limited. While the hierarchical structure and bilevel setup are well-motivated, they mainly combine known techniques such as policy gradients and dynamic sampling into a straightforward framework, without introducing fundamentally new optimization principles.\n2. This paper lacks strong theoretical or analytical justification for why the proposed reward formulations (gradient norm and perplexity ratio) should lead to optimal or stable data allocation.\n3. Although the experiments are comprehensive, the reported improvements are modest (often within 1–2 points), raising questions about whether the additional implementation overhead (15% extra training cost) is justified.\n4. Some important recent baselines [1,2] are missing. The paper would benefit from either a comparison with these methods or a discussion of their relevance.\n5. The authors may want to provide deeper analysis of failure cases or scenarios where HBO underperforms, as well as qualitative insights into how the hierarchical balancing actually affects learning dynamics beyond probability curves.\n\n[1] How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. ACL 2024.\n\n[2] Boosting Multi-Domain Fine-Tuning of Large Language Models through Evolving Interactions between Samples. ICML 2025."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T8U4n3x9T6", "forum": "JnhahbMvRE", "replyto": "JnhahbMvRE", "signatures": ["ICLR.cc/2026/Conference/Submission12856/Reviewer_9Qbd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12856/Reviewer_9Qbd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706223629, "cdate": 1761706223629, "tmdate": 1762923649955, "mdate": 1762923649955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Hierarchical Balancing Optimization (HBO), a bilevel optimization framework designed to mitigate data imbalance and heterogeneity when fine-tuning LLMs. HBO introduces two interacting components, i.e., a Global Actor that adjusts sampling probabilities across datasets and several Local Actors that manage sampling within datasets based on difficulty levels. Both actors are guided by rewards derived from the LLM's training state: gradient norms for global balancing and perplexity ratios for local balancing. The authors evaluate HBO on three model backbones (Llama-3.1-8B, Qwen2.5-7B, EuroLLM-9B) and nine tasks across multilingual and multitask setups, reporting consistent performance improvements over both heuristic and dynamic baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets an important problem, i.e., data imbalance and heterogeneity in LLM fine-tuning,which is relevant to current multi-task and multilingual training paradigms.\n2. The hierarchical bilevel optimization formulation is conceptually interesting and provides a unified framework for global and local data balancing.\n3. The paper is well-written and easy to follow."}, "weaknesses": {"value": "I have the following concerns. *If the authors could properly address them during the rebuttal phase, I am willing to raise my score.*\n1. The technical novelty is somewhat limited. While the hierarchical structure and bilevel setup are well-motivated, they mainly combine known techniques such as policy gradients and dynamic sampling into a straightforward framework, without introducing fundamentally new optimization principles.\n2. This paper lacks strong theoretical or analytical justification for why the proposed reward formulations (gradient norm and perplexity ratio) should lead to optimal or stable data allocation.\n3. Although the experiments are comprehensive, the reported improvements are modest (often within 1–2 points), raising questions about whether the additional implementation overhead (15% extra training cost) is justified.\n4. Some important recent baselines [1,2] are missing. The paper would benefit from either a comparison with these methods or a discussion of their relevance.\n5. The authors may want to provide deeper analysis of failure cases or scenarios where HBO underperforms, as well as qualitative insights into how the hierarchical balancing actually affects learning dynamics beyond probability curves.\n\n[1] How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. ACL 2024.\n\n[2] Boosting Multi-Domain Fine-Tuning of Large Language Models through Evolving Interactions between Samples. ICML 2025."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T8U4n3x9T6", "forum": "JnhahbMvRE", "replyto": "JnhahbMvRE", "signatures": ["ICLR.cc/2026/Conference/Submission12856/Reviewer_9Qbd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12856/Reviewer_9Qbd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706223629, "cdate": 1761706223629, "tmdate": 1763713773554, "mdate": 1763713773554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Hierarchical Balancing Optimization (HBO), a novel framework designed to address data imbalance and heterogeneity during the fine-tuning of Large Language Models (LLMs). The authors argue that existing methods typically focus on balancing data across different datasets (globally) but neglect imbalances and variations within individual datasets (locally). HBO aims to solve this by enabling the LLM to autonomously adjust data sampling probabilities at both levels. It employs a bilevel optimization strategy featuring a Global Actor, responsible for balancing sampling across datasets, and multiple Local Actors, each optimizing sampling within a specific dataset based on predefined difficulty groups. These actors are trained using reward signals derived from the LLM's training state: the global reward is based on the L2 norm of gradients (indicating learning progress), and the local reward uses the ratio of current to initial perplexity (indicating relative improvement on difficulty groups). The framework is evaluated on several LLM backbones across multilingual and multitask settings, reportedly outperforming various baseline sampling strategies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles a significant and nuanced challenge in LLM fine-tuning by explicitly addressing hierarchical data imbalance and heterogeneity (both global, across datasets, and local, within datasets), which is often overlooked by simpler methods.\n\n2. The proposed HBO mechanism, utilizing a bilevel optimization framework with distinct global and local actors guided by rewards derived from the model's own training state, is a novel and sophisticated approach to achieve autonomous, dynamic data balancing.\n\n3. The empirical results are strong and comprehensive, showing consistent improvements over heuristic and existing dynamic sampling baselines across multiple LLM backbones (Llama, Qwen, EuroLLM), diverse tasks (multilingual, multitask), and including insightful analyses like the dynamic evolution of sampling probabilities."}, "weaknesses": {"value": "1. The framework introduces substantial complexity compared to standard fine-tuning or simpler dynamic sampling. Implementing and tuning the bilevel optimization setup, managing multiple actors (one global, potentially many local), and ensuring stable training with the Reinforce algorithm likely requires significant expertise and effort.\n\n\n2. The reported computational overhead, while quantified (~15%), is non-negligible and could be a barrier to practical adoption. This additional runtime cost for actor updates and reward computations might be prohibitive, especially for resource-intensive LLMs or scenarios requiring frequent retraining.\n\n\n3. The method's performance relies heavily on the specific choices for reward functions and the difficulty grouping metric. While the chosen rewards (L2 gradient norm, perplexity ratio) and the SuperFiltering metric  show good results in the experiments, their universal optimality or robustness across different datasets, tasks, or model architectures is not guaranteed. The framework might be sensitive to these design choices.\n\n4. The paper would be improved by comparing this RL-based actor approach to other recent dynamic strategies for multi-domain data, including those based on sample interactions[1] or alternative optimization objectives [2]\n\n[1] Boosting Multi-Domain Fine-Tuning of Large Language Models through Evolving Interactions between Samples. ICML 2025.\n\n[2] Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large Language Models. EMNLP 2024."}, "questions": {"value": "1. Could the authors provide more specifics about the SuperFiltering metric  used to partition data into difficulty groups? How is difficulty defined and measured by this metric, and how robust is the local balancing performance if a different difficulty metric were used?\n\n2. The cyclical patterns observed in the local sampling probabilities (e.g., Figure 2c) are interesting. Is this behavior consistently observed across different datasets and models? What mechanism within the HBO framework drives this apparent emergent curriculum?\n\n3. Please review the formatting of Equation 8; the \"where\" clause defining PPL seems awkwardly placed on the same line and might be clearer if moved below or reformatted."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OkcjTJQNwE", "forum": "JnhahbMvRE", "replyto": "JnhahbMvRE", "signatures": ["ICLR.cc/2026/Conference/Submission12856/Reviewer_9MNG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12856/Reviewer_9MNG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722997535, "cdate": 1761722997535, "tmdate": 1762923648811, "mdate": 1762923648811, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Hierarchical Balancing Optimization for fine-tuning large language models (LLMs) on diverse datasets by addressing both global and local data imbalance and heterogeneity. HBO uses a bilevel optimization framework with two types of actors: a Global Actor, which adjusts data allocation across different datasets, and Local Actors, which optimize data usage within individual datasets based on difficulty levels. Extensive experiments show that HBO consistently outperforms existing methods, offering significant improvements in model performance. The proposed method provides a comprehensive solution to the challenges of data imbalance and heterogeneity during fine-tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) HBO effectively addresses both global and local data imbalances, providing a more comprehensive solution to the challenges of fine-tuning LLMs on diverse datasets.\n\n2) The bilevel optimization framework with Global and Local Actors allows for fine-grained control over data sampling, leading to improved model performance across various tasks.\n\n3) Extensive experiments demonstrate HBO's strong applicability across multiple LLM backbones and tasks, consistently outperforming existing baselines and offering superior accuracy gains."}, "weaknesses": {"value": "1) My main concern is the proposed method adds more computations based on MoS. The reinforcement learning framework, as well as some reward, is similar to the MoS method. This work adds more actors and the grad norm reward, more insights of this field could be added.\n\n2) This paper primarily compares three sampling balancing methods: MoS, MultiUAT, and MultiDDS. However, many of the results are similar to uniform sampling. What is the next step of this field could be discussed."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "j9SZt2qVOP", "forum": "JnhahbMvRE", "replyto": "JnhahbMvRE", "signatures": ["ICLR.cc/2026/Conference/Submission12856/Reviewer_dqCa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12856/Reviewer_dqCa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996199176, "cdate": 1761996199176, "tmdate": 1762923648530, "mdate": 1762923648530, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}