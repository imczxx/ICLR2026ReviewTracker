{"id": "vT2511wojJ", "number": 13392, "cdate": 1758217313011, "mdate": 1759897440712, "content": {"title": "Openhelix: Empirical Analysis of Dual-System VLA Models for Robotic Manipulation", "abstract": "Dual-system vision-language-action (VLA) architectures are emerging as a promising approach in embodied intelligence. However, current works lack consistency in training and evaluation protocols across high- and low-level modules, making systematic comparison and rigorous analysis challenging. In this work, we conduct a comprehensive study of core design principles in existing dual-system VLA architectures and introduce DSVLABench, a new suite that covers diverse evaluation scenarios and standardizes the assessment pipeline for various architectures. Our results show that prompt tuning preserves multimodal large language model generalization, fine-tuning from pre-trained policies outperforms training from scratch in policy learning, and pre-aligning projectors with auxiliary dynamic visual tasks significantly enhances latent space training. Additionally, we find that the frequency of high-level updates has minimal impact during asynchronous inference, with latent embeddings remaining robust to dynamic changes. We hope our findings provide practical guidelines for developing more generalizable and robust dual-system VLA models.", "tldr": "", "keywords": ["VLA; Dual system; Dynamic Scenarios"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c5244683fe0028dc62f56cc64a4a318b5e575622.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper “OpenHelix: Empirical Analysis of Dual-System VLA Models for Robotic Manipulation” presents a comprehensive empirical study of dual-system vision-language-action (VLA) architectures, which combine a high-level multimodal large language model (MLLM; System 2) and a low-level reactive policy (System 1). The authors propose a unified evaluation suite called DSVLABench, covering both static (CALVIN-E) and dynamic (CALVIN-D) robotic manipulation benchmarks.\nThrough controlled experiments, they explore five key questions: (1) the necessity of true dual-system designs, (2) best training strategies for the MLLM, (3) best training strategies for the low-level policy, (4) the importance of latent projector pre-alignment, and (5) the effects of asynchronous inference.\nKey findings include that prompt tuning preserves MLLM generalization while improving coordination, fine-tuning pre-trained policies outperforms training from scratch, and pre-aligned projectors are essential for stable latent communication. Interestingly, they observe that asynchronous update frequency between the two systems barely affects performance. Building on these insights, the paper introduces OpenHelix, a simple but effective dual-system model that achieves state-of-the-art results on CALVIN benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper conducts one of the most thorough empirical studies of dual-system VLA models to date, carefully standardizing training and evaluation conditions. The DSVLABench suite provides a valuable resource for future comparisons and ensures reproducibility.\n\n- The ablation studies convincingly identify what matters in these architectures—showing, for instance, that prompt tuning retains generalization, projector pre-alignment is crucial, and pretrained policies dramatically accelerate convergence. These practical insights are highly useful to the community.\n\n- The extended CALVIN-E (language diversity) and CALVIN-D (dynamic object motion) benchmarks represent meaningful contributions that test both semantic generalization and real-time adaptability—two core challenges in embodied learning.\n\n- Despite using a straightforward architecture, OpenHelix achieves state-of-the-art results, surpassing complex prior models (e.g., Robodual, Seer) on multiple metrics. This validates the paper’s claim that design consistency and modular coordination can outperform architectural complexity."}, "weaknesses": {"value": "- While the empirical findings are robust, the methodological contribution (OpenHelix) mainly aggregates established best practices. There is little theoretical insight into why prompt tuning and asynchronous inference behave as observed, and the “dual-system” framing draws heavily from prior works like DP-VLA and LCB.\n\n- All experiments are conducted in simulation (CALVIN environments). Given the paper’s emphasis on real-time inference and dynamic adaptation, demonstrating transfer to real hardware would have significantly strengthened the claims.\n\n- The discovery that asynchronous inference frequency has minimal impact is intriguing but insufficiently analyzed. It raises questions about whether the high-level embeddings are too static or the MLLM insufficiently sensitive to evolving visual context.\n\n- Some aspects of DSVLABench overlap with prior frameworks like RoboBench or RT-X comparisons. The novelty lies more in consolidation than in conceptual or algorithmic innovation."}, "questions": {"value": "- Could the negligible impact of asynchronous inference suggest that System 2’s latent token is semantically static? Have you measured the variance of latent embeddings across steps?\n\n- How scalable is the proposed setup when using larger backbones (e.g., Qwen2-VL-7B instead of LLaVA-7B)?\n\n- Would integrating explicit feedback from System 1 (e.g., action outcome or success cues) into System 2 improve adaptability in dynamic settings?\n\n- Are there observed limitations when prompt tuning is applied to MLLMs pretrained with different modality alignments (e.g., OpenVLA vs Qwen2-VL)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CHl2flbp5m", "forum": "vT2511wojJ", "replyto": "vT2511wojJ", "signatures": ["ICLR.cc/2026/Conference/Submission13392/Reviewer_oK3Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13392/Reviewer_oK3Z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761513718325, "cdate": 1761513718325, "tmdate": 1762924028800, "mdate": 1762924028800, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel dual-system VLA architecture and introduces a benchmark called DSVLABench, designed to systematically evaluate and compare different VLA architectures. The authors experimentally validate the effective collaboration between the high-level language model and the low-level control policy, and propose an innovative training method (prompt tuning), to enhance the model's generalization ability. Experimental results demonstrate that the proposed OpenHelix model performs excellently in multimodal reasoning tasks, showing superior performance compared to other models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors introduce the DSVLABench benchmark, providing a standardized platform for the comparison and evaluation of VLA architectures, filling the gap in the evaluation framework within this field. They also introduce the strategy of prompt tuning, which effectively enhances the generalization ability of the high-level language model, particularly in cross-modal tasks involving vision and language.\n- Despite its simple structure, the proposed OpenHelix model has been systematically evaluated and compared with other dual-system VLA architectures on the CALVIN benchmark. Experimental results demonstrate its outstanding performance in task success rate, highlighting its efficiency."}, "weaknesses": {"value": "- Although the paper shows good results in simulation environments, it lacks validation of the model’s application in the real world, which affects its generalizability and practicality in real-world scenarios.\n- While the paper focuses on the integration of the high-level language model and low-level control strategy, as well as the performance of the high-level language model, it provides limited in-depth discussion on the low-level control strategy, especially regarding its performance and optimization in different application scenarios, which requires further exploration.\n- Although the paper compares the performance of different models, it lacks a detailed analysis of how the selection of training data and optimization strategies specifically impact the final results."}, "questions": {"value": "- In real-world scenarios, how adaptable and flexible are the low-level control strategies? In the real and complex real world, does the model have sufficient generalization ability? \n- The experiments in the paper mainly focus on comparative tests in the simulation environment, but lack comprehensive evaluations under different datasets and task scenarios. Could more abundant experimental Settings be provided further to test the generalization ability and robustness of the model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "k2gV9ODAac", "forum": "vT2511wojJ", "replyto": "vT2511wojJ", "signatures": ["ICLR.cc/2026/Conference/Submission13392/Reviewer_9bia"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13392/Reviewer_9bia"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904903516, "cdate": 1761904903516, "tmdate": 1762924028379, "mdate": 1762924028379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an empirical study of various design decisions for dual-system vision-language-action models, given the recent rise in their popularity and large variation in their designs among latest works (which make it difficult to perform controlled comparisons between them). The paper introduces two new benchmarks that are built on top of the existing CALVIN simulation benchmark: CALVIN-E (which assesses high-level semantic understanding, by testing generalization to new language commands) and CALVIN-D (which assesses coordination between the two systems in dual-system VLAs and reactivity to dynamic scenarios). These benchmarks are included in the proposed DSVLABench, which examines five key aspects of dual-system VLAs and provides a systematic comparison of different design decisions. The results of the empirical study lead to five insights related to effects of various components of dual-system VLAs, such as the dual-system architecture, the usefulness of auxiliary training tasks, and the frequency of high-level updates during asynchronous dual-system inference."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper conducts a large quantity of experiments, which lead to useful insights about which techniques are necessary or helpful when training dual-system VLAs. The discussions in Section 5.4 and Section 5.5 are particularly interesting, as they reveal that the projector training strategy is crucial when training the dual-system VLA on CALVIN, and that the policy is robust to infrequent high-level updates from the MLLM during evaluations in dynamic tasks.\n* The paper introduces two new evaluation suites, CALVIN-D and CALVIN-E, which test robustness to dynamic changes in object position and new language instructions.\n* The paper systematically studies individual components in the design of a dual-system VLA policy with various ablations to highlight their effects on policy performance.\n* The paper is generally well written and easy to follow."}, "weaknesses": {"value": "* Section 5.1 seems to be missing important details. For example, there is no discussion on \"3DDA Ke et al. (2024)\" in Table 1, and it is unclear to the reader how this method is evaluated and why it performs much better than the \"pseudo dual-system\" VLA RoboFlamingo. Elaboration on this comparison would greatly aid the reader. Also, it is not clear to me why pseudo dual-system VLAs necessarily fail in dynamic tasks like the ones used in the proposed CALVIN-D test suite. What happens if the policies are queried much more frequently and action chunks are only partially executed so that the policies are more reactive? Relatedly, what are the querying frequency and action chunk sizes for the two methods tested in Table 1? Further, while the paper comments on the lack of fair comparisons due to the variation in designs of dual-system VLAs, the comparison in Table 1 does not seem like a controlled comparison either, as entirely different architectures and algorithms are used.\n* In Section 5.2, while the proposed techniques such as CLIP loss and prompt tuning individually show improvements over other variants, this comparison is conducted with one particular type of MLLM architecture in one particular benchmark, and I have concerns about whether the findings generalize broadly. Therefore, the authors' conclusion that \"prompt tuning is an effective strategy for balancing adaptability and generalization in dual-system VLA models\" seems too broad and should be qualified. In my opinion, a general claim like this should be supported by multiple pieces of evidence, such as similar findings across more than one architecture/model and more than one task suite. This is especially the case because it is not obvious that, e.g., freezing the MLLM backbone and just doing prompt tuning is a technique that will scale to other task suites (for example, what if this strategy shows limited capacity for fine-tuning at larger dataset scales?). Also, why does prompt tuning lead to worse performance on the base CALVIN suite (3.45) than fine-tuning with CLIP loss (3.53)?\n* Fine-tuning outperforming training from scratch in Section 5.3 is not a novel finding in VLA works and is a fairly established understanding at this point. For example, the OpenVLA paper by Kim et al. (CoRL 2024) discusses this already.\n* \"OpenHelix\" is not presented in the main text until Section 6, and it is not clear how it is defined. (It does appear in Figure 1 but without a concrete definition). It would be good to explain what exactly this name refers to, and present it earlier on in the paper.\n* Several state-of-the-art prior works are omitted in the CALVIN ABC->D comparisons, including UniVLA (Bu et al., RSS 2025) which gets an average length of 4.41 and Seer-Large (Tian et al., ICLR 2025) which gets 4.28. Why these are not included in the comparisons warrants discussion.\n* All of the comparisons are done in the CALVIN simulation benchmark, which adds uncertainty as to whether the findings hold across other benchmarks/tasks. Similar findings in other benchmarks/tasks would strengthen the paper.\n\nMinor:\n* The usage of `\\citet{}` and `\\citep{}` is not correct throughout the paper and the lack of punctuation around citations is distracting to the reader. For example, in the first sentence of the introduction, there are missing parentheses around the cited vision-language-action model works.\n* \"Roboflmanigo\" typo appears multiple times in the paper."}, "questions": {"value": "See questions in the Weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ehz1bG9miv", "forum": "vT2511wojJ", "replyto": "vT2511wojJ", "signatures": ["ICLR.cc/2026/Conference/Submission13392/Reviewer_Bsn4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13392/Reviewer_Bsn4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970854912, "cdate": 1761970854912, "tmdate": 1762924028069, "mdate": 1762924028069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates dual-system VLA architectures, where a high-level multimodal large language model (System 2) operates asynchronously with a low-level control policy (System 1). The authors present OpenHelix, an empirical framework analyzing different training strategies on the CALVIN benchmark."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The research problem is important: dual-system design addresses the critical trade-off between performance and efficiency in real-time robotic control."}, "weaknesses": {"value": "- Classification of pseudo dual systems\n   The paper classifies π₀ and GR00TN1 as pseudo dual systems because “their action experts do not receive real-time perceptual feedback.”  \n   However, according to their original papers:  \n   - π₀ operates in a *closed-loop* fashion, though without explicit asynchronous scheduling.  \n   - GR00TN1’s System 2 reportedly runs at around 10 Hz feedback frequency.  \nWhile these may not be fully asynchronous dual systems, this classification alone does not necessarily imply high time latency. To make the argument more rigorous, it would be helpful to include **quantitative latency and success rate** to justify dual system has low time latency while keep high performance. Simply assigning this label without testing might overlook the fact that some closed-loop single-system architectures already maintain reasonably low-latency feedback.\n\n- The experiments would benefit from additional real-world validation.  \n  Since the paper’s motivation emphasizes *real-time deployment*, including results from a physical robot setup or latency profiling would make the findings more persuasive and practically relevant.\n\n- The overall experimental design could be guided by a clearer unifying objective.  It remains somewhat unclear why the dual-system structure is fundamentally needed, and which specific components should be updated to achieve better performance.\n\n- The comparison scope might be further expanded.  \n  In particular, Q1 could include stronger closed-loop single-system baselines such as **RobotVLM** or other online perception-action models, rather than focusing mainly on pseudo dual systems (RoboFlamingo, π₀, GR00TN1).\n\n- The paper currently does not analyze time latency or efficiency trade-offs in depth.  Since asynchronous real-time performance is one of the main motivations, a latency comparison between single- and dual-system VLAs would significantly strengthen the empirical argument."}, "questions": {"value": "On the claim that “without pre-alignment the model completely fails” This is a strong assertion.  Many recent VLM-based robotic policies (e.g., OpenVLA, Pi0) can be trained end-to-end without explicit pre-alignment modules.  Why does OpenHelix require pre-alignment so critically?  A deeper explanation or ablation could make this claim more convincing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XI2Pp4Kw2g", "forum": "vT2511wojJ", "replyto": "vT2511wojJ", "signatures": ["ICLR.cc/2026/Conference/Submission13392/Reviewer_v8Uw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13392/Reviewer_v8Uw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762097506740, "cdate": 1762097506740, "tmdate": 1762924027684, "mdate": 1762924027684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}