{"id": "YGUKPGO182", "number": 7485, "cdate": 1758024168870, "mdate": 1759897849940, "content": {"title": "Speech World Model: Causal State–Action Planning with Explicit Reasoning for Speech", "abstract": "Current speech-language models (SLMs) typically use a cascade of speech encoder and large language model, treating speech understanding as a single black box. They analyze the content of speech well but reason weakly about other aspects, especially under sparse supervision. Thus, we argue for explicit reasoning over speech states and actions with modular and transparent decisions. Inspired by cognitive science we adopt a modular perspective and a world model view in which the system learns forward dynamics over latent states. We factorize speech understanding into four modules that communicate through a causal graph, establishing a cognitive state search space. Guided by posterior traces from this space, an instruction-tuned language model produces a concise causal analysis and a user-facing response, enabling counterfactual interventions and interpretability under partial supervision. We present the first graph based modular speech model for explicit reasoning and we will open source the model and data to promote the development of advanced speech understanding.", "tldr": "", "keywords": ["speech", "spoken language understanding", "state-action", "causal reasoning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0045fde9c8de056c2584fc272276773fd5590166.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a Speech World Model that enables explicit reasoning over speech states. It defines a four-node  DAG (WMA, ToM, SA, Prag) whose topology is fixed from cognitive science; the mechanisms are learned via neural classifiers over speech/text features and parent states The graph’s inferred states are (i) serialized to instruction-tune a text LLM and (ii) fed directly to a multimodal SLM. The proposed learning method operates in both a semi-supervised and a fully supervised manner, improving data efficiency where annotations across modules are sparse. Evaluation is split into two axes: a) Quality of the estimated graph, and b) Speech understanding and reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n- This paper proposes a causality-inspired method where the underlying causal graph is built from expert knowledge. This is an approach that more papers could follow.\n- The paper is terse but well-written.\n- Explicit, interpretable reasoning over speech states is novel and useful.\n- Solid conceptual grounding; edge-level analysis and ablations are appreciated."}, "weaknesses": {"value": "- Label generation with no human oversight casts uncertainty on the quality of the labels.\n- The label-imputation pipeline is under-specified in the main text.\n- Section 3 is particularly hard to follow; a running example would help.\n- Section 4 feels disconnected: redundancy/last-paragraph argument is unclear and Eq. (9) (CMC) belongs earlier.\n- Evaluation relies on a single LLM judge.\n- Results often mix gold and imputed labels, conflating model learning with label quality.\n- Causal scope is unclear: interventions (and ACE/ICS) are performed on model-internal states."}, "questions": {"value": "- Equation (4) seems to be doing what I would call “stochastic teacher forcing”. I am a bit lost by the motivation and the need for this. Can you elaborate?\n- Why only one judge for LLM-as-judge? Please add more judges and report win-rates and agreements, given known style biases of LLM judges [1].\n- Can you also report results on true labels only? The current setup may conflate the performance of the imputation and the overall performance as some labels are generated while others aren’t.\n- Please evaluate your imputation by masking gold labels at random, using your imputation procedure to recover them and evaluating accuracy/macro-F1.\n- Check multimodal causal-faithfulness: flip a single parent state in the graph serialization passed to the multimodal generator; extract the child state from the response and check movement in the predicted direction. Include negative controls by flipping a non-parent.\n- The label imputation paragraph should be explained in more detail in the main text.\n- Claims on learning speed should move to the main text with seeded means+std and wall-clock details.\n- Clarify whether causal claims target the data-generating process or the learned representation.\n\nMinor:\n- Figure 2: Instcution->Instruction\n- The type of the causal variables is not explicitly defined in the main text and has to be inferred from the rest of the text.\n- Make tables self-contained: state which datasets feed which rows/metrics.\n- L416-417: Can you elaborate on the instability of Random Graph?\n\n[1] Benjamin Feuer, Micah Goldblum, Teresa Datta, Sanjana Nambiar, Raz Besaleli, Samuel Dooley, Max Cembalest, & John P Dickerson (2025). Style Outweighs Substance: Failure Modes of LLM Judges in Alignment Benchmarking. In The Thirteenth International Conference on Learning Representations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Ur0jn8PyDG", "forum": "YGUKPGO182", "replyto": "YGUKPGO182", "signatures": ["ICLR.cc/2026/Conference/Submission7485/Reviewer_eLqM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7485/Reviewer_eLqM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845429292, "cdate": 1761845429292, "tmdate": 1762919601803, "mdate": 1762919601803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Speech World Model (SWM) that explicitly models causal relationships among four key components of speech understanding: World Model Activation (WMA), Theory of Mind (ToM), Speech Act (SA), and Pragmatic Intent (Prag). The model builds a causal graph connecting these modules and uses the inferred latent cognitive states to guide a language world model for reasoning and response generation. To handle incomplete supervision, the framework employs semi-supervised learning, allowing unlabeled nodes to benefit from gradients propagated through causal dependencies. Experimental results show that the proposed causal structure improves node inference accuracy under sparse labels, enhances reasoning performance compared with open-source baselines, and achieves these results with significantly lower training cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. While prior work has explored explicit modeling of context or theory of mind, this paper uniquely integrates them into a causally grounded framework that links perceptual and pragmatic dimensions of speech. The structured reasoning graph offers interpretability and aligns with cognitive principles of human speech understanding.\n\n2. The causal dependencies enable effective gradient flow even when some states are unlabeled, improving learning efficiency and robustness compared with fully independent module training."}, "weaknesses": {"value": "1. It would strengthen the paper to include experiments that isolate the benefit of the causal graph itself—for example, by training all four modules independently or removing all edges—and then feeding these disconnected representations into the language model. This would help quantify how much causal reasoning contributes to downstream reasoning and response quality.\n\n2. The current graph structure is manually predefined based on cognitive intuition rather than learned from data. While this design is interpretable, it may limit adaptability to new domains or cultural variations in communicative patterns. Exploring learnable or adaptive causal graphs could make the model more generalizable.\n\n3. The label completion and reasoning–response generation pipeline relies heavily on pseudo-labels generated by large language models (Vicuna, GPT-4o). An analysis of label accuracy or a comparison with human annotations would clarify how this synthetic supervision affects model reliability."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fv9PRTDpnz", "forum": "YGUKPGO182", "replyto": "YGUKPGO182", "signatures": ["ICLR.cc/2026/Conference/Submission7485/Reviewer_xGU2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7485/Reviewer_xGU2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955927349, "cdate": 1761955927349, "tmdate": 1762919600853, "mdate": 1762919600853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces speech world model, a structured formalism that factorizes speech understanding into four modules that communicate through a causal graph. Instruction-tuned languages models can provide better reasoning and response guided by posterior traces from the proposed formalism. The authors show empirical validation for their approach on several speech datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper has an interesting framing. It recognizes that speech understanding with language model still has large room for improvement, and it proposes to use a structured and theoretically grounded framework to improve speech understanding. The notion of world models makes sense.\n- The authors experimentally show that the causal graph matters (Table 1 and 2) and SMW significantly improves the performance of LLMs (Table 3). Experiments are done with several different datasets, providing evidence for generality of the approach.\n- This paper tackles a problem that has considerable real-world relevance."}, "weaknesses": {"value": "- The literature review in this paper is highly unsatisfactory. Theory of Mind, Speech Act, and Pragmatic Intent all have long traditions in cognitive science and linguistics. Yet the authors only primarily cite one work for each, and the selection is a bit ad-hoc. Why not cite the classic papers? Also, for example, Theory of Mind with LLMs alone is a popular topic in the past few years, but that is not reflected in the paper. Overall, I think the authors should conduct a more thorough review of related work; otherwise I do not think this is at publication standard.\n- Similarly, for concepts around world models and cognitive science, I recommend checking out [1] and references therein. It offers a perspective on cognitive world models that supports what this work aims to do, so engaging with that line of research would support this work.\n- How did the authors decide on the combination of WMA, ToM, SA, Prag? Why not more or less? Why these four in particular? These choices need more arguments/justifications. I think there are ways to justify them---currently just saying \"We define four key modules...\" is not enough.\n- I would appreciate more concrete examples on why the proposed approach works (which can go into the appendix). Figure 1 and 2 are helpful, but I think a reader would like to get more intuitions and concrete case study/analysis.\n\n[1] Ullman, T. D., & Tenenbaum, J. B. (2020). Bayesian models of conceptual development: Learning as building models of the world. Annual Review of Developmental Psychology, 2(1), 533-558."}, "questions": {"value": "Writing suggestions: \n- On Page 7, Sec. 5 and subsections 5.1 and 5.11 are next to each other without any text. And 5.11 begins with bullet points. These patterns are not the best practices for scholarly writing. Consider adding guiding text/sentences for clarity.\n- Also on Page 7, why citing \"Tree of Thoughts\" when you only talk about CoT (Line 348). I suggest that the authors carefully verify their citations in this work.\n- Currently, the paper leaves little room for discussion. I would recommend moving a bit of the technical details to the appendix and include more discussions/interpretations/limitations at the end. As of now it feels that the paper ends abruptly.\n- Some of the figures/tables could benefit from more detailed captions. For example, Table 3 is supposed to be a main result table, but it only has a 1-sentence caption. It would be better if it briefly explains/reminds the reader of what some of the important columns mean."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mVg0bOtqFX", "forum": "YGUKPGO182", "replyto": "YGUKPGO182", "signatures": ["ICLR.cc/2026/Conference/Submission7485/Reviewer_FHEH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7485/Reviewer_FHEH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762710370447, "cdate": 1762710370447, "tmdate": 1762919599991, "mdate": 1762919599991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}