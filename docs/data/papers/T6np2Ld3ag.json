{"id": "T6np2Ld3ag", "number": 4571, "cdate": 1757709124377, "mdate": 1759898025909, "content": {"title": "Fine-grained Token Allocation Via Operation Pruning for Efficient MLLMs", "abstract": "Token reduction accelerates Multimodal Large Language Models (MLLMs) by reducing excessive tokens, but overlooks structural redundancy differences where critical and redundant modules process identical token loads. \nFor fine-grained computation control, we define an ``operation\" as the computation for a module to process a group of tokens and introduce the operation pruning framework to enable modules to selectively process tokens.\nBuilt on this framework, we propose \\textbf{D}epth-wise \\textbf{O}peration \\textbf{P}runing (\\textbf{DOP}), a data-driven method that searches for strategies to prune redundant operations and save computational budget for critical modules to process more tokens than uniform allocation by minimizing divergence from the original model's output probability distribution on a small validation set while satisfying computational constraints. For efficient optimization, DOP applies depth-wise pruning to reduce policy space and uses an additive approximation to minimize required validation runs.\nDepth-wise pruning partitions operations by module type and token group, and prunes operations in deeper layers before those in shallower layers within each module-group pair. The additive approximation obtains individual divergences by independently varying each policy parameter, then sums them to approximate the joint divergence of simultaneously changing all policy parameters, reducing required validation runs from exponential to linear with respect to the number of policy parameters. Comprehensive evaluations show that DOP establishes new state-of-the-art performance across 6 MLLMs and 13 benchmarks against 12 baselines. On LLaVA-Next-7B, DOP achieves 86\\% TFLOPS reduction and 83\\% latency reduction on real GPU with only 1\\% performance loss. Our extensive ablation studies further demonstrate DOP's data and time efficiency as well as strong generalization capabilities.", "tldr": "", "keywords": ["Token Pruning", "Efficient MLLM"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8bf199a8602d6ce81eb4215da096db1fe9c13950.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the token computation allocation problem in multimodal large models across three dimensions: tokens, model depth, and computational modules. It proposes DOP, a token pruning method (can be considered as token early exiting). To reduce the size of the strategy design space, this paper introduces an Additive Approximation approach, which effectively reduces the complexity of divergence evaluation. Furthermore, sparse sampling with interpolation is adopted to reduce the final strategy search complexity, enabling the algorithm to complete with only a small calibration set and limited search time. The experimental section is comprehensive, evaluating multimodal large models with different architectures and scales across multiple benchmarks and comparative methods, demonstrating the effectiveness of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper proposes several improvements addressing aspects such as strategy search complexity and data dependency. The resulting algorithm achieves low computational complexity and requires only a minimal calibration set.\n* Searching different exiting point for {attn, mlp} is interesting.\n* The paper provides comprehensive experiments, validating the algorithm's generalizability across multimodal large models with diverse architectures and scales."}, "weaknesses": {"value": "* Limited overall novelty. The core contribution--allocating computation for tokens along the depth dimension--is closely related to existing ideas of token-level early exit and dynamic computation allocation. Similarly, the decoupling of {attn, mlp} modules has also been explored in prior work on dynamic computation allocation. Here lists some works:\n\n1. [ICLR 25] Routing Experts: Learning to Route Dynamic Experts in Multi-modal Large Language Models. It learns to dynamically skip some layer for <Q, A> pair tokens, achieves depth flexibility, which can also be applied to visual tokens.\n2. [ACL 21] Accelerating BERT Inference for Sequence Labeling via Early-Exit. It learns token-level early-exit policy for inference acceleration. Its search strategy differs from that of this paper, but their core objectives are consistent.\n3. [ICML 25] SkipGPT: Dynamic Layer Pruning Reinvented with Token Awareness and Module Decoupling. Token-level dynamic computation allocation with decoupled modules, i.e. attn/mlp.\n\n* I think the paper appears to overestimate the complexity of the original search space (Sec. 3.1 - policy space size). In general, token pruning can be categorized as: (1) One-shot pruning: Redundant tokens are filtered out based on importance before being processed by the large model. (2) Early exit: The system decides during the forward pass at which layer a token should exit, after which it undergoes no further computation.(3) Dynamic computation allocation: Before each computational unit, a decision is made independently on whether to execute the current unit for the token. Unlike early exit, a token that \"exiting\" for one unit may still be executed in the next. In my view, the method in this paper falls into category (2), early exit, with a search space of $2 \\times L \\times N$ (finding an exit point for each token in both the attn and mlp modules across $L=32$ layers). In contrast, the search space for the  dynamic computation allocation in category (3) would be $2^{(2L)} \\times N$.\n\n\n* Need additional evidence. In Sec.3.2.1, the authors claim that: ‘we observe that for the same group-module type (g, m), a deeper operation (g, l2, m) remains generally more redundant than a shallower operation (g, l1, m) with $l2 > l1’$. However, no experimental evidence or cites are included. I think it is a crucial observation for the designing of method, i.e., if deeper operations are more redundant, then token early-exit (type 2) is sufficient, re-use token (type 3) in deeper layers is unnecessary."}, "questions": {"value": "Although the authors empirically demonstrate a high correlation coefficient between the estimated divergence and the joint divergence when used as a ranking criterion, I remain interested in the error of the Additive Approximation. It would be very informative to see: how large is the gap between the strategies searched using the approximated divergence versus the true joint divergence (can be examined in smaller-scale scenarios, e.g., with smaller MLLM and less data)? Furthermore, what would be the corresponding impact on downstream task performance? I believe the paper would be strengthened by including such an ablation study."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5eB0Kc7gBH", "forum": "T6np2Ld3ag", "replyto": "T6np2Ld3ag", "signatures": ["ICLR.cc/2026/Conference/Submission4571/Reviewer_ZZ6f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4571/Reviewer_ZZ6f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4571/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760585387057, "cdate": 1760585387057, "tmdate": 1762917447875, "mdate": 1762917447875, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Depth-wise Operation Pruning (DOP), a fine-grained token allocation framework for accelerating Multimodal Large Language Models (MLLMs). DOP defines an \"operation\" as the computation of a specific module processing a group of tokens and enables different modules to process varying numbers of visual tokens, moving beyond uniform token reduction. It is a data-driven method that optimizes a pruning policy by minimizing the KL divergence from the original model's output distribution under a computational budget. To ensure efficiency, DOP employs depth-wise pruning constraints and an additive approximation to drastically reduce the policy search space and validation cost. Experiments show that DOP outperforms existing token pruning baselines across multiple MLLMs and benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles the critical problem of MLLM inference efficiency with a conceptually clear and technically sound approach. The shift from \"token-level\" to \"operation-level\" pruning is a well-motivated extension of the existing paradigm, offering finer-grained control with clear theoretical and practical value. The optimization strategy—combining depth-wise constraints with additive approximation—is cleverly designed to balance performance and efficiency, making DOP feasible for real-world deployment. The evaluation is comprehensive, covering 6 prominent MLLMs and 13 benchmarks, and includes real GPU latency measurements, lending strong credibility to the results."}, "weaknesses": {"value": "1. The paper fails to adequately discuss or compare against recent works that also focus on \"operation pruning,\" notably GSOP [1], Short-LVLM [2], and Skip-Vision [3]. These works similarly aim to accelerate models by pruning internal operations rather than just tokens, yet they are omitted from both the Related Work and experiments. This omission weakens the paper's novelty claim. The authors should clearly articulate the core methodological differences between DOP and GSOP (e.g., DOP's depth-wise policy vs. GSOP's greedy sorting) and include direct experimental comparisons.\n\n2. The potential of DOP is not sufficiently explored, as follows: \n\n- (a) All experiments are confined to static image VQA tasks, with no evaluation on caption tasks like Nocaps and TextCaps or video understanding tasks like VideoMME or MLVU. Given the inherent redundancy in video data and the fact that recent works (e.g., VisPruner, CDPruner) have validated their methods on video tasks, demonstrating DOP's efficacy in video domain is crucial. \n- (b) DOP is only applied to the LLM decoder, ignoring the computationally expensive visual encoder (e.g., ViT), which is a major bottleneck for high-resolution image and video understanding. \n- (c) The paper does not investigate DOP's applicability to pure long-context text tasks (e.g., LongBench, RULER), limiting the demonstration of its generalizability.\n\n3. For Qwen2.5-VL, the authors only report results using input resizing as the underlying token reduction method. In contrast, for LLaVA-NeXT and InternVL3, they evaluate DOP with multiple token compression strategies (e.g., VisPruner, CDPruner). To ensure fair and comprehensive assessment, the authors should at least include one experiment on Qwen2.5-VL combining DOP with a state-of-the-art token pruning method like CDPruner.\n\n4. The paper does not provide any visualization of how DOP dynamically skips computations across different benchmarks or models. For instance, showing which layers or modules are pruned under DOP for Qwen2.5-VL on tasks like TextVQA versus MME would greatly enhance interpretability and help readers intuitively understand the adaptive nature of the proposed strategy.\n\n5. The depth-wise pruning constraint is central to DOP’s efficiency, yet the paper justifies it only with the empirical observation that “deeper layers are typically more redundant in LLMs”, which is insufficient. The authors should provide stronger theoretical or empirical support for why pruning all operations beyond a fixed depth per module type is a valid and near-optimal assumption. As presented in Figure 2 (b), the DOP Rules appear as an unverified design choice; without ablation against more flexible strategies (e.g., non-consecutive layer pruning), this key simplification lacks credible justification.\n\n[1] Beyond Token Pruning: Operation Pruning in Vision-Language Models. arXiv 2025.\n\n[2] Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping. ICCV 2025.\n\n[3] Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers. ACM MM 2025."}, "questions": {"value": "1. Could the authors clarify the core methodological differences between DOP and recent works like GSOP and Skip-Vision, and please include experimental comparisons with these methods?\n\n2. Why is DOP only applied to the LLM decoder and not to the computationally intensive visual encoder (e.g., ViT)?\n\n3. Can the authors provide experimental results for DOP on video understanding benchmarks (e.g., using Qwen2.5-VL on VideoMME) and pure long-context text benchmarks (e.g., LongBench)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HDDLDtgjnR", "forum": "T6np2Ld3ag", "replyto": "T6np2Ld3ag", "signatures": ["ICLR.cc/2026/Conference/Submission4571/Reviewer_aoQh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4571/Reviewer_aoQh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4571/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761476723046, "cdate": 1761476723046, "tmdate": 1762917447355, "mdate": 1762917447355, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the Depth-wise Operation Pruning (DOP) framework, designed to improve the inference efficiency of Multimodal Large Language Models (MLLMs). DOP breaks the computation process into small “operations” and focuses on reducing structural redundancy that traditional token-pruning methods often miss. By applying MHA/MLP depth decoupling and a depth-wise continuous pruning strategy, it turns a difficult policy search problem into a much simpler optimization task with only three parameters: $(\\mathbf{D_A}, \\mathbf{D_P}, \\mathbf{n_v})$. Experiments on many MLLM models show that DOP delivers strong performance and clear efficiency gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Through depth-wise pruning constraints and additive approximation, the complex optimization problem becomes highly efficient to solve.\n2. The experimental validation is strong. The method is tested on diverse MLLMs (LLaVA, Qwen, InternVL) and 13 benchmarks, with comparisons against recent baselines. Using fixed TFLOPs budgets ensures fair evaluation."}, "weaknesses": {"value": "1.\tThe method relies on two strong simplifying assumptions—monotonic depth redundancy and additive independence across $\\mathbf{D_A}$, $\\mathbf{D_P}$, and $\\mathbf{n_v}$—which may not always hold, as deeper layers are not necessarily more redundant for all tasks. This can limit the method’s ability to reach the global optimum and lead to suboptimal strategies in certain scenarios.\n2.\tThe performance of DPO is highly sensitive to the validation set used for optimization, and strategies optimized on one task or data distribution may not generalize well to others."}, "questions": {"value": "1.\tPlease see the weakness above.\n2.\tThe evaluation benchmarks mainly focus on short-answer VQA tasks. How might DOP perform on multimodal tasks that require either short- or long-form generation, such as detailed image analysis or story generation? Could aggressively pruning visual operations in deeper layers prematurely remove the visual grounding necessary to maintain factual consistency throughout a longer narrative?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HmTfePk61b", "forum": "T6np2Ld3ag", "replyto": "T6np2Ld3ag", "signatures": ["ICLR.cc/2026/Conference/Submission4571/Reviewer_DwzN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4571/Reviewer_DwzN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4571/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923702677, "cdate": 1761923702677, "tmdate": 1762917447055, "mdate": 1762917447055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **Depth-wise Operation Pruning (DOP)**, an operation-level pruning strategy for MLLMs that claims finer control than token pruning. The method prunes redundant operations (defined as module–token computations) using two heuristics: (1) depth-wise layer pruning and (2) additive divergence approximation for efficient search. Experiments on six MLLMs across 13 benchmarks show large FLOPs savings with minimal performance loss."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Addresses an important and timely efficiency problem in multimodal LLMs.\n\n* The method is simple, easy to integrate, and empirically effective across different architectures.\n\n* Extensive experimental coverage with clear ablations and latency analysis."}, "weaknesses": {"value": "* **Incremental novelty:** The idea of pruning at finer granularity is not fundamentally new; the contribution is mostly heuristic refinements (depth ordering + additive scoring).\n\n* **Limited theoretical insight:** The additive approximation is empirical, with no formal justification or guarantees; the correlation analysis is weak evidence for correctness.\n\n* **Heavy reliance on validation heuristics:** The optimization objective (KL divergence on a small validation set) may not correlate well with downstream task performance; no robustness or sensitivity analysis is provided.\n\n * **Selective scope:** Despite framing as general “operation pruning,” the paper only applies it to visual tokens; this weakens the generality claim.\n\n* **Unclear comparison fairness:** Some baselines (e.g., progressive pruning) are not re-tuned under identical FLOPs constraints. It’s unclear whether hyperparameters were optimized equally.\n\n * **Overemphasis on numbers:** The main results show marginal performance differences compared to strong baselines like CDPruner; the claimed 7\\% gain seems dataset-specific.\n\n * **Ablations lack depth:** No analysis of failure cases, gradient sensitivity, or interplay between MHA vs. MLP pruning depth."}, "questions": {"value": "The work would benefit from a deeper analysis of why DOP works and under what conditions it fails.\n\nThere can be an analysis of failure cases, gradient sensitivity, or interplay between MHA vs. MLP pruning depth."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aIwmAWFCuy", "forum": "T6np2Ld3ag", "replyto": "T6np2Ld3ag", "signatures": ["ICLR.cc/2026/Conference/Submission4571/Reviewer_GM9q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4571/Reviewer_GM9q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4571/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989490813, "cdate": 1761989490813, "tmdate": 1762917446673, "mdate": 1762917446673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}