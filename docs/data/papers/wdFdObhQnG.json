{"id": "wdFdObhQnG", "number": 8150, "cdate": 1758070387084, "mdate": 1763226319413, "content": {"title": "Text-Trained LLMs Can Zero-Shot Extrapolate PDE Dynamics", "abstract": "Large language models (LLMs) have demonstrated emergent in-context learning (ICL) capabilities across a range of tasks, including zero-shot time-series forecasting. We show that text-trained foundation models can accurately extrapolate spatiotemporal dynamics from discretized partial differential equation (PDE) solutions without fine-tuning or natural language prompting. Predictive accuracy improves with longer temporal contexts but degrades at finer spatial discretizations. In multi-step rollouts, where the model recursively predicts future spatial states over multiple time steps, errors grow algebraically with the time horizon, reminiscent of global error accumulation in classical finite-difference solvers. We interpret these trends as in-context neural scaling laws, where prediction quality varies predictably with both context length and output length. To better understand how LLMs are able to internally process PDE solutions so as to accurately roll them out, we analyze token-level output distributions and uncover a consistent ICL progression: beginning with syntactic pattern imitation, transitioning through an exploratory high-entropy phase, and culminating in confident, numerically grounded predictions.", "tldr": "Text-trained LLMs can zero-shot extrapolate spatiotemporal dynamics of PDE solutions, exhibiting systematic in-context learning progression and behaviors analogous to classical numerical solvers.", "keywords": ["Large Language Models", "In-Context Learning", "Partial Differential Equations", "Spatiotemporal Dynamics", "Zero-Shot Extrapolation", "Numerical Analysis", "Interpretability", "AI4Science"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/528ec4b8ecd2263a2f1d46bdade5acd0f6019b48.pdf", "supplementary_material": "/attachment/88286bd2e421963f95642929e1f7c8b1215fe6b6.zip"}, "replies": [{"content": {"summary": {"value": "The paper studies the ability of pre-trained LLMs to extrapolate PDE solutions given the solution trajectory up to some time. The paper investigates how the error and the uncertainty in the model’s prediction varies as the context length, rollout length, and spatial discretization are all varied. In the one-step prediction setting, they find that the mean error decay exhibits different behaviors depending on the context length, and that for sufficiently long contexts, the error decays similarly to a numerical solver. They also find that, unlike numerical solvers, the LLM’s prediction error increases as the spatial resolution is increased, since this results in a larger token length. In the multi-step prediction setting, they find that errors accumulate algebraically along the predicted trajectory, which is also observed in numerical solvers. Finally, they find that the uncertainty of the model’s prediction (as measured by the Shannon entropy) decreases as the context length increases and increases as the token length increases."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides a very thorough empirical study of the scaling laws for solving PDEs with pre-trained LLMs, and the fact that you see similar behavior to classical numerical solvers across various initial conditions makes me feel better about the use of LLMs as PDE solvers.\n- Uncertainty quantification for LLMs is a very important problem, especially in scientific domains where interpretability is valued. I find it very interesting and encouraging that increasing context length reduces the uncertainty of the model’s prediction in this setting.\n- The paper is very well-written, and it is easy to interpret their figures and understand their central claims."}, "weaknesses": {"value": "- The collection of PDEs considered is somewhat limited, since the parameters of the nonlinear PDEs are fixed.\n- There is no theory to explain the empirical results, though of course a theory of modern LLMs is beyond our current scope."}, "questions": {"value": "- For one-step prediction, does the RMSE take into account the scale or the smoothness of the ground truth solution? It seems like it does not. I don’t think the choice of metric is too important, since ultimately you are comparing the model’s error with the numerical solver. But it occurs to me that, if your solution is very smooth in time, the model could just output the final token of the context and achieve $O(\\Delta t)$ error (maybe this is what the model does at intermediate context lengths?).\n- I would be interested to see how the LLM’s prediction depends on the choice of discretization, e.g., what happens if you instead represent the solution as a Fourier series (in $x$) and truncate the number of terms. \n- The RMSE and MAE approximate the $L^2$ and $\\sup$-norms on the function space. Do you have any sense of how well the model is predicting the (spatial) derivative of the solution at each time (i.e., what the $C^1$ or $H^1$ looks like)? I guess this is related to my previous question - since the model output does not define a continuous function, it is difficult to take derivatives, but you could do this if you had the Fourier coefficients."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PCOJ5J7tlU", "forum": "wdFdObhQnG", "replyto": "wdFdObhQnG", "signatures": ["ICLR.cc/2026/Conference/Submission8150/Reviewer_Z8eQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8150/Reviewer_Z8eQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760994953151, "cdate": 1760994953151, "tmdate": 1762920120772, "mdate": 1762920120772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We thank the reviewers for their time and constructive feedback. Our motivation in this formulation of the work was not to propose using foundation models (such as Llama 3.1, Phi-4, and SmolLM 3) as PDE solvers, but rather to study the kinds of emergent in-context learning capabilities and shared behaviors these models exhibit when, without any natural-language prompting, PDE/BC/IC descriptors, or fine-tuning, they are exposed solely to the spatiotemporal trajectories of PDE dynamics. By using families of 1D linear and nonlinear PDE solutions (including Allen–Cahn, Fisher–KPP, Heat, and Wave equations) with randomized initial conditions as a clean and controlled setting, we aim to illuminate the numerical priors and inductive biases that arise purely from large-scale pretraining on textual data such as natural language and code. Across these PDEs, we uncover consistent in-context learning behavior in PDE continuation shared across different LLM families. We have decided to withdraw the submission and appreciate the reviewers’ suggestions and questions."}}, "id": "9KQ5sz3V3m", "forum": "wdFdObhQnG", "replyto": "wdFdObhQnG", "signatures": ["ICLR.cc/2026/Conference/Submission8150/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8150/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763226318643, "cdate": 1763226318643, "tmdate": 1763226318643, "mdate": 1763226318643, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a novel and ambitious approach to solving Partial Differential Equations (PDEs) by using text-trained Large Language Models (LLMs) in a zero-shot setting. The central claim is that these models, despite being trained purely on natural language, can \"extrapolate\" to solve unseen PDE problems, ostensibly by reasoning over the textual representation of the equations. The paper investigates this capability, through multiple empirical experiments. They show that 1) LLM's are able to correctly perform next-step and multi-step prediction of time-dependent PDEs, when a large context window is given. 2) They show that uncertainty decreases with the LLM context and 3) uncertainty growth with output length.\n\nThe main contributions are:\n\n- they demonstrate LLMs exhibit zero-shot predictive capabilities.\n- they in-context scaling laws for time-dependent PDEs with respect to context length and spatial discretization, ...\n- they analyze token-level predictive entropy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "I think the idea of using LLMs for time-dependent PDEs is an interesting area of research and is worth investigating. This is intriguing question: can the reasoning capabilities of LLMs, developed through language modeling, be transferred to a complex, formal domain like PDEs without any domain-specific fine-tuning?\n\nGlobally, the paper is well written and well presented."}, "weaknesses": {"value": "Here is a more direct rephrasing of your points:\n\nThe paper's contributions and experiments are relatively weak. The finding that error decreases with context length is an expected outcome for next-step prediction in LLMs; a larger context simply provides better statistics for pattern matching. This result offers little evidence of a genuine ability to extrapolate PDE dynamics. Furthermore, the multi-step prediction results (e.g., Figure 4) show error increasing rapidly, which undermines the extrapolation claim by demonstrating the model fails to capture the underlying governing principles.\n\nThe core premise seems based on a misunderstanding of what LLMs learn. These models are trained on token co-occurrence, not to derive or understand first-principles physics. There is no strong theoretical justification for why a model trained on web text should be able to solve PDEs. This is an important question that should be treated to justify LLMs can perform zero-shot on PDE dynamics.\n\nFinally, the method has only been tested on simple PDEs over a few time steps. Given these limited results, the title and its \"zero-shot extrapolation\" claim seem significantly overclaimed."}, "questions": {"value": "Could the authors provide a direct, quantitative comparison of the numerical error (e.g., MSE, L2 error) of their method against a standard baseline neural operator (like FNO) on the exact same problem instances, including compute time?\n\nThere is a pretty large literature on in-context learning, that explores the properties of LLM architectures for PDEs. While the approach is different, it seems natural to me to compare to these methods [1, 2, 3, 4].\n\nDid you try to explore few-shot learning with parameter efficient fine tuning methods (e.g. LORA) to see how the LLM would behave, compared to a fully zero-shot setting?\n\n[1] Chen et al, Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning. 2024\n[2] Cao et al, VICON: Vision In-Context Operator Networks for Multi-Physics Fluid Dynamics Prediction. 2025.\n[3] Serrano et al, Zebra: In-Context Generative Pretraining for Solving Parametric PDEs. 2025\n[4] Kassaï Koupaï et al, ENMA: Tokenwise Autoregression for Generative Neural PDE Operators. 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethical concerns."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7k13UAgXy0", "forum": "wdFdObhQnG", "replyto": "wdFdObhQnG", "signatures": ["ICLR.cc/2026/Conference/Submission8150/Reviewer_CtL5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8150/Reviewer_CtL5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761569896520, "cdate": 1761569896520, "tmdate": 1762920120335, "mdate": 1762920120335, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper demonstrates that large language models can, to a certain extent, extrapolate the temporal dynamics of one-dimensional systems governed by partial differential equations. Using open-source LLM implementations (such as LLaMA 3) and a tokenization scheme that maps floating-point observations to three-digit integer tokens, the authors evaluate zero-shot performance on several equations, including the Allen–Cahn, Fisher–KPP, heat, and wave equations. The results indicate that LLMs are capable of short-term extrapolation and benefit from extended temporal context, but their predictions deteriorate rapidly over multiple time steps when compared to classical numerical solvers."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Applying text-trained large language models to data governed by partial differential equations is an intriguing idea; nonetheless, it appears reasonable, given the existence of similar approaches on time series data.\n- The tokenization scheme is simple and draws inspiration from the work of Gruver et al. [1].\n\n\n[1] Gruver et al., Large language models are zero-shot time series forecasters., 2023"}, "weaknesses": {"value": "- I do not fully understand why the authors apply quantization to the inputs of the numerical solvers as well. Quantization is primarily a limitation of LLMs, not of traditional numerical solvers.\n\n- As the authors note, LLMs do not perform zero-shot extrapolation on temporal PDEs—otherwise, increasing the number of spatial discretization points would similarly reduce the error, as seen in numerical solvers. A more modest claim would be that LLMs can extrapolate, to some extent, very simple spatiotemporal dynamics.\n\n- The interpretation of Figure 5 is somewhat unclear. It appears to show that LLMs require a sufficient amount of input context to make confident predictions.\n\n- The related work section omits prior studies on the application of LLMs to PDEs, specifically [1] and [2].\n\n[1] Serrano et al., Zebra: In-context and Generative Pretraining for Solving Parametric PDEs, 2025.\n[2] Zhou et al., Text2PDE: Latent Diffusion Models for Accessible Physics Simulation, 2024."}, "questions": {"value": "- I am curious about the main motivation behind this work. Is the goal to establish a new benchmark for evaluating the advanced capabilities of large language models, or is it primarily aimed at advancing the field of PDE surrogates? I am inclined to think that the former interpretation would make more sense. However, the paper is not currently written in a way that clearly supports this. I would therefore suggest including a benchmark that compares more LLMs and uses a broader range of data, which should be feasible since no additional training is required.\n- Do you believe that this approach could scale effectively to 2D datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zYgynKhB8q", "forum": "wdFdObhQnG", "replyto": "wdFdObhQnG", "signatures": ["ICLR.cc/2026/Conference/Submission8150/Reviewer_69VJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8150/Reviewer_69VJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841151907, "cdate": 1761841151907, "tmdate": 1762920119836, "mdate": 1762920119836, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper shows that a pretrained LLM, without any fine-tuning, can autoregressively continue solutions of time-dependent PDEs when the spatiotemporal field u(x,t) is linearly quantized to 3-digit integers and serialized as a comma-delimited spatial vector with semicolons separating time steps. Empirically, longer temporal context improves accuracy, and multi-step rollout errors grow with the horizon."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Extremely simple pipeline: the authors feed the serialized numeric sequence directly to a pretrained LLM with no fine-tuning and obtain next-step predictions autoregressively."}, "weaknesses": {"value": "1. Lack of theoretical guarantees: PDE dynamics vary widely with governing equations, boundary, and initial conditions. In this zero-shot setup, the LLM receives no explicit PDE/BC/IC descriptors beyond the numeric prefix, so stability, conservation, and correctness are not guaranteed; the paper emphasizes analysis of emergent ICL behavior rather than proposing a principled solver. \n\n2. Limited scope to 1D cases: although the study covers Allen–Cahn, Fisher–KPP, Heat, and Wave, all experiments are 1D; extending to 2D/3D complex PDEs (e.g., Navier–Stokes) remains open. \n\n3. No explicit conditioning interface for BC/IC: apart from what can be inferred from the observed history, there is no mechanism to inject symbolic BC/IC or PDE parameters into the prompt."}, "questions": {"value": "1. The authors state they don’t intend this as a PDE solver, yet the title sounds assertive. Would they consider softening the framing to avoid over-claiming? (e.g., emphasize “analysis of zero-shot ICL behavior.”) \n\n2. Please evaluate complex boundary conditions and irregular grids to test robustness beyond the current 1D setups (they include Dirichlet and Neumann in 1D; broader cases would help). \n\n3. Neural operators (FNO/DeepONet/FFNO, etc) can also do autoregressive PDE continuation. How does zero-shot LLM compare numerically (one-step and rollout RMSE/MAE) under the same discretization and context?\n\n4. The PDE foundation-model line is cited, but a clearer positioning and experimental or analytical comparison would help: when and why is zero-shot LLM preferable to in-context operator learning or large PDE foundation models? \n\n5. What happens if the codebook is enlarged (4 or 5 digits)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pE3GHMGs5v", "forum": "wdFdObhQnG", "replyto": "wdFdObhQnG", "signatures": ["ICLR.cc/2026/Conference/Submission8150/Reviewer_ATXj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8150/Reviewer_ATXj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897563861, "cdate": 1761897563861, "tmdate": 1762920119390, "mdate": 1762920119390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}