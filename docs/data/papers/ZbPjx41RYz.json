{"id": "ZbPjx41RYz", "number": 3541, "cdate": 1757469595182, "mdate": 1759898082312, "content": {"title": "Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution", "abstract": "Mobile App Agents powered by large foundation models represent a transformative approach to human-computer interaction, enabling autonomous task execution within dynamic mobile applications. However, the volatile nature of mobile ecosystems characterized by frequent application updates poses challenges to agent reliability and long-term viability. We identify two critical problems: UI element identification failure when visual or structural changes occur, and task logic drift when fundamental workflows are altered. To address these challenges, we propose \\textbf{\\modelname}, a \\textbf{M}emory-driven \\textbf{A}daptive a\\textbf{GENT} framework, equipped with a novel dual-level memory consisting of stationary memory and procedural memory. The stationary memory maintains rich multimodal representations of UI elements, enabling robust action grounding despite interface modifications, while the procedural memory captures and adapts structured task workflows to handle logical changes in operations. This framework effectively bridges the update gap that has limited the practical deployment of mobile agents. \nComprehensive experiments demonstrate that \\modelname achieves robust generalization across various in-domain scenarios and strong adaptability to novel task domains.", "tldr": "We propose MAGNET, a memory-driven framework that adapts mobile app agents to UI and workflow changes for robust long-term reliability.", "keywords": ["GUI Navigation", "Agent", "Memory"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2022fced8f6ccd5fb6796590c2a720675df056f5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper aims to solve the adaptability of GUI agents across app versions by decoupling procedural and UI element knowledge and encoding them in two complementary memory systems. The stationary memory stores an N-to-N mapping between UI elements and their functional descriptions, the procedural memory retains abstracted action sequences and task workflows that guide the agent’s planning in new environments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths\n- The paper identifies a clear and practical challenge for GUI agents: the lack of adaptability when app interfaces evolve over time. The problem setting is realistic and relevant to how GUI systems are deployed in the real world.\n- The proposed MAGNET aims to address this by separating procedural and visual-semantic knowledge into two complementary memory modules. The dual-memory design is conceptually clean and easy to understand, offering a structured way to organize long-term knowledge for GUI agents.\n- The procedural memory is built by clustering task instructions according to their high-level objectives, grouping semantically related tasks and abstracting their shared execution patterns into reusable workflows. This approach effectively captures task-level logic that can generalize across interface changes."}, "weaknesses": {"value": "Weaknesses\n- The improvements reported in both the main experiments and the ablation studies are relatively trivial, mostly around 2%. This makes it difficult to judge the practical impact of the method. \n- The paper lacks comparisons with strong existing baselines on the same benchmarks, such as UI-Venus[1], InfiGUI-R1[2].\n- The UI-40K dataset deserves a more detailed presentation. The region annotation is based on a UI parser, but the paper does not discuss how accurate these annotations are. Some evidence or analysis of annotation quality would make the dataset more convincing. Additionally, subcomponents for constructing the system, like task cluster and workflow abstraction, are not evaluated in this paper.\n- The writing could be improved and better organized. Several figures could also be clearer and more standardized. For example, Figure 4 doesn’t explain what the colors and line styles represent. Each figure should be self-contained.\n\n[1] UI-Venus Technical Report: Building High-performance UI Agents with RFT\n\n[2] InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners"}, "questions": {"value": "How accurate are the region annotations generated by the UI parser? Did the authors conduct any validation or quality check?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RAQlWL5GsU", "forum": "ZbPjx41RYz", "replyto": "ZbPjx41RYz", "signatures": ["ICLR.cc/2026/Conference/Submission3541/Reviewer_mtDY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3541/Reviewer_mtDY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879741402, "cdate": 1761879741402, "tmdate": 1762916801953, "mdate": 1762916801953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the reliability issues of GUI agents in dynamic mobile environments where applications are frequently updated. The authors identify two primary challenges: \"task logic drift\" and \"UI element identification failure\". To tackle these, they propose MAGNET, a memory-driven framework featuring a dual-level memory system. This system comprises a procedural memory to capture and generalize task workflows and a stationary memory for robust UI element grounding. The paper also introduces UI-40K, a dataset of over 40,000 UI elements with functional descriptions. Experiments show that the framework improves agent performance and adaptability across several configurations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a novel memory-based adaptive agent framework to address critical real-world challenges. By designing distinct procedural and stationary memory modules, it systematically targets the problems of task logic drift and UI element identification failure that arise from app updates.\n\n2. A nice contribution is the UI-40K dataset, which links visual UI elements to their functional semantics, provides a valuable foundation for the community."}, "weaknesses": {"value": "1. The paper does not sufficiently articulate the connection between its proposed memory modules and the adaptation challenges they aim to solve. The core problem is that app updates introduce new information. However, the proposed memories are built from existing, potentially outdated data. It is unclear how a memory of old UI elements or workflows helps the agent adapt to a redesigned interface or a fundamentally altered task logic. There is a risk that this outdated knowledge could mislead the agent, and the paper does not discuss mechanisms to mitigate this negative transfer.\n\n2. The memory construction process appears to depend heavily on high-quality, human-annotated datasets. These datasets are expensive to collect and can quickly become obsolete as apps evolve. This raises concerns about the scalability and practical applicability of the proposed method. The paper does not explore whether the memory modules could be effectively constructed or continuously updated using data from the agent's own autonomous (and possibly imperfect) explorations, which would be a more scalable and dynamic approach.\n\n3. The evaluation is confined to offline datasets (AITZ, GUI-Odyssey, Amex), which contradicts the paper's primary motivation of addressing challenges in dynamic online environments. The introduction correctly argues that existing methods fail to adapt in online settings, yet the experiments do not validate the proposed solution in such an environment (e.g., AndroidWorld, OSWorld). To substantiate the claims of improved adaptability to app updates, an evaluation on an interactive, online benchmark is essential.\n\n4. While the framework is well-designed, the novelty of the core techniques used to build the memory modules is somewhat limited. Methodologies such as embedding-based clustering of instructions and using large multimodal models to generate descriptions for image patches are relatively standard practices in the current literature. The contribution lies more in the novel application and system-level integration of these components rather than in fundamental algorithmic innovation."}, "questions": {"value": "1. How does the framework prevent outdated information in the stationary and procedural memories from negatively impacting performance on updated apps, and are there mechanisms to detect and purge obsolete knowledge?\n\n2. How crucial is the reliance on high-quality human demonstration data for memory construction? \n\n3. Given the paper's focus on adapting to dynamic online environments, have the authors considered evaluating on interactive benchmarks (AndroidWorld, OSWorld, etc.) or even real-world apps to more directly validate its core claims?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WE8MoLmNv8", "forum": "ZbPjx41RYz", "replyto": "ZbPjx41RYz", "signatures": ["ICLR.cc/2026/Conference/Submission3541/Reviewer_HHxY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3541/Reviewer_HHxY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900345160, "cdate": 1761900345160, "tmdate": 1762916801110, "mdate": 1762916801110, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a memory-driven adaptive framework for GUI agents. It introduces a dual-memory system: procedural memory to capture reusable task workflows for handling logic drift, and stationary memory for UI elements for better grounding. Experiments on three GUI benchmarks have shown some consistent performance improvements in success rate and grounding accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents the clear motivation and analysis, and the framing of the research problems look intuitive.\n\nThe dual-memory system design also sounds reasonable, which could be reused by other GUI agent frameworks.\n\nThe new UI-40K dataset (41 k UI-function pairs) might be a valuable contribution to the research in CUA, but the authors need to demonstrate its general usage."}, "weaknesses": {"value": "The main weakness of this paper lies in the novelty. The proposed memory mechanisms are primarily database-like retrieval and clustering operations rather than genuinely new learning paradigms. There is no clear theoretical or algorithmic advance beyond standard memory augmentation.\n\nThe reported improvements are relatively marginal and may not justify that the proposed framework as well as contributions is significant.\n\nIn the experiments part, the “SOURCE” data used to construct memory are split from the same dataset, which may make the results inconvincible in terms of the proposed algorithm's generalization capability. \n\nThe writing of the paper could be improved. It has excessive repetition across sections, restating the same conceptual points (e.g., the two challenges and the dual-memory mechanism) multiple times with little new insight or analysis. \n\nMinor issue: The paper refers to the fine-tuned Atlas-Pro-7B model as an “upper bound” for GUI navigation performance, which may be more suitable to positive as a \"reference baseline\"."}, "questions": {"value": "The paper only compares the performance with and without the proposed memory. How about the comparison with other memory-enhanced GUI agents, as mentioned in the related work (e.g., Chain-of-Memory and others)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rl3eJrgjQO", "forum": "ZbPjx41RYz", "replyto": "ZbPjx41RYz", "signatures": ["ICLR.cc/2026/Conference/Submission3541/Reviewer_XV59"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3541/Reviewer_XV59"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920568989, "cdate": 1761920568989, "tmdate": 1762916800567, "mdate": 1762916800567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a memory-augmented mobile agent, equipped with a \"stationary memory\" storing icon knowledge and a \"procedural memory\" storing workflow experience. The combination of memory succeeds in boosting the agent's\nperformance on static **grounding** benchmarks, but no direct evidences show\nthat they also work in interactive environments. The ablation results also fail\nto match with the design motivation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper designs a novel knowledge base memory and its contruction pipeline\n  for icon grounding.\n2. Adequate improvements are acquired on GUI grounding benchmarks."}, "weaknesses": {"value": "1. I don't see any valid results on a reliable interactive environment. Results\n   on static datasets can only properly depict the grounding capability, but\n   not the whole success rate. The authors need to append experiments on at\n   least one reliable interactive environment like AndroidWorld or Mobile-Env.\n2. The results in Table 2 don't support the memory design well, as it seems\n   that the procedural memory contributes to the grounding performance more\n   than the stationary memory. This lacks a proper explanation.\n3. Baselines of other memory-augmented agents lack.\n4. The generalizability is mediocre compared to baseline."}, "questions": {"value": "The first paragraph of Sec 3.1 saids that the old knowledge may become\n   obsolete in updated environments. So why will the experiences abstracted\n   from old trajectories still work in updated environments? A more clear\n   explanation is needed to illuminate the motivation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8W76mEqo29", "forum": "ZbPjx41RYz", "replyto": "ZbPjx41RYz", "signatures": ["ICLR.cc/2026/Conference/Submission3541/Reviewer_tuZJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3541/Reviewer_tuZJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996125524, "cdate": 1761996125524, "tmdate": 1762916800138, "mdate": 1762916800138, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}