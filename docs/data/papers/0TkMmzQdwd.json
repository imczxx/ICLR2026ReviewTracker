{"id": "0TkMmzQdwd", "number": 4401, "cdate": 1757674018743, "mdate": 1759898034478, "content": {"title": "RETIMECAUSAL: A CONSISTENT EM FRAMEWORK FOR CAUSAL DISCOVERY IN IRREGULAR TIME SERIES", "abstract": "This paper studies causal discovery in irregularly sampled time series—a pivotal challenge in high-stakes domains like finance, healthcare, and climate science, where missing data and inconsistent sampling frequencies distort causal mechanisms. The core challenge arises from the interdependence between missing data imputation and causal structure recovery: an error in either component can cascade into the other, ultimately distorting the inferred causal graph. Existing methods either impute first and then discover, or jointly optimize both via neural representation learning, but lack explicit mechanisms to ensure mutual consistency of imputation and structure learning. We address this challenge with ReTimeCausal, an EM-based framework that alternates between imputation and structure learning, promoting structural consistency throughout the optimization process. Our framework emphasizes theoretical consistency guarantees for structure recovery, extending classical results to settings with irregular sampling and high missingness. Through kernelized sparse regression and structural constraints, ReTimeCausal iteratively refines missing values (E-step) and causal graphs (M-step), resolving cross-frequency dependencies and missing data issues. Extensive experiments on synthetic and real-world datasets demonstrate that ReTimeCausal outperforms existing state-of-the-art methods under challenging irregular sampling and missing data conditions.", "tldr": "ReTimeCausal is a robust method for causal discovery in multivariate time series with missing and irregular data, employing an EM-style framework grounded in Additive Noise Models to ensure accurate structure recovery across varying conditions.", "keywords": ["Causal Discovery", "Expectation-Maximization (EM)", "Additive Noise Model (ANM)", "Irregular Sampling", "Time Series"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e5d72c038fda6c5ea49b6772e5d059c7f072f1b6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses a critical challenge in temporal causal discovery: the presence of missing values and inconsistent sampling frequencies in multivariate time series data. These data issues commonly lead to distortions that severely weaken the performance of subsequent causal inference methods. To overcome this limitation, the authors propose a novel, unified framework that tackles the problems of alignment and imputation concurrently with causal structure learning. The core of their solution is an Expectation-Maximization (EM) style method that allows the two traditionally separate processes to be mutually promoted, thereby improving the robustness and accuracy of the resulting causal graph."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a well-motivated approach and proposes a framework that is both simple and effective.\n2. The authors provide a compelling argument challenging the traditional two-step approach (imputation followed by causal discovery), emphasizing instead that these two processes can and should be mutually promoted. This insight forms the basis of their innovative approach."}, "weaknesses": {"value": "1. The authors need to clarify the definitions of numerous mathematical symbols. For instance, the variable $k$ appears to denote the number of iteration. Overall, the mathematical notation and methodology presentation in the paper require significant improvement for clarity and rigor.\n2. The empirical evaluation lacks sufficient breadth to fully validate the proposed framework's generalizability and robustness. Specifically, the authors should include comparisons against a wider range of competitive state-of-the-art methods and ideally use more diverse real-world datasets to demonstrate the method's effectiveness across different domains and data characteristics."}, "questions": {"value": "1. (Page 3, Equation 1): Regarding the ANM framework employed, could the authors please clarify whether the proposed approach explicitly accounts for and models contemporaneous effects (instantaneous effects) between variables?\n\n2. (Page 5, Equation 3): When dealing with consecutive missing values (as depicted in Figure 2), does the calculation rely solely on directly observed data, or does it utilize autoregressively imputed values from the previous timestep as input?\n\n3. (Page 5, Equation 4): The paper needs to clarify the functional form of $f_i$. The authors state that black-box neural networks are not used; however, it remains ambiguous whether the inherent interpolation or modeling of $f_i$ is strictly linear, a form of low-order non-linearity, or another mechanism.\n\n4. Clarification on the RKHS and dimensional handling is essential. While we infer the input space dimension to be $p$ (based on the $p \\times p$ matrix $\\mathbf{W}$), please confirm this and explain the conceptual role and effective dimensionality of the RKHS. Furthermore, a major inconsistency exists in the regularization output: if $\\mathbf{W}$ is $p \\times p$, and $\\mathbf{G}$ is derived via LASSO, how is the dimension of $\\mathbf{G}$ subsequently reduced or transformed from $p \\times p$ to $d \\times d$?\n\n5. The selection of the crucial threshold parameter should be clarified. Please detail the methodology used to determine this parameter in the experiments, and provide recommended strategies or principles for practitioners seeking to tune it for real-world applications.\n\n6. The current set of comparison methods is too limited. The authors should include a wider range of modern and relevant time series causal discovery baselines. Specifically, please evaluate powerful two-step processes, i.e., combining the most advanced imputation methods with established discovery techniques. Please find a list of relevant references provided below for your consideration.\n\n7. The superior performance of PCMCI + TimeMixer in Table 3 requires a detailed analysis to clarify its mechanism. Does this superior performance primarily stem from the high quality of the TimeMixer imputation? If so, does this imply that combining TimeMixer with other temporal causal discovery methods would also achieve similar high performance? If the strength lies uniquely in the PCMCI method itself, the authors could provide a clear justification for why PCMCI is uniquely well-suited for the TimeMixer-imputed outputs in this missing data scenario.\n\n8. The paper lacks an ablation study to substantiate the central claim of mutual promotion between imputation and discovery. Could the authors provide a visualization (a plot over iterations $k$) showing how both the causal recovery accuracy and the imputation quality evolve, demonstrating how they promote each other?\n\n9. While the paper addresses inconsistent sampling, clarification is needed on how the alignment mechanism handles time distortions (e.g., issues typically addressed by dynamic time warping). How is this addressed, and how does the model differentiate between a true missing block and a time warp?\n\nReferences: \n\na. Han et al. \"Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery.\" ICLR 2025.\n\nb. Gong et al. \"Rhino: Deep causal temporal relationship learning with history-dependent noise.\" ICLR 2023.\n\nc. Gao et al. \"IDYNO: Learning nonparametric DAGs from interventional dynamic data.\" ICML 2022.\n\nd. Marcinkevičs et al. \"Interpretable models for granger causality using self-explaining neural networks.\" ICLR 2021."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HgmiSKX9WA", "forum": "0TkMmzQdwd", "replyto": "0TkMmzQdwd", "signatures": ["ICLR.cc/2026/Conference/Submission4401/Reviewer_UPVv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4401/Reviewer_UPVv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761600909845, "cdate": 1761600909845, "tmdate": 1762917343472, "mdate": 1762917343472, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses causal discovery when multivariate time series are irregularly sampled and contain substantial missingness. Standard interpolation or alignment steps often distort causal order and create spurious dependencies.\nThe authors propose ReTimeCausal, an Expectation–Maximization (EM) style framework that alternates between\n\n1. a structure-aware imputation step that estimates missing values based on conditional expectations under additive-noise models, and\n\n2. a structure-learning step that performs kernelized sparse regression with projection to input space and thresholding to infer lagged causal graphs.\n\n\nA noise-aware imputation mechanism injects residual noise to preserve independence assumptions used for pruning. Theoretical analysis (Proposition 1) establishes structural consistency under standard assumptions — MCAR/MAR missingness, finite-order Markovity, causal sufficiency, and faithfulness — given appropriate smoothing and threshold schedules.\nExperiments on synthetic linear and nonlinear systems and the CausalRivers dataset show that ReTimeCausal maintains high F1-scores even with 60–80 % missingness and outperforms baselines such as PCMCI, DYNOTEARS, and CUTS+ (with TimeMixer preprocessing). On CausalRivers, it achieves the best reported F1 = 0.463 (MR = 0.2) and 0.414 (MR = 0.6)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Principled EM alternation: directly enforces consistency between imputation and structure learning.\n- Kernelized sparse regression: captures nonlinear lagged effects and projects to interpretable input-space graphs.\n- Noise-aware imputation: preserves independence assumptions for accurate CAM-style pruning.\n- Theoretical support: provides asymptotic structural consistency (Proposition 1) under clear conditions.\n- Empirical robustness: strong performance across missingness levels; best F1 on CausalRivers with competitive SID/SHD."}, "weaknesses": {"value": "- Assumption scope: relies on MCAR/MAR and causal sufficiency; MNAR and latent confounding remain open.\n- Hyperparameter sensitivity: thresholds (γ, β) and smoothing (α) impact performance but lack systematic tuning guidance.\n- Computational profile: runtime and memory costs for kernel features plus EM iterations are not detailed.\n- Evaluation scale: real-world validation limited to a 10-node CausalRivers subgraph; larger datasets would improve external validity."}, "questions": {"value": "1. How sensitive are the results to thresholds (γ, β) and smoothing (α)? Any principled selection strategy?\n2. Can you provide empirical convergence diagnostics (E/M objective traces or iteration counts)?\n3. How does the method behave under mild MNAR violations where missingness depends weakly on unobserved values?\n4. What are the main computational bottlenecks, and can kernel features be approximated (e.g., random features)?\n5. How does CAM-style pruning compare with simpler coefficient-magnitude pruning in nonlinear regimes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9WcS8JmHA9", "forum": "0TkMmzQdwd", "replyto": "0TkMmzQdwd", "signatures": ["ICLR.cc/2026/Conference/Submission4401/Reviewer_CgG6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4401/Reviewer_CgG6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971095850, "cdate": 1761971095850, "tmdate": 1762917343049, "mdate": 1762917343049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ReTimeCausal, an EM-based framework for causal discovery in multivariate time series with irregular sampling and high data missingness. By alternating between smart imputation and causal graph estimation, the method aims to ensure mutual consistency between the imputed values and the learned causal structure. The authors provide theoretical guarantees of consistency for structure recovery under a set of explicit assumptions. Experiments on synthetic and real-world datasets demonstrate improved performance over classical and recent baselines for both structural accuracy and robustness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The EM-based approach is an intuitive solution to the often glossed over problem of missing data in prior work.\n2. The theoretical results on structure consistency are justified and rigorous.\n3. The kernelized sparse reg approach allows for nonlinear dynamics as well as linear.\n4. Good recent baselines in experiments."}, "weaknesses": {"value": "1. Although multiple real-world datasets are tested, the primary evaluation still leans heavily on synthetic data with relatively small- to medium-scale graphs (10–50 variables). The main real-world benchmark (CausalRivers) comprises a 10-node subgraph, and other datasets (NetSim, CausalTime) are also moderate in scale. Absence of large-scale, high-noise, and highly nonstationary real-world benchmarks undercuts the claimed generalizability.\n2. Theoretical results hinge on a strong modeling assumption: MCAR/MAR missingness (Assumption 3.2). Many domains of practical interest, especially healthcare and finance, often involve MNAR data, latent confounding, or nonstationary relationships. While the authors acknowledge this (Appendix A.5, A.10), the framework offers no empirical or algorithmic pathway for relaxing these beyond a brief mention as future work. \n\n### Minor comments:\n3. You mention Assumption 3.1 in lines 145 and 357 but there is no such assumption in the text."}, "questions": {"value": "1. Can the EM pipeline be extended to non-ignorable missingness (e.g., selection/Heckman-style or propensity-aware E-steps)?\n2. What is the time complexity of ReTimeCausal?\n3. How robust is the approach to severe nonstationarity and rapidly shifting lag structures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P8qLdi8QKU", "forum": "0TkMmzQdwd", "replyto": "0TkMmzQdwd", "signatures": ["ICLR.cc/2026/Conference/Submission4401/Reviewer_eYxy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4401/Reviewer_eYxy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989944312, "cdate": 1761989944312, "tmdate": 1762917342526, "mdate": 1762917342526, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}