{"id": "4xPmlk3Zcg", "number": 5097, "cdate": 1757847238367, "mdate": 1763707161775, "content": {"title": "CoVAE: Consistency Training of Variational Autoencoders", "abstract": "Current state-of-the-art generative approaches frequently rely on a two-stage training procedure, where an autoencoder (often a VAE) first performs dimensionality reduction, followed by training a generative model on the learned latent space. While effective, this introduces computational overhead and increased sampling times. We challenge this paradigm by proposing Consistency Training of Variational AutoEncoders (CoVAE), a novel single-stage generative autoencoding framework that adopts techniques from consistency models to train a VAE architecture. The CoVAE encoder learns a progressive series of latent representations with increasing encoding noise levels, mirroring the forward processes of diffusion and flow matching models. This sequence of representations is regulated by a time dependent $\\beta$ parameter that scales the KL loss. The decoder is trained using a consistency loss with variational regularization, which reduces to a conventional VAE loss at the earliest latent time. We show that CoVAE can generate high-quality samples in one or few steps without the use of a learned prior, significantly outperforming equivalent VAEs and other single-stage VAEs methods. Our approach provides a unified framework for autoencoding and diffusion-style generative modeling and provides a viable route for one-step generative high-performance autoencoding. Our code is available in the supplementary material.", "tldr": "Training a generative autoencoder as a consistency model", "keywords": ["Generative Models", "Consistency Models", "Variational Autoencoders", "Diffusion Models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/943a294f53a340db704090a7a301b2889c48309a.pdf", "supplementary_material": "/attachment/aa2375d95a6b3c812a9ff56670460384d9cfd403.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduices CoVAE which builds upon the VAE architecture but modifies both the encoding and decoding processes to ensure temporal consistency across latent representations along the learning phase.\n•\tThe encoder learns progressively noisier latent representations, controlled by a time-dependent noise schedule β(t). At low noise levels (small t), the model captures detailed structure; as t increases, the latent codes gradually transition to Gaussian noise, providing a continuous interpolation between structured and random representations.\n•\tThe decoder is trained using a consistency loss that enforces agreement between predictions at adjacent time steps. This mechanism enables the model to learn denoising dynamics similar to those in diffusion models, but without requiring iterative multi-step sampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "•\tSingle-stage training (faster, simpler)\n•\tFast sampling without leaning an adaptive priori or learning the posterior distribution of the embeddings. \n•\tDisentangled latent space for image manipulation"}, "weaknesses": {"value": "The model cannot easily compute a tight Evidence Lower Bound (ELBO), which complicates likelihood-based evaluation and comparison with classical VAEs. \nIts performance depends on several empirically tuned hyperparameters. \nWhile it closes part of the gap between VAEs and diffusion models, it still lags behind the best direct diffusion approaches in sample fidelity and comparisons with the latent diffusion models are lacking. \nOther Latent SDE approached should also have been considered for comparison.\n\nOverall the idea looks interesting to have a \"diffusion like\" model to better learn the latent prior without the diffusion forward-backward equations to solve but comparisons with this literature is missing.\n\nThere is a typo in the pseudo code Algorithm 1 for the cm likelihood: , should be -."}, "questions": {"value": "Is the multistep CoVAE remaining in interesting areas of the latent space when moving around? In particular, the experiments have been performed with a lot of data. Is this method \"scalable\" for low amount of data?\n\nIs the use of patch-based adversarial loss interesting for the β-VAE itself. If yes, can you show the increase of performance of your combined approach with CoVAR vs the combination with the β-VAE?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ISiU2zwodE", "forum": "4xPmlk3Zcg", "replyto": "4xPmlk3Zcg", "signatures": ["ICLR.cc/2026/Conference/Submission5097/Reviewer_DFFZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5097/Reviewer_DFFZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761563658556, "cdate": 1761563658556, "tmdate": 1762917871935, "mdate": 1762917871935, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Answer"}, "comment": {"value": "We sincerely thank all reviewers for their thoughtful and constructive feedback. \n\nWe are encouraged to see that all reviewers recognized the novelty of CoVAE, specifically the integration of time-dependent latent VAEs with consistency-style training, and acknowledged the empirical benefits over both standard VAEs and strong single-stage VAE baselines. We also appreciate that several reviewers highlighted the practicality of one and few-step sampling and the conceptual contribution of unifying autoencoding and consistency training within a single framework.\n\nA recurring request concerns evaluating CoVAE on higher-resolution datasets such as ImageNet. We agree that large-scale experiments are an important and informative test of scalability. However, such experiments are beyond our current computational budget. Importantly, our goal in this paper is to establish the viability of a single-stage generative autoencoding framework trained end-to-end, without complex priors or diffusion-style sampling. For this purpose, we selected datasets that allow extensive ablations, controlled comparisons, and fast iteration within our resource constraints. Across these benchmarks, CoVAE consistently delivers strong empirical results, substantially outperforming equivalent VAE and β-VAE architectures and improving over strong one-stage VAE baselines (NVAE, DC-VAE), even without employing hierarchical priors or complex flows."}}, "id": "X7XfJ3cVqo", "forum": "4xPmlk3Zcg", "replyto": "4xPmlk3Zcg", "signatures": ["ICLR.cc/2026/Conference/Submission5097/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5097/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5097/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763707321471, "cdate": 1763707321471, "tmdate": 1763707321471, "mdate": 1763707321471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces consistency training for Variational AutoEncoders (CoVAEs). In contrast with two-stage approaches based on generative models over dimensionality reduction, CoVAE is a one-stage approach that learns a sequence of latent representations with a time dependent parameter scaling regularization and trained using consistency loss that is related to standard the VAE. Experiments on MNIST, CIFAR-10 and CelebA comparing performance with baseline models to illustrate the quality of images generated."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths of the paper include:\n- Concise, clear mathematical introduction of VAEs, Diffusion models, Consistency models, and the proposed CoVAE approach.\n- Detailed experiments including multiple datasets and multiple baseline models\n- Detailed and fair discussion of related work\n- Clear statements of limitations of the current work that identify important problems to address in future research"}, "weaknesses": {"value": "The main weaknesses of the paper are twofold; \n- First, the datasets are limited to MNIST, CIFAR10, and CelebA\n- Second, the models compared with are valuable but not state-of-the-art in terms of performance \n\n\nMinor issues: \n- Small typo in Figure 1 caption: Consistenct\n- Line 229 \"Form small time steps\"\n- Figure 2 is confusing. I suggest you explain what the objects in the future are one by one, starting from the left. E.g. is \"In Diffusion and Consistency\" about the first picture or the first two? Epsilon_psi is in in the figure but is in the caption. \"in this case we use a dashed line\" This is confusing. \n- Figure 3, the caption never mentions t. \n- \"Form small time steps, the samples from each class are embedded in well separated areas, while they gradually become more random\nas time increases.\" This is unclear. Is t representing size of time steps or time? (Or are they confounded.)"}, "questions": {"value": "Please see weaknesses. Specifically, it seems important to better understand the implications of the current approach for the state-of-the-art in image generation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B0ZKDoaiQz", "forum": "4xPmlk3Zcg", "replyto": "4xPmlk3Zcg", "signatures": ["ICLR.cc/2026/Conference/Submission5097/Reviewer_ovEJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5097/Reviewer_ovEJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834418878, "cdate": 1761834418878, "tmdate": 1762917869856, "mdate": 1762917869856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CoVAE, training VAEs using consistency loss, in similar fashion as the consistency models. The encoder is parametrized with the time step in addition to the input, and the decoder is trained to map the latent representations from any time step to the original image. The proposed method shows improved performance among the state-of-the-art VAE methods, but still lags behind diffusion models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed idea in CoVAE to use consistency training in VAEs is novel and interesting.\n- The performance among VAEs is better, and CoVAE also offers the option to trade off efficiency and performance with multi-step generation."}, "weaknesses": {"value": "- There is limited insight into the fundamental difference consistency training brings in VAEs that leads to performance improvements. While iterative denoising is intuitively justified in diffusion-based or consistency models—where the coupling between latent variables and data points is unknown, it is less clear in the case of VAEs, where the latent variable corresponding to a given data point can be obtained through the encoder.\n- In Section 2.1, the authors mention the prior hole problem, which is a fundamental problem with VAEs when used for generation. It is not discussed whether CoVAE mitigates the problem or if CoVAE has any impact on it.\n- At lines 372/373 it is mentioned that a patch-based adversarial loss is used, and it should be clear in the performance tables about the role of this additional loss. While Table 1 has  CoVAE with and without patch-based losses, Table 2 does not include it.\n- I would recommend using higher resolution images and the Imagenet dataset for experiments, as it is a fundamental benchmark for image generation.\n\nI believe the paper would benefit from deeper insights into why consistency training is necessary and what conceptual effect it introduces. Additionally, the experimental section could be strengthened through refinements involving higher-resolution datasets, such as ImageNet. I would be open to reconsidering my evaluation if these aspects are addressed."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7cXm1XYuX7", "forum": "4xPmlk3Zcg", "replyto": "4xPmlk3Zcg", "signatures": ["ICLR.cc/2026/Conference/Submission5097/Reviewer_b5HX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5097/Reviewer_b5HX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885047221, "cdate": 1761885047221, "tmdate": 1762917869449, "mdate": 1762917869449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CoVAE, a single-stage generative autoencoding framework that unifies a time-dependent \\beta-VAE with consistency training. The encoder produces progressively noised latents via a time-dependent KL weight \\beta(t); the decoder is trained with a latent consistency loss (bootstrapping adjacent times) with a denoiser-style term. This enables one- or few-step generation without a learned prior. On MNIST, CIFAR-10, and CelebA-64, CoVAE improves FID over standard VAE and \\beta-VAE baselines and outperforms strong single-stage VAEs (NVAE, DC-VAE); adding a lightweight adversarial term further improves FID and reconstruction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper formulates the VAE reparametrization as a time-indexed “forward process” in latent space and replaces standard reconstruction with a discrete consistency objective that bootstraps from early times. The method section and algorithmic details substantiate this bridge.\n\n2. CoVAE generates in one step and can optionally do few-step refinement by re-encoding/re-denoising at intermediate t. This is a practical departure from the common “VAE + latent diffusion/flow” recipe.\n\n3. The paper shows promising reconstruction and generation capacity of CoVAE in experiments. On CIFAR-10, CoVAE (1-step) improves FID over NVAE and DC-VAE. On MNIST, CoVAE simultaneously improves generation and reconstruction over β-VAE."}, "weaknesses": {"value": "1. A major concern is the applicability of the proposed approach, both to future research and real-world application. While CoVAE aims to unify VAE and the diffusion process for generation tasks in one single stage, it neglects text (or class) conditioning in modeling and implementation for image generation, which is crucial in current generative models. The paper compares CoVAE with standard VAE and demonstrates its advantages. However, standard VAE can be readily used to modeling visual signals in the latent space, for further diffusion-based generation. It is not clear how the time-dependent latents in CoVAE can be refined or utilized in downstream tasks.\n\n2. Experiments show results on relatively low-resolution (up to 64x64) image generation tasks. More convincing results are missing to show how CoVAE performs on high-resolution tasks and how it compares with strong baselines such as GANs."}, "questions": {"value": "1. Are there principled ways to design \\beta(t) and \\lambda(t)? How sensitive is empirical performance to their values?\n\n2. What is the compute and inference time of CoVAE? And what about the training efficiency and scalability of CoVAE?\n\n3. Would the generation quality consistently improve if the sampling steps are increased?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bzZKsti8jo", "forum": "4xPmlk3Zcg", "replyto": "4xPmlk3Zcg", "signatures": ["ICLR.cc/2026/Conference/Submission5097/Reviewer_Ptc5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5097/Reviewer_Ptc5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894421706, "cdate": 1761894421706, "tmdate": 1762917868918, "mdate": 1762917868918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}