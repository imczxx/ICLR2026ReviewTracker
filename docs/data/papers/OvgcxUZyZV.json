{"id": "OvgcxUZyZV", "number": 8007, "cdate": 1758051117956, "mdate": 1759897815035, "content": {"title": "BRIDGE: A Risk-Aware Framework for Evaluating Behavioral Fidelity in LLM Agents", "abstract": "We study behavioral fidelity: whether a conversational agent reliably enacts intended aims. While recent work evaluates accuracy or task success, it offers limited tools for calibrated behavioral assessment in multi-turn dialog. We present \\textsc{BRIDGE}, a selective evaluation framework with deterministic gates for validity and safety, a probabilistic judge for trait scoring, and a conformal-inspired mapper that converts scores to \\{\\texttt{yes}, \\texttt{ambiguous}, \\texttt{no}\\} using per-trait dual thresholds centered at empirical human prevalence with half-width \\((1-\\kappa)/2\\), where \\(\\kappa\\) is interrater agreement. A dialog passes only if all relevant traits are \\texttt{yes}; otherwise, it abstains and escalates. Thresholds are derived from a small, disjoint, human-annotated calibration set. On 5{,}960 dialogs across two domains and two aims, 87.7\\% pass without human review, and abstentions concentrate in semantically appropriate traits. Stored thresholds match the declared rule to machine precision.", "tldr": "BRIDGE measures behavioral fidelity via validity/safety gates, a calibrated probabilistic judge, and conformal style dual thresholds that trigger abstention and escalation; tested on 5,960 multi turn synthetic dialogs.", "keywords": ["LLM-based Agents", "Behavioral Fidelity", "Evaluation Frameworks", "Conformal Prediction", "Guardrails", "Trustworthiness", "Dialog Behavior Analysis", "Conversational Recommender Systems"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e0d0e032fd9e2ee7846bb238b240fa42c4ff2b48.pdf", "supplementary_material": "/attachment/2f169c17af486d202a2c1cb986f6a3abb7a7f3fc.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes BRIDGE, a risk-aware framework for evaluating behavioral fidelity in multi-turn conversational agents. The authors distinguish between two structured interaction aims—EDUCATIVE and EXPLORATIVE—and define a set of behavioral traits associated with each aim (e.g., transparency, cognitive support, self-reflection, curiosity, discovery, and serendipity). The proposed Gate–Judge–Mapper pipeline consists of four deterministic gates that ensure formal validity, a probabilistic Judge that evaluates the quality of behaviors, and a conformal-inspired Mapper that maps trait scores to YES/NO/AMBIGUOUS categories through calibrated thresholds.\nThe goal is to provide a reusable, risk-aware evaluation framework that explicitly manages uncertainty and ensures that multi-turn agents reliably exhibit intended behavioral patterns under different instructed aims, abstaining or escalating when uncertainty arises."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\t**Novel risk-awareness and uncertainty handling**: The framework explicitly incorporates risk-awareness by quantifying uncertainty through calibrated thresholds and abstention logic. This design aligns with real-world deployment needs and contributes to safe and trustworthy conversational systems.\n\n2.\t**Rigorous calibration and decision mechanism**: The use of Cohen’s κ to quantify inter-annotator agreement and define confidence margins ensures statistical grounding. The aim-level fidelity score further captures the weakest behavioral dimension, providing a comprehensive fidelity metric."}, "weaknesses": {"value": "1.\tThe proposed calibration and decision mapping in BRIDGE lack theoretical coherence. The framework combines two inherently incompatible scales—a probabilistic score pt output by an LLM-as-Judge and empirical prevalence values derived from human annotations. The Judge’s scores are not calibrated probabilities; they merely reflect unnormalized model confidence, and thus cannot be meaningfully compared with human-derived frequency estimates. Directly thresholding these uncalibrated scores against prevalence-based bounds (adjusted by 1−κt) results in arbitrary interval slicing rather than principled uncertainty estimation. Moreover, Cohen’s κ measures inter-rater reliability, not probabilistic uncertainty, so treating 1−κt as a confidence width is theoretically unfounded. In essence, the mapping rule operates on mismatched probability spaces, rendering the “risk-aware” decision logic heuristic at best.\n---\n2.\tSimilarly, the design of the rule-based gates (G1–G4) appears ad hoc and insufficiently justified. The choice of filters—retrieval sufficiency, contradiction detection, dialog-act coverage, and tone control—does not stem from a clear theoretical framework for uncertainty assessment. These rules capture surface-level validity but do not guarantee comprehensive evaluation of epistemic or behavioral uncertainty. The authors should further clarify the rationale for selecting these specific gating dimensions and explain how they collectively approximate uncertainty or behavioral risk in multi-turn dialogue."}, "questions": {"value": "see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KNaVYXnD5B", "forum": "OvgcxUZyZV", "replyto": "OvgcxUZyZV", "signatures": ["ICLR.cc/2026/Conference/Submission8007/Reviewer_9S4r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8007/Reviewer_9S4r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761549301037, "cdate": 1761549301037, "tmdate": 1762920009245, "mdate": 1762920009245, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response: New Organic Experiments, Sensitivity Analysis & Theoretical Clarifications"}, "comment": {"value": "We thank the reviewers for their constructive feedback. In response to the consensus regarding ecological validity, calibration stability, and robustness, we have performed significant new analysis which we summarize here.\n\n### 1. New \"In-the-Wild\" Organic Study (Ecological Validity)\nTo address concerns that our synthetic testbed was \"too clean\", we applied BRIDGE to **61 organic dialogs** from a deployed Conversational Recommender System (CRS). Unlike the synthetic set, organic dialogs frequently trigger the gates. Specifically, Gate 4 (Tone/Verbosity) rejects 25% of organic sessions, validating that the gates are effective filters for real-world failures.\n\n**Table R1: CRS-61 Gate Outcomes (Organic Data)**\n\n| Gate | Strict Pass | Any-pass | Selectivity Note |\n| :--- | :--- | :--- | :--- |\n| **G1 (Retrieval)** | 48/61 | 61/61 | Flags 13 sessions with ungrounded turns. |\n| **G2 (Contradiction)**| **10/61** | **61/61** | **Flags 128 turns; Used as a turn-level screen to flag specific risks.** |\n| **G3 (Aim Coverage)** | 55/61 | 55/61 | 6 sessions failed to attempt the aim. |\n| **G4 (Tone)** | **46/61** | 61/61 | **24.6% of sessions rejected** for tone/verbosity. |\n\n### 2. Sensitivity & Intra-Model Variance (Robustness)\nTo address robustness concerns, we analyzed the stability of the Judge using a new prompt-paraphrase test on the CRS-61 dataset.\n* **Data:** We tested 3 paraphrased prompts per trait. While raw trait scores fluctuated (mean range $0.34$), the $\\kappa$-derived abstention bands successfully absorbed this variance.\n* **Key Stat:** The final **Pass/Abstain decision changed in only 2.1% of cases**. This confirms decisions are driven by content ambiguity, not prompt artifacts.\n\n### 3. Calibration Stability Analysis\nTo address sample size concerns ($N=40$), we performed a bootstrap analysis (1,000 resamples). The 95% Confidence Intervals for the thresholds are narrow (Standard Error $< 0.02$), confirming statistical sufficiency for estimating the central tendency of human agreement in this domain.\n\n### 4. Theoretical Stance\nWe clarify that BRIDGE operates on a paradigm of **Human-Centric Reliability**. We do not claim to calibrate model probabilities (as in Conformal Prediction); rather, we map decision boundaries to **human label noise** ($\\kappa$). This ensures the system abstains specifically where humans themselves disagree."}}, "id": "iklxloHET3", "forum": "OvgcxUZyZV", "replyto": "OvgcxUZyZV", "signatures": ["ICLR.cc/2026/Conference/Submission8007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8007/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763554211847, "cdate": 1763554211847, "tmdate": 1763554211847, "mdate": 1763554211847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces BRIDGE, a risk-aware, selective evaluation pipeline for “behavioral fidelity” of conversational LLM agents. The system applies four deterministic gates (retrieval sufficiency, contradiction screen, dialog-act coverage, tone/verbosity), a probabilistic LLM Judge that scores per-trait behavior, and a “conformal-inspired” mapper that maps trait scores to {YES, AMBIGUOUS, NO} using dual thresholds centered at human prevalence with half-width ($(1-\\kappa)/2 $) (κ = inter-rater agreement). A dialog passes only if every required trait is YES; otherwise the system abstains. Experiments cover 5,960 synthetic 12-turn dialogs across two domains (Travel, Lifestyle) and two aims (EDUCATIVE, EXPLORATIVE), reporting that 87.7% of dialogs pass without human review and that abstentions cluster in semantically aligned traits (e.g., Self-reflection for educative). The calibration slice is small (40 dialogs, two raters) and provides prevalence and κ to freeze thresholds; the authors emphasize “process guarantees” (frozen thresholds, disjoint calibration/eval) rather than distribution-free risk guarantees, while claiming compatibility with conformal risk control."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Modular and transparent design.** This paper proposes a clearly structured evaluation pipeline that separates deterministic gates from probabilistic judgment, allowing explicit abstention and traceable decisions.\n- **Basic robustness diagnostics.** This paper include small but systematic sensitivity checks by perturbing the upper threshold (ε ∈ {0.00, 0.02, 0.05}) and by comparing against a naïve single-cutoff baseline. The monotonic and stable pass-rate responses demonstrate at least internal consistency of their scoring rule, and confirm that the dual-threshold formulation avoids trivial boundary effects\n- **Reproducibility and transparency.** Thresholds are frozen and versioned; computational cost, API usage, and evaluation setup are reported in detail, ensuring auditability and replicability."}, "weaknesses": {"value": "- **Calibration evidence is too thin to justify trait-level operating points.** All thresholds are derived from n=40 dialogs with two raters, yielding wide CIs for κ/ICC; the method’s central construct ($(1-\\kappa)/2)$ half-width) is therefore pegged to a noisy estimate. The paper asserts robustness to CI endpoints, but this remains a post-hoc simulation over stored scores rather than a prospective evaluation with re-annotated calibration.\n- **The overall framing of the paper is difficult to follow.** The structure frequently alternates between conceptual discussion, procedural details, and empirical results without clear separation. Many core ideas (e.g., process guarantees, risk bands, trait schema) are introduced abruptly without formal definitions or figure-based intuition, so the narrative feels fragmented.\n- **Insufficient reliability in calibration setup (κ with two raters only).** The calibration and inter-rater agreement analysis (Section 3.3) is based on n = 40 dialogs annotated by only two raters. In standard reliability measurement, at least three independent annotators are typically required to obtain a stable κ estimate and to mitigate pairwise bias or chance alignment.\n- **Limited and homogeneous evaluation scenarios** Although the paper claims domain-agnostic applicability, all experiments are confined to two highly similar synthetic settings (Travel and Lifestyle) and two behavioral aims (Educative and Explorative). These scenarios share nearly identical linguistic and topical structures, providing little evidence that BRIDGE generalizes beyond templated, model-generated conversations.\n- **Arbitrary and unverified design choices.** The selection of exactly four deterministic gates, the use of fixed per-trait thresholds, and the adoption of a “frozen threshold” policy are not justified empirically or theoretically. The paper does not present ablation or sensitivity analyses that could validate these design decisions. The architecture feels handcrafted rather than systematically motivated."}, "questions": {"value": "- **On prompt sensitivity and interpretability**. How consistent are Judge outputs under small prompt paraphrases or reordering of context? Have you evaluated intra-model variance (same model, same dialog, different seeds or paraphrased traits)? Such an analysis would clarify whether the abstention mechanism is stable to linguistic perturbations rather than prompt artifacts.\n- **On scenario diversity and generalization**. Although BRIDGE is claimed to be domain-agnostic, all evaluations use synthetic dialogs from two very similar domains (Travel, Lifestyle). How would the pipeline handle open-domain or safety-related conversations, or multilingual settings? Which components (gates, Judge, or thresholds) would require re-tuning to generalize beyond the tested domains?\n- **On κ-based threshold derivation**. The dual-threshold rule is centered at human prevalence with half-width ($(1 - κ)/2 $). Could you provide theoretical or empirical justification for why κ should determine abstention width? Have you compared this approach with alternative uncertainty calibrations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ne9gUWqCNE", "forum": "OvgcxUZyZV", "replyto": "OvgcxUZyZV", "signatures": ["ICLR.cc/2026/Conference/Submission8007/Reviewer_XZRL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8007/Reviewer_XZRL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761797061144, "cdate": 1761797061144, "tmdate": 1762920006936, "mdate": 1762920006936, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work introduces BRIDGE, a risk-aware, selective evaluation framework for assessing behavioral fidelity—the extent to which conversational LLM agents reliably enact intended behavioral aims such as being educative (e.g., transparent, cognitively supportive) or explorative (e.g., curious, serendipitous). BRIDGE combines deterministic gates (for validity, safety, act coverage, and tone), a probabilistic Judge (to score domain-specific behavioral traits), and a conformal-inspired mapper that converts scores into {yes, ambiguous, no} decisions using dual thresholds centered on empirical human prevalence and calibrated by interrater agreement (κ). A dialog passes only if all relevant traits are labeled “yes”; otherwise, the system abstains and escalates for human review. Evaluated on 5,960 multi-turn dialogs across Travel and Lifestyle domains, BRIDGE achieves an 87.7% pass rate without human intervention, with abstentions concentrated in semantically appropriate traits. Thresholds are derived from a small, disjoint human-annotated calibration set, ensuring auditability, reproducibility, and compatibility with formal risk-control methods like conformal prediction."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. BRIDGE explicitly abstains from making judgments when uncertain, routing ambiguous or low-confidence cases to human review, thereby reducing overclaiming and supporting high-stakes deployment.\n\n2. Thresholds for behavioral traits are derived from empirical human prevalence and interrater agreement (Cohen’s κ), grounding evaluation in real human judgments rather than raw model confidence."}, "weaknesses": {"value": "1. One notable weakness of BRIDGE is its reliance on a relatively small and potentially non-representative human calibration set. The framework derives all its decision thresholds from just 40 annotated dialogs (20 per aim) rated by only two annotators. While the authors report moderate to substantial interrater agreement, such a limited sample may not capture the full diversity of real-world interactions, especially across different user demographics, linguistic styles, or edge cases. This raises concerns about the generalizability of the thresholds and whether they would remain valid under distributional shifts or in more complex, organic conversational settings.\n\n2. Another limitation lies in the synthetic nature of the evaluation environment. All 5,960 dialogs were generated programmatically using fixed user seeds and controlled retrieval contexts, which may not reflect the messiness, ambiguity, or unpredictability of real user interactions. The absence of actual user feedback or longitudinal engagement metrics means the study cannot assess whether high behavioral fidelity as defined by BRIDGE actually translates to improved user satisfaction, trust, or task outcomes. This gap between controlled benchmark performance and real-world utility weakens the ecological validity of the findings.\n\n3. The framework also assumes that behavioral aims can be cleanly decomposed into a fixed set of discrete, observable traits, such as \"self-reflection\" or \"serendipity\", which may oversimplify the nuanced and context-dependent nature of human-like conversation. Some of these traits are inherently subjective and difficult to operationalize consistently, even for human raters. Although interrater agreement is reported, the binary or Likert-based labeling scheme may not fully capture the spectrum of behavioral expression, potentially leading to rigid or misaligned evaluations when applied to more fluid or culturally varied dialogues.\n\n4. The computational and operational overhead of maintaining the BRIDGE pipeline may pose scalability challenges. Although the local components run efficiently, the system depends on an external LLM-as-a-Judge (e.g., GPT-4.1), which introduces latency, cost, and dependency on third-party APIs. While the per-dialog cost is modest, it accumulates at scale and may become prohibitive for high-volume applications. Additionally, the need for human review of 12.3% of dialogs—though reduced from 100%—still requires staffing, training, and coordination, which could be a barrier for teams without access to expert reviewers or robust escalation workflows."}, "questions": {"value": "Please refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z2jQbwz8MM", "forum": "OvgcxUZyZV", "replyto": "OvgcxUZyZV", "signatures": ["ICLR.cc/2026/Conference/Submission8007/Reviewer_ddaK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8007/Reviewer_ddaK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899076304, "cdate": 1761899076304, "tmdate": 1762920006522, "mdate": 1762920006522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the BRIDGE framework for evaluating behavioral fidelity in conversational agents, focusing on selective evaluation and human-anchored calibration to ensure reliable performance in multi-turn dialogues."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The BRIDGE framework provides a structured and innovative approach to evaluate behavioral fidelity in conversational agents, focusing on traits like transparency, cognitive support, curiosity, and serendipity.\n\n- The use of deterministic gates and probabilistic judgment ensures a robust and auditable evaluation process, reducing human workload by 87.7% while maintaining high precision.\n\n- The framework is domain-agnostic and can be adapted to other conversational agent tasks by swapping the trait schema and recalibrating thresholds."}, "weaknesses": {"value": "1. The introduction provides a general overview of the proposed framework but lacks sufficient contextual grounding within the broader research landscape of conversational agent evaluation. It does not clearly situate the work relative to existing frameworks for behavioral assessment, safety calibration, or risk-controlled evaluation. Moreover, the discussion remains surface-level, focusing on system description rather than offering deeper analytical insights into why current evaluation paradigms are inadequate or how BRIDGE fundamentally advances the field.\n\n2. **Gate Outcomes in Table 1.** Table 1 shows that only a very small number of samples were filtered by the G1–G4 gates, with Gate2 (contradiction detection) and Gate4 (tone and verbosity control) filtering almost none. This suggests that these modules may have low sensitivity or overly loose thresholds, failing to capture potential semantic conflicts or stylistic deviations. The authors are encouraged to further analyze the detection criteria and triggering mechanisms of these two gates, and to evaluate them on more challenging or realistic conversational data to better demonstrate the framework’s filtering effectiveness.\n\n3. In sec. 4.4, the calibration set is relatively small (40 dialogs), which may introduce variability in the thresholds. ​ Larger calibration datasets could improve reliability."}, "questions": {"value": "Please refer to Weaknesses.\n\n1. The study is conducted in a controlled environment with synthetic dialogs, which may limit generalizability to real-world scenarios. ​ Please add experiments that focus on testing the framework with organic user interactions.\n\n2. Please include some concrete examples to illustrate the entire process — for instance, under what circumstances the deterministic gates are triggered and how the Judge performs scoring."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "niyeqrYbJ4", "forum": "OvgcxUZyZV", "replyto": "OvgcxUZyZV", "signatures": ["ICLR.cc/2026/Conference/Submission8007/Reviewer_K9Md"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8007/Reviewer_K9Md"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948406409, "cdate": 1761948406409, "tmdate": 1762920006137, "mdate": 1762920006137, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}