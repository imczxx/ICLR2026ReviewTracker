{"id": "5majEbTAZa", "number": 20230, "cdate": 1758303930070, "mdate": 1759896989560, "content": {"title": "Laplacian Kernelized Bandit", "abstract": "We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\\\\{f_u\\\\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified _multi-user RKHS_. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single \"lifted\" function, enabling the design of principled algorithms, LK-GP-UCB and LK-GP-TS, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an _effective dimension_ of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.", "tldr": "", "keywords": ["Bandit Problem", "Kernel Method", "Graph Laplacian Regularization"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f5c76c8752f29d9511672646ae105b4a0bef77da.pdf", "supplementary_material": "/attachment/7c96530973a9a25f081c6cb44bc68f99407f7107.zip"}, "replies": [{"content": {"summary": {"value": "The paper studies multi-user contextual bandits where users are connected by a known graph and have nonlinear reward functions. It builds a joint RKHS kernel combining (i) graph smoothness via the Laplacian and (ii) nonlinear structure over arms, and then runs GP-UCB / GP-TS on this kernel. It proves regret bounds that depend on an effective dimension of the graph+kernel, not just number of users, and shows strong performance in experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Gives a clean unified kernel that fuses graph structure and nonlinear rewards in one theory.\n- Provides GP-UCB / GP-TS algorithms that share information across similar users automatically.\n- Regret scales with an effective dimension (can be much smaller than #users).\n- Shows consistent empirical gains, especially on nonlinear graph-smooth tasks."}, "weaknesses": {"value": "- The paper omits key related work. The problem setting is very close to prior work on graph-structured / collaborative contextual bandits [1][2], but these are not adequately discussed in the introduction or positioned against the proposed approach.\n\n- The baseline comparison is incomplete. Modern neural contextual bandits can learn richer representations than fixed kernels, e.g. neural GP / neural UCB style methods [3]. These should be discussed and, ideally, included as baselines.\n\n- The UCB/TS exploration terms depend on problem-dependent quantities (like the RKHS norm bound and noise level). These are not observable in practice, so the theoretical guarantees rely on tuning parameters you don’t actually know.\n\n- While the bound is written in terms of an “effective dimension” $\\tilde{d}$, the asymptotic rate is the same $\\sqrt{T}$ scaling as standard kernelized bandits. The paper does not prove matching lower bounds or show regimes where $\\tilde{d}$ is provably small, so the improvement can be marginal."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LhpH7eA29J", "forum": "5majEbTAZa", "replyto": "5majEbTAZa", "signatures": ["ICLR.cc/2026/Conference/Submission20230/Reviewer_uAXP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20230/Reviewer_uAXP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761747388912, "cdate": 1761747388912, "tmdate": 1762933724843, "mdate": 1762933724843, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "**Summary**\n\nThis paper addresses the multi-user contextual bandit problem where users are related by a graph and reward functions are both non-linear and exhibit graph homophily (i.e., connected users have similar rewards). The authors introduce a joint penalty that combines a graph smoothness term (based on RKHS distances between users) with an individual roughness penalty for each user's function. The central contribution is a proof that this intuitive, additive penalty is mathematically equivalent to the squared norm within a single, unified multi-user RKHS. The authors explicitly derive the reproducing kernel for this new space, which fuses the graph Laplacian and the base arm kernel. This unification allows them to reframe the problem as learning a single \"lifted\" function, enabling the development of GP-based algorithms. They provide regret bounds that depend on the effective dimension of this new kernel, rather than on the number of users or ambient dimension, and show empirically that their methods outperform strong baselines in non-linear settings.\n\n\n\n\n**Advantages**\n\n* The theoretical unification of the graph smoothness penalty and the individual RKHS penalties into a single, valid multi-user RKHS is the strength of this paper, providing a foundation for the proposed algorithms.\n\n* By deriving the explicit multi-user kernel, the paper bridges the gap between Laplacian regularization and kernelized bandits, allowing the direct application of powerful GP bandit machinery (UCB and TS) to the graph-based problem.\n\n* The resulting regret bounds replace a direct dependency on the number of users ($n$) with a dependency on the \"effective dimension\" of the new kernel, which captures the spectral properties of both the graph and the arm kernel.\n\n\n\n\n**Shortcoming and Questions**\n\n* The practical implementation of the proposed algorithms requires inverting a $t \\times t$ matrix at each step $t$, leading to a computational complexity that scales poorly with the number of rounds, a common issue for GP-based methods.Given that the paper suggests recursive updates as a solution, could the authors provide an experiment comparing the cumulative regret of the exact GP-UCB update versus a more scalable approximation (like the recursive formulas or a sparse GP approach) as the time horizon $T$ becomes very large?\n\n\n* The derived kernel requires the inversion of the $n \\times n$ regularized Laplacian $L_{\\rho}$, which could be computationally prohibitive if the number of users ($n$) is extremely large (e.g., millions of users). Would it be possible to conduct an experiment analyzing the scalability of the method with respect to the number of users $n$, and perhaps explore whether an approximation of $L_{\\rho}^{-1}$ (e.g., using graph sparsification or spectral methods) could maintain competitive regret?\n\n\n* The theoretical regret bounds depend on the effective dimension $\\tilde{d}$, which is data-dependent and defined based on the entire sequence of actions up to time $T$, making it an a-posteriori quantity that is not known in advance. Could the authors provide an empirical analysis plotting the growth of the effective dimension $\\tilde{d}$ relative to $T$ in the synthetic experiments, to give a clearer intuition for how this value behaves in practice?"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Please see above."}, "weaknesses": {"value": "Please see above."}, "questions": {"value": "Please see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fqHFZlDXnv", "forum": "5majEbTAZa", "replyto": "5majEbTAZa", "signatures": ["ICLR.cc/2026/Conference/Submission20230/Reviewer_ZSey"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20230/Reviewer_ZSey"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943618132, "cdate": 1761943618132, "tmdate": 1762933724428, "mdate": 1762933724428, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies multi-user contextual bandits with a known user graph. The authors show how individual RKHS-based reward modeling and graph homophily (via the graph Laplacian) come together by deriving the reproducing kernel of a unified multi-user RKHS. Using this kernel, they design GP-UCB and Thompson Sampling algorithms and analyze their regret."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Theorem 2.1 provides a clean theoretical connection between Laplacian regularization across users and RKHS-based regularization on arm features. This connection is elegant and makes the overall framework principled and well-founded.\n\n2. The proposed GP-based UCB algorithm are grounded on solid theoretical foundations. The corresponding regret bounds based on the effective dimension are sharp and well-justified, making the theoretical contribution of the paper clear and convincing."}, "weaknesses": {"value": "1. The formulation mainly builds on previous work on linear Laplacian bandits by extending the idea from linear models to general RKHS functions. While the conceptual novelty is moderate, I think this extension is meaningful and technically non-trivial, as it requires re-deriving the RKHS characterization and associated regret analysis.\n\n\n2. I am a bit confuse about the result for TS, as described below in detail."}, "questions": {"value": "I am a bit surprised by the reported TS result. With a naive TS design, the paper claims a frequentist regret of order $d\\sqrt{T}$. However, up to my knowledge, even in the simpler linear bandit setting, the naive version of TS typically achieves only $d^{3/2}\\sqrt{T}$ frequentist regret, and stronger results usually require additional design modifications such as the feel-good TS algorithm [1]. Could the authors clarify what differs in their analysis that allows this improved bound? Or are there extra assumptions that effectively bypass the limitations known in previous TS literature?\n\n\n\n[1] Zhang, Tong. \"Feel-good thompson sampling for contextual bandits and reinforcement learning.\" SIAM Journal on Mathematics of Data Science 4.2 (2022): 834-857."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rCF6ugHuU9", "forum": "5majEbTAZa", "replyto": "5majEbTAZa", "signatures": ["ICLR.cc/2026/Conference/Submission20230/Reviewer_xoe9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20230/Reviewer_xoe9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968936892, "cdate": 1761968936892, "tmdate": 1762933724007, "mdate": 1762933724007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of multi-user contextual bandits and proposed a framework based on a novel penalty that explicitly captures the relations between the user reward functions. The authors went on to provide a justification of this penalty by linking it to a multi-user RKHS, which allows for the development of two Gaussian process based algorithms. Theoretical result on  the regret bound has been derived for both algorithms, and experimental results validate their  effectiveness and superiority over existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles an under-explored but interesting problem.\n- The formulation of the penalty and its link to a RKHS is interesting and provides guidance on how relational information can be taken into account in learning.\n- Theoretical results on regret bounds are a plus.\n- The paper is generally well presented with clear motivation and technical descriptions."}, "weaknesses": {"value": "**Connection to existing literature.** I believe it would be helpful for the authors to make a greater effort connecting their approach to similar attempts in the literature:\n- First, the link between kernels and regularisations, as well as its extension to the graph case via the graph Laplacian, has been well-documented in the literature [1], and in my view this should be properly discussed in the derivation of the proposed approach.\n- Second, the way the graph structure is incorporated into learning bears similarly with recent work in the space of multi-output and graph-based GPs, where this is done either implicitly [2] or explicitly [3,4]. I feel additional discussion and comparison against those would make the contribution of the paper conceptually clearer. \n\n**Technical framework.** The paper only focuses on a smoothness assumption, which is a reasonable starting point, however I was left wondering whether this can be generalised to the case where the user reward relations are more complex? I feel this should be possible to address by following for example the spectral learning approach in [4]. \n\n**Experiments.** Experimental results, while convincing, are relatively brief:\n- Can the authors demonstrate the impact of different graph topology on learning performance, for example by using graphs generated from the stochastic block model? I think this can connect nicely to the discussion on effective dimension. \n- Can the authors provide ablation studies that demonstrate the utility of both the graph-based kernel and the classical kernel in the Kronecker product? \n- All experiments are synthetic at the moment, can the authors think about potential real-world experiments? This can also help a reader appreciate the practical utility of the proposed approach.\n\n[1] Smola and Kondor, “Kernels and Regularization on Graphs,” COLT, 2023.\n\n[2] Alvarez et al., “Kernels for vector-valued functions: A review,” Foundations and Trends in Machine Learning, 2012.\n\n[3] Venkitaraman et al., “Gaussian processes over graphs,” IEEE ICASSP, 2020.\n\n[4] Zhi et al., “Gaussian Processes on Graphs Via Spectral Kernel Learning,” IEEE TSIPN, 2023."}, "questions": {"value": "See weaknesses above for the specific points I would like the authors to address or discuss."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8BcD7p7CNS", "forum": "5majEbTAZa", "replyto": "5majEbTAZa", "signatures": ["ICLR.cc/2026/Conference/Submission20230/Reviewer_jACQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20230/Reviewer_jACQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762189471363, "cdate": 1762189471363, "tmdate": 1762933723501, "mdate": 1762933723501, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}