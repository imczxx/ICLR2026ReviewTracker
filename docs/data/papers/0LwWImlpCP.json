{"id": "0LwWImlpCP", "number": 18263, "cdate": 1758285746596, "mdate": 1759897115734, "content": {"title": "Electrostatics from Laplacian Eigenbasis for Neural Network Interatomic Potentials", "abstract": "In this work, we introduce $\\Phi$-Module, a universal plugin module that enforces Poisson’s equation within the message-passing framework to learn electrostatic interactions in a self-supervised manner. Specifically, each atom-wise representation is encouraged to satisfy a discretized Poisson's equation, making it possible to acquire a potential $\\boldsymbol{\\phi}$ and a corresponding charges $\\boldsymbol{\\rho}$ linked to the learnable Laplacian eigenbasis coefficients of a given molecular graph. We then derive an electrostatic energy term, crucial for improved total energy predictions. This approach integrates seamlessly into any existing neural potential with insignificant computational overhead. Our results underscore how embedding a first-principles constraint in neural interatomic potentials can significantly improve performance while remaining hyperparameter-friendly, memory-efficient and lightweight in training.", "tldr": "A universal plugin module for neural network interatomic potentials which enables electrostatic energy in a self-supervised manner", "keywords": ["Graph Neural Networks", "Scientific Machine Learning", "Quantum Chemistry", "Message Passing Neural Networks", "Long-Range Interactions", "AI4Science", "Neural Interatomic Potentials"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a990d17e092ee9c52db4feeed0aead6a941aa0c9.pdf", "supplementary_material": "/attachment/5b69f92c64566cfb011f5c0da63335ae9595325d.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Φ-Module, a plug-and-play Laplacian-eigenbasis module that embeds the Poisson equation as a self-supervised physical constraint within graph neural network (GNN) interatomic potentials."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposed module can predict atomic potential ϕ and charge ρ from learned eigenbasis coefficients and adds an electrostatic energy term to improve total-energy and force predictions."}, "weaknesses": {"value": "The paper repeatedly claims that Φ-Module captures non-local electrostatic interactions, yet no benchmark explicitly demonstrates this. Improvements in energy and force MAE alone are insufficient proof of non-local interaction modeling.\n\nFor MD22, the authors selected two of the smallest molecules, while the claim centers on modeling non-local interactions. Larger systems such as Ac-Ala15-NHMe or DHA are more appropriate to evaluate the alleged long-range capability. Without them, the argument remains speculative.\n\nOn the OE62 experiments, the baselines (SchNet, DimeNet++, PaiNN, etc.) are 2019–2021 architectures. Recent high-order equivariant models—MACE, eSCN, NequIP, Equiformer-V2, ViSNet—represent the current state of the field. Because the Φ-Module is advertised as a general plug-in, results on these modern architectures are essential for a credible evaluation. \n\nOn the MD22 experiments, the reported performance differences from the original ViSNet paper are unusually large for the same datasets. The authors should clarify training settings (data splits, learning rates, cutoff, etc.) and reproduce the original ViSNet baseline under identical conditions."}, "questions": {"value": "See Section Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1YWKCNP0ES", "forum": "0LwWImlpCP", "replyto": "0LwWImlpCP", "signatures": ["ICLR.cc/2026/Conference/Submission18263/Reviewer_QJiW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18263/Reviewer_QJiW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760545341110, "cdate": 1760545341110, "tmdate": 1762927988607, "mdate": 1762927988607, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces $\\Phi$-Module, an extension to atom-based machine learning interatomic potentials that intends to resolve long-range energy contributions. $\\Phi$-Module is derived from the discretized Poisson equation for electrostatics and uses the graph Laplacian for efficient long-range propagation. In their experimental evaluation, the authors find the $\\Phi$-Module to be an effficient addition to MLIAP, reducing errors at low computational overheads."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The proposed $\\Phi$-module presents a novel addition to the field of MLFFs.\n* The experiments suggest a very valuable extensions with favorable runtime-accuracy tradeoff.\n* $\\Phi$-module appears quite modular and presents an easy integration."}, "weaknesses": {"value": "1. The authors claim that their method is self-supervised and does not need external labeled data (l.50-51 + abstract). However, the losses introduced in l.174 and l.179 do not ensure that predictions improve, the method additionally **needs** the standard supervised learning loss.\n2. The use of 1D convolutions over the nuclei breaks the permutation invariance. I find the paper lacks to discuss this disadvantage. One could in general neglect permutation invariance in MLFFs, does that yield similar improvements?\n3. The authors leave a lot of questions open or are not specific in several key areas, see questions.\n\n\nMinor:\n* l.26-33: DFT and MLFFs are quite different things and the section suggest they accomplish the same.\n* l.34 which alternatives?\n* Table 1 is never referenced.\n* l.432 formatting"}, "questions": {"value": "1. What is used as graph connectivity for the graph laplacian? A radial cutoff or molecular bonds? In either case, doesn't bond-breaking or going out of the cutoff radius, introduces jumps in the energy surface?\n2. Why is the Laplacian weighted by the pairwise distance, intuitively, I'd expect it to be weighted by the inverse of the distance?\n3. l.173 is the same alpha-Net used for phi and rho?\n4. Couldn't one enforce the PDE and net zero loss analytically? How does that compare to training?\n5. What is the x-axis in Figure 4? (Also the figure is never referenced)\n6. Table 1: What about other MLFF+Phi module combinations?\n7. Are the hyperparameter optimization from l.684 used for all experiments? This seems quite excessive given that no hyperparameter optimization is done for any of the baseline models.\n8. What units are Table 4 and what target, which dataset, etc?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TNF7WGIToC", "forum": "0LwWImlpCP", "replyto": "0LwWImlpCP", "signatures": ["ICLR.cc/2026/Conference/Submission18263/Reviewer_oDat"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18263/Reviewer_oDat"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917085975, "cdate": 1761917085975, "tmdate": 1762927988117, "mdate": 1762927988117, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a module for learning the electrostatic interactions for interatomic potentials based on sparse graph neural networks and Poisson equation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed method is simple yet performative.\n- The paper is very well presented with the advantage of the designed model clearly highlighted.\n- The tradeoff between efficiency and performance is discussed in detail.\n- The problem addressed in this paper is of importance to the molecular modeling community."}, "weaknesses": {"value": "- There seems to be limited novelty in the proposed graph representation module."}, "questions": {"value": "- Could you kindly elaborate more on the choice of using spectral graph neural networks, rather than the spatial ones, which are more popular?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x7cdhiOgA5", "forum": "0LwWImlpCP", "replyto": "0LwWImlpCP", "signatures": ["ICLR.cc/2026/Conference/Submission18263/Reviewer_H2RH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18263/Reviewer_H2RH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010766311, "cdate": 1762010766311, "tmdate": 1762927987192, "mdate": 1762927987192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a Phi module, a module that can be added to any MLIP architecture to introduce a long-range electro statics inductive bias. They imitate the computational structure of a poission equation to learn a sort of latent charges that can be trained self-consistently."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-The method is well motivated and makes intuitive sense\n-The experimental evaluation is thorough\n-The improvements are very consistent"}, "weaknesses": {"value": "-The accuracy improvements are rather small\n-The spectral decomposition introduces an N^2 scaling operation, which could become problematic for larger-scale simulations. The paper only benchmarks memory, but not runtime with system size; this should be benchmarked and could change my opinion\n-There have been works before that incorporate explicit charge equilibrium/coulomb interactions, in particular https://www.nature.com/articles/s41467-020-20427-2 . A comparison would be appropriate\n- The phi module only targets electrostatics and not other long range effects, which may make fully learned approaches preferable"}, "questions": {"value": "- Do you use a dense connectivity graph L? And why is it weighted by d_ij, doenst this imply that far away atoms interact stronger than closer ones?\n- Why did you use VisNet in favour of a newer architecture?\n\nRemark:\n\"In quantum chemistry, the task of correct prediction of atomic energies is paramount, but stands\na great challenge…” Atomic energies are not a well defined concept, did you mean molecular energies?\n“Some of those require prior data in the form of partial charges or\ndipole moments, which is costly to retrieve using DFT”, If the DFT calculation is already converged to get the molecular energies, it is trivial to get dipoles or partial charges at negligible costs\n“...and gives the opportunity to process large macromolecules with the Φ-Module. This decision also keeps us away from the ambiguity of invariance and sorting of eigenvalues and eigenvectors during their computations - we strictly get k-selected eigenvalues and their corresponding eigenvectors without the need to sort them anyhow.” This is not convincing, if the Laplacina has a degenerate eigenspace the order will be arbitrary and specifics will be subject to numerical noise, a conjugated gradient solver doesnt change this"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6Cys8Q4YDy", "forum": "0LwWImlpCP", "replyto": "0LwWImlpCP", "signatures": ["ICLR.cc/2026/Conference/Submission18263/Reviewer_gZro"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18263/Reviewer_gZro"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762043218675, "cdate": 1762043218675, "tmdate": 1762927986700, "mdate": 1762927986700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Φ-Module, a physics-informed plugin designed to integrate electrostatic interactions into graph neural networks in a self-supervised way. By enforcing Poisson’s equation within the message-passing framework, Φ-Module enables models to learn atomic potentials and charges represented in the Laplacian eigenbasis of molecular graphs. This approach captures long-range electrostatic effects that standard local message passing often misses. The module includes a lightweight subnetwork, α-Net, that predicts eigenbasis coefficients, allowing derivation of an electrostatic energy term that improves total energy predictions with minimal computational overhead. Experiments on the OE62 and MD22 benchmarks show accuracy gains across several neural potentials"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes an integration of a first-principles physical law (Poisson’s equation) into GNN-based interatomic potentials. By embedding the Poisson constraint, the model learns to produce physically meaningful electrostatic potentials and charges in a self-supervised way, without requiring any ground-truth charges or external fields.\n2. Φ-Module is designed as a universal augmentation that can be attached to essentially any GNN architecture for molecules. The authors demonstrate this generality by incorporating Φ-Module into multiple established models \n3. A claimed advantage is that Φ-Module introduces very little overhead. The spectral α-Net and Laplacian eigenbasis computation are lightweight, adding roughly 5–10% to training time per epoch and a modest amount of memory usage."}, "weaknesses": {"value": "1. The biggest weakness is generalizability and scalability. Experiments are restricted to OE62 and MD22. There’s no end-to-end training on truly realistic, large, diverse, million–sample datasets (e.g., OMol 25) or cross-dataset transfer demonstrating generalization across broader chemistries. As a result, it’s unclear how Φ-Module scales in sample size or generalizes to diverse systems.\n2. Although the overall results favor Φ-Module, the improvements are not uniformly overwhelming. In OE62, one baseline GNN saw only ~5% error improvement with Φ-Module, which is relatively modest. On MD22, the Φ-augmented model did not win on every single metric – the original ViSNet still had the best outcome on 2 of the 14 comparisons, and in 3 of 14 cases Φ-Module failed to set a new state-of-the-art. This indicates that the benefits, while present, can be incremental, task-dependent, or just random (no error bar / std is given)\n3. As a plug-in, Φ-Module adds four new hyperparameters and extra computations (solving for eigenvectors) to a model. While the authors argue this is lightweight, one might be concerned about implementation complexity."}, "questions": {"value": "1. Could you clarify how the Laplacian eigenpairs are computed during training? The paper suggests using a fixed number k of eigenvectors and a batched eigendecomposition approach. Is this done via an iterative solver each message-passing step, or are eigenvalues computed once per epoch/structure and reused? \n2. The paper references alternatives like adding Ewald summation to GNNs or using pre-computed partial charges. Did you consider comparing Φ-Module’s performance to such methods? \n3. Beyond the tasks in this paper, how general is Φ-Module’s applicability? For instance, can it handle systems with periodic boundary conditions (common in materials simulations where Ewald is often needed)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qzkP0wlSnn", "forum": "0LwWImlpCP", "replyto": "0LwWImlpCP", "signatures": ["ICLR.cc/2026/Conference/Submission18263/Reviewer_GKpD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18263/Reviewer_GKpD"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762079319877, "cdate": 1762079319877, "tmdate": 1762927986302, "mdate": 1762927986302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}