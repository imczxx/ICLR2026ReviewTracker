{"id": "3GH2fZd9pI", "number": 20523, "cdate": 1758307070500, "mdate": 1759896973550, "content": {"title": "Shaping Robotic Actions with Fourier Flow Matching", "abstract": "We present a Fourier-based flow-matching method for Vision-Language-Action (VLA) policies that lets the policy reason over smooth trajectories, rather than stepwise actions. Instead of training on raw joint- or Cartesian-space action sequences, we project each sequence into a compact Discrete Cosine Transform (DCT) basis and learn directly in coefficient space via flow matching. This trajectory-level representation enforces smoothness and reduces dimensionality. Importantly, we show that the DCT representation integrates with asynchronous plan-execute schemes, preserving policy responsiveness. In experiments, predicting DCT coefficients yields higher task success than classical flow matching VLA baselines trained on per-step actions. Our results indicate that Fourier-domain flow matching is a simple, drop-in alternative that improves the performance and stability of VLA policies.", "tldr": "Fourier-based flow-matching method for Vision-Language-Action (VLA) policies.", "keywords": ["Vision-Language-Action Models", "Generalist Policies", "Robotic Manipulation", "Robotics"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/486c50419533f06b71e14a76328d04834fdc06ea.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a Fourier-based flow-matching method (FFM) for VLA policies, which is presented as a variant of flow matching. Compared to standard flow matching, FFM performs flow matching in a compact Fourier domain using forward and inverse Discrete Cosine Transform (DCT). The authors argue that this trajectory-level representation yields smoother and lower-dimensional embeddings that facilitate policy learning. However, the overall contribution is thin: the work primarily grafts a common signal processing tool (DCT) into flow matching. With very limited experiments, the paper fails to convincingly validate its claims or provide new insights."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The choice of representation space is indeed a relevant issue for VLA research. The DCT-based representation seems simple, plug-and-play, and easy to implement."}, "weaknesses": {"value": "1.\tLimited contribution: The method is essentially just a change of representation (stepwise actions → DCT space). The properties of this space are not theoretically or empirically validated. Moreover, the paper does not clarify what practical advantages this representation enables (e.g., can it support cross-embodiment policies?).\n\n2.\tLack of theoretical analysis: The paper provides no rigorous theoretical justification. The claim that “DCT enforces smoothness and reduces noise” is neither new nor well supported.\n\n3.\tInsufficient experimental support: Experiments are restricted to PushT simulation and two simple tabletop tasks (collecting and precise packing) on UR10. These toy tasks are insufficient to demonstrate scalability. In PushT, the baseline even slightly outperforms FFM; only in packing does FFM achieve a relative gain. The study compares against only one baseline (stepwise flow matching, Black et al. 2024) and omits broader comparisons (e.g., diffusion policy, autoregressive or tokenized action methods).\n\n4.\tPoor literature coverage: The paper cites only 11 references, which fail to reflect the breadth of prior work. Many relevant works on trajectory/action representations and policy learning are not cited."}, "questions": {"value": "In addition to the weaknesses above:\n\n1.\tCan the authors provide more theoretical analysis to substantiate claims of smoothness and explain the practical downstream benefits of this representation (e.g., improved downstream success rates for pre-training VLAs, cross-embodiment generalization)?\n\n2.\tCan the authors compare against stronger baselines, such as diffusion policies, autoregressive models, or tokenization-based approaches?\n\n3.\tCan FFM be scaled to large-scale VLA training or cross-embodiment transfer, which are central to current VLA research?\n\n4.\tAs a flow matching variant, can FFM improve the performance of open-source foundation VLA models (e.g., Pi0.5, GR00t)?\n\n5.\tSince DCT coefficient count K is not linearly correlated with success rate, does one have to rely on hyperparameter search for tuning?\n\n6.\tHow does FFM perform in contact-rich tasks or fine-grained dexterous hand manipulation scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kynLfINQ6P", "forum": "3GH2fZd9pI", "replyto": "3GH2fZd9pI", "signatures": ["ICLR.cc/2026/Conference/Submission20523/Reviewer_Q3yZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20523/Reviewer_Q3yZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761569239610, "cdate": 1761569239610, "tmdate": 1762933944383, "mdate": 1762933944383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to improve on robot control actions generated from VLAs by learning to generate the fourier coefficients of the flow field, rather than the direct flow field itself. Generating fourier coefficients of the flow field helps to ensure smooth outputs and also helps to reduce the dimensionality of the generation process."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The overall idea is interesting and reasonable. The proposed modification to flow generation is relatively straight forward."}, "weaknesses": {"value": "Unfortunately, the paper leaves a great many questions unanswered. The overall idea is not well-known but is also not completely novel, in that there have been some recent papers in functional flow matching (including Fourier functional bases), such as Kerrigan et al 2023 and Li et al 2024. How does this paper relate to that work in functional flow matching? The related work section and references are relatively brief.\n\nThe technical development is even more cursory, as there is not description of the training process, but simply a statement of what the DCT is and how the DCT co-efficients can be used to generate a flow field. There is no discussion of the training data sampling, and the relationship to the frequencies of the corresponding flow field.\n\nThe only reported metrics are success rate and completion time, but the purpose of the paper is to produce better (e.g., smoother) trajectories. It is interesting that on PushT, the baseline does slightly better (if not statistically significantly better) in success rate and the authors do not report completion time for this task. The differences between the policies are not substantial, which raises questions about whether or not this technique is especially effective in any way.\n\nThere is some analysis of the compression achieved, and one of the promises is to reduce the dimensionality, but there is no comparison to a time-series flow field representation.\n\nThe experimental demonstrations on the robot are relatively uncompelling. There is no description of a trajectory that is poorly generated by the baseline time-series flow field, and an improved trajectory from the Fourier flow field."}, "questions": {"value": "How do the authors propose to train the model?\n\nHow stable are the Fourier flow fields?\n\nHow do the authors propose to address sampling questions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M43tKrVIbr", "forum": "3GH2fZd9pI", "replyto": "3GH2fZd9pI", "signatures": ["ICLR.cc/2026/Conference/Submission20523/Reviewer_F1vP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20523/Reviewer_F1vP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761873869744, "cdate": 1761873869744, "tmdate": 1762933943661, "mdate": 1762933943661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes Fourier Flow Matching (FFM) for VLA robot policies. Instead of predicting step-wise joint/Cartesian actions like existing flow-matching models (e.g., pi-0), the FFM predicts Discrete Cosine Transform (DCT) coefficients of the trajectory and reconstructs the action sequence by inverse DCT. This encourages smoothness and reduces the dimensionality of the action. Experimental results show similar performance to a step-wise baseline in simulation and improvements on two real-world robot tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The motivation is clear, step-wise flows introduce discontinuities and high-frequency noise.\n* The methodology/implementation is straightforward, i.e., no need for tokenizer training, drop-in usage of DCT.\n* Real hardware deployments: showing improvements in precision tasks.\n* Good ablation on the number of coefficients K."}, "weaknesses": {"value": "* The originality is somehow incremental\n\t* The combination of DCT and flow-based VLA is expected since prior works (e.g., FAST/BEAST) already introduced Fourier/spline action compression effectiveness.\n* Evaluations are limited\n\t* Only a single baseline is considered\n\t* Lacks of comparions to strong AR + tokenizer models (e.g., FAST)\n* The robustness/generality of the work is not thoroughly discussed\n\t* Only show improvements for tabletop tasks, no other types of manipulations\n* Insufficient discussion of the selection of K\n\t* How to tune K in an empirical way?"}, "questions": {"value": "* Did author(s) try to train FFM from scratch? How would it end?\n* Why no comparison to FAST/BEAST, as they also adopt similar approaches with strong performance?\n* Could the author(s) provide some principles that help to choose K since the results are nonmonotonic?\n* What is the inference latency w.r.t. existing flow-based VLA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AZuShoPIOq", "forum": "3GH2fZd9pI", "replyto": "3GH2fZd9pI", "signatures": ["ICLR.cc/2026/Conference/Submission20523/Reviewer_k8dz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20523/Reviewer_k8dz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762338872470, "cdate": 1762338872470, "tmdate": 1762933943285, "mdate": 1762933943285, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Fourier Flow Matching (FFM), an approach that replaces stepwise joint/Cartesian actions in Vision–Language–Action (VLA) flow-matching policies with a compact set of DCT-II coefficients. The model learns a probability flow directly in coefficient space and reconstructs actions via inverse DCT at inference time. The authors argue that this parameterization enforces smoothness, reduces dimensionality, and decouples planning from controller rate. Experiments on PushT and two real-robot tasks show moderate improvements in success rate and slight reductions in completion time compared to a stepwise flow-matching baseline."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper introduces a simple, elegant modification to flow-matching VLA policies: representing actions in the Fourier domain via DCT coefficients. This idea is not new, but well-motivated, and it leverages established signal-processing principles to enforce smoothness and reduce high-frequency noise.\n\n2. The real-robot results—particularly on precise packing—show substantial gains in task success (e.g., 0.715 vs 0.500)."}, "weaknesses": {"value": "1. While the application of DCT parameterization to flow matching is new, action compression through Fourier[1], spline[2], or movement primitives[3] representations is not. The paper’s methodological novelty is therefore incremental: essentially swapping the raw action representation for DCT coefficients.\n\n2. The paper heavily motivates the DCT choice through intuition (smoothness priors, low-frequency dominance) but does not offer theoretical justification for why DCT is explicitly well matched to robot motion in VLA settings compared to other bases (splines, RVQ[4], movement primitives, etc.).\n\n3. No comparison against non-flow-matching, trajectory-based models. Recent autoregressive VLA models using learned tokenizers (e.g., FAST[1], BEAST[2]) could serve as competitive baselines. \n\n4. The empirical study is inefficient. The method is evaluated with only a single VLA backbone ($\\pi_0$), and tested in one simulation environment (PushT) and two relatively simple real-robot tasks. This makes it difficult to assess robustness, generalizability, or task diversity. Evaluation on additional benchmark suites—such as LIBERO or CALVIN, which contain multi-stage, long-horizon, visually diverse manipulation tasks—would significantly strengthen the empirical claims.\n\n5. The writing quality requires substantial improvement. The paper currently reads more like a technical report than a polished conference submission.\n\n[1] Pertsch, Karl, et al. \"Fast: Efficient action tokenization for vision-language-action models.\" RSS 2025.\n\n[2] Zhou, Hongyi, et al. \"BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning.\" arXiv preprint arXiv:2506.06072 (2025).\n\n[3] Scheikl, Paul Maria, et al. \"Movement primitive diffusion: Learning gentle robotic manipulation of deformable objects.\" IEEE Robotics and Automation Letters 9.6 (2024): 5338-5345.\n\n[4] Lee, Seungjae, et al. \"Behavior generation with latent actions.\" ICML 2024."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ZQlaT7QeWS", "forum": "3GH2fZd9pI", "replyto": "3GH2fZd9pI", "signatures": ["ICLR.cc/2026/Conference/Submission20523/Reviewer_j6VK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20523/Reviewer_j6VK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762598574339, "cdate": 1762598574339, "tmdate": 1762933942911, "mdate": 1762933942911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}