{"id": "v217hjzwQE", "number": 19048, "cdate": 1758293122121, "mdate": 1759897064021, "content": {"title": "LOGOS: Precision Retrieval via Logical Document Graphs for Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) systems struggle with long documents because conventional retrieval methods provide noisy, page-level context that degrades generation quality. These methods are fundamentally limited by treating documents as a linear sequence of pages, which breaks the crucial logical dependencies—like tables, paragraphs, or references—that span across page boundaries. To overcome this limitation, we propose Precision Retrieval via Logical Document Graphs for Retrieval-Augmented Generation (LOGOS), a new RAG method that achieves precision retrieval by modeling a document's intrinsic logical structure. LOGOS transforms a document into a graph where semantic regions are nodes and logical connections are edges, effectively bridging page breaks. A Graph Neural Network then generates fine-grained, context-aware representations for each node, enabling a more concise and semantically relevant context for the generator. Extensive experiments on the ViDoRe and MMDOCIR benchmarks show that LOGOS sets a new state-of-the-art, significantly outperforming strong baselines by up to 2\\%  in average Recall@1.", "tldr": "Enhancing Contextual Understanding in Long Documents via Cross-Page Heterogeneous GNN", "keywords": ["Graph Neural Network", "RAG"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bc4ead56adc23ca6e8b0c597797a7f19f5c954bb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces LOGOS, a RAG framework designed for long multimodal documents. It addresses the issue of context fragmentation caused by linear chunking. The core innovation is to model documents as logical graphs where semantic regions are nodes and their relationships are edges. A Graph Neural Network (GNN) is then used to generate context-aware embeddings for each node, aiming for more precise retrieval. The method is evaluated on retrieval benchmarks, where it outperforms recent state-of-the-art models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The conceptual shift from treating documents as linear sequences to structured graphs is highly original and significant. This approach directly tackles a fundamental limitation in how RAG systems process complex, real-world documents. Besides, the methodology is robust, leveraging components for layout analysis and graph representation learning. The ablation and sensitivity analyses are thorough and provide strong evidence for the contribution of each component. Moreover, the paper is well-written, and the core idea is presented clearly with effective visualizations."}, "weaknesses": {"value": "1. The paper targets to RAG, but the experiments are exclusively focused on retrieval metrics like Recall@K. This represents a significant gap between the paper's claims and its empirical validation.\n2. The necessity of the complex GNN-based information fusion is not fully justified. A simpler, more intuitive baseline seems plausible: one could group semantically related text blocks, link them to the images/tables they explicitly reference, and then index only the text embeddings. Retrieval would be performed on text, with linked visuals retrieved alongside. The paper fails to argue why the GNN's expensive message-passing mechanism is superior to such a heuristic-based linking approach.\n3. The \"w/o GNN\" ablation is the most critical one for assessing the core contribution, yet its exact configuration is not described. Without knowing how the embeddings are generated in this variant, it's difficult to interpret the reported 10.1-point performance drop and fairly evaluate the GNN's role."}, "questions": {"value": "1. Could you please clarify the experimental setup for the \"w/o GNN\" ablation study? \n2. Why did you choose to evaluate only on retrieval benchmarks instead of an end-to-end generation task like question answering? Could you provide any results demonstrating that LOGOS's superior retrieval leads to more accurate or factual generated outputs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xwzux4OxNn", "forum": "v217hjzwQE", "replyto": "v217hjzwQE", "signatures": ["ICLR.cc/2026/Conference/Submission19048/Reviewer_5ZQj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19048/Reviewer_5ZQj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760596369795, "cdate": 1760596369795, "tmdate": 1762931083455, "mdate": 1762931083455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LOGOS, a framework for Retrieval-Augmented Generation (RAG) targeting long and complex documents. Instead of typical chunks, LOGOS decomposes documents into fine-grained semantic regions and constructs a cross-page heterogeneous graph, embedded by GNN. Experiments on two benchmarks demonstrate Recall@K performance improvement over baselines. Ablation study and sensitivity analysis are conducted to verify the contributions of main components and the impacts of hyperparameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation for the noise caused by a broken logical structure in long documents\n- Reasonable design and exploitation of heterogeneous graph structure to reflect cross-page semantic relationships\n- Empirical experiment results on two benchmark datasets, where the proposed framework consistently outperforms baselines"}, "weaknesses": {"value": "- A motivating example is not directly addressing the core idea of this work\n    - Figure 1 mainly illustrates how excessive context could cause a performance drop at some point, but it does not show the direct necessity for logical-structure modeling, which weakens the empirical justification of the motivation.\n    - The quality and clarity of Figure 2 are low, which makes it difficult to interpret the pipeline details\n- There is a lack of sufficient discussion on existing graph-based document structuration and RAG approaches\n    - Connecting semantic components as a graph and fusing them through GNN seems reasonable, but it appears conceptually straightforward, too\n    - It would be encouraged to specifically clarify the explicit challenges in extracting semantic components, connecting them to construct a graph, or fusing this information to be effective for RAG\n    - Related work focuses briefly on benchmarks, without including a sufficient methodological comparison with existing efforts\n- Methodological design needs more improvement and justification\n    - Overall performance improvements are marginal; given no additional context of task difficulties in the relevant tasks and datasets, it is hard to justify the substantial engineering additions used in the framework\n    - No qualitative analysis was provided to specifically illustrate how the logical graph benefits retrieval performance compared with existing approaches\n    - Edge linking strategies seem to rely mostly on heuristics, and there is a lack of analysis on which edge types contribute most"}, "questions": {"value": "Please see the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TdxxgLpM1H", "forum": "v217hjzwQE", "replyto": "v217hjzwQE", "signatures": ["ICLR.cc/2026/Conference/Submission19048/Reviewer_d4sR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19048/Reviewer_d4sR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556224655, "cdate": 1761556224655, "tmdate": 1762931082852, "mdate": 1762931082852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors look at the challenge of retrieval from large documents having cross references, images , tables running across pages. They use a VGT transformer to segment the pages and then use a semi-heurestic technique (but reasonable) to map the components into a graph and then build graph embeddings out of it. This leads to better performance than other methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem is an important problem and the basis of their solution around documents having a graph structure is intuititve. Also their graph formulation is heurestic driven (e.g. spatial adjancency / cross-page continuation) but perfectly reasonable - whilst edge cases may happen it should cover most real world cases. \n\nTheir results are clearly better (numerically if not statistically) in most cases than baseline models."}, "weaknesses": {"value": "The paper provides a good experimental setup for a real problem however it is not clear how the setup is being trained and why such a training objective will lead to better results.  \n\nSpecific comments below:-\n\n1. Semantic similarity (211-213) - how do the authors propose to compute semantic similarity across modalities. \n2. Explicit reference - it is not clear as to how regex based search is scalable for a large dataset.\n3. I did not follow the loss function in the section 3.3 . How is this trained?\n4. I am confused on the online querying part. The first issue is the multimodal nature of the content but the query being most often text. But more importantly what is not clear how a text query will lead to a better mapping if the resultant vectors are GNN-enhanced. Suppose for example, the author gives an exact text it will not retrieve that since the GNN- enhancement will have rotated (and potentially scaled - no comments are there on normalization) the vectors in the db\n5. Although the authors provide results on two datasets but it would have been better if they had provided some examples (even as supplementary material) on the dataset and queries as well as some error analysis results.\n6. Table 1 and 2 should have statistical significance analysis - at least is the proposed model statistically better than the second best performing model in each case? \n7. The authors should have done a more comprehensive literature survey on the use of graphs for document structure in multimodal retrieval. \n\nMinor comment:-\n\n1. Line 106 Vidore/MMDOCIR benchmark needs a citation where it is first referred to outside of the abstract.\n2. A very special case so can be considered minor - the reading order mentioned in lines 206-211 is not valid for two-column documents like academic papers.  Some books also use this format."}, "questions": {"value": "please address the concerns in the weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MWJFxZ2tmB", "forum": "v217hjzwQE", "replyto": "v217hjzwQE", "signatures": ["ICLR.cc/2026/Conference/Submission19048/Reviewer_yEPK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19048/Reviewer_yEPK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680879564, "cdate": 1761680879564, "tmdate": 1762931082226, "mdate": 1762931082226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LOGOS, a precision retrieval method for long-document RAG. It segments pages into semantic regions (paragraphs, tables, images), converts the document into a cross-page heterogeneous graph, uses a shared text encoder (with VLM-generated textual summaries for visual regions) plus an R-GCN to produce context-aware node embeddings, and performs node-level retrieval. It has achieved strong performance on ViDoRe and MMDocIR."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Captures an important problem in RAG: content across pages is related and should not be encoded independently.\n\n2. Method is reasonable and well-motivated; reported performance is strong.\n\n3. Ablation study shows the improvement contributed by each component."}, "weaknesses": {"value": "1. Building graphs over documents is well studied in RAG (e.g., GraphRAG and its follow-ups), but the paper lacks comparison and discussion in this area. Comparisons are needed to justify the novelty of this work.\n\n2. The text encoder is under-specified.\n\n3. The paper claims that small-snippet chunking addresses page-level chunking issues, but this is not directly tested. It is recommended to add a page-level baseline (e.g., concatenate the content of each page and input it as long text to the text encoder).\n\n4. Missing related work like  “Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models,” which also focuses on building connections between chunks."}, "questions": {"value": "1. Which text encoder is used?\n\n2. Is the ground truth at the page level? If so, how is the retrieved chunk mapped to page-level retrieval?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J9uSs7ENOF", "forum": "v217hjzwQE", "replyto": "v217hjzwQE", "signatures": ["ICLR.cc/2026/Conference/Submission19048/Reviewer_kaVd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19048/Reviewer_kaVd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762760098821, "cdate": 1762760098821, "tmdate": 1762931081813, "mdate": 1762931081813, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}