{"id": "qwS1bEqdrS", "number": 8760, "cdate": 1758097342742, "mdate": 1763106708034, "content": {"title": "Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity", "abstract": "Text-to-image (T2I) models excel on single-entity prompts but struggle with multi-subject descriptions, often showing attribute leakage, identity entanglement, and subject omissions. We introduce the first theoretical framework with a principled, optimizable objective for steering sampling dynamics toward multi-subject fidelity. Viewing flow matching (FM) through stochastic optimal control (SOC), we formulate subject disentanglement as control over a trained FM sampler. This yields two architecture-agnostic algorithms: (i) a training-free test-time controller that perturbs the base velocity with a single-pass update, and (ii) Adjoint Matching, a lightweight fine-tuning rule that regresses a control network to a backward adjoint signal while preserving base-model capabilities. The same formulation unifies prior attention heuristics, extends to diffusion models via a flow–diffusion correspondence, and provides the first fine-tuning route explicitly designed for multi-subject fidelity. Empirically, on Stable Diffusion 3.5, FLUX, and Stable Diffusion XL, both algorithms consistently improve multi-subject alignment while maintaining base-model style. Test-time control runs efficiently on commodity GPUs, and fine-tuned controllers trained on limited prompts generalize to unseen ones. We further highlight \\textsc{FOCUS} (Flow Optimal Control for Unentangled Subjects), which achieves state-of-the-art multi-subject fidelity across models.", "tldr": "", "keywords": ["Stochastic Optimal Control", "Controllable generation", "Multi-subject fidelity"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/9aca096bb0015ee4c83e794af514cea49f3472b5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses multi-subject fidelity in text-to-image (T2I) generation by formulating the problem as stochastic optimal control (SOC) over flow matching (FM) dynamics. The authors observe that modern T2I models struggle with multi-subject prompts, exhibiting attribute leakage (attributes bleeding between subjects), identity entanglement (subjects merging), and subject omissions. To tackle these issues, they introduce a principled theoretical framework that views disentanglement as a control problem over trained FM samplers.\n\nThe paper presents two main algorithmic contributions: (1) a training-free test-time controller that perturbs the base velocity field with a single-pass gradient-based update derived from SOC optimality conditions, and (2) Adjoint Matching-based fine-tuning that regresses a lightweight control network (LoRA adapters) onto backward adjoint signals computed along frozen trajectories. Both methods balance proximity to the base model against a differentiable disentanglement objective. The authors introduce FOCUS (Flow Optimal Control for Unentangled Subjects), a probabilistic attention-based cost function using Jensen-Shannon divergence (JSD) to measure subject separation and within-subject coherence.\n\nEmpirically, the methods are evaluated on Stable Diffusion 3.5, FLUX.1, and Stable Diffusion XL using a curated 150-prompt dataset with 2-4 subjects per prompt. Results show consistent improvements in multi-subject alignment metrics (CLIP, SigLIP-2, BLIP, Qwen2-VL, PickScore, ImageReward) and human preference studies. Test-time control provides modest gains with minimal overhead (~2× inference time), while fine-tuning achieves stronger improvements, with models trained on as few as one prompt generalizing to unseen prompts. The framework unifies prior attention heuristics under a single optimization objective and extends to classical diffusion models via a flow-diffusion correspondence."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Quality of Results:** Qualitative examples (Figures 1, 3, 4, 9-12) consistently show improved subject presence, reduced attribute leakage, and better separation compared to baselines. Quantitative results show consistent gains across metrics and human preferences, with FOCUS typically achieving best composite scores.\n\n**Theoretical Foundation:** The paper's core strength is establishing the first principled, optimization-based framework for multi-subject disentanglement in T2I models. \n\n**FOCUS Objective Design:** The probabilistic treatment of cross-attention as distributions is principled and well-motivated. Using Jensen-Shannon divergence respects the probabilistic structure of softmax attention, and the two-term formulation (within-subject coherence + between-subject separation) is intuitive. The bounded, normalized score enables meaningful comparison across prompts with different subject counts. The spatial smoothing and aggregation strategy (Section B) shows thoughtful engineering."}, "weaknesses": {"value": "1. **FOCUS design choices lack justification**: While using JSD is principled, several decisions appear ad-hoc: (a) Why Gaussian smoothing specifically?  (b) Why average attention across blocks before scoring rather than score-then-average? (c) Why did the entropy regularizer fail (Figure 6 shows it pushes mass away from subjects—but why theoretically?)? (d) How sensitive is performance to these choices?\n\n2.  **Incomplete diffusion model evaluation**: Claims of \"extending to diffusion models via flow-diffusion correspondence\" rest on one SDXL example (Figure 5). No quantitative evaluation, no comparison to diffusion-specific methods, no verification that theoretical correspondence translates to empirical effectiveness.\n\n3. **Metric limitations**: Standard alignment metrics (CLIP, SigLIP) may not capture attribute leakage well (acknowledged for OWL-V2 but applies broadly). The composite score (Eq. 35) macro-averages relative improvements, which could mask failures on specific prompts or metrics. Human study uses only seed=0, potentially missing variation across seeds."}, "questions": {"value": "1. **Approximation error analysis**: Can you provide theoretical or empirical bounds on the error introduced by the local adjoint approximation (Eq. 11)? How does this approximation degrade for longer time horizons or highly nonlinear dynamics?\n2. **Alternative adjoint approximations**: Have you compared the left-Riemann approximation to other integration schemes (midpoint, trapezoid, higher-order) or to multi-step forward-backward passes? This would validate whether the simplest approximation suffices.\n3. **FOCUS design ablations**:\n* (a) What is the effect of removing Gaussian smoothing?\n* (b) How does score-then-average compare to average-then-score for attention aggregation?\n* (c) Why does the entropy regularizer push mass away from subjects (Figure 6)—can you explain this theoretically?\n* (d) Is JSD specifically necessary, or would other divergences (KL, Wasserstein, Total Variation) work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "B37Eisa5Wi", "forum": "qwS1bEqdrS", "replyto": "qwS1bEqdrS", "signatures": ["ICLR.cc/2026/Conference/Submission8760/Reviewer_HYS7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8760/Reviewer_HYS7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620722033, "cdate": 1761620722033, "tmdate": 1762920544115, "mdate": 1762920544115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "65axFDiAEp", "forum": "qwS1bEqdrS", "replyto": "qwS1bEqdrS", "signatures": ["ICLR.cc/2026/Conference/Submission8760/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8760/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763106707332, "cdate": 1763106707332, "tmdate": 1763106707332, "mdate": 1763106707332, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper views flow matching from stochastic optimal control and introduces two architecture-agnostic algorithms to improve generative diffusion models, specifically for generation of multiple subjects. This paper proposes a parameter-efficient finetuning approach based on Adjoint Matching and a training-free method \"FOCUS\". FOCUS is a loss function that measures and minimizes subject entanglement. The experiments show advantages in improving attribute alignment and reducing object missing."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work conducts experiments across different architectures, showing transferability.\n2. The perspectives from stochastic optimal control is interesting and the proposed method by adapting adjoint matching and memoryless training is intuitive."}, "weaknesses": {"value": "1. Most previous methods that the authors compare to do not natively design for SD3.5 and FLUX and are no longer SOTA. The authors should cite and compare to more recent and well-related papers and report quantitative comparisons with them, such as Self-Cross [1], EnMMDiT [2], TP-Blend [3].\n2. This paper claims that it improves SDXL. However, there is no quantitative experiments supporting this. The only support comes from a single pair of qualitative results, which is insufficient.\n3. The improvements over the previous methods are marginal, with usually worse BLIP text-to-text similarities. The authors introduce other metrics that other baselines do not report, such as PickScore and ImageReward, but do not explain the motivations. The authors should discuss why other metrics/benchmarks are flawed or unfair.\n\n[1] Self-Cross Diffusion Guidance for Text-to-Image Synthesis of Similar Subjects, CVPR 2025\n\n[2] Enhancing MMDiT-Based Text-to-Image Models for Similar Subject Generation, arXiv 2025\n\n[3] TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models, TMLR 2025"}, "questions": {"value": "1. The computational efficiency is not reported and the trade-off between computations and success rates is questionable. This method shows ~10% win rates over the backbone (SD3.5 or FLUX) but is at a cost of increasing computations. However, with test-time scaling by running the model multiple times until it successfully generates a certain number of samples, does the proposed method actually use fewer computations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dLejYSCwAN", "forum": "qwS1bEqdrS", "replyto": "qwS1bEqdrS", "signatures": ["ICLR.cc/2026/Conference/Submission8760/Reviewer_FE9W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8760/Reviewer_FE9W"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832619084, "cdate": 1761832619084, "tmdate": 1762920543708, "mdate": 1762920543708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper formulates the problem of multi-subject disentanglement as a stochastic optimal control (SOC) problem built upon a trained flow matching model. Leveraging the SOC theoretical framework, the authors propose two algorithms: (1) A training-free test-time controller that perturbs the velocity during sampling; (2) A fine-tuning approach using Adjoint Matching to regress the network to a backward adjoint signal. In addition, the authors design a metric called FOCUS to measure multi-subject entanglement. Experiments show that both algorithms improve the performance of text-to-image models (including SD3.5, FLUX, and SDXL) in multi-subject generation scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is theoretically grounded in the stochastic optimal control framework, offering a solid mathematical foundation.\n\n2. The paper presents two complementary methods, one training-free and one fine-tuning based, providing users with a flexible trade-off between computational resources and inference efficiency."}, "weaknesses": {"value": "1. Since FOCUS relies on cross-attention maps, the method appears to be limited to prompts that explicitly enumerate subjects (e.g., “a cat and a dog …”) and may not generalize well to prompts that specify quantities (e.g., “four cats …”).\n\n2. As noted by the authors, the alignment metrics used in the paper may not fully capture attribute leakage issues. Existing benchmarks such as GenEval [1] and T2I-CompBench [2], which specifically target multi-subject generation, would provide a more comprehensive evaluation. It would be valuable to assess the proposed methods on these benchmarks to substantiate their effectiveness.\n\n[1] Ghosh, Dhruba, Hannaneh Hajishirzi, and Ludwig Schmidt. \"Geneval: An object-focused framework for evaluating text-to-image alignment.\" Advances in Neural Information Processing Systems 36 (2023): 52132-52152.\n\n[2] Huang, Kaiyi, et al. \"T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation.\" Advances in Neural Information Processing Systems 36 (2023): 78723-78747."}, "questions": {"value": "1. How does the proposed approach handle prompts that describe multiple subjects in terms of quantity, for example, “**four cats** sitting on a sofa”?\n\n2. A minor typo: in Line 261, should the expression $P=\\\\{vp_1,\\ldots,\\boldsymbol p_n\\\\}$ be corrected to $P=\\\\{\\boldsymbol p_1,\\ldots,\\boldsymbol p_n\\\\}$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gQTwuTYzTU", "forum": "qwS1bEqdrS", "replyto": "qwS1bEqdrS", "signatures": ["ICLR.cc/2026/Conference/Submission8760/Reviewer_5xxm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8760/Reviewer_5xxm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762267810061, "cdate": 1762267810061, "tmdate": 1762920543252, "mdate": 1762920543252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses multi-subject entanglement in text-to-image models. The authors introduce FOCUS, an intermediate time-step reward function based on the Jensen-Shannon divergence cost over attention maps, and propose two methods: (i) test-time control that adds gradient-based corrections to the velocity, and (ii) fine-tuning via Adjoint Matching that trains a control network. Experiments on SD 3.5, FLUX.1, and SDXL show improvements in multi-subject fidelity."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Well-motivated cost function.** FOCUS treats attention maps as probability distributions and uses Jensen-Shannon divergence to encourage within-subject coherence and between-subject separation, which is more principled than similarity metrics used in prior work.\n- **Methodological contribution: Adjoint Matching for running cost optimization.** While Adjoint Matching (Domingo-Enrich et al., 2025) was developed for terminal costs, this paper adapts it to optimize intermediate running costs f(X_t, t) throughout the generation trajectory.\n- Good empirical results including human user studies."}, "weaknesses": {"value": "- **The test-time method appears to reduce to standard gradient-based guidance.** The core update (Eq. 17) is v* = v_base - (1-t)∇_X f(X_t, t), which appears mathematically equivalent to existing gradient-based guidance methods. Attend&Excite optimizes latents using ∇f, Divide&Bind uses gradients of coverage/binding costs, CONFORM uses contrastive gradients. In comparison, this paper\n\t- derives a weighted version of gradient-based guidance from SOC theory using control-theoretic notation (Hamiltonian, adjoint)\n\t- calls prior methods \"heuristic\" despite doing the same gradient-based updates\n\t- claims to provide \"a principled route to adapt existing heuristics to modern FM models\" but doesn't show whether this adaptation offers any advantage over simply applying original methods\n- **No evidence the SOC formulation provides benefit beyond notational reframing.** To effectively validate this contribution, the following comparisons would be needed:\n\t- Rewards in SOC vs. Rewards in \"standard guidance\" formulation (shows if the added time-weighting term ($1-t$) adds value)\n\t- FOCUS vs. baseline costs in the same settings (ideally both SOC and standard guidance, show if FOCUS is generally the superior reward)\n- **Contribution framing obscures the actual novelty.** The paper emphasizes the SOC derivation (Section 3.1-3.2), but this appears to be primarily mathematical repackaging of existing gradient guidance. The genuinely novel contributions are in my opinion (i) FOCUS as a cost function and (ii) Adjoint Matching for running cost optimization with generalization. These are somewhat buried. In my view, the paper should be repositioned around these contributions rather than claiming the control-theoretic framework as the primary novelty.\n- **The fine-tuning setup is confusing and under-analyzed.** The paper trains on 1 prompt (HORSE&BEAR) or 15 prompts (TWOOBJECTS), evaluates on 150 diverse prompts, yet training on 1 prompt yields 85% better results than 15 prompts (Table 5). Shouldn't the fine-tuning generalize better when trained on more and more prompts? A larger analysis would make these experiments more convincing. Does performance improve with 50 or 100 prompts, or does it plateau/degrade? Without this, it's unclear whether minimal data is a feature or a limitation."}, "questions": {"value": "- Can you provide direct comparisons between: (i) FOCUS in your SOC formulation vs. FOCUS in standard gradient-based guidance (e.g., Attend&Excite-style latent updates), and (ii) baseline methods in their original implementations vs. your SOC adaptations?\n- Table 1 runs all baselines \"at optimal λ\", does this mean you reimplemented Attend&Excite, CONFORM, and Divide&Bind within the SOC framework or run \"standard guidance\"? What is their performance in original formulations on FM models?\n- Beyond mathematical elegance, what does the SOC formulation provide that standard gradient-based guidance does not?\n- Could you provide some intuition on fine-tuning on a single prompt outperforming fine-tuning on 15 prompts? This seems counter intuitive.\n- Recently, noise-based test-time techniques have demonstrated strong performance on reward alignment benchmarks, particularly search-based [1] or optimization-based [2,3] methods outperforming standard reward guidance. Have you considered applying the FOCUS reward in one of these settings compared to standard guidance?\n\n[1] Ma et al. \"Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\". CVPR 2025.\n\n[2] Tang et al. \"Inference-Time Alignment of Diffusion Models with Direct Noise Optimization\". ICML 2025\n\n[3] Eyring et al. \"ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization\". NeurIPS 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9JFsUPecz0", "forum": "qwS1bEqdrS", "replyto": "qwS1bEqdrS", "signatures": ["ICLR.cc/2026/Conference/Submission8760/Reviewer_UHsk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8760/Reviewer_UHsk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762390238016, "cdate": 1762390238016, "tmdate": 1762920542938, "mdate": 1762920542938, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}