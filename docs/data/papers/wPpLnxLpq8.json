{"id": "wPpLnxLpq8", "number": 19406, "cdate": 1758295959377, "mdate": 1762941597192, "content": {"title": "Debunking the Illusion of Backdoor Robustness in Vision Transformers", "abstract": "Backdoor attacks, which make Convolution Neural Networks (CNNs) exhibit specific behaviors in the presence of a predefined trigger, bring risks to the usage of CNNs. These threats should be also considered on Vision Transformers. However, previous studies found that the existing backdoor attacks are powerful enough in ViTs to bypass common backdoor defenses, \\textit{i.e.}, these defenses either fail to reduce the attack success rate or cause a significant accuracy drop. In this paper, we first investigate this phenomenon and find that this kind of achievement is over-optimistic, caused by the inappropriate adaptation of defenses from CNNs to ViTs. Existing backdoor attacks can still be easily defended against with proper inheritance. Furthermore, we propose a more reliable attack: adding a small perturbation on the trigger is enough to help existing attacks more persistent against various defenses. We hope our contributions, including the finding that existing attacks are still easy to defend with adaptations and the new backdoor attack, will promote more in-depth research into the backdoor robustness of ViTs.", "tldr": "In this paper, we investigate how to adapt existing defenses to ViTs and propose a new attacks, named CAT for more reliable evaluations.", "keywords": ["Backdoor Attacks", "Vision Transformer"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/b194dd04ea227d58d2a19794aa6a45622b008325.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates backdoor defenses for Vision Transformers, demonstrating that with a proper optimizer (AdamW instead of SGD) and appropriate pruning granularity, existing defenses can effectively mitigate backdoor attacks on ViTs.\nThey then propose CAT, a new backdoor attack that adds small perturbations to triggers to reduce channel activation differences between benign and triggered inputs, making attacks more resistant to defenses."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper includes experiments across multiple ViT architectures, demonstrating the effectiveness of the proposed method.\n\n2. The paper conducts an in-depth analysis of the principles behind both previous defenses (utilizing activation differences) and the proposed CAT attack (reducing activation differences)."}, "weaknesses": {"value": "1. I think that the optimizer for fine-tuning can be chosen by defenders. When the defender knows that ViT is being used, they can choose AdamW directly, which should be considered a variant of previous defense methods. This discovery is trivial and could be considered an implementation detail rather than a fundamental insight.\n\n2. Some baseline attacks are not implemented only on the CIFAR-10 dataset. Although the authors mention “considering the large computation costs”, they didn't implement the ImageNet version, I still do not think this is a good reason. In fact, to better demonstrate the attack's effectiveness on ViT, experiments on high-resolution datasets are more important than those on low-resolution datasets like CIFAR-10. Therefore, including these experiments would better highlight the paper's contribution.\n\n3. Although CAT can enhance the attack's resistance to defenses in most cases, in some situations, it still fails to resolve the issue of the attack being ineffective (e.g., ASR increasing from 1.01% to 3.17%, which still means a failed attack).\n\n4. Small suggestion: Figures 2 and 3 should be enlarged. The text appears a bit too small, possibly due to space constraints."}, "questions": {"value": "- Transfer learning scenario assumptions are not thoroughly discussed. The CAT attack relies on a surrogate model to generate trigger perturbations. How much impact does the architectural difference between the surrogate and victim models have on CAT's effectiveness? Would using a matched surrogate model (e.g., DeiT-S surrogate -> DeiT-S victim) produce a stronger attack than using the ViT-B surrogate?\n\n- If there any adaptive defenses against CAT? How would CAT perform if defenders were aware of the attack and specifically tuned defenses against perturbation-based triggers?\n\n- Could simple input preprocessing (e.g., JPEG compression, Gaussian smoothing) mitigate CAT attacks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qi8ud7IbEn", "forum": "wPpLnxLpq8", "replyto": "wPpLnxLpq8", "signatures": ["ICLR.cc/2026/Conference/Submission19406/Reviewer_J1M6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19406/Reviewer_J1M6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636763083, "cdate": 1761636763083, "tmdate": 1762931323829, "mdate": 1762931323829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "DD39n2qSNU", "forum": "wPpLnxLpq8", "replyto": "wPpLnxLpq8", "signatures": ["ICLR.cc/2026/Conference/Submission19406/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19406/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762939383906, "cdate": 1762939383906, "tmdate": 1762939383906, "mdate": 1762939383906, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits the perceived vulnerability of ViTs to backdoor attacks. The authors identify that past observations of poor robustness were caused by improper defense adaptation (e.g., mismatched optimizer). Once corrected, conventional defenses succeed on ViTs, contradicting prior conclusions.\n\nTo push the threat landscape further, the paper introduces CAT, a perturbation-based trigger enhancement that reduces activation differences between benign and poisoned samples, making backdoor attacks significantly more resilient under defended settings.\n\nThe paper is well presented and provides a valuable update to the community’s understanding of ViT security."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Addresses a highly relevant and practical security concern\n2. Balanced contributions: both remediation (defense fix) and escalation (stronger attack)\n3. Extensive experimental validation and cross-architecture study\n4. Contributes a more realistic backdoor robustness baseline"}, "weaknesses": {"value": "1. Lack of robustness demonstration\nCAT introduces deterministic perturbations to triggers. This potentially creates consistent spatial artifacts. While improvements are observed empirically, right now, CAT appears empirically effective but mechanistically unclear. Please provide either a causal explanation or ablations demonstrating predictable behavior.\n\n2. Relation to and distinction from patch-based defenses\nPrior work includes patch-level suppression and showed strong results against backdoor triggers on ViTs. Please clarify:\n\nHow CAT differs mechanistically from patch-denoising defense methods\n\nWhy defense techniques exploiting similar activation suppression would fail against CAT\n\n3. Practical threat model validity\nCAT requires intermediate activations, training discriminators and adversarial optimization against multiple layers. These capabilities assume partial white-box access to victim architecture.\n\nPlease clarify:\n\nWould CAT still hold when attackers only modify input-space triggers without model internals?\n\nIs CAT robust when defenders update models post-deployment?"}, "questions": {"value": "If the authors can clarify the robustness and theoretical underpinnings of CAT and its distinction from patch-based defenses including [1,2], I will enthusiastically update my score during the post-rebuttal stage. For example, the papers highlight that robustness may arise from inherent mismatches between attacker and defender optimization objectives, rather than directly from spatial or activation-space distortions.\n\nIn this context, it would be valuable if the authors could:\n\nIdentify whether CAT leverages a systematic vulnerability of ViT training dynamics\n(e.g., norm-induced channel bottlenecks, feature sparsity, or attention locality)\n\nProvide insights into what structural properties of ViTs make perturbation smoothing effective\n\nClarify how CAT differs from patch-based defenses in terms of\n\n• targeted representation subspaces\n\n• optimization goals\n\n• reliance on specific architectural priors\n\nSuch clarifications would greatly enhance the scientific impact of this paper and solidify CAT as a principled new attack direction, rather than a heuristic escalation.\n\n[1] Rethinking the Adversarial Robustness of Multi-Exit Neural Networks in an Attack-Defense Game.\n\n[2] MEGATRON: Evasive Clean-Label Backdoor Attacks against Vision Transformer."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1bX9SEKibR", "forum": "wPpLnxLpq8", "replyto": "wPpLnxLpq8", "signatures": ["ICLR.cc/2026/Conference/Submission19406/Reviewer_9nnE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19406/Reviewer_9nnE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761685833022, "cdate": 1761685833022, "tmdate": 1762931323347, "mdate": 1762931323347, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits backdoor attacks on Vision Transformers (ViTs) and argues that their reported vulnerability is overstated. The authors show that prior studies misapplied CNN-based defenses to ViTs, particularly when using mismatched optimizers, thereby exaggerating attack success rates. Correcting this restores ViT's robustness to levels comparable to those of CNNs. To further challenge defenses, they propose the channel activation attack in ViT (CAT), which introduces small perturbations to triggers during training to reduce activation differences between clean and poisoned inputs, improving stealthiness. Experiments on CIFAR-10 and ImageNet across multiple ViT architectures and defenses confirm that CAT strengthens existing attacks. The study offers both diagnostic insight and a stronger baseline for evaluating ViT backdoor robustness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a valuable diagnostic insight by demonstrating that prior work often misapplied CNN-based defenses to ViTs, leading to an overestimation of ViT's vulnerability. This clarifies a common misunderstanding in the field.\n- The paper provides comprehensive evaluations across multiple ViT variants, showing the generalizability of their proposed method (CAT). It also considers many defenses, which makes the evaluation setup thorough and well-rounded.\n- The results demonstrate that combining CAT with existing attacks (Badnets, Blend) significantly improves the attack success rate (ASR) against various defenses, suggesting CAT effectively enhances attack robustness."}, "weaknesses": {"value": "In Table 5, CAT is only compared with earlier attacks (Badnets, Blend) but not with more recent methods (TrojViT, DBIA, BadViT). As a result, the fairness and completeness of the claimed superiority are questionable, since the comparisons seem to rely on previously reported results obtained under different experimental settings."}, "questions": {"value": "Could you please clarify the significance of TrojViT, DBIA, and BadViT as presented in Table 5? Their reported results appear to be disconnected from those of your proposed method. I believe the comparison between the two sides has not been conducted under the same baseline."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "62T2zHH5sD", "forum": "wPpLnxLpq8", "replyto": "wPpLnxLpq8", "signatures": ["ICLR.cc/2026/Conference/Submission19406/Reviewer_teGj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19406/Reviewer_teGj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946181271, "cdate": 1761946181271, "tmdate": 1762931322871, "mdate": 1762931322871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper primarily presented the evaluations of backdoor attacks on vision transformer models, and pointed out that current defense methods can easily defend against backdoor triggers in ViTs. Furthermore, the authors proposed a new attack method called CAT that enhances backdoor attacks. In the experiment section, they demonstrate that CAT increases attack success rates (ASR) across multiple ViT architectures (ViT-B, DeiT-S, Swin-B, CaiT-S, XciT-S) while maintaining similar clean accuracy (ACC)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors re-evaluated multiple existing attack and defense methods on ViTs, including fine-tuning-based defenses, pruning-based ones. I would say this is the main contribution of this paper, since it provides useful benchmarking numbers on FT, FP, NAD, ANP, AWM, etc.\n\n2. The authors were able to point out a mistake in previous findings of ViT vulnerability: optimizer mismatch (SDG and AdamW) and pruning misalignments. This is an important clarification in the research space of adversarial machine learning on ViT models."}, "weaknesses": {"value": "1. The technical novelty seems to be limited. The proposed method is just adding an adversarial perturbation to existing triggers. The authors could discuss the CAT method further in terms of how it presents a qualitatively new mechanism. \n\n2. The proposed method does not seem to be limited to ViT. It is unclear why adding a perturbation is specifically useful for ViT compared to other models, such as CNNs. \n\n3. I would suggest the authors position the paper a bit more clearly. The paper seems more like a benchmark study at the moment, rather than proposing a new technical idea.\n\n4. More recent attacks and defenses are needed, including ABS and MOTH for defense, and WaNet, COMBAT, and other strong invisible backdoor attacks.\n\n5. There are also prior works that aim to reduce the distance of the original data and backdoor data in the representation space, such as the Wasserstein backdoor. The paper should also compare to these methods."}, "questions": {"value": "Given the CAT method, could the same perturbation strategy be applied to CNN backdoors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "H9zbK15A4A", "forum": "wPpLnxLpq8", "replyto": "wPpLnxLpq8", "signatures": ["ICLR.cc/2026/Conference/Submission19406/Reviewer_skK6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19406/Reviewer_skK6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963310481, "cdate": 1761963310481, "tmdate": 1762931322525, "mdate": 1762931322525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}