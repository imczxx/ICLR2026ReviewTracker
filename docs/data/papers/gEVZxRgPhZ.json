{"id": "gEVZxRgPhZ", "number": 20491, "cdate": 1758306726778, "mdate": 1759896974844, "content": {"title": "Transduction is All You Need for Structured Data Workflows", "abstract": "This paper introduces Agentics, a functional agentic AI framework for building LLM-based structured data workflow pipelines. Designed for both research and practical applications, Agentics offers a new data-centric paradigm in which agents are embedded within data types, enabling logical transduction between structured states. This design shifts the focus toward principled data modeling, providing a declarative language where data types are directly exposed to large language models and composed through transductions triggered by type connections. We present a range of structured data workflow tasks and empirical evidence demonstrating the effectiveness of this approach, including data wrangling, text-to-SQL parsing, and domain-specific multiple-choice question answering.", "tldr": "Introducing Agentics, a framework that simplifies building agentic AI systems through logical transduction, allowing for declarative data modeling and improved scalability in wide range of structured data workflow tasks.", "keywords": ["Large Language Models", "Agentics", "Agent", "Structured Data", "Software"], "primary_area": "infrastructure, software libraries, hardware, systems, etc.", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b8b41793a653193afe33e9b35d3f383df4ed734e.pdf", "supplementary_material": "/attachment/9b069d719b4fd002f6d90c9536753d37130e2d83.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Agentics, a novel functional AI framework designed to address the brittleness and lack of formal semantics in current LLM-based systems for structured data workflows. The core concept is logical transduction, a data-centric paradigm where agents act as stateless transducers that transform data between strongly-typed schemas. This approach shifts the focus from conversational, prompt-chained interactions to a more principled, type-driven computation.\nThe framework is formalized through a Logical Transduction Algebra\" (LTA), which guarantees key properties like conditional determinism, statelessness, and compositionality. It is implemented with an asynchronous map-reduce style programming model, enhancing modularity, parallelism, and reproducibility. Through experiments on tasks like text-to-SQL, schema matching, and domain-specific question answering, the authors demonstrate that Agentics achieves competitive or improved performance. Notably, it shows significant gains in robustness against knowledge-invariant perturbations, underscoring its reliability. The paper advocates for a paradigm shift towards a more formal, data-centric approach for building reliable and scalable data workflows with LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Rather than offering an incremental improvement on existing frameworks, the paper introduces a genuine paradigm shift, moving from chat-centric models to a principled, data-centric functional approach. The introduction of a formal Logical Transduction Algebra is a profound and novel contribution, as it grounds the behavior of LLM agents in a mathematically rigorous foundation—a rarity in this empirically-driven \nfield. This theoretical rigor directly translates into the work's high quality. The LTA is not merely conceptual; it is formally defined with proven properties, which provides a sound basis for the claims. The empirical validation is equally strong, moving beyond standard accuracy metrics. The inclusion of robustness tests against knowledge-invariant perturbations is particularly compelling, as it provides direct, powerful evidence for the central hypothesis that this approach mitigates the \"brittleness\" of LLM pipelines."}, "weaknesses": {"value": "1. Lack of Direct Comparative Evaluation with Existing Frameworks: The most significant weakness is the absence of a direct, quantitative benchmark against the very frameworks it critiques, such as LangChain. The paper makes strong claims about overcoming their brittleness and lack of formal semantics. While the internal experiments and ablation studies are valuable, they only compare variations of the Agentics approach against a baseline. To truly substantiate the superiority of this new paradigm, an end-to-end implementation of a complex, multi-step workflow in both Agentics and a state-of-the-art alternative framework would be necessary. Such a comparison could measure key metrics like final task accuracy, error recovery rate, execution speed, and perhaps even lines of code or development complexity, providing much stronger evidence for its claims.\n2. Unaddressed Limitations of the Stateless Paradigm: The framework's core strength—statelessness—is also its primary limitation. This design choice is fundamental to achieving parallelism and reproducibility. However, many real-world data workflows are inherently stateful. For example, a workflow might need to aggregate information over a series of steps where the context from step 1 is needed in step 5, or it might need to maintain a conversational memory in an interactive data-cleaning session. The paper does not adequately discuss the boundaries of its paradigm or offer clear patterns for handling state when it is unavoidable. This leaves a critical gap in understanding the practical applicability of Agentics for a whole class of important problems."}, "questions": {"value": "1. On Comparative Evaluation: Could you elaborate on the decision not to include a direct benchmark against a mainstream agentic framework like LangGraph? We believe that even a single, detailed case study comparing the implementation of one of the paper's complex workflows in Agentics versus a state-of-the-art alternative would powerfully highlight the practical benefits in terms of robustness, code clarity, and performance.\n2. On Handling State: The stateless nature of transduction is a cornerstone of the framework, enabling parallelism and reproducibility. However, how does the Agentics paradigm envision handling workflows that intrinsically require state to be maintained and passed between non-adjacent steps? Are such workflows considered out-of-scope, or are there recommended design patterns to manage this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "um2Otz8qXF", "forum": "gEVZxRgPhZ", "replyto": "gEVZxRgPhZ", "signatures": ["ICLR.cc/2026/Conference/Submission20491/Reviewer_jijG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20491/Reviewer_jijG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761559673795, "cdate": 1761559673795, "tmdate": 1762933926027, "mdate": 1762933926027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose a framework for processing LLM-based structured data workflow pipelines. The authors evaluate Agentics on tasks such as schema matching, text-to-SQL parsing, data imputation, and domain-specific multiple-choice question answering (MCQA), showing competitive or improved performance compared to baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The introduction of Logical Transduction Algebra (LTA) provides a principled, algebraic framework for composing LLM-based workflows. This formalism is a significant contribution, offering reproducibility, statelessness, and composability.\n- The asynchronous MapReduce-style programming model (aMap/aReduce) enables efficient parallel execution, which is crucial for large-scale data workflows."}, "weaknesses": {"value": "- The framework is highly optimized for structured data workflows but may not generalize well to open-ended, context-heavy, or creative tasks that require rich contextual understanding or instruction-following.\n- For some tasks (e.g., schema matching), the baselines are limited to GPT-3.5. Comparing against more recent or task-specific models could strengthen the claims."}, "questions": {"value": "The reviewer is not familiar with the logical transduction area and therefore CANNOT make a fair judgement of the technical merits of the paper. Please refer to other reviewers for the detailed concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "KP3I4iFylO", "forum": "gEVZxRgPhZ", "replyto": "gEVZxRgPhZ", "signatures": ["ICLR.cc/2026/Conference/Submission20491/Reviewer_PX9e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20491/Reviewer_PX9e"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808718536, "cdate": 1761808718536, "tmdate": 1762933925538, "mdate": 1762933925538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors of this paper propose a functional agentic AI framework Agentics, which is designed for building LLM-based structured data workflow pipelines. Its core contribution is a shift from conversation-centric to a data-centric paradigm, where agents are modeled as stateless transducers operating over well-defined, Pydantic-based types. This paper formalizes this approach with a Logical Transduction Algebra (LTA), which provides a compositional calculus for building, analyzing, and optimizing these pipelines. The proposed framework is implemented as a Python library and evaluated on a range of structured data tasks, including schema matching, text-to-SQL, data imputation, and domain-specific multiple-choice QA, demonstrating competitive or improved performance due to its structured prompting and asynchronous execution model."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This work is significant for addressing the critical challenge of building robust, composable, and scalable data workflows with LLMs, offering a principled alternative to fragile, chat-based agent systems.\n\n2. The proposed \"logical transduction\" paradigm is well executed, which elegantly re-frames LLM agents as stateless transducers over typed data. It combines a sound theoretical foundation (provides formal definitions with proven properties) with a practical Python implementation, demonstrating strong empirical results across diverse structured data tasks.\n\n3. The framework is evaluated across multiple domains and tasks, including schema matching, text-to-SQL (BIRD, Archer), data imputation, and domain-specific multiple-choice QA, demonstrating its broad applicability."}, "weaknesses": {"value": "1. This paper's motivation is not convinced and clear. It never truly clarifies why existing agent frameworks are fundamentally ill-suited for structured data, offering no tangible examples of where they fail and why a new paradigm is needed.\n\n2. The experiments are not sufficient to verify the proposed framework's advantage, since the baselines are really weak (GPT-3.5), missing the comparisons with recent frameworks like DSPy or AutoGen on the same tasks. \n\n3. The paper frames LTA as a major contribution, but the algebra is relatively straightforward, essentially applying monoid operations to typed data structures with LLM inference. The claimed properties are mainly inherited from the underlying components rather than emergent from the algebra itself.\n\n4. The presentation is somewhat difficult to follow, with excessive formalism in early sections that could be streamlined. The connection between theoretical LTA and practical implementation is unclear. Code examples mix pseudo-code with Python syntax inconsistently."}, "questions": {"value": "Miner issues:\n1. Line 486: \"Ethics Statement\" should be in a separate \\section.\n\n2. The composite workflow (P+FS+KW+SQ+SL+OP) achieves 10.33% improvement, but individual components show negative or minimal gains. Can you provide more analysis on why the combination works better?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LKgKYjtoWn", "forum": "gEVZxRgPhZ", "replyto": "gEVZxRgPhZ", "signatures": ["ICLR.cc/2026/Conference/Submission20491/Reviewer_Bc8M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20491/Reviewer_Bc8M"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839644889, "cdate": 1761839644889, "tmdate": 1762933925131, "mdate": 1762933925131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global response to all reviewers"}, "comment": {"value": "We thank all reviewers for their efforts in reviewing our submission, and insightful comments and constructive feedback.\nWe will address the questions and comments individually to reviewers, but we believe the comparison of programs implemented in different frameworks is worth being shown in the global response. \nThe comparison was suggested by reviewer jijG, and it will also address other issues requesting clear motivation by Bc8M, weak suitability for creativity tasks by reviewer PX9e.\n\n\nReflecting the comments on the experiments, we would like to add an additional experiment with DiscoveryBench (Bodhisattwa Prasad Majumder, et al, 2024) to address the concerns on the weakness of the experiment raised by reviewers (PX9e, Bc8M).\nIn addition, we also improve the experiment of the schema matching task by evaluating the baseline with newer models. Unfortunately, we couldn’t reproduce the data imputation task since the exact prompt was not accessible. In our experiment, the imputation task is selecting the missing labels from all existing labels in the training set. It is not clear how these classification labels were defined in the baseline implementation."}}, "id": "0fPN2e12OU", "forum": "gEVZxRgPhZ", "replyto": "gEVZxRgPhZ", "signatures": ["ICLR.cc/2026/Conference/Submission20491/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20491/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission20491/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763687452326, "cdate": 1763687452326, "tmdate": 1763687452326, "mdate": 1763687452326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}