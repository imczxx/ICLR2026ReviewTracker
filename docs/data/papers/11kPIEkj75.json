{"id": "11kPIEkj75", "number": 8043, "cdate": 1758054560396, "mdate": 1759897812233, "content": {"title": "Semantic Uncertainty Quantification of Hallucinations in LLMs: A Quantum Tensor Network Based Method", "abstract": "Large language models (LLMs) exhibit strong generative capabilities but remain vulnerable to confabulations, fluent yet unreliable outputs that vary arbitrarily even under identical prompts. Leveraging a quantum tensor network–based pipeline, we propose a quantum physics-inspired uncertainty quantification framework that accounts for the aleatoric uncertainty in token sequence probability for semantic equivalence-based clustering of LLM generations. In turn, this offers a principled and interpretable scheme for hallucination detection. We further introduce an entropy-maximization strategy that prioritizes high-certainty, semantically coherent outputs and highlights entropy regions where LLM decisions are likely to be unreliable, offering practical guidelines for when human oversight is warranted. We evaluate the robustness of our scheme under different generation lengths and quantization levels, dimensions overlooked in prior studies, demonstrating that our approach remains reliable even in resource-constrained deployments. A total of 116 experiments on TriviaQA, NQ, SVAMP, and SQuAD across multiple architectures (Mistral-7B, Mistral-7B-instruct, Falcon-rw-1b, LLaMA-3.2-1b, LLaMA-2-13b-chat, LLaMA-2-7b-chat, LLaMA-2-13b and LLaMA-2-7b) show consistent improvements in AUROC and AURAC over state-of-the-art baselines.", "tldr": "We model token probability uncertainty as a quantum wave function to enhance confabulation detection in LLMs, improving reliability across output lengths and quantization levels for more trustworthy AI.", "keywords": ["Semantic uncertainty", "Large language models", "quantum physics"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d1a57f321d84997454743f0dd751f165edfd6b6e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper uses a physics-inspired UQ method to modify cluster probabilities in a semantic entropy-type decomposition, based on prediction uncertainty. It’s a neat idea, and a way of incorporating distributional uncertainty that I haven’t seen much in the literature. There seems to be a small but persistent improvement over standard SE, across a variety of settings. However, I am confused on quite a few aspects, see the comments below."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* Interesting and novel way of thinking about uncertainty in LLMs\n* Small, but persistent, improvement over baselines (in a domain where the baselines are already pretty strong)"}, "weaknesses": {"value": "* Not enough background/intuition on QTNs and the physics-inspired approach used\n* Lack of technical detail: I am not sure how to construct all the estimators and would certainly not be able to implement the method myself.\n* Experiments do not fully tease apart the benefit of the proposed method\n\nI elaborate on all these points in my questions below."}, "questions": {"value": "First, I am not sure on whether my interpretations are correct, so I am going to summarize my interpretation (in the hopes that the authors can correct any misunderstanding!). For context, I am familiar with the semantic entropy line of work, Bayesian NNs, and KMEs, but not with the physics-inspired framework of Principe (I skimmed the Singh and Principe work; I suspect that the Vipulananathan et al paper would be helpful background but I couldn’t find it without a paywall):\n\n\n* Semantic Entropy is underspecified, because it does not consider uncertainty in the predictive distributions (loosely, epistemic uncertainty... not exactly, I know, but I’m going to refer to it as “epistemic” uncertainty in my review as a shorthand)\n* The physics-inspired approach of Principe offers a way of getting at this uncertainty, via permutation.\n* Rather than Shannon entropy, we can look at Renyi entropy, which can be expressed in terms of the kernel mean embedding of the sequence probabilities.\n* This is natural for the physics-inspired approach, because you can find a QTN whose Hamiltonian is aligned with the KME, and directly perturb that.\n    * i.e., the authors aren’t trying to claim that Renyi entropy is necessarily a “better” option than Shannon entropy, rather that adding in the “epistemic” uncertainty is important.\n\n\nI’d really appreciate any corrections on my understanding of the above — if I’m lost at this point, who knows how wrong my interpretations of the rest are!\n\nBased on this: I like the idea! I agree with the general idea that we should include uncertainty about the logits, and I am intrigued by the physics-based approach. But, I think the exposition could be improved so that people who aren’t already familiar with the physics-based approach (i.e., me! But also I suspect a lot of the people in the LLM/UQ community) can get better understanding and intuition. Also, the implementational details and details of the estimator are a little vague, and the experiments don’t fully explore the method (in one case, the authors seem to refer to an experiment that isn’t in table 1, but that I would love to see in table 1... perhaps something that got left out in last-minute editing?)\n\nGiven that, I have a number of questions/requests:\n\nIntuition:\n\n1. More background/intuition about the physics-inspired approach, and QTNs. In particular, in line 179, you say you identify a QTN whose Hamiltonian has $\\{\\underline{\\hat{\\psi}}_\\underline{y}\\}$ as an eigen-mode, and then perturb this Hamiltonian. How does one do this? What is the intuition for this giving reasonable estimates of the variability of the probabilities?\n2. What is the connection to other ways of estimating “epistemic” uncertainty? Eg: the perturbation-based approach seems similar to the Laplace approximation to a Bayesian posterior — is there a connection there? More generally, there probably should be some mention of the Bayesian deep learning literature, since they are coming from a similar viewpoint. I don’t think you need to compare with BDL, but it would be good to see some discussion of why you choose the physics-based approach vs alternatives.\n3. In Section 2.2, you say that the KME is an approximation of the semantic entropy, but it is not explicit how you get from eq 3 to eq 4. On the first read, I thought you were claiming that the KME of the entire distribution was equivalent to the Renyi Semantic Entropy, and I was confused how this incorporates the clustering. Reading on, it is clear that you are using deberta clustering... I assume that you calculate the KME for each cluster, then combine them, but I’m not exactly sure how I should combine these KMEs based on eq 4.\n4. I would like a little more intuition on the calibrated adjustment of the probabilities. Why is increasing the entropy in this way the “right” thing to do? I think I get it in a loose way — your KL term says “the raw probability is roughly right, where ”roughly“ is base on how uncertain I am” and the RE term say “but, we are underestimating the entropy so pull it up” — but are there theoretical underpinnings behind this specific formulation? Is the assumption that lambda is learned via cross-validation?\n5. Once you have the calibration-adjusted probabilities, are you then combining them using eq 4, or are you using the KMEs?\n\nExperiments:\nWhat I would hope to see from the experiments are evidence of the following: 1) using Renyi semantic entropy (without additional UQ) is as good, or better, than using Shannon semantic entropy; 2) adding in the entropy maximization correction improves on this; 3) ablations; 4) qualitative analysis of a specific case where you get differing results. Most of these are at least fully answered, but not completely.\n\n\n1. Using Renyi semantic entropy vs using Shannon. This is included in the heat maps, but could be discussed more. As far as I can see, shannon typically does better than renyi in terms of AUROC, but comparably in terms of AURAC. Is there any intuition behind this?\n2. Overall performance. Looking at win rate feels misleading, when (looking at the figures in the appendix) the actual differences between the various SE methods is pretty small (mostly invisible to the eye... I suspect the confidence intervals are greater than the difference in most cases). I know that the differences in AUROC in these sorts of LLM UQ paper tend to be small, so I’m not surprised to see that the improvement is slight.... however I've would like to see in the main paper, something that more gets at a specific effect size (e.g., notable increase for a given TPR/FPR tradeoff).\n3. Overall performance #2: I would like to see baseline SRE in figures 12-14. Based on Figure 24, at least in Falcon, UQ-based SRE can dramatically improve on baseline SRE — implying that in this case, baseline SRE is much worse than baseline shannon SE. Why is this?\n4. Ablations: Would it make sense to apply the UQ adjustment to Shannon Semantic Entropy? It seems you could take the adjusted probabilities from eq 7 and use them to calculate it. \n5. Qualitative analysis: In Table 1, but the main-text description doesn’t match the figure (it talks about the difference between $\\text{SE}_R$ and $\\text{SE}_R^+$, but $\\text{SE}_R$ isn’t in the table.\n6. Qualitative analysis: It would be nice to see a qualitative exploration of questions that get very different values of $\\text{SE}_R$ and $\\text{SE}_R^+$. Do these tend to correspond to questions the LLM is likely to have less data on? Or, some other form of additional uncertainty?\n\n\nGeneral comments: \n\n* There is a lot of space given to the quantization experiments, relative to how important it seems to the paper. I would like to see this shrunk or moved to the appendix in favor of more explanation/intuition/detail.\n* You are not very consistent in method naming (eg, $\\text{SE}_R^+$ vs SRE-UQ.\n\n\nI know that's a lot of comments and questions! But, it's because I really like the idea of the paper, and *want* to have a good in-depth understanding, but don't feel in its current form I am able to get all the information I need from it."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "j0sMbwnkbI", "forum": "11kPIEkj75", "replyto": "11kPIEkj75", "signatures": ["ICLR.cc/2026/Conference/Submission8043/Reviewer_Bhsm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8043/Reviewer_Bhsm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8043/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761072999044, "cdate": 1761072999044, "tmdate": 1762920037480, "mdate": 1762920037480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a quantum-inspired framework for estimating uncertainty in Large Language Models (LLMs) to better detect hallucinations.\nBuilding on Semantic Entropy (Farquhar et al., 2024), the authors reinterpret the model’s sequence probabilities as a wave-function in a reproducing-kernel Hilbert space and construct a quantum tensor-network (QTN) representation to analyze perturbations in this space.\nThey derive first-order perturbation features that quantify the local sensitivity of token probabilities and use these to re-weight output probabilities through an entropy-regularized optimization objective.\nIn parallel, they compute semantic-cluster probabilities and a Renyi-entropy-based uncertainty score.\nExperiments across Mistral-7B, Falcon-1B, and LLaMA-2/3 on TriviaQA, NQ, SVAMP, and SQuAD show consistent AUROC improvements over Semantic Entropy, naive token entropy, and other baselines, including under 4-bit quantization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear motivation: addresses the instability of entropy-based uncertainty when probability mass collapses into a few clusters.\n2. Conceptual novelty: combining semantic clustering with quantum-mechanical perturbation analysis is original and theoretically interesting.\n3. Methodological soundness: the derivations are mathematically consistent, and the optimization formulation is well justified.\n4. Robustness: results are shown across several models, datasets, and quantization levels, indicating the approach is not overly brittle.\n5. Empirical clarity: tables separate the effect of the perturbation term, Rényi entropy, and adjusted probabilities; ablations are informative.\n6. Good writing: the exposition is clean, equations are readable, and notation is consistent."}, "weaknesses": {"value": "1. Complexity and interpretability: the proposed QTN embedding and perturbation analysis are computationally heavier than simpler uncertainty measures; inference-time cost is not reported.\n2. Baselines could be broader: comparisons omit recent energy- or logits-based approaches (e.g., Semantic Energy, LogTokU).\n3. Sensitivity analysis: the method introduces several hyperparameters (kernel bandwidth, λ, Rényi α), but their tuning process and sensitivity are not discussed in depth.\n4. Clustering dependency: since semantic clustering remains the outer layer, the total uncertainty measure still inherits its limitations (e.g., sensitivity to embedding choice)."}, "questions": {"value": "1. How sensitive is the performance to the Rényi entropy order (α)? Did you experiment with α > 2 or other generalized entropies?\n2. What is the additional computational cost of the QTN perturbation step compared to standard Semantic Entropy?\n3. Would the uncertainty-aware reweighting change the model’s decoding behavior if used during generation (not only for scoring)?\n4. Did you test the approach in long-form generation (e.g., summarization) where clustering and token perturbations interact differently?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vZdrsHJkpA", "forum": "11kPIEkj75", "replyto": "11kPIEkj75", "signatures": ["ICLR.cc/2026/Conference/Submission8043/Reviewer_tnuf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8043/Reviewer_tnuf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8043/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838229910, "cdate": 1761838229910, "tmdate": 1762920037074, "mdate": 1762920037074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce a quantum tensor network (QTN)-based uncertainty quantification (UQ) framework that models aleatoric uncertainty of token sequence (TS) probabilities and leverages semantic clustering, producing a principled scheme for hallucination detection. Authors show experiments on multiple datasets and model scales to highlight the efficacy of their approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper is generally well written although a bit heavy on theoretical notations. It could be simplified a bit more though.\n\n- It brings quantum physics-inspired UQ to the LLM hallucination detection problem.\n\n- The paper tackles a very significant issue. Hallucination risk in LLMs is a key challenge for safe AI."}, "weaknesses": {"value": "- Heavy reliance on advanced mathematical machinery. Makes it a bit harder to adopt.\n\n- The apporach does not come significant performance boost."}, "questions": {"value": "- How does the hallucination detection robustness change with different semantic clustering models? Can you quantify error propagation from supplementary entailment models?\n\n- What are the runtime/memory costs versus baseline methods for real-time or production deployment at scale?\n\n- How do you use the local entropy/uncertainty scores in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "luivN4S37p", "forum": "11kPIEkj75", "replyto": "11kPIEkj75", "signatures": ["ICLR.cc/2026/Conference/Submission8043/Reviewer_YDUM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8043/Reviewer_YDUM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8043/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993981665, "cdate": 1761993981665, "tmdate": 1762920036638, "mdate": 1762920036638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}