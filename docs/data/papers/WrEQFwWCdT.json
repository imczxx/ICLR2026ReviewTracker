{"id": "WrEQFwWCdT", "number": 12089, "cdate": 1758205640003, "mdate": 1759897534813, "content": {"title": "MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting", "abstract": "Recent advances in dynamic scene reconstruction have significantly benefited from 3D Gaussian Splatting, yet existing methods show inconsistent performance across diverse scenes, indicating no single approach effectively handles all dynamic challenges. To overcome these limitations, we propose Mixture of Experts for Dynamic Gaussian Splatting (MoE-GS), a unified framework integrating multiple specialized experts via a novel Volume-aware Pixel Router. Our router adaptively blends expert outputs by projecting volumetric Gaussian-level weights into pixel space through differentiable weight splatting, ensuring spatially and temporally coherent results. Although MoE-GS improves rendering quality, the increased model capacity and reduced FPS are inherent to the MoE architecture. To mitigate this, we explore two complementary directions: (1) single-pass multi-expert rendering and gate-aware Gaussian pruning, which improve efficiency within the MoE framework, and (2) a distillation strategy that transfers MoE performance to individual experts, enabling lightweight deployment without architectural changes. To the best of our knowledge, MoE-GS is the first approach incorporating Mixture-of-Experts techniques into dynamic Gaussian splatting. Extensive experiments on the N3V and Technicolor datasets demonstrate that MoE-GS consistently outperforms state-of-the-art methods with improved efficiency. Video demonstrations are available at https://anonymous.4open.science/w/MoE-GS-68BA/.", "tldr": "MoE-GS reconstructs dynamic scenes using 2D weight splatting and learnable routing in a Mixture-of-Experts framework", "keywords": ["Gaussian Splatting", "Dynamic Scene Reconstruction"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/625805e6a4ff22a8c9d64ed52cb2c52226201b67.pdf", "supplementary_material": "/attachment/7a796b076144598a11bf3fdaf03530276e7f67dd.zip"}, "replies": [{"content": {"summary": {"value": "This paper MoE-GS employs the concept of MoE in 4D spatial reconstruction, based on the observation that multiple methods hold different individual optimal performances in multiple cases. This pipeline builds upon multiple baseline 4DGS methods and assigns volume-based per-Gaussian router score for each expert. The resulting system achieves SOTA reconstruction quality among baselines. This work also introduces acceleration and distillation techniques to improve the inference efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work introduces MoE into 4D reconstruction, which is a novel solution to enhance the 4D representation capability.\n2. The Volume aware Pixel Router serves a core innovative design, providing accurate and effective router score based on the rendering process. This design tackles the difficulty in obtaining a suitable score for GS based MoE, which distinguishes this work from previous MoE structures with direct evaluation score.\n3. The visual performances are impressive. Based on the MoE structure which aggregates the strength from multiple baseline methods, the proposed method meticulously achieves significantly high visual quality.\n4. The authors cater for the inference efficiency of the MoE model. Although the rendering cost is higher than baselines, it still maintains a real-time rendering."}, "weaknesses": {"value": "1. The primary concern is on the method efficiency. This method requires training multiple baseline 4DGS models along side the MoE router. This design costs significantly high time and GPU resources compared to baseline methods. Besides, the time cost used in deciding the router network is also a concern, i.e., the time spent on training the per-Gaussian dynamics property and router network.\n2. The significance of a MoE model in this 4D reconstruction scope. Although the MoE structure is applicable to 4D reconstruction problem, it is not an intuitive solution. The 4D reconstruction requires fitting to each individual scene, while the general LLM MoE requires only one training while reused for any inference. In this case, the cost of training a MoE model is efficient compared to training multiple full LLMs. However, this concept is not versatile in the proposed framework. The method requires full training of the individual method while the MoE-GS aggregates and overfits to each model's specialty. This leads to a conflict that, previous MoE for large models is used to improve the efficiency while maintaining high performance, while this framework takes costs to train MoE and improve the quality. These considerations weaken the necessity of such MoE-GS design. Besides, the 3D/4D reconstruction is random, i.e., multiple runs can yield different results. Does an MoE over multiple runs also improve the overall performance? Are the differences between different baselines large enough for a MoE structure?\n3. The hyperparameter in Eq. (11) seems an important hyperparameter for distillation. Its impact on the overall distillation performance is not clearly illustrated."}, "questions": {"value": "1. The time cost should be justified, as the method requires significantly higher resources to maintain the SOTA visual performance.\n2. The authors should clarify on their motivations and design choices regarding the MoE structure, as listed in the weakness part. The necessity of such structure should be illustrated. A detailed specialty comparison between the expert models, and why these expert models have these properties  should be provided, which are beneficial to the overall novelty.\n3. More ablations are recommended to make the experiments solid.\n\nBased on above considerations, I would like to give a positive recommendation regarding the paper's novelty, and I will adjust my score based on the authors' rebuttal on my concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "y8dwQqPjCB", "forum": "WrEQFwWCdT", "replyto": "WrEQFwWCdT", "signatures": ["ICLR.cc/2026/Conference/Submission12089/Reviewer_eMnv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12089/Reviewer_eMnv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761061264088, "cdate": 1761061264088, "tmdate": 1762923058822, "mdate": 1762923058822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MoE-GS, the first approach to apply a Mixture-of-Experts (MoE) architecture to Dynamic Gaussian Representation. Using a Volume-aware Pixel Router, MoE-GS mixes the Gaussians produced by experts specialized in representing specific Gaussians within the same scene. Although this introduces runtime overhead, the authors mitigate it with single-pass multi-expert rendering and gate-aware Gaussian pruning. As a result, experiments on the N3V and Technicolor datasets show that MoE-GS achieves better view-synthesis quality and efficiency than prior state-of-the-art methods."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "\tMoE-GS is the first work to introduce a Mixture-of-Experts architecture to dynamic Gaussian splatting, offering a new solution to the problem that a single model cannot handle scene-specific diversity.\n\n\tThe proposed MoE-GS model consistently achieves higher rendering quality than existing SOTA methods on complex dynamic scenes and demonstrated its superiority across diverse datasets (N3V, Technicolor).\n\n\tThe authors acknowledge the drawbacks of the MoE architecture, namely increased computational load and reduced speed and jointly propose techniques to mitigate these issues."}, "weaknesses": {"value": "Major weaknesses are as below:\n\n\tIn LLMs, MoE is typically used at inference time to reduce the number of activated parameters [1]. By contrast, this paper uses MoE as a mechanism for mixing multiple models. Nevertheless, it suggests that as the number of models increases, computational resource demands grow, while the performance gains are unlikely (at a fine-grained level, e.g. a patch of novel view image) to surpass the best performance of any single model.\n\n[1] Dai et al. “DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models.” CoRR. 2024.\n\n\tThe rationale for using the variational models (4DGaussians (Wu et al., 2024), E-D3DGS (Bae et al., 2024), Ex4DGS (Lee et al., 2024), and STG (Li et al., 2024)) is sufficient. However, the paper lacks analysis of which aspects each model is strong in and why. It also lacks an examination of whether there are synergies among the models and what performance gains such synergies bring.\n\nMinor comments or improvements are as below:\n\n\tTo emphasize that MoE-GS performs well across all aspects, including MoE-GS’s results in Figure 1 would help clarify that it achieves higher performance than all other methods.\n\n\tDo all models require training? If so, reporting the training time for each model and providing an analysis of the increased training time would be helpful.\n\nI will reconsider the score when all the concerns are handled well."}, "questions": {"value": "\tIn Equation (6), what is the rationale for multiplying the time variable by the time-dependent per-Gaussian weights?\n\n\tIn the Theater results of Table 2, MoE-GS underperforms relative to HyperReel. I hypothesize that this is because HyperReel is not employed as an expert; would incorporating HyperReel as an expert improve performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Qn99JCdq6i", "forum": "WrEQFwWCdT", "replyto": "WrEQFwWCdT", "signatures": ["ICLR.cc/2026/Conference/Submission12089/Reviewer_AHQB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12089/Reviewer_AHQB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896799125, "cdate": 1761896799125, "tmdate": 1762923058294, "mdate": 1762923058294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MoE-GS (Mixture of Experts for Dynamic Gaussian Splatting), the first framework to apply mixture-of-experts techniques to dynamic 3D scene reconstruction using Gaussian splatting. The authors observe that existing dynamic Gaussian splatting methods show inconsistent performance across different scenes, spatial regions, and temporal frames, indicating no single approach handles all dynamic challenges effectively. To address this, MoE-GS integrates multiple specialized expert models through a novel Volume-aware Pixel Router that adaptively blends expert outputs by projecting Gaussian-level weights into pixel space via differentiable splatting. The framework also includes efficiency optimizations like single-pass multi-expert rendering and gate-aware Gaussian pruning, plus a knowledge distillation strategy to transfer MoE performance to individual experts for lightweight deployment. Experiments on the N3V and Technicolor datasets demonstrate that MoE-GS consistently outperforms state-of-the-art methods in rendering quality while maintaining practical efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a solid diagnostic study (Fig. 1) showing how different dynamic Gaussian Splatting models reach performance peaks at different scenes, spatial regions, and time steps. This empirical observation is valuable to the community and highlights an important open problem of model generalization in dynamic reconstruction.\n\n2. Even if the current MoE-GS realization focuses on image-level blending, the paper raises the broader idea of combining specialized dynamic reconstruction models adaptively. This perspective could motivate subsequent studies toward true 3D-level mixtures or unified dynamic representations."}, "weaknesses": {"value": "1. Has conceptual mismatch between its stated motivation and its technical realization. In 3D reconstruction, **novel view synthesis is merely a means to validate that the reconstructed geometry is correct, not the ultimate goal itself**. However, MoE-GS operates entirely at the image level, where the proposed Volume-aware Pixel Router blends rendered 2D outputs from multiple experts using per-pixel softmax weighting. Each expert maintains an independent 3D Gaussian representation, and **the router does not modify or unify these geometries**. Consequently, the method **only improves rendering appearance (e.g., PSNR, SSIM)** through image-space ensembling but does not enhance or reconcile the underlying 3D geometry. The core mechanism of MoE-GS is effectively **no different from mixing several rendered images with learned blending weights**, since the entire representation being optimized is the final rendered image rather than the underlying 3D structure, with no merged model output. Consequently, the claimed benefit for “dynamic reconstruction” is not real. \n\nWhile I understand that per-Gaussian routing may be technically challenging, I would appreciate clarification on whether the authors believe their Mixture-of-Experts design can genuinely improve geometric reconstruction quality rather than primarily enhancing rendering appearance. \n\n2. In figure 1, the paper convincingly demonstrates empirically that different dynamic Gaussian Splatting (GS) methods achieve different performance peaks across scenes, spatial regions, and time steps, but it does not provide a clear causal explanation for why these variations occur. Adding deeper theoretical or empirical insight into why existing GS methods differ in scene-, region-, and time-dependent performance will increase interpretability and scientific understanding of the proposed approach’s foundations."}, "questions": {"value": "Please refer to the Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aofd63cUQg", "forum": "WrEQFwWCdT", "replyto": "WrEQFwWCdT", "signatures": ["ICLR.cc/2026/Conference/Submission12089/Reviewer_bdci"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12089/Reviewer_bdci"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915594070, "cdate": 1761915594070, "tmdate": 1762923057862, "mdate": 1762923057862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "MoE-GS identifies that different dynamic Gaussian Splatting methods have varying image quality performance across scenes, image patches, and time, and proposes a mixture-of-experts dynamic GS method to adaptively combine the outputs from a few experts, each using a different dynamic Gaussian Splatting method. To stabilize the MoE-GS optimization, the authors propose a novel Volume-aware Pixel Router design to combine expert outputs through differentiable weight splatting, where routing decisions at the Gaussian level are projected to the pixel level to facilitate optimization. To improve efficiency, the authors propose a single-pass multi-expert rendering to reduce GPU kernel launching and memory IO overhead and a gate-aware Gaussian pruning algorithm to remove less-impactful Gaussians in the MoE setting. To further improve efficiency, the authors propose distilling single experts with the help of the MoE model, which they show is superior to training an equivalent single expert from scratch, using only ground-truth images."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "Very good results supported by comprehensive quantitative experiments (more in the appendix!), images, and an easy-to-read demo webpage.\n\nMoE-GS runs with higher speeds and lower memory requirements (with pruning enabled) compared to only using one of the methods the experts are based on [Table 3], while offering state-of-the-art image quality.\n\nGood applicability/adaptability. Theoretically one can use any dynamic GS method as an \"expert\" so long as it returns a set of 3D Gaussians at each time step. \n\nThe paper supports the need for using different \"experts\" well, with Figure 1 showing different dynamic GS methods have varying image quality under different situations, thus it makes intuitive sense to combine different methods together."}, "weaknesses": {"value": "Minor weakness: unlike in MoE LLMs where most experts are not executed, the MoE mode here (i.e. without distillation) still runs all experts at all times. The inference speed has potential to be improved further if, we can combine experts with sparsity. Is there a reason this is not done in this paper?"}, "questions": {"value": "How are parameters for w_i^{dir} and w_i^{time} initialized? Are they learnable? L281 suggests they're included in the optimization.\n\nI understand that Single-Pass Multi-Expert Rendering improves speed by reducing kernel launches and memory IO, but it also sounds like it will increase peak VRAM, since we could also run the experts sequentially with CPU offloading (probably much slower), or distribute the experts across GPUs (probably almost just as fast)? Have you considered or tested these two alternative strategies?\n\nFigure 1 shows that different dynamic GS methods have differing performance across scenes, image patches, and time. I wonder if MoE-GS can be generalized to have experts that each represent a different dynamic GS method? E.g. having 2 experts, one using 4D GS and one using Ex4DGS?\n\nMinor points:\nI couldn't easily find what the abbreviations (Hex., Poly., Per., inter.) stand for in Figure 1. I know that this is explained in the main text, but it'd be nice to include what these are in the captions. Also, why is \"inter\" not capitalized while the other abbreviations are?\n\nVariables in Section 3.2 are defined and used confusingly. How do the \"2D\"-subscripted variables in eq. (7) relate to eq. (6)? w_i is defined in eq. (6) but never used or explained. I'm assuming w_{2D} is a collection of w_i's, but this is not explained."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LKjSMJnx5S", "forum": "WrEQFwWCdT", "replyto": "WrEQFwWCdT", "signatures": ["ICLR.cc/2026/Conference/Submission12089/Reviewer_7MH6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12089/Reviewer_7MH6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976504443, "cdate": 1761976504443, "tmdate": 1762923057523, "mdate": 1762923057523, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}