{"id": "gUIQzhao15", "number": 20494, "cdate": 1758306784637, "mdate": 1759896974637, "content": {"title": "Code-enabled language models can outperform reasoning models on diverse tasks", "abstract": "Reasoning models (RMs), language models (LMs) trained with reinforcement learning to produce long-form natural language reasoning, have been remarkably successful, but they still cost large amounts of compute and data to train and can be slow and expensive to run. \nIn this paper, we show that ordinary LMs can already be elicited to be strong reasoners at a level comparable to or even surpass their corresponding RMs (e.g., DeepSeek V3 vs R1) without finetuning, across diverse domains from instruction following and creative generation to mathematical reasoning. This is achieved by combining the CodeAct approach, where LMs interleave natural language reasoning with code executions in a multi-step fashion, with few-shot bootstrap in-context learning---from as few as five training problems. \nAnalyzing four matched pairs of LMs and RMs, we find that our framework, coined *CodeAdapt*, enables three LMs to outperform the corresponding RMs on average over eight tasks (up to 22.9\\%) while being 10-81\\% more token efficient, and delivers superior performance for six tasks on average over models (up to 35.7\\%). The code-augmented reasoning traces further display rich and varied problem-solving strategies. Our findings support that (1) CodeAdapt-style learning and reasoning may be domain general and robust and (2) code-enabled LMs are cognitively relevant and powerful systems, potentially providing a strong foundation for in-weight reinforcement learning.", "tldr": "Code-enabled language models can outperform reasoning models", "keywords": ["language models", "reasoning models", "neurosymbolic models", "few-shot learning"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9857a1a5bc290be4eea038874f0a01d46f470816.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper argues that integrating executable code into LLMs fundamentally enhances their reasoning ability. The authors posit that reasoning tasks often require structured computation, which pure text-based models approximate but do not execute. By allowing LLMs to generate, manage, and interpret code within reasoning processes, models can perform verifiable intermediate computations and systematically improve task accuracy. The study evaluates this approach across mathematical and logical reasoning benchmarks, comparing code-enabled models to standard CoT prompting. Results show significant gains in reasoning accuracy and consistency, suggesting that access to a code interpreter reduces hallucination, enforces step validity, and better aligns outputs with formal reasoning logic. There are a number of well-established works along the lines proposed by the authors that use code-based approaches (known as PAL) to solve mathematical, multimodal, and multilingual tasks. The authors have not cited them, and I strongly recommend checking them out."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- empirical reuslts: Comparative experiments demonstrate consistent improvements over standard CoT baselines, confirming the practical benefit of code-enabled reasoning.\n\n- clarity: The authors articulate a coherent argument that reasoning can be viewed as “neural-programmatic execution”, bridging formal computation and language understanding.\n\n- impact: The approach is broadly applicable to domains requiring structured reasoning, such as mathematics, data analysis, and theorem proving."}, "weaknesses": {"value": "- Severe figure readability issues: Many figures are illegible, overcrowded, or rendered in fonts too small to interpret. Axes and legends are poorly visible, making it nearly impossible to verify the numerical trends the authors describe. This critically undermines the transparency of their results and the paper’s overall readability. The authors should completely redesign the figures, enlarging fonts, clarifying contrasts, and simplifying layouts to foreground the main findings.\n\n- theoretical grounding: The work is mainly empirical and descriptive, offering little formal analysis of why or when code execution leads to better reasoning.\n\n- Unclear evaluation protocols: The paper does not sufficiently detail the criteria for “successful reasoning” or how correctness is verified when code is executed internally.\n\n- confounds: Improvements may arise from tool-use effects (e.g., calling external functions) rather than intrinsic reasoning advances."}, "questions": {"value": "How do you ensure that improvements from code execution reflect genuine reasoning enhancement rather than simple access to an external computational oracle?\n\nHow generalisable is your framework to reasoning tasks that are non-programmatic or linguistically abstract, where code execution provides no direct computational benefit?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OQek3EPN58", "forum": "gUIQzhao15", "replyto": "gUIQzhao15", "signatures": ["ICLR.cc/2026/Conference/Submission20494/Reviewer_QqoW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20494/Reviewer_QqoW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20494/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761398866450, "cdate": 1761398866450, "tmdate": 1762933928607, "mdate": 1762933928607, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CodeAdapt, which incorporates few-shot bootstrap in-context learning based on CodeAct. CodeAdapt achieves performance improvements in areas such as instruction following, language processing, and formal reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. By adding few-shot bootstrap in-context learning on top of CodeAct, it enables self-exploration of reasoning trajectories, eliminating the need for expert demonstrations.\n2. It achieves performance improvements across multiple domains."}, "weaknesses": {"value": "1. The main issue with this paper is the lack of originality. Using code as a form of reasoning has already been widely studied in previous work. This paper mainly adds few-shot in-context learning on top of CodeAct, which does not provide substantial new insights. Domain adaptation through in-context examples has also been extensively explored in prior research.\n\n2. The paper lacks comparisons with other few-shot in-context learning or few-shot domain adaptation methods."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GzKAyOvh18", "forum": "gUIQzhao15", "replyto": "gUIQzhao15", "signatures": ["ICLR.cc/2026/Conference/Submission20494/Reviewer_xas3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20494/Reviewer_xas3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20494/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968682652, "cdate": 1761968682652, "tmdate": 1762933928260, "mdate": 1762933928260, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a compelling study on how code-enabled language models (LMs) can achieve reasoning capabilities comparable to or even surpassing specialized reasoning models (RMs) without expensive reinforcement learning training. By integrating iterative code execution (CodeAct) with lightweight in-context learning (CodeAdapt), the authors demonstrate that ordinary LMs can excel across diverse tasks—from instruction following to mathematical reasoning—using only a handful of training examples. The work highlights a cost-effective and efficient alternative to resource-intensive RM training, contributing significantly to the advancement of hybrid reasoning systems in AI."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The research addresses a timely and novel question—whether code-augmented LMs can compete with expensively trained RMs—offering a fresh perspective on resource-efficient AI reasoning.\n- The proposed CodeAdapt framework is both effective and practical, achieving superior performance across multiple tasks with minimal data and computational overhead, as validated by extensive experiments.\n- The paper is well-structured and clearly written, with comprehensive evaluations, ablation studies, and insightful analyses of reasoning patterns and resource usage."}, "weaknesses": {"value": "While the study is thorough, future work could explore the scalability of CodeAdapt to a broader range of models and real-world applications to further strengthen its generalizability."}, "questions": {"value": "- Using code to enhance language models is very common in current LLM research, which is why I'm concerned about the limited novelty of this paper. Can you summarize your core innovations again?\n- In the experiments, is the baseline design too simple?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OGIQHiold0", "forum": "gUIQzhao15", "replyto": "gUIQzhao15", "signatures": ["ICLR.cc/2026/Conference/Submission20494/Reviewer_eWPP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20494/Reviewer_eWPP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20494/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998471204, "cdate": 1761998471204, "tmdate": 1762933927774, "mdate": 1762933927774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CodeAdapt, a framework that equips LLMs with the ability to perform complex reasoning by interleaving natural language with code execution, combined with a lightweight, few-shot in-context learning procedure. The central claim is that this approach allows non-reasoning LLMs to match or even surpass the performance of specialized, expensively trained reasoning models across a diverse set of tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Enhancing the reasoning capabilities of models under low-resource conditions is a topic worthy of research.\n2. The paper is easy to read."}, "weaknesses": {"value": "1. The contribution is limited, which is a small incremental work upon CodeAct.\n2. The work does not compare with other training-free and training-based methods for enhancing LLM reasoning.\n3. The experimental setup is limited to 30/32B and API-based LLMs. The lack of experiments with 7B models raises questions about whether the method's effectiveness is overly dependent on the inherent reasoning capabilities of the LLMs.\n4. The dataset used in the paper is relatively small, which is insufficient to verify the robustness of the proposed method.\n5. What is the performance of the reasoning LLMs with general in-context learning? The proposed method uses 2-shot for in-context learning, making the comparison not fair."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kPZpJQNZsg", "forum": "gUIQzhao15", "replyto": "gUIQzhao15", "signatures": ["ICLR.cc/2026/Conference/Submission20494/Reviewer_2f2z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20494/Reviewer_2f2z"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission20494/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001316553, "cdate": 1762001316553, "tmdate": 1762933927242, "mdate": 1762933927242, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}