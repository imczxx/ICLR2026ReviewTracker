{"id": "7NNJDPCvDz", "number": 9952, "cdate": 1758152247576, "mdate": 1759897683594, "content": {"title": "When Aggregation Fails: From PAC-Bayes Theory to Practical Selection for Conformal Prediction", "abstract": "We identify and characterize a fundamental incompatibility between PAC-Bayes theory and conformal prediction: while PAC-Bayes minimizes average risk through posterior aggregation, conformal prediction's efficiency depends on quantile behavior. We prove that this \\emph{average-quantile divergence} phenomenon causes standard PAC-Bayes aggregation to systematically select suboptimal models for conformal prediction, with linear aggregation methods unable to preserve quantile optimality and efficiency losses proportional to both posterior entropy and score heterogeneity. To address this limitation, we develop PAC-Bayes Informed Selection (PBIS), which uses quantile-aware posteriors for model selection rather than aggregation. We establish PAC-Bayes bounds for quantile functionals requiring novel techniques to handle their non-differentiable nature, and prove that PBIS achieves selection consistency with $O(\\sqrt{T \\log |\\Theta|})$ regret in online settings. Empirical validation across 27 datasets demonstrates that PBIS achieves the narrowest prediction intervals among nine conformal methods while maintaining valid coverage, with 7.3\\% average improvement in high-divergence scenarios versus 2.1\\% in low-divergence ones compared to standard PAC-Bayes aggregation. The method maintains computational efficiency comparable to split conformal while being 82$\\times$ faster than CQR. In online settings with distribution shifts, PBIS uniquely maintains valid coverage across gradual, sudden, and recurring shifts where competing adaptive methods fail. Our theoretical and empirical results establish that selection-based approaches fundamentally outperform aggregation for conformal prediction by avoiding the mathematical incompatibility between average risk and quantile optimization.", "tldr": "", "keywords": ["conformal prediction", "PAC-Bayes"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2f770757bcfacb49118bc3134e8cc50d4cb75e16.pdf", "supplementary_material": "/attachment/f14cce7047ac32b6d853f6b9f077bc9b86957f71.pdf"}, "replies": [{"content": {"summary": {"value": "The PAC Bayes framework for model selection is based on empirical risk minimization over a hypothesis class with a prior distribution placed over the parameterized hypothesis class. While such model selection is natural in some settings, this paper argues that it is at odds with the goal of optimal model selection with respect to maximal efficiency after conformalization. This is because PAC Bayes is predicated on average model performance, whereas conformalized model behavior is dictated by tail behavior. Towards this end, the paper presents a characterization of the circumstances in which such a behavior arises and demonstrates how the common strategy of model aggregation can give rise to precisely this scenario. The authors, in turn, suggest performing model selection in place of aggregation, specifically selecting the model with optimal efficiency, encouraging exploration with a tunable parameter $\\lambda$. They then demonstrate several results of this proposed framework in experiments, demonstrating the coverage gap convergence, the improved predictive efficiency over alternate aggregation strategies, and validation of the claimed source of predictive inefficiency arising from naive aggregation."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper is very clearly presented, with each step of the proposed methodology both well-motivated and well-described. The paper makes claims and theoretically justifies each one, regarding the source of predictive inefficiencies and a clear proposal on how to address this issue. The method is novel and thoroughly justified in its theoretical analyses. The proofs also seem mostly sound, although there appear to be some (minor) bugs I came across in some of them (presented in the weaknesses section below). The empirical validation is also very thoroughly done, with a comprehensive set of benchmarks tested and a good collection of baselines that were compared against. Each claim is also separately justified in the empirical studies, outside of just the predictive efficiency claim, including the coverage convergence analysis and validation of the source of the aggregation inefficiency."}, "weaknesses": {"value": "While the storyline and presentation is well done, there are a couple of technical bugs I seem to have come across while going through the paper. These seem fairly minor to the overall flow of the paper, but they, I believe, do require correction.\n\n**Theorem 2**: I am unsure what this “entropy-variance inequality” refers to. It appears that the inequality as framed as \n\n$$ Var_{w}(q_i) \\ge H(w) Var(\\mathcal{Q}) \\delta_{\\min} $$\n\nIs not true, which we can see in the following counterexample:\n\n$$ (q_1, q_2) = (0, 1) $$\n$$ (w_1, w_2) = (1-\\epsilon, \\epsilon) $$\n$$ \\overline{q} = (1-\\epsilon) (0) + (\\epsilon) (1) =\\epsilon$$\n\n$$ Var_w(q_i) = \\sum_i w_i (q_i - \\overline{q})^2$$\n$$ = (1-\\epsilon) (\\epsilon)^2 + \\epsilon (1-\\epsilon)^2$$\n$$ = \\epsilon[ (\\epsilon-\\epsilon^2) + (1-2\\epsilon + \\epsilon^2) ]\n= \\epsilon(1-\\epsilon)$$\n\n$$ Var(\\mathcal{Q}) = Var({0, 1}) = (1-1/2)^2 = 1/4$$\n\n$$ \\delta_{\\min} = 1$$\n\n$$ H(w) = -(\\epsilon \\log(\\epsilon) + (1-\\epsilon) \\log(1-\\epsilon))$$\n\nFor $\\epsilon$ sufficiently small, we have that $\\epsilon(1-\\epsilon)\\approx \\epsilon$ and $1-\\epsilon\\approx 1$, meaning $(1-\\epsilon) \\log(1-\\epsilon) \\approx 0$. Thus, $H(w) \\approx -\\epsilon \\log(\\epsilon)$. This means, for small $\\epsilon, we have\n\n$$ H(w) Var(w) \\delta_{\\min} \\approx -\\epsilon \\log(\\epsilon)/4  $$\n\nThus, the claim of this statement is that\n\n$$ \\epsilon \\ge\\epsilon(-\\log(\\epsilon)/4) $$\n\nWhich is clearly untrue for any $\\epsilon$ such that $-\\log(\\epsilon)/4 > 1$, i.e. for any $\\epsilon < 10^{-4}$.\n\n**Theorem 7**: In part b, the events $V_i < K/2$ sums over the events $Y_i\\in C_k$. However, these $C_k$ will clearly be dependent on one another, since they all come from the same underlying dataset (training on slightly different folds). So, while the Chebyshev bound seems valid, I do not see how the bound relying on Hoeffding follows, as Hoeffding requires independence of the summed variables.\n\n**Theorem 6**: (More of a nitpick than an actual error) The expression $| \\widehat{Q} _{1-\\alpha}(s _{\\theta}) - Q _{1-\\alpha}[s _{\\theta}]| \\le \\frac{\\tau}{2}\\, Q _{1-\\alpha}[s _{\\theta^*}]$ is claimed to be “required”; however, this is actually just a sufficient condition for the proof and is not “required.”"}, "questions": {"value": "1. I believe this is implicitly handled by the proofs, but how is the issue of multiple testing handled to ensure coverage validity for the model selection from Phase 1 of PBIS?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0UVivDJ8h2", "forum": "7NNJDPCvDz", "replyto": "7NNJDPCvDz", "signatures": ["ICLR.cc/2026/Conference/Submission9952/Reviewer_Eaji"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9952/Reviewer_Eaji"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761248016233, "cdate": 1761248016233, "tmdate": 1762921398027, "mdate": 1762921398027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies a fundamental mismatch between PAC-Bayes aggregation and conformal prediction.It formalizes an average–quantile divergence and shows standard PAC-Bayes can favor quantile-suboptimal models. To address the problem, the authors propose PBIS: a quantile-aware PAC-Bayes posterior for model selection, with theoretical guarantees and an online variant. On 27 datasets and under distribution shifts, PBIS maintains valid coverage and runs fast, with largest gains in high-divergence settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear identification and formalization of the “average–quantile divergence” between PAC-Bayes aggregation and conformal prediction. Theorems 1–3 articulate why linear aggregation and standard PAC-Bayes objectives are misaligned.\n 2. The authors demonstrate the practical utility of their methods with an extensive series of experiments."}, "weaknesses": {"value": "1. The results in table 2 show that PBIS yields no significant improvement over traditional PAC-Bayes-CP. Besides, Coverage should be as high as possible; 0.898 should not be bolded.\n\n 2. The experiments in the online adaptive Performence part lack comparisons with more recent baselines, such as [1] and [2]. The validiy of PBIS in this scenerio requires further consideration. See questions.\n\n [1]: Xu C, Xie Y. Sequential predictive conformal inference for time series[C]//International Conference on Machine Learning. PMLR, 2023\n\n [2]: Wu J, Hu D, Bao Y, et al. Error-quantified Conformal Inference for Time Series[C]//The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "1. In online settings with distribution shifts, the magnitude of scores and $(1-\\alpha)$-quantile of scores seem less informative because the coverage of CP is not guaranteed. Instead, a more appropriate way to consider selection and aggregation may be to leverage quantile loss and replace the empirical risk in line 169 with sum of quantile loss. How do the authors comment about this? The discussions with the aggregation method in [1] and [2] should be included.    \n\n[1]: Gibbs I, Candès E J. Conformal inference for online prediction with arbitrary distribution shifts[J]. Journal of Machine Learning Research, 2024.\n\n[2]: Hajihashemi E, Shen Y. Multi-model ensemble conformal prediction in dynamic environments[J]. Advances in Neural Information Processing Systems, 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FrwDvI9ZiM", "forum": "7NNJDPCvDz", "replyto": "7NNJDPCvDz", "signatures": ["ICLR.cc/2026/Conference/Submission9952/Reviewer_5Dur"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9952/Reviewer_5Dur"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761649631668, "cdate": 1761649631668, "tmdate": 1762921397682, "mdate": 1762921397682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates a fundamental incompatibility between PAC-Bayes aggregation and conformal prediction. The authors identify the average–quantile divergence phenomenon—a mismatch between average-risk minimization (PAC-Bayes) and quantile-based efficiency (conformal prediction). They prove that any linear aggregation method fails to preserve quantile optimality and propose PAC-Bayes Informed Selection, a quantile-aware selection framework. PBIS achieves theoretical guarantees such as selection consistency and PAC-Bayes bounds for quantile functionals."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Theorems are rigorously stated, covering impossibility results, new PAC-Bayes bounds for quantile functionals, and finite-sample guarantees.\n\n- PBIS provides a simple yet useful modification.\n\n- The experiments are extensive."}, "weaknesses": {"value": "- The literature review is rather limited and could be expanded to better situate the paper within existing work.\n- The presentation is at times difficult to follow, and additional intuition or explanations—particularly around the main theorems—would greatly enhance readability.\n- The average–quantile mismatch is somewhat expected, as quantiles and expectations inherently capture different aspects of a distribution.\n- The theoretical analysis assumes a finite and discrete model space; it would be valuable to discuss how the results extend or behave when $|\\Theta|$is infinite."}, "questions": {"value": "Could PBIS be extended to continuous posterior distributions or infinite hypothesis spaces?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9cEwDP14KN", "forum": "7NNJDPCvDz", "replyto": "7NNJDPCvDz", "signatures": ["ICLR.cc/2026/Conference/Submission9952/Reviewer_P3hw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9952/Reviewer_P3hw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761810565437, "cdate": 1761810565437, "tmdate": 1762921397274, "mdate": 1762921397274, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper highlights a mismatch between PAC-Bayes aggregation and conformal prediction. The authors prove that linear aggregation can be quantile-inefficient, and motivates a solution, PAC-Bayes Informed Selection (PBIS), that uses a quantile-aware posterior to select a single model for conformal calibration instead of averaging. The authors derive finite-sample PAC-Bayes bounds for quantile functionals and give online selection guarantees, then show across many datasets (and under distribution shift) that PBIS attains valid coverage with narrower intervals and competitive runtime relative to standard baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "First of all, I think the authors the authors did a good job in the actual writing (and also formatting) of the paper and the corresponding supplementary material. Unfortunately this is not always the case these days, therefore already very good to see. \n\nApart from this (while I am not entirely sure about its motivation, see later section of my review), the authors do indeed very nicely formalize, what they call the average–quantile divergence, which explains why aggregation can fail and motivates a quantile-aware alternative. I have to admit, I am not convinced about each of the steps in the proofs, but see my later comments, happy to get corrected, or confirmed.\n\nAn other substantial strength might be the following (at least my interpretation): The results give practitioners a principled reason to prefer selection over aggregation when model scores are heterogeneous, and the broad empirical sweep (e.g. distribution-shift scenarios) suggests real impact on how ensembles are built for calibrated uncertainty."}, "weaknesses": {"value": "Frankly speaking, I have a hard time understanding the motivation of the paper itself. I am very happy to further discuss this with the authors, and change my mind. In particular, I have the following dilemma. Why should (PAC)-Bayes care about conformal prediction and vice versa? It would be great, if the authors could provide some (more) literature which works in the intersection of Bayesian and frequentist inference. \n\nApart from this, let me elaborate on some (technical) things that caught my eye. As a disclaimer: I am by no means expert when it comes to PAC-Bayes, while I am quite confident about conformal prediction and its theoretical foundations; so please elaborate if there is at any point a misunderstanding from my side.  \n\nSome comments for the theoretical parts (in particular proofs in the supplementary material):\n\n>In the proof of Theorem 2, the CDF of the aggregated score is first defined for the sum $\\bar{s} = \\sum_i w_i s_{\\theta_i}$ via $F_{\\bar{s}}(t) = P(\\sum_i w_i s_{\\theta_i}\\le t)$ and then, a few lines later, the argument switches to properties of mixtures $\\bar{F} = \\sum_i w_i F_i$. Those are not the same operation. The CDF of a weighted sum is a convolution, not a convex combination of the marginal CDFs. The subsequent Taylor argument is then carried out on $\\bar{F}=\\sum w_i F_i$, i.e., on the mixture, not on the sum originally defined. Why is then the chain from (19) to (21) – (26) still valid? (this argument is also used in the Proof of Theorem 5).\n\n>The supplement claims \"by Jensen’s inequality for quantiles (which are convex functionals in the Wasserstein metric)\" and concludes\n$Q_{1-\\alpha}[s_\\rho] \\leq E_\\theta[Q_{1-\\alpha}[s_\\theta]]$. The random object is $s_\\rho = E_\\theta[s_\\theta]$, not a Wasserstein barycenter of distributions, hence why should convexity in Wasserstein apply to this averaging operation? \n\n>The proof expands $F_i(\\bar q)$ around $q_i$ and then aggregates the linear terms to conclude an excess quantile $\\approx Var_w(q_i)/(2\\bar f(\\bar q))$. This assumes differentiability and positive density at the quantile for all $I$, and that the object being expanded matches the earlier definition. Neither the smoothness, positivity assumptions nor independence or error control terms are stated, and the target remains the mixture expression. \n\n>The proof ends with $Var_w (q_i) \\geq H(w) Var(Q) \\delta_{min}$, but the precise definition of $H(w)$ or $\\delta_{min}$ is not given here, and the relation mixes a variance of quantiles with a variance of an unspecified distribution $\\mathcal{Q}$ over models/parameters, producing a dimensionally unclear bound that drives the claim.\n\nFurther, the authors claim that PBIS satisfies DKW while PAC-Bayes marginally violates it and attribute this to the Rademacher complexity introduced by convex combinations. DKW is a distribution-free, single-sample inequality for the empirical CDF of i.i.d. draws. In particular, it does not depend on whether a predictor is an average or a selected model, and comparing a standard deviation of an error to a DKW upper bound on the sup deviation feels like apples-to-oranges. Thus, in my opinion, the violation reported is therefore not evidence against DKW, it only reflects a mismatch of quantities.\n\nRight now, I have put my score as marginally below acceptance, but I am happy to adjust, since I think the paper and its supplementary material is actually quite nicely written (modulo the things I mention), and the authors obviously have spend some thought on the topic."}, "questions": {"value": "I implicitly formulated some questions in earlier parts of the review, but I will list more questions that I had while reading the paper.\n\nAre PBIS decisions invariant to monotone re-scalings of the nonconformity score?\n\nIn the streaming scenarios, how often do you update the posterior versus the calibration threshold, and do you recommend recalibrating every update or only when a drift test triggers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IcLoI1zoQg", "forum": "7NNJDPCvDz", "replyto": "7NNJDPCvDz", "signatures": ["ICLR.cc/2026/Conference/Submission9952/Reviewer_nbLY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9952/Reviewer_nbLY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932165075, "cdate": 1761932165075, "tmdate": 1762921396945, "mdate": 1762921396945, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}