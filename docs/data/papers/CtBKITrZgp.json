{"id": "CtBKITrZgp", "number": 14656, "cdate": 1758240885823, "mdate": 1758854696556, "content": {"title": "VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models", "abstract": "We introduce a unified generative framework for solving partial differential equations (PDEs) and quantifying predictive uncertainty across forward, inverse, and partial-observation tasks. In contrast to prior approaches that design separate strategies for each setting, we recast PDE solving as a generalized video inpainting problem, where future or missing spatiotemporal states are inferred from arbitrary patterns of observed data. Our method employs a pixel-space transformer diffusion model that directly operates on physical fields, avoiding the accuracy degradation observed with latent-space representations in scientific domains. To enhance efficiency, we incorporate a hierarchical transformer strategy that balances resolution, fidelity, and computational cost. This design enables fine-grained, high-quality reconstructions together with per-pixel uncertainty estimates that capture spatial and temporal variability. Extensive experiments on five representative synthetic PDE benchmarks and a real-world ERA5 dataset demonstrate that our framework consistently outperforms state-of-the-art baselines, offering a versatile and robust approach to scientific and engineering applications.", "tldr": "We present a unified framework for predicting forward/inverse/partial PDE soltuions under ambiguity using a video inpainting diffusion model.", "keywords": ["Partial differential equations", "Video diffusion models", "Sparse observation", "Data Imputation", "Uncertainty Quantification"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/80cfaa56316000e63212cc11db2a09253f0426cb.pdf", "supplementary_material": "/attachment/2d4d1c005583297e18b0727b00de40722d4fcef1.zip"}, "replies": [], "withdrawn": true}