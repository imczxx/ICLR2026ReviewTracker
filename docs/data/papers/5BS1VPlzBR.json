{"id": "5BS1VPlzBR", "number": 19763, "cdate": 1758299127256, "mdate": 1759897020981, "content": {"title": "Balancing the False Positive-Negative tradeoff to enhance Image Segmentation", "abstract": "Image segmentation is a fundamental task in computer vision with applications spanning diverse domains, particularly in medical imaging. However, the effectiveness of segmentation techniques often varies across datasets and tasks. For instance, methods like SRL and cLDice focus on segmenting thin tubular structures, while models such as IC-Net are tailored for brain tumor segmentation in MRI scans. Despite the availability of such specialized approaches, there remains a need for a unified framework that can generalize well across different segmentation challenges. In this study, we work on the observation that in many segmentation tasks, the False Negative Rate (FNR) tends to be significantly higher than the False Positive Rate (FPR). Building on this observation, we propose a novel method, SMM, that enhances segmentation performance by conditioning the ground truth masks during training with the aim to make the model achieve a balance between false positive and false negative rates. Our approach is architecture-agnostic and has been validated on a range of benchmark datasets, consistently outperforming state-of-the-art methods, often achieving significantly better results than the baseline.", "tldr": "The paper aims to enhance image segmentation by balancing false positive and negative values using a dynamic ground truth mask modulation strategy.", "keywords": ["deep learning", "image segmentation", "mask transformation", "computer vision"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c53bede388e92af632e9001444dde381accb14fd.pdf", "supplementary_material": "/attachment/58b0bcf875ae899ca7cb0159acede3a80723da78.pdf"}, "replies": [{"content": {"summary": {"value": "(1) Exploits the hypothesis that the number of FN is significantly higher than the number of FP. We attempt to improve the model’s performance by introducing intended FP, conditioned by model performance, into the ground truth masks for enhanced training, thereby penalizing the model for missing out class pixels in smaller regions or some structures entirely. The results validate that this strategy tends to bring an overall improvement in the model performance.\n(2) Proved effective across diverse datasets, demonstrating improved performance on both binary and multi-class segmentation tasks. Its versatility makes it applicable to a wide range of imaging scenarios"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) Authors evaluated their method on difference tasks and datasets.\n\n(2) Quantitative and qualitative results were provided to help readers understand the benefits of the proposed methods."}, "weaknesses": {"value": "(1) The overall contribution is low. The proposed method did not improve the segmentation performance significantly. In contrast, the proposed method demonstrated a similar performance with U-Net (67.46 vs. 67.09 and 80.64 vs 80.01). Thus, if this method was proposed with other more advanced methods instead of U-Net, it would not outperform them.\n\n(2) The overall novelty is low. Authors only proposed a Miss-aware Mask Modulation which included a simple structure. Based on the segmentation results reported in different tasks, this proposed module did not demonstrate significant improvements over existing methods.\n\n(3) The reproducibility is low. Some implementation details are missing, and authors did not provide these details.\n\n(4) Author did not provide computational complexity of the proposed method. Authors added a new module into the baseline network, such as U-Net, so it is necessary to show the increased parameters and FLOPs due to the incorporation of this module.\n\n(5) The evaluation is insufficient. Authors only evaluated their method on convolutional neural networks, but they did not evaluate it on Vision transformer-based segmentation models."}, "questions": {"value": "(1) The overall contribution is low. The proposed method did not improve the segmentation performance significantly. In contrast, the proposed method demonstrated a similar performance with U-Net (67.46 vs. 67.09 and 80.64 vs 80.01). Thus, if this method was proposed with other more advanced methods instead of U-Net, it would not outperform them.\n\n(2) The overall novelty is low. Authors only proposed a Miss-aware Mask Modulation which included a simple structure. Based on the segmentation results reported in different tasks, this proposed module did not demonstrate significant improvements over existing methods.\n\n(3) The reproducibility is low. Some implementation details are missing, and authors did not provide these details.\n\n(4) Author did not provide computational complexity of the proposed method. Authors added a new module into the baseline network, such as U-Net, so it is necessary to show the increased parameters and FLOPs due to the incorporation of this module.\n\n(5) The evaluation is insufficient. Authors only evaluated their method on convolutional neural networks, but they did not evaluate it on Vision transformer-based segmentation models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0xaCGs9Oav", "forum": "5BS1VPlzBR", "replyto": "5BS1VPlzBR", "signatures": ["ICLR.cc/2026/Conference/Submission19763/Reviewer_rVMb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19763/Reviewer_rVMb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795236329, "cdate": 1761795236329, "tmdate": 1762931602818, "mdate": 1762931602818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work is motivated by the observation that, for medical segmentation tasks, false positives and false negatives are usually not well balanced, resulting in a disproportionate emphasis on one of them.\n The authors proposed a supervised mask modulation (SMM) method to address this issue. The proposed method is architecture-agnostic. SMM improves performance by introducing intentional false positives, under the hypothesis that, for certain tasks, the false negative rate (FNR) is higher than the false positive rate (FPR) due to the small segmentation region (class imbalance).\n The proposed method was tested on four datasets with two variants."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation of this work is clearly articulated, and I appreciate the effort to address the observed issues, especially in the medical domain, where further research is certainly needed.\n2. The authors run multiple seeds for performance evaluation and conduct proper statistical analyses. This aspect is often overlooked in machine learning research, even though it should not be. I appreciate the authors’ efforts in ensuring the reproducibility of this work.\n3. The presentation is clear and easy to follow, with figures that are both intuitive and informative."}, "weaknesses": {"value": "1. The proposed solution appears to be quite hard-coded. To my understanding, the core idea of the method is to force the model to learn a larger mask through dilation. This raises a concern: what if the class imbalance is reversed, i.e., there are more samples of class = 1 than class = 0? In that case, one would likely need to invert the strategy by shrinking the mask instead. This makes the proposed method heavily hard-coded. It would be more interesting if the authors could propose an adaptive mechanism that automatically accounts for the degree and direction of class imbalance. In this regard, I believe there is substantial room for improvement.\n\n2. The structure of the paper could also be improved. It seems that there are two main components of related work or background information that deserve emphasis. The first concerns evidence from prior work showing that the false negative rate (FNR) tends to exceed the false positive rate (FPR), and the second concerns previous efforts to address this issue and how the proposed method differs from them. Currently, the first part appears in Section 3, and the second is in the first paragraph of Section 2. Both aspects are also briefly mentioned in the introduction but without any citations. I recommend that the authors: (1) cite relevant literature whenever the issue or existing solutions are discussed, and (2) consolidate these contents into a dedicated section with clear subsections.\n\n3. Finally, there is a lack of discussion regarding the results. For example, in Figure 4, it is unclear what the yellow arrow represents and how it should be interpreted. The caption is not sufficiently intuitive. I would suggest saving some space from, for instance, Figure 3 (which could be made smaller or even omitted) and using it to include more paragraphs analyzing and discussing the results in greater depth."}, "questions": {"value": "1. There’s no weighting inbetween the 2 loss terms in algorithm 2? \n2. Isn’t that the Loss of ESL, is: $L_{ESL} = - \\frac{TP+FP}{N+FP+FN}$? I am not sure why this could help the better balance between FP and FN as they have the same weights (weights = 1.0 for both of them). Also do you have any intuition behind this design?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2Bg7EGOItP", "forum": "5BS1VPlzBR", "replyto": "5BS1VPlzBR", "signatures": ["ICLR.cc/2026/Conference/Submission19763/Reviewer_as4E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19763/Reviewer_as4E"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885721648, "cdate": 1761885721648, "tmdate": 1762931601772, "mdate": 1762931601772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Supervised Mask Modulation (SMM), a training-time, architecture-agnostic approach for image segmentation that aims to reduce false negatives while controlling false positives. The core idea (MAMM) dilates predicted FN regions and merges them into the ground truth masks during training. Two variants are presented: SMMv1 (with an elevated-sensitivity loss) and SMMv2 (with an adaptive threshold guided by recall trends). Experiments span several datasets (BoMBR, DRIVE, Cracks, Drone) with multiple metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Problem motivation is clear and relevant, especially in FN-sensitive domains (e.g., medical, defects). \n\n2. The method integrates at training time without architectural changes, which is easy to adopt. \n\n3. Experiments cover multiple datasets and metrics.\n\n4. The paper is generally readable."}, "weaknesses": {"value": "1. Novelty: The mechanism—dilating FN regions and augmenting labels—resembles label modulation/cost-sensitive training; ESL aligns with recall-weighted objectives. Without a clearer theoretical account or principled links to established losses, the contribution feels incremental for ICLR.\n\n2. Baselines: Key baselines are missing (Tversky, Focal), and evaluations focus on U-Net (and SegNet in the appendix) without modern backbones (e.g., DeepLabv3+, transformer-based segmenters), limiting the architecture-agnostic claim.\n\n3. Dataset: The datasets are small and 2D-only, which limits assessment of scalability and modern applicability. If a 2D focus is intentional, the paper should justify this choice and discuss applicability to volumetric/3D tasks.\n\n4. Result: The main text makes a strong claim that the approach has been \"validated on a range of benchmark datasets, consistently outperforming state-of-the-art methods,\" yet Appendix A shows most improvements are not statistically significant. The authors' own summary acknowledges that \"while not all improvements reach statistical significance, there are multiple encouraging trends in favor of our approach.\""}, "questions": {"value": "1. Why restrict evaluation to 2D tasks when many target domains use volumetric/3D data? Can SMM be extended to volumetric segmentation, and what limitations would arise?\n\n2. How should readers reconcile the strong claim in the main text with Appendix A showing limited significance (e.g., BoMBR/DRIVE: all p>0.05; Cracks: clDice/JSI; Drone: FPR)? Can you report effect sizes and confidence intervals?\n\n3. How does SMM compare with tuned Tversky and Focal losses? Where does SMM provide unique benefits?\n\n4. How do you ensure modulated masks remain bounded and do not overfit to early noise? How are overlaps handled in multi-class settings in practice?\n\n5. What is the training time and memory overhead relative to the baseline pipeline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "A1lwvqOASl", "forum": "5BS1VPlzBR", "replyto": "5BS1VPlzBR", "signatures": ["ICLR.cc/2026/Conference/Submission19763/Reviewer_oQze"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19763/Reviewer_oQze"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918040871, "cdate": 1761918040871, "tmdate": 1762931600504, "mdate": 1762931600504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}