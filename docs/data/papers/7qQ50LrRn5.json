{"id": "7qQ50LrRn5", "number": 14866, "cdate": 1758244867576, "mdate": 1759897344583, "content": {"title": "Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning", "abstract": "Current knowledge-enhanced large language models (LLMs) rely on static, pre-constructed knowledge bases that suffer from coverage gaps and temporal obsolescence, limiting their effectiveness in dynamic information environments. We present Agentic-KGR, a novel framework enabling co-evolution between LLMs and knowledge graphs (KGs) through multi-round reinforcement learning (RL). Our approach introduces three key innovations: (1) a retrieval-augmented memory system enabling synergistic co-evolution between model parameters and knowledge structures through continuous optimization; (2) a dynamic schema expansion mechanism that systematically extends graph ontologies beyond pre-defined boundaries during training; (3) a learnable multi-scale prompt compression approach that preserves critical information while reducing computational complexity through adaptive sequence optimization. Experimental results demonstrate substantial improvements over supervised baselines and single-round RL approaches in knowledge extraction tasks. When integrated with GraphRAG, our method achieves superior performance in downstream QA tasks, with significant gains in both accuracy and knowledge coverage compared to existing methods.", "tldr": "", "keywords": ["Agentic", "Reinforcement Learning", "Knowledge Graph", "Large Language Model"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/26877a80a74c7567cb2718adf33f53a067ccf082.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces the Agentic-KGR framework, a novel method that facilitates the co-evolution of large language models and knowledge graphs through multi-agent reinforcement learning. It aims to overcome the limitations of static knowledge bases by enabling dynamic knowledge construction and adaptation. Key innovations include a dynamic schema expansion mechanism, a retrieval-augmented memory system, and a learnable multi-scale prompt compression approach."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The concept of co-evolution between LLMs and KGs is well-founded and provides a fresh perspective on knowledge graph construction. The integration of multi-round RL is particularly valuable for addressing the dynamic nature of real-world knowledge and improving LLM performance in knowledge-intensive tasks.\n2. The paper demonstrates solid experimental results, with clear improvements in knowledge extraction and QA performance."}, "weaknesses": {"value": "1. While the paper covers a significant amount of technical depth, it occasionally becomes difficult to follow, especially in the description of the architecture and algorithmic details. The explanations of the co-evolutionary memory and multi-scale compression mechanisms could benefit from more intuitive explanations to help the reader grasp the concepts more quickly.\n2. The paper focuses heavily on the proposed framework's strengths but could benefit from a more thorough discussion of its limitations or challenges. For example, how scalable is this approach for large-scale knowledge graph construction in real-world applications? Additionally, potential pitfalls or failure modes in dynamic KG construction could have been addressed more comprehensively."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "itdGzhiDSZ", "forum": "7qQ50LrRn5", "replyto": "7qQ50LrRn5", "signatures": ["ICLR.cc/2026/Conference/Submission14866/Reviewer_aAWs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14866/Reviewer_aAWs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761028501710, "cdate": 1761028501710, "tmdate": 1762925218241, "mdate": 1762925218241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of LLMs hallucination.  The paper proposes a framework that enables co-evolution between LLMs and Kgs through multi-round RL."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "As LLMs are more and more integrated in our daily life, the problem of LLMs hallucination is a problem that needs a particular attention. The experiment of the approach is well described, along with the experimentation environment."}, "weaknesses": {"value": "The paper in its current form has several issues. \nThe paper claims that the approach is and innovation, which is not the case\nMissing summary of the experiments (e.g., datasets, models used) and results in the abstract and introduction.\nMissing of the related work in the paper. Provided in the additional materials. However, the paper should be self contained.\nLine 52-53: “Existing methods rely on static, pre-constructed KGs that suffer from coverage gaps, temporal obsolescence, and inability to adapt to emerging domain knowledge or evolving query patterns” That is not true. No. KGs are supposed to evolve and agentic methods are there to take care of the evolution of Kgs\nLine 54-59: These claims should be supported by examples/evidence provided by references\nTable 1:  Put the table near the place it is cited. The tables are in page 5, 6 and used in page 8."}, "questions": {"value": "Integrate the related work in the paper to make the paper self contained.\nSummarize the experiments and results in the abstract and introduction\nImprove the quality of the manuscript by putting the figure near the place they are cited for the first time"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wbomeja0tX", "forum": "7qQ50LrRn5", "replyto": "7qQ50LrRn5", "signatures": ["ICLR.cc/2026/Conference/Submission14866/Reviewer_VHjg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14866/Reviewer_VHjg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826683693, "cdate": 1761826683693, "tmdate": 1762925217584, "mdate": 1762925217584, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Agentic-KGR, a novel framework designed to address the limitations of static, pre-constructed knowledge bases (KGs) often used by knowledge-enhanced large language models (LLMs). These static knowledge bases typically suffer from coverage gaps and temporal obsolescence. The core contribution of Agentic-KGR is enabling the co-evolution between LLMs (acting as reasoning agents) and dynamic KGs through multi-round reinforcement learning (RL). This paradigm shifts the approach from static knowledge retrieval to adaptive knowledge co-creation, viewing knowledge construction and utilization as interconnected, mutually reinforcing processes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper's primary strength in originality lies in defining a novel paradigm shift for knowledge-enhanced language models. Instead of relying on static, pre-constructed knowledge bases (KGs) which suffer from coverage gaps and obsolescence, Agentic-KGR introduces a framework that enables the co-evolution between LLMs and KGs through multi-round reinforcement learning (RL). This fundamentally transforms the approach from static knowledge retrieval to adaptive knowledge co-creation."}, "weaknesses": {"value": "1. One of the key innovations is the Learnable Multi-Scale Prompt Compression (LMPC), intended to preserve critical information while reducing computational overhead. While the results demonstrate that Agentic-KGR successfully reduces the overall average response length across all architectures (Figure 4, Figure 7), this does not directly prove cost or latency reduction.\n\n2. The most significant performance gains in both extraction (RE performance) and downstream QA (Table 2) rely heavily on domain-specific datasets derived from communication technology/telecom documentation (CommTKG, MmlKG, ConfigKG, WirelessKG, DcommKG). Actionable Insight: The paper must demonstrate the robustness of the dynamic schema expansion and co-evolution mechanisms on highly volatile, cross-domain, or general-purpose knowledge datasets to ensure the results are not heavily contingent on the structure or language features unique to structured technical manuals."}, "questions": {"value": "1. In the multi-round retrieval framework proposed in this paper, there is only a single LLM agent, whereas a typical multi-agent system usually contains at least two LLM agents. Does this make the paper’s naming somewhat misleading?\n\n2. Could the authors provide a direct comparison of Agentic-KGR's KG extraction (RE/NER) and downstream QA performance against state-of-the-art agentic reinforcement learning baselines mentioned in the related work, specifically Graph-R1 (for end-to-end graph RAG optimization) and ReSearch (for LLMs learning to reason with search via RL)?\n\n3. As an end-to-end optimization framework, Agentic-KGR uses reinforcement learning to directly optimize the agent policy, compression scales, and knowledge-graph update operators. Could this make the method overly sensitive to hyper-parameters and cause unstable training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QS5aXYuRJc", "forum": "7qQ50LrRn5", "replyto": "7qQ50LrRn5", "signatures": ["ICLR.cc/2026/Conference/Submission14866/Reviewer_nGcN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14866/Reviewer_nGcN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925476556, "cdate": 1761925476556, "tmdate": 1762925217310, "mdate": 1762925217310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Agentic-KGR, a framework for co-evolutionary knowledge graph construction using multi-agent reinforcement learning. It overcomes the limitations of static KGs by enabling dynamic schema expansion, a retrieval-augmented memory system for synergistic optimization, and a learnable multi-scale prompt compression to handle computational complexity."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of mutual adaptation between LLMs and KGs via multi-round RL is timely and innovative.\n2. The methodology is well-formalized with clear definitions。\n3. Claims of substantial gains in KG density/coverage and QA accuracy are compelling, especially the integration with GraphRAG for end-to-end validation."}, "weaknesses": {"value": "1. The experiments focus on KG extraction and QA, but details are sparse in the provided sections (e.g., datasets not specified early; baselines like DeepPath or MINERVA mentioned but not compared quantitatively here).\n2. No discussion of scalability (e.g., for large KGs) or real-world costs (tokens/time in multi-round RL).\n3. Diversity in tasks/domains beyond product QA is missing, for instance, the medical RAG in GraphRAG-benchmark[1].\n\n- [1] When to use graphs in rag: A comprehensive analysis for graph retrieval-augmented generation."}, "questions": {"value": "Please see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PAfpordvW3", "forum": "7qQ50LrRn5", "replyto": "7qQ50LrRn5", "signatures": ["ICLR.cc/2026/Conference/Submission14866/Reviewer_xU37"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14866/Reviewer_xU37"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992396569, "cdate": 1761992396569, "tmdate": 1762925216906, "mdate": 1762925216906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}