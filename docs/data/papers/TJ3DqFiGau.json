{"id": "TJ3DqFiGau", "number": 10059, "cdate": 1758159229726, "mdate": 1759897677394, "content": {"title": "Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models", "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large Language Models (LLMs) by integrating external knowledge. However, conflicts between parametric knowledge and retrieved context pose challenges, particularly when retrieved information is unreliable or the model's internal knowledge is outdated. In such cases, LLMs struggle to determine whether to rely more on their own parameters or the conflicted context. To address this, we propose CK-PLUG, a plug-and-play method for controlling LLMs' reliance on parametric and contextual knowledge. We introduce a novel knowledge consistency metric, Confidence Gain, which detects knowledge conflicts by measuring entropy shifts in token probability distributions after context insertion. CK-PLUG then enables fine-grained control over knowledge preference by adjusting the probability distribution of tokens with negative confidence gain through a single tuning parameter. Experiments demonstrate CK-PLUG's ability to significantly regulate knowledge reliance in counterfactual RAG scenarios while maintaining generation fluency and knowledge accuracy. For instance, on LLaMA3-8B, memory recall (MR) of RAG response can be adjusted within a broad range (9.9%-71.9%), compared to the baseline of 42.1%. Moreover, CK-PLUG supports adaptive control based on the model's confidence in both internal and external knowledge, achieving consistent performance improvements across various general RAG tasks. Our code is available at: https://anonymous.4open.science/r/CK-PLUG-Ano-8E62", "tldr": "", "keywords": ["Large Language Models", "Retrieval-Augmented Generation", "Knowledge Conflict", "Controllable Generation", "Knowledge Reliance"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eb16b3bd293ef2dff3cc946fc104213874f0a165.pdf", "supplementary_material": "/attachment/a3425176ea3e7f5a6efaacccc0012eab67eeee92.zip"}, "replies": [{"content": {"summary": {"value": "The approach detects tokens susceptible to conflicts between these two knowledge sources by measuring per-token entropy, then interpolates between their context-dependent and context-independent probability distributions. The degree of interpolation is governed by a single hyperparameter, which can be set manually or determined automatically using a heuristic based on the entropy ratio of the two variants."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is clearly written and easy to understand.\n\n- The authors introduce a conceptually straightforward and well-motivated approach to regulate the model’s dependence on retrieved context.\n\n- The proposed method is empirically solid and thoroughly evaluated, demonstrating its effectiveness in balancing contextual and parametric knowledge and enhancing question-answering accuracy."}, "weaknesses": {"value": "### Methodological Evaluation\n\nFrom a methodological standpoint, the proposed approach offers **limited novelty**, as it also relies on **distribution interpolation** between context-dependent and context-independent probabilities, similar to [1].  \n\nThe main differences are:  \n- **Selective interpolation:** In this paper, interpolation is applied **only to tokens whose entropy increases after adding context**, assuming these tokens indicate parameter–context conflict. In contrast, [1] applies interpolation **to all tokens**.  \n- **Different interpolation formula:**  \n  This paper uses  \n  $$\n  \\alpha \\log p(y \\mid x) + (1 - \\alpha) \\log \\frac{p(y \\mid c, x)}{p(y \\mid x)} = (1 - \\alpha) \\log p(y \\mid c, x) - (1 - 2\\alpha) \\log p(y \\mid x)\n  $$  \n  whereas [1] uses  \n  $$\n  (1 + \\alpha) \\operatorname{logit}(y \\mid c, x) - \\alpha \\operatorname{logit}(y \\mid x)\n  $$  \n\nHowever, the **motivation for this specific interpolation formula** is largely **intuitive**, and the **procedure for identifying conflict-inducing tokens** is not rigorously justified.  \n\nThe **improvements in accuracy** over the standard RAG baseline are **modest**—and sometimes even **negative** (e.g., on **FEVER**, performance drops from 89.5 % to 89.2 % for Mistral, see Table 2)—which is disappointing given the method requires **approximately double the compute**.  \n\nOverall, **more analysis and empirical/theoretical justification** are needed to demonstrate that the proposed method is truly worth its computational overhead and that it **outperforms [1]** in a meaningful way.  \n\n**Reference:**  \n[1] Shi, Weijia, et al. *Trusting Your Evidence: Hallucinate Less with Context-Aware Decoding.* *Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers).* 2024."}, "questions": {"value": "### General Questions\n\n- What are the exact formulas used to define **ConR** and **ParR**? They are mentioned in line 309, but no details are provided on how they are computed.  \n- It would be helpful to analyze how much **context vs. parametric reliance** affects performance to justify why adjusting this balance is important. I’m particularly interested in the **question-answering accuracy** corresponding to each ratio in Table 1.  \n- Could you please specify the **number of forward passes** (or total compute) used by each method in Table 2 to ensure a fair comparison?\n\n---\n\n### Suggested Experiments\n\n#### Justify the Interpolation Formula\nI recommend comparing the current method directly with [1], including:\n- **No ConD + interpolation from [1]**\n- **CK-Plug** results from Table 1 and Table 2  \nAdditionally, please include an **ablation on the interpolation formula** in Table 3. At present, it includes (ConD + interpolation from CK-Plug) and (no ConD + interpolation from CK-Plug); it would be informative to also test (ConD + interpolation from [1]) and (no ConD + interpolation from [1]).  \n\nThese comparisons would clarify the necessity of introducing **ConD** and justify your **specific interpolation design**. If the interpolation from [1] performs robustly without ConD, then the added component may not be needed.\n\n---\n\n#### Explore More Challenging Context–Parameter Conflict Scenarios\nIt would strengthen the paper to test **CK-Plug** in settings with **stronger context–parameter conflicts**, such as those difficult even for large models like ChatGPT.  \nYou could evaluate performance in scenarios like §4.4.2 (where the parametric answer is inserted as a substring into the context) or use **Table 6 in [3]** as reference.  \nThis would help determine whether CK-Plug can effectively guide the model to prefer the **contextual** rather than **parametric** answer under such conditions.\n\n---\n\n#### Justify the Use of Entropy for Conflict Detection\nI suggest performing **ablations on different uncertainty measures** for identifying conflict-prone tokens, beyond entropy.  \nFor example, try using **maximum token probability** or more recent uncertainty estimation techniques such as [2].  \nThis would validate whether entropy is indeed the most suitable choice for detecting parameter–context conflicts.\n\n---\n\n**References**\n\n[1] Shi, Weijia, et al. *Trusting Your Evidence: Hallucinate Less with Context-Aware Decoding.*  \nProceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics (Volume 2: Short Papers), 2024.  \n\n[2] Ma, Huan, et al. *Estimating LLM Uncertainty with Logits.* arXiv preprint arXiv:2502.00290 (2025).  \n\n[3] Kortukov, Evgenii, et al. *Studying Large Language Model Behaviors Under Context–Memory Conflicts With Real Documents.*  \nFirst Conference on Language Modeling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VNsUD0TmZQ", "forum": "TJ3DqFiGau", "replyto": "TJ3DqFiGau", "signatures": ["ICLR.cc/2026/Conference/Submission10059/Reviewer_yNez"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10059/Reviewer_yNez"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761487730781, "cdate": 1761487730781, "tmdate": 1762921454494, "mdate": 1762921454494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CK-PLUG, a plug-and-play method for controlling knowledge reliance in RAG systems when conflicts arise between LLMs' parametric knowledge and retrieved context. The approach uses a novel Confidence Gain metric based on entropy shifts to detect knowledge conflicts at the token level. CK-PLUG modulates token probability distributions through weighted fusion of parameter-aware and context-aware predictions, controlled by a single tuning parameter α. Experiments on four LLMs (LLAMA2/3, Mistral, Qwen) demonstrate wide-range controllability on counterfactual datasets while maintaining fluency. The method also offers an adaptive mode that automatically balances knowledge sources based on model confidence, achieving consistent improvements across six diverse RAG tasks without requiring parameter modifications or retraining."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Novel entropy-based conflict detection that provides interpretable, theoretically-grounded identification of knowledge conflicts through Confidence Gain metric\n- Flexible control via single parameter enabling smooth adjustment from full contextual to full parametric reliance with optional autonomous mode\n- Practical plug-and-play design requiring no training or architecture changes while demonstrating effectiveness across multiple models and diverse RAG tasks"}, "weaknesses": {"value": "1. **Insufficient Baseline Comparisons** \n\n   The paper lacks comparisons with existing adaptive RAG methods that also address knowledge conflicts or context utilization. Notable missing baselines include:\n   - Adaptive retrieval methods: FLARE, Self-RAG, DRAGIN, SeaKR\n   - Context-aware generation: RQ-RAG, QC-RAG, CtrlA\n\n   Without these comparisons, it is difficult to assess whether the performance gains are due to CK-PLUG's novel approach or simply from any form of adaptive control. The authors should include at least a subset of these methods to demonstrate the unique advantages of their entropy-based approach.\n\n\n2. **Missing Critical Related Work**\n\n   The paper overlooks several highly relevant previous or concurrent works that employ similar entropy-based or conflict-detection approaches for RAG:\n   - Entropy-Based Decoding for Retrieval-Augmented Large Language Models (arXiv:2406.17519, June 2024) - uses entropy for RAG decoding\n   - Discerning and Resolving Knowledge Conflicts through Adaptive Decoding with Contextual Information-Entropy Constraint (arXiv:2402.11893, Feb 2024) - directly addresses knowledge conflicts via entropy\n   - SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion (arXiv:2505.07528, May 2025) - combines semantic entropy with context-parameter fusion\n   - FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation (arXiv:2506.08938, Jun 2025) - models fact-level conflicts\n\n3. **Limited Applicability to Modern Agentic RAG Systems**. \n\n   Current RAG systems are evolving toward agentic architectures involving multi-step planning, iterative search, self-reflection, and answer verification (e.g., Search-o1, Search-R1, Reason-RAG, Web-walker, Web-sailor, etc). CK-PLUG operates at the token-level decoding stage, and it remains unclear whether:\n   - The method can be integrated into multi-turn agentic workflows\n   - Conflict detection works when contexts are iteratively refined\n   - The approach scales to complex reasoning chains\n\n   The authors should discuss or demonstrate CK-PLUG's compatibility with agentic RAG frameworks to ensure practical relevance.\n\n\n4. **Insufficient Analysis of Computational Overhead**\n   While claimed to be \"lightweight,\" the paper provides no quantitative analysis of:\n   - Latency increases during inference (requires two forward passes for parameter-aware and context-aware distributions)\n   - Memory overhead from maintaining multiple probability distributions\n   - Scalability with increasing context length"}, "questions": {"value": "Q1: Clarification on Notation (Line 143-144). There is a typographical error with double periods: \"distributions..\" Please correct.\n\nQ2: Ambiguous \"Baseline\" Definition in Table 1. The \"Baseline\" row in Table 1 is unclear. Does it refer to:\n- (a) Vanilla LLM without RAG (direct question answering), or\n- (b) Standard RAG with both query and retrieved context, but without CK-PLUG?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xFi6mgQ4eG", "forum": "TJ3DqFiGau", "replyto": "TJ3DqFiGau", "signatures": ["ICLR.cc/2026/Conference/Submission10059/Reviewer_yjeZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10059/Reviewer_yjeZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761646742165, "cdate": 1761646742165, "tmdate": 1762921453858, "mdate": 1762921453858, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Retrieval-Augmented Generation (RAG) reduces hallucinations in Large Language Models (LLMs) by incorporating external knowledge, yet it faces challenges from conflicts between the models’ parametric knowledge (internal) and retrieved context (external)—especially when the retrieved information is unreliable or the internal knowledge is outdated, leaving LLMs unable to decide which type of knowledge to prioritize. To solve this, the authors propose CK-PLUG, a plug-and-play method designed to control LLMs’ reliance on parametric and contextual knowledge. CK-PLUG introduces a new knowledge consistency metric called Confidence Gain, which detects knowledge conflicts by measuring entropy shifts in token probability distributions after context insertion; it then enables fine-grained control over knowledge preference by adjusting the probability distribution of tokens with negative Confidence Gain via a single tuning parameter, and also supports adaptive control based on the model’s confidence in both knowledge types."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The biggest advantage of this paper is proposing a \"plug-and-play\" inference-time method.\n\n2. Conflict Detector: It introduces a metric called \"Confidence Gain (CG)\", which identifies conflicts by comparing the entropy change of token distribution between RAG input (context + query) and regular input (query only). A conflict is determined when there is an entropy increase (i.e., the model becomes more confused), and this definition is reasonably sound.\n\n3. Knowledge Controller: This method isolates the logits purely contributed by the \"context\" through log subtraction, and then uses a single parameter to perform weighted fusion of parametric knowledge and contextual knowledge (Eq. 8). This is an extremely concise and theoretically grounded approach to logits manipulation.\n\n4. Adaptive Model Construction: The paper also proposes an adaptive mode with \"automatic (parameter adjustment)\" (Eq. 10), whose logic is equally intuitive — the model automatically trusts the knowledge source with lower entropy (i.e., higher confidence)."}, "weaknesses": {"value": "1. This is the most serious and obvious flaw of the paper. To calculate [relevant parameters] and [relevant parameters], CK-PLUG must execute two complete forward propagations in parallel at each decoding step: one for [input with context + query + generated tokens] and the other for [input with query only + generated tokens]. This almost doubles the inference latency and computational cost.\n\n2. The core assumption of the paper is that \"conflicts lead to entropy increase\". However, if the erroneous context itself is highly \"credible\" and \"fluent\" (e.g., \"The capital of France is Lyon\"), it is entirely possible to reduce the model’s perplexity, resulting in \"entropy decrease\".\n\n3. The calculation of (Eq. 6) may be numerically unstable. If [parametric distribution] assigns a near-zero probability to a certain token (with [log value] approaching negative infinity) while [context-enhanced distribution] assigns a high probability to it, [resulting value] may \"explode\". The paper does not discuss any suggestions for handling numerical stability."}, "questions": {"value": "1. Supplement implementation details regarding the calculation of [relevant parameter], and explain whether and how potential numerical instability issues have been addressed.\n\n2. Conduct more rigorous stress tests on the \"Confidence Gain (CG)\" assumption—specifically construct erroneous contexts that are \"highly credible and highly fluent\", and illustrate the changes in [relevant indicator] under such circumstances as well as CK-PLUG’s performance metrics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5FzCsnID45", "forum": "TJ3DqFiGau", "replyto": "TJ3DqFiGau", "signatures": ["ICLR.cc/2026/Conference/Submission10059/Reviewer_BrkV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10059/Reviewer_BrkV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761818456968, "cdate": 1761818456968, "tmdate": 1762921453467, "mdate": 1762921453467, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CK-PLUG, a plug-and-play method that enables large language models to dynamically balance reliance on internal (parametric) knowledge and external (retrieved) context during retrieval-augmented generation. Using a novel Confidence Gain metric that detects knowledge conflicts via entropy shifts in token probabilities, CK-PLUG selectively adjusts token-level predictions with a single tuning parameter $\\alpha$ (or adaptive enhancement) to favor either parameters or context. Experiments demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper was well-written and had very nice figures.\n- The proposed method is lightweight and effective."}, "weaknesses": {"value": "- My biggest concern with this paper is novelty. The use of entropy for identifying key tokens has been explored in recent works [1–2], yet these closely related studies are not cited—especially [1], which shares a similar methodology for token-level entropy analysis. Even if applied in a different context, omitting these references significantly weakens the originality of the contribution.\n- The proposed CK-PLUG method may not generalize across all scenarios. For example, if the model is confidently wrong and the retrieved context reinforces the incorrect belief, the system may still fail. The authors should clarify the underlying assumptions and delineate conditions where CK-PLUG is reliable to enhance its scientific soundness. \n- The paper lacks comparisons with prior decoding-based [3–7] and intervention-based [8–9] approaches that similarly aim to regulate factuality and knowledge conflicts. Including such baselines would better demonstrate the advantages and distinct contributions of CK-PLUG. \n\n[1] What is Wrong with Perplexity for Long-context Language Modeling? ICLR'25\n\n[2] Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models. ACL'25 \n\n[3] Trusting Your Evidence: Hallucinate Less with Context-aware Decoding. NAACL'24\n\n[4] Sled: Self logits evolution decoding for improving factuality in large language models. NeurIPS'24\n\n[5] Dola: Decoding by contrasting layers improves factuality in large language models. ICLR'24\n\n[6] Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation. EMNLP'25\n\n[7] AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge. NACCL'25\n\n[8] Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models. ACL'24\n\n[9] Taming Knowledge Conflict in Language Models. ICML'25"}, "questions": {"value": "Aforementioned in the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BKmBe9b5ZJ", "forum": "TJ3DqFiGau", "replyto": "TJ3DqFiGau", "signatures": ["ICLR.cc/2026/Conference/Submission10059/Reviewer_jata"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10059/Reviewer_jata"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761855219345, "cdate": 1761855219345, "tmdate": 1762921453170, "mdate": 1762921453170, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}