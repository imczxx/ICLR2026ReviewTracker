{"id": "NjjRuJuMTd", "number": 17715, "cdate": 1758279655754, "mdate": 1759897158749, "content": {"title": "Alternating Diffusion for Proximal Sampling with Zeroth Order Queries", "abstract": "This work introduces a new approximate proximal sampler that operates solely with zeroth-order information of the potential function. Prior theoretical analyses have revealed that proximal sampling corresponds to alternating forward and backward iterations of the heat flow. The backward step was originally implemented by rejection sampling, whereas we directly simulate the dynamics. Unlike diffusion-based sampling methods that estimate scores via learned models or by invoking auxiliary samplers, our method treats the intermediate particle distribution as a Gaussian mixture, thereby yielding a Monte Carlo score estimator from directly samplable distributions. Theoretically, when the score estimation error is sufficiently controlled, our method inherits the exponential convergence of proximal sampling under isoperimetric conditions on the target distribution. In practice, the algorithm avoids rejection sampling, permits flexible step sizes, and runs with a deterministic runtime budget. Numerical experiments demonstrate that our approach converges rapidly to the target distribution, driven by interactions among multiple particles and by exploiting parallel computation.", "tldr": "We introduce a zeroth-order proximal sampler with Gaussian-mixture score estimation that converges rapidly without rejection sampling.", "keywords": ["Sampling", "Diffusion-based Monte Carlo", "Zeroth-order methods"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/495b8c2218f748085f88a2a3929af4d2be64398b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Method for non-parametric diffusion based approximation of proximal sampling exploiting zeroth-order information\nwith particle interaction. The authors use a Gaussian mixture surrogate for denoising the particles in the alternating proximal sampling process. They avoid the computation of gradient of $f$ for guidance in the SDEs and use of wasteful rejection sampling for denoising step. This leads to a multi particle sampling algorithm with deterministic runtime and exponential convergence guarantees with accurate score function esitmation"}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The authors present a very clear motivation and methodology for their work. The background is covered in a structure manner and the theoretical analysis and the experiments support the claims in the paper. The paper is very well written and the contributions are noteworthy. \n\nThe proposed sampling method uses simple surrogate to bypass inefficient use of rejection sampling and approximation of the score function. The method relies on noisy approximation of the score function of the denoising SDE, which derives it from zeroth order information and multi-particle interactions, improving the coverage of the disconnected modes of the distributions, and alleviating the need for projection and convex support."}, "weaknesses": {"value": "The introduction stresses that the proximal algorithm should be scalable. However the experiments are limited to small $d$ scenarios. It would be informative to have additional results showing convergence time vs $d$ and compare the algorithm with the baselines.\n\nTypo: 146 $B_t^\\leftarrow$ is backward Brownian motion."}, "questions": {"value": "The Monte Carlo estimation of the score function is increasing the overall computation with $M$ - But in the experiment section I didn't understand how the authors used large $M$ and compare to algorithms that don't have that many parallel threads in a fair setup. Can the authors provide a description of the fairness?\n\nMode coverage in the target is attributed to both the ability to use larger noise scale $h$ and the inverse weight of $x$ in high concentration regions. But the two seem to be in contention in $\\hat q_{k+1/2}(\\cdot|X_k)$, i.e close to $X_k$ and with small $h$ the component weights in Eq 10 will be smaller. Doesn't increasing $h$ at the same time make the weights more uniform?\n\nHave the authors studied the convergece time vs $M$ and $N$ when $N\\times M$ is fixed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rw2U2wTBPl", "forum": "NjjRuJuMTd", "replyto": "NjjRuJuMTd", "signatures": ["ICLR.cc/2026/Conference/Submission17715/Reviewer_RPkJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17715/Reviewer_RPkJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667057845, "cdate": 1761667057845, "tmdate": 1762927550482, "mdate": 1762927550482, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a canonical isoperimetric sampling problem via a localized reverse heat flow and develops theoretical guarantees by leveraging the proximal-sampling analysis paradigm, reflecting the close connection between proximal operators and localized reverse diffusion. Unlike standard proximal samplers, the proposed method does not require first-order (gradient) information of the target distribution. This is enabled by a Tweedie-style identity that reformulates the denoising score, thereby removing the need for explicit gradients. While related identities have been used for importance weighting in [huang2024a], the probability path considered here is distinct—combining a global proximal path with a local reverse diffusion path—and the paper analyzes a Sequential Monte Carlo (SMC) scheme, which was not studied in [huang2024a]."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Although many components (proximal samplers, reverse diffusion Monte Carlo, and SMC) are drawn from prior work, the paper integrates them coherently to deliver a zero-order sampling scheme with provable convergence. The design is guided by a clear insight: Langevin-based methods inherently require gradients, whereas reverse-diffusion samplers can operate using only zero-order information.\n2. The paper explicitly elucidates the close connection between proximal sampling and reverse diffusion, an important and conceptually insightful observation that may inform the design of gradient-free samplers.\n3. The exposition is clear and well-structured: the intuition, assumptions, and main theorems are presented transparently, and the experiments are comprehensive, effectively demonstrating the proposed method’s efficacy."}, "weaknesses": {"value": "1. The complexity analysis appears incomplete. The paper provides a one-step KL contraction bound with an additive term, but lacks an end-to-end error and cost analysis that composes these bounds over the full trajectory. A global, non-asymptotic complexity guarantee would substantially strengthen the contribution.\n2. The theoretical results are largely asymptotic. In practice, performance with finite $M$ (particles) and $N$ (time steps) is crucial. The assumptions used to control the one-step error via $M$ and $N$ seem idealized; we recommend validating their plausibility empirically on synthetic data and reporting sensitivity to $M$ and $N$.\n3. The comparison with RGO is unclear. What constitutes an ``iteration''? Does one pass that updates the entire sequence $\\{x_i\\}_{i=1}^N$ count as a single iteration or as $N$ iterations? Please clarify the accounting, and provide convergence comparisons against wall-clock time to enable fair, hardware-agnostic evaluation."}, "questions": {"value": "Refer to the above parts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VmmZjI8SKW", "forum": "NjjRuJuMTd", "replyto": "NjjRuJuMTd", "signatures": ["ICLR.cc/2026/Conference/Submission17715/Reviewer_rzzM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17715/Reviewer_rzzM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880133434, "cdate": 1761880133434, "tmdate": 1762927550021, "mdate": 1762927550021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The method provides an alternate implementation of the proximal sampler/RGO, based on an estimate for the scores using a particle ensemble of samples. This method yields a score estimator which appears as a mixture of Gaussians; in particular, the score estimator is implementable using zeroth order oracle queries. Theoretical analysis for this algorithm is provided, showing rates polynomial in the problem parameters. Experimental evidence then shows that this algorithm outperforms standard implementations of the RGO several benchmarks of interest."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The method provides a means for implementing the RGO in the proximal sampler using only \\emph{zeroth} order queries, which is a more general computational model than the standard gradient oracle model. Furthermore, it does not need any convoluted tricks (MALA + underdamped) to implement the proximal sampler, compared to prior theoretical proposals.\n\nThe method appears to work extremely well in practice when compared to the standard implementation of the RGO. Generally, I suppose it is not too surprising that these particle methods can perform well in practice, although theoretical guarantees may be harder to establish.\n\nThe method seems to be easily parallelizable."}, "weaknesses": {"value": "The theoretical guarantees are not particularly strong; I would be surprised if in the LSI setting this could improve upon the guarantees for the usual implementation of the RGO. Indeed, as the error scales as 1/N in the number of particles, so we should expect $N \\asymp \\varepsilon^{-2}$ or polynomial in the accuracy (compared to the standard implementation). Of course, there are other drawbacks to the theory."}, "questions": {"value": "For this algorithm, when running the particle ensemble, do we take the entire ensemble of N particles as samples? This has the risk of inducing extra errors from correlation, but is unlikely to matter much in practice.\n\nI am also surprised that we only see $1/N$ in the error, compared to the usual curse of dimensionality for non-parametric estimation. What is the intuition here?\n\nLine 373 has some space formatting issues.\n\n\nNotation for R\\’enyi divergence switches between $\\mathcal R$ and $R$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZEVDVpx8TO", "forum": "NjjRuJuMTd", "replyto": "NjjRuJuMTd", "signatures": ["ICLR.cc/2026/Conference/Submission17715/Reviewer_zSYe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17715/Reviewer_zSYe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965481256, "cdate": 1761965481256, "tmdate": 1762927549035, "mdate": 1762927549035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies proximal sampling for a distribution satisfying the log-Sobolev inequality without implementing the restricted Gaussian oracle (RGO) by rejection sampling. Instead, it uses the idea of diffusion-based Monte Carlo to simulate the backward SDE (i.e., eq (5)) for the backward step in proximal sampling, that is, the RGO. By tracking $N$ particles, the proposed method approximates $\\pi^X$ by (9), and hence approximates the score function in (5) by (11). The key idea behind the approximation (9) is importance sampling. Thus, different from the exact implementation of RGO using first-order oracle of potential $f$ (for solving an optimization problem) and rejection sampling, Algorithm 1 approximately implements RGO by simulating (5) over $T$ internal steps within the stepsize $h$ of the (outer) proximal sampling.\n\nThe paper presents a complete analysis of Algorithm 1 with both discretization error and score estimation/Monte Carlo simulation error. It also provides two numerical experiments: 1) Gaussian-LASSO mixture; and 2) uniform sampling over non-convex sets. Numerical results in Section 5.1 demonstrate the advantages of the proposed method: it allows the use of a larger stepsize $h$ compared with proximal sampling based on rejection sampling, leading to faster convergence."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Unlike the proximal sampling based on rejection sampling, this paper approximately implements RGO via simulation backward SDE and score function using a particle system (i.e., Monte Carlo simulation). The advantage (as reflected in the experiments) is that the stepsize $h$ of the proximal sampling could be taken large (as long as $T={\\cal O}(h)$). In particular, $h$ does not depend on dimension $d$ and properties of $f$ such as smoothness $L$. Moreover, the method does not require the first-order oracle of $f$, such as a subgradient; instead, it only assumes the zeroth-order oracle."}, "weaknesses": {"value": "A major shortcoming is that the technical challenge addressed by the work is not very clear. Simulating SDEs with particle systems is a well-studied idea that has appeared frequently in the literature, so the methodological novelty seems limited, in view of the comparison with related works in Section 6. Moreover, the technical depth of the analysis is uncertain, as many of the proof techniques appear to be adapted from existing works, such as Vempala and Wibisono (2019).\n\nAnother notable shortcoming lies in the experiment in Section 5.2. In-and-Out finds T1 but fails to reach T2. It is claimed that the proposed method successfully explores both T1 and T2; however, based on Figure 4, it is difficult to conclude that the proposed method clearly identifies either region. The yellow points appear scattered all over, so there is no specific pattern that can be observed. The uniform sampling results are not convincing.\n\nFinally, the comparison only with RGO in Section 5.1 might be limited."}, "questions": {"value": "1. The key idea behind the approximation (9) is importance sampling. It would be nice if this insight could be made explicit in the paper.\n\n2. Typo: line 710, a \"$y$\" is missing in the Gaussian.\n\n3. Line 130, Fisher information should be relative Fisher information.\n\n4. Some related papers might be missing:\nMixing Time of the Proximal Sampler in Relative Fisher Information via Strong Data Processing Inequality, Andre Wibisono\nProximal Oracles for Optimization and Sampling, Jiaming Liang and Yongxin Chen\nOracle-based Uniform Sampling from Convex Bodies, Thanh Dang and Jiaming Liang\n\n5. Similar to (Kook, Vempala, and Zhang, 2024), the last paper above by Dang and Liang studies proximal sampling for uniform sampling on convex bodies. It presents two implementations of RGO using projection and separation oracles. It would be interesting to compare with this paper as well in Section 5.2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Yl5nz1d0fm", "forum": "NjjRuJuMTd", "replyto": "NjjRuJuMTd", "signatures": ["ICLR.cc/2026/Conference/Submission17715/Reviewer_bjDQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17715/Reviewer_bjDQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977998419, "cdate": 1761977998419, "tmdate": 1762927548568, "mdate": 1762927548568, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}