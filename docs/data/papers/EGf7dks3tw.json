{"id": "EGf7dks3tw", "number": 1105, "cdate": 1756841120352, "mdate": 1763683880580, "content": {"title": "Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics", "abstract": "Large language models  (LLMs) struggle with cross-lingual knowledge transfer: they hallucinate when asked in one language about facts expressed in a different language during training.\nThis work introduces a controlled setting to study the causes and training dynamics of this phenomenon by training small Transformer models from scratch on synthetic multilingual datasets.\nWe identify a learning phase wherein a model develops either separate or unified representations of the same facts across languages, and show that unification is essential for cross-lingual transfer.\nWe also show that the degree of unification depends on how strongly a fact is associated with a particular language, and on how easy it is to identify the language.  \nBased on these insights, we develop methods to modulate the level of cross-lingual transfer by manipulating data distribution and tokenization, and we introduce metrics and visualizations to characterize their effects on unification.\nFinally, we show that our measures of representational unification correlate with cross-lingual factual accuracy in LLMs, such as Gemma.\nOur work shows how controlled settings can shed light on pre-training dynamics and suggests new directions for improving cross-lingual transfer in LLMs.", "tldr": "", "keywords": ["multilinguality", "factual recall", "training dynamics"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cba75a5cf4c9b1a32ed84ddc3d7d415dd27d6ed3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies why LLMs hallucinate facts when queried across languages, using a synthetic “Petri dish” to train small Transformers from scratch. It finds that models either unify or separate representations of the same fact across languages during an early training phase, and this unification—predicted by a simple similarity-based score—determines cross-lingual generalization. \nCrucially, separation is driven by how informative and easily extractable the language identity is; \nmanipulating monolingual data (balancing attributes, obfuscating language cues) improves transfer without more parallel data. The score also predicts accuracy in Gemma-2B, offering a practical tool for model selection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.I think the motivation of this paper is solid: why models hallucinate facts in cross-lingual settings, even when they know the fact in another language. This is especially relevant for low-resource languages.\n2. The paper is well-written and easy to understand, the experimental design is logically presented, and the figures effectively illustrate key concepts like the unification score and checker-boarding."}, "weaknesses": {"value": "1. I think the baseline is a little weak, only on Gemma-2-2B models, which is not a strong LLM, and without enough justification.\nAdding experiments on stronger LLMs such as Qwen, llama, could be justify the performance.\n2. While the paper shows that parallel data helps, it does not disentangle whether this is due to increased exposure to facts or reduced language informativeness. A more fine-grained ablation (e.g., parallel data with balanced vs. imbalanced attributes) would clarify this.\n3.The paper does not compare its findings to existing multilingual alignment methods (e.g., shared subword vocabularies, alignment losses, code-switching). I would like to see the comparison and analysis against these methods."}, "questions": {"value": "see weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OMaGyMwXov", "forum": "EGf7dks3tw", "replyto": "EGf7dks3tw", "signatures": ["ICLR.cc/2026/Conference/Submission1105/Reviewer_w4K3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1105/Reviewer_w4K3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1105/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929789498, "cdate": 1761929789498, "tmdate": 1762915679331, "mdate": 1762915679331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a very interesting study into generalisation in LLMs based on internal representations. Specifically, the authors focus on cross-lingual representations and cross-lingual generalisation. Their study focusses on how specific dataset statistics impact that generalisation. They develop a method of predicting this generalisation based on their developed \"unification\" score."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Interesting and detailed analysis into pre-training mixtures and effect on generalisation (specifically in the context of cross-language generalisation)\n2. Development of an automatic metric that correlates strongly with task generalisation (\"Unification Metric\")\n3. Development of a synthetic language for such analysis."}, "weaknesses": {"value": "1. Section 3 is quite hard to follow and the plots are very small and hard to make proper use of. (although the general picture of checkboard vs. not checkerboard gets conveyed.\n2. Section 6 is very biased to a single model \"Gemma\" (that is perhaps from the authors themselves [btw, we are not from a \"competing\" lab, rather this is a scientific assessment]). Secondly, Section 6 is impossible to reproduce from the very short description - limiting it's meaningfulness for the paper as well as a scientific contribution. Section 6 however, is an important contribution to the argument of the paper (as without it synthetic languages form a major limitation).\n3. The \"Unifcation\" metric is probably not sufficiently described to properly reproduce the results.\n4. Overall - reproducibility of the paper is limited and it would be hard to verify the results (or their impact).\n5. The (presented) results in Section 6 (even though vague) are much lower than on the synthetic data (65% correlation)"}, "questions": {"value": "1. Could you describe the Unification metric in more detail. How exactly do you calculate it.\n2. Could you describe the KG + Method / Code for producing the synthetic datasets in more detail. Specifically, can you share statistics of your KG and the resulting datasets.\n3. Could you expand upon section 6. What are the exact training datasets (+ statistics)? How exactly do you evaluate the model \"with LLM judge\"? (A follow on would be, how accurate is the method?). etc.\n4. Why have you not tried other models (incl. those that are fully open source OLMO, Merlin, GPT-like architectures)."}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "Not a big concern, however, the authors clearly present work about Gemma and analysis of Gemma only. Indicating a strong bias towards the LAB's own work and sharing it openly."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dciKTR6Hx5", "forum": "EGf7dks3tw", "replyto": "EGf7dks3tw", "signatures": ["ICLR.cc/2026/Conference/Submission1105/Reviewer_XjnT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1105/Reviewer_XjnT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1105/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762090295878, "cdate": 1762090295878, "tmdate": 1762915679133, "mdate": 1762915679133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the generalization of knowledge across languages. The authors suggest a Petri dish setup, where synthetic knowledge graphs are used to sample bilingual datasets, to control shared information across languages, and then train a tiny transformer to observe the generalization across languages from multiple checkpoints during training. To facilitate the observation, the authors consider Unification Score, a metric to evaluate the difference between representations in two languages. Finally, the authors leverage Unification Score to examine Gemma-2B on the ECLeKTic dataset (Goldman et al., 2025), attempting to verify all findings for a  real LLM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Understanding and interpreting the emergence of cross-lingual generalization is an interesting question as it helps understand how to effectively train an LLM to support multiple languages, esp. low-resource languages."}, "weaknesses": {"value": "1. The presentation of this paper is not very good, making this paper vague, unclear, and verbose. For example, in line 258, the authors state “Concretely, the unification score captures the similarity between semantically equivalent cross-lingual datapoints against a baseline of similarity between semantically distinct same-language datapoints.” , but in the following equation, they define “sim(x, y) against sim (x, x)”. Also, I believe including statistics of the synthetic datasets and more experimental setups (e.g., training steps, batch size, and learning curves) could strengthen the paper.\n\n2. The main finding of this paper is that explosibility or frequency of appearance is the key cross-lingual transfer. However, there is a body of studies focusing on this idea. For example, [1] set up a similar experiment by controlling parallel datasets.\n\n3. The last part, 6 LARGE LM EXPERIMENTS, is not convincing and seems disconnected from other findings. There is an important confounding factor that the frequency of appearance is not the same across languages. For example, a word X appears in English 10k times, but 1 time in other languages, thus it will increase the Jaccard similarity but not improve cross-lingual transfer or predict the cross-lingual transfer, according to other experiments in this paper.\n\n[1] Cross-Lingual Transfer of Cultural Knowledge, ACL 2025"}, "questions": {"value": "Refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Hc4JwQsy8c", "forum": "EGf7dks3tw", "replyto": "EGf7dks3tw", "signatures": ["ICLR.cc/2026/Conference/Submission1105/Reviewer_41AX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1105/Reviewer_41AX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1105/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762196495544, "cdate": 1762196495544, "tmdate": 1762915678958, "mdate": 1762915678958, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Thank you to all reviewers!"}, "comment": {"value": "We appreciate the interest in the details around the unification score, knowledge graph generation and data. To this end, we’ve provided pseudocode for these in the appendix (A.1, A.2, A.3, A.16, A.17).\n\nRegarding how the findings relate to large LMs, we updated the last two sections to clearly articulate the link from the tiny-scale experiments to LLMs and added results for three more open models (Llama-3.2-3B-Instruct, Qwen3-4B-Instruct, and Mistral-7B-Instruct-v0.3, in addition to Gemma 2 and Gemma 3 that we had). Experimental results on larger LMs (both ours and from prior work) are provided to confirm that our findings are not specific to our petri dish environment. Rather, they provide an explanation for why shared script and vocabulary overlap correlate with cross-lingual performance, and why techniques like embedding alignment promote cross-lingual generalization. Namely, the representational footprint of the language feature depends on its extractability early in training, and a larger footprint causes the separation of semantically equivalent factual statements."}}, "id": "xEdr73wZCY", "forum": "EGf7dks3tw", "replyto": "EGf7dks3tw", "signatures": ["ICLR.cc/2026/Conference/Submission1105/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1105/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission1105/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763684275105, "cdate": 1763684275105, "tmdate": 1763685470997, "mdate": 1763685470997, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}