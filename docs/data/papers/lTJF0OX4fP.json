{"id": "lTJF0OX4fP", "number": 8350, "cdate": 1758079603937, "mdate": 1762941683215, "content": {"title": "Rectified Attribute-Missing Graph Clustering", "abstract": "Deep Graph Clustering(DGC) has gained widespread attention in some tasks like face recognition and social network analysis because of its powerful capability of capturing the latent distribution of multi-view graph-structured data and grouping nodes in the graph into different clusters. However, in the real world, they often face the situation where attributes of some nodes are missing, resulting in clustering performance degradation. Although many methods have been developed to mitigate the problem, most of them are two-stage methods that separate embedding learning from clustering, and may cause deviation of node embedding because of the missing nodes.\nTo address this problem, we propose a novel end-to-end attribute-missing graph clustering learning method termed $\\underline{R}$ectified  $\\underline{A}$ttribute-$\\underline{M}$issing $\\underline{G}$raph $\\underline{C}$lustering (R-AMGC). First, it performs two augmentations to generate two attribute views, and the missing attributes are set to be learnable in one of the views. Subsequently, we maximize the mutual information between two encoded views via contrastive learning and then effectively mitigate the embedding distortion. Additionally, to learn clustering-friendly embedding, we design a module termed triple constraint, which not only maintains the alignment between graph structure and cluster assignment but also captures structural and attribute information. Extensive experiments on four graph datasets have strongly validated the effectiveness and superiority of R-AMGC compared to other counterparts.", "tldr": "a novel end-to-end unified framework conclusively for attribute-missing graph clustering", "keywords": ["Attribute-Missing Graphs", "Deep Graph Clustering", "Unsupervised Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/27cb1b4c34cafc318e7d75319690f8b26e2dba69.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces R-AMGC, an end-to-end graph clustering framework tailored to handle missing node attributes. The approach builds on two key components: (1) a rectification module using multi-head attention to reduce embedding distortion from missing nodes, and (2) a triple constraint loss that enforces consistency across graph structure, attribute reconstruction, and clustering assignments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Clear problem motivation: The work correctly identifies a practical challenge and positions itself as an end-to-end solution rather than a two-stage approach\n\n* Modular design: The pipeline is structurally neat and conceptually easy to follow, which could make it extensible.\n\n* Comprehensive evaluation setup: Experiments include multiple missing rates and datasets, with ablation studies on key components, giving some evidence of contribution isolation\n\n* Readable methodology: Compared to some GNN clustering works, the mathematical formulation is laid out systematically, making the implementation conceptually accessible."}, "weaknesses": {"value": "* Lack of conceptual novelty: Nearly every element of the method is a direct reuse of standard techniques (contrastive learning, heat kernel diffusion, GCN encoder, multi-head attention, reconstruction losses, and modularity-based clustering). The rectification module is essentially attention-weighted message passing with a fixed decay factor, and the triple constraint is just a weighted sum of existing loss functions. There’s no fundamentally new algorithmic insight here.\n\n* Shallow technical depth: The rectification mechanism is described as if novel, but it's essentially GAT with a fixed $\\lambda$ decay on masked nodes, which is neither theoretically analyzed nor empirically compared to simpler baselines (e.g., weighted neighbor aggregation or masking strategies).\n\n* No theoretical or empirical justification for design choices.\n\n* The core idea is essentially a combination of existing standard components, with minimal novelty and no rigorous justification. The empirical results, while not bad, do not show compelling or robust gains."}, "questions": {"value": "Please see the above weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pP7ahzxrnO", "forum": "lTJF0OX4fP", "replyto": "lTJF0OX4fP", "signatures": ["ICLR.cc/2026/Conference/Submission8350/Reviewer_jAB7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8350/Reviewer_jAB7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760681468009, "cdate": 1760681468009, "tmdate": 1762920267759, "mdate": 1762920267759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "W1HpArrjk4", "forum": "lTJF0OX4fP", "replyto": "lTJF0OX4fP", "signatures": ["ICLR.cc/2026/Conference/Submission8350/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8350/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762940459777, "cdate": 1762940459777, "tmdate": 1762940459777, "mdate": 1762940459777, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Rectified Attribute-Missing Graph Clustering (AMGC) method. The authors design a rectification mechanism inspired by the multi-head attention mechanism to address embedding distortion caused by missing node attributes. The rectified embeddings are then decoded to reconstruct structural and attribute information. Additionally, a clustering consistency loss is employed to ensure alignment between the graph structure and clustering results, forming an end-to-end learning framework. Extensive experiments under different missing ratios are conducted to validate the model’s performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper evaluates model performance under different levels of missing attributes, providing empirical evidence for the proposed approach.\n\n2. The manuscript is clearly structured and offers a detailed overview of prior work on attribute-missing graph learning."}, "weaknesses": {"value": "1. The paper lacks clear innovation. The rectified structure and several loss functions are largely derived from existing studies, making the proposed method appear as a straightforward extension to the missing-attribute scenario.\n\n2. The experimental setup is relatively low-end. A higher-capacity environment (e.g., with 24 GB GPU memory) should have been adopted to ensure smooth operation of the AMGC and baseline algorithms.\n\n3. All datasets used in the experiments are small-scale. It remains unclear whether the proposed method can be effectively applied to large-scale datasets (e.g., those with more than 10,000 samples).\n\n4. The paper contains numerous minor errors—for instance, the first word after Equation (17) should be lowercase, and some spaces are missing.\n\n5. In Equation (21), all loss terms appear to have the same scale. The authors should explain why no balancing coefficients were introduced to control their relative magnitudes."}, "questions": {"value": "Please see the Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "NV5v1zn2Ov", "forum": "lTJF0OX4fP", "replyto": "lTJF0OX4fP", "signatures": ["ICLR.cc/2026/Conference/Submission8350/Reviewer_EB6s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8350/Reviewer_EB6s"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725822863, "cdate": 1761725822863, "tmdate": 1762920267399, "mdate": 1762920267399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Rectified Attribute-Missing Graph Clustering (R-AMGC), an end-to-end framework for deep graph clustering under attribute-missing scenarios. The method introduces learnable imputation for missing attributes, an embedding rectification module based on multi-head attention to mitigate representation distortion, and a triple constraint loss to jointly reconstruct structure, attributes, and clustering consistency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The model provides a unified end-to-end solution integrating imputation, embedding learning, and clustering optimization.\n\n- The introduction of an embedding rectification mechanism addresses the bias caused by missing node attributes.\n\n- Experimental evaluations include multiple datasets, ablation studies, and visualization analysis."}, "weaknesses": {"value": "- There is no clear explanation of how the model avoids overfitting or ensures the accuracy of the imputed attributes.\n﻿\n- The rectification matrix P and the attention-based correction process lack quantitative validation; the reliability of the “corrected” embeddings remains unclear.\n﻿\n- The computational complexity is not analyzed; both multi-head attention and multiple reconstruction losses could significantly increase training cost for large-scale graphs.\n﻿\n- The scalability of R-AMGC to large datasets is not demonstrated or discussed.\n﻿\n- Although the triple constraint module combines reconstruction and clustering consistency, its optimization stability and convergence properties are not theoretically analyzed.\n﻿\n- The comparison baselines do not include the most recent 2025 graph imputation and clustering methods, which may weaken the claim of superiority."}, "questions": {"value": "- How does the proposed learnable imputation ensure that the filled attributes accurately approximate the true values rather than introducing noise?\n﻿\n- What mechanisms are employed to verify or guarantee the correctness of the rectified P matrix during training?\n﻿\n- How does the proposed method perform on large-scale datasets, and what is the expected computational and memory complexity with increasing graph size?\n﻿\n- What is the asymptotic time and space complexity of the embedding rectification module and triple constraint optimization, especially in relation to node and edge counts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "CE3GUazHaE", "forum": "lTJF0OX4fP", "replyto": "lTJF0OX4fP", "signatures": ["ICLR.cc/2026/Conference/Submission8350/Reviewer_4D4q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8350/Reviewer_4D4q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839467247, "cdate": 1761839467247, "tmdate": 1762920267034, "mdate": 1762920267034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes R-AMGC, an end-to-end framework for attribute-missing graph clustering. The approach introduces two augmented attribute views, including one with learnable missing attributes, and employs a multi-head attention-based embedding rectification module to alleviate embedding distortion caused by missing attributes. A triple-constraint loss jointly optimizes structure reconstruction, attribute reconstruction, and clustering consistency. Experiments on four benchmark graph datasets demonstrate that R-AMGC achieves superior performance compared to several state-of-the-art baselines, particularly under high missing rates."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed embedding rectification module based on multi-head attention effectively mitigates embedding distortion arising from missing attributes.\n2. The framework integrates imputation and clustering in a unified manner, reducing potential error propagation associated with multi-stage methods.\n3. Experiments demonstrate that the proposed approach is robust to high levels of missing attributes."}, "weaknesses": {"value": "1. The paper claims that existing methods perform poorly under high missing rates, but this statement is not sufficiently substantiated. \n2. The rationale behind the two specific attribute augmentation strategies is not clearly justified. Including theoretical insights or empirical ablations would enhance the methodological soundness.\n3. In Section 3.4.1, the model performs structure reconstruction even though the graph structure is assumed complete. The motivation for this design choice should be clarified.\n4. The total loss function in Eq. (21) is defined as a simple sum of four components. Discussion on the relative weighting or adaptive balancing of these terms would help assess the robustness and sensitivity of the optimization.\n5. Some baseline methods used for comparison, particularly those designed for attribute-complete settings, appear outdated. Incorporating more recent graph clustering models would improve the fairness and credibility of the evaluation.\n6. In Table 1, R-AMGC underperforms on certain datasets (e.g., CITESEER with 0.3 missing rate). The paper should provide an analysis or discussion of these cases to better understand the model’s limitations."}, "questions": {"value": "1. How do existing methods specifically fail under high missing rates? Providing more analyses would strengthen the argument.\n2. What is the theoretical or empirical motivation for selecting the two particular attribute augmentation strategies for generating the two views?\n3. Given that the graph structure is assumed to be complete, what is the purpose of performing structure reconstruction in Section 3.4.1?\n4. Have you considered adopting a weighted or adaptive loss balancing scheme for Eq. (21)? How sensitive is model performance to the choice of these weights?\n5. Some attribute-complete baselines seem outdated. Have you considered comparing with more recent methods to better demonstrate the advancement of R-AMGC? \n6. For the datasets where R-AMGC performs worse than baselines (e.g., CITESEER with 0.3 missing rate), what are the potential causes? Is there any identifiable pattern in dataset characteristics or missing attribute distributions that may explain this behavior?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rDjh1NXCC1", "forum": "lTJF0OX4fP", "replyto": "lTJF0OX4fP", "signatures": ["ICLR.cc/2026/Conference/Submission8350/Reviewer_A3nz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8350/Reviewer_A3nz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879532495, "cdate": 1761879532495, "tmdate": 1762920266551, "mdate": 1762920266551, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes R-AMGC, an end-to-end framework for attribute-missing graph clustering. It estimates missing node attributes, learns representations with contrastive learning, and rectifies embeddings to reduce the impact of missing features before clustering. Experiments on several benchmark datasets show improved performance over existing AMGC methods, especially under high missing rates."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. This paper addresses the attribute-missing graph clustering setting in a unified end-to-end manner.\n\nS2. The idea of rectifying unreliable embeddings for missing-attribute nodes is clear and improves robustness.\n\nS3. Experimental results show performance gains under higher missing-rate scenarios."}, "weaknesses": {"value": "W1. The novelty is somewhat limited; the method mainly combines known components (imputation, contrastive learning, GAE-style clustering).\n\nW2. Baseline comparison is incomplete and omits stronger recent GCL/AMGC methods, weakening SOTA claims.\n\nW3. The design appears over-engineered with multiple losses and modules, without clear evidence that each part is necessary.\n\nW4. Limited evaluation scope - no large-scale or various graph types; scalability and generality remain unclear."}, "questions": {"value": "Q1. What is the main technical novelty beyond combining existing imputation, contrastive, and GAE-based clustering techniques?\n\nQ2. Can you include evaluations against stronger recent GCL/AMGC baselines to more reliably support the SOTA claim? Is it possible or not?\n\nQ3. Can you provide ablations isolating each module and loss to confirm which components are actually necessary?\n\nQ4. How does the proposed method perform on larger graphs and different graph types (e.g., heterophilic) to validate scalability and generality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7rtE16vdVt", "forum": "lTJF0OX4fP", "replyto": "lTJF0OX4fP", "signatures": ["ICLR.cc/2026/Conference/Submission8350/Reviewer_DZ5T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8350/Reviewer_DZ5T"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762152607462, "cdate": 1762152607462, "tmdate": 1762920266093, "mdate": 1762920266093, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}