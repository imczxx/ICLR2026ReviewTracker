{"id": "gorR3RUgwy", "number": 12613, "cdate": 1758208982803, "mdate": 1759897498631, "content": {"title": "When Glass Disappears at Night: A Novel NIR-RGB Multi-modal Solution", "abstract": "Glass surface detection (GSD) has recently been attracting research interests. However, existing GSD methods focus on modeling glass surface properties for daytime scenes, and can easily fail in nighttime scenes due to significant lighting discrepancies. We observe that, due to the spectral differences between Near-Infrared (NIR) light sources and common LED lights, NIR and RGB cameras capture complementary visual patterns (e.g., light reflections, shadows, and edges) of glass surfaces, and cross-comparing their lighting and reflectance information can provide reliable cues for GSD at nighttime. Inspired by this observation, we propose a novel approach for nighttime GSD based on the multi-modal NIR and RGB image pairs. We first construct a nighttime GSD dataset, which contains 6,192 RGB-NIR image pairs captured in diverse real-world nighttime scenes, with corresponding carefully-annotated glass surface masks. We then propose a novel network for the nighttime GSD task with two novel modules: (1) a RGB-NIR Guidance Enhancement (RNGE) module for extracting and enriching the NIR reflectance features with the guidance of RGB reflectance features, and (2) a RGB-NIR Fusion and Localization (RNFL) module for fusing RGB and NIR reflectance features into glass features conditioned on the multi-modal illumination discrepancy-aware features. Extensive experiments demonstrate that our method outperforms state-of-the-art methods in nighttime scenes while generalizing well to daytime scenes. We will release our dataset and codes.", "tldr": "We propose a novel approach for nighttime GSD based on the multi-modal NIR and RGB image pairs, and first construct a nighttime GSD dataset, which contains 6192 RGB-NIR image pairs captured in diverse real-world nighttime scenes.", "keywords": ["Glass surface detection", "multi-modal image", "deep learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b3fc08544238fa35d81df060b228f4b2e926bf91.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This submission introduces a method for glass detection at night by proposing an approach for nighttime glass surface detection."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The author claims that this is the first method for the related topics. \n2. This work also contributes a dataset."}, "weaknesses": {"value": "1. I remain unconvinced by the rationale for employing NIR images. Is the underlying reason that the task is entirely unsolvable using the RGB modality alone? If this is the case, the authors should conduct and present more comprehensive experiments to clearly illustrate the shortcomings of existing RGB-based methods.\n\n2. If the additional modality is necessary, why can the authors only consider NIR? Is it possible to use another modality?\n\n3. Though the NIR camera can provide some helpful information at night, it also has obvious limitations. For example, the distance of the NIR may limit its usage. Besides, NIR light can sometimes lead to a see-through effect, which may violate privacy. \n\n4. For such a fusion task, it is challenging to develop a framework with novelty. From an architectural perspective, the proposed approach shares a very similar framework to previous approaches. It presents only some standard feature fusion modules. It is better to rephrase the contribution at this point."}, "questions": {"value": "See me concerns in the weakness."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "details_of_ethics_concerns": {"value": "I often feel that NIR-related work may raise some privacy concerns. Although it may not be severe, it is still necessary to undergo some ethics reviews."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "q8ZUos2NDW", "forum": "gorR3RUgwy", "replyto": "gorR3RUgwy", "signatures": ["ICLR.cc/2026/Conference/Submission12613/Reviewer_ysrH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12613/Reviewer_ysrH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12613/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883913939, "cdate": 1761883913939, "tmdate": 1762923459758, "mdate": 1762923459758, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a night-time glass surfaces detection method. The reflectance and illumination components of RGB and NIR images are first decomposed, respectively. Then the semantics-aware features from the RGB reflectance are extracted to enhance the material-aware features from the NIR reflectance. The multi-modal features of the lighting and material information are fused together to detect glass areas. The authors also constructed a night-time glass surface detection dataset containing 6,192 RGB-NIR image pairs with the corresponding manually annotated glass surface masks. Comparative experimental results showed that the proposed method outperformed the existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper introduced a relatively new problem of night-time glass surface detection, and showed the proposed method yields better performance than the compared existing methods.\n\nA new dataset of night-time glass surface detection was constructed, which is welcomed in the research community."}, "weaknesses": {"value": "1) The proposed night-time glass surface detection problem is basically a combined problem of low-light image enhancement and glass surface detection. Specifically, the proposed Retinex decomposition module decomposes input low-light image into reflectance and illumination components, which is similar to the behavior of low-light image enhancement. Table 2 seems to provide the related experimental results, however it is not easy to figure out the benefit of the proposed method in this experimental setting, since the performance of low-light enhancement was not guaranteed. It is recommended to visualize the input low-light enhanced images as well.\n \n2) The architectures and their explanations in Sec. 4 are easy to follow, and therefore the related equations such as (1), (2),(3) are not required. Furthermore, instead of naïve explanation about the procedures of architecture, more evidences and discussions are recommended to be provided to support that the proposed architecture exploits complementary features between RGB and NIR effectively. In this context, proper visualization of the complementary features between RGB and NIR images are also recommended. \n\nAlso, the explained behavior of the proposed architecture in Figure 4 can be confirmed by visualizing intermediate features such as X^i_d and X^i_f. \nM_d in Figure 5 does not properly highlight the glass area. \nIt is also recommended to discuss the results of intermediate feature maps in Figure 5."}, "questions": {"value": "My main concerns are given in the Weaknesses section.\n\nIn addition, some minor questions are as follows:\n\n- Why are the distributions of the glass area ratio different between training dataset and testing dataset, even though the two datasets are randomly split? \n\n- Are the existing datasets of GDD and GSD in Table 7 also multimodal datasets including NIR images? \n\n- The GT in the 3rd row in Figure 12 seems to fail to capture the opened window, while NRGlass successfully captured.\n\n- In A. 10, instead of naïve reporting the failure cases, discussion why the proposed method fails on the images is recommended."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yzEmkBqXjR", "forum": "gorR3RUgwy", "replyto": "gorR3RUgwy", "signatures": ["ICLR.cc/2026/Conference/Submission12613/Reviewer_7XQx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12613/Reviewer_7XQx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12613/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917232690, "cdate": 1761917232690, "tmdate": 1762923458155, "mdate": 1762923458155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the challenge of nighttime glass surface detection (GSD) by leveraging the complementary sensing of RGB and active Near-Infrared (NIR) imaging. The authors build the first large-scale nighttime RGB–NIR dataset with 6,192 paired images and high-quality annotations. They propose a Retinex-based dual-branch network with two key modules: RNGE, which uses RGB semantic features to enhance NIR material and boundary cues, and RNFL, which fuses RGB–NIR features via illumination-aware cross-modal attention. The method outperforms state-of-the-art approaches on nighttime scenes"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The work focuses on the “nighttime” domain, an underexplored yet highly practical setting ,where RGB-only cues fail under low or complex artificial illumination. The use of active NIR sensing as a complementary modality is both well-motivated and technically novel.\n\n- The paper presents the first large-scale RGB–NIR glass surface dataset for nighttime scenes. It includes realistic environments and detailed annotations, offering a valuable benchmark for future research."}, "weaknesses": {"value": "- This paper lacks a comprehensive analysis of the diversity of the dataset, such as curved or irregular glass surfaces, extreme lighting variations, or outdoor conditions. \n\n- The study primarily compares against glass-specific models. It would be more convincing to include general cross-modal or RGB–NIR segmentation/detection baselines. \n\n- Retinex pre-processing introduces computational overhead and potential instability under noisy nighttime conditions. It would be valuable to explore lighter or integrated alternatives, such as explicitly modeling reflectance/illumination branches within the backbone itself, to reduce latency."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l8FWewpwhS", "forum": "gorR3RUgwy", "replyto": "gorR3RUgwy", "signatures": ["ICLR.cc/2026/Conference/Submission12613/Reviewer_NYLP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12613/Reviewer_NYLP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12613/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992404781, "cdate": 1761992404781, "tmdate": 1762923457161, "mdate": 1762923457161, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes method and multi-modal NIR-RGB paired dataset to do night-time glass surface detection. \nThe authors test inversigate different backbones (including swinV2 and ResNet). The results look close to the ground truth from the paper."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed NIR-RGB paired dataset could be useful for the community. \n2. The authors conduct ablation studies on their pipeline."}, "weaknesses": {"value": "1. Lack of comparison with any state-of-the-art zero-shot segementation models e.g., SAM 2.\n2. Images in the paper seems to be in a very narrow distribution, therefore, the results are less convincing, and could indicate a potential overlap. \n3. The retinex for illumination decompositon sounds very arbitry, retinex based decomposition could contain with many leakages, and a better intrinsic decomposition method could be used."}, "questions": {"value": "1. Are there any comparisons with segementation models like SAM 2?\n2. Are there any out-of-distribution results? I am curiours if the model has a generalizable capacity in the real world images. \n3. Besides the glass detection, are there any other applications that can employ this method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "maqmNVCykl", "forum": "gorR3RUgwy", "replyto": "gorR3RUgwy", "signatures": ["ICLR.cc/2026/Conference/Submission12613/Reviewer_P9xm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12613/Reviewer_P9xm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12613/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762034257676, "cdate": 1762034257676, "tmdate": 1762923456807, "mdate": 1762923456807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}