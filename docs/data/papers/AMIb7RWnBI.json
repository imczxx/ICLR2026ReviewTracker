{"id": "AMIb7RWnBI", "number": 13176, "cdate": 1758214666483, "mdate": 1759897458779, "content": {"title": "AGENTCON: PRACTICAL ATTACKS ON GENERALIST WEB AGENTS VIA IMPERCEPTIBLE MANIPULATION", "abstract": "Recent progress in generalist web agents built on large multimodal models has enabled automation of complex web tasks but also created new security risks. We identify a new attack vector against web agents that does not require manipulating HTML elements, unlike prior work. Our threat model focuses on marketplace websites, a primary target of generalist web agents, where users and sellers can upload images themselves. We propose AGENTCON, a practical attack that crafts adversarial perturbations on listing images, rather than perturbing the entire input as in traditional adversarial attacks, to induce the intended target action by web agents. AGENTCON incorporates real-world constraints from webpage rendering into the optimization so that the attack remains effective when neighboring listings and the attack image’s position vary. Our evaluation on 1,680 tasks against a state-of-the-art web agent framework demonstrates the effectiveness of AGENTCON, with an attack success rate (ASR) of 80.4% on average across four application scenarios and three agent models. AGENTCON is also resilient to common countermeasures, achieving an ASR of 76% on average.", "tldr": "", "keywords": ["Privacy", "Safety", "VLM web agents", "Adversarial examples", "Web agents", "Vision-Language Model"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a7b8365a80d58906740ac477248926c6c6a43640.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an attack strategy to manipulate web agents. The evaluation with three models demonstrates the effectiveness of the approach and validates the design of the algorithm with different ablation studies."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper focuses on an interesting and important attack scenario where malicious sellers at a marketplace website can exploit the system by uploading intentionally perturbed images for personal gain."}, "weaknesses": {"value": "1. The writing can be significantly improved.\n     - In the first sentence of the first paragraph, the first citation does not show up correctly.\n     - The first sentence says ‘recent advances in web agents’, while the citations, including ROPE positional embeddings, QWen2 model, are not that relevant to the ‘recent advances in web agents’. \n     - In the first two paragraphs, the better logic can be: ‘Prior studies **have** demonstrated xx’. ‘**However**, existing attacks xxx’. Current writing lacks these essential transitional words and phrases\n     - The choice of words can be largely refined. For instance, ‘the **advantage** of our design’ in line 328.\n     - Try to avoid unnecessary mathematical elaboration unless it adds clarity.  For example, there is no need to expand the $q$ and $p$ into $(q1,q2,q3)$ ,$(p1,p2,p3)$, as these components are never referenced later.\n\n\n2. The core idea of uploading perturbed images to manipulate web agents is not new. Similar attack settings have already been explored in “Dissecting Adversarial Robustness of Multimodal LM Agents” (ICLR 2025), where the authors studied a highly similar threat model. However, this prior work is neither cited nor discussed in the current manuscript. To strengthen the positioning and clarity of the contribution, the authors are encouraged to discuss this work and incorporate their approach as an important baseline.\n\n\n3. It’s important to evaluate if the attack can be transferred to black-box models, such as Operator and Claude Computer use, which are more likely to be deployed as web agents in real life.\n\n\n4. How would different screen resolutions affect the performance? Since users may access websites through various devices and thus encounter different resolutions, it would be valuable to examine whether the optimized image can generalize across such settings. Furthermore, it would be interesting to evaluate whether the optimized image remains effective across different platforms—for example, various marketplace websites—as this would demonstrate stronger robustness and highlight more significant security risks. In addition, it would be helpful to report the extra computational cost (if any) of generating the optimized image compared with the PGD baseline.\n\n\n5. The threat model is that the attacker cannot manipulate the webpage. If so, how can the attacker get instances with varying positions and varying campaigns during the optimization as described in lines 302- 310?\n\n\n6. Since the work targets the agent setting, the paper would be substantially strengthened by evaluating the attack in the end2end, interactive sandbox rather than in a static single-step setting. Existing sandbox frameworks such as WebArena, OSWorld, RedTeamCUA, or WASP could be useful to test the method under realistic agent settings."}, "questions": {"value": "See the Weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nGgPo9sQxe", "forum": "AMIb7RWnBI", "replyto": "AMIb7RWnBI", "signatures": ["ICLR.cc/2026/Conference/Submission13176/Reviewer_D5Sj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13176/Reviewer_D5Sj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760480162387, "cdate": 1760480162387, "tmdate": 1762923878459, "mdate": 1762923878459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces AGENTCON, a white-box adversarial attack on multimodal web agents that manipulates uploaded listing images instead of HTML elements. The threat model focuses on plausible real-world marketplaces (like Amazon or Airbnb) where attackers can only control image uploads. AGENTCON crafts imperceptible perturbations on adversary-controlled images so that web agents (e.g., SEEACT powered by LLaVA, MiniCPM, or Phi-3 vision) take malicious target actions. Unlike standard PGD attacks, AGENTCON explicitly accounts for confounding real-world factors: variation in neighboring listings, unpredictable image positions on the screen, and JPEG/blur transformations. Through simulation across 1,680 tasks over 13 marketplaces, AGENTCON achieves ~80% average attack success rate while remaining visually imperceptible, outperforming baseline PGD (26%)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper provides a well-defined practical threat model, focusing on a realistic and underexplored surface where adversaries can upload images but cannot alter webpage HTML.\n\n- Methodology is detailed and reproducible, with formal definitions for “human perception stability” and “exploitability” of agents, a differentiable approximation of preprocessing pipelines, and clarity about constraints (companion variation, positional shift).\n\n- Strong experimental results: thorough evaluation spanning different vision backbones, perturbation magnitudes, and mitigation scenarios; robustness to compression and blur; decent analysis of generalization across varied user prompts."}, "weaknesses": {"value": "- The novelty is limited. The conceptual foundation of perturbation-based attacks on web agents is already established by work such as “Dissecting Adversarial Robustness of Multimodal LM Agents” (Wu et al., 2024), which also examines screenshot-based perturbations and quantifies adversarial information flow through agent components, and the authors don’t cite the work. AGENTCON’s adjustment to real-world layouts (varying neighbor content and positional shifts) seems like a practical refinement rather than a substantive conceptual advance.\n\n- The claim that confounding factors like “relative positions or compression artifacts” represent a new attack surface feels overstated as these are predictable effects when applying adversarial examples to rendered screenshots.\n\n- Overall contribution beyond adapting standard white-box perturbations to a slightly more constrained environment is minor."}, "questions": {"value": "- How exactly is PGD adapted for the web-agent setting as in does it attack the full screenshot, or just the attacker-controlled image region? Without clarity, the comparison seems unfair.\n\n- How does AGENTCON behave for black-box agents or closed APIs (e.g., no access to gradients)? Does the perturbed image transfer to closed source models?\n\n- Can the attack generalize beyond SEEACT ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ovYtamh95k", "forum": "AMIb7RWnBI", "replyto": "AMIb7RWnBI", "signatures": ["ICLR.cc/2026/Conference/Submission13176/Reviewer_YZbv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13176/Reviewer_YZbv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761422667913, "cdate": 1761422667913, "tmdate": 1762923878091, "mdate": 1762923878091, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes AGENTCON, a white-box, constraint-aware attack on generalist web agents that perturbs only seller-uploaded listing images on marketplace sites. It explicitly models two real-world nuisances that break naive attacks: unknown neighbors in the listing row and positional shifts of the target image after rendering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Focuses on a realistic attack surface that doesn’t require HTML injection: adversarial perturbations to self-uploaded marketplace images.\n\n2. Captures marketplace constraints via companion variation and positional shift, and folds them into the optimization by sampling layouts and positions during attack generation.\n\n3. Broad task suite (1,680 tasks; 13 marketplaces; four scenarios) with comparisons to PGD, analyses of positional and neighbor variability, query paraphrase robustness, perturbation budget, and simple countermeasures"}, "weaknesses": {"value": "1. Some related work are missing. In particular, [1] also targets the vision pathway using CLIP-based attacks on multimodal agents, and [2] attacks web agents via white-box optimization but over textual reasoning chains.\n\n2. The method and results rely on white-box knowledge of the agent VLM stack. There’s no gray/black-box evaluation or transferability analysis across unseen VLMs/agents beyond the three instantiated backbones (e.g., over GPT-4o). This limits external validity.\n\n3. Only two rendering nuisances are modeled: unknown neighbors and positional shift. Real sites also introduce auto-cropping, aspect-ratio normalization, A/B UI variants, etc.\n\n[1] Wu, C. H., Koh, J. Y., Salakhutdinov, R., Fried, D., & Raghunathan, A. (2024). Adversarial attacks on multimodal agents. arXiv e-prints, arXiv-2406.\n\n[2] Zhang, J., Yang, S., & Li, B. UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning. In Forty-second International Conference on Machine Learning."}, "questions": {"value": "1. How does AGENTCON perform under gray/black-box access with only surrogate training or zero-shot transfer across unseen VLMs/agents? It would be great to report cross-model transfer matrices (e.g., GPT-4o) and query-limited results.\n\n2. Is it possible to learn a site-agnostic universal perturbation like what shown in GCG attack that composes with seller images and remains effective under companion and position randomness, and can it be updated online with a small query budget as layouts drift?\n\n3. For home-service tasks, why the ASR is relatively much lower when compared to other tasks?\n\n4. I would suggest to add one more ablation study on showing ASR vs perturbation budget, training epochs to separate algorithmic gains from compute/budget effects.\n\n5. Please clarify which stage defines a successful attack: selecting the target listing, adding it to the cart, submitting the order, or completing payment. The manuscript appears to treat \"incorrectly selecting the attacker’s listing\" as success, could the author make this definition more clear?\n\nI would increase my score if the authors can help clarify those questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4lrH77jYaQ", "forum": "AMIb7RWnBI", "replyto": "AMIb7RWnBI", "signatures": ["ICLR.cc/2026/Conference/Submission13176/Reviewer_gQ93"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13176/Reviewer_gQ93"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969919644, "cdate": 1761969919644, "tmdate": 1762923877766, "mdate": 1762923877766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces AGENTCON, a white-box adversarial attack targeting generalist web agents by perturbing user-uploaded listing images rather than webpage HTML. The attack accounts for two practical factors, companion variation and positional shift, to simulate realistic webpage layouts. Evaluations are conducted on 1,680 marketplace tasks across multiple domains (e.g., product listings, accommodation, traveling, home services) and vision-language models (VLMs) such as Llava-34B, MiniCPM-8B, and Phi-3-vision-4B. Results indicate attack success rates exceeding 80% on average and robustness against JPEG compression and Gaussian blur."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear writing and well-organized methodology.\n2. Comprehensive evaluation across several scenarios and VLMs."}, "weaknesses": {"value": "1. The paper has limited novelty. Despite the new attack surface (user-uploaded images), the core method largely extends standard white-box adversarial optimization (PGD) by adding simple randomization to model layout variations. The conceptual advance over classical adversarial attacks appears incremental.\n2. The assumption of the paper is impractical. The approach assumes full white-box access to the victim agent (including gradients and model architecture), which is unrealistic for deployed systems. This limits the claimed practicality of the attack.\n3. The work highlights vulnerabilities but does not propose or analyze defense or detection mechanisms, which weakens its contribution to actionable robustness research.\n4. The paper only compares to PGD, lacks stronger baselines or black-box attacks."}, "questions": {"value": "1. What potential defense or detection strategies might mitigate such attacks?\n2. Have you evaluated whether AGENTCON-generated perturbations transfer to different web agents or models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CVo5Tnm2wr", "forum": "AMIb7RWnBI", "replyto": "AMIb7RWnBI", "signatures": ["ICLR.cc/2026/Conference/Submission13176/Reviewer_FFyC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13176/Reviewer_FFyC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762067472010, "cdate": 1762067472010, "tmdate": 1762923877507, "mdate": 1762923877507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}