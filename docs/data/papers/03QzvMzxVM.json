{"id": "03QzvMzxVM", "number": 7389, "cdate": 1758019401870, "mdate": 1759897855752, "content": {"title": "Robust Uncertainty-Aware Learning via Boltzmann-weighted NLL", "abstract": "Uncertainty estimation is critical for deploying deep learning models in high-stakes applications such as autonomy and decision-making. While prior works on data uncertainty modeling estimate aleatoric uncertainty by minimizing the negative log-likelihood (NLL) loss, they often fail under the presence of outliers. To address this limitation, we introduce Robust-NLL, a drop-in replacement for vanilla NLL that filters noisy or adversarial samples. Robust-NLL learns robust uncertainty estimates in neural networks through a Boltzmann-weighted NLL loss that requires no architectural changes, additional parameters, or iterative procedures, and acts as a plug-and-play loss function that maintains full differentiability and mini-batch compatibility. We evaluate our approach on synthetic regression tasks and real-world visual localization benchmarks with injected outliers. Experimental results demonstrate that simply replacing NLL with Robust-NLL consistently improves both prediction accuracy and reliability of uncertainty estimates, achieving substantial performance gains across diverse tasks and architectures.", "tldr": "We introduce Robust-NLL for modeling uncertainty under the presence of outliers.", "keywords": ["robust estimation", "uncertainty estimation"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/444e8304cd012c1ab5fb9f3ae96a85fe575c79e2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work presents Robust-NLL, which serves as a plug-and-play loss replacing vanilla NLL loss for robust uncertainty-aware training against label-space outliers. The proposed loss function uses softmax reweighting over sample losses to filter out outliers. The author also provides theoretical analysis and empirical verification of their proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method is clear and easy to understand. Empirical results also verify the effectiveness of the proposed method, boosting baseline results by adding the reweighting term."}, "weaknesses": {"value": "My main concern with this work is the novelty of the proposed method. As depicted in Section 3.1, the proposed Robust-NLL loss is a regular NLL loss equipped with softmax-with-temperature weighting. With a Gaussian posterior, such a weighting function is simply determined by the Euclidean distance of the outlier label and predicted mean. The method might already be well examined by practitioners and prior works.\n\nNevertheless, it might be worth a detailed discussion of this type of method. However, the provided theoretical analysis covers only a limited aspect of the proposed method. It focuses on the differentiability of the Robust-NLL loss and its behavior when temperature $T=0,1,\\infty$, which in general is a result one can easily expect given the formulation of the proposed loss and properties of softmax-with-temperature. A more detailed analysis, for example, deriving bounds that demonstrate the robustness against outliers of the Robust-NLL loss, would be greatly appreciated."}, "questions": {"value": "As the authors stated in Section 4.4, selecting the optimal $T$ is critical in practice. Are there any intuitions or evidence for choosing a good $T$ given a dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ObgeLTHjtu", "forum": "03QzvMzxVM", "replyto": "03QzvMzxVM", "signatures": ["ICLR.cc/2026/Conference/Submission7389/Reviewer_qR4J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7389/Reviewer_qR4J"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930757582, "cdate": 1761930757582, "tmdate": 1762919513536, "mdate": 1762919513536, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors study uncertainty estimation for regression.\n\nThey propose Robust-NLL, a simple and intuitive modification of the standard NLL loss that weighs each loss term with a softmax weight computed across the batch. Robust-NLL is supposed to make the model training more robust to outliers in the train labels.\n\nThey evaluate Robust-NLL on two synthetic 1D regression examples, and on a visual localization dataset. They compare the performance with standard NLL and two NLL variants."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is very well written and solid overall, basically not a single typo or similar issue.\n- The studied problem is interesting, I still think uncertainty estimation for regression is understudied compared to classification.\n- The proposed Robust-NLL method is conceptually simple and intuitive, it does indeed seem like an easy-to-use plug-in replacement for the standard NLL loss."}, "weaknesses": {"value": "- The experimental evaluation is not particularly extensive, just a single real-world dataset.\n- As stated by the authors themselves, Robust-NLL \"_requires careful tuning of the surrogate parameter T. Selecting an appropriate T can be dataset-specific and requires extensive validation, especially in real-world settings where outlier rates are often unknown_\".\n- I think the experimental results might be somewhat misleading, given that the results for Robust-NLL in Figure 1 are obtained with two different values of T (T=64 in the top row, T=16 in the bottom row), and that Robust-NLL not is compared with standard NLL on the original train dataset in Section 4.3.\n- Section 3.1 and 3.2 contain quite a lot of details which I think could be better suited for an appendix. This would create space for an extended experimental evaluation.\n- The technical contribution/novelty is perhaps somewhat limited, but on the other hand, the simplicity of Robust-NLL is also a strength."}, "questions": {"value": "Questions/suggestions:\n- What would the results for Robust-NLL look like in Figure 1 if the same T was used in both rows? Is it not quite unfair to compare standard NLL with Robust-NLL using two different values of T here?\n- Why do you not compare Robust-NLL with NLL, $\\beta$-NLL and Faithful also in Table 1, with the original train data? Does it actually outperform standard NLL in this setting?\n- I would really like to see at least one more real-world image-based regression task being added to the experimental evaluation.\n- You mention that the Robust-NLL approach in principle could be applied also to classification, could you expand on this? If experimental results could be added also for some image classification task, that would probably strengthen the paper quite significantly.   \n- Section 2 is nice, but could also be made a bit shorter to make more space for the experimental evaluation.\n- Could the proposed approach be extended to multi-dim (more than just 1D) regression problems as well?\n\n\n\n\nMinor things:\n- Line 214: \"In contrast to many robust learning methods that rely on iterative scheme\" --> \"In contrast to many robust learning methods that rely on an iterative scheme\" / \"In contrast to many robust learning methods that rely on iterative schemes\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "H8bucPeIyD", "forum": "03QzvMzxVM", "replyto": "03QzvMzxVM", "signatures": ["ICLR.cc/2026/Conference/Submission7389/Reviewer_mpW2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7389/Reviewer_mpW2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931450252, "cdate": 1761931450252, "tmdate": 1762919513024, "mdate": 1762919513024, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a robust uncertainty-aware learning where they weight the NLL loss of each training through a temperature-dependent softmax distribution. They provide theortetical analysis of their proposed approach and demonstrate their proposed method's effiicany in three different tasks ranging from simple linear regression to visual localization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**1. Well-written.** This paper is well-written with clearn presentation of their proposed methodology. They initiate their discussion from uncertainty-theoretic point of view and sheds light on the lack of robustness of the classical approaches. Then, they discuss their proposed method in apt details. \n\n**2. Mix of synthetic and real dataset.** Their proposed approach outperforms many of the former method in the synthetic setting. They also demonstrate applicability of their method in visual localization as a practical regression task."}, "weaknesses": {"value": "**1. Literature review missing** This paper proposes a weighting scheme of training samples in the training. However, this particular approach has been discussed in several previous works [1-2]. The paper needs to revisit those papers and shed lights on their proposed approach in light of those works.  [1] focuses on attention mechanism for Multiple-Instance Learning and [2] focuses on addressing noisy labels through softmax activations. \n\n**2. More experiments needed** This paper is a direct improvement over the original uncertainty-awre regression network in [3]. Therefore, it would be best to recreate those experiments of [3] involving depth estimation and directly compare with [3]. This baseline study will clearly prove the superiority of the proposed methods' efficacy. \n\n[1] Ilse, M., Tomczak, J. and Welling, M., 2018, July. Attention-based deep multiple instance learning. In International conference on machine learning (pp. 2127-2136). PMLR.\n\n[2] Zhou, T., Wang, S. and Bilmes, J., 2020. Robust curriculum learning: from clean label detection to noisy label self-correction. In International conference on learning representations. \n\n[3] A. Kendall and Y. Gal. What uncertainties do we need in bayesian deep learning for computer vision? In Advances in Neural Information Processing Systems, pp. 5574–5584, 2017."}, "questions": {"value": "Is the proposed robustness approach applicable to image classification as well? Similar to the tasks studied in the paper, image classification also relies on NLL-based training and involves a mixture of easy and hard samples. If the proposed method can be generalized to classification settings, it could have broad applicability across domains such as image classification, token classification in Transformers, and image segmentation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Nhxc4sQpSR", "forum": "03QzvMzxVM", "replyto": "03QzvMzxVM", "signatures": ["ICLR.cc/2026/Conference/Submission7389/Reviewer_CHX1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7389/Reviewer_CHX1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154303217, "cdate": 1762154303217, "tmdate": 1762919512443, "mdate": 1762919512443, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Robust-NLL, a modified loss function that improves uncertainty estimation in neural networks when training data contains outliers. The method uses Boltzmann weighting to down-weight noisy samples while maintaining compatibility with standard training procedures—requiring no architectural changes or additional parameters. Experiments on synthetic and real-world tasks show improvements in both prediction accuracy and uncertainty calibration compared to standard negative log-likelihood training."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and easy to follow. \n- The authors of the paper tackle an important problem. \n- The proposed approach is technically sound. \n- The experiments conducted show significant improvements in performances across several different scenarios."}, "weaknesses": {"value": "- To the best of my understanding, the authors of the paper is missing some simple yet relevant baselines. For instance, what if we replaced the regular L2 loss with L1 loss or Huber loss, which are known to be more robust than L2 loss? Moreover, a comparison using the loss proposed in \"A General and Adaptive Robust Loss Function\" seems also relevant. How does the proposed method perform against these losses? \n- The paper seems like a somewhat obvious extension of the focal loss [1] for classifications to the case of L2 loss, which also proposed to weight loss based on the probability. Similar idea of weighting loss based on the current probability values have also been extensively explored in prior literatures [2-4] in the context of noise-robust classification. \n- The experiments conducted are somewhat limited. There are a lot other real world regression-based problems that can be considered to demonstrate the effectiveness. \n\n[1] \"Focal Loss for Dense Object Detection\"\n[2] \"Normalized Loss Functions for Deep Learning with Noisy Labels\"\n[3] \"Generalized cross entropy loss for training deep neural networks with noisy labels\"\n[4] \"Symmetric Cross Entropy for Robust Learning With Noisy Labels\""}, "questions": {"value": "- Standard benchmark dataset seems to have been used for experiments in 4.3. Does the dataset inherently contain noise? If so, what is the noise ratio?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ldzrt1maqB", "forum": "03QzvMzxVM", "replyto": "03QzvMzxVM", "signatures": ["ICLR.cc/2026/Conference/Submission7389/Reviewer_c95g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7389/Reviewer_c95g"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762206681293, "cdate": 1762206681293, "tmdate": 1762919511986, "mdate": 1762919511986, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}