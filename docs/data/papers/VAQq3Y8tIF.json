{"id": "VAQq3Y8tIF", "number": 8916, "cdate": 1758102322786, "mdate": 1763649519945, "content": {"title": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "abstract": "Large language models excel at generating individual functions or single files of code, yet generating complete repositories from scratch remains a fundamental challenge. This capability is key to building coherent software systems from high-level specifications and realizing the full potential of automated code generation. The process requires planning at two levels: deciding what features and modules to build (proposal stage) and defining their implementation details (implementation stage). Current approaches rely on natural language planning, which often produces unclear specifications, misaligned components, and brittle designs due to its inherent ambiguity and lack of structure. To address these limitations, we introduce the Repository Planning Graph (RPG), a structured representation that encodes capabilities, file structures, data flows, and functions in a unified graph. By replacing free-form natural language with an explicit blueprint, RPG enables consistent long-horizon planning for repository generation. Building on RPG, we develop ZeroRepo, a graph-driven framework that operates in three stages: proposal-level planning, implementation-level construction, and graph-guided code generation with test validation To evaluate, we construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks. On RepoCraft, ZeroRepo produces nearly 36K Code Lines and 445K Code Tokens, on average 3.9× larger than the strongest baseline (Claude Code), and 68× larger than others. It also achieves 81.5% coverage and 69.7% test accuracy, improving over Claude Code by 27.3 and 35.8 points. Further analysis shows that RPG models complex dependencies, enables more sophisticated planning through near-linear scaling, and improves agent understanding of repositories, thus accelerating localization.", "tldr": "To address ambiguity and verbosity in natural language–based repository generation, we propose the Repository Planning Graph (RPG), and further build ZeroRepo and the RepoCraft benchmark.", "keywords": ["planning", "repository generation", "agent", "code generation"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/19784e798e80383dfdc56233312a65f011583ffb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents RPG (Repository Planning Graph), a prompting framework for generating software repositories with LLMs. RPG generates sketches of a repository in graphs, where nodes represent functions and edges represent dependencies and information flow. The actual code is then generated from this sketch graph.\n\nExperiments with two backbone models (o3-mini and Qwen3-Coder) show that RPG outperforms some other frameworks such as MetaGPT and Paper2Code on six repositories."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem (generating an entire repository from nothing) is interesting. Experiments show improvement compared with multiple other frameworks."}, "weaknesses": {"value": "- In essence, RPG is a prompting framework and does not involve training better models, limiting its novelty and contribution. Experiments only involve two API-based models, raising questions about RPG's applicability in many real-world applications that require deploying models locally.\n\n- The problem setting - generating an entire repository from scratch - is unrealistic. The most common application of LLMs in software engineering is resolving an existing issue or implementing new features in an existing repository.\n\n- Line 106-107: I'm confused by the structure here. I can understand that \"multi-agent systems assign roles, while workflows follow stages\". But then the authors state \"Industrial systems automate SWE tasks\". How is this parallel to the previous two? Aren't multi-agent systems and workflows supposed to automate SWE tasks?\n\n- Figure 1 is too crammed and looks messy.\n\n- References are not formatted professionally. For example, Line 522, 527, 587 are all arxiv preprints, yet three different formats are used. The authors also cited many papers' preprint versions when there are peer-reviewed versions. For example, Epicoder (Line 598) is published at ICML, while DeepSeek-R1 (Line 528) is published at Nature.\n\n- Details are lacking in Section 3.2. What models are used for graph node embedding? What models are used for feature path retrieval?"}, "questions": {"value": "- According to Figure 1 and 2, edges in the RPG indicate hierarchy and information flow. Does this imply that graphs in RPG are always acyclic? If so, what's the advantage of the proposed RPG over graphs automatically constructed with program analysis tools, such as file structure tree, import dependency, and control flow? If not, can the authors provide an example of cyclic graph?\n\n- Line 238: there are only three subplots (A, B, C) in Figure 1, and no D. I suppose this is a typo."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SXKyUlGU9O", "forum": "VAQq3Y8tIF", "replyto": "VAQq3Y8tIF", "signatures": ["ICLR.cc/2026/Conference/Submission8916/Reviewer_Gi5H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8916/Reviewer_Gi5H"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760759556067, "cdate": 1760759556067, "tmdate": 1762920669446, "mdate": 1762920669446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the Repository Planning Graph (RPG), a structured representation that unifies proposal-level capability planning with implementation-level file, class, and function dependencies for repository generation. Building on RPG, the ZeroRepo agent conducts planning, graph-guided code synthesis, and test validation. The authors also release RepoCraft, a benchmark derived from six paraphrased real-world repositories (1,052 tasks). ZeroRepo substantially outperforms multi-agent, workflow, and terminal baselines on RepoCraft, reaching 81.5% coverage, 69.7% pass rate, and dramatically larger codebases, with analyses showing near-linear scaling and efficiency benefits from graph-guided localization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- RPG provides a clear structured alternative to natural-language planning, coupling capability decomposition with file-level structure and data-flow constraints, with the design well illustrated in Figure 2. This representation offers an explicit, interpretable blueprint that can support consistent long-horizon planning in repository generation.\n- RepoCraft offers a comprehensive benchmark with six substantial real-world repositories, paraphrased specifications, and 1,052 evaluation tasks derived systematically from test files, filling a gap for repository-scale assessment of agent planning capabilities.\n- ZeroRepo achieves substantial gains over strong baselines, demonstrating +27.3% coverage and +35.8% pass rate improvements compared to Claude Code (Table 2) while generating significantly larger repositories (36K LOC, 445K tokens vs. 10.6K LOC, 105K tokens),."}, "weaknesses": {"value": "- ZeroRepo relies heavily on the 1.5M-node EpiCoder feature ontology as its knowledge base for proposal-level planning. However, it is unclear whether all competing baselines had equal access to comparable structured priors.\n- The coverage and novelty metrics depend critically on K-means clustering with LLM adjudication, and correctness evaluation relies on LLM-adapted test cases. Beyond the Gold Project sanity check (81.0% pass rate on human-developed repositories), there is limited independent evidence that these automated evaluation pipelines produce stable and reproducible judgments, particularly for edge cases where generated functionality diverges significantly from reference implementations.\n- Key architectural decisions—including reliance on the feature tree for initial planning, data-flow encoding at multiple hierarchy levels, test-driven code generation with majority-vote diagnosis—lack comprehensive ablation studies. The paper only provides an ablation for graph-guided localization (Table 4); without component-level comparisons, it is difficult to attribute the reported performance gains specifically to the RPG representation versus confounding factors like the planning budget, LLM backbone choice, or architectural engineering."}, "questions": {"value": "1. Was the EpiCoder ontology filtered or deduplicated to ensure it does not contain paraphrases or derivatives of the six target repositories used in RepoCraft? Did all baseline methods have equal access to this knowledge base?\n2. Beyond the Gold Project validation on human-developed repositories, can the authors provide evidence (e.g., correlation with manual evaluation) that the LLM-based coverage/novelty pipeline produces reliable judgments consistently across different types of generated code?\n3. Which component—the feature tree initialization, data-flow encoding, or graph-guided generation—contributes most to the observed performance gains? An ablation removing RPG structure while maintaining the same planning budget would clarify this."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SGRdT3lFkb", "forum": "VAQq3Y8tIF", "replyto": "VAQq3Y8tIF", "signatures": ["ICLR.cc/2026/Conference/Submission8916/Reviewer_PvAb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8916/Reviewer_PvAb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761853572922, "cdate": 1761853572922, "tmdate": 1762920668809, "mdate": 1762920668809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response(Part 1)"}, "comment": {"value": "We thank all reviewers for your thoughtful and constructive feedback. \n\nOur motivation starts from a simple but critical observation: **repository-level generation is fundamentally a long-horizon planning problem.** The dominant paradigm—planning in unstructured natural language—is the main bottleneck. Free-form text is ambiguous and lacks architectural constraints, much like trying to construct a skyscraper from an essay instead of a blueprint. To make progress on repository-scale generation, we must first solve this planning problem.\n\nOur core contribution is **the Repository Planning Graph (RPG)**, a structured, executable blueprint for software repositories. Designed to overcome the ambiguity of natural language, the RPG is explicit, verifiable, and architectural. It unifies the functional requirements (\"what to build\") and the implementation strategy (\"how to build it\") into a cohesive graph representation.\n\nWe instantiate this with the ZeroRepo framework:\n\n1. **Stages A (Proposal-level Planning) and B (Implementation-level Planning)**: This is our core planning module. Its single, unified purpose is to construct the complete RPG, encoding the what and how into one graph.\n2. **Stage C (Graph-Guided Code Generation)**: This is a simple, replaceable agent pipeline that executes the plan defined by the RPG. Its success is derivative of the RPG's quality, and it is not the focus of our novelty."}}, "id": "x0H7hzb96F", "forum": "VAQq3Y8tIF", "replyto": "VAQq3Y8tIF", "signatures": ["ICLR.cc/2026/Conference/Submission8916/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8916/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8916/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763645324298, "cdate": 1763645324298, "tmdate": 1763645324298, "mdate": 1763645324298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the Repository Planning Graph, a structured graph representation that integrates proposal and implementation planning for repository-level code generation. Specifically, proposal-level planning decides what functionalities to include, and implementation-level planning decides how to realize them. RPG encoding functionalities, data flows, file structures, and class/function dependencies into a coherent graph. Based on this graph, the authors develop ZeroRepo, a framework that constructs and traverses the RPG to generate repositories from natural language specifications. In addition, the authors introduce a benchmark RepoCraft to evaluate the ZeroRepo. RepoCraft covers six real-world software projects with 1052 functional tasks. Experiment demonstrates ZeroRepo outperforms other baselines in coverage, test accuracy, and code scale."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method integrates functional and structural dependencies, providing graph abstraction as an intermediate for natural language description and code repository implementation. The RPG is both explicit and fully machine interpretable.\n\n2. The paper also provides a graph-guided code repository generation method. The method traverses the RPG in topological order, applying test-driven development to ensure incremental expansion while preserving stability.\n\n3. The paper also provides a valuable testbed covering six projects and 1052 tasks, assessing coverage, accuracy, and code scale.\n\n4. The experiment demonstrates significant improvement compared with SOTA methods. The additional scaling analysis shows near-linear growth in functionality and repository size."}, "weaknesses": {"value": "1. The paper only includes a single ablation study without a graph, while the effectiveness of other components remains unclear (e.g., exploration strategy). As there are 3 generation level, it is important to conduct ablation study. For example, can we remove stage A?\n\n2. RepoCraft relies on automatic localization and major-voting validation. This may introduce evaluation errors from LLMs.\n\n3. Efficiency analysis of computational overhead from RPG constructions is not discussed."}, "questions": {"value": "1. How is the accuracy for automatic localization and major voting? Providing a manual verification on a subset would strengthen the evaluation.\n\n2. How would the cost compare to RPG+RepoCraft and traditional natural language based code repository generators?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A3487tVug5", "forum": "VAQq3Y8tIF", "replyto": "VAQq3Y8tIF", "signatures": ["ICLR.cc/2026/Conference/Submission8916/Reviewer_rT1s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8916/Reviewer_rT1s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948778779, "cdate": 1761948778779, "tmdate": 1762920668310, "mdate": 1762920668310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the challenging problem of scaling large language models (LLMs) from generating single files to complete, multi-file software repositories. The authors argue that current approaches, which often rely on natural language for high-level planning, are brittle and fail to scale due to ambiguity and a lack of structure.\nTo address this, the paper introduces three main contributions:\n- Repository Planning Graph (RPG): A novel graph-based representation that serves as a structured blueprint for repository generation.\n- ZeroRepo Framework: A graph-driven agent framework that builds and utilizes the RPG.\n- RepoCraft Benchmark: A new, challenging benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Moving from function-level to repository-level generation is arguably the most critical open problem in the area. This paper tackles it directly.\n\n- The main results table (Table 2) shows a massive performance gap between the RPG-based ZeroRepo and all baselines (multi-agent, workflow, and terminal-based) on all key metrics: coverage, accuracy, and scale.\n\n\n- The paper shows a clear benefit for the graph-guided localization, with the RPG speeding up localization tasks by 30-50% compared to a \"w/o Graph\" baseline."}, "weaknesses": {"value": "- Dependency on External Knowledge Base: The \"Proposal-Level Construction\" stage seems heavily dependent on the \"EpiCoder Feature Tree,\" a pre-existing 1.5M-node ontology of software capabilities. It is unclear how much of the system's strong performance is due to the novel RPG framework versus this massive, highly-structured knowledge base.\n\n- Evaluation of \"Novelty\": The paper introduces \"Novelty\" as a metric and provides qualitative examples of new features (e.g., \"Prophet forecasting\" ). However, the paper does not seem to evaluate the functional correctness of these novel features. The main accuracy metrics (Pass/Voting Rate) are based on the 1,052 tasks from the reference projects. It's unclear if the \"novel\" features are correct, functional implementations or just plausible-sounding, well-structured stubs.\n\n- Potential for Benchmark Leakage: The RepoCraft benchmark is based on extremely well-known projects (pandas, scikit-learn, etc.)."}, "questions": {"value": "What is the practical cost of running ZeroRepo? Could the authors provide an estimate of the total tokens, API calls, or wall-clock time required to generate one repository compared to the Claude Code baseline over its 30 iterations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "cDLcagdPaS", "forum": "VAQq3Y8tIF", "replyto": "VAQq3Y8tIF", "signatures": ["ICLR.cc/2026/Conference/Submission8916/Reviewer_1t6n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8916/Reviewer_1t6n"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972014933, "cdate": 1761972014933, "tmdate": 1762920666583, "mdate": 1762920666583, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}