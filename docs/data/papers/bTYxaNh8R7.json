{"id": "bTYxaNh8R7", "number": 9748, "cdate": 1758137978658, "mdate": 1762962511059, "content": {"title": "WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents", "abstract": "Multiple prompt injection attacks have been proposed against web agents. At the same time, various methods have been developed to detect general prompt injection attacks, but none have been systematically evaluated for web agents. In this work, we bridge this gap by presenting the first comprehensive benchmark study on detecting prompt injection attacks targeting web agents. We begin by introducing a fine-grained categorization of such attacks based on the threat model. We then construct datasets containing both malicious and benign samples: malicious text segments generated by different attacks, benign text segments from four categories, malicious images produced by attacks, and benign images from two categories. Next, we systematize both text-based and image-based detection methods. Finally, we evaluate their performance across multiple scenarios. Our key findings show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. Our datasets and code are released at: https://anonymous.4open.science/r/WAInjectBench-C51D.", "tldr": "", "keywords": ["web agents", "prompt injection attacks"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/736ec053bfd103099e0a549de3931ba01859d3ba.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents WAInjectBench, a comprehensive benchmark for evaluating prompt injection detection methods in web agent settings. It includes both text-based and image-based injection samples and evaluates the detectors using text and image modalities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The writing is clear and easy to follow.\n\nThe experiment is comprehensive. It compiles a diverse dataset of injections from existing literature and studies 12 representative detectors (including prompting-, embedding-, and fine-tuning-based methods)."}, "weaknesses": {"value": "Overall, my main concern is that the paper does not provide additional insights into how to effectively protect web agents from prompt injection risks. In realistic deployments, users typically have no prior knowledge of whether injections exist, nor their modality (text or image), location, or injected content. This means we cannot know in advance which detector would be most effective. As a result, benchmarking detectors under pre-specified threat settings may have limited practical value.\n\nGiven this, it would be valuable to explore approaches like ensembling text- and image-based detectors, to assess whether such a unified detector yields robust detection performance when the nature of the threats is unknown.\n\nIn addition, many deployed web agents (e.g., Operator) already integrate built-in detection. It would be important to evaluate and compare with these commercial-level detectors. Agents also have self-evaluation mechanisms. These models can sometimes autonomously identify suspicious inputs during execution rather than relying on an external detector. Including such baselines would strengthen the study and clarify whether standalone detectors provide any unique advantages. This comparison could also offer practical guidance on whether future safe web agents should adopt independent detection modules or embed this capability directly within the model.\n\nAnother practical consideration is runtime efficiency. In real-world scenarios, detectors would need to operate in real time, potentially introducing non-trivial latency. Measuring and reporting the time cost of each detector would be an important complement to the accuracy-based evaluation. Furthermore, discussing when and how frequently the detector should be invoked would provide valuable insight. For instance, continuously running detection at every step may be infeasible—especially since many web-agent tasks (e.g., in OSWorld) require 100–200 interaction steps.\n\n\nQuestion:\n\nFrom my understanding, EIA involves injections with zero opacity, meaning the malicious instruction is not rendered visibly on the webpage. In that case, it is unclear how the image-based detectors achieved a TPR as high as 0.77. If the reported results correspond only to EIA samples with explicit instructions, this should be clearly stated in the paper, as it affects the interpretation of the experiment setup and conclusions."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wqsQSftTNN", "forum": "bTYxaNh8R7", "replyto": "bTYxaNh8R7", "signatures": ["ICLR.cc/2026/Conference/Submission9748/Reviewer_nViD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9748/Reviewer_nViD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760506427922, "cdate": 1760506427922, "tmdate": 1762921242979, "mdate": 1762921242979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "JV3IpuxYD9", "forum": "bTYxaNh8R7", "replyto": "bTYxaNh8R7", "signatures": ["ICLR.cc/2026/Conference/Submission9748/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9748/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762962510324, "cdate": 1762962510324, "tmdate": 1762962510324, "mdate": 1762962510324, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces WAInjectBench, a benchmark for detecting prompt-injection attacks against web agents. It formalizes a threat model, curates multi-modal datasets (text and images), instantiates families of detectors (prompting, embedding, fine-tuning, ensembling), and reports that detectors do fine when attacks are loud and explicit but crater on implicit or imperceptible perturbations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear formulation of prompt-injection detection specifically for web agents rather than generic chatbots; grounded in the agent’s observation channels (screenshots, SoM/a11y/DOM/captions).\n\n2. Curates multi-modal attack families (pop-ups, UI insertions, caption-based, WebInject, imperceptible VWA-Adv) with corresponding benign counterparts; reasonably broad coverage of real agent I/O.\n\n3. Evaluates four detector families for both modalities (prompting, embeddings, fine-tuning, ensembles) rather than a single favored approach.\n\n4. The paper shows a useful takeaway: detectors succeed on explicit instructions and visible artifacts, but fail on implicit or imperceptible perturbations; ensembling boosts recall at the cost of higher FPR."}, "weaknesses": {"value": "1. Novelty: The claim of being the \"first comprehensive\" detection benchmark is under-argued relative to prior agent-security suites (e.g., WASP, VPI-Bench) that, while attack/eval-focused, will be viewed as adjacent.\n\n2. Table 1 is not complete: Beyond malicious users and website owners, Table 1 should include a malicious platform participant [1,2], e.g., an Amazon seller who controls the content of their listing. This actor can inject instructions into product titles, descriptions, images, or metadata, yet is neither the end-user nor the platform owner.\n\n3. Benign text distribution is mismatched: Negative text comes from ham emails/SMS on Kaggle and generated captions, which do not match web-UI distributions the agent actually observes; this likely understates FPR and miscalibrates thresholds for interface text.\n\n4. Benign captions are generated with LLaVA-1.5-7B while LLaVA-1.5-7B is also a detector baseline (prompted and fine-tuned), risking optimistic FPRs via model-family coupling.\n\n5. The strongest individual image baseline is GPT-4o-Prompt with low FPRs, making core results mainly rely on one proprietary model.\n\n[1] Zhan, Q., Liang, Z., Ying, Z., & Kang, D. (2024, August). InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents. In Findings of the Association for Computational Linguistics ACL 2024 (pp. 10471-10506).\n\n[2] Zhang, J., Yang, S., & Li, B. UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning. In Forty-second International Conference on Machine Learning."}, "questions": {"value": "1. Decouple model families. I suggest decoupling the models used to generate captions from those used for detection, since sharing a model family can introduce bias.\n\n2. Include more MLLMs. Incorporate additional multimodal LMs, both open and closed, for a more comprehensive assessment. Currently, there are few MLLMs evaluated.\n\n3. Report efficiency metrics. Please provide per-sample latency, throughput, and cost for each detector family on common hardware to establish feasibility for real-time agent defenses.\n\n4. From my perspective, we should replace or augment benign text with DOM-, a11y-, or SoM-derived interface strings and site-native emails or messages, so that false positive rates reflect the true web-agent distribution rather than artifacts like Kaggle ham/SMS datasets or LLaVA-generated captions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pleGp3ABEj", "forum": "bTYxaNh8R7", "replyto": "bTYxaNh8R7", "signatures": ["ICLR.cc/2026/Conference/Submission9748/Reviewer_eAxj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9748/Reviewer_eAxj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966441871, "cdate": 1761966441871, "tmdate": 1762921242547, "mdate": 1762921242547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a benchmark for prompt injection attack on web agents. The benchmark consists of six prompt injection attacks, six text-based and six image-based detectors, text dataset and image dataset."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This is a comprehensive benchmark on prompt injection threat eval for web agents. It includes advanced attack and defense strategies in a unified framework for fair comparisons."}, "weaknesses": {"value": "1. It would be more convincing to validate why and how the LLM-based detector is optimal for this paper. Results with different models as backbones are helpful. Results with different prompts can be useful to show the optimality of the prompts the paper adopts and interesting findings may be drawn from it.\n\n2. Using of TPR or FPR in main tables is questionable. Why not using F1 score?\n\n3. There is no insight we can get from the evaluation here that motivates the community to build a more secure agent. As a benchmark paper, lack of useful insights/findings and motivation for future development will harm the contribution of this paper."}, "questions": {"value": "Please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IdvrJu7KHb", "forum": "bTYxaNh8R7", "replyto": "bTYxaNh8R7", "signatures": ["ICLR.cc/2026/Conference/Submission9748/Reviewer_BCyu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9748/Reviewer_BCyu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762052086988, "cdate": 1762052086988, "tmdate": 1762921242008, "mdate": 1762921242008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces WAInjectBench, a benchmark for evaluating prompt injection detection methods for web agents. It categorizes six attacks, builds text- and image-based datasets of malicious and benign samples, and benchmarks existing/self-built detectors (prompting, embedding, fine-tuning, and ensemble-based). The main finding is that detectors perform well on explicit attacks but fail on implicit or imperceptible ones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses an important and timely problem in web-agent safety.\n2. Provides a comprehensive dataset across modalities.\n3. Offers a systematic comparison of many existing detectors under one framework."}, "weaknesses": {"value": "1. No evaluation of simple fine-tuning baselines.\n2. In the proposed dataset, benign samples may not correspond directly to malicious ones. Including the benign version of the malicious ones could be helpful for furtuer comparison.\n3. Limited novelty. The paper mostly aggregates prior attacks and detectors without new methods or deep analysis.\n4. Shallow insights. The paper reports results but does not analyze failure cases or provide actionable design guidance."}, "questions": {"value": "1. Do benign samples explicitly include benign versions of the malicious ones?\n2. How would embedding and fine-tuning-based detectors perform when trained on subsets of your dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hNoxWehJyK", "forum": "bTYxaNh8R7", "replyto": "bTYxaNh8R7", "signatures": ["ICLR.cc/2026/Conference/Submission9748/Reviewer_bBa4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9748/Reviewer_bBa4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762066885061, "cdate": 1762066885061, "tmdate": 1762921241387, "mdate": 1762921241387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}