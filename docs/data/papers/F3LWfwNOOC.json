{"id": "F3LWfwNOOC", "number": 4663, "cdate": 1757738753292, "mdate": 1759898021071, "content": {"title": "OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models", "abstract": "Advances in Multimodal Large Language Models (MLLMs) intensify concerns about data privacy, making Machine Unlearning (MU), the selective removal of learned information, a critical necessity. \nHowever, existing MU benchmarks for MLLMs are limited by a lack of image diversity, potential inaccuracies, and insufficient evaluation scenarios, which fail to capture the complexity of real-world applications. \nTo facilitate the development of MLLMs unlearning and alleviate the aforementioned limitations, we introduce OFFSIDE, a novel benchmark for evaluating misinformation unlearning in MLLMs based on football transfer rumors. \nThis manually curated dataset contains 15.68K records for 80 players, providing a comprehensive framework with four test sets to assess forgetting efficacy, generalization, utility, and robustness. \nOFFSIDE supports advanced settings like selective unlearning and corrective relearning, and crucially, unimodal unlearning (forgetting only text data). Our extensive evaluation of multiple baselines reveals key findings: \n(1) Unimodal methods (erasing text-based knowledge) fail on multimodal rumors; \n(2) Unlearning efficacy is largely driven by catastrophic forgetting; \n(3) All methods struggle with \"visual rumors\" (rumors appear in the image); \n(4) The unlearned rumors can be easily recovered and\n(5) All methods are vulnerable to prompt attacks. \nThese results expose significant vulnerabilities in current approaches, highlighting the need for more robust multimodal unlearning solutions.", "tldr": "This paper introduces a novel benchmark for MLLMs unlearning.", "keywords": ["Multimodal large language model; Machine unlearning"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6b83ccf2039acec33c5d24bcaa32e39261d09fab.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new benchmark, offside, to evaluate machine unlearning methods in multimodal large language models. OFFSIDE collects the image and information from real-world football players from google engines. This paper also evaluates several existing methods in unimodel unlearning to compare their performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper summarizes four settings of unlearning in MLLMs, which are significant contributions in the research field.\n\n2. The rumors of images and texts in the football fiedl are well motivated to construct this benchmark,\n\n3. The paper is well-written and easy to understand.\n\n4.The unimodel unlearning methods are evaluated comprehensively across different tasks."}, "weaknesses": {"value": "Despite a novel benchmark on MU in MLLMs, there are several drawbacks in this paper\n1. As a benchmark paper, several multimodal methods are not evaluated such as [1] [2], which did not provide a comprehensive evaluation of unlearning methods.\n\n2. Table 1 lists MMUBench, however, in the introduction section this benchmark is not metioned,  especially in line second paragraph, where related works are introduces.\n\n3. The football field is rather limited in the real-world setting. Some other fields needs to be evaluated such as politicians and singers, etc.\n\n4. I think classification and generation task are somewhat redundant. Classification is also a type of generation in the LLM tasks.\n\n\n\n\n## References ##\n\n[1] Huo, Jiahao, et al. \"Mmunlearner: Reformulating multimodal machine unlearning in the era of multimodal large language models.\" arXiv preprint arXiv:2502.11051 (2025).\n\n[2] Liu, Zheyuan, et al. \"Modality-aware neuron pruning for unlearning in multimodal large language models.\" arXiv preprint arXiv:2502.15910 (2025)."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "CSP2ED8n0c", "forum": "F3LWfwNOOC", "replyto": "F3LWfwNOOC", "signatures": ["ICLR.cc/2026/Conference/Submission4663/Reviewer_qQfk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4663/Reviewer_qQfk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761031848797, "cdate": 1761031848797, "tmdate": 1762917498751, "mdate": 1762917498751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OFFSIDE, a new benchmark for evaluating machine unlearning in multimodal large language models (MLLMs).\nThe benchmark focuses on football transfer rumors as a misinformation scenario and defines four evaluation settings: Complete, Selective, Corrective, and Unimodal unlearning. These settings are designed to assess an MLLM's ability to selectively forget and relearn knowledge across both textual and visual modalities.\n\nThe authors conduct systematic experiments with several representative unlearning methods under consistent experimental conditions and report the following key findings:\n(1) unimodal text-based methods fail on multimodal rumors;\n(2) unlearning efficacy is largely determined by catastrophic forgetting;\n(3) all methods struggle when misinformation is visually grounded;\n(4) unlearned knowledge can be easily recovered through relearning; and\n(5) all methods remain vulnerable to prompt-based attacks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**S1. Systematic Formulation of Evaluation Settings**\n\nThis paper organizes four unlearning scenarios, i.e., Complete, Selective, Corrective, and Unimodal, within a single benchmark. Although several of these aspects have been individually explored before, presenting them together in a unified benchmark offers practical value for researchers studying multimodal unlearning.\n\n\n**S2. Comprehensive Experimental Comparison**\n\nThis paper provides a broad empirical comparison of representative unlearning methods under consistent experimental conditions. Even if the findings largely align with prior studies, the inclusion of multiple modalities and evaluation aspects helps confirm and contextualize known challenges such as catastrophic forgetting and prompt vulnerability."}, "weaknesses": {"value": "**W1. Scope of Benchmark**\n\nThe OFFSIDE benchmark focuses solely on football transfer rumors, which constitutes a narrow and specialized scenario. In contrast, other multimodal unlearning benchmarks such as MLLMU-Bench, CLEAR, and PEBench are designed around more general and socially relevant domains (e.g., person profiles, privacy, or harmful content) that better reflect practical application contexts for unlearning.\n\nThe paper does not adequately explain how misinformation about football transfers impacts the real world or what specific harms could be mitigated through unlearning in this domain. The only passage that briefly touches on this issue, referring to \"demonstrating the practical value of multimodal unlearning in real-world applications\" (L157), is superficial and lacks substantive discussion of social impact or practical relevance. Without such justification, it remains unclear whether the chosen domain can serve as a representative real-world use case for unlearning tasks.\n\n\n**W2. Novelty of Benchmark**\n\nThe proposed \"Corrective Relearning\" setting appears to substantially overlap with knowledge editing, which likewise aims to modify or restore specific knowledge already learned by a pre-trained LLM/MLLM. Existing datasets and benchmarks such as [a-e] already evaluate this process by measuring knowledge correction accuracy, generalization, and side-effects after targeted knowledge updates. The authors need to clearly articulate conceptual or methodological distinctions from these knowledge editing benchmarks.\n\n[a] Meng et al., Locating and Editing Factual Associations in GPT, ICLR 2022.\n\n[b] Zhong et al., MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions, EMNLP 2023.\n\n[c] Huang et al., VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark, NeurIPS 2024.\n\n[d] Zhang et al., MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency, ACL findings 2025.\n\n[e] Du et al., MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge, ICLR 2025.\n\n\n**W3. Composability of Existing Benchmarks**\n\n**W3-1.** Given that existing benchmarks already cover unimodal, selective, and corrective (see W2) aspects separately, their combination could approximate the proposed benchmark. This raises questions about the necessity and standalone contribution of OFFSIDE as a new benchmark.\n\n**W3-2.** The reported findings, namely, (1) unimodal methods fail on multimodal rumors, (2) unlearning efficacy is largely driven by catastrophic forgetting, (3) all methods struggle with visual rumors, (4) unlearned rumors can be easily recovered, and (5) all methods remain vulnerable to prompt attacks, are mostly consistent with observations reported in prior unimodal/multimodal unlearning studies (e.g., CLEAR, PEBench, MMUBench). It is unclear whether these insights uniquely emerge from OFFSIDE, or whether they simply reinforce existing knowledge observed across benchmarks.\n\n\n**W4. Clarity of Dataset Construction Process**\n\nSome important details about the dataset construction process are missing. In particular, the paper does not specify the criteria for selecting players, the criteria for labeling rumors vs. facts, or the reliability of data sources (e.g., official media outlets vs. fan forums)."}, "questions": {"value": "**W1.** Could the authors elaborate on why football transfer rumors were chosen as the domain for this benchmark? In particular, how does this setting reflect practical and socially relevant unlearning scenarios (e.g., personal data deletion, misinformation mitigation, or legal compliance)? Please also clarify any social impacts or safety motivations that justify the choice of this domain.\n\n**W2.** How is the proposed Corrective Relearning setting conceptually or methodologically different from existing knowledge editing frameworks such as COUNTERFACT, MQuAKE, VLKEB, MC-MKE, or MMKE-Bench? Does the task introduce any new evaluation dimensions beyond what these benchmarks already measure?\n\n\n**W3.** Several findings reported in the paper (e.g., catastrophic forgetting, recovery of unlearned information, and vulnerability to prompt attacks) seem consistent with prior unlearning studies (e.g., CLEAR, PEBench, MMUBench). Could the authors clarify which observations are unique to OFFSIDE and could not have been discovered through combinations of these existing benchmarks? Highlighting any domain-specific phenomena would strengthen the case for the necessity of OFFSIDE.\n\n\n**W4.** Please provide more details about the dataset construction process. Specifically:\n\n- What criteria were used to select the 80 players?\n\n- How were rumors and facts labeled or verified (e.g., by which sources and at what time)?\n\n- What are the primary data sources (official media outlets, news APIs, social media, fan forums, etc.), and how was their reliability ensured?\n\n- Are there plans to release the dataset or documentation (e.g., annotation guidelines, license information) to support reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AHX8Y3ATpi", "forum": "F3LWfwNOOC", "replyto": "F3LWfwNOOC", "signatures": ["ICLR.cc/2026/Conference/Submission4663/Reviewer_4cFW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4663/Reviewer_4cFW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761493847049, "cdate": 1761493847049, "tmdate": 1762917498408, "mdate": 1762917498408, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OFFSIDE, a new benchmark for evaluating misinformation unlearning in Multimodal Large Language Models (MLLMs).  OFFSIDE is based on football transfer rumors and includes 15.68K records for 80 players. It provides four test sets to assess forgetting efficacy, generalization, utility, and robustness, and supports selective unlearning, corrective relearning, and unimodal unlearning. Experiments reveal key findings in current unlearning methods in each setting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-  S1. The paper systematically divides the unlearning problem into Complete Unlearning, Selective Unlearning, Corrective Relearning, and Unimodal Unlearning, which facilitates a more fine-grained analysis.\n\n-  S2. One of the main challenges in this field is the lack of datasets with a sufficient number of samples and the fact that most existing datasets are limited to facial images. In this regard, creating a dataset with a sufficient number of samples is highly commendable."}, "weaknesses": {"value": "- W1. The interpretation of the results is somewhat unclear. For example, in L382-383, the paper states, “We observe that all the baselines exhibit a performance drop (compared to the vanilla model) in both private information and shared information.”. However, looking at Table 3, the Shared Information scores do not appear to decrease significantly for GD and KL. The Retain Set in Complete Unlearning also shows a similar drop. Therefore, the difference between the findings of Selective and Complete Unlearning seems minimal. \n\n- W2. The claim made in Lines 379–381 is also confusing. The paper mentions overfitting to the Retain Set, yet the models achieve high scores on MMBench, which would not be consistent with overfitting. This shows that the baselines may have been underestimated.\n\n- W3. The experiments are limited to LoRA fine-tuning. Since the knowledge acquired through LoRA fine-tuning is stored in a relatively small number of parameters, the results could differ from those obtained through full fine-tuning. Given that the Qwen model used is relatively small, including results with full fine-tuning and analyzing how the outcomes differ would make this paper more valuable.\n\n- W4. The paper could further explore practical failure cases or qualitative analyses. Although it identifies the problems of existing methods in each unlearning category, it does not provide enough insight into how unlearning can be improved or concrete examples of failure cases. Including such an analysis or more failure cases would be particularly useful for a benchmark-focused paper."}, "questions": {"value": "- I would like a more detailed explanation of the differences between the findings of Selective and Complete Unlearning.\n \n- Regarding Lines 379–381, I would like to understand why the model is overfitting to the Retain Set, even though its performance on MMBench remains high.\n\n- I am also interested in seeing the results of full fine-tuning.\n\n- I would like to know if there are any insights for improving unlearning performance based on their analysis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tj9qvf1lGR", "forum": "F3LWfwNOOC", "replyto": "F3LWfwNOOC", "signatures": ["ICLR.cc/2026/Conference/Submission4663/Reviewer_wAqb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4663/Reviewer_wAqb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806354524, "cdate": 1761806354524, "tmdate": 1762917498222, "mdate": 1762917498222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Exisiting benchmarks do have selective forgetting\nDomain is very niche\n\nThe paper introdices OFFSIDE a new benchmark for evaluating machine unlearning in multimodal large language models (MLLMs), focusing on misinformation such as football transfer rumors.\nThe dataset contains real-world vision–question–answer pairs across four evaluation settings: complete, selective, corrective relearning, and unimodal unlearning.\nIt enables studying how well models can selectively forget false or private information while retaining general knowledge.\nExperiments with five unlearning baselines show that text-only (unimodal) methods fail on multimodal misinformation, and that most apparent unlearning results from catastrophic forgetting rather than targeted removal.\nOverall, OFFSIDE reveals that current unlearning approaches remain ineffective, easily reversible, and vulnerable to prompt-based attacks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- OFFSIDE introduces a real-world, benchmark based on football transfer rumors, representing a realistic domain where misinformation and visual evidence interact.\n- The inclusion of four complementary unlearning scenarios (complete, selective, corrective relearning, and unimodal) adds diverse evaluation sets, extending prior unlearning paradigms to more complex multimodal and continual learning contexts."}, "weaknesses": {"value": "- Certain sections (e.g., Table 1 and parts of the Introduction) are somewhat dense, making it harder for readers to immediately grasp how OFFSIDE concretely differs from prior datasets.\n\n- While the paper introduces the “Corrective Relearning” scenario and lists four datasets (Forget Set, Retain Set, Test Set, Relearn Set), it only briefly mentions how these relate to continual learning (“simulates a continual learning framework to examine whether previously unlearned rumors can be successfully recovered after post-training”). However, it does not clearly explain:\n\n- How examples in the Relearn Set are derived from the Forget Set (e.g., are they corrected versions of the same rumors, or new data about the same entities?).\n\n- Whether the Retain Set is revisited or frozen during relearning, and how the model’s stability on it is assessed.\n\n- The temporal or procedural link between unlearning and relearning phases — i.e., whether the model is incrementally trained on new data or simply fine-tuned again.\n\n- The paper has limited novelty. Selective unlearning has been explored in previous multimodal unlearning datasets [1,2]\n\n- Continual learning as defined is the paper is essentially the finetuning attack against unlearning and safety methods that previous works have explored [3, 1].\n\n- The domain of the dataset is very niche and the findings may or may not generalize across domains.\n\n[1] Patil, Vaidehi, et al. \"Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation.\" Transactions on Machine Learning Research.\n\n[2] Liu, Zheyuan, et al. \"Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench.\" Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). 2025.\n\n[3] Qi, Xiangyu, et al. \"Safety Alignment Should be Made More Than Just a Few Tokens Deep.\" The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "- Why does the continual learning set be a part of the dataset? It can be any other dataset, right? Is there a reason for the way it is designed?\n- Is there a difference between the continual learning setting proposed in the paper and finetuning attacks proposed in previous papers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9GiElYJABq", "forum": "F3LWfwNOOC", "replyto": "F3LWfwNOOC", "signatures": ["ICLR.cc/2026/Conference/Submission4663/Reviewer_TYug"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4663/Reviewer_TYug"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762201870841, "cdate": 1762201870841, "tmdate": 1762917497906, "mdate": 1762917497906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}