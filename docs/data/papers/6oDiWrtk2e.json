{"id": "6oDiWrtk2e", "number": 574, "cdate": 1756749035455, "mdate": 1759898252628, "content": {"title": "Generative Simulation for Dexterous Hands", "abstract": "Data scarcity remains a fundamental bottleneck for embodied intelligence. \nExisting approaches use large language models (LLMs) to automate gripper‑based simulation generation, but they transfer poorly to dexterous manipulation, which demands more specialized environment design. Meanwhile, dexterous manipulation tasks are inherently more difficult due to their higher degrees of freedom. Massively generating feasible and trainable dexterous hand tasks remains an open challenge. To this end, we present **GenDexHand**, a *generative simulation pipeline* that autonomously produces diverse robotic tasks and environments for dexterous manipulation. **GenDexHand** introduces a closed‑loop refinement process that adjusts object placements and scales based on vision‑language model (VLM) feedback, substantially improving the average quality of generated environments. Each task is further decomposed into sub‑tasks to enable sequential reinforcement learning, reducing training time and increasing success rates.\nOur work provides a viable path toward scalable training of diverse dexterous hand behaviors in embodied intelligence by offering a simulation-based solution to synthetic data generation. Our anonymous website: https://sites.google.com/view/gendexhand.", "tldr": "GenDexHand is a generative pipeline for dexterous hand tasks that combines LLM/VLM refinement, motion planning, DoF constraints, and subtask decomposition to generate scalable, high-quality trajectory data.", "keywords": ["Robotics;Embodied AI;Generative Simulation;Foundation Model;"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/779da69a611267b014cfab764442795377e81f59.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a generative simulation pipeline to produce robotic tasks and environments for dexterous manipulation. It consists of three stages: (i) task proposal and environment generation (using Claude Sonnet 4.0 and assets sampled from DexYCB, RoboTwin/Robotwin, PartNet-Mobility, (ii) multimodal large language model refinement (using Gemini Pro 2.5 to explicitly adjust object size, placement, andorientation), and (iii) policy generation (using motion planning + RL)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The idea is interesting and new.\n- The generative pipeline design seems solid.\n- paper is well written and well structured. the examples given in the paper are easy to follow and the supplementary materials provide quite a lot details."}, "weaknesses": {"value": "- My biggest concern is the efficiency and effectiveness of the generative method in terms of sim2real. The authors did not provide any sim2real experiments to evaluate the quality of their generated data.\n- The experiments only use a small set of tasks. \n- Figure 2 caption description is not consistent with the previous statement. It says the process consists of four stages, in which it counts environment proposal and generation as two separate stages, whereas in the introduction section, it claims the pipeline consists of three stages and counts environment proposal and generation as one stage."}, "questions": {"value": "- Does the RL policy need to be retrained for every task generated? or the RL policy can be trained on one/several subtasks and generalize across tasks?\n- How many hours does it take to generate X samples on Y device?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Z8KW1tzkGu", "forum": "6oDiWrtk2e", "replyto": "6oDiWrtk2e", "signatures": ["ICLR.cc/2026/Conference/Submission574/Reviewer_B3uT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission574/Reviewer_B3uT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760995220715, "cdate": 1760995220715, "tmdate": 1762915551095, "mdate": 1762915551095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a generative simulation pipeline for dexterous hand manipulation. It has several stages—task proposal and environment generation, MLLM refinement, and policy generation, with designs including closed-loop MLLM-driven scene adjustment, subtask decomposition, and hybrid motion planning/reinforcement learning (RL) for policy training. Experiments show it can generate physically plausible tasks and achieves a 53.4% average improvement in task success rate compared to baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The entire pipeline appears to be feasible.\n2. The paper is well-structured and clearly written."}, "weaknesses": {"value": "1. The work represents only an incremental improvement over existing gripper-based data generation approaches [1,2] and lacks novelty.\n\n2. Most experiments in the paper do not actually require a dexterous hand — the tasks can largely be accomplished with a simple gripper, revealing a lack of truly dexterous manipulation tasks. Only a in-hand manipulation task truly needs dexterous hand, however this task don't need this pipeline actually, because a lot of previous works have done it well. \n\n3. The provided video demonstrations are short and feature relatively simple tasks, lacking examples of complex or long-horizon manipulation.\n\n4. The work lacks the results of imitation learning experiments trained on its data. The collected data needs to be validated for its effectiveness in training autonomous policies — otherwise, the dataset itself holds limited practical significance.\n\n5. Due to the absence of real-world robot experiments, the authors fail to demonstrate the practical usefulness of the proposed pipeline for real dexterous robotic manipulation.\n\n[1] GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs\n\n[2] RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation"}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xX7zv0tpBw", "forum": "6oDiWrtk2e", "replyto": "6oDiWrtk2e", "signatures": ["ICLR.cc/2026/Conference/Submission574/Reviewer_DQ93"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission574/Reviewer_DQ93"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761481452481, "cdate": 1761481452481, "tmdate": 1762915550827, "mdate": 1762915550827, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a GenDexHand, a simulation framework to generate tasks and data, tailored specifically for dextrous manipulation tasks. The use LLMs to generate tasks, MLLMs to refine them, and they benchmark various methods to generate data for these tasks. While the ideas are sound and experiments are promising, there are several missing details in the paper about the scope of the benchmark, and experiments are sparse. Please see comments below for additional details."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- the prompts to generate tasks and data are elaborate and well-thought out. they are clearly laid out in the appendix, making it transparent how the system works.\n- using MMLMs to refine tasks is a practical idea, and the authors show specific examples how this is applied in practice to obtain more realistic tasks."}, "weaknesses": {"value": "- The experiment to quantify task diversity via cosine similarities of the text embeddings is just one specific metric, but is not a holistic way to measure task diversity. For example, how many assets are incorporated? How many skill families are present, compared to other works? What is the distribution of the number of stages per task? How many environments are present? This information is missing in the current manuscript.\n- The experiments only feature three tasks (figure 4), and the tasks are not very diverse (two are basic pick-place tasks). I presume there are more tasks that this framework can generate, but the main text does not mention the full scope of tasks.\n- The paper presents a simulation framework with the goal of generating diverse data, presumably to build real-world robot agents, but there are no experiments or discussion about how to use the generated data for transfer to real world environments and tasks."}, "questions": {"value": "- How many tasks in total are generated by this simulation framework? What are the skill families present?\n- It's unclear why without subtask decomposition, the episode length is 400 steps, but with subtask decomposition the episode length is 200 steps. Is this a fair comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BTYLkpph6C", "forum": "6oDiWrtk2e", "replyto": "6oDiWrtk2e", "signatures": ["ICLR.cc/2026/Conference/Submission574/Reviewer_MgvZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission574/Reviewer_MgvZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971790740, "cdate": 1761971790740, "tmdate": 1762915550686, "mdate": 1762915550686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents GenDexHand, which uses VLMs to automate environment and data generation in simulation for dexterous hand manipulation tasks. The main contributions are:  \n1. It focuses on dexterous hand manipulation.  \n2. It uses VLMs not only to create tasks but also to check and refine them.  \n3. It studies policy learning for the proposed tasks, including task decomposition and motion planning integration.\nExperiments are done on several simulation tasks, and task diversity is reported."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The writing is clear and easy to follow.  \nIt is good to explore using VLMs for dexterous task design and simulation setup.  \nIt is also good to study reinforcement learning, frozen joints, and motion planning."}, "weaknesses": {"value": "- The main weakness is that there are no real-world experiments. This means the paper cannot show if the simulation is actually useful in real applications, which makes it less convincing for manipulation research.  \n- Another weakness is that the idea of using VLMs for simulation setup is no longer new (unlike GenSim or RoboGen). Many researchers now question the value of VLM-generated simulations. Reviewers may expect a solid and practical simulation benchmark such as THOR or RoboCasa. The authors are encouraged to build a far more diverse and convincing VLM-based simulation benchmark that includes extensive real-world validation. For the tasks in this paper, setting them up manually would be easier and more controllable than using prompts.  \n- From the policy learning point of view, compared to recent studies, it is hard to say that subtask decomposition, motion planning, or freezing degrees of freedom are contributions. If the authors want to highlight policy learning, they should provide more insights, compare with state-of-the-art methods and include real-world demonstrations. \n- The results in Table 1 are also not convincing, and more experiments are recommended."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6J6mGkfLkf", "forum": "6oDiWrtk2e", "replyto": "6oDiWrtk2e", "signatures": ["ICLR.cc/2026/Conference/Submission574/Reviewer_NbQh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission574/Reviewer_NbQh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762034799671, "cdate": 1762034799671, "tmdate": 1762915550030, "mdate": 1762915550030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}