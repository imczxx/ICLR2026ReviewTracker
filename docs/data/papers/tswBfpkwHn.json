{"id": "tswBfpkwHn", "number": 7901, "cdate": 1758042154425, "mdate": 1759897823481, "content": {"title": "Can Mamba Learn In Context with Outliers? A Theoretical Generalization Analysis", "abstract": "The Mamba model has gained significant attention for its computational advantages over Transformer-based models, while achieving comparable performance across a wide range of language tasks. Like Transformers, Mamba exhibits in-context learning (ICL) capabilities, i.e.,  making predictions for new tasks based on a prompt containing input-label pairs and a query, without requiring fine-tuning.\nDespite its empirical success, the theoretical understanding of Mamba remains limited, largely due to the nonlinearity introduced by its gating mechanism. To the best of our knowledge, this paper presents the first theoretical analysis of the training dynamics of a one-layer Mamba model, which consists of a linear attention component followed by a nonlinear gating layer, and its ICL generalization on unseen binary classification tasks, even when the prompt includes additive outliers. Our analysis shows that Mamba leverages the linear attention layer to select informative context examples and uses the nonlinear gating layer to suppress the influence of outliers. By establishing and comparing to the analysis of linear Transformers under the same setting, we show that although Mamba may require more training iterations to converge, it maintains accurate predictions even when the proportion of outliers exceeds the threshold that a linear Transformer can tolerate. These theoretical findings are supported by empirical experiments.", "tldr": "This paper provide the first theoretical analysis of the training dynamics of a one-layer Mamba model and characterizes its in-context learning generaization ability with additive outliers in the prompt", "keywords": ["Mamba", "in-context learning", "Transformer", "generalization", "training dynamics", "deep learning theory"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4ead1079944dfe3146c82ef818a885e4d63395b6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper provides a theoretical study of in-context learning (ICL) capabilities, focusing on a one-layer Mamba model, which consists of linear attention plus a non-linear gating layer. Focusing on synthetic binary classification prompts with additive outliers, the authors prove convergence and sample-complexity guarantees, and provide conditions under which the model generalizes to unseen tasks, and remains robust to distribution-shifted outliers. Mainly, the bound permits a test outlier fraction value that is more flexible than a linear Transformer, capped at 1/2, which the authors attribute to the nonlinear gating layer that suppresses corrupted examples, and emphasizes pattern-matching entries. Empirical demonstrations illustrate the main theorems."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Clear theoretical results and comparison with Mamba vs. Linear Transformer. This strengthens the paper's analysis that gating helps in ignoring noisy examples.\n- The theoretical results match the synthetic experiments, such as Mamba's tolerance to many outliers, and sensitivity to outliers near the query.\n- More specifically, the paper includes the analysis of comparative training bounds and robustness regime.\n- The synthetic generation setup is fully specified (i.e. the parameters) and the paper discusses the limitations in conclusions."}, "weaknesses": {"value": "The weaknesses I will address are intertwined with questions that I have regarding this work. \n- Since the paper points out the limitation of single-head linear attention Transformer, i.e. the tolerance parameter alpha having to be less than 1/2, a brief discussion, even if not supported by theoretical results, on whether more realistic Transformers would suffer less from this constraint. In other words, would having multiple heads help mitigate this issue?\n- The manuscript will be much easier to read and understand if takeaway messages for each figure are listed in the captions."}, "questions": {"value": "- It seems form Table 1 that closest to query (CQ) hurts Mamba's performance substantially. I think this result intuitively makes sense if we take the RNN perspective of understanding Mamba, which could mean that while gating layers can suppress outliers, it needs to see sufficient number of examples before being able to do so. In this regard, (i) what could be a possible mitigation strategy to this? (ii) This also could suggest that Mamba is strongly biased against the first few samples that it has seen, learns the underlying function, and uses that for the rest of the in-context examples. First, I would like to double check with the authors if my understanding is correct. If it is, I am wondering if this could be a reason that Mamba performs better when alpha is larger than 1/2, and even closer to 1. \n- In the regard of the first question, it would be interesting to see what the number 78% for the Linear Transformer means. Is it trying to do fit a least squares function with the presence of noise? If such functions exist, does that match the empirical performance of 78% we are seeing, regardless of the positions of the queries?\n\nI believe the paper is solid, but there could be much more interesting discussions that can happen around these results. I would be inclined to raise the score if we see some of them during the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XcqUJh4pgW", "forum": "tswBfpkwHn", "replyto": "tswBfpkwHn", "signatures": ["ICLR.cc/2026/Conference/Submission7901/Reviewer_2qkh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7901/Reviewer_2qkh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977182538, "cdate": 1761977182538, "tmdate": 1762919930862, "mdate": 1762919930862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the first theoretical analysis of in-context learning (ICL) in Mamba. Specifically, the authors study a one-layer Mamba with a linear attention component followed by a nonlinear gating mechanism and analyze its ability to perform ICL on binary classification tasks—even when prompts contain additive outliers.\nThe paper’s main contributions are:\n1. It provides quantitative convergence and generalization guarantees for Mamba trained on prompts with outliers, showing robustness even when nearly all examples are corrupted.\n2. It theoretically compares Mamba to linear Transformers, proving that Mamba can generalize in the presence of a higher fraction of outliers.\n3. It characterizes the mechanistic role of Mamba’s components: linear attention selects examples sharing relevant patterns with the query, while the gating mechanism suppresses outliers and emphasizes nearby examples.\n\nSynthetic experiments support the theory by showing that Mamba achieves lower classification error than linear Transformers under various outlier corruption schemes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Originality:\nThis work is among the first to give a theoretical treatment of Mamba’s ICL mechanism, especially under the presence of outliers. Previous ICL analyses primarily focus on Transformers. The extension to Mamba—given its nonlinear gating and state-space formulation—is novel and nontrivial.\n\nTechnical quality:\nThe paper presents well-structured theorems (Theorems 1–4) detailing convergence, sample complexity, and robustness. The proofs seem grounded in prior analytical frameworks for Transformers (Li et al., 2024a,b) but adapted to handle the additional nonlinearity of gating. The comparison to linear Transformers provides useful insights into the tradeoff between convergence speed and robustness.\n\nSignificance:\nUnderstanding Mamba’s ICL properties is highly relevant as Mamba-based models gain traction as efficient alternatives to Transformers. The result that Mamba tolerates a higher fraction of outliers could motivate more robust sequence modeling approaches in practice.\n\nClarity and organization:\nThe paper is generally well-written and logically organized."}, "weaknesses": {"value": "1. The task and outlier definition seem not natural and general. This limits the generality of the conclusions. It is unclear whether similar robustness properties would hold for more natural data distributions or real-world text prompts.\n\n2. Several theorems introduce numerous symbols without sufficient intuitive explanation, which makes the results hard to interpret. The meaning of constants such as Θ(·), poly(·), and ranges should be contextualized more clearly.\n\n3. The experiments are purely synthetic and cover only a very limited case. While they match the theory, they provide no evidence that these findings generalize to realistic NLP or vision tasks.\n\n4. Recent empirical work shows that large Transformers can also exhibit robustness to mislabeling or outlier examples in ICL regimes. A discussion or comparison to this line of work is missing.\n\n5. The analysis assumes that “examples close to the query” are beneficial, but if these nearby examples are adversarial or have opposite labels, the gating mechanism could amplify errors instead of mitigating them. This edge case should be acknowledged."}, "questions": {"value": "How would the gating mechanism behave if the nearest examples to the query are misleading or adversarially labeled? Does the exponential decay still guarantee robustness, or could it amplify incorrect patterns?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pUV9wrsc7E", "forum": "tswBfpkwHn", "replyto": "tswBfpkwHn", "signatures": ["ICLR.cc/2026/Conference/Submission7901/Reviewer_v2NB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7901/Reviewer_v2NB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762155829347, "cdate": 1762155829347, "tmdate": 1762919930126, "mdate": 1762919930126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on building theoretical understanding of the Mamba model for its powerful in-context learning capability. According to the results, the authors demonstrate that Mamba leverages the linear attention layer to select informative context examples and uses the nonlinear gating layers to suppress the influence of outliers."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- This paper is the first paper to theoretically understand the in-context capability of Mamba, which is an essential contribution.\n- The paper is well written. \n- The empirical results are good."}, "weaknesses": {"value": "- The paper mainly focuses on the one-layer Mamba model, which cannot be seen as a comprehensive understanding of Mamba. However, this is not a significant drawback due to the complex large models.\n- As a following question, can a model with just one layer achieve the similar capability of large Mamba models, such as in-context learning?\n- The assumptions, which decompose the data into components of relevant and irrelevant parts, in Section 3.2 are interesting. I think such assumptions contribute to the theoretical analyses later. However, I am curious about whether such assumptions work in practice. In other words, can you provide some empirical or simple theoretical results to demonstrate that some assumptions are derived from the real cases?\n- In Remark 4, a comparison between Mamba and the linear Transformer is reported. Specifically, compared to Mamba, the linear Transformer should satisfy some specific conditions for similar performance as Mamba. This is interesting. However, is there any empirical evidence to support the summaries? For example, consider two LLMs with the same architecture and trained with different hyperparameters. Do the empirical evaluations support your theoretical results?\n\n**Minors**:\n- What is $A$ in Lines 130 and 132?\n- Lines 163 & 310, the references have the wrong format."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a2BM6XBeTf", "forum": "tswBfpkwHn", "replyto": "tswBfpkwHn", "signatures": ["ICLR.cc/2026/Conference/Submission7901/Reviewer_1e2F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7901/Reviewer_1e2F"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762158578475, "cdate": 1762158578475, "tmdate": 1762919929538, "mdate": 1762919929538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper shows a one-layer Mamba block can implement in-context learning (ICL) on stylized binary tasks, and its nonlinear gate is the key: linear attention selects helpful examples; the gate suppresses outliers and induces a local bias. Compared to a linear-attention Transformer (same setting), Mamba may train a bit slower but stays accurate under a much higher fraction of corrupted examples—even approaching 100% under their assumptions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The theoretical claims seem to align with empirical evidence (on the high level), e.g., the paper’s core takeaway—Mamba’s gate makes ICL more robust to corrupted prompts than a pure linear-attention Transformer—is directionally consistent with what the community has observed.\n\n- Clear mechanistic story: linear attention aligns to the query’s relevant pattern; gating both suppresses outliers and biases to nearby positions."}, "weaknesses": {"value": "1. The paper studies a stylized binary, pattern-based ICL task where each input contains exactly one relevant and one irrelevant orthogonal pattern of equal norm; labels depend only on the relevant pattern. This is a clean but **unnatural** abstraction for real data. Results derived on this task may not transfer to more general tasks studies in practice. \n\n2. Outlier modeling is also narrow/artificial: Outliers are injected additively, orthogonal to both relevant and irrelevant patterns during training, and at test time are linear combinations of the training-time outlier directions with a positivity constraint.\n\n3. Transformer comparator is a very specific “linear attention” variant (no softmax, multi-heads...). So the headline advantage (“Mamba tolerates higher outlier fractions”) is established against a simplified comparator that may be unrepresentative of modern Transformers. This undermines the breadth of the claim."}, "questions": {"value": "1. The test outlier is a positive combination of train outliers (Condition (11)). How realistic is this in language tasks? What happens for combinations with mixed signs or novel directions?\n\n2. Can you extend beyond binary classification to multiclass or regression within the same framework? Where do the proofs fail?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8vQz25BpCf", "forum": "tswBfpkwHn", "replyto": "tswBfpkwHn", "signatures": ["ICLR.cc/2026/Conference/Submission7901/Reviewer_okLR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7901/Reviewer_okLR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762280243034, "cdate": 1762280243034, "tmdate": 1762919929155, "mdate": 1762919929155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}