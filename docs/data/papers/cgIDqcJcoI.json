{"id": "cgIDqcJcoI", "number": 2285, "cdate": 1757048623194, "mdate": 1763611960232, "content": {"title": "WALT: Web Agents that Learn Tools", "abstract": "Web agents promise to automate complex browser tasks, but current methods remain brittle -- relying on step-by-step UI interactions and heavy LLM reasoning that break under dynamic layouts and long horizons. Humans, by contrast, exploit website-provided functionality through high-level operations like search, filter, and sort. We introduce WALT (Web Agents that Learn Tools), a framework that reverse-engineers latent website functionality into deterministic, callable tools. Rather than hypothesizing ad-hoc skills, WALT exposes robust implementations of automations already designed into websites, spanning discovery (search, filter, sort), communication (post, comment, upvote), and content management (create, edit, delete). Tools abstract away low-level execution: instead of reasoning about how to click and type, agents simply call search(query) or create(listing). This shifts the computational burden from fragile step-by-step reasoning to reliable tool invocation. On VisualWebArena and WebArena, WALT achieves significantly higher success rates with fewer steps and less LLM-dependent reasoning, establishing a robust and generalizable paradigm for browser automation.", "tldr": "Web Agents that Learn Tools autonomously that leads to improved success rate and efficiency", "keywords": ["web agents", "tool use", "LLMs", "agentic reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ddc9a16ac8df304704fcdde41836802599f7915d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The research paper introduces WALT (Web Agents that Learn Tools), a novel framework designed to overcome the brittleness and inefficiency of web agents. The core problem is that existing agents rely on step-by-step UI interactions, which frequently fail on dynamic websites or over long task horizons. In contrast, WALT proposes a paradigm shift from learning agent-centric \"skills\" to reverse-engineering a website's functionalities—spanning discovery, communication, and content management—into reusable \"tools\". The methodology follow the demonstrate-generate-validate loop, where a browser agent first demonstrates a function, a tool-generation agent then maps the interaction trace to a structured tool, and a test agent rigorously validates it offline. Optimize multi-step UI sequences into single, robust URL manipulations. This abstraction change the agent's role from a low-level manipulator to a high-level planner. \nOn the VisualWebArena and WebArena benchmarks, WALT achieve (52.9% and 51%, respectively) and fewer action than previous methods, demonstrating a more robust approach to browser automation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Shift from inducing brittle, low-level click/browse action to discovering environment-centric \"tools.\" Address the cause of fragility in web automation. \n2. Change some of the UI interactions to direct URL manipulations, which can directly reduce the long-horizon UI interaction with better robustness.\n3. Achieves state-of-the-art performance on two challenging benchmarks, with comprehensive ablation studies on gpt-4.1, gemini-2.5-flash and gpt5-mini that convincingly attribute these gains to the tool-based framework itself, rather than the powerful LLM."}, "weaknesses": {"value": "1. Significant practical limitations on scalability and long-term maintenance. The discovery process need upfront computational and time cost. It is impractical to apply at the scale of the entire web.\n2. It require the server store all the website which have explored before. Also, if the some pre-extract website changed. The agent still need update the tools. Still need a efficient way to detect the website change and update the knowledge.\n3. The paper proposed that convert several UI action into one URL operation. It is hard to gurantee all action can change to URL operation. The methods lack some generalization. \n4. The evaluation is limit to a small number of research benchmarks. The framework's effectiveness against real-world adversarial challenges, the sophisticated anti-automation measures in real world still can be improved. \n\nThe main concerns lie in the generalizability, cost-effectiveness, and long-term maintainance of the WALT approach in production environments beyond simulated academic settings."}, "questions": {"value": "When real use want to delegate a task on general websites, it is hard to predict the performance on unseen website. If focus on a small range of websites, some prepopulate specific api rules in prompt/tools may generate better performance. Hope the author can share some experiments or analysis about the WALT test on any real world senoria."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nVQE7oaKbF", "forum": "cgIDqcJcoI", "replyto": "cgIDqcJcoI", "signatures": ["ICLR.cc/2026/Conference/Submission2285/Reviewer_FkiG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2285/Reviewer_FkiG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2285/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760769898374, "cdate": 1760769898374, "tmdate": 1762916176324, "mdate": 1762916176324, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response to all reviewers (1/2)"}, "comment": {"value": "We thank all reviewers for their thoughtful and constructive feedback. We appreciate the recognition of WALT's conceptual novelty (LBGY, FkiG) and strong empirical results (all reviewers). The primary concern across reviews is **generalizability to real-world websites beyond simulated benchmarks**. We address this directly with new experiments, along with clarifications on novelty, costs, and presentation improvements.\n\n---\n\n### Real-World Validation: Online-Mind2Web Benchmark\n\n**We evaluated WALT on Online-Mind2Web**, a benchmark comprising **139 real-world websites** spanning e-commerce, healthcare, travel, education, and government domains (Target, GameStop, Healthgrades, Coursera, IRS, etc.). This directly addresses concerns about WALT's generalization to real-world websites, in the presence of CAPTCHAs, dynamic layouts, and production environments. \n\nWe first use WALT to discover tools on the 139 websites (2-3 per site to keep costs reasonable), and then provide these to the agent at runtime.\n\n**Results breakdown:**\n- **WALT learns useful tools**: WALT autonomously discovers **252** validated tools on Online-Mind2Web, and successfully completes (i.e. finishes without environment errors) 238/300 tasks. Compared to a controlled tool-free baseline, WALT:\n   - **Improves success rate**: by **20.5\\%** (42.9&rarr;51.2) \n   - **Improves efficiency**: using **23.3\\%** fewer steps on average (10.8&rarr;8.2).\n- **27 tasks show \"tool wins\"**: cases where baseline failed but WALT used learned tools to succeed, spanning 24 different websites (examples in Fig. 5 and Appendix).\n- **Real-world limitations** (CcSC, FkiG): 62 tasks fail either due to bot detection (35) or timeout errors (27). In total, 22 websites are *completely* untestable due to strong anti-bot measures (*e.g.*, Apartments.com, Cars.com, UPS.com), illustrating the messy reality of real-world web automation. Some of these may be circumvented with sophisticated stealth strategies but is outside the scope of our work.\n    \n**Complementarity of simulated and real benchmarks:**\nOnline-Mind2Web validates real-world generalization but is limited to **read-only tasks** (browsing, search), as authenticated operations would be unsafe. **WebArena/VisualWebArena enable the full task spectrum**: content management (create/edit/delete with authentication), communication (post, upvote), and complex authenticated workflows. WALT discovers bespoke tools for these operations (e.g., `create_listing`, `post_comment`) – functionality Online-Mind2Web cannot safely test. The benchmarks are complementary: simulated for task diversity, real-world for robustness.\n\n**Comparison to Claude Computer Use (yMR2):** To address the reviewer's concern, we evaluate WALT offline on Online-Mind2Web and compare against Claude Computer Use's **official leaderboard results**: promisingly, we find that WALT achieves near-parity in performance (-0.5\\% lower success rate, absolute), *without any specialized end-to-end training for computer use tasks*. This demonstrates that tool discovery can rival specialized model training—a more generalizable and cost-effective paradigm.\n\n---\n\n### Novelty: WALT vs Prior \"Skills\" and APIs\n\n**Core insight:** Humans use **website-provided functionality** (search, filters, forms)—robust by design. Prior \"skill\" approaches solve an artificial problem: they induce ad-hoc patterns from agent behavior rather than leveraging this infrastructure.\n\n**WALT's paradigm:** Build robust and efficient tools that exploit **website-provided** functionality.\n\n|  | SkillWeaver / AWM / ASI | Hybrid Agent | **WALT** |\n|--------|------------------------|--------------|----------|\n| **Approach** | Agent-induced from successful trajectories | Curated API docs | **Systematic exploration of website functionality** |\n| **Consequence** | Codify existing behavior | Reliant on human-written docs | **Reverse-engineer site infrastructure** |\n| **Implementation** | Brittle UI action replay | API calls (when available) | **URL promotion + validated schemas + fallbacks** |\n| **Validation** | Unit tests on synthetic inputs | N/A | **Stress-testing on pre-vetted inputs** |\n\n**Key differences:**\n1. WALT discovers what *websites provide*, not what *agents did* - mirroring human web use\n2. No documentation required; autonomous reverse-engineering\n3. Optimized for robustness via schema validation, selector stabilization, URL inference\n\nThese distinctions mark a paradigm shift from mining agent behavior to surfacing site functionality."}}, "id": "3zf7TEAAhb", "forum": "cgIDqcJcoI", "replyto": "cgIDqcJcoI", "signatures": ["ICLR.cc/2026/Conference/Submission2285/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2285/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2285/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763607017522, "cdate": 1763607017522, "tmdate": 1763607017522, "mdate": 1763607017522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents WALT, a framework for constructing web “tools” from the functional elements of websites. The central idea is to enable an agent to broadly explore and interact with a website, identify its reusable functionalities (such as search, filtering, or posting), and abstract them into high-level tools that can be invoked directly in subsequent tasks. These tools allow the agent to operate at a more semantic level, avoiding fragile, step-by-step UI manipulations. Experiments on the VisualWebArena and WebArena benchmarks demonstrate that WALT achieves substantial improvements in both success rate and execution efficiency compared with previous web-agent baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The core idea is novel and intuitive and abstraction is conceptually sound and potentially impactful.\n2. The empirical results show consistent improvement over prior methods across two benchmarks."}, "weaknesses": {"value": "1. The paper is difficult to follow, particularly in the method section. Many paragraphs are either overly verbose or lack essential details, making it challenging to reconstruct the full workflow. Logical connections between subsections are weak, and the role of each module is not clearly articulated. For example, the implementation and workflow of B_browser, which generates demonstrations, are insufficiently described.\n2. The proposed approach requires significant offline effort to explore and build a tool set for each website. And these tools are effective only for one website. If the websites change, or when the agent encounters unseen sites, this method does not work.\n3. While the offline stage costs a lot, the experiment section does not analyze the time cost, success rate, or resource consumption of tool construction.\n4. The paper does not include experiments that directly evaluate the Tool Construction procedure itself (e.g., URL promotion, schema synthesis, validation loops). The current experiments merely show that “using tools” improves results but do not demonstrate that the proposed construction method is necessary or superior to simpler alternatives. There is no analysis of whether this complex construction pipeline is justified in terms of accuracy, efficiency, or cost.\n5. The labels of Figure 4 overlap and the text is unreadable."}, "questions": {"value": "1. If the system detects or constructs a very large number of tools, how does it manage them efficiently? Would the growing tool set cause degradation in planning or selection performance?\n2. It remains unclear how this method was used for the benchmark experiments. Were the same websites used in both the construction and evaluation phases? If so, could there be potential leakage or overfitting to specific site structures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5IuOIGhsYq", "forum": "cgIDqcJcoI", "replyto": "cgIDqcJcoI", "signatures": ["ICLR.cc/2026/Conference/Submission2285/Reviewer_CcSC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2285/Reviewer_CcSC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2285/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957108777, "cdate": 1761957108777, "tmdate": 1762916176129, "mdate": 1762916176129, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes WALT, a novel framework that reverse-engineers website functionalities into deterministic, invocable tools. This abstract away frafile, step-by-step UI interactions, making browser automation more reliable. One core contribution is to replace brittle click-based sequences with robust URL manipulations through API reverseengineering. Evaluation was run on VisualWebArena and WebAreana. WALT achieves state-of-the-art success rates with fewer steps than the baselines."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- **Originality:** WALT is novel in that it reframing browser automation as demonstrate-generate-validate high-level tools corresponding to website-provided functionalities, which is intuitive and robust. \n- **Significance:** WALT shows SOTA performance on the two evaluaiton benchmarks, with higher efficiency with a controlled baseline approach without tools [Figure 3].\n- **Robustness and generalizability:** Tools span multiple categories (search, filter, content creation, communication) and remain reliable under diverse layouts.\n- **Great qualitatitive analysis:** Detailed analysis and observation of composition, success rates, and action type of discovered tools [Section 4.5]."}, "weaknesses": {"value": "- **Cost not quantified.** The paper does not specify the cost of offline exploration/validation. Please report discovery time distributions and other costs per validated tool.\n- **Generalizability / Practicality beyond benchmarks.** WALT's generalization to live, frequently changing websites (e.g., with CAPTCHA or A/B testing) remains untested; a small study on production sandboxes or WorkArena++ tasks would be better.\n- **Presentation**\n  - Citation format: Line 299"}, "questions": {"value": "1. Why does the ablation study focus on a single split (VisualWebArena Classifieds) but not on other splits or WebArena?\n2. There is a large focus on promoting eligible UI chains to URL operations. What is the frequency of failure for URL promotion or schema inference? How does WALT handle this?\n3. **Fairness of comparison.** Some baselines like Claude Computer-Use Agent may operate with different observation spaces/limits/paradigm. How do you ensure comparison with baselines is fair with no hidden advantages for WALT?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H6pOiRv6ZV", "forum": "cgIDqcJcoI", "replyto": "cgIDqcJcoI", "signatures": ["ICLR.cc/2026/Conference/Submission2285/Reviewer_yMR2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2285/Reviewer_yMR2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2285/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974458225, "cdate": 1761974458225, "tmdate": 1762916175771, "mdate": 1762916175771, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces WALT (Web Agents that Learn Tools), a new framework designed to make web agents more robust and efficient. It tackles a core problem: current web agents are \"brittle\" because they rely on step-by-step UI interactions (e.g., click, type) and heavy LLM reasoning for every single action. This approach easily fails when website layouts change or tasks become complex.\n\nWALT’s solution is inspired by how humans browse the web. Instead of thinking about individual clicks, humans use high-level functions a website provides, like \"search,\" \"filter,\" or \"sort\". WALT is a framework that reverse-engineers a website's built-in functionality into a set of reusable, callable \"tools\".\n\nFor example, instead of an agent executing a long, fragile sequence of actions to find the \"cheapest blue kayak,\" the WALT agent can invoke a single, robust tool it learned for that site, such as search(query='kayak', category='Boats', sort_by='price', order='asc'). This \"abstracts away low-level execution\" and shifts the agent's job from fragile, step-by-step reasoning to high-level planning and reliable tool invocation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  It proposes a new paradigm for web automation that shifts from brittle, low-level UI sequences to robust, high-level tool invocation.\n\n2. It introduces a \"demonstrate-generate-validate\" loop to autonomously create these tools.  A browser agent explores the site to demonstrate its functionality (e.g., using search with all its filters). A \"tool generation agent\" analyzes these traces to create a structured tool, prioritizing robust URL manipulation (API reverse-engineering) over simple UI replays. A test agent verifies that the newly created tool works correctly before it is registered for use.\n\n3. WALT achieves significantly higher success rates on the Visual WebArena (52.9%) and WebArena (51%) benchmarks, outperforming prior methods.\n\n4. By abstracting complex actions into single tool calls, WALT completes tasks using fewer steps and less LLM-dependent reasoning."}, "weaknesses": {"value": "1. The paper frames WALT as a paradigm shift from “skills” to “tools,” but the distinction is not always clear. Prior work such as SkillWeaver (Zheng et al., 2025) and Hybrid Agent (Song et al., 2024) already explored higher-level abstractions (skills, APIs) that reduce reliance on brittle UI actions. WALT’s contribution risks being seen as a rebranding of “API induction” or “workflow abstraction” unless the conceptual boundary is sharpened.\n\n2. While ablations are provided, they mostly show aggregate improvements (e.g., +2.6% from multimodal DOM parsing). The analysis does not deeply isolate why certain components matter or how they interact. For example, how much of the gain comes from URL promotion vs. schema validation vs. fallback strategies?\n\n3. WALT excels at deterministic, schema-driven tasks (search, sort, CRUD operations) but struggles with compound reasoning tasks (e.g., “find the most expensive boat with an image showing it on water and then rate it”). These failures highlight that WALT’s abstraction layer may not handle tasks requiring joint optimization across structured and perceptual constraints."}, "questions": {"value": "Evaluation is limited to WebArena and VisualWebArena, which are simulated benchmarks. While these are standard, they may not capture the full variability of real-world websites (CAPTCHAs, A/B testing, anti-bot measures, dynamic content). The paper acknowledges this but does not empirically test robustness outside controlled environments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PrCHcwEDNo", "forum": "cgIDqcJcoI", "replyto": "cgIDqcJcoI", "signatures": ["ICLR.cc/2026/Conference/Submission2285/Reviewer_LBGY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2285/Reviewer_LBGY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2285/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762342921789, "cdate": 1762342921789, "tmdate": 1762916175507, "mdate": 1762916175507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}