{"id": "BcxM6dZiXc", "number": 9738, "cdate": 1758137200591, "mdate": 1763624311629, "content": {"title": "A Tale of LLMs and Induced Small Proxies: Scalable Agents for Knowledge Mining", "abstract": "At the core of Deep Research is knowledge mining, the task of extracting structured information from massive unstructured text in response to user instructions.\nLarge language models (LLMs) excel at interpreting such instructions but are prohibitively expensive to deploy at scale, while traditional pipelines of classifiers and extractors remain efficient yet brittle and unable to generalize to new tasks.\nWe introduce Falconer, a collaborative framework that combines the agentic reasoning of LLMs with lightweight proxy models for scalable knowledge mining.\nIn Falconer, LLMs act _as planners_, decomposing user instructions into executable pipelines, and _as annotators_, generating supervision to train a compact proxy. \nThe framework unifies classification and extraction into two atomic operations, _get\\_label_ and _get\\_span_, enabling a single instruction-following model to replace multiple task-specific components. \nTo evaluate the consistency between proxy models incubated by Falconer and annotations provided by humans and large models, we construct new benchmarks covering both planning and end-to-end execution. \nExperiments show that Falconer closely matches state-of-the-art LLMs in instruction-following accuracy while reducing inference cost by up to 90\\% and accelerating large-scale knowledge mining by more than 20x, offering an efficient and scalable foundation for Deep Research.", "tldr": "", "keywords": ["Knowledge Mining", "Large Language Models", "Agents"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/f4e0d67b35dfc9462cd73ec0d91664b912900ffd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Falconer, a framework for scalable knowledge mining that addresses the trade-off between the high cost of LLMs and the brittleness of traditional IE pipelines. Falconer employs a powerful LLM in two key roles: as a \"planner\" that decomposes high-level user instructions into a sequence of executable steps, and as an \"annotator\" that generates supervision data from a small corpus sample. These steps are then executed by a lightweight, instruction-following \"proxy\" model. The framework elegantly unifies diverse knowledge mining subtasks (classification, extraction) into two atomic primitives, get_label and get_span. The authors create new benchmarks to evaluate this approach and demonstrate that Falconer can match or even exceed the performance of state-of-the-art LLMs like GPT-4o on end-to-end tasks, while reducing inference costs by up to 90% and accelerating throughput by over 20x."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper seems to address a critical, real-world bottleneck in applied AI: the prohibitive cost and latency of using flagship LLMs for large-scale data processing.\n\n- The experimental validation may be another major strength. The authors test their system across a wide variety of datasets and task types, using both ground-truth labels and LLM-as-a-judge setups."}, "weaknesses": {"value": "- Limited Generality and Reliance on Heuristics: The framework's primary strength—its efficiency—seems to stem from its highly specialized design, which may limit its broader applicability. \n- Specialization for Extractive Tasks: The entire system is built upon two atomic primitives: get_label and get_span. This design makes Falconer a highly optimized solution for extractive and classification-based knowledge mining. However, it inherently restricts its use for other important NLP tasks, particularly generative ones like text summarization, translation, or complex reasoning QA that cannot be decomposed into simple span extractions. The paper should perhaps more explicitly frame Falconer as a specialized framework for its target domain, rather than a general-purpose alternative to LLM agents.\n- Generalizability beyond cuckoo: The success of the proxy model, particularly the fascinating \"arising abilities\" phenomenon, is strongly linked to the Cuckoo model and its specific pre-training paradigm. This raises the question of how generalizable the Falconer framework is. Would the framework be as effective with other open-source small language models (e.g., Phi-3, Gemma, Qwen3-0.6B)?"}, "questions": {"value": "Please see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SiHpYynvaJ", "forum": "BcxM6dZiXc", "replyto": "BcxM6dZiXc", "signatures": ["ICLR.cc/2026/Conference/Submission9738/Reviewer_Y8g4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9738/Reviewer_Y8g4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760595912063, "cdate": 1760595912063, "tmdate": 1762921234021, "mdate": 1762921234021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "lodtW43PjZ", "forum": "BcxM6dZiXc", "replyto": "BcxM6dZiXc", "signatures": ["ICLR.cc/2026/Conference/Submission9738/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9738/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763624311040, "cdate": 1763624311040, "tmdate": 1763624311040, "mdate": 1763624311040, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents Falconer, a framework that coordinates multiple agents—including LLMs and lightweight proxy models—for a set of information extraction tasks. Empirical studies are conducted using RoBERTa-large as a baseline on both human-labeled benchmarks and GPT-labeled datasets.\n\nMy concerns include:\n\n1. Limited technical novelty.\n\nThe proposed framework largely builds upon existing paradigms of multi-agent coordination and LLM-based workflow design (e.g., [1] and [2]). The use of powerful closed-source LLMs (e.g., GPT-4.1) as both a planner (for translating natural-language instructions into executable operations) and as an annotator (for generating labels to fine-tune a lightweight model) has been a common practice in a lot of agent projects.\n\nMoreover, the proxy model Cuckoo is open-sourced, and the technical contribution primarily lies in distilling GPT-4.1 into this small model. While practical, this process does not appear to introduce fundamentally new mechanisms or theoretical insights.\n\n2. Unconvincing empirical studies.\n\nThe authors use RoBERTa-large as the only baseline, which is relatively outdated. Given the wide availability of powerful and compact open-source models (e.g., Qwen2.5-0.5B-Instruct), this choice weakens the empirical comparison. Since most text-mining tasks (e.g., NER, RE) have already been effectively addressed by recent LLMs, it is not compelling to demonstrate improvements only over RoBERTa. It is also puzzling that RoBERTa achieves 0 accuracy on some tasks under 64- and 512-sample settings. Was the model fine-tuned on the same data as Falconer? If not, the comparison may be unfair or misleading.\n\nOverall, the work lacks both technical novelty and compelling empirical resutls. The proposed approach appears incremental and primarily implements existing multi-agent workflow concepts without introducing substantial new insights.\n\n[1] Sirui Hong et al., MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework\n\n[2] Jian Guan et al., AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "a multi-agent implemetation on text mining tasks"}, "weaknesses": {"value": "see my comments in Summary"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PgTa0cmR7e", "forum": "BcxM6dZiXc", "replyto": "BcxM6dZiXc", "signatures": ["ICLR.cc/2026/Conference/Submission9738/Reviewer_1m17"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9738/Reviewer_1m17"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761613893137, "cdate": 1761613893137, "tmdate": 1762921233635, "mdate": 1762921233635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework where LLMs are used as planners and annotators for a knowledge mining task. They introduce two basic operators for classification and entity extraction that are defined as meta operators and train a meta model that can be tuned to perform data mining tasks across various tasks.  As part of the model building, they also build an instruction following benchmark for knowledge mining, which is used for building their meta model.  The proposed method is a performant cost cost-effective alternative to costly LLMs to perform full task vs task-specific models, which do not generalize across various tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Approach of utilizing frontier models with ICL examples for planner and building a meta model to do actual data mining is an interesting approach with good cost savings while maintaining the overall performance. \nEmpirical results showing the effectiveness of the approach are extensive."}, "weaknesses": {"value": "How does the approach compare to any task specific fine tuned models? I don’t see any comments on that? Are the gains significant with respect to those models to adapt this approach in practical settings?"}, "questions": {"value": "Please check the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qIATBIWSOL", "forum": "BcxM6dZiXc", "replyto": "BcxM6dZiXc", "signatures": ["ICLR.cc/2026/Conference/Submission9738/Reviewer_bP2o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9738/Reviewer_bP2o"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923069969, "cdate": 1761923069969, "tmdate": 1762921232940, "mdate": 1762921232940, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Falconer, a scalable framework for knowledge mining that fuses the reasoning power of large language models (LLMs) with the efficiency of compact proxy models. In Falconer, LLMs serve as planners—decomposing user instructions into structured subtasks—and annotators, generating high-quality supervision to train lightweight proxies. Central to the framework is the unification of classification and extraction into two atomic operations (get label, get span), allowing a single small instruction-aware model (Cuckoo) to replace multiple specialized components. The authors design new benchmarks to evaluate Falconer’s pipeline planning and end-to-end capability, showing that, with just 5% labeled data, their proxy matches or surpasses state-of-the-art LLMs in accuracy while reducing inference cost by up to 90% and accelerating processing by over 20×. Experiments on both labeled and unlabeled corpora demonstrate strong alignment with human and LLM annotations and highlight the metamodel’s adaptability and continual learning ability. The analysis shows Falconer balances performance, efficiency, and flexibility far better than hand-crafted or purely LLM-based systems, and even demonstrates emergent capabilities, such as self-correction on noisy annotations. In summary, Falconer presents an effective, scalable solution for automated knowledge mining by modularizing task planning and leveraging compact, instruction-following proxies."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Presents a new paradigm that merges LLM planning/annotation with lightweight proxies, unifying extraction and classification under a single, instruction-aware model.\n- Goes beyond prior work by automating both supervision (via LLM) and modular pipeline construction.\n- Extensive benchmarks comparing to strong baselines (RoBERTa, MetaIE, Cuckoo, state-of-the-art LLMs) across labeled/unlabeled data, sample size, continual learning, efficiency, and diverse task types.\n- Clear demonstration of performance, cost, and speed trade-offs.\n- Investigates “arising ability” where the proxy model can correct or surpass noisy LLM annotations.\n- Well-articulated motivation illustrating limitations of existing pipelines and LLM approaches; easy-to-understand scenario illustrations.\n- Achieves substantial reductions in inference cost and deployment overhead.\n- Shows feasibility of training on as little as 5% of the data.\n- Demonstrates that the proxy can sequentially adapt to diverse tasks with minimal degradation.\n- New instruction-following benchmarks and tasks, which could become a community resource."}, "weaknesses": {"value": "- The process for validating LLM-generated supervision, mitigating hallucinations or label errors, and aligning with human annotation is unclear. There is little statistical evidence or qualitative error analysis surrounding annotation reliability.\n\n- Construction, coverage, and difficulty of the new benchmarks are not detailed; it is unclear how well they reflect real-world complexity and industrial use cases.\n\n- The main text lacks deeper discussion of where Falconer or its proxy underperforms (relative to LLMs or modular pipelines), how performance trades off with task complexity, or concrete examples of failure cases.\n\n- No confidence intervals, variance, or significance tests are reported alongside experimental results, which limits the assessment of empirical claims.\n\n- No comprehensive reporting on compute cost, memory/latency figures, or open-source code/benchmarks.\n\n- Needs more explicit differentiation and empirical comparison with closely related recent instruction-IE baselines (e.g., MetaIE, Cuckoo)."}, "questions": {"value": "- Could you elaborate more on the design and composition of your new instruction-following benchmarks—specifically task types, annotation processes, and how difficulty was determined? Understanding these aspects is crucial for evaluating the validity and generalizability of your empirical claims.\n\n- Are there specific categories of tasks or scenarios where the unified proxy metamodel underperforms compared to traditional modular or LLM-based approaches? Highlighting limitations will help the community better understand the boundaries of Falconer’s practicality.\n\n- How is annotation quality from LLM “generator” validated—are there measures taken to address potential LLM hallucinations, annotation errors, or domain shift, and how might these influence metamodel outcomes? Since the proxy's learning depends heavily on LLM-generated supervision, understanding annotation reliability and any mitigation steps is necessary for assessing practical effectiveness.\n\n- Please provide complete hyperparameter settings, training/inference resource usage, and dataset splits in the main text, or concisely summarize them with explicit pointers to the appendices.  (To enable reproducibility and fair comparison, readers need direct access to these key experimental details.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6CbFrAchAp", "forum": "BcxM6dZiXc", "replyto": "BcxM6dZiXc", "signatures": ["ICLR.cc/2026/Conference/Submission9738/Reviewer_jrA7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9738/Reviewer_jrA7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990506993, "cdate": 1761990506993, "tmdate": 1762921232360, "mdate": 1762921232360, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}