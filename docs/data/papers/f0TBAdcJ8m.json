{"id": "f0TBAdcJ8m", "number": 21260, "cdate": 1758315573530, "mdate": 1759896931811, "content": {"title": "ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention", "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, yet their direct application to NP-hard combinatorial problems (CPs) remains underexplored. In this work, we systematically investigate the reasoning abilities of LLMs on a variety of NP-hard combinatorial optimization tasks and introduce \\textbf{ACCORD}: \\textbf{A}utoregressive \\textbf{C}onstraint-satisfying generation for \\textbf{CO}mbinatorial optimization with \\textbf{R}outing and \\textbf{D}ynamic attention. ACCORD features a novel dataset representation and model architecture that leverage the autoregressive nature of LLMs to dynamically enforce feasibility constraints, coupled with attention-based routing to activate problem-specific LoRA modules. We also present the ACCORD-90k supervised dataset, covering six NP-hard combinatorial problems: TSP, VRP, Knapsack, FlowShop, JSSP, and BinPacking. Extensive experiments demonstrate that our ACCORD model, built on an 8B-parameter Llama backbone, consistently outperforms standard prompting and input-output methods, even when compared to much larger LLMs, such as gpt-4. Ablation studies further show that our output structure enhances solution feasibility. To the best of our knowledge, this is the first large-scale, end-to-end framework for exploring the applications of LLMs to a broad spectrum of combinatorial optimization problems.", "tldr": "ACCORD is an end-to-end framework that uses a fine-tuned 8B-parameter Llama model with an autoregressive representation and dynamic attention to solve various NP-hard combinatorial optimization problems with high feasibility and low optimality gaps.", "keywords": ["Large Language Models", "Combinatorial Optimization", "Autoregressive Generation", "Constraint Satisfaction", "NP-hard problems", "Fine-tuning", "LoRA", "Attention-based Routing", "TSP", "VRP", "Knapsack", "FlowShop", "JSSP", "BinPacking"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e6bc2dd640568c4be6ba1eeabd52ea12feab6f9c.pdf", "supplementary_material": "/attachment/70d07d0e4de7b15a7c22d9abc72ddc1fc9e9cd1f.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents an attempt to fine-tune LLaMA models for solving combinatorial optimization problems."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Using LLMs to solve combinatorial optimization problems is a hot topic and will likely remain an active area of research in the future."}, "weaknesses": {"value": "The paper contains numerous confusing claims and several serious errors, it must to be written more carefully. (Please refer to the questions section for details.)"}, "questions": {"value": "Fundamental issues:\n\n1. It is completely unclear what the second problem you address actually is. It is referred to as a VRP, but later, vehicle capacity (sometimes also customer demands) are mentioned. This suggests it might actually be a Capacitated Vehicle Routing Problem (CVRP) rather than a standard VRP (TSP with multiple vehicles). In Appendix A, a capacity constraint is explicitly defined. Given that, how states (line 219) can be the same for both TSP and (C)VRP? Similarly in A1, capacity constraint is given as an input, but there is no customer demands and obviously it is not taken into account in solving the problem.\n\n2. The same confusion applies to FSSP (or PFSP?). Which problem are you actually trying to solve? Throughout the paper, you appear to mix these two problems - sometimes even within the same sentence (line 976). There is no description of this problem at all - it is even  missing from the prompt at line 881, and incorrectly stated in the prompt at line 1096 - there is no mention of the operations order constraint.\n\n3. There are also fundamental errors in examples provided in Appendix A.1. VRP Example is:  Input: customers with coordinates, a depot, and multiple vehicles with capacity 85. Coordinates: 0:(34, 42), 1:(39, 58), 2:(46, 48), 3:(57, 49), 4:(45, 16)\n \nSeveral problems arise here:\n\n   - What about customer demands? Why do vehicles have a defined capacity if no demands are provided?\n   - Where is the depot located? It's not specified.\n   - What does the provided solution represent? Do four vehicles have empty routes? Route length of the fifth vehicle is wrongly computed. The Euclidean distance between customer 0 (34, 42) and customer 1 (39, 58) is approximately 16.7. Your reported solution gives a distance of 16. The same rounding issue appears for other distance as well as in the TSP example. Such inaccuracies are **unacceptable**.\n\n4. Furthermore, this raises a new important question: How are objective values computed? Is the LLM responsible for these computations? Is there any verification to ensure that the computed objective values are accurate? If not, computing optimality gap is meaningless.\n\n5. The example provided for the Knapsack problem is not meaningful, as all items fit into the knapsack without any constraint. Additionally, input to LLM can not be a matrix object as it is shown in the knapsack example. \n\n6. I am not sure I fully understood Figures 2 and 3. Do they both represent the ablation studies on your fine-tuned models for the 1B and 8B parameter sizes, as well as different input representations? If both figures show results after fine-tuning (I assume that is the case), I would expect some correlation between them. For example, in Figure 2, the feasibility for Knapsack 5 is reported as 5.4% and 16.0%, whereas in Figure 3, the feasibility for Knapsack 5 is approximately 20%.\n\n7. Regarding these figures, what does it mean when the TSP solution is marked as infeasible? Any permutation of input nodes is a feasible solution. Does this imply that the LLM fails to produce a valid permutation of 50 elements in 99% of attempts? This seems impossible. It is especially surprising that the feasibility of TSP50 is only 1%, while for FSSP50 it is almost 20%, even though the feasibility constraints for FSSP are very hard to satisfy.\n\nOther:\n\n8. Router Architecture - There is no mention of any hyperparameters for this network. Figure 1 shows that the output of the Router is the input to the LLM - how is that possible? Also, what does $a_i$ represent in equation (6)?\n\n9. What does “size” represent? Specifically, what is meant by “increasing instance scales per task”? Is it the problem size? If so, for JSSP, what does a problem size of 10 correspond to in terms of the number of jobs and operations? \n\n10. There is no description or references in the main text for some baselines used in this work, these are only mentioned in the appendix.\n\n11. The first claimed contribution of this paper is providing a supervised dataset for COPs with 90K instances (15K per problem), which is not very significant since many existing works on NCO have provided datasets with up to 1 million solved instances.\n\n12. NCO baselines for JSSP in the table 2 are outdated."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Hof8SYzPoH", "forum": "f0TBAdcJ8m", "replyto": "f0TBAdcJ8m", "signatures": ["ICLR.cc/2026/Conference/Submission21260/Reviewer_cJmY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21260/Reviewer_cJmY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761059341823, "cdate": 1761059341823, "tmdate": 1762941659777, "mdate": 1762941659777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Autoregressive Constraint-Satisfying Generation for Combinatorial Optimization with Routing and Dynamic Attention (ACCORD). Specifically, it introduces the ACCORD90k supervised dataset along with an ACCORD representation that explicitly encodes problem constraints. Building on this, the authors fine-tune LLMs using attention-based dynamic routing and specialized Low-Rank Adaptation (LoRA) modules. Experiments are conducted across six combinatorial optimization (CO) problems: TSP, VRP, Knapsack, FlowShop, JSSP, and BinPacking."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Fine-tuning LLMs to directly solve CO problems is an interesting yet challenging direction.\n* The authors provide source code to support reproducibility (but please use an anonymous link)."}, "weaknesses": {"value": "* The writing quality of this paper should be improved. For instance, some citation format should follow the correct convention (e.g., use `\\citep`).\n* As acknowledged by the authors in lines 75–78, LLMs are originally designed for natural language generation rather than NP-hard optimization problems, which require complex search within constrained spaces. Given this, why do the authors choose to fine-tune such LLMs for directly solving CO problems? Would it not be more suitable to train a smaller, task-specific neural network for CO problems, as in GOAL [1]? In my view, leveraging (e.g., prompting or fine-tuning) LLMs to generate code—an area where they naturally excel—to solve CO problems appears to be a more reasonable direction.\n* Prior work [2] has explored fine-tuning LLMs for directly solving various CO problems. Could the authors clarify the main differences compared with it?\n* As shown in Tables 10–11, ACCORD does not show superiority upon traditional or neural solvers in terms of solution optimality and solving efficiency. Then what is the advantage of fine-tuning LLMs for directly solving CO problems?\n\n[1] GOAL: A Generalist Combinatorial Optimization Agent Learner.  \n[2] Large Language Models as End-to-end Combinatorial Optimization Solvers.\n\n----\n\nUnfortunately, based on the above evaluation, the paper in its current form is not ready for publication at ICLR."}, "questions": {"value": "* Why is there no information about node demands in the VRP inputs provided to the LLM, as shown on page 15?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xCldn78qLH", "forum": "f0TBAdcJ8m", "replyto": "f0TBAdcJ8m", "signatures": ["ICLR.cc/2026/Conference/Submission21260/Reviewer_yUyE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21260/Reviewer_yUyE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761310810118, "cdate": 1761310810118, "tmdate": 1762941659500, "mdate": 1762941659500, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ACCORD proposes an output format with feasibility checks at each step for solving CO problems with LLMs.\nThis is combined with a dynamic router that selects problem-specific LoRA adapters.\nACCORD is evaluated on six NP-hard tasks (TSP, VRP, Knapsack, FlowShop, JSSP, BinPacking) where it is reported to beat baselines (including GPT-4 with Code Interpreter) on feasibility and optimality gaps."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The empirical results suggest that the suggested format with step-by-step feasibility checks improves LLM performance on CO tasks.\n* The evaluation covers six different NP-hard tasks.\n* The paper additionally contributes the ACCORD-90K dataset as a new benchmark."}, "weaknesses": {"value": "1. The dynamic routing adds significant complexity but seems to offer limited utility. In practice one could simply select the LoRA based on the given CO task or train one bigger combined LoRA for all given CO tasks.\n2. It is not clear that a LoRA is needed for an LLM to follow the suggested output format. Instead, the output format may be acquired through in-context learning. The system prompt could specify the ACCORD format for the given CO problem and provide few-shot examples for some problem instances. This would be low-cost, even for frontier models. I think this is a key baseline missing from Table 1 that would justify the use of LoRA's.\n3. The presentation of the experiments also lacks clarity. Figure 2 in particular raises some questions. The numbers reported in Figure 2 appear to be aggregated over only those runs with feasible solutions. In practice, runs with infeasible solutions would still incur a computational cost. The reported runtimes also seem very noisy and plotting a runtime of 0 for cases where no solution is feasible is not a reasonable representation of the data.\n4. The paper does not analyze how reliably the trained models actually follow the ACCORD output format. The format requires step-by-step arithmetic for tracking the value and feasibility constraints. As LLMs are notoriously error prone when doing integer arithmetic, it is not clear that the trained models can reliably follow this format without mistakes. The paper would be strengthened by an analysis that studies how accurately the models compute the steps defined by ACCORD.\n\nWhile the suggested data format seems sensible and novel, I think these weaknesses currently outweigh the presented contributions."}, "questions": {"value": "1. Can the ACCORD format be acquired through in-context learning instead of LoRA's?\n2. Why are the runtimes reported in figure 2 as noisy as they are? Is this an artifact of only aggregating over feasible runs?\n3. How reliably do the models carry out the arithmetic calculations required by the ACCORD format?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UfneC1YLcK", "forum": "f0TBAdcJ8m", "replyto": "f0TBAdcJ8m", "signatures": ["ICLR.cc/2026/Conference/Submission21260/Reviewer_1Gfv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21260/Reviewer_1Gfv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861176695, "cdate": 1761861176695, "tmdate": 1762941659155, "mdate": 1762941659155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Autoregressive Constraint-satisfying generation for COmbinatorial optimization with Routing and Dynamic attention (ACCORD). It first constructs a supervised dataset comprising a total of 90,000 instances and corresponding solutions generated by OR-Tools for six combinatorial optimization problems: TSP, VRP, Knapsack, FlowShop, JSSP, and BinPacking. It designs an attention-based router to encode natural language descriptions of the problems, and fine-tunes a base LLM (LLaMA 8B) with problem-specific LoRA modules using the constructed dataset."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of fine-tuning an LLM for CO is interesting.\n\n2. Generating solutions under an autoregressive decoding framework ensures that feasibility constraints can be enforced step-by-step during generation.\n\n3. The authors have provided the source code."}, "weaknesses": {"value": "1. The presentation needs further improvement. For example:\n   - In line 67, the capitalized \"*A*ttention based *D*ynamic router\" and the appearance of \"5\" are confusing.\n   - Figure 1 does not illustrate the autoregressive decoding process of solution generation. After reading the figure and its caption, it initially seemed that the model samples solutions from an output probability distribution over nodes/tokens (e.g., via a heatmap), and only checks feasibility after generating the entire solution. However, Section 4 clarifies that feasibility is checked at each decoding step.\n   - There are multiple incorrect uses of `\\citet` throughout the paper where `\\citep` should have been used.\n   - The terminology for combinatorial optimization problems is inconsistent. The manuscript alternates between \"CO\" and \"CP\".\n   - The term \"updated state summary\" in line 210 is vague and should be clarified.\n   - Lines 227–230 should be expressed using proper mathematical formulations.\n   - The font size in several figures is too small, which affects readability.\n\n2. What is the runtime budget for OR-Tools used to generate the supervised dataset? How good are the solutions it provides?\n\n3. What does \"opt\" refer to in the caption of Table 1? Are the OR-Tools solutions treated as the optimal?\n\n4. What is the inference time for the results reported in Table 1? The overhead introduced by autoregressive decoding should be discussed.\n\n5. The problem sizes in Table 1 are quite small, yet the reported optimality gaps are relatively high.\n\n6. Why are the results for FSSP missing in Table 1?\n\n7. The paper lacks comparisons with relevant LLM-based and ML-based baselines."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pPFnkVa9QY", "forum": "f0TBAdcJ8m", "replyto": "f0TBAdcJ8m", "signatures": ["ICLR.cc/2026/Conference/Submission21260/Reviewer_bhnA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21260/Reviewer_bhnA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995075357, "cdate": 1761995075357, "tmdate": 1762941658877, "mdate": 1762941658877, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}