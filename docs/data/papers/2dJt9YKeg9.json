{"id": "2dJt9YKeg9", "number": 10215, "cdate": 1758164210799, "mdate": 1759897666054, "content": {"title": "When Evolution Meets Momentum: Orchestrating Goal-oriented and Process-oriented reasoning for LLM Inference Scaling", "abstract": "Large language models (LLMs) have demonstrated strong reasoning ability when given additional compute at inference time. However, existing inference-time scaling methods are fundamentally limited by their design. On the one hand, gaol-oriented approaches, such as Line or Tree Search, refine candidate solutions using feedback but are vulnerable to sequential dependence, often collapsing into suboptimal reasoning trajectories. On the other hand, process-driven approaches such as Best-of-N sampling encourage diversity through random exploration but lack feedback mechanisms, leading to inefficient computation allocation and unguided search. In this work, we propose EvoMo, a novel inference-time scaling approach that unifies both paradigms by embedding a globally evolving strategy pool into MCTS, where each node expansion selects reasoning strategies under an $\\varepsilon$-soft policy.\nTo further avoid stagnation in familiar strategies, we introduce a \\textit{momentum-based optimization} mechanism that monitors similarity among generated solutions and encourages the exploration of underutilized strategies. Across benchmarks, EvoMo reveals significant performance gains over SOTA inference scaling methods.", "tldr": "Mixing MCTS and Policy Evolution in the LLM search, and borrow the idea of Momentum in Optimization to prevent from local optimal", "keywords": ["Inference Scaling", "Momentum", "Reasoning", "LLM Agent and Human"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e059863e800dfbfa4da035218a0923aa4ee8d935.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The work proposes an inference time scaling technique that induces diversity into MCTS-like techniques to improve Best of N performance. The method observes the similarity of different approaches and through momentum based strategies, it encourages more utilization on under represented approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Increasing solution diversity is a promising avenue for this research that deserves more attention.\n\n- The method is simple, well motivated and clearly explained. \n\n- Initial results look promising especially for the larger models"}, "weaknesses": {"value": "- I found that the improvements gained through the method are either modest or otherwise not very well highlighted in the paper. For example the larger models seem to have a larger gain but this comes very late in the paper. Also, the paper does not shown results for all datasets on all models to get a good picture of reality. I would suggest the authors to add a full page set of figures with number of tries in the x axis and accuracy +bon in Y for all datasets and all models they work with. Otherwise, the story is too distributed.\n\n- In the diversity for inference time scaling field, there are some traditional methods that basically try to sample at different temperatures (the Self Consistency method) or via prompting by asking the model to follow a particular approach or style or persona or in-context examples to enforce diversity (see Diversity of thought improves reasoning abilities of large language models). Would be useful to compare with some of these more straightforward approaches to judge the benefits. The appendix talks somewhat about this but 1:1 comparisons are not available.\n\n- More generally, it would be good to see benefits in other domains, beyond code."}, "questions": {"value": "- What model is used in Figure 1?\n\n- Why do the authors only track BoN? It would be useful to also see trends in majority vote and average accuracy.\n\n- Improvements in Table 1 even for BoN seem very modest. What am I missing?\n\n- Why do the authors only consider coding benchmarks?\n\n- How does token cost usage compare for your method and the baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "y8poXs1xSu", "forum": "2dJt9YKeg9", "replyto": "2dJt9YKeg9", "signatures": ["ICLR.cc/2026/Conference/Submission10215/Reviewer_WhMT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10215/Reviewer_WhMT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927881788, "cdate": 1761927881788, "tmdate": 1762921574657, "mdate": 1762921574657, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EvoMo, a hybrid inference-time scaling framework for large language models that unifies goal-oriented search (like MCTS) with process-oriented diversification (like sampling). It maintains a global pool of reasoning strategies and uses a momentum-based mechanism to trigger exploration when solution similarity indicates stagnation, evolving new strategies via crossover and mutation. Experiments on multiple code-generation benchmarks show consistent Pass@K gains (≈+1–4pp) and higher diversity compared with baselines such as SFS and BoN."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents an interesting combination of goal-oriented (MCTS) and process-oriented (diversity-based) methods, addressing fundamental limitations of each paradigm when used in isolation.\n2. The evaluation spans multiple challenging benchmarks (APPS, HumanEval, MBPP+, LeetCode, CodeContests) with consistent improvements demonstrated across different search methods.\n3. The method's ability to integrate with existing search frameworks (BoN, Tree Search, GA, SFS) without structural modifications is practically valuable."}, "weaknesses": {"value": "1. The strategy pool appears domain-specific and manually designed. The generalizability to other domains beyond code generation is questionable.\n2. The paper lacks detailed analysis of the computational overhead introduced by the momentum mechanism, particularly the repeated similarity computations."}, "questions": {"value": "1. How would the strategy pool be adapted to non-coding domains? Is manual strategy design always necessary?\n2. Integrating EvoMo presumably requires modifying the search loop, node data structure, and prompt construction logic. How large is this engineering overhead in practice? Did the authors quantify the actual gain after integration relative to the added complexity or runtime cost for each baseline (BoN, SFS, MCTS)?\n3. Since EvoMo sometimes uses longer prompts and extra similarity computation, do gains still hold under strictly token- or time-normalized budgets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "060LPZmTuj", "forum": "2dJt9YKeg9", "replyto": "2dJt9YKeg9", "signatures": ["ICLR.cc/2026/Conference/Submission10215/Reviewer_GjuR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10215/Reviewer_GjuR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994178050, "cdate": 1761994178050, "tmdate": 1762921574297, "mdate": 1762921574297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EvoMo, a test-time (inference-time) scaling method that aims to unify goal-oriented search (e.g., MCTS/ToT) with process-oriented diversification (e.g., Best-of-N). Concretely, the authors (i) embed a global strategy pool of “reasoning strategies” into MCTS via an (\\epsilon)-soft selection policy, and (ii) introduce a momentum-inspired controller that monitors inter-solution similarity and, when a threshold is exceeded, forces exploration of under-used strategies and triggers lightweight “evolution” (crossover/mutation) of strategies. Experiments on coding and reasoning benchmarks (e.g., APPS, CodeContests, HumanEval, LeetCode, MBPP+) report modest to moderate gains in Pass@K over baselines (BoN, MCTS, SFS), with larger improvements at higher iteration budgets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Empirical gains: The method reports consistent improvements on several benchmarks under fixed search budgets, sometimes reaching the strongest Pass@K among compared methods; e.g., on CodeContests and APPS under 40 iterations, EvoMo surpasses BoN, MCTS, and SFS variants. These results suggest the approach can be a practical plug-and-play enhancer for existing test-time pipelines. \n- General framing: Positioning a strategy pool inside a search controller is a clean way to expose “reasoning modes” as first-class actions. The idea could generalize beyond coding to other inference-time search settings. \n- Scalability intuition: The claim that diversity helps escape sequential traps in tree-like search is plausible, and the paper provides curves suggesting that benefits grow with more iterations. \n- Attempted analysis: The paper sketches a theoretical perspective arguing that similarity-triggered “momentum” can help the strategy action space approach a near-optimal pool over time."}, "weaknesses": {"value": "1. Originality / motivation not crisp:\n\nThe core components—MCTS with policy over “reasoning strategies,” an evolving pool, and a momentum-style trigger based on solution similarity—feel like a direct stitching of existing ideas (tree/beam/MCTS search, evolutionary pools, and optimization-inspired momentum/diversity controllers). The paper does not clearly isolate a singular conceptual contribution beyond combining these ingredients, nor does it convincingly argue why this particular combination is necessary or superior to simpler diversity controllers applied to SFS or BoN. \n\n2. Clarity / specification gaps: Several important mechanisms are underspecified, inhibiting reproducibility and interpretability:\n- Similarity metric: The momentum trigger hinges on measuring the semantic similarity (\\Phi(\\cdot\\Vert\\cdot)) between generated solutions, yet the paper does not concretely define which representation(s) and distance(s) are ultimately used in the controller (beyond listing options later for analysis); thresholds, normalization, and how multi-metric signals are combined for the actual trigger are not made precise in the main text. \n- Momentum details: The “momentum” mechanism is described at a high level (inject under-used strategies; crossover/mutation of strategies; prompt augmentation), but the exact update rules, scheduling, parameter settings ((\\epsilon), (\\theta_{\\text{sim}}), window sizes (k), tie-handling), and ablation isolating momentum vs. basic diversity are not clearly presented in the main paper. \n- What exactly is a “strategy”? The taxonomy, initialization, and evolution operators for strategies (and how they map to concrete prompts/tool uses) are not fully specified; it is unclear which parts are hand-engineered vs. learned, and how much human tuning is required for each domain. \n\n3. Experimental coverage appears insufficient:\n\n- Backbone choices and sizes: The main coding experiments rely heavily on a single or very limited set of LLM backbones (e.g., GPT-4o-mini is mentioned repeatedly). It’s unclear what base models are used across all tables, how large they are, and whether results hold on 30B+ class open-weight models (or stronger closed ones) to support claims about inference-time scaling at realistic capability tiers. The paper also suggests some multi-LLM runs but does not systematically explore multiple families and sizes under the same protocol. \n- Baselines vs. SFS: From Table 1, the strategy pool alone sometimes yields limited gains over SFS, suggesting the improvements may be sensitive to settings and not always substantial (e.g., marginal Pass@K increases on certain datasets). A more thorough analysis of when/why EvoMo helps (or fails) is missing. \n- Compute / cost accounting: Since the method’s value proposition is test-time scaling, the paper should provide detailed token/latency budgets, variance across runs, and cost-normalized comparisons (e.g., improvements per token or per second) to tease apart algorithmic gains from simply “more tries.” \n\n4. Positioning relative to prior momentum/diversity controllers:\n\nThe paper acknowledges related work that adds diversity or multi-agent search at inference time, but it does not clearly differentiate its “momentum” trigger and evolution step from prior diversity-on-plateau heuristics. Without sharper contrasts or controlled ablations against simpler triggers, the incremental contribution of “momentum” remains unclear."}, "questions": {"value": "1.\tSimilarity & Triggering\n\n- What exact similarity function(s) (\\Phi) feed the trigger in the core algorithm (not only diagnostic plots)? If multiple metrics are used, how are they aggregated (weighted average? learned combiner? max?) and what are the precise thresholds and window (k)? Please provide pseudocode for the trigger. \n\n2.\tMomentum Mechanics\n\n- How is “momentum” formally implemented? What are the update rules, scheduling, and hyperparameters? How do you pick which under-used strategy to inject, and how do you combine it with the best strategy (the “evolve” operator) deterministically and reproducibly? A step-by-step algorithm box would help. \n\n3.\tStrategy Pool Definition\n\n- Please enumerate the initial strategy set, give one-line operational definitions (e.g., prompt templates/tooling), and describe crossover/mutation operators with examples. How much manual engineering or task-specific tailoring is required? \n\n4.\tBackbones & Scaling\n\n- Report results across multiple model families and sizes, including ≥30B open-weight models where feasible, under identical budgets. Do gains persist or grow with stronger backbones? Provide variance across random seeds. \n\n5.\tCost/Benefit Analysis\n\n- Provide token-normalized and latency-normalized comparisons against SFS/BoN/MCTS. Where is EvoMo most cost-effective? Include Ablations that isolate: (i) strategy pool only, (ii) momentum only, (iii) simpler “diversity-on-plateau” heuristics, (iv) your full method. \n\n6.\tWhen does it help?\n\n- Table-by-table analysis where the strategy pool delivers limited gains over SFS: what characteristics of tasks correlate with small vs. large improvements (e.g., solution length, unit-test density, reward sparsity)? Could task-aware trigger thresholds help? \n\n7.\tTheoretical claims\n\n- The analysis sketches terminality/near-optimality of the evolving pool. What assumptions on reward smoothness, trigger firing frequency, and pool capacity are needed? Can you include a finite-budget bound or a practical stopping criterion consistent with the empirical budgets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "q3JRafDXEX", "forum": "2dJt9YKeg9", "replyto": "2dJt9YKeg9", "signatures": ["ICLR.cc/2026/Conference/Submission10215/Reviewer_33g1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10215/Reviewer_33g1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762051795566, "cdate": 1762051795566, "tmdate": 1762921573898, "mdate": 1762921573898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose an inference-time scaling framework (they call it EvoMo) that tries to combine the benefits of (i) goal-oriented search methods (e.g., tree or line search and MCTS) and (ii) process-oriented diversification (e.g., Best-of-N and evolutionary search). Their key idea is to embed a global, evolving strategy pool (a set of distinct thinking modes) into the expansion step of MCTS. And also to further mitigate entrapment in local optima, the authors incorporate a momentum-inspired mechanism that monitors similarity among recently generated solutions. When a similarity threshold is exceeded, the system forces exploration by combining an under-used strategy with a strong one via simple evolutionary operators and injects the resulting evolved strategy for the next expansion. The intent is to re-diversify the search when it starts collapsing to near-duplicates. Detailed theoretical analysis is also provided by the authors to support their claims. The authors validate the effectiveness of EvoMo on APPS, CodeContests, LeetCode, HumanEval, MBPP+ and show certain effectiveness.\n\nI'm in fact impressed by the abundant content provided in the appendix, which shows the authors' efforts to make it more understandable for the readers."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "``S1``:  The global strategy pool and similarity-triggered momentum is an intuitive method that can potentially be incorporated into different search pipelines.\n\n``S2``: The theoretical guarantees provided in Appendix A (When momentum meets search) support the authors’ claims. \n\n``S3``: The appendix is well organised and contains abundant details and information."}, "weaknesses": {"value": "``W1``: Following ``S3``, in fact, I don’t think the paper is very well written. On the one hand, the motivation described in the introduction is not very clear and sharp. The authors claim their contributions as simply combining the strengths of goal-oriented and process-oriented methods. Personally, I may consider this contribution a bit incremental. Is there any other alternative method to achieve this target? Why the proposed one is better? Clarifying these points would greatly strengthen the clarity and contributions of this paper. On the other hand, abundant details are given in the appendix. If possible, I would suggest the authors move some of the content in the appendix to the main paper.\n\n``W2``: For the experiments, most gains are on code datasets. The framework should also generalise to other broader non-code evaluations. This would strengthen the “general test-time scaling” claim.\n\n``W3``: It would be interesting to discuss some extensions of EvoMo such as incorporating PRMs."}, "questions": {"value": "``Q1``: Is it possible for EvoMo to incorporate process-level reward models (that is, PRMs) to bias strategy selection earlier in the tree?\n\n``Q2``: Are there alternative potential approaches to combine the strengths of goal-oriented and process-oriented methods? How EvoMo outperforms these potential solutions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cu9RTeb9Cj", "forum": "2dJt9YKeg9", "replyto": "2dJt9YKeg9", "signatures": ["ICLR.cc/2026/Conference/Submission10215/Reviewer_16WW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10215/Reviewer_16WW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145702654, "cdate": 1762145702654, "tmdate": 1762921573541, "mdate": 1762921573541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}