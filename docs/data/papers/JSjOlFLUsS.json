{"id": "JSjOlFLUsS", "number": 15032, "cdate": 1758247049287, "mdate": 1759897334324, "content": {"title": "Localized Concept Erasure in Text-to-Image Diffusion Models via High-Level Representation Misdirection", "abstract": "Recent advances in text-to-image (T2I) diffusion models have seen rapid and widespread adoption. However, their powerful generative capabilities raise concerns about potential misuse for synthesizing harmful, private, or copyrighted content. To mitigate such risks, concept erasure techniques have emerged as a promising solution. Prior works have primarily focused on fine-tuning the denoising component (e.g., the U-Net backbone). However, recent causal tracing studies suggest that visual attribute information is localized in the early self-attention layers of the text encoder, indicating a potential alternative for concept erasing. Building on this insight, we conduct preliminary experiments and find that directly fine-tuning early layers can suppress target concepts but often degrades the generation quality of non-target concepts. To overcome this limitation, \nwe propose High-Level Representation Misdirection (HiRM), which misdirects high-level semantic representations of target concepts in the text encoder toward designated vectors such as random directions or semantically defined directions (e.g., super-categories), while updating only early layers that contain causal states of visual attributes. Our decoupling strategy enables precise concept removal with minimal impact on unrelated concepts, as demonstrated by strong results on UnlearnCanvas and NSFW benchmarks across diverse targets (e.g., objects, styles, nudity). HiRM also preserves generative utility at low training cost and transfers effectively to state-of-the-art architectures such as Flux without additional training.", "tldr": "", "keywords": ["Concept Erasing", "Unlearning", "Robustness", "Text-to-Image Generation", "Diffusion Models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0022893ab7d3e88864e4aab8b3e261e92d9c52f0.pdf", "supplementary_material": "/attachment/644637d527c3d25d358d162f5f44682edecdc4c5.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes HiRM, a concept erasure method that edits only the text encoder with a decoupled strategy: it sets the erasure target on the final text-encoder layer but updates only the first layer. There are two variants: HiRM-R (random target) and HiRM-S (semantic/safety target). Results on UnlearnCanvas and several adversarial benchmarks show a balanced trade-off: reasonable erasure, small utility loss, low compute, and transferable between model variants (e.g., SD/FLUX).\n\nHowever, gains over Diff-Q on UnlearnCanvas are small, and there is a clear gap to SOTA on some adversarial benchmarks. The NSFW pipeline relies on templates and keyword gates, which may not generalize to other abstract concepts or compositional prompts.\n\nOverall, the method is simple and practical, but the novelty is not enough and the robustness is not fully established."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Decoupled supervision: HiRM applies the erasure objective at the final text-encoder block and only update the first block, avoiding low-level \"representation shattering\" and yielding a better erasure–utility trade-off. \n\n- Efficiency and modularity: Only editing the text encoder makes the approach easy to train and transferable across pretrained T2I models (e.g., SD and FLUX variants) without modifying the backbone (UNets and Transformers).\n\n- Balanced empirical profile: On UnlearnCanvas, HiRM-S matches or slightly improves over strong text-side baselines with very low cost rather than heavy retraining."}, "weaknesses": {"value": "- The paper is an incremental iteration on Diff-Q: it still modifies the first transformer block of the text encoder but shifts the optimization target to the final layer, which carries higher-level representations. Conceptually sound, but not a paradigm shift.\n\n- Gains over Diff-Q are small. In Table 2, IRA (object erasure) drops from 98.37 to 98.18 (−0.19 pts). The gap to SOTA remains large: in Table 3 the method underperforms on UnlearnDiffAtk (19.01 vs. 9.80) and MMA-Diffusion (3.30 vs. 0.40).\n\n- For NSFW, HiRM-S constructs a safety vector by differencing prompt embeddings, making it dependent on template and vocabulary. This may risk brittleness under template changes, across languages, or at nuanced concept boundaries."}, "questions": {"value": "1. Your method uses two pipelines for *nudity* vs. *non-nudity* (keyword/template gated). Why is this split necessary? Could a single pipeline (no keyword gate) achieve similar or better results? \n\n2. For abstract attributes (e.g., *violent scene* vs. *scene*), the difference vector seems to capture a theme (e.g., war) rather than the attribute(violence). How do you ensure the vector encodes the attribute itself, not a topic proxy? Show stress tests across domains (e.g., domestic/school violence).\n\n3. How does the method handle compositional prompts with scope and negation (e.g., \"… but without weapons\")? Can you provide some targeted evaluations (AND/OR/NOT, \"topic vs. attribute\" disentanglement)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sHkXxVsYSo", "forum": "JSjOlFLUsS", "replyto": "JSjOlFLUsS", "signatures": ["ICLR.cc/2026/Conference/Submission15032/Reviewer_ARWM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15032/Reviewer_ARWM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761582674426, "cdate": 1761582674426, "tmdate": 1762925359602, "mdate": 1762925359602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a concept erasure method that operates solely on the text encoder, called High-Level Representation Misdirection (HiRM). Specifically, HiRM guides the token representations output by the last layer of the text encoder in an incorrect direction and updates the weights of the first layer accordingly. Extensive experiments demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The writing is fluent and logically coherent, exhibiting strong readability.\n* The proposed method is highly modular, requiring only a modification to the first layer of the text encoder to achieve concept erasure, which demonstrates strong practical applicability.  \n* The experimental design is thorough, and the results yield insights with meaningful implications for the research community."}, "weaknesses": {"value": "* The proposed method is relatively empirical and experimental, lacking solid theoretical support. It would be more beneficial to the community if the interpretability of the erased concept could be analyzed from the perspective of the distribution of activated neurons.\n* The core idea of HiRM lies in computing the loss based on the output of the last layer of the text encoder, thereby enhancing its ability to erase high-level concepts. However, in Figure 2, the elimination of the high-level concept *Fauvism* appears to be less effective than that of the more concrete concept *Tree*. Why is this the case?\n* Although the authors provide additional examples in the Appendix, the reviewer finds that the visualizations still lack sufficient diversity. Including more prompts and results across a wider range of backbone models would make the work more convincing.\n* The reviewer observes that both HiRM-R and HiRM-S may, to some extent, affect the similarity between non-target concepts and the original model outputs — as shown in Figures 9 and 10. Could the authors please provide an explanation for this issue?"}, "questions": {"value": "See 'Weaknesses'."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "N5S5UV5iw2", "forum": "JSjOlFLUsS", "replyto": "JSjOlFLUsS", "signatures": ["ICLR.cc/2026/Conference/Submission15032/Reviewer_955x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15032/Reviewer_955x"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761822048987, "cdate": 1761822048987, "tmdate": 1762925358918, "mdate": 1762925358918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper leverages a fine-tuned text encoder for concept erasure. The authors propose fine-tuning the early layers of the text encoder by directing the high-level semantic representations of target concepts toward random or super-category directions. Experimental results on single-concept erasure demonstrate that the method achieves comparable performance while requiring minimal time and memory."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Rather than training the diffusion model parameters, the authors fine-tune the text encoder parameters to improve efficiency.\n2. The proposed method is straightforward and easy to implement.\n3. The idea of using high-level semantic representations to guide updates in the early layers is interesting."}, "weaknesses": {"value": "1. Related work is missing. SPEED [A] leverages null-space constraints to achieve rapid concept erasure and can be extended to multi-concept scenarios. The authors should include SPEED as a baseline and compare efficiency.\n\n2. Although the authors mention plans to extend the proposed method to multi-concept erasure, its tuning-based nature limits scalability. As more concepts are introduced, optimizing the early layers becomes increasingly difficult. Therefore, the authors should include a multi-concept erasure setting to demonstrate the method’s potential.\n\n3. Table 2 shows that Diff-Q achieves comparable results on UnlearnCanvas, and unlike training-based methods, it attains higher performance via a closed-form solution. It shows limited improvement introduced by HiRM. Besides, Table 1 reports the low performance of Diff-Q in preserving untargeted concepts. Does this suggest that the metrics used in Table 2 may not effectively reflect the ability to preserve untargeted concepts, given that IRA and CRA scores are near 100?\n\n[A] Li, Ouxiang, et al. \"Speed: Scalable, precise, and efficient concept erasure for diffusion models.\" arXiv preprint arXiv:2503.07392 (2025)."}, "questions": {"value": "1. Comparison with SPEED.\n2. Support for multi-concept erasure.\n3. Choice and justification of evaluation metrics.\n4. Would introducing additional constraints on the higher layers (e.g., the last two layers) improve performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9WKsgD3yeR", "forum": "JSjOlFLUsS", "replyto": "JSjOlFLUsS", "signatures": ["ICLR.cc/2026/Conference/Submission15032/Reviewer_Jypt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15032/Reviewer_Jypt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860483983, "cdate": 1761860483983, "tmdate": 1762925358544, "mdate": 1762925358544, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper is motivated by the observation that Diff-QuickFix, which modifies only the first self-attention layer, performs poorly when addressing high-level abstract concepts such as nudity or NSFW content. Moreover, when modifying the entire first transformer block toward random vectors (inspired by the RMU approach in LLMs), it tends to over-unlearn, negatively affecting unrelated concepts.\n\nTo address this, the paper proposes targeting high-level concept representations in the final encoder block (rather than the first layer) while applying updates only to the early-layer weights. This decoupling strategy enables more precise concept removal with minimal impact on unrelated concepts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "•  The paper is clearly written and easy to follow.\n\n•  The proposed method is simple and intuitively reasonable.\n\n•  The experiments appear comprehensive, and the results look promising."}, "weaknesses": {"value": "-\tIn diffusion model training, the text encoder is typically a pre-trained model (e.g., CLIP text encoder) and remains frozen throughout the training process. This means that if unlearning is applied only to the text encoder, malicious users could easily replace the sanitized text encoder with the original one to recover all unlearned concepts. Therefore, in open-source settings, fine-tuning the core denoising model (i.e., the U-Net) makes more sense and is a more robust approach. This can be seen in Table 4, where HiRM-R does not perform as well as ESD, CA on Flux architectures (which use two text encoders rather than one, as in Stable Diffusion) \n-\tThe proposed method appears to be a simple extension of RMU (a popular unlearning method for LLMs) to diffusion models, with the additional trick of fine-tuning only the early layers instead of all layers. This could be viewed as the result of a simple ablation study on layer selection rather than a fundamentally new approach. \n-\tWhile the paper emphasizes its efficiency (faster than training-based methods), this seems somewhat expected — since it only updates weights without requiring output generation (as in ESD or other training-based methods), it is naturally much faster."}, "questions": {"value": "•  Does the method employ any losses to preserve unrelated concepts, similar to UCE or SHS? If yes, how are the to-be-retained concepts chosen?\n\n•  How does the method perform against the Random Probe recovery attack proposed in [1], which adds noise to the text encoder to confuse generation and recover unlearned concepts?\n\n•  How are the super-categories determined? Are they predefined manually, or can they be learned end-to-end as in [2]?\n\n[1] Lu, Kevin, et al. \"When Are Concepts Erased From Diffusion Models?.\" NeurIPS 2025 \n\n[2] Bui, Anh, et al. \"Fantastic targets for concept erasure in diffusion models and where to find them.\" ICLR 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l9ciK6hbQs", "forum": "JSjOlFLUsS", "replyto": "JSjOlFLUsS", "signatures": ["ICLR.cc/2026/Conference/Submission15032/Reviewer_X6qh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15032/Reviewer_X6qh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15032/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762088689037, "cdate": 1762088689037, "tmdate": 1762925358059, "mdate": 1762925358059, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}