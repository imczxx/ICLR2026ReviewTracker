{"id": "Phv5G3rxOx", "number": 5932, "cdate": 1757947371554, "mdate": 1763373909479, "content": {"title": "TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal  Conversational Music Recommendation", "abstract": "We present TalkPlayData 2, a synthetic dataset for multimodal conversational music recommendation generated by an agentic data pipeline. In the proposed pipeline, multiple large language model (LLM) agents are created under various roles with specialized prompts and access to different parts of information, and the chat data is acquired by logging the conversation between the Listener LLM and the Recsys LLM. To cover various conversation scenarios, for each conversation, the Listener LLM is conditioned on a finetuned conversation goal. Finally, all the LLMs are multimodal with audio and images, allowing a simulation of multimodal recommendation and conversation. In the LLM-as-a-judge and subjective evaluation experiments, TalkPlayData 2 achieved the proposed goal in various aspects related to training a generative recommendation model for music.", "tldr": "Use multiple, multimodal LLMs with specialized roles and prompts to synthesize a dataset for conversational music recommendation", "keywords": ["music", "recsys", "dataset", "conversational recommendation", "LLM"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e50311560ba5fd8b18d1480815010c3404c7a0cc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents TalkPlayData 2, a new synthetically constructed conversational recommendation dataset for music. The authors overview the design decisions behind their dataset and the agentic framework used to construct it, and evaluate its overall quality as a simulation for real music recommendation conversations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The overall documentation of dataset construction is exceedingly detailed. The authors attention to detail in describing all parts of the dataset generation pipeline are quite welcome, and strengthen the contribution exceedingly.\n- The high level goal of the paper is quite timely, and seems to address a much needed gap in current datasets for training / evaluation of conversational music recommendation."}, "weaknesses": {"value": "- From a writing perspective, while the finale 3-9 pages of the paper have quite good style, the first two pages stand out as remarkably different and somewhat overly sparse and incoherent relative to the rest of the text. The paper seems to be without a proper introduction, and thus, the beginning of this manuscript feels jarring and the motivation is left underdeveloped. While this may be helped by moving the related works to the forefront of the paper, it would be more useful to have a more standard introduction as typical of an ICLR paper.\n- The main weakness of the paper, which aligns with the above issue, is that there is a lack of proper evaluation showing a real *use* for the dataset, as the present evaluation only assesses the quality of the synthetic data itself. While this is important, it would be useful to assess how MLLMs perform on the 0-shot test set of TalkPlayData 2, even if just a limited set of them, in order to establish a clear use for the dataset (in this case, evaluation of conversation music recommendation abilities).\n- The objective evaluation, while concerted, feels as if it is missing a clear sort of baseline. It is both unclear whether the LLM-as-a-judge setting is even valid in the context (such a verification could be performed by a limited amount of human verification / user study to correlate LLM ratings with human ratings), and more importantly, how these numbers would compare against any sort of baseline data. While it is understandable that not all other datasets share the same construction as the present one, even comparing in the aspects that are shared with other datasets (such as TalkPlayData 1) would significantly improve the analysis here.\n\nOverall, I believe while there are key issues in the paper, the depth of technical documentation outweighs these at least to cross the threshold for acceptance. However, I believe that by addressing the above concerns, the paper would be significantly improved."}, "questions": {"value": "No real questions, please see weaknesses for main points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "g1xVEIJMrn", "forum": "Phv5G3rxOx", "replyto": "Phv5G3rxOx", "signatures": ["ICLR.cc/2026/Conference/Submission5932/Reviewer_Zw5K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5932/Reviewer_Zw5K"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761459329815, "cdate": 1761459329815, "tmdate": 1762918359233, "mdate": 1762918359233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents TalkPlayData 2, a synthetic multimodal conversational music recommendation dataset. It is generated with an agent pipeline of four LLM roles: a Profile model that builds a listener persona from demographic info and recent tracks, a Goal model that defines what the listener is trying to get from the conversation, a Listener model that simulates the user over multiple turns, and a Recsys model that recommends music. Each conversation is grounded in real listening sessions from LFM-2b. From each session, the pipeline samples a small pool of candidate tracks. All recommendations must come from this pool. For each track, the system includes metadata, lyrics, audio previews, and album art, so the models can refer to musical, lyrical, and visual qualities. The dataset is split chronologically and includes cold-start test cases."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Dialogues and justifications are tied to real tracks with audio, lyrics, and album art, and the system forces recommendations to come from known items. This reduces hallucination and makes explanations about style, mood, or instrumentation more meaningful.\n\n2. By separating Profile, Goal, Listener, and Recsys models and limiting what each can see, the paper mimics a real recommender that must infer user intent over time. The Listener model also marks whether each suggestion helps achieve its goal, which creates an explicit supervision / preference signal for training.\n\n3. The paper shows that removing parts of the pipeline harms diversity of topics and request types, and it reports human judgments that favor TalkPlayData 2 over existing datasets in perceived recommendation relevance and conversational naturalness."}, "weaknesses": {"value": "1. The work extends an existing dataset using known ingredients: multi-agent LLM data generation, LLM-as-a-judge evaluation, and synthetic conversational recommendation grounded in a retrieval pool. The paper’s main advance is scale, added multimodal context, and cleaner role separation across agents, but the general recipe of “use multiple LLM roles with asymmetric information to script synthetic recommender dialogues” is already present in recent synthetic data pipelines. The contribution may be viewed as incremental rather than conceptually new. \n\n2. The paper does not demonstrate that training on TalkPlayData 2 improves any real recommender or conversational policy. The support is mostly subjective quality scores and LLM-judge ratings, not measurable gains on a downstream task. \n\n3. Each dialogue constrains the Recsys model to pick from a short list of tracks sampled from one listening session. This is much simpler than real large-catalog retrieval and raises questions about generalization beyond the curated pool."}, "questions": {"value": "1. How should the “moves toward goal” label be used in training? Do authors expect this to serve as a binary reward for reinforcement-style tuning, as a supervised relevance label for ranking, or as an auxiliary generation target? Please describe the intended training setup, since you present this label as a core advantage.\n\n2. How do authors handle factual music errors in explanations? The Recsys model often justifies recommendations by describing genre, mood, tempo, era, instrumentation, and so on. Beyond an LLM judge score, do authors filter out conversations where these descriptions are clearly wrong, or do authors release them as-is? Users of the dataset need to know how much noisy musical attribution is included."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ZRAFNoANla", "forum": "Phv5G3rxOx", "replyto": "Phv5G3rxOx", "signatures": ["ICLR.cc/2026/Conference/Submission5932/Reviewer_DgEG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5932/Reviewer_DgEG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806284985, "cdate": 1761806284985, "tmdate": 1762918358979, "mdate": 1762918358979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents TalkPlayData 2, an extended multimodal dataset aimed at advancing embodied conversational understanding. It integrates synchronized audio, video, and text streams, along with detailed temporal and behavioral annotations such as gaze, gestures, and environmental context. The dataset is designed to support the development of multimodal models capable of perceiving, reasoning, and responding within dynamic real-world settings.\n\nThe contribution lies primarily in data design and annotation methodology: the authors frame multimodal interaction as an agentic process, emphasizing intentionality, grounding, and situational awareness, which are essential for training multimodal conversational agents."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Rich multimodal alignment: The dataset includes temporally synchronized audio, visual, and textual data with multiple levels of annotation, including dialogue acts, emotion states, gaze, and contextual grounding.\nAgentic framing: Explicitly modeling agent intent and environmental affordances provides a valuable structure for embodied dialogue research.\nComprehensive metadata: Fine-grained labeling of visual scenes, speaker states, and gestures can support a wide range of multimodal learning tasks, from cross-modal grounding to embodied reasoning.\nResearch utility: The resource is well positioned to bridge perception and dialogue modeling for real-world human–agent interaction research."}, "weaknesses": {"value": "The paper presents a well-designed multimodal dataset but lacks a modeling benchmark to demonstrate its effectiveness. No end-to-end model or quantitative evaluation is provided to show improvements in grounding or reasoning. The discussion of agentic intent remains conceptual, without experiments validating its impact on multimodal alignment. Many dialogues appear synthetic, limiting linguistic diversity and realism. The annotation process seems difficult to scale, with no reported inter-annotator reliability. Finally, the dataset’s ability to generalize to new environments or tasks is not tested, leaving its broader applicability unclear."}, "questions": {"value": "1. How are the dialogues generated and validated? Were human annotators involved in ensuring contextual and linguistic naturalness?\n2. Are temporal annotations across modalities (speech, gaze, gesture) manually aligned or automatically synchronized, and what accuracy can be guaranteed?\n3. How were the “agentic” intent and rationale labels defined, and do they correspond to discrete reasoning categories or continuous embeddings?\n4. Is there an evaluation pipeline or baseline model that quantifies multimodal alignment, for example via cross-modal retrieval or embodied reasoning tasks?\n5. How scalable is the data collection and annotation framework to new environments or interaction types?\n6. Have you conducted quality checks for inter-annotator agreement or cross-modal consistency?\n7. How is privacy handled for audio–video recordings, and can the dataset be made fully open for research use?\n8. Do you plan to extend the dataset to interactive multimodal agents that can reason and act in real time using these annotations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VwcpQ33xIb", "forum": "Phv5G3rxOx", "replyto": "Phv5G3rxOx", "signatures": ["ICLR.cc/2026/Conference/Submission5932/Reviewer_6Xi8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5932/Reviewer_6Xi8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762134572301, "cdate": 1762134572301, "tmdate": 1762918358705, "mdate": 1762918358705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TalkPlayData 2, a synthetic dataset for multimodal conversational music recommendation. The dataset is generated by a complex, two-stage \"agentic pipeline\" involving four distinct Large Language Models (LLMs) : a Profile LLM (to create a listener profile), a Goal LLM (to set a conversation goal), a Listener LLM (to simulate the user), and a Recsys LLM (to act as the recommender). This pipeline is grounded in real music data from the LFM-2b dataset and augmented with multimodal information (audio, images) from Spotify. The primary claims are that this multi-agent, multimodal pipeline produces more diverse and \"natural\" conversations than prior single-LLM approaches , which is validated through LLM-as-a-judge and a small human evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The agentic design correctly identifies a flaw in single-LLM generation, which is the tendency to \"cheat\" by seeing all information. The separation of information (e.g., Recsys LLM not seeing the goal) is a good design choice.\n- The ablation study (Table 8) effectively demonstrates that within their own complex pipeline, the Goal and Profile agents are necessary for achieving topical diversity."}, "weaknesses": {"value": "- Critically Lacking Novelty: The paper is highly incremental. It combines TalkPlayData 1 with known multi-agent techniques and off-the-shelf multimodal LLMs.\n- Fundamentally Unsound Evaluation: The work relies almost entirely on LLM-as-a-judge validation, which is self-referential. The human validation is too small to be statistically valid.\n- Compounding Error: The 4-agent pipeline  is a complex, brittle system where errors in early stages (e.g., a bad profile) cannot be caught and will poison the final generated conversation.\n- Cost and Complexity: The proposed pipeline is incredibly complex and expensive (reports $109.08 for 1,000 conversations ) and it is not clear that this massive increase in complexity yields a meaningfully better dataset than the simpler, single-LLM approaches it aims to replace, especially given the weak validation."}, "questions": {"value": "- How can the authors justify claims of \"high naturalness\" (4.15/5) for the entire 16.5K dataset based on a human evaluation with only 26 raters? This sample is less than 0.2% of the test set conversations.\n- The validation relies heavily on LLM-as-a-judge (Table 6), using Gemini 2.5 Pro to judge Gemini 2.5 Flash. How do you account for the well-known self-enhancement bias where LLMs favorably rate outputs from their own architectural family?\n- The core contributions over TalkPlayData 1 are (1) multimodality and (2) a multi-agent pipeline. Both are existing, known techniques. What is the fundamental research contribution of this paper beyond a simple (and very complex) engineering integration?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UwpVxVcbo9", "forum": "Phv5G3rxOx", "replyto": "Phv5G3rxOx", "signatures": ["ICLR.cc/2026/Conference/Submission5932/Reviewer_x9zc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5932/Reviewer_x9zc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762884203483, "cdate": 1762884203483, "tmdate": 1762918358380, "mdate": 1762918358380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}