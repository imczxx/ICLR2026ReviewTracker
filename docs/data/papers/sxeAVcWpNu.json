{"id": "sxeAVcWpNu", "number": 16181, "cdate": 1758261122132, "mdate": 1759897256173, "content": {"title": "InferSpec: Adaptive Inference-Time Compute with Ensemble Verifier-Guided Speculative Decoding for Efficient Reasoning", "abstract": "Large language models (LLMs) are effective at multistep reasoning, but suffer from high inference costs, making efficient deployment challenging. Although speculative decoding (SD) offers latency reductions by letting a lightweight draft propose tokens that a stronger target verifies, yet its token-centric nature admits subtle flaws in intermediate steps to propagate, ultimately producing incorrect final output.\nThe existing literature, such as reward-guided SD, rely on external pre-trained reward models, which increase latency and limit generalizability. To overcome this limitation, we propose InferSpec, a mathematically grounded, verification-aware framework for adaptive inference-time compute allocation.\nAt each step, InferSpec samples multiple draft candidates and applies a self-consistency selector to choose a representative one. It then evaluates the selected step using two model-internal criteria: (i) Attention-Based Grounding Verification (ABGV), which computes grounding scores from attention rollout matrices to ensure attribution to inputs or prior steps, and (ii) Log-Probability-Based Verification (LPBV), which bounds token-level confidence. \nThese signals form a weighted ensemble score with formal guarantees that only grounded, high-confidence steps are accepted; uncertain steps escalate to the target model, allocating compute selectively.\nExperiments on MATH500, GSM8K, Gaokao-2023-En, and OlympiadBench show that InferSpec improves accuracy by up to 3.6% while reducing latency by 11%, consistently outperforming both standard SD and reward-guided SD.", "tldr": "InferSpec improves speculative decoding by adaptively verifying reasoning steps using internal measures of confidence and grounding, achieving higher accuracy on reasoning tasks while maintaining efficiency without external verifiers.", "keywords": ["Inference-time Compute", "Speculative Decoding", "Ensemble Verifiers", "Multi-Step Reasoning"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/943406d80141eec0eda23f5dfc60ee0510abb94f.pdf", "supplementary_material": "/attachment/1f5a7d6780cc3986424bff0da460badb919d17c2.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes INFERSPEC, a speculative decoding framework for multi-step reasoning that aims to replace expensive external reward models. It uses a lightweight \"ensemble verifier\" based on two model-internal signals: Attention-Based Grounding Verification (ABGV) and Log-Probability-Based Verification (LPBV). This verifier adaptively accepts draft steps or escalates to a stronger target model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tImportant Problem: The paper tackles the critical problem of high inference cost in LLM reasoning.\n\n2.\tClear Motivation: The goal of replacing heavy, external Process Reward Models (PRMs) with lightweight, model-internal signals is excellent and practical."}, "weaknesses": {"value": "1.\t(Major Weakness) Lack of Foundational Validation: The paper fails to provide any direct evidence (e.g., correlation studies) that its two core signals, ABGV and LPBV, are meaningful proxies for step-wise reasoning correctness. The entire proposal is built on an unproven premise.\n\n2.\tLack of Generality: The paper's claims of efficiency and accuracy are only supported by experiments on mathematical and formal reasoning datasets (MATH500, GSM8K, etc.) . It is completely unclear if this method has any utility in open-ended or creative generative tasks.\n\n3.\tMissing Critical Ablation: The method combines the new verifier (ABGV+LPBV) with a Self-Consistency Selector. The paper does not ablate the effect of the selector, making it impossible to know if the small accuracy gains come from the novel verifier or just from applying the known self-consistency technique."}, "questions": {"value": "1.\tCan the authors provide a direct quantitative analysis (e.g., a correlation) to demonstrate that the proposed ABGV and LPBV scores actually correlate with ground-truth step-wise correctness?\n\n2.\tWhat is the performance of a baseline that uses only the Self-Consistency Selector to choose from k draft candidates, but uses a simpler verification rule (e.g., standard SD or just LPBV)? This is critical to isolate the true contribution of the ABGV verifier."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "utsH3yUaPo", "forum": "sxeAVcWpNu", "replyto": "sxeAVcWpNu", "signatures": ["ICLR.cc/2026/Conference/Submission16181/Reviewer_v1Ds"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16181/Reviewer_v1Ds"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833265564, "cdate": 1761833265564, "tmdate": 1762926343483, "mdate": 1762926343483, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes InferSpec, a framework that enhances speculative decoding for LLM reasoning tasks through adaptive inference-time compute allocation. Different from Standard speculative decoding (SD) and reward-guided SD (RSD), InferSpec replaces external verifiers with two model-internal verification signals: (i) Attention-Based Grounding Verification (ABGV), which uses attention rollout matrices to ensure outputs are grounded in inputs or validated prior steps, and (ii) Log-Probability-Based Verification (LPBV), which enforces token-level confidence. At each reasoning step, InferSpec samples multiple draft candidates, applies a self-consistency selector to identify the most representative one, then evaluates it using a weighted ensemble of ABGV and LPBV scores. Steps passing the threshold are accepted; others trigger target model recomputation. Experiments on MATH500, GSM8K, Gaokao-2023-En, and OlympiadBench show InferSpec improves accuracy by up to 3.6% while reducing latency by ~11% compared to RSD and standard SD."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. InferSpec introduces complementary internal signals (ABGV via attention rollout, LPBV via log-probabilities) that eliminate external PRM overhead while maintaining generalizability. \n2. Thorough evaluation across four reasoning benchmarks, three model families, and multiple baselines (majority voting, Best-of-N, beam search, SD, RSD). Systematic ablations examine design choices, and qualitative analysis effectively illustrates PRM failure modes.\n3. InferSpec consistently achieves higher accuracy with lower latency than RSD (e.g., 95.8% in 34 minutes vs. 88.7% in 41 minutes on GSM8K). Complexity analysis confirms practical efficiency gains from avoiding external verifiers."}, "weaknesses": {"value": "1. The approach exhibit limited domain generalizability. All experiments focus exclusively on mathematical reasoning. No evidence demonstrates that ABGV and LPBV generalize to code generation, commonsense reasoning, or other domains where attention patterns and confidence distributions may differ substantially.\n2. The parameter setting of InferSpec seems to be crucial and determined empirically. Self-consistency selector overhead are not compared against simpler strategies. \n3. Authors should consider comparing the InferSpec to more recent baselines such as SpecReason: https://arxiv.org/abs/2504.07891 by Rui Pan, Yinwei Dai, Zhihao Zhang, etc."}, "questions": {"value": "1. Have authors evaluated InferSpec on non-mathematical reasoning domains (e.g., code generation, commonsense reasoning, multi-hop QA) to validate whether ABGV and LPBV generalize beyond math-specific attention and confidence patterns?\n2. ow does InferSpec compare against more recent speculative reasoning methods such as SpecReason (Pan et al., 2025)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QFzjtt2JYc", "forum": "sxeAVcWpNu", "replyto": "sxeAVcWpNu", "signatures": ["ICLR.cc/2026/Conference/Submission16181/Reviewer_GsNE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16181/Reviewer_GsNE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967735938, "cdate": 1761967735938, "tmdate": 1762926342966, "mdate": 1762926342966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on efficient generation by incorporating SLM and LLM. Traditional speculative decoding (SD) method requires a strict distribution alighnment between LLM and SLM, and its token-centric nature admits subtle flaws in intermediate steps to propagate. A recent variant, RSD, relies on external reward, introducing latency.\n\nIn this paper, the authors propose InferSpec that samples multiple steps with SLM, selects a reprentative one with semantic similarity, then evaluates it with two model-internal criteria (attention-based grounding verification and log-probability based verification). If the selected step is rejected, the LLM will sample multple steps, chooses the representative one. And the decoding is switch again to SLM. \n\nWith theoretical justification and extensive experiments, InferSpec shows comparable or better accuracy and efficiency than SD and RSD. Detailed ablation studies also justify the dsign choice."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written with a clear motivation, i.e. using model-internal signal to verify the step instead of external reward.\n2. The theoretical justification supports the proposed method.\n3. Extensive experiments show the accuray and efficiency benefits from InferSpec."}, "weaknesses": {"value": "1. Lack of baseline. Since InferSpec applies the target model to sample multiple steps, it's suggested to include the majority vorting results from the target model only. \n2. Unfair runtime comparison. According to Table 1, it seems RSD is originally designed without majority voting. With majority voting, RSD performs much worse. When comparing runtime with RSD in Figure 2, I don't see the reason to compare with RSD majority.\n3. Potential more memory consumption. According to L147, we need to save the attention matrices from each layer to compute R. This saving becomes more memory-consumed for larger model and longer output."}, "questions": {"value": "1. Why do you still use the target model to generate multiple steps? What is the difference bwteen generating only one step and multiple steps with the target model?\n\n### Suggestion\n1. Table 1: highlight the best results for easy observation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gBBu9cXvDE", "forum": "sxeAVcWpNu", "replyto": "sxeAVcWpNu", "signatures": ["ICLR.cc/2026/Conference/Submission16181/Reviewer_adcc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16181/Reviewer_adcc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996286882, "cdate": 1761996286882, "tmdate": 1762926342527, "mdate": 1762926342527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}