{"id": "2LzYaW032Q", "number": 22443, "cdate": 1758331144175, "mdate": 1759896865907, "content": {"title": "ProReGen: Progressive Residual Generation under Attribute Correlations", "abstract": "Attribute correlations in the training data will compromise the ability of a deep generative model (DGM) to synthesize images with under-represented attribute combinations ($\\textit{i.e.,}$ minority samples). Existing approaches mitigate this by data re-sampling to remove attribute correlations seen by the DGM, using a classifier to provide $\\textit{pseudo-supervision}$ for the generation of counterfactual samples, or incorporating inductive bias to explicitly decompose the generation into independent causal mechanisms. We present ProReGen, a $\\textit{progressive residual generation}$ approach inspired by the classical Robinson's transformation to partial out from an image attribute $\\mathbf{x}_2$ its component $m(\\mathbf{x}_1)$ that is predictable by other image attributes $\\mathbf{x}_1$, and the residual $\\gamma = \\mathbf{x}_2 - m(\\mathbf{x}_1)$ that is not. This simplifies the original problem of learning a DGM $g(\\mathbf{x}_1, \\mathbf{x}_2)$ conditioned on correlated inputs, to learning $\\tilde{g}(\\mathbf{x}_1, \\gamma)$ conditioned on orthogonal inputs. It further allows us to progressively learn $\\tilde{g}$ by first shifting the burden to abundant majority samples to learn the generator $\\tilde{g}(\\mathbf{x}_1, \\gamma = 0)$, and then expanding it with additional layers $g\\_{\\text{res}}$ to resolve its difference to $\\tilde{g}(\\mathbf{x}_1, \\gamma)$ using residual attribute $\\gamma$ on limited minority samples. On three benchmark datasets with curated varying strengths of attribute correlations, we demonstrate that ProReGen---with input orthogonalizaton and progressive residual learning---improved the correctness and quality of generations compared to existing strategies.", "tldr": "", "keywords": ["attribute correlation", "progressive training", "data generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ce3cab8f46a54513ad518ebbf6ab70c6795e34ac.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors study the problem of training a generative model under attribute correlation. To this end, they propose a novel approach that separates training into two stages. First, a part of the model is trained on the majority data, while in the second stage the network learns only the residual information for the correlated attribute. The efficacy of the method is evaluated on variations of MNIST and CIFAR."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The main idea is novel and clearly presented.\n\n- The studied problem is relevant and the proposed solution appropriately motivated.\n\n- The experimental results highlight the efficacy of the method in variations of MNIST and CIFAR10.\n\n- I appreciate the ablation of the inverse causal direction for MNIST."}, "weaknesses": {"value": "- The main weakness of the paper lies in the insufficient experimental support. To showcase the effectiveness of the method, as well as the importance of the task, I would expect evaluation on more complex and natural scenarios. For example, a multi-attribute dataset e.g., [1], where this kind of attribute imbalances are naturally occurring would be appropriate.\n\n- I am missing a discussion on earlier works that study generative models under imbalanced attribute distributions. For example,  [2],  [3] to name a few.\n\n- It would be interesting to discuss how (or whether) the presented method can be applied to SOTA image generation models e.g., diffusion-based models.\n\n- On a similar note, I am missing a discussion on the form of the studied problem in scenarios, e.g., text-to image,  where the conditioning variable lives in a combinatorially large space. How would imbalances affect the performance in such models?\n\n- It would be valuable to discuss the presented method under the light of disentanglement and potentially add relevant comparisons.\n\n[1]. Deep Learning Face Attributes in the Wild\n\n[2]. Bias and generalization in deep generative models: An empirical study.\n\n[3]. Multilinear Latent Conditioning for Generating Unseen Attribute Combinations"}, "questions": {"value": "I would appreciate if the authors address the main points raised in the weaknesses section. In particular, I would encourage further experimentation on multi-attribute images (e.g., [1]). Further discussion/comparison to earlier works on disentanglement and generative modelling under imbalanced attribute distributions would also improve the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "deGVZNykbb", "forum": "2LzYaW032Q", "replyto": "2LzYaW032Q", "signatures": ["ICLR.cc/2026/Conference/Submission22443/Reviewer_eCdH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22443/Reviewer_eCdH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761785000612, "cdate": 1761785000612, "tmdate": 1762942221920, "mdate": 1762942221920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ProReGen is an approach for generative modeling that addresses the challenge of generating underrepresented minority samples in the presence of attribute correlations. The paper proposes a two-stage progressive learning framework inspired by Robinson's partialling-out transformation, which orthogonalizes correlated input attributes and decomposes generation into majority and residual components. The method has been evaluated on Colored-MNIST, MNIST-Correlation, and Corrupted-CIFAR10, showing improvements in minority sample generation correctness compared to naive baselines and existing mitigation strategies"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper demonstrates both VAEs and GANs, which is diverse in nature\n- The application of partialling out transformation for generative modelling is well motivated\n- The paper evaluates across multiple metrics and provides multiple ablation studies \n- The existing methods rely on signals from an external classifier to provide pseudo-supervision to the conditional generative models. Interestingly, they partially out an image from its components"}, "weaknesses": {"value": "- The paper demonstrates both VAEs and GANs, which is diverse in nature\n- The application of partialling out transformation for generative modelling is well motivated\n- The paper evaluates across multiple metrics and provides multiple ablation studies \n- The existing methods rely on signals from an external classifier to provide pseudo-supervision to the conditional generative models. Interestingly, they partially out an image from its components"}, "questions": {"value": "How sensitive is the performance to eros in estmaiting m(x1)?\nWhy does cGAN not perform well compared to the original paper\nWhat happens when the oracle classifiers are not so accurate\nCan the framework also incorporate continuos attributes or only discere ones?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "q65oJv5UGz", "forum": "2LzYaW032Q", "replyto": "2LzYaW032Q", "signatures": ["ICLR.cc/2026/Conference/Submission22443/Reviewer_P42c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22443/Reviewer_P42c"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129051597, "cdate": 1762129051597, "tmdate": 1762942221593, "mdate": 1762942221593, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new approach for training deep generative models (DGMs) that are robust to under-represented attribute combinations. Given attributes X_1 and X_2, the model learns g(X_1, $\\gamma$) rather than g(X_1, X_2), where $\\gamma$ is the residual after predicting X_2 given X_1. This, the generative model is conditioned on orthogonal variables, rather than potentially very correlated variables. This makes the model more robust when generating rare attribute combinations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed approach of orthogonalizing attributes and the two-stage residual training approach is novel. The proposed solution is intuitive and seems very reasonable. \n\n- The fact that ProReGen is agnostic to the choice of underlying DGM, rather than being designed with only VAEs or the like, is a clear strength of the proposed approach \n\n- The writing is clear and easy to follow"}, "weaknesses": {"value": "- The experiments are all on toy, synthetic or partially-synthetic data. The evaluation is performed on colored-mnist, mnist correlation, and Corrupted-CIFAR10 (wherein synthetic noise was added to CIFAR images). This is not a very convincing evaluation; at least, it does not provide evidence that the proposed ProReGen approach would correctly model under-represented attribute combinations in realistic data with natural correlations. \n\n- The authors claim that the proposed approach is agnostic to the choice of deep generative models, but only discuss and implement it on VAEs and GANs. I am surprised to not see results or discussion on the case where Diffusion models (DDPM, DDIM, latent diffusion, etc) are used as the base DGM.  I don't see a technical reason why diffusion wouldn't work; the authors' claim that the choice of DGM is arbitrary seems reasonable to me.  For that reason, I think the authors should either empirically evaluate PreReGen on Diffusion models, or else clarify why this is not possible and then amended their claim about the DGM being model agnostic. \n\n- This is a minor point, but I believe the paper would benefit if it included a discussion of property-controllable VAEs [1]. PCVAE is definitely different, as it tries to learn a disentangled latent representation rather than making the model robust to correlated attributes and minority samples. But the underlying goals are similar enough that I believe comparing and contrasting the proposed approach with existing property-controllable works would be interesting. \n\n[1] Guo, Xiaojie, Yuanqi Du, and Liang Zhao. \"Property controllable variational autoencoder via invertible mutual dependence.\" ICLR. 2020."}, "questions": {"value": "Can a Diffusion model be used as the underlying DGM? Does ProReGen perform well on larger, more complicated, realistic datasets? \n\nIf these points are well addressed, then I am happy to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6A6NYjwFKP", "forum": "2LzYaW032Q", "replyto": "2LzYaW032Q", "signatures": ["ICLR.cc/2026/Conference/Submission22443/Reviewer_dzuq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22443/Reviewer_dzuq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762141256415, "cdate": 1762141256415, "tmdate": 1762942221212, "mdate": 1762942221212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ProReGen that tackles conditional generation modeling for synthesizing under-represented minority images. ProReGen first learns the predictable part of one attribute from another and then treats what’s left as a residual signal that highlights the minority cases. Training is performed in two stages: Stage I trains a standard VAE/GAN on the common cases; Stage II freezes this backbone and adds a small residual-conditioned module trained only on minority examples to correct the missing variations. Therefore, this separates the attributes so the base learns general realism while the add-on learns rarity (minority attributes). Both VAE and GAN applicability is shown on Colored-MNIST, MNIST-Correlation, and Corrupted-CIFAR-10. The method improves correctness on rare attribute combinations and achieves competitive performance (FID, Coverage, Density)"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed approach is explained in detail and could be easy to incorporate ie (progressive training scheme and plug and play for VAE/GAN architecture).\n- Proper baselines are discussed in the related section and used to compare the performance."}, "weaknesses": {"value": "- It would be great to show the results on some real and large scale vision dataset to help the readers evaluate the efficacy of the proposed approach. It’s unclear how the gains would translate to higher-resolution, richly annotated datasets (faces, scenes) or to modern diffusion/flow models, which are the latest common practice. A larger-scale study would strengthen the empirical case.\n- Stage-II adds networks and trains only on minority samples while freezing the backbone. It would help the readers to show discussions around added compute cost, convergence stability, or sensitivity to the size of the residual sub-network."}, "questions": {"value": "Please refer to the weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VjRpsvP9JE", "forum": "2LzYaW032Q", "replyto": "2LzYaW032Q", "signatures": ["ICLR.cc/2026/Conference/Submission22443/Reviewer_7gY6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22443/Reviewer_7gY6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762335478640, "cdate": 1762335478640, "tmdate": 1762942220980, "mdate": 1762942220980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}