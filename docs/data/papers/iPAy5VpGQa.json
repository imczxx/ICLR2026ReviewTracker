{"id": "iPAy5VpGQa", "number": 20543, "cdate": 1758307244112, "mdate": 1763505514661, "content": {"title": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "abstract": "Wearable sensors provide abundant physiological time series, yet the principles governing their predictive utility remain unclear. We hypothesize that temporal resolution is a fundamental axis of representation learning, with different clinical and behavioral outcomes relying on structure at distinct scales. To test this \\emph{resolution hypothesis}, we introduce \\emph{HiMAE} (Hierarchical Masked Autoencoder), a self-supervised framework that combines masked autoencoding with a hierarchical convolutional encoder–decoder. HiMAE produces multi-resolution embeddings that enable systematic evaluation of which temporal scales carry predictive signal, transforming resolution from a  hyperparameter into a probe for interpretability. Across classification, regression, and generative benchmarks, HiMAE consistently outperforms state-of-the-art foundation models that collapse scale, while being orders of magnitude smaller. HiMAE is an efficient representation learner compact enough to run entirely on-watch, achieving sub-millisecond inference on smartwatch-class CPUs for true edge inference. Together, these contributions position HiMAE as both an efficient self supervised learning method and a discovery tool for scale-sensitive structure in wearable health.", "tldr": "We propose a lightweight SSL objective that competes with much larger transformer Foundation models that also serve as an interpretability tool.", "keywords": ["SSL", "Wearables", "Interpretability", "Inductive Bias"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a7d085962b132bd23c835ce782ba483acd98e790.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work introduces a hierarchical masked autoencoder termed HiMAE to capture multi-resolution representations in PPG signals. The authors hypothesize that predictive information in physiological signals resides at distinct temporal scales and such multi-resolution information can be extracted by CNN-based encoder-decoder architecture relying on U-NET, and trained with a masked reconstruction loss. The model extracts embeddings at several temporal granularities, which are then evaluated across a distinct downstream tasks. HiMAE is shown to outperform or match large transformer-based baselines such as LSM with significantly fewer parameters and faster inference, even achieving on-watch inference capabilities."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The idea that different downstream tasks may depend on representations at distinct temporal resolutions is both intuitive and well-motivated. Designing the architecture explicitly around this principle provides a clear and reasonable inductive bias for modeling physiological time series.\n- The proposed method is thoroughly evaluated across several downstream tasks, showing consistent improvements over large-scale baselines such as LSM while using substantially fewer parameters.\n- The emphasis on on-device inference is important and relevant for wearable applications. The authors convincingly show that HiMAE achieves remarkably lower latency and memory requirements compared to transformer-based counterparts, showing its practical compatibility with resource-limited wearable hardware."}, "weaknesses": {"value": "- While the idea of resolution as interpretability is interesting, the paper primarily focuses on downstream performance differences across embeddings obtained from different HiMAE layers. Although this evaluation setup is reasonable, it is not clear that it fully substantiates the claimed interpretability of HiMAE. Visualization analyses of embeddings or frequency-response characterizations across layers could strengthen the interpretability argument.\n- The authors could provide more intuition or physiological grounding for why certain downstream tasks (e.g., sleep staging vs. cardiovascular detection) depend on finer versus coarser embeddings. Such a discussion would enhance both the interpretability and the practical implications of the resolution hypothesis.\n- The approach multiplies patches by their corresponding binary mask values, which may inject noise or misinformation during training. Have the authors tried other alternatives, such as dropping masked patches entirely or replacing them with a learnable mask token. This can also be an important design consideration when extending this work to other wearable signals that can contain large amounts of naturally missing observations.\n- It is not clearly stated whether the masked reconstruction loss used in the scaling analysis (Fig. 3) is computed on a held-out validation/test set or directly on the training data, particularly for data- and participant-scaling experiments. Clarification here is important for assessing generalization.\n- Several figures are difficult to interpret, which significantly affects the readability: the colors in Fig. 3 are nearly indistinguishable, the markers in Figs. 4–5 are very small, and the text in the confusion-matrix style visualization of Fig. 6 is hard to read. \n- Statistical significance or performance bounds are largely missing. Except for the error bars in Fig. 4, no standard deviations or confidence intervals are provided. Given that multiple baselines exhibit similar downstream decoding performance (e.g., Fig. 5; Tables 13–15), such statistical significance tests are necessary to assess whether improvements are meaningful.\n- The paper compares HiMAE only against the original LSM model, but LSM-2 is a more recent and stronger baseline shown to outperform LSM. While HiMAE’s on-device efficiency is important and valuable, a direct comparison with LSM-2 would better establish its standing among current state-of-the-art SSL methods for wearables.\n- Figure 6 provides an insightful layer-wise analysis for HiMAE. However, even though transformer layers are globally receptive by design, it is possible that they also evolve from encoding local to increasingly global relationships with depth. A similar per-layer analysis for LSM (e.g., comparing early vs. deep layers) would help determine whether the observed resolution-specific trends are unique to HiMAE or more general.\n- The paper proposes the local sufficiency notion in Appendix H.2 (Eq. 1) as a justification for the masked prediction objective, yet the concept is neither formally defined nor supported by prior references. Moreover, if local sufficiency truly held, it is unclear how the model could reliably reconstruct up to 80 % of masked patches from only 20 % visible input. The stable training observed under such high masking ratios suggests that PPG signals—and possibly the learned representations—encode substantial global temporal information, which appears inconsistent with a strict locality assumption.\n- The inability to release the codebase remains a key limitation. Providing even a minimal reproducibility package, such as a subset of data, a lightweight training/evaluation script would greatly improve transparency and contribute to the open-source community."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pCsj2fu9l7", "forum": "iPAy5VpGQa", "replyto": "iPAy5VpGQa", "signatures": ["ICLR.cc/2026/Conference/Submission20543/Reviewer_uicj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20543/Reviewer_uicj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760911568249, "cdate": 1760911568249, "tmdate": 1762933961120, "mdate": 1762933961120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Hierarchical Masked Autoencoder with a U-Net architecture for self-supervised pre-training on wearable signals. The model divides input PPG signals into patches and randomly masks partial signals for reconstruction. The stride-2 convolutional blocks downsample the input signal by a factor of 2 at each stage to enable multi-scale learning. The model is pre-trained on 80,000 hours of PPG signals collected from 47,755 subjects. Comprehensive downstream tasks, such as generative and classification, are included. Further case studies are conducted on on-device benchmarking to demonstrate real-world application ability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The training set is large, with substantial hours and participants, which is good for alleviating subject-specific noise. The experiment is comprehensive, including different classification tasks, such as cardiovascular and sleep stages, which are the functionalities widely required for wearable devices. The model scale and total training time show the efficiency and applicability for wearable devices."}, "weaknesses": {"value": "The method lacks novelty. Multi-scale learning is commonly used in medical/wearable time series representation learning, either through model-based or manual data preprocessing. Multi-scale learning using convolutional networks is more common in past research on time series analysis. Besides, it is better to have a comprehensive results table for comparison with baseline methods on different tasks. The results in Figure 5 are not straightforward enough."}, "questions": {"value": "For the existing wearable PPG foundation model, PaPaGei, how did you compare with it? Did you load their pre-trained model and fine-tune it directly, or self-supervise and pre-train it on your dataset? If you pre-trained their model on your dataset from the beginning, please also report the linear probing result on their provided pre-trained weights."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "CHaWIYCHKr", "forum": "iPAy5VpGQa", "replyto": "iPAy5VpGQa", "signatures": ["ICLR.cc/2026/Conference/Submission20543/Reviewer_CnvE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20543/Reviewer_CnvE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974789333, "cdate": 1761974789333, "tmdate": 1762933960700, "mdate": 1762933960700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HiMAE (Hierarchical Masked Autoencoder), a self-supervised learning (SSL) framework for wearable time-series data, primarily focusing on photoplethysmography (PPG) signals. The central hypothesis, termed the \"resolution hypothesis,\" is that different clinical and behavioral outcomes depend on predictive structures at distinct temporal scales. The key feature of the proposed architecture is that it produces multi-resolution embeddings from its different hierarchical layers. These embeddings can be independently evaluated (e.g., via linear probing) to determine which temporal scale (i.e., which receptive field) carries the most predictive signal for a specific downstream task."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. High Practical Significance (On-Watch Inference): The paper's most compelling strength is its focus on and successful demonstration of a \"true on-watch\" SSL model. By creating a model that is ~99% smaller (1.2M vs 110M params) and significantly faster (0.99ms CPU latency) than transformer baselines, the authors present a practical path toward real-time, continuous health monitoring while preserving user privacy (since data does not need to leave the device).\n\n2. Novel Interpretability Framework: The \"resolution hypothesis\" is an elegant conceptual framework. HiMAE's design, which \"transforms resolution from a hyperparameter into a probe for interpretability\", is a key strength. The resulting analysis in Figure 6, which maps tasks like \"PVC Detection\" to fine-grained layers and \"Sleep Staging\" to coarser layers, is a genuinely novel discovery tool that provides insight into the temporal structure of physiological signals.\n\n3. Experimental Rigor and Breadth: The paper is experimentally dense. The authors evaluate HiMAE on 14 different tasks against a strong set of SSL baselines (SimCLR, DINO, MSN, LSM, etc.). The inclusion of scaling law analysis (Figure 3), multiple generative tasks (Figure 4), few-shot learning (Figure 8), and extensive ablations (Appendix F.1) demonstrates a high-quality, thorough evaluation (assuming the results are verifiable).\n\n4. Strong Inductive Bias: The paper makes a strong case for not defaulting to transformers. It argues that the hierarchical convolutional biases of a U-Net are better \"inductively aligned with the temporal statistics of wearable signals\", which exhibit strong local dependencies. The results, showing HiMAE achieves lower error at much smaller model sizes, provide compelling evidence for this architectural choice."}, "weaknesses": {"value": "1. Poor Presentation and Figure Quality: The paper suffers from a clear lack of polish. For instance, the choice of color palette is a significant problem. In Figures 3, 4, 5, and 15, the colors for competing models are nearly indistinguishable (e.g., \"PaPaGel-S\", \"SimCLR\", \"DINO\", \"MSN\", \"LSM\", \"HIMAE\" are all shades of blue/teal/green). This makes it extremely difficult to review the paper's core performance claims. This is particularly problematic for presenting clear comparisons against baselines, and maybe unreadable for colorblind readers. Additionally, multiple figures (e.g., Figures 3, 4, 5, 6, 14 and 15) needs either larger or smaller fonts for clearer readability.\n\n2. Unverifiable On-Device Benchmarks: The on-device latency (0.99 ms) and throughput (1.2k/s) figures in the text and Table 18 are inconsistent. The text calculation of $\\approx 1,010$ samples/s (which is $1/0.00099s$) seems correct, but Table 18 reports 1.2k/s. This discrepancy undermines confidence in the on-device benchmark.\n\n3. Proprietary Dataset: The pre-training corpus of ~80,000 hours is proprietary. While this is often unavoidable, when combined with the lack of model source code, it means the paper's results are entirely unverifiable from start to finish."}, "questions": {"value": "1. Could you please regenerate the main results figures (3, 4, 5, 15) using a high-contrast, colorblind-friendly color palette? It is currently very hard to distinguish the performance of the different models.\n\n2. Could you please clarify the discrepancy in the on-device benchmark? Why does the text state 0.99ms latency ($\\approx 1.01$k samples/s) while Table 18 reports a throughput of 1.2k/s? Which number is correct?\n\n3. The paper focuses on PPG, with a brief but promising result on ECG in the appendix (Table 16). Given that other physiological signals (e.g., accelerometry, electrodermal activity) also possess rich, multi-scale structures, do you have any intuition or preliminary results on how the HiMAE framework would perform on these other common wearable modalities? Or considering adding results on those public datasets for better reproducibility and verification?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The authors have provided a thorough ethics statement in Appendix B. They proactively address data privacy and consent, bias and representativeness (noting their data comes from 4 countries), clinical implications (positioning the tool for decision support, not diagnosis), and environmental impact. So no further review is needed."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dv0eiayg80", "forum": "iPAy5VpGQa", "replyto": "iPAy5VpGQa", "signatures": ["ICLR.cc/2026/Conference/Submission20543/Reviewer_5CPC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20543/Reviewer_5CPC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978865195, "cdate": 1761978865195, "tmdate": 1762933960366, "mdate": 1762933960366, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}