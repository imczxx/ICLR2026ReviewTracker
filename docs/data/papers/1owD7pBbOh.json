{"id": "1owD7pBbOh", "number": 23131, "cdate": 1758340006044, "mdate": 1763172331543, "content": {"title": "TRUST ‚Äì Transformer-Driven U-Net for Sparse Target Recovery", "abstract": "Many inverse problems---from coded aperture optics to undersampled MRI---operate with unknown or poorly characterized sensing operators $ \\mathbf{A} $. Yet most sparse recovery methods assume $ \\mathbf{A} $ is precisely known, forcing costly calibration or restrictive acquisition protocols. We address the more realistic setting in which only limited number of observation--target pairs $ (\\mathbf{y},\\mathbf{x}) $ are available, necessitating joint operator learning and signal reconstruction. The core challenge is cross-domain dispersion: local structures in the signal $ \\mathbf{x} $ are spread globally into measurements $ \\mathbf{y} = \\mathbf{A}\\mathbf{x} $, while CNN architectures rely on local receptive fields. We propose TRUST, a hybrid model that uses multi-resolution attention to recover sparse support directly from measurements. Theoretically, under the standard RIP conditions on $ \\mathbf{A} $, we show that attention maps computed on $ \\mathbf{y} $ approximate those computed on the true signal $ \\mathbf{x} $, with error bounded by the RIP constant. Architecturally, a Vision Transformer encoder estimates global sparse support from $ \\bf y $, and attention-guided skip connections steer a U-Net decoder to concentrate reconstruction capacity on support-consistent regions, coupling global contexts with local details. TRUST resolves the mismatch between measurement dispersion and the locality bias of CNN-only approaches. Across optical imaging, FastMRI, and ImageNet benchmarks, it consistently surpasses strong baselines -- both objectively and subjectively -- with marked reductions in hallucination artifacts. These results establish attention-guided support estimation as a principled and effective approach to high-quality reconstruction while jointly learning unknown sensing operators, enabling robust performance on inverse problems where conventional methods require the precise knowledge of forward models.", "tldr": "We introduce TRUST, a hybrid Transformer‚ÄìU-Net architecture that jointly learns unknown sensing operators and reconstructs signals, using attention to recover sparse support directly from measurements.", "keywords": ["Inverse Problem", "Sparse recovery", "Compressed sensing", "Cross-domain reconstruction"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/b3898f7ccdb11c7a79037cb756028a7359cd08f3.pdf", "supplementary_material": "/attachment/22cf81bee62b3657f4bfaac8b4e9b769cc9bc377.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a hybrid transfomer-CNN architecture for solving inverse problems, and experiments on FastMRI, random impainting and fiber coded aperture microendoscope. The paper argues that the attention mechanism improves the capacity of the reconstruction network to deal with 'global' forward operators that mix information across large spatial regions in the image."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- the paper studies deep learning-based reconstruction methods for coded aperture microendoscopy, which seems an important application."}, "weaknesses": {"value": "- The presentation of the paper could be significantly improved:\n    - claims such as \"such as classical CNNs or even U-Net‚Äîcan struggle to recover globally consistent structure, especially when long-range dependencies are critical to disambiguate spatial information.\" are not backed by references\n    - There seems to be some confusion regarding the 'attention' mechanism used in Restormer, which is based on channel attention, and not spatial self-attention used in ViT and other similar architectures. \n   - various sentences are flawed, e.g. \"using the same fixed mask and randomly retains 25% of pixels \"\n   - The setup of the optical experiments (Section 4.4) lacks more explanation about the forward operator and the imaging setting.\n   - There seems to be confusion regarding unrolled networks: these architectures can use arbitrary learnable regularization terms, often being replaced by a U-Net architecture (potentially with attention blocks).\n\n- The link with compressed-sensing, RIP, and sparsity doesn't have much relationship with the actual method that is evaluated in the experiments. \n   - There is no clear \"sparsity\" in the proposed network, as far as I understand\n   - The RIP analysis is vacuous in my opinion: self-attention is not performed directly on $y$, but rather some deep internal representation of the measurements\n\n- The experiments seem flawed: The FastMRI results in Fig. 7 seem very blurry and severely far from those in the state-of-the-art for that level of acceleration (as it can be deduced from the measurements $y$ in that figure). It appears that the authors have also incorrectly rescaled the MRI figures, resulting in a distorted aspect ratio for the knee images.\n\n- The novelty of the paper is limited: the paper proposes an end-to-end architecture based on existing well-known blocks."}, "questions": {"value": "- The goal of figures 3 and 4 is unclear? What is the reader supposed to learn from them? It is not easy to take strong conclusions from feature maps and their downsampled counterparts.\n\n- What is the goal of the CS equations in (1)? They have no link to the proposed method as far as I understand."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B4XHFBlFG1", "forum": "1owD7pBbOh", "replyto": "1owD7pBbOh", "signatures": ["ICLR.cc/2026/Conference/Submission23131/Reviewer_jJLw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23131/Reviewer_jJLw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761415294630, "cdate": 1761415294630, "tmdate": 1762942524921, "mdate": 1762942524921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "WNaUlxCJ14", "forum": "1owD7pBbOh", "replyto": "1owD7pBbOh", "signatures": ["ICLR.cc/2026/Conference/Submission23131/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23131/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763172330780, "cdate": 1763172330780, "tmdate": 1763172330780, "mdate": 1763172330780, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a hybrid architecture (TRUST) that combines a Vision Transformer (ViT) encoder with a U-Net‚Äìstyle decoder to address sparse signal recovery in inverse problems where the forward operator A is unknown and must be implicitly learned from observation‚Äìtarget pairs. The proposed architecture leverages multi-resolution attention to estimate sparse support directly from the measurements $y$, then uses attention-guided skip connections to steer the decoder toward support-consistent regions. The authors provide a theoretical justification based on the Restricted Isometry Property (RIP), showing that attention maps computed on $y$ approximate those on the target signal $x$ with an error bounded by the RIP constant."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The authors provide a theoretical justification using the Restricted Isometry Property and show that self-attention computed on the measurements $y$ approximates that on the target signal  $x$, with error bounded by the RIP constant. This offers a signal-processing justification for applying self-attention directly in the measurement domain, a useful insight for the inverse problems community."}, "weaknesses": {"value": "* While the hybrid encoder-decoder architecture of TRUST is well motivated, it closely resembles TransUNet. The claimed innovation, the attention-guided skip connections, is not described in sufficient technical detail (e.g., how attention maps modulate skip features), making it hard to assess how this differentiates from prior hybrid models. More specifically, the design presented in Section 3.2 and Figure 2 is not different from the standard ViT + UNeT architecture.\n* The authors assume sparsity but do not clarify whether it refers to pixel-domain sparsity, transform-domain sparsity, or learned sparsity. This matters because the theoretical RIP argument applies strictly to k-sparse vectors in the same domain as A, which may not hold in natural images.\n* The bound $|x^TA^TAx' - x^Tx'|$ assumes $x$ and $x^‚Ä≤$ are k-sparse and normalized, which is unrealistic for natural images (e.g., ImageNet). The empirical success may rely more on pretraining and data-driven learning than the RIP-based guarantee, which weakens the theoretical contribution‚Äôs practical scope.\n* Models like SwinIR, Uformer, or MIMOUNet, which also integrate multi-scale attention for inverse problems are not discussed, raising questions about the completeness of the related work.\n* By inspecting the code, the comparison between TRUST and TransUNet is not fair.  The encoder used in TransUNet is trained from scratch while TRUST utilizes pretrained CLIP weights."}, "questions": {"value": "The authors repeatedly emphasize ‚Äúattention-guided skip connections‚Äù as a core innovation, but never specify how attention maps modulate the skip pathways. Can you please elaborate on this aspect?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nculgLQZXV", "forum": "1owD7pBbOh", "replyto": "1owD7pBbOh", "signatures": ["ICLR.cc/2026/Conference/Submission23131/Reviewer_AAAK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23131/Reviewer_AAAK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935540402, "cdate": 1761935540402, "tmdate": 1762942523873, "mdate": 1762942523873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TRUST, a ViT-encoder + U-Net-decoder architecture for solving linear inverse problems when the forward operator A is unknown or poorly characterized. The core idea is that self-attention on measurements y=Ax can approximate attention on x under RIP-like assumptions, allowing a Vision Transformer to extract global dependencies directly from measurements. Attention-guided skip connections then feed this global context into a U-Net decoder to reconstruct fine details. Experiments on masked ImageNet patches, single-coil FastMRI, and a coded-aperture optics dataset show moderate improvements over U-Net and TransUNet, but only small or mixed gains over Restormer."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Clean, practical hybrid architecture combining ViT for global context with a U-Net decoder for detail refinement.\n\nPretraining benefits are well demonstrated, and the overall design is computationally efficient at inference relative to Restormer.\n\nThe use of the false discovery rate (FDR) metric is a valuable addition for quantifying hallucinations in reconstructions.\n\nImplementation simplicity: TRUST can be applied with minimal modification to standard reconstruction pipelines."}, "weaknesses": {"value": "heoretical contribution is minimal. The RIP-based argument about attention similarity is trivial and disconnected from end-to-end reconstruction performance.\n\nClaimed robustness to unknown or uncalibrated A is not demonstrated; all experiments use known and fixed operators.\n\nImprovements over Restormer are marginal or inconsistent (e.g., identical PSNR/SSIM in ImageNet 100%, mixed results at 25%, small +1 dB gain on FastMRI). No confidence intervals or statistical tests are provided.\n\nThe analysis does not identify which component‚ÄîViT encoder, skip design, or loss formulation‚Äîdrives improvements.\n\nBenchmarks are limited: masked ImageNet and single-coil FastMRI do not test generalization or operator mismatch.\n\nNo study of computational budget, model robustness, or sensitivity to operator perturbations."}, "questions": {"value": "Can you connect the RIP-based attention bound to actual reconstruction accuracy or sample complexity?\n\nHow robust is TRUST to operator mismatch‚Äîe.g., unseen masks, changed optics PSFs, or altered sampling patterns?\n\nAre the improvements over Restormer statistically significant under equal compute and training schedules?\n\nWhich architectural element (ViT encoder, skip connections, or loss) is primarily responsible for the gains?\n\nCan the model generalize to multi-coil or nonlinear operators?\n\nHow reliable is the FDR metric as a measure of hallucination‚Äîdoes it correlate with perceptual error or SSIM/PSNR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "A4TsoSGrTO", "forum": "1owD7pBbOh", "replyto": "1owD7pBbOh", "signatures": ["ICLR.cc/2026/Conference/Submission23131/Reviewer_ejiZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23131/Reviewer_ejiZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135806370, "cdate": 1762135806370, "tmdate": 1762942523578, "mdate": 1762942523578, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a hybrid deep network, TRUST, for solving linear inverse problems where the sensing operator \nùê¥ is unknown or partially known. The method uses: a Vision Transformer encoder to estimate global sparse support directly from the measurement y, and attention-guided skip connections and a U-Net-style decoder to refine local details. The method is supervised-based.\nExperiments on optical coded-aperture imaging, FastMRI, and masked ImageNet show improved PSNR/SSIM and fewer hallucination artifacts compared with U-Net, TransUNet, and Restormer baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ Clear motivation, and it is important to tackle the practical challenge of incomplete knowledge of the forward operator, moving beyond the idealized assumptions of traditional compressed sensing.\n\n+ The paper includes ablation studies on loss functions, skip connections, and ViT pretraining, providing certain insights into the contribution of each component to the studied question."}, "weaknesses": {"value": "- The core motivation of this paper is actually very straightforward ‚Äî essentially, the authors aim to reconstruct images from incomplete measurements when the sensing operator A is unknown/partial. However, the presentation makes this simple idea unnecessarily difficult to follow. The writing is overly verbose and circuitous: the abstract and introduction repeat the same points in different forms instead of directly stating the motivation and contribution. As a result, readers must work hard to extract a concept that could have been summarized in a few sentences. Also, for example, Figure 1 and its accompanying discussion add little technical value and could be safely removed; the space would be better used to clearly explain the problem setting and the novelty, and include more evaluation tasks.\n- Technically, the work has limited novelty. The model is essentially a supervised combination of a Vision Transformer encoder and a U-Net decoder, using standard losses (‚Ñì‚ÇÇ + SSIM) and skip connections. The method remains a straightforward supervised mapping. Conceptually, this is an incremental variation of prior architectures such as TransUNet or Restormer. \n- Generalization and reconstruction quality remain weak. Results show visible blur and artifacts, particularly outside the training domain, indicating that the network overfits to specific measurement operators and does not robustly handle unseen conditions.\n- The authors should also consider evaluating Helmholtz-governed wave problems. This is a natural fit for their ‚Äúunknown A\" claim and would more rigorously probe operator-shift generalization, complex-valued reconstruction, and artifact control."}, "questions": {"value": "See \"weaknesses\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O3Z53KKXIW", "forum": "1owD7pBbOh", "replyto": "1owD7pBbOh", "signatures": ["ICLR.cc/2026/Conference/Submission23131/Reviewer_EBKL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23131/Reviewer_EBKL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762489632541, "cdate": 1762489632541, "tmdate": 1762942523258, "mdate": 1762942523258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}