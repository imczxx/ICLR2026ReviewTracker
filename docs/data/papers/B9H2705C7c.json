{"id": "B9H2705C7c", "number": 20742, "cdate": 1758309554719, "mdate": 1763591082337, "content": {"title": "Prediction with Expert Advice under Local Differential Privacy", "abstract": "We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \\textit{central} DP algorithm by 1.5-3$\\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.", "tldr": "Two locally-DP online learning algorithms that improve on the privacy and utility of the classical baseline at minimal cost.", "keywords": ["privacy", "differential privacy", "online learning", "online linear optimization", "local differential privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dca02af456347d35214a4f61eaa5141769c12f52.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies the problem of online prediction with expert advice under local DP constraints. It introduces two algorithms, RW-AdaBatch and RW-Meta, and provides theoretical analyses of the proposed methods. The paper also includes experimental results on a real-world dataset."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper studies a relevant problem.\n- The proposed methods are supported by formal regret bounds and empirical experiments on real-world data."}, "weaknesses": {"value": "- From Table 1, the proposed algorithms appear to improve over RW-FTPL only by a small constant factor, which does not seem significant.\n- The paper lacks a regret lower bound for the problem."}, "questions": {"value": "- In Line 151, the authors state that the LDP guarantees still hold even against adaptive adversaries. Does the algorithm also remain valid in the adaptive setting? If so, what is the utility in this case?\n- Why is there no experimental comparison with Asi et al. (2023)? From Line 103, the authors mention that Asi et al. (2023) studies the high-dimensional regime. Could you further what this means and why it makes direct comparison difficult?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tGQY2HAamj", "forum": "B9H2705C7c", "replyto": "B9H2705C7c", "signatures": ["ICLR.cc/2026/Conference/Submission20742/Reviewer_M68M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20742/Reviewer_M68M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761088719994, "cdate": 1761088719994, "tmdate": 1762934163574, "mdate": 1762934163574, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work studied the problem of prediction from expert advice under local differential privacy constraints. Building on random-walk follow-the-perturbed-leader (RW-FTPL), the authors first showed that the perturbation in RW-FTPL can imply LDP guarantee. Based on it, they designed the RW-AdaBatch algorithm to achieve privacy amplification. And they also designed RW-Meta algorithm for dynamic environments by adopting a noise-sharing scheme. They provided stability,  theoretical privacy and utility analysis for RW-FTPL and regret guarantee for RW-Meta. Finally, they also provided empirical results on the COVID-19 task to show the advantages of their methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper investigated an interesting problem of prediction from expert advice in online learning under differential privacy.\n2. The paper provided some theoretical analysis and guarantees.\n3. The authors implement their methods on real data."}, "weaknesses": {"value": "1. The statement of writing and notation is confusing. For example, the paper mixed the statements of LDP and CDP. In the title, the authors used LDP, but in many places, they claim CDP. For the privacy parameter, somewhere $\\epsilon$ is used, and somewhere $\\mu$ is used.\n2. Lacks direct numerical comparisons with recent LDP online learning works [1].\n3. See more in the Questions part.\n\n[1]. Cheng, Duo, Xingyu Zhou, and Bo Ji. \"Follow-the-Perturbed-Leader for Adversarial Bandits: Heavy Tails, Robustness, and Privacy.\""}, "questions": {"value": "1. Why is the description for RW-FTPL from lines 188-192 different from Algorithm 1? \n2. The final step in Algorithm 2: set a new delay using Theorem 1. It is unclear to me how to set it. Can you explain more about it?\n3. What does \"Ada\"  mean in \"RW-AdaBatch\"? Could you please give some explanation for it?\n4.  What is the advantage of RW-AdaBatch compared with RW-FTPL? And from your Table 1, the regret of RW-AdaBatch is worse than RW-FTPL where $\\alpha>0$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GCWW292zN8", "forum": "B9H2705C7c", "replyto": "B9H2705C7c", "signatures": ["ICLR.cc/2026/Conference/Submission20742/Reviewer_1cZk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20742/Reviewer_1cZk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761228118622, "cdate": 1761228118622, "tmdate": 1762934162460, "mdate": 1762934162460, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the classical problem of prediction with expert advice under local differential privacy (LDP) constraints. The authors show that an existing algorithm naturally satisfies LDP. Moreover, the authors extend this algorithm to two new ones, named RW-AdaBatch and RW-Meta. RW-AdaBatch leverages the limited switching behavior of the existing algorithm to achieve adaptive privacy amplification while incurring a minimal cost to utility. RW-Meta extends the classical algorithm to data-dependent experts, which themselves are online learning algorithms. Finally, the authors complement their theoretical results with experiments on real-world data reported by hospitals during the COVID-19 pandemic."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper studies an important problem at the intersection of privacy and online learning\n- The theoretical results seem to be novel, and the experimental results are strong."}, "weaknesses": {"value": "My biggest issue with this paper is its lack of clarity regarding the significance of its results. While I don't doubt that results and proofs are novel, I am having a hard time seeing what these results improve upon in private online learning. \n\nFor example, a regret bound of $\\frac{\\sqrt{T}}{\\eps}$  under local DP can be derived from Theorem 4.1 in [1] by doing the same analysis except using the full-information multiplicative weights algorithm instead of EXP2.  In light of this, what are the main contributions of your work? Do you obtain a better privacy-utility tradeoff than this? Is your algorithm more efficient than running MWU on the noisy loss vectors? Do your algorithms obtain better central privacy-utility tradeoffs? More generally, why should I run your algorithm over just MWU on the noisy loss vectors?\n\nIn addition, as there are no closed-form privacy guarantees, it was not clear to me how the proposed algorithms will be practically useful. That is, how should a practitioner translate their desired privacy guarantee to the correct hyperparameters in the proposed algorithms? It would be great if the authors could walk me through how to do this.  \n\n[1] Agarwal, Naman, and Karan Singh. \"The price of differential privacy for online learning.\" International Conference on Machine Learning. PMLR, 2017."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ob86lCkXCe", "forum": "B9H2705C7c", "replyto": "B9H2705C7c", "signatures": ["ICLR.cc/2026/Conference/Submission20742/Reviewer_J3Gx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20742/Reviewer_J3Gx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947290820, "cdate": 1761947290820, "tmdate": 1762934160983, "mdate": 1762934160983, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies prediction with expert advice under local differential privacy. That is, a learner aims to minimize the regret when the gains provided are noisy. It introduces two algorithms RW-AdaBatch, which modifies Random-Walk Follow-the-Perturbed-Leader (RW-FTPL) to adaptively batch inputs when predictions are unlikely to change, and RW-Meta, a meta-learner that privately selects among data-dependent experts using shared Gaussian noise."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Extends the prediction-with-expert-advice framework to the local DP regime.\n- RW-AdaBatch builds on RW-FTPL, showing that when its predictions stay stable, several updates can be grouped together. This  effectively mixes them like shuffling does in batch privacy, hence, gains privacy at little extra cost.\n- Introduces a new LDP setting where the meta-learner selects among data-dependent experts sharing the same privatized data stream. \n- In RW-Meta, the idea of reusing noise across learners is interesting."}, "weaknesses": {"value": "- The work’s strength is theoretical rather than practical. Local-DP assumptions are hard to satisfy in realistic online settings, and the empirical evaluation is limited in scale and scope.\n- The novelty seems to be low. RW-AdaBatch’s batching idea is a reformulation of existing privacy-amplification and RW-Meta reuses known post-processing principles rather than introducing a fundamentally new privacy mechanism.\n- RW-Meta’s design involves maintaining and updating full covariance matrices across all learners, which is feasible for small ensembles but would scale poorly if the number of learners grows, limiting practical flexibility.\n- The COVID-19 hospital experiment is limited (three states, one task), lacks baselines under equal conditions, and provides little sense of how privacy actually trades off against accuracy.\n- The paper is dense and somewhat hard to follow. Intuitions such as why batching helps or how covariance correction works are found in the proofs rather than illustrated clearly in the main paper."}, "questions": {"value": "1) RW-AdaBatch’s privacy amplification is demonstrated analytically but not empirically. Have the authors simulated or estimated the effective $\\epsilon$-$\\delta$ improvement to validate the theoretical claim?\n\n1) RW-Meta assumes that all learners observe the exact same privatized data stream. In more realistic scenarios, learners might instead see partially correlated noisy versions of the same underlying data. Could the authors comment on whether their analysis could extend to this setting, and how such correlated noise would affect both privacy and regret guarantees?\n\n2) RW-Meta maintains and updates full covariance matrices across learners. Up to what number of learners $m$ is this tractable in practice? What are realistic values of $m$? Could approximate or sparse updates mitigate the cost?\n\n3) The evaluation focuses solely on a COVID-19 hospital dataset with one prediction task, which feels somewhat artificial. Can the authors explain why this setup meaningfully represents real online decision problems under local privacy, or discuss how their methods might generalize to more natural data streams?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4h2pzRceTL", "forum": "B9H2705C7c", "replyto": "B9H2705C7c", "signatures": ["ICLR.cc/2026/Conference/Submission20742/Reviewer_7KQP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20742/Reviewer_7KQP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20742/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118970996, "cdate": 1762118970996, "tmdate": 1762934160048, "mdate": 1762934160048, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}