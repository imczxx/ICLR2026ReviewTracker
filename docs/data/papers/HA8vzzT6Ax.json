{"id": "HA8vzzT6Ax", "number": 5331, "cdate": 1757901880161, "mdate": 1759897981066, "content": {"title": "Break the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models", "abstract": "Watermarking is a principled approach for tracing the provenance of large language model (LLM) outputs, but its deployment in practice is hindered by inference inefficiency. Speculative sampling accelerates inference, with efficiency improving as the acceptance rate between draft and target models increases. Yet recent work reveals a fundamental trade-off: higher watermark strength reduces acceptance, preventing their simultaneous achievement.\nWe revisit this trade-off and show it is not absolute. We introduce a quantitative measure of watermark strength that governs statistical detectability and is maximized when tokens are deterministic functions of pseudorandom numbers. Using this measure, we fully characterize the trade-off as a constrained optimization problem and derive explicit Pareto curves for two existing watermarking schemes.\nFinally, we introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency. Experiments further show that this approach improves detectability without sacrificing efficiency.\nOur findings uncover a principle that unites speculative sampling and watermarking, paving the way for their efficient and practical deployment.", "tldr": "We revisit the trade-off between watermarking and speculative sampling, introducing a new strength measure and mechanism to break the trade-off.", "keywords": ["Watermark", "LLM decoding", "Speculative Sampling"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/48476ce6c5eca2dfcdb7390c21fa464b667e8f4d.pdf", "supplementary_material": "/attachment/22a965bdedc9f72d9e63d763e6f31703dcd021d2.zip"}, "replies": [{"content": {"summary": {"value": "This paper revisits the trade-off between watermark strength and speculative sampling efficiency in large language models (LLMs). The authors argue that the incompatibility stems from the use of independent random sources: watermarking modifies token sampling using pseudorandomness, while speculative sampling introduces additional stochasticity through draft-token acceptance. This mismatch weakens watermark detectability and limits inference efficiency. To resolve this, the paper proposes a unified pseudorandom framework that decomposes random sources into three independent components: \\(ζ_D\\) (for the draft model), \\(ζ_T\\) (for the target model), and \\(ζ_R\\) (for acceptance decisions)"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides a clear theoretical explanation for why speculative sampling and watermarking interfere with each other—namely, their reliance on separate random sources.  \n- The proposed pseudorandom acceptance mechanism is simple yet elegant, turning the generation process into a deterministic function of pseudorandom variables.  \n- Theoretical analysis (Pareto frontier characterization) and empirical evidence consistently demonstrate that the proposed design breaks the previously assumed trade-off between watermark strength and efficiency.  \n- The work unifies two practically important but previously conflicting mechanisms, offering a potential path toward efficient and traceable LLM inference"}, "weaknesses": {"value": "1. The experimental evaluation only considers two unbiased watermarking schemes (Gumbel-max and SynthID). The analysis would be more convincing if extended to other representative watermarking frameworks, such as KGW or reweight-based methods [1,2].  \n\n2. The proposed method requires applying watermarking to both the draft and target models during speculative sampling. The paper does not analyze whether this dual watermarking might affect text quality or fluency.  \n\n[1] Hu, Zhengmian, Lichang Chen, Xidong Wu, Yihan Wu, Hongyang Zhang, and Heng Huang. *Unbiased watermark for large language models.* arXiv preprint arXiv:2310.10669 (2023).  \n[2] Wu, Y., Hu, Z., Guo, J., Zhang, H., & Huang, H. *A resilient and accessible distribution-preserving watermark for large language models.* arXiv preprint arXiv:2310.07710 (2023)."}, "questions": {"value": "1. Could the authors discuss whether the pseudorandom control framework can be generalized to biased or reweighted watermark schemes?  \n\n2. Considering that speculative sampling is primarily designed to accelerate inference, the paper should report additional runtime measurements comparing (a) standard speculative sampling, (b) speculative sampling with watermarking, and (c) the proposed method, to confirm that efficiency gains are retained."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PCJTNKWyr7", "forum": "HA8vzzT6Ax", "replyto": "HA8vzzT6Ax", "signatures": ["ICLR.cc/2026/Conference/Submission5331/Reviewer_Zd3w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5331/Reviewer_Zd3w"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761704194918, "cdate": 1761704194918, "tmdate": 1762918012205, "mdate": 1762918012205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper revisits the trade-off between watermark strength and speculative sampling efficiency in large language models. It formally quantifies watermark strength using KL divergence and derives a theoretical upper bound equal to the entropy of the base model. To overcome the claimed inevitable trade-off from prior work, the authors propose a pseudorandom acceptance mechanism that makes the entire sampling process a deterministic function of pseudorandom seeds. They further introduce new detection methods (Ars-$\\tau$ and Bayes-MLP) leveraging this mechanism, and demonstrate through experiments that the approach improves detection performance without reducing decoding throughput."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper provides a theoretical framework connecting watermark strength and speculative-sampling efficiency. The proposed pseudorandom-acceptance mechanism is theoretically appealing, showing that the trade-off can be alleviated under certain conditions."}, "weaknesses": {"value": "1. The proof that watermark strength can reach the upper bound $WS = H(P)$ (Theorem 3.2) assumes that each $P_\\zeta$ is a completely deterministic distribution, where every generated token is fixed once the pseudorandom seed is given. However, even SynthID’s tournament sampling still has randomness after top-$k$ and $2^m$ rounds, so $P_\\zeta$ isn’t truly deterministic. This means the bound is more of a theoretical ideal than something achievable in real LLM decoding. The paper should make this distinction clearer and discuss how far practical schemes are from that ideal. For example, how much does it improve over different m (the number of layers used in SynthID)?\n\n2. The claim of achieving both the best sampling efficiency ($SSE = 1 - \\mathrm{TV}(Q, P)$) and the highest watermark strength ($WS = H(P)$) relies on several strong assumptions, such as perfectly unbiased decoders, fully deterministic generation, and independent pseudorandom seeds. If any of these assumptions don’t hold, the trade-off comes back. So should the result really be interpreted as showing what’s possible under idealized conditions, not as a general solution that always works?"}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fYIWbJdugf", "forum": "HA8vzzT6Ax", "replyto": "HA8vzzT6Ax", "signatures": ["ICLR.cc/2026/Conference/Submission5331/Reviewer_sUKk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5331/Reviewer_sUKk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934039706, "cdate": 1761934039706, "tmdate": 1762918011967, "mdate": 1762918011967, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper revisits the trade-off between watermarking and speculative sampling. It (i) quantifies watermark strength as the expected KL divergence, showing this metric controls the asymptotic p‑value decay rate of the optimal detector (ii) formalizes the strength–efficiency Pareto frontier (iii) proposes pseudorandom acceptance by introducing an extra seed $\\zeta_R$ so the accept/reject step is itself a deterministic function of pseudorandomness. Empirically, the method matches standard speculative sampling in AATPS while improving TPR@FPR=1% for detection compared with previous methods that preserve AATPS."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. New perspective (not detection‑first, measure strength via KL).\nThe paper propose to cleanly separates watermark strength from detector performance, grounding the former in an information‑theoretic quantity (expected KL) with a clear sample‑complexity interpretation (Theorem 3.1) and a tight entropy upper bound (Theorem 3.2). This presents a principled framework for further analysis.\n\n2. Evidence of better trade‑offs in practice.\nAATPS closely tracks the standard baseline, while detection improves compared with previous methods that preserve AATPS.\n\n3. Clear writing and organization.\nThe paper is easy to follow, with crisp statements, clear algorithm, and figures that directly support claims."}, "weaknesses": {"value": "### Whether the “trade‑off” truly disappears (terminology/interpretation).\n\nTheorem 4.1. builds on redefining strength as expected KL. This metrics makes some new proposed analysis possible. However, the paper itself clarifies that watermark strength ≠ detection efficiency (Remark 3.1): two schemes with comparable watermark strength may still differ in detection efficiency.\n\nRegarding specific methods, mixture of multiple pseudorandom sources will hurt detection efficiency, as more pseudorandom sources means more ambiguity at detection time. (Hu & Huang, 2024) uses one pseudorandom seed. (Dathathri et al., 2024) uses two seeds (draft + target), with multi-round tournaments there may be effectively more. This paper uses three seeds, further compounding interference among signals at detection time. Concretely, for any observed token the detector does not know whether it came from (i) an accepted draft token, (ii) a rejected token replaced from the residual, or (iii) the “extra” token when all draft tokens were accepted. This uncertainty necessarily makes practical detection weaker than the paper’s “WS” metric.\n\nIn Experiment section of this paper, the claim is also “improved detectability,” not matching with non-accelerated watermarking.\n\nTherefore, the “trade‑off” still exists. The paper pushes the practical frontier but does not remove it, the headline “BREAK THE TRADE-OFF” is overstated. A more faithful summary is that the method steadily approaches a better trade-off.\n\n### Minors:\n\nThe paper, for simplicity, treats positions as independent. A stricter analysis should avoid this assumption, and some results can hold without independence.\n\nSeed reuse is not discussed. Re-applying the same pseudorandom seed should be skipped (e.g., as in prior “context code history”) to maintain unbiasedness."}, "questions": {"value": "I would encourage authors to also report ANLPPT, as with AATPS for efficiency, to quantify the detectability gap relative to a non-speculative watermarked baseline.\nHow large is the remaining gap in detectable watermark signal strength?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bnG7cdJsOb", "forum": "HA8vzzT6Ax", "replyto": "HA8vzzT6Ax", "signatures": ["ICLR.cc/2026/Conference/Submission5331/Reviewer_d8rs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5331/Reviewer_d8rs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986456930, "cdate": 1761986456930, "tmdate": 1762918011654, "mdate": 1762918011654, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## Summary\nThis paper tackles a practical tension in LLM serving: **unbiased text watermarking** (for provenance) versus **speculative sampling** (for speed). Prior work framed this as a binary impossibility: you can either preserve the watermarked distribution or preserve the acceptance rate, not both. The authors (i) introduce a **quantitative notion of watermark strength** — the expected KL divergence $E_\\zeta[D_{KL}(P_\\zeta || P)]$ — and prove it is the **exact detection rate** (via Chernoff–Stein); (ii) cast watermark–efficiency trade-offs as a **Pareto optimization** and empirically map the curve for several watermark classes (Gumbel-max, SynthID, linear mixtures, prior classes); and (iii) propose a simple fix — **pseudorandomizing the accept/reject coin** in speculative sampling — so the whole decode becomes a deterministic function of seeds, achieving **maximum sampling efficiency** $1 - TV(Q,P)$ and **maximum watermark strength** $H(P)$ simultaneously. They also give practical detectors for speculative pipelines (Ars-$\\tau$ / Ars-Prior and Bayes-MLP / Bayes-Prior).\n\nProduction stacks already depend on speculative sampling; having a *measurable* frontier and a concrete recipe to sit on that frontier is valuable.\n\n## Main claims / contributions\n1. **Strength as information:** Define watermark strength as $E_\\zeta[D_{KL}(P_\\zeta || P)]$ and prove it controls the optimal detector’s p-value decay (through the per-token log-likelihood ratio).  \n2. **Tight frontier & optima:** For unbiased schemes, strength is upper-bounded by $H(P)$; speculative acceptance is upper-bounded by $1 - TV(Q,P)$. Gumbel-max and SynthID (as $m \\to \\infty$) are strength-optimal; the proposed **seeded acceptance** achieves *both* bounds simultaneously.  \n3. **Operational trade-offs & detectors:** A constrained program (Eq. 10) traces the **Pareto curve** $L(r)$. The paper designs detectors that account for draft/target paths; when the accept coin is known (Ars-$\\tau$, Bayes-MLP), detection is stronger than prior averaging approaches (Ars-Prior, Bayes-Prior)."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "## Strengths\n- **Conceptual clarity:** Moving from a binary notion to a continuous, information-theoretic strength is the right abstraction. It cleanly explains earlier \"impossibility\" statements and yields a usable frontier.  \n- **Tight theory that lines up with practice:** The Chernoff–Stein interpretation makes sample-complexity predictions directly actionable; the entropy and TV bounds give interpretable ceilings.  \n- **Simple, impactful algorithmic tweak:** Seeding the accept coin is minimal and compatible with production speculative pipelines.  \n- **Detector design under speculative sampling:** The draft/target path issue is real; the two Ars and two Bayes variants are a neat, pragmatic treatment.  \n- **Figures are helpful:** The trade-off plots communicate the Pareto picture at a glance; markers (WS/SE maintained, optimum) guide interpretation."}, "weaknesses": {"value": "## Weaknesses / limitations\n- **Oracle knowledge vs deployment reality:** Many results assume access to the base distribution $P_t$ (or accurate logits) and, for the strongest detectors, the **accept coin**. External forensics often lacks both; estimation error can materially affect strength and false positives.  \n- **Model/scale realism:** Simulated $(Q,P)$ pairs and small-vocab settings may not capture calibration quirks, long-tail tokens, or beam-blocking in large models.  \n- **Robustness / attack model:** The paper doesn’t stress-test adversaries who (i) alter spacing/punctuation, (ii) paraphrase with another model, or (iii) run ensemble-style removal — how quickly does the effective KL collapse?  \n- **Broader behavioral impacts not discussed:** Recent studies suggest watermarking can alter model behavior beyond detectability or quality trade-offs. *Downstream Trade-offs of a Family of Text Watermarks* (Ajith et al., EMNLP 2024) reports 10–20% drops in downstream task accuracy even for “unbiased” schemes like KGW, while *WaterJudge* (Molenda et al., NAACL 2024) quantifies a detectability–quality trade-off across watermark strengths. *Watermarking Degrades Alignment in Language Models* (Verma et al., ICLR 2025) further shows that watermarking can shift alignment properties such as truthfulness, safety, and helpfulness, mitigated partly by an external reward model. The paper would be stronger with a targeted discussion of how speculative sampling with watermarking affects alignment-relevant metrics (e.g., reward scores) and a short discussion citing these works to contextualize potential side effects.  \n- **Downstream behavior:** Stronger coupling can interact with alignment/quality. Recent work reports reward/quality/alignment degradations under watermarking; the paper doesn’t quantify the proposed method’s effect on reward score or human preference.  \n- **Reporting details:** Some derivations (e.g., Eq. 10) are explained tersely; detector training details and calibration of $\\tau$ / $p$ could be easier to reproduce.\n\n## Actionable suggestions\n1. **Adversarial/transform robustness:** Evaluate detectability after common edits (paraphrase via another model, synonym swaps, punctuation/whitespace jitter, mild re-ordering). Report the induced drop in effective strength and how close it is to theoretical predictions.  \n2. **Latency & throughput accounting:** Since the goal is \"fast **and** provable,\" include an end-to-end latency/throughput table under seeded acceptance (overhead of PRNG, acceptance calibration, detector extraction) to confirm the practical speedup survives.  \n3. **Downstream effects audit:** Report reward-model scores or human preference deltas for seeded-accept decoding vs baseline speculative and vs classic watermarks. Even a small ablation will reassure readers that “max strength” doesn’t quietly harm alignment/quality.  \n4. **Clarity & reproducibility:** Expand the derivation around Eq. 10 in the main text (one boxed paragraph). Right now it jumps out of the blue without providing much background.\n\nThe narrative is coherent and the prior binary impossibility is treated respectfully. I appreciated the clean placement of this work relative to Hu & Huang and SynthID, as well as the detector connection to Bayesian scoring networks. I would like to see clearer statements about assumptions (knowledge of $P_t$, seed/coin access) up front.\n\n\n## Writing and Presentation\nGenerally clear but somewhat difficult to follow; figures carry their weight. The \"what to believe after reading\" is crisp: *use KL as strength, plot the Pareto, seed the accept coin to sit on the frontier.* A bit more exposition around the constrained program and detector calibration would help readers who don’t already know speculative internals.\n\n## Nits / small issues\n- Define “accept coin” once in the intro or prelims to avoid hunting later.  \n- Around the entropy upper bound, one sentence explaining $WS = H(P) - E[H(P_\\zeta)]$ would help a beginner.  \n- Minor typographical cleanups: consistent capitalization of \"SynthID,\" spacing around $TV(\\cdot,\\cdot)$, and equation referencing."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VD6SypuVQi", "forum": "HA8vzzT6Ax", "replyto": "HA8vzzT6Ax", "signatures": ["ICLR.cc/2026/Conference/Submission5331/Reviewer_LCLc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5331/Reviewer_LCLc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762044870016, "cdate": 1762044870016, "tmdate": 1762918011451, "mdate": 1762918011451, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers watermarking when speculative sampling is used. Their results seem modular, allowing for improved watermarking with speculative sampling by improving standard watermarking schemes and applying them to both the draft and target models. Making this optimal seems to require an interesting trick that (pseudo)randomizes acceptance. They appear to understand all the key points, like that this will not introduce new distortions if the watermarks for the two models are independent."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper has several strong results. The basic observation, that one can overcome the limitation of Hu et al. by allowing for pseudorandom draft-token acceptance, is very nice and important. Watermarking under speculative sampling is an extremely important technical issue for deploying watermarks in real-world LLMs.\n\nI haven't read the paper carefully, but it seems to make real progress on an important practical question."}, "weaknesses": {"value": "I don't know of any."}, "questions": {"value": "Is Google's watermark really a deterministic function of pseudorandom numbers? I thought that tournament sampling doesn't satisfy this property at all: Doesn't it work by first sampling a few tokens, and then choosing deterministically between them? In which case, there's still a bunch of entropy left on the table in the initial sampling process."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DN4JcSSNY1", "forum": "HA8vzzT6Ax", "replyto": "HA8vzzT6Ax", "signatures": ["ICLR.cc/2026/Conference/Submission5331/Reviewer_m26b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5331/Reviewer_m26b"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission5331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762180694496, "cdate": 1762180694496, "tmdate": 1762918011189, "mdate": 1762918011189, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the trade-off between watermarking and speculative decoding. A relatively recent work had made a 'no-free lunch' observation, which shows that improving the watermark is at the cost of weakening the speculative decoding (acceptance rate), and vice versa. This paper challenges this observation by integrating the watermarking's pseduorandom mechanism into the speculative decoding mechanism. The paper studies the speculative-decoding and watermarking tradeoff and the resulting curves, proposes a method to 'break' these curves and presents some experiments, demonstrating the proposed method on the Gumbel and SynthID watermarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Overall, this is a solid and creative work. Here are some of its strengths:\n\n1. The paper is clearly written. Even though I have significant prior knowledge about both watermarking and speculative decoding I believe this paper will not be too hard to follow for a newcomer to these fields.\n\n2. The idea is novel and seemingly powerful. Furthermore, the authors address the combination of two important subjects in the AI community - trustworthiness and efficiency.\n\n3. The analysis is very interesting and creative! Reading this paper was really delightful."}, "weaknesses": {"value": "### Major:\n\n- **Clarity on SynthID:** The paper uses SynthId as a case-study in this work, as it is an 'unbiased watermark'. However, SynthID is a relatively large class of watermarks that follow the tournament sampling mechanism. The general SynthID watermark is not even unbiased (when N>2). Unfortunately, the authors do not provide sufficient information to understand which specific case of SynthID is proposed in this work. I also believe that such information should be added for the sake of clarity.\n\n- **Missing related work:** The content of this paper misses several related works on 'unbiased' watermarks for better context, which can also be considered for the analysis and experiments. The first [1] considers a similar hypothesis test to the one that is considered int his work, however through the Bayesian setting. This work is highly relevant due to its analysis in the 'token-level', as considered in this work. Furthermore, the results of [1] are stated in terms of the total variation distance, which may lead to easier integration with the speculative-decoding analysis that is done in this work. Beyond that work, there are highly related work that is missing for context - [2] provides a general formulation in terms of score and watermark transform optimization, proposing methods that outperform the considered watermarks in this work. [3] studies optimality \n\n- **Experiments section should be extended.** I would expect this section to consider more experiments, through more datasets (testing across specific tasks/domains) and testing more aspects of watermarking (robustness?). The current collection is quite narrow. Furthermore, I would expect a quantification of the watermark strength through p-values and quantification of the bias (through either textual quality or cross entropy/relative perplexity). \n\n### Minor:\n- The title of section 3 \"COMPLETE THE TRADE-OFF DIAGRAM\" is not clear.\n\n[1] Tsur, D., Long, C. X., Verdun, C. M., Hsu, H., Permuter, H., & Calmon, F. P. (2025). Optimized Couplings for Watermarking Large Language Models. arXiv preprint arXiv:2505.08878.‏\n\n[2] Tsur, D., Long, C. X., Verdun, C. M., Vithana, S., Hsu, H., Chen, C. F., ... & Calmon, F. HeavyWater and SimplexWater: Distortion-free LLM Watermarks for Low-Entropy Distributions. In The Thirty-ninth Annual Conference on Neural Information Processing Systems.‏‏\n\n[3] He, Haiyun, et al. \"Universally optimal watermarking schemes for llms: from theory to practice.\" (2024).‏"}, "questions": {"value": "Bellow are both questions and comments:\n\n- **Connection to (Hu & Huang 24) and the hypothesis test:** The difference from the results in (Hu & Huang 24). which is explained in Remark 3.1 is unclear to me. First, the comparison itself is a bit odd. The referred paper discusses asymptotic results of the hypothesis test, while this work (while not stating clearly) is a token-level mechanism. The notion of a sequence is not addressed at any stage of this work. Second, Both works quantify the watermarks strength (detection) through the KL between distributions. This is an immediate results from the error exponent of the hypothesis test. \n\n- Following the previous comment, as the authors consider the 'token-level' hypothesis test, the use of the KL divergence to quantify the distributional divergence seems a little odd. In the hypothesis testing context, and as noted in this paper, KL divergence emerges in an asymptotic analysis (Through the error exponent of the type-2 error in the equivalent independence the between the 'i.i.d.' tokens and the psuedorandom process). The setting that manifests the KL divergence doesn't seem to fit strongly in the proposed operational setting of this work. I would appreciate the authors' thoughts on that. I believe that the mentioned related works [1,2] might be highly impactful to address this issue.\n\n- The expected KL divergence in eqn (7) is a popular quantity in information theory termed 'conditional KL divergence' - I would use that standard notation.\n\n- I believe that the watermark transformation can be regarded as a transition kernel similarly to the speculative decoding mechanism. Is there a reason to not address is as one in this work?\n\n- Do the results of this work extend to the unbiased case? I would believe that the tilting mechanism in [2, Section 2] might come in handy as a formulation of 'removing bias'.\n\n- Is the proposed method applicable to a general new watermark or does a new solution should be tailored to each new watermark?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5D2niQL2pU", "forum": "HA8vzzT6Ax", "replyto": "HA8vzzT6Ax", "signatures": ["ICLR.cc/2026/Conference/Submission5331/Reviewer_4VEY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5331/Reviewer_4VEY"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission5331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762625348064, "cdate": 1762625348064, "tmdate": 1762918010910, "mdate": 1762918010910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}