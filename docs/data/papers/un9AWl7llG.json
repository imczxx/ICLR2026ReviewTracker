{"id": "un9AWl7llG", "number": 546, "cdate": 1756745574633, "mdate": 1759898254462, "content": {"title": "An Exploration of Non-Euclidean Gradient Descent: Muon and its Many Variants", "abstract": "To define a steepest descent method over a neural network, we need to choose a norm for each layer, a way to aggregate these norms across layers, and whether to use normalization.\nWe systematically explore different alternatives for aggregating norms across layers, both formalizing existing combinations of Adam and the recently proposed Muon as a type of non-Euclidean gradient descent, and deriving new variants of the Muon optimizer.\nThrough a comprehensive experimental evaluation of the optimizers within our framework, we find that Muon is sensitive to the choice of learning rate, whereas a new variant we call MuonMax is significantly more robust.\nWe then show how to combine any Non-Euclidean gradient method with model based momentum (known as Momo).\nThe new Momo variants of Muon are significantly more robust to hyperparameter tuning, and often achieve a better validation score.\nThus for new tasks, where the optimal hyperparameters are not known, we advocate for using Momo in combination with MuonMax to save on costly hyperparameter tuning.", "tldr": "We formalize many variations of the Muon optimizer as steepest descent, and propose new variations which significantly improve robustness to the choice of learning rate.", "keywords": ["optimization", "steepest descent", "muon", "spectral norm", "speedrun"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1cb07eda7bd3779a9847f61c5baeb84b2d0484af.pdf", "supplementary_material": "/attachment/32346f2a639760eb06bfae49e52c03c5f982f6b8.zip"}, "replies": [{"content": {"summary": {"value": "The paper formalizes Muon/Scion-style optimizers as steepest descent under non-Euclidean product norms, showing that practical MuonAdam is exactly constrained steepest descent w.r.t. a norm that aggregates spectral norms with an adaptive infinite norm. It then (i) generalizes Momo to arbitrary norms; (ii) proposes MuonMax, together with a stale dual-norm approximation that avoids extra polar computations; and (iii) provides controlled experiments on GPT-2-scale LMs over FineWeb/SlimPajama, showing substantially improved LR robustness with near-Muon’s memory and small wall-clock overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Unifying theory with practical implications. Clear derivations for constrained/regularized steepest descent, LMO/dual norms on product spaces, and an exact reinterpretation of Adam as steepest descent under adaptive norms—bridging disparate practices into one framework. \n2. Actionable new variants. MuonMax emerges naturally from the framework and, when combined with Momo, exhibits wide learning-rate basins and lower seed variance; the stale nuclear-norm trick is elegant and empirically effective.  \n3. Clarity and completeness. Propositions/Lemmas are precise; pseudocode and ablations aid reproducibility. The study isolates design axes and reports across them. \n4. Relevance. Addresses an active area and offers a principled recipe to reduce hyper-parameter tuning burden in new tasks."}, "weaknesses": {"value": "1. Scale & metrics. Experiments stop at GPT-2-Large on next-token loss; no downstream evaluations (e.g., perplexity-to-task correlation, zero-shot LM benchmarks) or larger-scale LLMs to confirm external validity.  \n2. Theory for “stale” approximation. The stale dual-norm update is well motivated but lacks stability/error bounds; only empirical justification is provided\n3. Ablation breadth. Useful ablations are present, yet a deeper comparison against other non-Euclidean/product-norm choices (e.g., modular norm training) and recent LMO variants would strengthen claims of generality"}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YK9oU9C7wR", "forum": "un9AWl7llG", "replyto": "un9AWl7llG", "signatures": ["ICLR.cc/2026/Conference/Submission546/Reviewer_27dR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission546/Reviewer_27dR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761542152031, "cdate": 1761542152031, "tmdate": 1762919194911, "mdate": 1762919194911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- Presents a unified view of Muon with Adam on a subset of parameters (MuonAdam) using non-Euclidean gradient descent, and places several existing opimizers, such as MuonAdam, Scion, and PolarGrad, within the same framework.\n- Generalizes the model-based momentum method for adaptive learning rates (Momo) to arbitrary norms; and plug it into models on the non-Euclidean gradient descent framework.\n- Systematically evaluates variants categorized by steepest-descent types (regularized or constrained), norm choices for Muon and Adam, finding that MuonMax-Momo achieves strong validation scores across a wider range of learning rates."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Places MuonAdam and several other optimizers on the same non-Euclidean gradient descent framework.\n- Combines Momo with the framework to achieve robustness to LR choices.\n- Proposes MuonMax-Momo, which demonstrates increased LR-tuning robustness while keeping near-identical memory overhead and 5% additional wall-clock time per step compared with Muon."}, "weaknesses": {"value": "- The paper unifies prior methods under the framework of non-Euclidean gradient-descent. Could this framework also help explain the theoretical properties of those methods? For example, the Momo paper includes a convergence analysis for Momo(-SGD) but not for Momo-Adam. How does this framework help understand the convergence properties for the algorithms such as MuonMax-Momo?\n- Without theoretical analysis, evaluation of a paper may rely on empirical results. However, because the experiments were conducted only on GPT-2–based models and were limited to two datasets, it is difficult to confirm that the proposed approach will generalize broadly."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F9URDG0cRA", "forum": "un9AWl7llG", "replyto": "un9AWl7llG", "signatures": ["ICLR.cc/2026/Conference/Submission546/Reviewer_VeqW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission546/Reviewer_VeqW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803856887, "cdate": 1761803856887, "tmdate": 1762915544825, "mdate": 1762915544825, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript challenges gradient descent optimization techniques. Based on alternative norm computation, the authors propose MuonMax and Momo, which enable improved insensitivity to hyperparameter tuning, specifically on the learning rate. Experiments demonstrate these improvements."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- I appreciate the learning rate sweep results, such as Figure 1, which clearly demonstrates the proposed method succeeds in achieving robust hyperparameter tuning.\n- Indeed, the hyperparameter tuning is an important issue, especially for large models. The learning rate is a core hyperparameter, and its insensitivity is expected to contribute to this field.\n- Indeed, the transformers exhibit different properties for optimization. The authors performed targeted experiments on transformers, especially for LLM tasks."}, "weaknesses": {"value": "- The experiments were performed for only two models and two datasets, which might be insufficient. The optimizers for comparison are limited to specific ones such as Muon and Scion.\n- Although the results are convincing in robust hyperparameter tuning, the demonstration is focused only on the final validation loss. Is it possible to demonstrate other indices, such as practical ones? I think certain practitioners may want to capture the performance more practically, but the value of loss is difficult to understand on an absolute scale. It is also difficult to understand whether it corresponds to sufficient convergence or is still far from convergence.\n- Experiments on more practical scenarios when learning rate tuning becomes difficult would enhance the results. For example, increasing mini-batch size affects tuning of learning rate; a sweep graph with mini-batch size, as well as learning rate, would make this manuscript further convincing.\n- How about hyperparameter tuning sensitivity on \\beta in the Adam family?\n- Please check the following mathematics.\n    - At Line 769, I think it should be $+r_t \\Delta_t$, not $-r_t \\Delta_t$.\n    - At Line 938, it should be $r_t \\Delta_t$, not $r_t + \\Delta_t$.\n    - For Line 8 of Algorithm 3, the last term should be g_t^\\theta with \\theta_t, not with m_t^\\theta, to be compatible with Eqs. 85-88.\n    - The sign of LMO is confusing. Specifically, when following the standard definition, LMO should be already negative, whose gradient descent becomes rather ascent. How about writing LMO at Eq. 68 to include a negative sign and writing the sign of LMO to be +, not -, at Eqs. 22 and 24? This choice depends on the authors but might improve readability.\n- Writing should be improved.\n    - “Furthermore” → “Furthermore, ” at Line 131.\n    - “was” → “were” at Line 165.\n    - “Schaipp et al. (2024)” should be written with \\citep.\n    - “the the final loss” → “the final loss” at Line 455.\n    - “increases the lost” → “increases the loss” at Line 482.\n    - “this is function is” → “this function is” at Line 1010.\n    - For the caption of Figure 1, GPT2-Large should be 774M, not 124M.\n- For the source code, the authors write HybridProductNorm, which computes lmo_dict. For this code, LMO is computed as a single constant for muon, whereas others are allowed to be layerwise constant. This requires explanation."}, "questions": {"value": "Please see the weaknesses above. My score is based on the assumption that all typos are corrected in the revised manuscript."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SWOmEsE5Xe", "forum": "un9AWl7llG", "replyto": "un9AWl7llG", "signatures": ["ICLR.cc/2026/Conference/Submission546/Reviewer_jNaZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission546/Reviewer_jNaZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812678361, "cdate": 1761812678361, "tmdate": 1762915544731, "mdate": 1762915544731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a unified steepest-descent view of Muon-type optimizers by choosing per-layer norms, an across-layer product norm, and optional normalization. Within this framework it formalizes practical Muon+Adam (MuonAdam) as constrained steepest descent, extends model-truncation momentum (Momo) to arbitrary norms, and proposes MuonMax, a new regularized variant induced by a max-spectral or ada2 product norm. Language-modeling experiments on GPT-2 scales suggest that Momo-augmented variants, especially MuonMax-Momo, achieve similar or better final loss with wider learning-rate basins, while a stale dual-norm trick preserves accuracy with modest overhead."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear theoretical unification. The paper characterizes MuonAdam as constrained steepest descent under a specific product norm, aligning spectral-norm LMOs for matrices with Adam-style updates for non-matrix parameters in a single principled step and opening a coherent design space.\n\n2. Practical and robust variant with concrete derivations. MuonMax is explicitly defined, its Momo version admits a closed-form update, and experiments show broad learning-rate robustness and reduced seed variance relative to strong baselines."}, "weaknesses": {"value": "1. Efficiency overhead is only partially quantified. The stale nuclear-norm approximation reduces MuonMax-Momo overhead from roughly eleven percent to about five percent per step versus MuonAdam, but the paper does not report end-to-end throughput or time-to-target loss across hardware and precision regimes, and the reliance on PolarExpress in bfloat16 introduces possible stability and accuracy tradeoffs that are not analyzed.\n\n2. Scope limited to autoregressive language model pretraining. All experiments are on GPT-2-style models and two text corpora, with no tests on architectures or modalities where parameter partitions and curvature differ, such as ViTs, ConvNets, MoEs, or sequence-to-sequence models. The paper cites closely related modular-norm methods but does not include a direct baseline from that family.\n\n3. Limited baseline coverage under matched tuning budgets. Comparisons emphasize Muon family variants, but the paper does not present compute-normalized results against strong first-order baselines such as AdamW, Lion, Adan, or Sophia with matched hyperparameter search budgets. Because the paper highlights “wide learning-rate basins” as a key advantage, the absence of equal-budget LR and scheduler sweeps for these baselines weakens the central empirical claim."}, "questions": {"value": "1. Will you add compute-normalized, equal-budget comparisons against strong first-order baselines such as AdamW, Lion, Adan, and Sophia, reporting identical hyperparameter search grids, scheduler options, and seeds, and measuring both final loss and time-to-target?\n\n2. Since wide learning-rate basins are a central claim, can you quantify basin width uniformly across methods using the same grid and seed protocol, and report success rates, median best LR, and sensitivity surfaces for matrix and non-matrix step sizes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mgVtFI8Atz", "forum": "un9AWl7llG", "replyto": "un9AWl7llG", "signatures": ["ICLR.cc/2026/Conference/Submission546/Reviewer_kwnU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission546/Reviewer_kwnU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940386716, "cdate": 1761940386716, "tmdate": 1762915544449, "mdate": 1762915544449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a unified theoretical framework for understanding the Muon optimizer and its variants as forms of steepest descent. The framework is characterized by three main design choices: the norm for each parameter group, the product norm used to aggregate norms across groups, and the type of steepest descent (constrained vs. regularized). Based on the framework, the authors propose a new variant, MuonMax. Furthermore, the paper generalizes an adaptive step-size method based on model truncation (Momo) to work with arbitrary norms. Experiemnts are conducted on GPT-2 models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The main strength of the paper is the development of a clear and unifying theoretical framework. Casting Muon-style optimizers as non-Euclidean steepest descent with choices of product norms and descent types is an insightful contribution.\n2. The technical contribution of extending Momo to operate with arbitrary norms is potentially useful for applying model truncation techniques to a wider range of optimizers."}, "weaknesses": {"value": "1. While the framework is theoretically elegant, it defines a large design space (norm for each parameter group, product norm, CSD vs. RSD) without providing strong principles or theoretical intuition for navigating it. The choice of MuonMax's design feels arbitrary rather than being a principled consequence of the theory.\n2. The proposed MuonMax optimizer is not sufficiently motivated. It is presented as one alternative in the design space, but the paper offers no theoretical argument for its superiority. Empirically, its performance is inconsistent. For instance, vanilla MuonMax is outperformed by MuonAdam as shown in Fig. 5. The paper's central claims heavily rely on its combination with Momo, suggesting MuonMax itself may not be a robust improvement.\n3. The paper's solution to learning rate sensitivity, Momo, introduces its own hyperparameters. Fig. 3 shows that the final performance of both MuonAdam-Momo and MuonMax-Momo is sensitive to the choice of $F_*$. This undermines the claim of reducing tuning complexity, as it appears to merely shift the burden from tuning $\\eta$ to tuning $F_*$.\n4. The experimental evaluation is narrow. The comparison is entirely focused on Muon variants within the proposed framework, missing widely-used baselines like AdamW. Furthermore, using only GPT-2 architectures limits the claims of generality."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PvCVsAbQRN", "forum": "un9AWl7llG", "replyto": "un9AWl7llG", "signatures": ["ICLR.cc/2026/Conference/Submission546/Reviewer_xjd6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission546/Reviewer_xjd6"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988894563, "cdate": 1761988894563, "tmdate": 1762915544038, "mdate": 1762915544038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}