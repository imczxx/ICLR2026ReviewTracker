{"id": "Lwn67fk9e1", "number": 23376, "cdate": 1758342804281, "mdate": 1763733171860, "content": {"title": "PerFit: Exploring Personalization Shifts in Representation Space of LLMs", "abstract": "Personalization has become a pivotal field of study in contemporary intelligent systems. While large language models (LLMs) excel at general knowledge tasks, they often struggle with personalization, i.e., adapting their outputs to individual user expectations. Existing approaches that steer LLM behavior to meet users’ implicit preferences and behavior patterns, primarily relying on tune-free methods (e.g., RAG, PAG) or parameter fine-tuning methods (e.g., LoRA), face challenges in effectively balancing effectiveness and efficiency. Moreover, the mechanisms underlying personalized preferences remain underexplored. To address these challenges, we first uncover key patterns of user-specific information embedded in the representation space. Specifically, we find that (1) personalized information lies within a low-rank subspace represented by vectors, and (2) these vectors demonstrate both a collective shift shared across users and a personalized shift unique to each individual user. Building on these insights, we introduce PerFit, a novel two-stage solution that directly fine-tunes interventions in the hidden representation space by addressing both collective and user-specific shifts, thereby achieving precise steering of LLM with minimal parameter overhead. Experimental results demonstrate that \\perfit delivers strong performance across six datasets while \\cutting the number of parameters by an average of 92.3% compared to the state-of-the-art method.", "tldr": "", "keywords": ["Personalization", "Large Language Models"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c6a0ecbe30333f967a12fd1c4e81e3c77f92ffd6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents PerFit, a novel two-stage personalized fine-tuning method based on activation engineering that directly intervenes in the hidden representation space of large language models. The method design is motivated by an analytical study on difference-in-means personalization vectors, revealing that personalization lies in a low-rank subspace with collective and user-specific shifts. On top of this, PerFit first learns a global “collective shift” shared by all users and then learn user-specific vectors to modify the hidden representations. Experiments on various benchmarks show that PerFit achieves superior performance compared to state-of-the-art PEFT baselines, while reducing personalized parameters by ~92%, demonstrating the method’s efficiency and scalability."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-presented and easy for readers to understand.\n\n2. The analytical investigation on personalization vectors is interesting and well motivates the two-stage design of the method.\n\n3. By operating on low-rank hidden activation, PerFit greatly reduces the cost of both training and storage for each user, opening a new door for the following social simulation research, which involves many user behavior simulations.\n\n4. The experiments are comprehensive and well demonstrate the competitive performance and efficiency across six personalization tasks."}, "weaknesses": {"value": "1. While the experiments are comprehensive, the impact of collective user composition in Stage-1 remains underexplored. Since Stage-1 requires training across a group of users, it is likely that different levels of user diversity or distributional imbalance would affect the effectiveness and stability of the learned collective shift. The paper does not analyze the sensitivity of PerFit to the selection and variety of collective users.\n\n2. Although PerFit generally performs well, the paper provides limited insight into cases where it underperforms. For example, in Table 3, PerFit is worse than OPPU on Tweet Paraphrasing, yet no analysis is provided. Understanding failure patterns would be valuable for both practical deployment and method improvement.\n\n3. Efficiency claims mainly rely on parameter size and relative training time relationships. However, key metrics for real-world deployment, such as wall-clock latency (training and inference), GPU memory consumption, are not reported. Thus, the practical scalability advantage remains partially demonstrated.\n\n4. The two-stage design assumes that the learned collective shift generalizes across users. However, in dynamic environments where new users continuously join, it is unclear whether Stage-1 must be retrained or can be directly transferred. The paper does not empirically validate the stability of Stage-1 when user distributions change.\n\n5. PerFit injects personalization interventions into multiple layers, including early layers that encode core linguistic and semantic representations. Without any mechanism to constrain interference, such interventions may degrade the model’s general abilities. Yet no evaluation is conducted to verify preservation of generic performance or robustness.\n\n\nThe paper is technically strong and practically impactful, with clear novelty in modeling personalization in the representation space. Some analyses require further expansion, but the work provides valuable contributions to personalized LLM adaptation and opens promising directions for future research."}, "questions": {"value": "1. Can the authors provide insights or evaluate how the performance varies when the collective user set differs in diversity or behavioral distribution?\n\n2. What are the author’s hypotheses on why PerFit underperforms in the Tweet Paraphrasing task, and are there task-specific characteristics where representation-space interventions may be less effective?\n\n3. Could the authors provide more detailed runtime and memory measurements to substantiate the real-world efficiency improvements?\n\n4. Given dynamic real-world personalization, the transferability of Stage-1 to unseen users could be an interesting direction to explore. Have the authors observed whether the collective shift generalizes across user populations?\n\n5. Since personalization is applied at several (including early) layers, evaluating the effect on general model capability might provide additional assurance. Have the authors examined whether general capabilities are impacted when personalization vectors are injected?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Qt4xA6RPBG", "forum": "Lwn67fk9e1", "replyto": "Lwn67fk9e1", "signatures": ["ICLR.cc/2026/Conference/Submission23376/Reviewer_eWQo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23376/Reviewer_eWQo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761759781221, "cdate": 1761759781221, "tmdate": 1762942633302, "mdate": 1762942633302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PerFit, a two-stage framework for personalizing large language models (LLMs) via interventions in the representation space rather than the parameter space. The authors first uncover that user-specific information lies in a low-rank subspace characterized by both a collective shift shared across users and personalized shifts unique to each user. Leveraging these findings, they propose a two-stage fine-tuning procedure that first learns a collective representation shift from all users, and then conducts fine-tuning personalized shifts for each user. Experimental results on six LaMP datasets show that PerFit achieves comparable or better performance to strong baselines, while significantly reducing the number of trainable parameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. Conducts a comprehensive investigation into how personalization is captured by LLMs towards tackling the challenges associated with balancing the efficiency and performance, which provides key findings, including that users share clear collective shifts leading to their two-stage framework.\n\nS2. The framework itself is straightforward after uncovering the key findings in S1; although not technically complex, this is actually seen as a benefit. \n\nS3. The practicality of the framework with being so parameter efficient is likely to have significant impact on the community and lead to numerous follow up works in this direction."}, "weaknesses": {"value": "W1. Some concerns that with this framework primarily appearing to be heavily built on ReFT there is still something left for more novelty in the methodology. \n\nW2. The collective and personalization shift hypothesis is supported primarily through visualizations rather than more rigorous analysis."}, "questions": {"value": "Q1. Can you clarify the distinct differences between PerFit and prior representation fine-tuning methods?\n\nQ2. How do training and inference times compare to those baseline methods, given that your projection operation could not be absorbed into the base model?\n\nQ3. Do the collective shifts transfer across users or tasks, or are they tightly coupled to the dataset used in Stage 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zGYPdRaG02", "forum": "Lwn67fk9e1", "replyto": "Lwn67fk9e1", "signatures": ["ICLR.cc/2026/Conference/Submission23376/Reviewer_xGBE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23376/Reviewer_xGBE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980014122, "cdate": 1761980014122, "tmdate": 1762942633046, "mdate": 1762942633046, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PerFit, a novel parameter-efficient fine-tuning method for personalising large language models (LLMs). PerFit directly fine-tunes intervention vectors in this low-rank subspace via a two-stage process, first learning a collective shift and then user-specific personalised shifts. The method is evaluated on six tasks from the LaMP benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The achieved parameter reduction (81.25% to 98.44% compared to OPPU) is substantial and a clear practical advantage for scalable personalisation, where storing a unique adapter per user is a key bottleneck.\n2. The paper provides a thorough experimental section, answering key research questions with main results, efficiency analysis, and detailed ablation studies."}, "weaknesses": {"value": "1. The paper finds that intervening in earlier/middle layers (e.g., layers 5-10) works best (Fig. 6, Table 11) and that cumulative intervention can be harmful. However, the rationale for the specific choice of intervention layers is not sufficiently justified. It remains unclear if this is an optimal configuration derived from the analysis or a heuristic choice. A more principled connection between the location of the discovered low-rank subspace (Observation 1) and the optimal intervention layer would strengthen the methodology.\n\n2. The primary baseline comparison is against LoRA-based PEFT methods. While this is relevant, the work would benefit from a direct comparison to other Representation Fine-Tuning (ReFT) methods, such as the specific method presented in [1]. The authors mention that ReFT is used as a baseline with matched parameters (L1134-1136), but its results are not shown in the main tables. A direct comparison would better situate PerFit's two-stage, low-rank approach within the emerging ReFT paradigm.\n\n3. The concept of the \"collective shift\" is central to the method. However, its interpretation could be more deeply discussed. Is it primarily capturing a shift from a generic to a \"personalised-in-general\" mode of operation? Or could it be conflated with domain adaptation, as the collective data is task-specific (e.g., all news data for LaMP-4)? A brief discussion on disentangling these concepts would be helpful.\n\n\n[1] ReFT: Representation Finetuning for Language Models"}, "questions": {"value": "1. Was the analysis in Section 3 conducted per-layer to identify which layer's representations best exhibit the low-rank property for personalisation?\n\n2. Algorithm 1 and its context state that Stage-2 parameters are initialised from the shared parameters trained in Stage-1, rather than being initialised separately for each user. Could you elaborate on the rationale for this choice? Was ablating against random initialisation for Stage-2 parameters considered? This choice seems crucial for efficient knowledge transfer from the collective shift."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "U5JrHKYeCY", "forum": "Lwn67fk9e1", "replyto": "Lwn67fk9e1", "signatures": ["ICLR.cc/2026/Conference/Submission23376/Reviewer_CFGx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23376/Reviewer_CFGx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762188545991, "cdate": 1762188545991, "tmdate": 1762942632820, "mdate": 1762942632820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}