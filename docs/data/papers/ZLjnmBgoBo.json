{"id": "ZLjnmBgoBo", "number": 21474, "cdate": 1758317974648, "mdate": 1759896920016, "content": {"title": "Time-series based quantum state discrimination", "abstract": "Measurement errors in quantum computers are very detrimental to quantum computations. The ability to efficiently and accurately readout quantum states is crucial for quantum error correction schemes and quantum algorithms. Readout fidelity is typically limited by a poor signal-to-noise (SNR) ratio between the quantum states we intend to classify, as well as energy relaxation (e.g., T1 decay) from an excited state to a lower state during readout. Superconducting quantum bits (qubits), one of the leading candidates for scalable quantum computing hardware, are particularly limited by energy relaxation due to their relatively short coherence times. While most approaches for classifying the results of readout on superconducting qubits typically utilize clustering algorithms (e.g., a Gaussian mixture model) on integrated readout signals, these cannot distinguish between a quantum bit that was in the ground state prior to measurement from a qubit that decays to the ground state during measurement. For this reason, we instead propose using machine learning (ML) on the raw (non-integrated) analog signal and classification models on the full time series data (i.e., the trajectory). We observe that time series classification methods, such as our chosen long short-term memory (LSTM) model, in combination with filtering and feature engineering techniques, consistently outperform clustering models.  In particular, we find that the largest improvements come from reclassifying points in the boundary regions between neighboring clusters. These boundary points correspond to measurement records that deviate from the typical cluster, likely due to transient or noisy features in the signal that are not captured when the data is integrated. By retaining temporal information, sequence-aware models such as LSTMs can better discriminate these trajectories, whereas clustering methods based on integrated values are more prone to misclassifications.", "tldr": "Using time-series readout with preprocessing, we improve superconducting qubit state fidelity by ~1% over Gaussian Mixture Models across quantum qubits, offering a lightweight solution.", "keywords": ["Quantum Information Processing", "LSTM"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1acaf57ed110cf9c733033f5d5c1f4b1f1f37b5f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper utilizes LSTM networks to read out qutrit states from a superconducting transmon device. In typical setups, Gaussian mixture models, or GMMs, are typically employed for the task of identifying the states of the qutrits after integration is done on the raw signals. In doing so, critical information about the measurements is lost, and it can become difficult to identify states along what would be described as the decision boundary in classical machine learning. By using an LSTM, the authors argue that this important temporal information is captured, improving the classification accuracy of the states and therefore, the effective fidelity of the device. To show this, the authors perform a comparison between the GMM and the LSTM on a standard driving task by comparing the final accuracy of the two models. They find that the LSTM outperforms the GMM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The problem of error correction is, as clearly stated by the authors, a pressing issue in the community. Further, it appears that the LSTM approach improves the effective fidelity of these devices.\n* The experiments were conducted on real quantum devices, removing issues with simulation parameters and noise modeling. \n* The concepts are made clear to a broader audience, and in general, the paper is written very well."}, "weaknesses": {"value": "While overall the paper is quite sound and of interest, there were some parts that lacked clarity and accuracy.\n\n* Why do the authors not show the direct classification results? Showing only where one model gets it right but the other wrong does little to highlight the performance of the models. Further, without showing where both models go wrong, it isn't clear whether this comes down to architecture or other factors.  I see that this is included as fidelity scores later in the paper, but perhaps the structure could be cleaned up to show the raw results, followed by how the LSTM beats the GMM.\n* The areas where the LSTM beats the GMM are the same as where the GMM beats the LSTM. In the caption of Figure 5, only the former is highlighted as a feature. True, there are more points captured by the LSTM, but I think this needs to be elaborated on. In general, how much of that area is correctly or incorrectly classified? Judging by the fidelity results shown later, it is quite a small amount. That isn't to say it's not impactful, but I think this needs to be made clearer. \n* It is not clear that the structure processing of time in the LSTM is the reason for the improvements in the LSTM model. To make this claim, the authors would likely need to perform ablation studies with different context lengths.\n* Further, would a dense network with all measurements through time also perform well? For small trajectories, this would be feasible and fast. In general, a broader comparison of machine learning architectures would be helpful rather than jumping straight from GMM to LSTM. This would also align better with the goal of integrating these models onto devices.\n* I'm curious about the use of the term fidelity in describing the performance of the classification networks. This is for two reasons. One is purely from an understanding perspective. In the broader ML community, discussing fidelity in the context of classification performance will likely confuse people. The second is more technical. Should this value be referred to as a fidelity? I would consider fidelity to be how well my measurement aligned with my inputs. If I use a classification algorithm to classify my measurements, their performance isn't so much fidelity as simple algorithmic accuracy. Consider the case where a machine has perfect fidelity, but my algorithm is trained to also produce the wrong state. Does this system display a fidelity of 0 or 1? I would be interested in hearing the author's thoughts on this.\n* Information about model training is very limited. It would be nice to see the training curves, sizes of networks tested, and their performance, particularly under the motivation of embedding them onto a device."}, "questions": {"value": "* Can the authors quantify the preparation errors mentioned? The fidelities of the devices are already reasonably high, although it is stated that these preparation errors are small compared with noise, it would be good to have a general idea of their size.\n* How large were the biggest models used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9i75G4XQjg", "forum": "ZLjnmBgoBo", "replyto": "ZLjnmBgoBo", "signatures": ["ICLR.cc/2026/Conference/Submission21474/Reviewer_wCGo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21474/Reviewer_wCGo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761666123509, "cdate": 1761666123509, "tmdate": 1762941796430, "mdate": 1762941796430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper is concerned with quantum state discrimination: the problem of accurately reading out quantum states. Typical approaches for this problem employ Gaussian mixture model-based clustering algorithms. Here, the authors suggest to use LSTMs in combination with filtering and feature engineering approaches for quantum state discrimination based on the time series of the readout signal."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Currently used methods do not employ temporal information, so employing sequence models for incorporating time series data is well-motivated. Thus, the problem is very relevant for quantum computing, as quantum error correction schemes require high quantum state readout fidelity.\n\nThe experiments are based on real data and appear to be pratictically relevant. The experimental results (Table 2) indicate a consistent improvement of LSTM-based methods over the GMM-baseline method."}, "weaknesses": {"value": "My main concern with this paper is that, from a machine learning perspective, the innovation is very limited. LSTMs are standard models for sequence modelling and applying them to time-series classification is well-established. Thus, there do not seem to be any insights for a broader ML audience. The main challenge and contribution of the paper appears to be in the data pre-processing step. Then, any time-series classification method could be applied. Overall, the paper is written in a way that is much more suitable to a quantum computing venue, with the main emphasis put on physical details and on applying off-the-shelf ML methods to quantum state discrimination. \n\nIn addition, I also have several concerns regarding presentation and experiments.\n\nMissing experimental details: the paper does not provide sufficient details on the experiments to make them reproducible. For example, the number of layers / hidden nodes in the LSTMs are not specified. The chosen bin size for the binning procedure is not specified. The paper does not appear to use a validation set for selecting these hyper-parameters. Does Table 2 report classification accuracy on the test set?\n\nMethodology: the paper does not clearly explain how the LSTM is trained. The baseline method (GMM clustering) is an unsupervised learning method. In contrast, LSTM-based classification requires labeled training data and it remains unclear where this data is obtained from. \n\nComputing times: The paper states that the LSTMs make the approach feasible for deployment in real-time readout hardware (line 348), but does not report the compute times for the different methods. To support such a claim, also compute times need to be reported. \n\nRole of LSTMs: with the key step being the data preprocessing, the paper does not sufficiently examine the role of LSTMs for the improved accuracies. Does the improved accuracy stem from the improved data preprocessing step? Or does it actually stem from using LSTMs? Insight on this could be gained by including other time-series classification models in the comparison, for example, standard RNNs or state-of-the art time-series classifiers such as \nROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels by Angus Dempster, François Petitjean, Geoffrey I. Webb. \n\nLimited baselines: Since the introduction of GMM methods for this problem in 2014, there have been several other works that employ deep learning-based classifiers for quantum state discrimination (such as B. Lienhard et al. 2022 cited in the paper). It would be important to compare also to such methods. \n\nWrong key reference: the paper attributes LSTMs to Bengio et al. 2000 (see line 202). However, the original reference is the very well-known paper by Hochreiter and Schmidhuber (1997). \n\nActivation function: the method uses a sigmoid activation function for multi-class classification, which is very uncommon. Rather, softmax activations are typically used, since they restrict the outputs to sum to one. How do you handle cases where you get very low/high probabilities for all cases?"}, "questions": {"value": "- How did you select the number of layers / hidden nodes in the LSTMs?\n- How did you select the bin size for the binning procedure? \n- Does Table 2 report classification accuracy on the test set?\n- Can you be more specific on how the labels for training the LSTMs were generated?  \n- Can you report compute times for your different methods? \n- Can you provide further insights on the importance of using LSTMs vs. the improved data pre-processing step? \n- Using a sigmoid activation function for a multi-class classification problem, how do you handle cases where you get very low/high probabilities for all cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "lNHAhCCEOF", "forum": "ZLjnmBgoBo", "replyto": "ZLjnmBgoBo", "signatures": ["ICLR.cc/2026/Conference/Submission21474/Reviewer_LG1n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21474/Reviewer_LG1n"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816001964, "cdate": 1761816001964, "tmdate": 1762941796135, "mdate": 1762941796135, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, a novel approach to efficiently and accurately readout quantum states is presented. This task is curcial for quantum error correction.\n\nThe authors proposed to use machine learning for this task. In particular a LSTM model, in bomcination with filtering and feature engineering techniques is presented.\n\nThe proposed approach outperform clustering models and is better that the proposed time-series baseline (GMM).\n\nThe application of an LSTM-based classifier to bandpass-filtered readout traces is not well aligned with ICLR’s core focus on methodological advances in machine learning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Readout fidelity is a well-known bottleneck in superconducting qubit systems\n- Time-series framing of qubit readout is promising\n- The proposed approach is novel\n- Quality of the presentation is high"}, "weaknesses": {"value": "- The reported improvement is small, even if significant\n- Only GMM is used for comparison\n- The topic is not closely aligned with ICLR’s core areas of interest"}, "questions": {"value": "Why do you compare only against GMMs? Are there other time-series ML models that could be used for this purpose?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "2y2WPAFybG", "forum": "ZLjnmBgoBo", "replyto": "ZLjnmBgoBo", "signatures": ["ICLR.cc/2026/Conference/Submission21474/Reviewer_v6GT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21474/Reviewer_v6GT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912444652, "cdate": 1761912444652, "tmdate": 1762941795910, "mdate": 1762941795910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}