{"id": "5vdw8Qmrre", "number": 15195, "cdate": 1758248846981, "mdate": 1759897322217, "content": {"title": "DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification", "abstract": "Functional data, representing curves or trajectories, are ubiquitous in fields like biomedicine and motion analysis. A fundamental challenge is phase variability—temporal misalignments that obscure underlying patterns and degrade model performance. Current methods often address registration (alignment) and classification as separate, sequential tasks. This paper introduces DeepFRC, an end-to-end deep learning framework that jointly learns diffeomorphic warping functions and a classifier within a unified architecture. DeepFRC combines a neural deformation operator for elastic alignment, a spectral representation using Fourier basis for smooth functional embedding, and a class-aware contrastive loss that promotes both intra-class coherence and inter-class separation. We provide the first theoretical guarantees for such a joint model, proving its ability to approximate optimal warpings  and establishing a data-dependent generalization bound that formally links registration fidelity to classification performance. Extensive experiments on synthetic and real-world datasets demonstrate that DeepFRC consistently outperforms state-of-the-art methods in both alignment quality and classification accuracy, while ablation studies validate the synergy of its components. DeepFRC also shows notable robustness to noise, missing data, and varying dataset scales. Code is available at https://github.com/Drivergo-93589/DeepFRC.", "tldr": "This paper introduces DeepFRC, an end-to-end deep learning framework that jointly performs alignment and classification of functional data to improve model performance.", "keywords": ["Functional Data Analysis; Deep Learning; Registration; Classification"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/daee18eb6655ce0f1a5a02e947d1ee25705f605f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel end-to-end deep learning model DeepFRC that integrates deformable registration with classification, tasks that are so far adressed usually separately. This is achieved utilizing a diffeomorphic neural registration operation, Fourier spectal representation for smooth functional encoding and a class-aware contrastive objective. Experiments on both synthetic and real datasets demonstrate consistently improved alignment together with competitive or superior classification performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Offers and end-to-end method to jointly learn functional registration and classification in a unified architecture rather than sequentially.\n2. Theoretical guarantees are provided that limk registration fidelity to classification generalization.\n3. Improved performance across real world and synthetic dataset and comprehensive ablation for each architectural component.\n4. Robustness is shown against noise and missing data.\n5. The language of the paper is clear. \n6. Git link to code is available."}, "weaknesses": {"value": "**Weaknesses and Questions**\n\n1. Since TTN is also addressing jointly the registration and classification tasks, can the authors elaborate and highlight a bit more the architectural and conceptual differences between these methods?\n2. How sensitive is the model to mis-specified diffeomorphic constraints if real warpings violate the diffeomorphic guarantees?\n3. In line 082: the paper claims that the paper of Tang et al. is heavily reliant on assumptions,…\nCan the authors clarify which assumptions those are and whether they avoid making these assumptions in this work?\n4. In the experiments the paper claims that simulated data provide insights regarding registration, classification and reconstruction. I would like to understand why is it important to draw conclusions on the reconstruction along with the other 2 tasks discussed thoroughly in the paper.\n5. In table 1 we sometimes see that several methods demonstrate high acc and F1 score while their registration performance is not optimal. Is there any intuition behind this? Does it mean that the SrvfRegNet was not tuned properly? Does this not make those methods robust against misregistration which can be an interesting and useful property? What is the intuition behind SrvfRegNet always not being able to recover the registration as accurately as the proposed method?\n6. Another question regarding the results is whether there is any intuition why in the case of Symbol 3 the SrvfRegNet + TSLANet is delivering higher classification accuracy compared to Symbol2. Is there any correlation to the number of classes?\n7. I would like to request some addition of limitations of the current method and of why one should not consider to addressing classification and registration jointly."}, "questions": {"value": "Please see above.\n\nIf the authors address some of the discussion points above I am willing to increase my score in the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZSjXMYZe9V", "forum": "5vdw8Qmrre", "replyto": "5vdw8Qmrre", "signatures": ["ICLR.cc/2026/Conference/Submission15195/Reviewer_gJ51"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15195/Reviewer_gJ51"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761664187330, "cdate": 1761664187330, "tmdate": 1762925497591, "mdate": 1762925497591, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DeepFRC, an end-to-end deep learning framework that jointly addresses functional data registration (alignment) and classification. Its main contribution is a unified architecture that integrates a neural deformation operator for diffeomorphic warping, a spectral representation for smooth functional encoding, and a class-aware contrastive loss. This approach eliminates the need for separate preprocessing steps and allows the alignment and classification tasks to mutually enhance each other. The work is further supported by theoretical guarantees on its approximation capability and generalization error, and is empirically validated to outperform state-of-the-art methods on both synthetic and real-world datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper demonstrates good originality by proposing the first end-to-end unified framework for joint functional data learning. \nThe research quality is solid, well-supported by comprehensive theoretical analysis and systematic experimental validation."}, "weaknesses": {"value": "1. It is not clear about the network architecture choices.\n2. Current computational complexity analysis is not sufficient.\n3. Lack of a detailed description of the datasets, which helps to understand the possible applications of the proposed method."}, "questions": {"value": "1. The paper uses a 1D CNN to parameterize the neural deformation operator (the registration module) but does not explain why Transformer-based models were not chosen. Can you explain the core reasons for this selection?\n2. It is recommended to supplement the experimental results with statistical significance analysis to prove that the performance improvements are statistically significant.\n3. The current computational efficiency comparison in the paper only mentions runtime. Would supplementing it with the total training time, model parameter count, and FLOPs provide a more comprehensive demonstration of DeepFRC's efficiency advantages?\n4. Can you further clarify the sampling methods of the four real-world experimental datasets? Additionally, could you explain how the proposed method handles highly irregularly sampled functional data?\n5. I would suggest adding more application analysis to demonstrate the effects of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jqIpduq6qN", "forum": "5vdw8Qmrre", "replyto": "5vdw8Qmrre", "signatures": ["ICLR.cc/2026/Conference/Submission15195/Reviewer_UBjh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15195/Reviewer_UBjh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761797449307, "cdate": 1761797449307, "tmdate": 1762925497171, "mdate": 1762925497171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DeepFRC, an end-to-end framework for function/sequence alignment and representation-driven registration/classification. The method builds a deformation operator for time warping, a spectral/spectral-coefficient representation of aligned functions, and a classifier that uses contrastive geometric alignment objectives."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The authors provide theoretical guarantees, proving that the model can approximate optimal warping functions and establishing a data-dependent generalization bound that links registration fidelity to classification performance."}, "weaknesses": {"value": "1.\tThe authors claim “but rarely addressing both simultaneously”, however, there are several works addressing registration and classification simultaneously, for example,\n[1] Zhang, Y. and Telesca, D., 2014. Joint clustering and registration of functional data. arXiv preprint arXiv:1403.7134.\n2.\tWhy transform the latent features into a monotone cumulative sum can guarantee diffeomorphism?\n3.\tNovelty is limited, for registration, only introduce neural deformation operator for alignment\n4.\tThe claim that DeepFRC is \"efficient\" is poorly supported. The authors only report inference time, which is already longer than other learning-based methods. Crucially, they omit training time, computational complexity analysis, and a comparison of model parameters (number of weights). \n5.\tThe theoretical results rely on assumptions (e.g., Lipschitz continuity, compactness) that should be discussed more critically.\n6.\tThe comparison methods are from 2021, the authors should compare most recent methods, like the methods published in 2025 and 2024."}, "questions": {"value": "1. add more comparisons to current methods.\n2. explain why transform the latent features into a monotone cumulative sum can guarantee diffeomorphism?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YCjYnRlutP", "forum": "5vdw8Qmrre", "replyto": "5vdw8Qmrre", "signatures": ["ICLR.cc/2026/Conference/Submission15195/Reviewer_q1ar"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15195/Reviewer_q1ar"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842137456, "cdate": 1761842137456, "tmdate": 1762925496713, "mdate": 1762925496713, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents DeepFRC, a deep learning framework that jointly performs functional registration and classification for functional or trajectory data. It integrates a neural deformation operator with 1D CNN to learn diffeomorphic time-warping functions for temporal alignment, a spectral representation module based on Fourier bases for smooth function embedding, and a classifier trained with a contrastive–geometric loss to align within classes and separate between classes.\n\nTheoretical analysis shows that DeepFRC can approximate optimal warpings and achieves bounded generalization error. Experiments on both synthetic and real-world datasets (Wave, Yoga, Symbol, MotionSense) demonstrate improved alignment and classification accuracy over baselines such as TTN and SrvfRegNet."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presents a well-motivated problem by targeting the joint challenge of phase variability and classification in functional data analysis (FDA).\n2. Empirical results are consistent: DeepFRC outperforms alternatives across several datasets, enhancing both alignment and classification and confirming the effectiveness of joint optimization.\n3. Theoretical discussions and included proofs, effectively situate the model within the mathematical landscape of FDA."}, "weaknesses": {"value": "1. The neural components (1D CNN, MLP, Fourier basis) are standard. The main contribution is integrating known elements instead of developing a new architecture or loss function.\n2. The baseline models are too few and outdated; it would be better to include more recent baseline models for comparison."}, "questions": {"value": "1. Theorems 3.1 and 3.3 rely on many assumptions such as smoothness, bound and compactness. How realistic are these for real-world datasets with irregular sampling or noise?\n2. How would the baseline models perform when scaling to the large datasets (time complexity, ATV, ACC, etc.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "doxkYtirTr", "forum": "5vdw8Qmrre", "replyto": "5vdw8Qmrre", "signatures": ["ICLR.cc/2026/Conference/Submission15195/Reviewer_PLqL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15195/Reviewer_PLqL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936858801, "cdate": 1761936858801, "tmdate": 1762925496306, "mdate": 1762925496306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}