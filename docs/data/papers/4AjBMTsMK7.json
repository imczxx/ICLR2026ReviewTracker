{"id": "4AjBMTsMK7", "number": 346, "cdate": 1756736150395, "mdate": 1763642047662, "content": {"title": "Go with Your Gut: Scaling Confidence for Autoregressive Image Generation", "abstract": "Test-time scaling (TTS) has demonstrated remarkable success in enhancing large language models, yet its application to next-token prediction (NTP) autoregressive (AR) image generation remains largely uncharted. Existing TTS approaches for visual AR (VAR), which rely on frequent partial decoding and external reward models, are ill-suited for NTP-based image generation due to the inherent incompleteness of intermediate decoding results. To bridge this gap, we introduce **ScalingAR**, the first TTS framework specifically designed for NTP-based AR image generation that eliminates the need for early decoding or auxiliary rewards. ScalingAR leverages *token entropy* as a novel signal in visual token generation and operates at two complementary scaling levels: (***i***) ***Profile Level***, which streams a calibrated confidence state by fusing intrinsic and conditional signals; and (***ii***) ***Policy Level***, which utilizes this state to adaptively terminate low-confidence trajectories and dynamically schedule guidance for phase-appropriate conditioning strength. Experiments on both general and compositional benchmarks show that ScalingAR **(1)** improves base models by 12.5% on GenEval and 15.2% on TIIF-Bench, **(2)** efficiently reduces visual token consumption by 62.0% while outperforming baselines, and **(3)** successfully enhances robustness, mitigating performance drops by 26.0% in challenging scenarios.", "tldr": "", "keywords": ["Autoregressive Image Generation", "Test-time Scaling"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8b46faf0a4ccbcb0eb24341f9520acf19160ce2e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a test-time controller for autoregressive image models that reads the model’s logits, not partial renders, to decide how to spend compute. It builds a two-channel confidence: an intrinsic stability signal from token entropy and a worst-block grid score, and a conditional-utilization signal from KL between conditional and unconditional logits to catch semantic fade. A lightweight policy prunes low-promise runs with a recovery check, and schedules classifier-free guidance on the fly, raising guidance when utilization drops and relaxing it once predictions stabilize. On GenEval and TIIF, it lifts strong AR bases and beats IS or BoN with fewer tokens, so you get better quality per unit test compute."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Uses logit confidence instead of partial renders. That targets the real pain in AR images: intermediate images are costly and uninformative, logits are cheap and continuous.\n2. The story reads straight. One state, confidence from logits; one purpose, allocate compute; two actions, prune and schedule guidance. \n3. Well-scoped claim. Improves quality per unit test compute, not a new training objective, not a reward model; scope and evidence match."}, "weaknesses": {"value": "1. Too many hyperparameters: weights, windows, percentiles, rebound length, CFG rates, clamps. \n2. Many moving parts: worst-block, conditional channel, CFG, rebound, threshold.\n3. Hand-designed controller. Not learned, no optimality claim. \n4. Compute-normalized fairness. Account for double forward passes for conditional and unconditional, edit scheduling, and any candidate scoring overheads.\n5. Confidence, entropy-based pruning and CFG scheduling exist in nearby areas. The novelty is the logit-only, image-specific fusion."}, "questions": {"value": "1. sensitivity analysis of the hyper parameters\n2. ablations of the two components: which plays the role?\n3. report success under normalized compute: matched token, FLOP, and memory budgets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Elv6iynsk3", "forum": "4AjBMTsMK7", "replyto": "4AjBMTsMK7", "signatures": ["ICLR.cc/2026/Conference/Submission346/Reviewer_E86T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission346/Reviewer_E86T"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761604327552, "cdate": 1761604327552, "tmdate": 1762924889992, "mdate": 1762924889992, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ScalingAR, a novel framework that applies Test-Time Scaling (TTS) to autoregressive (AR) image generation models based on the Next-Token Prediction (NTP) paradigm. The proposed method uses the model's intrinsic 'token entropy' as a proxy for the quality of the final result, without relying on external reward models or partial decoding. This confidence score is then used to inform policies that adaptively prune low-quality generation trajectories and dynamically schedule Classifier-Free Guidance (CFG) strength, improving final image quality and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is commendable for being the first to explore Test-Time Scaling (TTS) specifically for the Next-Token Prediction (NTP) visual autoregressive paradigm, which is a novel and relevant research direction.\n* Some experimental aspects, such as the robustness test using \"impossible prompts\" are noteworthy."}, "weaknesses": {"value": "1. **Unjustified Rationale for Proposed Metrics**\n\t* The paper's core motivation could be strengthened. There is insufficient direct evidence for the central claim that \"high local token entropy necessarily leads to poor final results\". The related concept of \"Block Stability\" is similarly presented as an assumption; the paper does not currently provide a clear causal link for why a few high-entropy blocks would result in global semantic corruption. These foundational assumptions would be more convincing with direct experimental validation.\n\t\n2. **Excessive Complexity and Hyperparameter Obscurity**\n\t* The proposed methodology is quite complex. While the basic concept is understandable, it is questionable whether such intricate formulations and the vast number of associated hyperparameters are necessary.\n\t* This complexity is a concern because the paper provides limited discussion on the hyperparameter tuning process (e.g., the tuning grid, configurations tested, or associated costs). The sensitivity analysis in Figure 8 suggests performance is notably reliant on this tuning, raising a concern that the reported performance might be more attributable to extensive, model-specific tuning rather than the intrinsic robustness of the method itself.\n\t* Furthermore, this complexity directly impacts clarity. The paper relies solely on textual descriptions to explain the intricate inference-time process, particularly the interaction between the Profile and Policy levels. The omission of a flow diagram or, at a minimum, a pseudo-code algorithm block makes the method's practical operation difficult to grasp and verify.\n\t\n3. **Insufficient Experimental Validation and Lack of Transparency**\n\t* The experimental validation could be more thorough, as several key details are missing, making it difficult to assess the method's contributions fully.\n\t* **Generalizability**: The method's generalizability is not fully demonstrated. It is only tested on two models (AR-GRPO and LlamaGen). Given the method's apparent dependency on hyperparameters, it would be essential to show that it is portable to other SOTA models (e.g., Emu3, Janus), which were listed but not tested with this method.\n\t* **Baseline Opacity and Counter-intuitive Results**: The experimental comparison is weakened by a lack of transparency. The paper does not specify the details for the baselines (IS, BoN), such as the number of samples $N$ used, the CFG scales, or the \"Best\" selection metric. This opacity is concerning, especially given the counterintuitive results in Table 1 (ScalingAR > BoN). Theoretically, a well-implemented BoN (selecting from $N$ full images) should represent a performance upper bound for ScalingAR (pruning from $N$ incomplete images). This discrepancy warrants further explanation.\n\t* **Insufficient Ablation Study**: The provided ablation (Table 2) is helpful but incomplete, as it only validates the input metrics (Sec 4.1). It does not analyze the policy components (Sec 4.2). A crucial ablation comparing Baseline vs. + Adaptive Termination Gate Only vs. + Guidance Scheduler Only vs. Full ScalingAR is missing. Without this, it is difficult to disentangle the contributions of the two policies and justify the inclusion of the highly complex components."}, "questions": {"value": "1. A key question is whether this framework's philosophy is somewhat at odds with traditional TTS/BoN. Standard TTS/BoN uses computation to explore diversity and then select the best. This method, conversely, appears to prune trajectories that deviate and enforce model certainty. While this is more efficient, the paper should provide clearer intuition for why this pruning strategy should yield a higher-quality ceiling than a full (and costly) BoN exploration. \n\n2. Regarding Figure 8 (Left), the relationship between the pruning threshold $p$ and accuracy is unclear. The chart shows $p=0.15$ (less pruning) resulting in lower accuracy than $p=0.20$ (more pruning). It would be expected that accuracy would monotonically increase as pruning decreases (i.e., $p=0.15$ should be better than $p=0.20$), as the sample set gets closer to the full, unpruned BoN set. Clarification on this relationship is requested.\n\n3. $C_i$ is introduced in Sec.3 but appears unused in the methodology. Additionally, $\\hat{D}_t$ is never formally defined. Is this a typo for $D_t$(eq.11)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6Ja82JjElD", "forum": "4AjBMTsMK7", "replyto": "4AjBMTsMK7", "signatures": ["ICLR.cc/2026/Conference/Submission346/Reviewer_uqBd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission346/Reviewer_uqBd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967035450, "cdate": 1761967035450, "tmdate": 1762915498107, "mdate": 1762915498107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors demonstrate that test-time scaling (TTS) can be made effective for next-token-prediction (NTP) visual autoregressive (AR) models without partial decoding or external rewards. They introduce ScalingAR, which builds a dual-channel confidence profile: an intrinsic channel based on token entropy, margin, and spatial stability, and a conditional channel measuring the marginal impact of textual conditioning. This calibrated confidence guides two policies: (i) early termination of low-confidence trajectories and (ii) dynamic scheduling of classifier-free guidance (CFG). Figures 1 and 3 illustrate confidence trajectories and the quality–alignment trade-off motivating adaptive guidance."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* Clear motivation. Language‑model TTS doesn’t transfer to images due to holism, objective ambiguity, and early‑signal scarcity; their design addresses each explicitly.\n\n* Two‑level design (profile/policy) is principled and easy to plug in; the conditional channel provides a concrete handle on prompt adherence during generation.\n\n* Experimental results are quite comprehensive on standard AR image benchmarks, and the figures show consistent improvements over baselines."}, "weaknesses": {"value": "I'm not an expert of this area, but I have some concerns about the paper based on my understanding.\n\n* In terms of novelty, token-entropy/margin as a confidence proxy is known in language models. In this context, what is new beyond adapting them to image domains? Please clarify what is fundamentally novel in the intrinsic/conditional fusion and how it differs from earlier entropy-based routing in decoding.\n\n* Early termination and confidence-guided re-weighting can introduce extra computations. What is the wall-clock overhead vs. sampling, and how much of the reported improvement gains stem from increased width vs. better selection?\n\n* Regarding sensitivity and robustness, the profile mixes entropy, margin with weights (\\alpha_H, \\alpha_M), and thresholds for termination. How sensitive are results to these hyper‑parameters and to token‑vocabulary size? The ablation studies on these parameters should be included I think."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "2ySaCpHIAO", "forum": "4AjBMTsMK7", "replyto": "4AjBMTsMK7", "signatures": ["ICLR.cc/2026/Conference/Submission346/Reviewer_ysTJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission346/Reviewer_ysTJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991263919, "cdate": 1761991263919, "tmdate": 1762915497980, "mdate": 1762915497980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Summary of Manuscript Revision"}, "comment": {"value": "Dear Reviewers,\n\nWe sincerely thank all the reviewers for your thoughtful and constructive feedback! We are really encouraged to see that the reviewers appreciate several positive aspects of our work, including **clear motivation & practical design** (Reviewer `ysTJ`), **novel framework** (Reviewer `uqBd`), **well-scoped claim** (Reviewer `E86T`), **comprehensive & noteworthy experiments** (Reviewer `ysTJ`, `uqBd`), as well as **effective & efficient method addressing key challenges** in AR image generation (Reviewer `uqBd`, `E86T`).\n\nYour expertise has been invaluable in helping us strengthen our manuscript! In addition to addressing your comments point-by-point on the OpenReview forum, we have made the following key revisions to the manuscript (all updated text is highlighted in blue): \n\n- **Expanded Hyperparameter Analysis:** We have included a more comprehensive analysis of ScalingAR's hyperparameters in `Appendix A.2`.\n- **Efficiency Evaluation:** Detailed computational cost metrics for ScalingAR have been added in `Table 4`.\n- **Transferability Demonstration:** To validate the generalizability of ScalingAR, we have incorporated results on two additional models (*i.e.*, SimpleAR and Janus-Pro) in `Appendix B`.\n- **Motivation and Entropy Mechanism:** We have further elaborated on the role of the entropy mechanism in AR image generation, providing additional insights in `Appendix C`.\n- **Algorithm Workflow:** We have summarized the workflow of ScalingAR in the form of pseudocode in `Appendix D`.\n\nWe have made earnest efforts to address the primary concerns raised and believe these revisions significantly enhance the clarity and comprehensiveness of our manuscript. We respectfully look forward to further feedback to continue improving the quality of our work.\n\nSincerely,\n\nAuthors"}}, "id": "HWWMg7ichj", "forum": "4AjBMTsMK7", "replyto": "4AjBMTsMK7", "signatures": ["ICLR.cc/2026/Conference/Submission346/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission346/Authors"], "number": 10, "invitations": ["ICLR.cc/2026/Conference/Submission346/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763642866531, "cdate": 1763642866531, "tmdate": 1763642971526, "mdate": 1763642971526, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}