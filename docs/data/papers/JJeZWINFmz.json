{"id": "JJeZWINFmz", "number": 25385, "cdate": 1758367415858, "mdate": 1759896722717, "content": {"title": "SAGE Can Quantify Why Two Models Behave Differently", "abstract": "Vision-based activity recognition tasks are sensitive to environmental context and lighting, making generalization across domains difficult. Models trained in controlled settings can report high accuracy, but often fail under domain shift, where it remains unclear whether predictions depend on causal foreground cues, spurious background signals, or shortcut learning tied to context rather than behavior. Saliency methods offer a view of model focus, but have largely been confined to qualitative visualization. We hypothesize that behavioral divergence between models is proportional to divergence in their saliency embeddings. To examine this, we introduce Saliency Attribution for Goal-grounded Evaluation (SAGE), a modular framework that unifies heterogeneous datasets through category mapping and balancing, generates controlled foreground and background variants, computes saliency maps, and encodes them into tokenized representations suitable for embedding and comparison. By disentangling foreground and background saliency, the framework provides a diagnostic signal of how models attend to causal versus spurious regions, complementing accuracy as a measure of generalization. We demonstrate feasibility on vision-based driver distraction detection, an activity recognition task where distraction is inferred from driver activities rather than objects, by creating a unified 10-class variant of the StateFarm and 100-Driver datasets that highlights the challenges of category mapping and background control. While full embedding-based evaluations are ongoing, the framework separates foreground and background saliency, discretizes them into tokens, and encodes them in a manner aligned with tokenized vision architectures such as ViTs and VLMs. This design makes the framework scalable across vision-based classification tasks where foreground-background disentanglement is critical, and presents it as a diagnostic tool for analyzing behavioral divergence and robustness under domain shift.", "tldr": "", "keywords": ["Explainable AI", "Vision-based Driver Distraction Detection (vDDD)", "SAGE", "Saliency Embeddings", "Behavioral Divergence", "Domain Shift", "Generalization", "Shortcut Learning", "Vision--Language Models (VLMs)"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ead736e219b2243d5f786eca923eafa27860fd53.pdf", "supplementary_material": "/attachment/039311be5f790d4e79b9c2d476321292ba1bf422.zip"}, "replies": [{"content": {"summary": {"value": "Generalization in activity recognition is difficult due to domain shift between controlled training data and in-the-wild data. It's not clear whether in-the-wild predictions depend on foreground cues which are \"causal\" in nature or on spurious background signals. The proposed works generalize the \"Class Activation Mapping\" frameworks which provided saliency wrt input (i.e. attribution maps) into a diagnostic framework."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Paper tackles an important problem, namely, assigning attribution for a black box prediction to the image regions, i.e. are the predictions being made causally tied to the image regions that are necessary to make such a prediction. As the authors point, class activation maps are attractive however can be misleading in nature. The authors propose to standardize the use of these activation maps to capture patch level statistics that can be correlated with downstream metrics like accuracy, which might be a plausible way of establishing some notion of causality and checking if spurious correlations exist."}, "weaknesses": {"value": "The paper reads like a technical report and does not clearly outline their algorithm or method -- or the specific strengths of why we need their framework to diagnose mis-classifications in activity recognition. I advise the authors the following concrete suggestions, however, there are likely many more such changes that are needed before acceptance at ICLR --\n\n(a) Demarcate and show why foreground object saliency is \"causal\" in nature and why is their tokenization framework necessary for \"diagnostics\". In general, the inputs, outputs and the end goal of their problem is not clearly defined in the paper and is hard to grasp even as a reader who is already well verse with the driver activity recognition task. For e.g. a person sitting behind the driver can trigger \"talk_to_passenger\" activity, thus if the saliency is not focussed on the driver (foreground in this case), that would make sense even if the saliency is focussed on the background.\n\n(b) The figures are very difficult to read and are dumped on the reader to interpret in context of the work, they need to be made more accessible and tied to the proposed method. Some of the figures are also incomplete (some confusion matrices show the class name, versus others show the index). For e.g., in fig 5, while I would like to believe there is significance in understanding their confidence-stratified clusters, however, the paper doesn't motivate what the reader should be looking at and why they should be looking at these clusters in these three different forms (scatter, band and histogram plots) in the context of their method. \n\n(c) I'm not sure what the specific claims made by the work are that was missing from prior work, and thus it is impossible to argue for or against the work. No comparisons are made to existing work or to any existing benchmark that would help situate their analysis. While I'm not against analysis papers, it is important for papers to describe the method succinctly and explain the kind of analysis that can be conducted given their new method."}, "questions": {"value": "Please provide a concrete response to the weaknesses and also provide a concrete list of contributions that the reviewers should employ to evaluate this work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Jqzg4JFUk8", "forum": "JJeZWINFmz", "replyto": "JJeZWINFmz", "signatures": ["ICLR.cc/2026/Conference/Submission25385/Reviewer_LnNh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25385/Reviewer_LnNh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25385/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878401708, "cdate": 1761878401708, "tmdate": 1762943419515, "mdate": 1762943419515, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors address the important problem of generalization for Vision-based activity recognition and propose a framework for it. The framework unifies heterogeneous datasets via category alignment and sample balancing. It then produces controlled foreground and background variants, computes saliency maps, and tokenizes them for comparison using embedding-based methods. Thus, the framework provides a diagnostic means to identify how models utilize causal versus spurious regions by disentangling foreground and background saliency. The authors provide empirical evidence to support their claims."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1) The authors address the important problem of cross domain generalization in Vision-based activity recognition.\n\n2) The design of experiment is well-structured to isloate background influenceby using four variants (FULL, BBOX, SEG, and BBOXSEG).\n\n3) Additionally the authors evaluates multiple CNN architectures, domains and integrates quantitative diagnostics in a unified pipeline."}, "weaknesses": {"value": "1) Although the framework is well-engineered and focuses on reproducibility yet the core operations (like spatial normalization, foreground/background separation, etc) are well-established in prior works. Hence, the conceptual novelty appears limited, as the primary contribution seems to be building the system and conducting large-scale analysis, rather than proposing a new methodological or theoretical advancement.\n\n2) The reported accuracies in the Results section are low. A within-domain baseline would help readers to better contextualize the reported numbers.\n\n3) The numbers in the confusion matrix of Figure 3 are barely visible.\n\n4) The paper is hard to follow, especially the Results section. While the authors have presented a large amount of experimental evidence but the results section is somewhat difficult to follow, as key findings and their implications become clear only in the Discussion section."}, "questions": {"value": "I request the authors to address the identified weaknesses above. I would be open to revising my evaluation if these issues are effectively resolved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Rej6t85XiT", "forum": "JJeZWINFmz", "replyto": "JJeZWINFmz", "signatures": ["ICLR.cc/2026/Conference/Submission25385/Reviewer_LQEA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25385/Reviewer_LQEA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25385/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909033003, "cdate": 1761909033003, "tmdate": 1762943419220, "mdate": 1762943419220, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SAGE, a framework designed to move beyond qualitative saliency visualizations by converting them into tokenized representations. The core idea is that behavioral divergence between models under domain shift can be diagnosed by comparing their saliency embeddings. The authors demonstrate the framework on a driver distraction detection task, unifying two datasets (StateFarm and 100-Driver) into a 10-class schema and generating various foreground/background variants (FULL, BBOX, SEG, BBOXSEG). They benchmark several CNN models, analyze cross-domain generalization, and show that saliency tokenization can reveal whether a model relies on causal foreground cues or spurious background signals. The primary contribution is a modular pipeline for standardized saliency diagnostics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a well-structured and reproducible pipeline for saliency analysis, which is a valuable contribution to the explainability toolbox. The idea of tokenizing saliency maps into structured, patch-level descriptors is novel and aligns well with modern patch-based architectures like Vision Transformers, providing a clear path for future integration. The experimental design is rigorous, featuring a systematic cross-dataset and cross-variant evaluation that cleanly isolates the effect of background context on model generalization. The comprehensive analysis—spanning performance metrics, confidence-stratified clustering, and qualitative saliency mosaics—provides compelling evidence that foreground-background saliency disentanglement offers a diagnostic signal complementary to accuracy. The framework is modular and generalizable, promising applicability beyond the specific task studied here."}, "weaknesses": {"value": "The most significant weakness is the disconnect between the paper's stated motivation and its actual execution. Despite prominently featuring \"Vision-Language Models (VLMs)\" in the abstract and keywords, and framing tokenization as being \"aligned with tokenized vision architectures such as ViTs and VLMs,\" the work contains zero experiments or analysis involving a Vision-Language Model. The entire study is conducted using standard CNNs (e.g., EfficientNet-B0). This renders the core motivational premise unfulfilled and undermines the paper's relevance to the VLM community.\n\nIn addition, the methodological contribution is incremental. The process of generating saliency maps (using established tools like Grad-CAM), segmenting foreground/background, and computing patch statistics is a straightforward engineering integration of existing techniques rather than a novel algorithmic advancement. The resulting \"token\" is simply a vector of hand-crafted statistical features (mass, mean, max, centroid), lacking the semantic richness one would expect from a representation designed for VLMs.\n\nThe paper reads more like a well-documented technical report or a system description. It extensively details the data preparation and experimental pipeline but offers limited new theoretical insight. The central hypothesis—that model behavioral divergence is proportional to saliency embedding divergence—is only partially supported by the presented analysis of CNNs. The failure to demonstrate this with the very architectures (VLMs) that would make the tokenization most powerful is a critical omission."}, "questions": {"value": "Please refer to my weaknesses, especially the first concern regarding vlm validation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zp15V5nCeN", "forum": "JJeZWINFmz", "replyto": "JJeZWINFmz", "signatures": ["ICLR.cc/2026/Conference/Submission25385/Reviewer_NX3V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25385/Reviewer_NX3V"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25385/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762229052375, "cdate": 1762229052375, "tmdate": 1762943418946, "mdate": 1762943418946, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a framework for saliency-based driver distraction recognition. The key idea is to distinguish between foreground and background in order to establish how a saliency model determines signals to attend to over spurious regions. The paper further proposes creating a 10-class variant of the Statefarm and 100-Driver datasets to highlight the challenges of identifying salient action over background control. Some early experiments show cross-domain generation between models trained on classes from one data and evaluated on another."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Overall, the paper discusses the important problem of driver distraction recognition, which can be considered as an activity recognition task across multiple classes of distraction. Furthermore, the experimental setup is quite rigorous, evaluating a large variety of model backbones. Lastly, the cross-domain evaluation is quite interesting, showing the ability of a model to generalize across multiple datasets for detecting driver attention/distraction."}, "weaknesses": {"value": "There are several issues with the paper in its current state:\n- It is unclear how saliency is a strong reflection of driver's activity. Specially when distinguishing between background and foreground, it seems like the driver will always occupy the foreground, regardless of what the type of distraction is (or is not). Explanation regarding this choice over others (say driver pose recognition) is missing in the paper.\n- In addition to above, the paper lacks several details and feels incomplete. While the motivation of the approach is sound, there are not enough diverse experiments to understand whether the proposed multi-background saliency variants (FULL vs BBOX vs SEG vs BBOXSEG) are sufficient.\n- The paper mentions using ViT and other VLM models being used, but there is no evaluation conducted to support this claim in either the table or the figures.\n- The writing of the paper could improve significantly. Details regarding CNN backbones can go to the appendix, allowing for more space to discuss detailed experiments and evaluations. Additionally, the framework section does not need to introduce so many variables, making it hard to follow. \n- Minor: There are several typos in the paper like in L139 and L184."}, "questions": {"value": "The reviewer requests the authors to read the things mentioned in the Weaknesses section, and possibly address them in a later version of the paper with more thorough analysis and experimental results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hX1jzi6IpP", "forum": "JJeZWINFmz", "replyto": "JJeZWINFmz", "signatures": ["ICLR.cc/2026/Conference/Submission25385/Reviewer_3aJK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25385/Reviewer_3aJK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25385/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763330013126, "cdate": 1763330013126, "tmdate": 1763330013126, "mdate": 1763330013126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}