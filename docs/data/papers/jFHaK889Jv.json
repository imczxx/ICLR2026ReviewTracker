{"id": "jFHaK889Jv", "number": 16116, "cdate": 1758260208195, "mdate": 1759897260841, "content": {"title": "SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation", "abstract": "Generating physically plausible human motion is crucial for applications such as character animation and virtual reality. Existing approaches often incorporate a simulator-based motion projection layer to the diffusion process to enforce physical plausibility. However, such a method is computationally expensive due to the sequential nature of the simulator, which prevents parallelization. We show that simulator-based motion projection can be interpreted as a form of guidance—either classifier-based or classifier-free—within the diffusion process. Building on this insight, we propose SimDiff, a Simulator-constrained Diffusion Model that integrates environment parameters (e.g., gravity, wind) directly into the denoising process. By conditioning on these parameters, SimDiff generates physically plausible motions efficiently, without repeated simulator calls at inference, and also provides fine-grained control over different physical coefficients. Moreover, SimDiff successfully generalises to unseen combinations of environmental parameters, demonstrating compositional generalisation.", "tldr": "", "keywords": ["diffusion model", "motion generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/032914644ec4c173de54cb0827fb700a8657106e.pdf", "supplementary_material": "/attachment/56a46ee6689f4a4282bedf86af4fea39e905aef9.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a method for motion generation that is more physically accurate than traditional diffusion-based generation. The main idea is using guidance to push the generation towards more plausible generations. While this idea is sound, efficient, and easy to implement. It is not very surprising, and its application is rather niche. For example, the paper states that as opposed to other approaches, the guidance-based approach is more computationally efficient, however motion generation models are rather slim, and a use-case where this add cost is crucial for is not presented. \nPerhaps most importantly, the presented results and evaluation are accordingly underwhelming. Against a rather dated method, some improvement in quality can be observed in the handful of demonstrated qualitative results. However even these selected motions are still not physically plausible, with minimal improvement in quality, and seem to be less prompt adherent. The quantitative evaluation supports this overall impression as well."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is concise and to the point, with decent theoretical analysis, and a simple to follow. The method is simple to implement and understand. Some quality improvements can be observed."}, "weaknesses": {"value": "- The paper presents an unclear usecase - of computationally efficient MDM-based generation with more physical plausibility: Why is the computational efficiency important? Why use a dated version of MDM when newer autoregressive versions of MDM (e.g., CAMDM, CLosD) have shown to have better performance?\n- The paper compares to Physdiff, which is a rather dated method. There have been many attempts to incorporate physics into human motion generation, including UniHSI, CHOIS, CLoSD (which is mentioned by the authors), and more. All these papers also show more applications to physical simulation, like object interaction. Does this method apply to such cases as well?\n- The qualitative evaluation is slim and unpersuasive\n- The quantitative evaluation is also slim and unpersuasive: comparing only to one previous and dated method is not enough, and the numbers show worse penetration (which is one of the only aspects presented as a usecase), floating that is similar to the GT (which is not great actually, it should have been improved), and FID which is comparable to the original MDM (which is good, meaning minimal harm) but not as good as state-of-the-art motion generation."}, "questions": {"value": "See questions in weaknesses. \nOverall the idea is sound, but does not pass the bar for a prestigious venue such as ICLR in this reviewer's opinion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qOP1jCkPgg", "forum": "jFHaK889Jv", "replyto": "jFHaK889Jv", "signatures": ["ICLR.cc/2026/Conference/Submission16116/Reviewer_vsFh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16116/Reviewer_vsFh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761657530449, "cdate": 1761657530449, "tmdate": 1762926290711, "mdate": 1762926290711, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper rethinks simulator-based motion projection (as used in previous papers such as PhysDiff) as guided diffusion. The authors propose SimDiff, which conditions a text-to-motion diffusion model on environment parameters (specifically gravity and wind). Instead of invoking a simulator at every step to generate physically plausible motion, SimDiff trains on simulator-augmented guidance. SimDiff uses classifier-free guidance with the parameters to steer the samples towards physically plausible motions. Experiments report better physics metrics than MDM and faster sampling than a modified PhysDiff baseline, along with qualitative compositional generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Amortizing physics using guided diffusion replaces the need to call a simulator at each reverse step, leading to big computational gains.\n- Conceptual bridge between projection and guidance.\n- Experiments show faster sampling than sim-in-the-loop PhysDiff at similar step counts, and demonstrate initial environmental control.\n- Conversion of HumanML3D to SMPL using SMPLify. Overall solid data pipeline.\n- Clear architectural choice of training motion adapters"}, "weaknesses": {"value": "- **Weak related work**: Section 2.1, the related work on human motion generation using diffusion, is not nearly expansive enough. It only cites 3 previous works on human motion generation with diffusion despite the literature that has come out in this area. As a result, the positioning of this paper contextually is not strong. Here are some more papers which can be cited.\n  - Goal-Driven Human Motion Synthesis in Diverse Tasks, CVPR 2025 HuMoGen.\n  - HOI-Diff: Text-Driven Synthesis of 3D Human-Object Interactions using Diffusion Models, CVPR 2025 HuMoGen.\n  - Fitness-Aware Human Motion Generation with Fine-Tuning, NeurIPS FITML 2024\n  - Constrained Synthesis with Projected Diffusion Models, Christopher et al, NeurIPS 2024\n  - Aligning Human Motion Generation with Human Perceptions, Wang et al, ICLR 2025\n- **Narrow conditioning scope in experiments**: Section 4.2 motivates conditioning on gravity and friction as environmental parameters, but only gravity and planar wind are varied in the experiments. Conditioning is a small set of global scalars $[g_z, w_x, w_y]$.\n- **Claim on generalization to unseen parameter combinations**: The abstract claims SimDiff \"successfully generalizes to unseen combinations of environmental parameters, demonstrating compositional generalization.\" However, the evidence is qualitative only with no quantitative compositional metric, and the conditioning space is only limited to global scalars in gravity and planar wind. This makes the claim **narrowly validated** - it shows qualitative composition of two global coefficients, not transfer to spatially varying or contact-rich regions. Without quantitative metrics or broader parameter types, this claim should be read as modest in scope.\n- **Selection bias in $\\mathcal{D}_\\text{sim}$**: In sections 5.3/5.4 and Appendix D, the authors state that **failed** controller rollouts are discarded when constructing the training set. This biases the learned conditional towards what *this particular* controller and contact model can track, rather than the full set of physically plausible motions. This risks degradation under parameter mismatch or different controllers. The controller's stabilization choices define what counts as success. PhysDiff adds a Residual Force term to compensate dynamics mismatch, which SimDiff's reproduction disables.\n- **Comparison to PhysDiff**: Appendix C states that the Residual Force term in PhysDiff is disabled, which is used to stabilize hard behaviors. This can understate PhysDiff's stability.\n- **Limited physics evaluation**: metrics are joint-based (not mesh-based), with no contact-force/torque statistics and no closed-loop tracking success under a different controller."}, "questions": {"value": "- How do text fidelity and physics metrics degrade when gravity/wind are misspecified at sampling time? It would be good to include curves vs $| \\Delta g|$ and wind-angle error.\n- Why did you remove the residual force term in PhysDiff? Can you report PhysDiff **with** RF in the MuJoCo port?\n- Do you have concrete projection schedules + wall-clock time?\n- Have you tested a subset of the experiments in section 5.3 using a different controller to see how the method reacts to an alternative controller?\n- Figure 5 shows qualitative composition; can compositional generalization be quantified?\n- Is classifier-free guidance essential, or could similar effects be obtained with learned conditioning through adapters alone?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iSmGILkhcR", "forum": "jFHaK889Jv", "replyto": "jFHaK889Jv", "signatures": ["ICLR.cc/2026/Conference/Submission16116/Reviewer_ZHbu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16116/Reviewer_ZHbu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761783534646, "cdate": 1761783534646, "tmdate": 1762926290272, "mdate": 1762926290272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SimDiff, a simulator-constrained diffusion model that integrates physical constraints directly into the diffusion process using classifier-free guidance. It is able to generalize to unseen combinations of environmental parameters."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of using physics guidance in the diffusion step is interesting. \n\n2. Ability to generalize to unseen explicit physical parameters is a plus."}, "weaknesses": {"value": "1. The statement “approaches have not yet provided (i) a principled way to modify the diffusion steps so that environment-specific physics constraints are taken into account” is too absolute and not fully accurate. Several lines of work already modify the denoising trajectory in a principled, per-step manner [1,2,3]. While many of these methods may not explicitly condition on environment parameters (gravity, wind, friction) or provide a calibrated physics likelihood, they do constitute principled step-level mechanisms beyond heuristic scaling.\n\n2. The method uses a physical simulator as the guidance in the diffusion step, but lacks the explicit control or modelling of the physical motions. \n\n3. Why is “modify the diffusion steps so that environment-specific physics constraints are taken into account” important? What benefit does it bring compared with other physics-guided methods, theoretically and empirically? Regarding the compositional generalization, the comparison with baselines is not presented. \n\n\n4. My major concerns are with the experiments conducted. (1). Only one dataset is evaluated; more commonly used benchmarks, like KIT-ML, HumanAct12, and UESTC, are needed. Otherwise, it is hard to justify the capability of the method on various datasets. (2). The reported scores for PhysDiff are pretty low compared to the results in their paper. For instance, the reported FID of PhysDiff is 0.433, while in your Table 1, it is 3.411. The difference is huge. Please explain, and justify if it is a fair comparison. (3). As the paper aims for a better way of incorporating the physical guidance, it should compare with more baselines in this direction. Current comparison is not enough. (4). Section 5.4, “Generalisation to diverse environments”. Only qualitative results are provided. More comprehensive comparisons, both qualitative and quantitative, are needed. \n\n\n5. Ablation studies are not sufficient, e.g., the guidance scale, the key components. \n\n\n[1]. Christopher J K, Baek S, Fioretto N. Constrained synthesis with projected diffusion models[J]. Advances in Neural Information Processing Systems, 2024, 37: 89307-89333.\n\n[2]. Li Z, Luo M, Hou R, et al. Morph: A Motion-free Physics Optimization Framework for Human Motion Generation[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2025: 14580-14589.\n\n[3]. Han G, Liang M, Tang J, et al. Reindiffuse: Crafting physically plausible motions with reinforced diffusion model[C]//2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). IEEE, 2025: 2218-2227."}, "questions": {"value": "See my weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xaPPse2s2z", "forum": "jFHaK889Jv", "replyto": "jFHaK889Jv", "signatures": ["ICLR.cc/2026/Conference/Submission16116/Reviewer_gF3b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16116/Reviewer_gF3b"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910303071, "cdate": 1761910303071, "tmdate": 1762926289838, "mdate": 1762926289838, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}