{"id": "ryc6WtvwDQ", "number": 3039, "cdate": 1757319675165, "mdate": 1763045540037, "content": {"title": "Does the Manipulation Process Matter? RITA: Reasoning Composite Image Manipulations via Reversely-Ordered Incremental-Transition Autoregression", "abstract": "Image manipulations often entail a complex manipulation process, comprising a series of editing operations to create a deceptive image, exhibiting **sequentiality** and **hierarchical** characteristics. However, existing IML methods remain manipulation-process-agnostic, directly producing localization masks in a one-shot prediction paradigm without modeling the underlying editing steps. This one-shot paradigm compresses the high-dimensional compositional space into a single binary mask, inducing severe **dimensional collapse**, thereby creating a fundamental mismatch with the intrinsic nature of the IML task.\n\nTo address this, we are the first to reformulate image manipulation localization as a conditional sequence prediction task, proposing the **RITA** framework. RITA predicts manipulated regions layer-by-layer in an ordered manner, using each step's prediction as the condition for the next, thereby explicitly modeling temporal dependencies and hierarchical structures among editing operations.\n\nTo enable training and evaluation, we synthesize multi-step manipulation data and construct a new benchmark **HSIM**. We further propose the **HSS** metric to assess sequential order and hierarchical alignment. Extensive experiments show RITA achieves SOTA on traditional benchmarks and provides a solid foundation for the novel hierarchical localization task, validating its potential as a general and effective paradigm. The code and dataset will be publicly available.", "tldr": "", "keywords": ["image manipulation localization", "IML"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/3380d9b99e7136f0d4341b7ede4cb63feb7518ca.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies image manipulation localization. Rather than predicting all manipulation masks in a single-shot fashion, which suffers from the issue of dimensional collapse, the authors propose to model step-by-step manipulation processes in mask prediction. To do so, they reformulate image manipulation localization, construct a training set that demonstrates sequential and hierarchical manipulation of image contents, and design a neural model for the proposed task. The empirical results show that their model performs best under most setups."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- the paper reformulates image manipulation localization to emphasize sequentiality and hierarchy among manipulation steps\n- a new model, training data, and evaluation metrics are introduced\n- analysis and ablation studies are performed"}, "weaknesses": {"value": "- unclear motivation for localizing image manipulation; i expect to see it at the very beginning of the introduction.\n- the related work section should comprehensively review existing works relevant to the task, model, data, and metrics, but currently, it simply repeats what has been said in the introduction section.\n- the experimental results are mixed; the proposed model underperforms baselines under some evaluation setups, so it is unclear how effective it is.\n- data curation relies on GPT-4o, but the potentially introduced biases are not discussed.\n- most of the baselines are quite outdated, i.e., before 2023; thus, unclear how they would perform when equipped with the latest neural architectures and learning paradigms.\n- claims are made without any references; for example, missing references to the claim in lines 45-46.\n- lacking experiments on scaling up the size of training data; will the proposed paradigm remain better than baselines when both are trained on a large dataset, e.g., a dataset consisting of millions of examples?"}, "questions": {"value": "see above *Weaknesses*\n\n- what are \"undo\" trajectories in line 195?\n- can you please fix the incorrect citation styles, for example, in line 037?\n- can you cite related work when using/mentioning existing resources, like CASIAv2 in line 170?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dESZEssi9m", "forum": "ryc6WtvwDQ", "replyto": "ryc6WtvwDQ", "signatures": ["ICLR.cc/2026/Conference/Submission3039/Reviewer_QeLE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3039/Reviewer_QeLE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761479980062, "cdate": 1761479980062, "tmdate": 1762916518977, "mdate": 1762916518977, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "LCpaTxKwhg", "forum": "ryc6WtvwDQ", "replyto": "ryc6WtvwDQ", "signatures": ["ICLR.cc/2026/Conference/Submission3039/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3039/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763045539128, "cdate": 1763045539128, "tmdate": 1763045539128, "mdate": 1763045539128, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel paradigm for Image Manipulation Localization (IML), reformulating it from a conventional one-shot prediction task to a conditional sequence prediction task. The authors propose RITA, an autoregressive framework that predicts manipulation masks layer-by-layer, where each step is conditioned on the previous one. To support this new paradigm, the paper makes three core contributions: 1) the RITA framework itself, 2) a new real-world dataset, HSIM, with multi-step manipulation annotations, along with a method for synthesizing hierarchical data, and 3) a new evaluation metric, the HSS, designed to assess the accuracy of sequential and hierarchical predictions. Experiments demonstrate that RITA not only establishes a strong baseline on the new sequential task but also outperforms baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-  RITA demonstrates state-of-the-art performance not only on its native sequential task but also on traditional one-shot benchmarks, where it outperforms existing methods in terms of both accuracy and efficiency\n\n- The paper is written with great clarity."}, "weaknesses": {"value": "- The paper's core evaluation relies on the HSIM dataset, which is generated exclusively by a single AI pipeline (GPT-Image-1). This raises significant concerns about source bias and generalizability. It is unclear if the model learns to detect fundamental manipulation traces or simply overfits to the specific artifacts of one generator. The evaluation should be more robust, testing the model against a diverse array of manipulation tools, including other state-of-the-art generative models (e.g., Qwen-Image, Nano Banana) that produce forgeries with far fewer artifacts.\n\n- The definition of hierarchy is strictly limited to spatial containment. This overlooks more complex semantic hierarchies. Furthermore, both the synthetic and real-world HSIM datasets are generated using automated or AI-assisted processes, which may not capture the nuances, imperfections, and diverse techniques of manual, human-driven forgeries.\n\n- It is difficult to determine whether the model's superior performance on traditional one-shot benchmarks stems from the novel sequential paradigm or simply from a more effective underlying architecture . This ambiguity makes it challenging to isolate and validate the paper's central claim that the sequential approach is inherently better for localization.\n\n- Autoregressive models are inherently sequential and thus slower at inference time than parallel, one-shot models. The paper reports FLOPs for a single forward pass but does not discuss the total inference time, which would scale linearly with the number of manipulation steps. This could be a significant drawback in applications requiring rapid analysis."}, "questions": {"value": "- Could you comment on the potential for source bias, as the HSIM dataset is created using only GPT-Image-1? How does RITA's performance generalize to forgeries from other modern generative models that may produce fewer artifacts?\n\n- The paper defines hierarchy based on spatial containment. How would the framework handle more complex, non-nested manipulations that are semantically hierarchical?\n\n- What is the total inference time compared to one-shot models, and what specific forensic scenarios justify this latency trade-off for knowing the edit sequence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9hONzZjBkL", "forum": "ryc6WtvwDQ", "replyto": "ryc6WtvwDQ", "signatures": ["ICLR.cc/2026/Conference/Submission3039/Reviewer_GCts"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3039/Reviewer_GCts"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911397147, "cdate": 1761911397147, "tmdate": 1762916518734, "mdate": 1762916518734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper revisits image manipulation localization by framing it as a conditional sequence prediction problem, capturing how edits unfold step by step. The authors present RITA, an innovative model that explicitly captures the temporal and hierarchical nature of manipulation processes. The authors introduce HSIM, a real-world dataset simulating multi-step manipulations, and propose HSS, a tailored metric for evaluating hierarchical localization quality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ The paper introduces a new problem by reformulating manipulation localization as a conditional sequence prediction task, which allows the model to capture temporal and hierarchical relationships between editing steps. \n+ Besides, the authors contribute a new dataset and evaluation metric tailored to this formulation. \n+ The proposed RITA model shows good performance in experiments and ablations."}, "weaknesses": {"value": "- When evaluating traditional one-shot benchmarks, the authors reformulate them as two-step tasks for RITA, while baselines operate in their native one-step mode. This raises fairness concerns and leaves it unclear whether the reported gains stem from the autoregressive design or from the task reformulation itself. \n- Since RITA can theoretically run in a single step, adding a one-step version trained and tested under the original benchmark setup would clarify whether the improvements come from the model architecture itself. \n- Moreover, the paper reports FLOPs and parameter counts for RITA but does not clarify whether efficiency is measured per prediction step or for full multi-step inference. This omission makes it difficult to fairly compare runtime with one-shot baselines, which perform only a single forward pass. \n- In addition, although the paper provides one illustrative example of the manipulation process, the overall description of the HSIM dataset remains limited. Key details, such as data sources, operational distributions, and the proportion of manually refined samples, are missing, making it difficult to assess the dataset’s realism and reproducibility."}, "questions": {"value": "1) In Figure 3, the “CGF Module” is shown in the model diagram, but its meaning is never explained in the text. Could you clarify whether CGF refers to the Transition Gated Fusion module? If so, please use a consistent name (either CGF or TGF) throughout the paper to avoid confusion.\n\n2) In Figure 3.C, the Transition Gated Fusion module illustrates a cross-gating mechanism where the image feature is modulated by the mask feature and vice versa. However, Eq. (14) defines G_M = σ(W_I F_I), which seems inconsistent with the figure. Should this instead be G_M = σ(W_M F_M)? Please double-check the equations (also Eq. (13)) for consistency with the diagram and the intended cross-gating design.\n\n3) Please clarify whether the reported FLOPs and efficiency metrics are measured per prediction step or across the full multi-step inference, and consider including total runtime and latency per image for a fair comparison with one-shot baselines.\n\n4) The decoder fuses CGF outputs with mask features, but it is unclear how much each contributes to performance. An ablation comparing (1) CGF-only features and (2) CGF combined with mask or image features would clarify whether the gain stems from the fusion design or the additional feature inputs.\n\n5) Since RITA can theoretically run with a single step, it would be helpful to include an experiment where a one-step version is trained and evaluated under the standard one-shot setting to clarify whether the performance gains arise from the autoregressive design or the model’s intrinsic architecture."}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "The HSIM dataset is described as being built upon CASIAv2 with additional manipulations generated using GPT-4o and GPT-Image-1, followed by manual refinements. Details about human involvement, compensation, and data release policies are missing. An ethics check is advised to ensure responsible data generation and release."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SpsL6zuRTn", "forum": "ryc6WtvwDQ", "replyto": "ryc6WtvwDQ", "signatures": ["ICLR.cc/2026/Conference/Submission3039/Reviewer_3bfE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3039/Reviewer_3bfE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956833106, "cdate": 1761956833106, "tmdate": 1762916517330, "mdate": 1762916517330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}