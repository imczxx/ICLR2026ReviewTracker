{"id": "rxZdaKhu2I", "number": 22187, "cdate": 1758327428986, "mdate": 1759896881593, "content": {"title": "Good allocations from bad estimates", "abstract": "Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $\\epsilon > 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/\\epsilon^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $\\epsilon$ error. \nIn this work, we show how to achieve the same total treatment effect as CATE with only $O(M/\\epsilon)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation.\nFinally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.", "tldr": "Course treatment effect estimates suffice for near-optimal treatment allocations.", "keywords": ["Treatment Allocation", "Treatment effects", "Sample complexity", "RCT"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d3bdced3f4a7f02f522e01ae644c941968f7a800.pdf", "supplementary_material": "/attachment/8d094a1758164b34d2ff2f87df5e05f3665cec4e.zip"}, "replies": [{"content": {"summary": {"value": "The authors investigate sample complexity bounds for estimating CATE across M different groups when trying to perform allocation to a K subset of them. Standard CATE analysis demonstrates a $\\frac{M}{\\epsilon^2}$ bound, as each group needs to learn a separate CATE, then the K-highest CATE values are selected. However, the authors argue for a $\\frac{M}{\\epsilon}$ bound by performing coarser estimation for treatments near the boundary. Essentially, the authors demonstrate that if CATE estimates can be learned within $\\sqrt{\\epsilon}$, then any estimation mistakes will not be very costly. Such learning is possible under certain assumptions on $\\tau$; for example, that $\\tau$ is smooth or is near-uniform. The authors conclude with experiments on real-world RCTs to demonstrate the efficacy of their experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Work tackles an important problem** - The authors tackle the important problem of $K$ selection from $M$ groups in a causal setting. Such a problem can be seen across a variety of real-word situations, and is especially prevalent in the world of policy. This can help more efficiently allocate resources and avoid unnecessary experiments. \n2. **Analysis is intuitive and clean** - The authors present a clean and intuitive reason why their proposed selector should outperform baselines. By avoiding the need to recompute CATE for each of the $M$ groups, the authors are able to achieve a better sample complexity, due to their ability to adaptively explore in some sense. \n3. **Characterizes when their new bound is possible** - The authors describe several scenarios where there newly proposed estimators reach the desired $\\frac{1}{\\epsilon}$ bound, and describe why such assumptions are not onerous. For example, the authors describe a class of smooth distributions for $\\tau$ that allow for such bounds, and they express an if and only if condition based on the CDF of $\\tau$. \n4. **Extension to Flexible Budget** - In Section 5, the authors include a discussion of flexible budgets, where an alternative budget $K'$ is used near $K$ that achieves better sample complexity performance. The authors sketch when such a method does and does not work, dependent on the distribution of $\\tau$."}, "weaknesses": {"value": "1. **Experiments are not Extensive** - The experiments in Section 6 are condensed to a half a page (with some extra material in the Appendix). As a result, it's hard to understand some of the results. For example, why is the failure percentage not monotonic in $\\epsilon$; presumably with increasing $\\epsilon$, it is less a stringent failure threshold, so it is surprising that this pattern is exhibited across datasets. Additionally, there is little comparison with the $\\frac{1}{\\epsilon^2}$ method. Finally, what does the actual distribution of $\\tau$ look like in practice; are the assumptions validated?"}, "questions": {"value": "1. In practice, on the datasets listed in the experiments section, how does the sample complexity of the CATE-style selector ($\\frac{1}{\\epsilon^2}$ compare with the selector proposed"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p2bVk8xiFq", "forum": "rxZdaKhu2I", "replyto": "rxZdaKhu2I", "signatures": ["ICLR.cc/2026/Conference/Submission22187/Reviewer_zW6P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22187/Reviewer_zW6P"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761739461051, "cdate": 1761739461051, "tmdate": 1762942107716, "mdate": 1762942107716, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors provide new theory showing that optimal treatment allocation can be achieved with fewer samples than classic predict-then-optimize approaches (FullCATE in the paper) would require. Their theory is built upon the insight that accurate estimates of CATE are only needed around the treatment allocation threshold."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The authors provide interesting insights about sample size requirements for optimal treatment allocation.\n- The authors substantiate their claims with extensive theoretical analysis"}, "weaknesses": {"value": "Some other related work exists that uses similar insights about the problem of optimally allocating treatment, though often without an extensive theoretical analysis. For example, some work has argued that when trying to find the optimal treatment allocation, accurate CATE estimation is not always the most effective [1,2]. \n\nWhile the authors provide a very extensive theoretical analysis, they only briefly explain the potential impact of their contributions. For example, I find it hard to understand what practitioners should do with this new information. It would be helpful if the authors could discuss this.\n\nI wonder why the authors decided to put the individuals into different groups and do the analysis based on these groups. As the number of groups decreases, the number of samples needed also decreases, but the quality of the overall allocation will also go down (because as you make the groups more granular, you will find more heterogeneity between groups, allowing for better decision-making). How should you choose the number of groups in practice if you have very little a priori information about the CATE distribution?\n\nRelated to the previous point, I do not understand how the different groups are created in the experiments. To me, this seems like the most crucial part when evaluating treatment allocation quality.\n\nI wonder why the authors did not use datasets that are often used in Uplift Modeling [1] and treatment effect estimation [3]. \n\n[1] Devriendt, F., Van Belle, J., Guns, T., & Verbeke, W. (2020). Learning to rank for uplift modeling. IEEE Transactions on Knowledge and Data Engineering, 34(10), 4888-4904.\n\n[2] Fernández-Loría, C., & Provost, F. (2022). Causal decision making and causal effect estimation are not the same… and why it matters. INFORMS Journal on Data Science, 1(1), 4-16.\n\n[3] Curth, A., Svensson, D., Weatherall, J., & Van Der Schaar, M. (2021, August). Really doing great at estimating cate? a critical look at ml benchmarking practices in treatment effect estimation. In Thirty-fifth conference on neural information processing systems datasets and benchmarks track (round 2)."}, "questions": {"value": "All the items listed in the Weaknesses section may be interpreted as questions by the authors.\n\nTypo: line 353 \"notion that requiring\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "an9Pw9Kltr", "forum": "rxZdaKhu2I", "replyto": "rxZdaKhu2I", "signatures": ["ICLR.cc/2026/Conference/Submission22187/Reviewer_mQ5Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22187/Reviewer_mQ5Z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920232037, "cdate": 1761920232037, "tmdate": 1762942107532, "mdate": 1762942107532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper fills the gap between estimating CATE and making decisions on the allocations. The authors show that while estimating all CATEs within $\\epsilon$ accuracy requires $O(M/\\epsilon^2)$ samples, achieving a near-optimal $(1-\\epsilon)$ treatment allocation typically needs only $O(M/\\epsilon)$ samples under mild distributional assumptions. In general, I personally see the results quite interesting and insightful."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper makes a clear and elegant theoretical distinction between estimation and allocation. The reduction of the sample complexity from $M/\\epsilon^2$ to $M/\\epsilon$ is insightful and exciting.\n2. Practical relevance: Direct implications for RCT and policy design: significant reduction in sample cost.\n3. The proofs are clean and well-structured and the theoretical results are rigor."}, "weaknesses": {"value": "In general, I enjoy reading the paper a lot. I do not have major concerns.\n\n1. Comparison to bandit best arm identification could be expanded. The link is conceptually strong. Particularly, recently, there are some works on good arm identification. Some ideas are very similar, although they are not is a causal inference setting.\n\n2. Policy implication is strong (“RCTs underpowered for CATE estimation can still yield good allocations”), but guidance on how to detect $\\rho$-regularity or compute sample sizes in practice is missing."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BxmygB9P3t", "forum": "rxZdaKhu2I", "replyto": "rxZdaKhu2I", "signatures": ["ICLR.cc/2026/Conference/Submission22187/Reviewer_92Sv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22187/Reviewer_92Sv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930147561, "cdate": 1761930147561, "tmdate": 1762942107247, "mdate": 1762942107247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}