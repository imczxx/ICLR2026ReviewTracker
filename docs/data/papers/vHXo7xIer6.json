{"id": "vHXo7xIer6", "number": 21867, "cdate": 1758322826779, "mdate": 1759896899348, "content": {"title": "Modeling Others' Minds as Code", "abstract": "Accurate prediction of human behavior is essential for robust and safe human-AI collaboration. However, existing approaches for modeling people are often data-hungry and brittle because they either make unrealistic assumptions about rationality or are too computationally demanding to adapt rapidly. Our key insight is that many everyday social interactions may follow predictable patterns; efficient \"scripts\" that minimize cognitive load for actors and observers, e.g., \"wait for the green light, then go.\" We propose modeling these routines as behavioral programs instantiated in computer code rather than policies conditioned on beliefs and desires. We introduce ROTE, a novel algorithm that leverages both large language models (LLMs) for synthesizing a hypothesis space of behavioral programs, and probabilistic inference for reasoning about uncertainty over that space. We test ROTE in a suite of gridworld tasks and a large-scale embodied household simulator. ROTE predicts human and AI behaviors from sparse observations, outperforming competitive baselines---including behavior cloning and LLM-based methods---by as much as 50% in terms of in-sample accuracy and out-of-sample generalization. By treating action understanding as a program synthesis problem, ROTE opens a path for AI systems to efficiently and effectively predict human behavior in the real-world.", "tldr": "", "keywords": ["Multi-agent", "theory of mind", "program synthesis", "action understanding", "goal inference"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/77a68a052b45afe6aabb2cd2afad06a720174cfc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes ROTE, which is an algorithm that leverage LLMs as code synthesis tools to predict others’ actions. It prompt LLMs to generate computer programs explaining observed behavioral traces, then perform Bayesian inference to reason about which programs are most likely. This gives a dynamic representation that can be analyzed, modified, and composed across agents and environments. The experiments show that ROTE can predicts human and AI behaviors from sparse observations. And ROTE outperform competitive baselines including behavior cloning and LLM-based methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The Related Work section is comprehensive and well-organized. It effectively situates the current work within the broader research landscape by thoroughly reviewing and analyzing three key areas: action prediction, the use of LLMs for behavior modeling, and program induction. The discussion clearly outlines the developments and current state of these fields, providing a solid foundation for positioning the paper's contributions.\n2. The proposed ROTE algorithm presents a novel approach by synergistically combining LLMs with probabilistic inference to translate observed agent behaviors into executable code programs. This represents a meaningful intermediate path between two conventional paradigms: computationally intensive inverse planning over beliefs and goals, and data-inefficient behavior cloning. By conceptualizing routines as executable \"scripts\" or \"programs,\" ROTE offers a fresh perspective on modeling structured, yet flexible, agent behavior.\n3. A comprehensive empirical evaluation is provided, systematically assessing performance across diverse scenarios—from scripted agents in gridworlds to complex human behaviors in embodied settings. Notably, ROTE demonstrates compelling zero-shot generalization capabilities across unseen environments, a critical feature for real-world applicability and a key advantage over more brittle baselines."}, "weaknesses": {"value": "1. The \"Related Work\" section omits discussion of one relevant research thread: the use of Temporal Point Processes (TPPs) for modeling human behavior with the application of first-order logic rules to constrain behavior prediction. These areas are closely related to the methodological context of this paper.\n2. The central claim of modeling behavior as \"programs\" lacks sufficient discussion of their connection to underlying cognitive processes. A key theoretical concern is whether finite-state machines can fully capture the richness of human behavior, particularly for goal-directed or socially complex scenarios. This fundamental limitation warrants deeper theoretical grounding, as it directly challenges the generalizability of the proposed approach.\n3. The experimental evaluation has several limitations. While the paper highlights ROTE's long-term prediction efficiency, it lacks comprehensive discussion of computational costs—particularly the potentially significant overhead during initial program synthesis, which could impact real-time applicability."}, "questions": {"value": "1. It lacks a clear operational definition of \"scripted\" behavior, leaving the boundary between scripted and non-scripted behaviors ambiguous. This conceptual vagueness—such as whether goal-directed planning qualifies as scripted—undermines the theoretical grounding of the proposed approach. Additionally, while ROTE demonstrates strong predictive accuracy, the semantic validity and interpretability of the generated programs remain underexplored. A more systematic analysis is needed to assess whether these programs meaningfully correspond to plausible behavioral logic or merely capture superficial statistical patterns.\n2. The construction of the program space $\\Lambda$ — including its syntactic constraints and upper bounds on state complexity — remains insufficiently specified. A more detailed description of these structural parameters would significantly enhance the reproducibility and rigorous evaluation of the proposed method. \n3. The core modeling assumption of combining deterministic programs with a noise model appears overly simplistic. Given the inherently stochastic and context-dependent nature of genuine human behavior, merely approximating behavioral uncertainty through a noise model may be insufficient to capture its full complexity, potentially limiting the model's realism and generalizability.\n4. What is the requirement for different levels of structural constraints?\n5. While multi-step prediction is efficient, the computational overhead during the initial program synthesis phase has not been compared against baseline methods. Could the authors provides more comparative measurements of this initial synthesis stage?\n6. The paper does not analyze how LLM scale affects performance. While multiple LLMs are used, their varying sizes' impact on program quality and inference speed remains unexplored.\n7. The TPP methods, such as [1, 2]，with the constraint of human-readable logic ruels, can be used to predict both future action time and type. Compared with these methods, what are the advantages of ROTE? Is it possible to add extra experiments to compare?\n\n[1] Neuro-Symbolic Temporal Point Processes. ICML 2024\n\n[2] Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human Actions. NeurIPS"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zuBhgb6RZq", "forum": "vHXo7xIer6", "replyto": "vHXo7xIer6", "signatures": ["ICLR.cc/2026/Conference/Submission21867/Reviewer_G1C7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21867/Reviewer_G1C7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21867/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760772633693, "cdate": 1760772633693, "tmdate": 1762941961921, "mdate": 1762941961921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents ROTE, a novel method that models others' minds as code. It leverages LLMs to synthesize behavioral programs from sparse observations and uses probabilistic inference to predict actions. Experiments show ROTE outperforms baselines and achieves human-level accuracy in predicting both human and AI behavior."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is generally well-written and structured. \n\n2. The method shows performance gains over the selected baselines, and in one task, it is reported to perform at a level comparable to human predictors."}, "weaknesses": {"value": "1. There is a lack of discussion regarding [1], which is a representative work that also utilizes LLMs to generate open-ended code for observed behaviors. While I can appreciate the potential differences, the complete absence of any discussion of this work is surprising.\n\n2. The claimed contribution of a \"novel algorithm\" does not seem to hold, in my opinion (at least pending further clarification). I find the architecture to be strikingly similar to that of [2], which might even be more sample-efficient. While some differences may exist in the format of the hypotheses or the use of weights, I consider these distinctions to be trivial. The complete omission of this highly relevant work is unacceptable.\n\n3. Given that the paper positions itself in the field of Program Induction, it should be compared with more related work from this area. My intuition is that some of these works, such as [3], could be directly applied to the proposed task (with prompt modifications, of course) and would likely achieve comparable results.\n\nOverall, I see too many shadows of prior work in this paper, along with potential baselines that should have been discussed but were omitted. While I appreciate the paper's motivation and writing, I believe it is not yet ready for acceptance.\n\n[1] Castro, Pablo Samuel, et al. \"Discovering symbolic cognitive models from human and animal behavior.\" bioRxiv (2025): 2025-02.\n\n[2] Zhou, Yangqiaoyu, et al. \"Hypothesis generation with large language models.\" arXiv preprint arXiv:2404.04326 (2024).\n\n[3] Qiu, Linlu, et al. \"Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement.\" arXiv preprint arXiv:2310.08559 (2023)."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OhCvUPSu0H", "forum": "vHXo7xIer6", "replyto": "vHXo7xIer6", "signatures": ["ICLR.cc/2026/Conference/Submission21867/Reviewer_P8y6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21867/Reviewer_P8y6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21867/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761758891912, "cdate": 1761758891912, "tmdate": 1762941961664, "mdate": 1762941961664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel approach to modeling others’ minds as code. It addresses the challenge of predicting agents’ actions in scenarios where behavior is not guided by explicit goals or beliefs, inspired by cognitive science studies on mindless behavior. The proposed ROTE algorithm integrates LLM-generated code with Bayesian inference to identify programs that best explain an agent’s observed behavior and to predict future actions. Experiments in two environments show substantial improvements over strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Motivated by findings in cognitive science, this work addresses a gap in machine mind modeling with potentially broad implications. \n\n- Experiments in two distinct environments show that ROTE consistently outperforms BC, AutoToM, and a naive LLM baseline in both single-step and multi-step prediction tasks. The method also demonstrates strong computational efficiency, particularly in long-horizon tasks."}, "weaknesses": {"value": "- The baselines and ROTE are evaluated with 8B and 16B, instruct and coder models. I wonder if more capable LLMs (such as GPT-4o) could directly solve the action prediction tasks as NLLM, without additional modeling approaches. This would provide a more realistic assessment of the practical need for such a modeling approach.\n\n- The proposed algorithm would be more significant if the generated programs could also handle action prediction tasks that require modeling agents’ beliefs, such as the Forward Action task in BigToM.\n\n- The description of the generalization experiments lacks some details. It would improve reproducibility to specify the environments used before and after the change. How are the textual descriptions different between the two environments?"}, "questions": {"value": "- How are different candidate programs generated, and how do you ensure their diversity? Is this achieved through a multi-pass or single-pass generation process?\n- Could you evaluate stronger LLMs to better illustrate the necessity of these action prediction tasks and how current models fall short?\n- How do the baselines (NLLM and AutoToM) with GPT-4o as their backend perform on the action prediction tasks compared to ROTE?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "j5sUnjZG7S", "forum": "vHXo7xIer6", "replyto": "vHXo7xIer6", "signatures": ["ICLR.cc/2026/Conference/Submission21867/Reviewer_vNqa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21867/Reviewer_vNqa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21867/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952153900, "cdate": 1761952153900, "tmdate": 1762941961396, "mdate": 1762941961396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper engages with the problem of social interaction modeling, proposing to model agents' predictable patterns as behavioral programs. The authors introduce ROTE, an algorithm that uses LLMs to synthesize behavioral programs and probabilistic inference for reasoning about uncertainty. By evaluating on gridworld tasks and embodied simulators, ROTE predicts human and AI behaviors well and outperforms baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper represents an interesting and novel idea. Using program synthesis with SMC inference for modeling agentic behavior is worth studying.\n- This paper shows good empirical results: ROTE outperforms baseline conditions. It also demonstrates superior generalization accuracy.\n- This paper has a reasonable selection of environment. It goes beyond simple 2D gridworld (Construction) with the inclusion of an embodied environment (Partnr).\n- This paper also condutcs human studies, allowing the reader to have a clearer sense of the performance of ROTE. That fact that ROTE achieves human-level performance while the baselines do not here is noteworthy.\n- The paper is generally well written."}, "weaknesses": {"value": "- The paper has Naive LLM (NLLM) as a baseline, which seems to be the strongest baseline. But why not also use Chain-of-Thought (few or zero shot) as a baseline? How would that compare to ROTE? (Or could you argue that CoT is not appropriate here?) I consider this to be a major weakness of the paper, and would raise my score if this issue is addressed.\n- Using programs to represent behavioral patterns can be a good idea, but it might be too rigid or inflexible in many cases. I would appreciate that the authors discuss this aspect more. For example, the first limitation at the end is related to this. But I think more discussions would be helpful. For example, as things currently stand, what kinds of real-world domains or settings do the authors expect ROTE to mostly work? For domains where ROTE may not work, would it be because the programs are not expressive enough (e.g., wrt high-dimentional inputs) or programs as a presentation is not suitable?"}, "questions": {"value": "See \"Weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QT8vHr8uBy", "forum": "vHXo7xIer6", "replyto": "vHXo7xIer6", "signatures": ["ICLR.cc/2026/Conference/Submission21867/Reviewer_5dXd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21867/Reviewer_5dXd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21867/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762121084413, "cdate": 1762121084413, "tmdate": 1762941961051, "mdate": 1762941961051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}