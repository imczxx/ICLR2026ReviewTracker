{"id": "Y1VgLHbzCC", "number": 3447, "cdate": 1757429356410, "mdate": 1759898089540, "content": {"title": "One Demo Is All It Takes: Planning Domain Derivation with LLMs from A Single Demonstration", "abstract": "Pre-trained large language models (LLMs) show promise for robotic task planning but often struggle to guarantee correctness in long-horizon problems. Task and motion planning (TAMP) addresses this by grounding symbolic plans in low-level execution, yet it relies heavily on manually engineered planning domains. To improve long-horizon planning reliability and reduce human intervention, we present Planning Domain Derivation with LLMs (PDDLLM), a framework that automatically induces symbolic predicates and actions directly from demonstration trajectories by combining LLM reasoning with physical simulation roll-outs. Unlike prior domain-inference methods that rely on partially predefined or language descriptions of planning domains, PDDLLM constructs domains without manual domain initialization and automatically integrates them with motion planners to produce executable plans, enhancing long-horizon planning automation. Across 1,200 tasks in nine environments, PDDLLM outperforms six LLM-based planning baselines, achieving at least 20% higher success rates, reduced token costs, and successful deployment on multiple physical robot platforms.", "tldr": "Using LLMs and physical simulation to derive planning domains without manual domain initialization, enhancing LLM's performance in long-horizon task planning.", "keywords": ["Planning Domain Inference", "PDDL", "Robot Task Planning", "Task and Motion Planning", "LLMs for Planning", "Embodied AI"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ac5845cfd6655d12fc4f47f205c394f234126a7b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces PDDLLM, a novel framework that enables LLMs to autonomously generate symbolic planning domains from a single human demonstration. PDDLLM derives both automatically by integrating LLM reasoning with physical simulation. Its Logical Constraint Adapter further connects high-level symbolic plans with low-level motion planning, allowing end-to-end execution. Evaluations across over  nine environments demonstrate that PDDLLM outperforms LLM-based baselines in success rate, planning efficiency, and token cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- PDDLLM automatically derives predicates and actions from a single demonstration without manual engineering or predefined templates.\n- Strong empirical results, outperforms six LLM-based baselines across 1,200 tasks.\n- Demonstrates effective transfer of learned domains and actions to new, unseen tasks and environments, on multiple robot platforms."}, "weaknesses": {"value": "- The difference from InterPreT is unclear. It seems PDDLLM replaces human-crafted planning examples with a single demonstration and a predefined constraint pool for predicate generation. More clarification on how this differs conceptually or technically would strengthen the paper.\n- Is GPT-4o necessary to achieve the reported performance? Have the authors tested other LLMs?\n- Since the method lacks a feedback loop, it seems to require perfect constraint design, perfect predicate specification, and perfect action proposals. A single failure at any step could lead to a catastrophic outcome. It is unclear why the method is described as robust and generalizable, could the authors provide examples demonstrating successful performance with imperfect intermediate steps?"}, "questions": {"value": "Questions:\n- Once a predicate is proposed with constraints, it appears that it is never updated. What happens if the constraints are incorrect? How do you ensure that the hyperparameters within these constraints are generalizable?\n- In Figure 2’s illustration, the x, y, and z axes all share the same hyperparameter u. Why is this the case, and how was u selected?\n- How do you handle low-level failures? Although the motion planning is formulated as a constrained optimization problem, the inequality constraints can accumulate errors. For example, in the stacking task, the third block may fall if the second block is not perfectly centered on the first one.\n\nComments: \n- L201-203, PDDL clauses have no comma in it\n\nMissing literature: \n\nZhu et al., PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models. 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tepeKU3BUz", "forum": "Y1VgLHbzCC", "replyto": "Y1VgLHbzCC", "signatures": ["ICLR.cc/2026/Conference/Submission3447/Reviewer_ZvYq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3447/Reviewer_ZvYq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943217369, "cdate": 1761943217369, "tmdate": 1762916728605, "mdate": 1762916728605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The submission proposes a framework to derive a symbolic planning domain from a single demonstration. It achieves this through predicate “imagination” from simulator roll-outs summarized by an LLM and action “invention” from logical state transitions. Then the produced domain can be used with a PDDL motion planner. The authors evaluate across  several tasks and environments and report large gains over LLM-enabled planners (with a fixed planning budget), includingl real-robot executions on three platforms."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The submission tackles the costly manual domain-spec bottleneck in TAMP and positions the work among LLM planners and domain-inference lines of work. The end-to-end automation pipeline (predicate imagination, action invention  and LoCA) is, in my understanding, the main contribution/novelty. The tasks are varied in difficulty and nature (Tower of Hanoi, bridge building, burger cooking), and multiple SOTA baselines are included (LLMTAMP, LLMTAMP-FF/FR, o1-TAMP, R1-TAMP, RuleAsMem). Analysis of time-limit is provided, which can be relevant when planning under a fixed time budget in real applications. Real robot demonstrations strengthen the empirical support of the frameworks effectiveness."}, "weaknesses": {"value": "Since the pipeline still relies on some hand-chosen design choices (e.g. $u$ for subspace granularity), statements about constructing domains \"without manual predesign\" might be exaggerated.\n\nHow often does the limited operator set miss required invariants? First-order predicates come from discretized subspaces while higher-order ones use a limited set of logical operators/quantifiers. The limitations section admits missing complex predicates (e.g., ordering constraints), which can materially affect plans in more challenging domains."}, "questions": {"value": "Can you add an ablation for u and for the number of parallel prompts? Including domain quality metrics (missing/redundant predicates) \n\nCan you include more quantitative per platform metrics for real robot experiments?\n\nCan you disambiguate token costs across domain derivation and per-task planning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Xx2oIl7jw7", "forum": "Y1VgLHbzCC", "replyto": "Y1VgLHbzCC", "signatures": ["ICLR.cc/2026/Conference/Submission3447/Reviewer_3sZG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3447/Reviewer_3sZG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956973411, "cdate": 1761956973411, "tmdate": 1762916728433, "mdate": 1762916728433, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PDDLLM, a framework that automatically generates the PDDL planning domain from one demonstration by combining LLMs with physical simulation. It introduces a Logical Constraint Adapter (LoCA) to automatically ground the generated symbolic actions into motion constraints, enabling seamless integration with motion planners and real-robot execution. Experiments on 9 tasks show that PDDLLM outperforms baselines and achieves performance comparable to expert-designed domains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper aims to automatically generate planning domains from one demonstration to reduce manual engineering efforts, which is a valuable goal for the field. \n2. Experiments on 9 tasks show that the proposed method achieves a high success rate, outperforming other baselines."}, "weaknesses": {"value": "1. The paper relies on a physics simulator to evaluate the physical feasibility of predicates. However, such simulation-based evaluation may fail to capture complex dynamics, limiting the method’s generalization to real-world settings. The current experiments only involve simple rigid-body interactions, so it remains unclear how the proposed approach would perform with more complex objects such as deformable materials or fluids.\n2. There are several unclear aspects in the paper:\n(1) It is not clearly stated whether the predicates must be predefined or can be freely generated by the LLM based on the task and scene. If predicates are required in advance, this could constrain the generality of the proposed framework.\n(2) The paper mentions that “the range of each feature is divided into intervals, with the length of each interval being a hyperparameter,” but does not specify how this hyperparameter is determined. Is it fixed manually or generated adaptively by the LLM?"}, "questions": {"value": "The paper claims that the framework can integrate knowledge across demonstrations. In this context, during the evaluation, were demonstrations from other tasks used to assist the construction of the domain model for the current task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EeOGHeCdI0", "forum": "Y1VgLHbzCC", "replyto": "Y1VgLHbzCC", "signatures": ["ICLR.cc/2026/Conference/Submission3447/Reviewer_h5Ug"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3447/Reviewer_h5Ug"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994965377, "cdate": 1761994965377, "tmdate": 1762916728185, "mdate": 1762916728185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new method that is capable to generate a complete planning domain from scratch, without relying on any predefined predicates or actions. The method employs the reasoning ability of LLMs to do generation based on demonstration."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This work targets an interesting and meaningful problem in planning.\n\nThe proposed methodology does not rely on pre-defined predicate space and action model, which reduce the effort of human annotation.\n\nExperimental in real robot environments demonstrates the effectiveness of the proposed method."}, "weaknesses": {"value": "**Major**\n\nSuccessful deployment of the proposed method requires a perception function that can accurately extract the continuous states from objects. It is unclear what types of the perception function the proposed method can work along well.\n\nIt was not extensively discussed in the paper how robust the proposed method is with respect to any noises in the perception process.\n\nIt seems that applying the proposed method in real applications requires setting up a same digital copy in a simulation. This limits the potential applicable areas as setting up simulation in some domains requires laborious manual modelling even for feature parameters. It would be better to discuss what kind of domain the proposed method can easily handle, and what domains the proposed method may encounter big challenges.\n\n**Minor**\n\nSome paragraph is not written with clear motivations, which makes the reading not easy to follow. For example, L180-L196, it is unclear why the method is dividing the feature space. It would be better to clearly explain the target problem at the moment, e.g., use parallel simulations to imagine predicates by summarizing the simulation roll-outs with LLMs, and explain what the challenges are."}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OybKzWxBjz", "forum": "Y1VgLHbzCC", "replyto": "Y1VgLHbzCC", "signatures": ["ICLR.cc/2026/Conference/Submission3447/Reviewer_MY9K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3447/Reviewer_MY9K"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995792328, "cdate": 1761995792328, "tmdate": 1762916727856, "mdate": 1762916727856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}