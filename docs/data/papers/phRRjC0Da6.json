{"id": "phRRjC0Da6", "number": 7241, "cdate": 1758012801031, "mdate": 1759897864153, "content": {"title": "Bayesian Primitive Distributing for Compositional Zero-shot Learning", "abstract": "Compositional zero-shot learning (CZSL) aims to recognize unseen attribute-object combinations by learning primitive concepts (i.e., attribute and object) from seen compositions. Existing CZSL solutions typically harness the power of vision-language models like CLIP via textual prompt tuning and visual adapters. However, they independently learn one deterministic textual prompt for each primitive or compositional labels, ignoring both the inherent semantic diversity within each primitive and the semantic relationships between primitive concepts and their compositions. In this paper, we propose BAYECZSL, a novel Bayesian-induced framework that learns probability distributions over each primitive textual prompt from a Bayesian perspective. Specifically, BAYECZSL models image-specific primitive textual prompts as learnable probability distributions to capture intra-primitive diversity. Building on these primitive distributions, we aggregate learned probability distributions from attribute and object branches to form compositional prompt space via Compositional Distribution Synthesis strategy, thus capturing the semantic relationships between primitive concepts and their compositions. Moreover, Three-path Distribution Enhancement module is introduced to transform initial distributions into expressive ones via invertible mappings.\nFinally, these enhanced distributions are sampled to generate diverse textual prompts, achieving more comprehensive coverage of the prompt space and generalizing to unseen compositions. Extensive experiments on multiple CZSL benchmarks demonstrate the superiority\nof our BAYECZSL. Code will be released.", "tldr": "We propose  a novel Bayesian-induced framework that learns a probability distribution over each primitive to model the intra-primitive variance.", "keywords": ["Compositional Zero-shot Learning", "Probability Distribution", "Bayesian Inference"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/925f02c07afae0f20213e1f2a62ad5b02e6485ed.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces BAYECZSL, a novel Bayesian-induced framework that learns distributions over primitive textual prompts. The authors observe that the existing CZSL works use a single deterministic textual prompt for each primitive concept and its composition, which is insufficient to capture variations within the compositions; for example, old in old dog is different from old town. Furthermore, they notice that prior work ignores the rich relational structure between the primitives and compositions. BAYECZSL addresses these limitations through the following steps. First, it learns a probability distribution over primitive concepts to better represent intra-primitive diversity and reduce overfitting. Then, it uses compositional distributional synthesis to aggregate the learned probability distributions into a unified compositional prompt space. Then, to model more complex distributions, it uses a three-path distribution enhancement module to transform the initial prompt and composition distributions into flexible distributions using a sequence of invertible mappings. Finally, it draws multiple Monte Carlo samples from the distributions and mixes them with the original prompt representations to improve generalization. The results on the CZSL benchmarks show that BAYECZSL improves performance over the state-of-the-art methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is easy to follow and well-written.\n\nThe proposed method is well-motivated. The method outperforms prior work on compositional zero-shot learning datasets.\n\nThe ablations in Section 4.3 are quite helpful in understanding the contributions of BAYECZSL."}, "weaknesses": {"value": "**Method**\n\n- The core components (variational posteriors, Gaussian fusion, normalizing-flow enhancement, and Monte Carlo sampling) are established Bayesian/VI tools. Novelty is rather modest since it mainly adapts these techniques to CZSL prompt distributions.\n\n- The approach uses MLP-based disentanglers to obtain attribute and object features and to parameterize their base posteriors. The compositional posterior is obtained via inverse-variance weighted fusion rather than being learned directly. A simpler alternative is to get a composition posterior from $x^{c}$ (Eq. 2) without CDS and additional disentanglers; an ablation here would be helpful.\n\n- The method is close to CoCoOp [a]. CoCoOp adds additional information about the image, in the form of a meta token, to the text prompts, thereby improving performance. Although this paper is included in the related work, it is not compared in the results section. Including them as baselines or explaining why they are not directly comparable would make the evaluation fairer.\n\n- The framework assumes single attribute-object compositions and does not evaluate multi-attribute or multi-object cases. Suppose there is an object with multiple attributes at test time (e.g., small white cat), the framework could potentially sample vectors from the same enhanced distributions for multiple attributes rather than treating them as separate attributes. This could lead to a performance drop when integrated into the prompt vectors. Including experiments on attribute-attribute-object settings [b] would strengthen the paper.\n\n**Architecture.**\n\nAll the experiments are limited to the CLIP ViT-L/14 model. It would be great if the authors could include experiments with additional CLIP models and other models such as BLIP, etc. It is also unclear from the paper if their method will even work with vision-language models that use a decoder instead of the bi-encoder architecture seen in CLIP (Figure 2).\n\n**Impact**\n\nWhile the paper shows positive, albeit small, improvements over prior methods on the compositional zero-shot learning datasets, my concern is that the paper is too task-specific.\nThe paper makes strong assumptions about the types of compositions it can handle, i.e., the method can only handle attribute-object compositions. This severely limits the impact of the paper.\n\n**Minor suggestions**\n\nLines 97-99: It would be great if the authors could explicitly say that they are reporting relative improvement in performance. At first glance, it appeared to be an absolute improvement.\n\n**References**\n\n[a] Conditional Prompt Learning for Vision-Language Models, CVPR 22.\n\n[b] Learning to Compose Soft Prompts for Compositional Zero-Shot Learning, ICLR 23."}, "questions": {"value": "In addition to the questions listed in the weaknesses section, here are a few more questions. \n\n**Clarification for Misc. claim**\n\n- Lines 61-63: What does “cross-branch synergies” mean? Could you explain that in simpler words? \n\n- In lines 60-61, the authors say that prior work ignores the rich relational structure between the primitives and their compositions. Could you clarify what this sentence means and how BAYECZSL understands the relational structure of the concepts? In addition, could you also discuss Appendix D in more detail in the main paper? The plots suggest the model's performance can drop below the best numbers reported in Table 1. I’d like to understand the trade-off between the number of Monte Carlo samples and performance.\n\n**Error bars**\n\nSince you are averaging over $L$ prompts, could you also include the error bars for the method in the results section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "coh76yB9of", "forum": "phRRjC0Da6", "replyto": "phRRjC0Da6", "signatures": ["ICLR.cc/2026/Conference/Submission7241/Reviewer_Hjnp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7241/Reviewer_Hjnp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7241/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957431898, "cdate": 1761957431898, "tmdate": 1762919380901, "mdate": 1762919380901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes BAYECZSL, a Bayesian-induced framework for compositional zero-shot learning (CZSL) that represents each primitive textual prompt (attribute/object) as a probability distribution, rather than a single deterministic vector like most prior work in recent years. WIthin the proposed approach, these distributions (of attributes and objects) are image-conditioned via variational inference, then synthesized into a compositional prompt distribution using variance-inverse Gaussian fusion; distributions are further made expressive by a three-path distribution enhancement module based on invertible mappings (normalizing-flow–style). Sampling from these distributions yields diverse prompts that are mixed with the soft prompts in a three-path CLIP-based architecture (attribute/object/composition). The loss combines branch cross-entropies with a Bayesian regularizer, and inference fuses composition scores with the product of primitive scores. The authors conduct experiments on standard CZSL benchmarks MIT-States, UT-Zappos, and C-GQA show state-of-the-art results in closed-world and open-world settings. The authors also conduct ablations on the three modules and sampling sensitivity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "To the best of my knowledge, the paper’s core idea—modeling attribute/object primitive prompts as image-conditioned distributions, composing them into a compositional distribution via variance-inverse Gaussian fusion is novel for CZSL. \n\nI think this probabilistic framing is clear and technically sound: the objectives are explicit, the inference story is coherent, and the components (BPD, CDS, TDE) are well-motivated. I think the evaluation setup in this paper is correct and consistent with the CZSL literature (closed-world and open-world settings on MIT-States, UT-Zappos, and C-GQA), and the approach shows strong performance overall, with especially robust gains on UT-Zappos. I like that the ablations are clean and isolate each module’s contribution, and the sensitivity analyses over the sampling count L and the mapping depth N are informative rather than cosmetic. \n\nOverall, I think this paper is a good work on compositionality in CZSL with a principled probabilistic formulation and solid empirical support."}, "weaknesses": {"value": "While I have no concerns about the novelty or the methodological soundness of this work, my primary concern is reproducibility. The reported numbers appear to be single-run point estimates without variability, and I do not see evidence of repeated runs or variance statistics. Including results over multiple random seeds (idealy over 5) with mean +/- confidence intervals would materially strengthen the quantitative claims, especially for the main comparisons and ablations. Clearly specifying the random seed policy, sources of stochasticity (e.g., initialization of the flow/TDE, sampling count L, data shuffling), and any early-stopping criteria would also help others reproduce the results faithfully."}, "questions": {"value": "I am wondering if the authors have thought about how sensitive are results to the diagonal-Gaussian residual assumption in BPD? Have the authors tried things like full-covariance, mixture posteriors, or normalizing flows in place of TDE to shift complexity upstream?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xC6Q2ZcTpk", "forum": "phRRjC0Da6", "replyto": "phRRjC0Da6", "signatures": ["ICLR.cc/2026/Conference/Submission7241/Reviewer_QwoX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7241/Reviewer_QwoX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7241/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957442477, "cdate": 1761957442477, "tmdate": 1762919380182, "mdate": 1762919380182, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BAYECZSL, a Bayesian-induced CZSL framework that learns probability distributions over each primitive textual prompt from a Bayesian perspective. The method explicitly models prompt uncertainty for attributes and objects, then synthesizes compositional distributions through a principled fusion mechanism, and enhances those distributions with invertible mappings. Experiments on three major CZSL benchmarks (MIT-States, UT-Zappos, C-GQA) demonstrate BAYECZSL outperforms existing CZSL methods in both Closed-World and Open-World settings."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1) This paper proposes very novel ideas to more effectively tackle the core challenge of intra-primitive semantic diversity in compositional zero-shot learning via Bayesian distribution modeling.\n2) The key idea of learning probability distributions over each primitive textual prompt, rather than learning a single deterministic prompt as in prior work, is both theoretically grounded and interesting. In addition, this idea is well-aligned with the core challenge.\n3) I am also generally impressed  by the the novel use of primitive distributions to construct a compositional prompt space, and the practical use of distribution enhancement strategy to facilitate diverse prompt sampling.\n4) The experimental results are convincing, naturally leading the reader to concur with the authors’ perspective. \n5) The paper is exceptionally well-written and a true pleasure to read."}, "weaknesses": {"value": "1) Its better to explain why the variance-inverse weight Gaussian fusion strategy is used in the Compositional Distribution Synthesis module. \n2) More extensive ablation experiments on more datasets, such as MIT-States or C-GQA, would improve the experiment part.\n3) Its better to analyze the impact of the hyper-parameters $\\beta_a,\\beta_o,\\beta_c$.\n4) The model introduces computational overhead compared to single-prompt and simple soft-prompt baselines, given multiple sampling, flows, and synthesizing steps. Its better to analyze training/inference cost, memory consumption, or tradeoffs between performance and complexity."}, "questions": {"value": "How is numerical stability maintained during covariance inversion in the compositional distribution synthesis step? Is regularization ever needed, and does this affect fusion quality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Uou0UZLbFs", "forum": "phRRjC0Da6", "replyto": "phRRjC0Da6", "signatures": ["ICLR.cc/2026/Conference/Submission7241/Reviewer_th9S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7241/Reviewer_th9S"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7241/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762005590079, "cdate": 1762005590079, "tmdate": 1762919379567, "mdate": 1762919379567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BAYECZSL, a Bayesian-induced framework for Compositional Zero-Shot Learning that models attribute and\nobject prompts as probability distributions rather than deterministic embeddings. The method captures intra-primitive diversity\nand semantic uncertainty by learning Bayesian distributions over textual prompts, which are then fused through a Compositional\nDistribution Synthesis module to form a compositional prompt space. A Three-path Distribution Enhancement module further\nrefines these distributions via invertible mappings, enabling more expressive sampling and richer semantic coverage."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper reformulates CZSL from a Bayesian inference standpoint, introducing the idea of learning probability distributions over primitive textual prompts. This probabilistic view allows the model to explicitly model intraprimitive variability and semantic uncertainty, addressing a key limitation of prior deterministic prompt-based methods.\n\n2. The proposed CDS and TDE modules jointly enable a unified, expressive prompt distribution space. CDS fuses attribute and object distributions to model their semantic relationships, while TDE transforms base distributions into more flexible ones via invertible mappings."}, "weaknesses": {"value": "1. Although the combination of Bayesian modeling and compositional synthesis is interesting, several prior works have explored distributional or probabilistic prompt spaces. E.g. \"Prompt Distribution Learning\" and \"Prompting Language-Informed Distribution for Compositional Zero-Shot Learning\". The contribution may thus be perceived as an evolutionary extension rather than a fundamentally new paradigm.\n\n2. The baselines used for comparison are outdated, primarily consisting of works from 2022 and 2023. It would strengthen the paper to include evaluations against more recent state-of-the-art approaches.\n\n3. Despite being compared with relatively outdated baselines, the reported improvements are not particularly significant."}, "questions": {"value": "How many prompt tokens are used ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WIzAsDlHn1", "forum": "phRRjC0Da6", "replyto": "phRRjC0Da6", "signatures": ["ICLR.cc/2026/Conference/Submission7241/Reviewer_beGh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7241/Reviewer_beGh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7241/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762864015664, "cdate": 1762864015664, "tmdate": 1762919379233, "mdate": 1762919379233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}