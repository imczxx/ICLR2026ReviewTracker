{"id": "yxJzmoEb48", "number": 20184, "cdate": 1758303417635, "mdate": 1759896993413, "content": {"title": "Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking", "abstract": "Retrieval-augmented generation (RAG) is critical for reducing hallucinations and incorporating external knowledge into Large Language Models (LLMs). However, advanced RAG systems face a trade-off between performance and efficiency. Multi-round RAG approaches achieve strong reasoning but incur excessive LLM calls and token costs, while Graph RAG methods suffer from computationally expensive, error-prone graph construction and retrieval redundancy. To address these challenges, we propose T$^2$RAG, a novel framework that operates on a simple, graph-free knowledge base of atomic triplets. T$^2$RAG leverages an LLM to decompose questions into searchable triplets with placeholders, which it then iteratively resolves by retrieving evidence from the triplet database. Empirical results show that T$^2$RAG significantly outperforms state-of-the-art multi-round and Graph RAG methods, achieving an average performance gain of up to 11% across six datasets while reducing retrieval costs by up to 45%.", "tldr": "We propose T$^2$RAG, a novel method that combines the advantages of both approaches while significantly reducing cost. T$^2$RAG leverages the inherent thinking capabilities of LLMs to expand questions into traceable triples containing question marks.", "keywords": ["retrieval-augmented generation", "chain-of-thought", "knowledge graphs"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5fc21f086d06f62468f2a04c73e5e239365965bf.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes $T^2RAG$, a lightweight and efficient retrieval-augmented generation framework that uses a graph-free knowledge base of atomic triplets. $T^2RAG$ decomposes questions into searchable triplets with placeholders and iteratively resolves them via evidence retrieval, reducing reliance on costly multi-round interactions or complex graph construction. Experiments show it outperforms state-of-the-art RAG methods, offering a more effective and efficient solution for knowledge-intensive reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* Using triplet with placeholder to represent the required information is new and interesting to me\n* The experiments are extensive"}, "weaknesses": {"value": "* The triplet update itself is not complicated, but in Step 2.3, the use of mathematical notation makes the process significantly harder to follow.\n* T^2RAG is actually a multi rould RAG, but only one multi round baseline is compared, maybe some more multi round baselines should be added."}, "questions": {"value": "* In section 4.3, line 262, the authors convert the triplet into query by simply concatenating the elements without the placeholder, but this query will be quite different from the normal ones, will the dense retriever perform suboptimally due to out of domain?\n* I do not quite understand why using triplet can reduce the number of llm calls. For each retrieval, the method still requires an LLM call to update the triplet, and other approaches can similarly update the next subquery after each retrieval.\n* Instructing the LLM to generate triplet seems to be difficult, how does small models like Llama 8B and Qwen 7B performs"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BJbyT63vQ7", "forum": "yxJzmoEb48", "replyto": "yxJzmoEb48", "signatures": ["ICLR.cc/2026/Conference/Submission20184/Reviewer_AQoT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20184/Reviewer_AQoT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761643003155, "cdate": 1761643003155, "tmdate": 1762933694234, "mdate": 1762933694234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes T2RAG, a retrieval-augmented generation framework that replaces chunk-level retrieval with a graph-free store of atomic triplets. An offline stage distills a corpus into triplets and embeds them with FAISS for fast lookup. At inference time, an LLM decomposes the user question into placeholder triplets, iteratively resolves missing arguments by retrieving candidate triplets, and finally answers the question using the resolved evidence. Across six datasets, the authors report performance gains over selected multi-round and graph-based RAG baselines while reducing retrieval costs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The work proposes triplet-driven thinking to reduce token footprint and simplify graph dependencies in the RAG pipeline.\n\n2.The split between offline distillation (triplet extraction/embedding) and online iterative resolution is clean and easy to reproduce, with a plausible path to system engineering and deployment. The placeholder-resolution idea encourages explicit evidence grounding rather than opaque, multi-turn prompts; this has the potential to reduce uncontrolled drift.\n\n3.The paper claims consistent improvements on multiple datasets along with cost reductions, suggesting that lighter-weight semantic atoms can be competitive with heavier chunk or graph pipelines."}, "weaknesses": {"value": "1.The settings of experiments appear to resolve to entity answers or facts naturally expressible as single triplets. This inherently benefits triplet retrieval and makes direct comparisons to multi-round RAG and GraphRAG less fair. The paper should include tasks where answers are compositional, multi-hop, or non-entity (rationales, procedural steps) to validate generality.\n\n2.The placeholder triplet decomposition and iterative resolution are described verbosely, but the novelty claim would be stronger with: (a) ablations comparing against simpler query rewriting + re-ranking loops; (b) a version that uses slot-filling over chunks without pre-extracted triplets; and (c) error-driven analyses showing why placeholders materially outperform strong query planners.\n\n3.Ablation results indicate that raw chunks still matter during retrieval, and that intermediate LLM calls over these chunks increase token usage and hallucination risk. This undercuts the central claim that “replacing chunks with triplets” consistently reduces cost and risk. \n\n4.There is no robustness study for incorrect or incomplete query-triplet decomposition. Since downstream retrieval depends on these slots, small decomposition errors could derail performance on complex questions. \n\n5.Only a few representatives of multi-round and GraphRAG are included. More representative baselines should be added to support the “state-of-the-art” claim. Also report exact prompting/cost budgets for each baseline to ensure fairness.\n\n6.Triplet-first retrieval may struggle on compositional, multi-hop, or explanatory tasks where answers are not atomic entities, which limits the practical value of T2RAG. \n\n7.Minor typos: Line 280: “and and.” Line 415: “Figure 5” should be “Table 2”."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OqaCyKyRfz", "forum": "yxJzmoEb48", "replyto": "yxJzmoEb48", "signatures": ["ICLR.cc/2026/Conference/Submission20184/Reviewer_pP8e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20184/Reviewer_pP8e"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890018023, "cdate": 1761890018023, "tmdate": 1762933693512, "mdate": 1762933693512, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes T2RAG, a novel framework for Retrieval-Augmented Generation (RAG) that improves multi-hop question answering by leveraging atomic triplets as the fundamental unit of retrieval and reasoning. Unlike traditional chunk-based or graph-based methods, T2RAG avoids costly graph construction and reduces token overhead by focusing on triplets with placeholders, which are resolved iteratively through an adaptive retrieval process. The paper demonstrates that T2RAG outperforms state-of-the-art RAG systems, achieving an 11% performance gain on various QA datasets while reducing retrieval costs by up to 45%."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper proposes T2RAG, an innovative framework that leverages atomic knowledge triplets to go beyond traditional chunk- or graph-based retrieval-augmented generation (RAG) approaches.\n\n2.\tThe authors demonstrate that T2RAG yields strong empirical gains across multiple QA datasets, improving average performance by 11% while reducing retrieval cost by up to 45%, which shows both effectiveness and efficiency."}, "weaknesses": {"value": "1.\tThe related-work section could be strengthened. Although GraphRAG and multi-round RAG methods are discussed, the paper lacks comparison with other triplet-based retrieval methods such as SubgraphRAG, which also uses triplets for retrieval.\n\n2.\tExperimental parameter choices are not always fair. When comparing multi-round methods to direct chunk-retrieval baselines there is an information imbalance: some settings allow more total retrieved content than others. \n\n3.\tSeveral implementation details are unclear and need to be spelled out — for example, the paper does not explicitly state how the system behaves when there are no searchable triplets available."}, "questions": {"value": "1.\tThe related-work section would benefit from a broader discussion of other triplet-based retrieval approaches. In particular, SubgraphRAG (Li et al., 2025) also employs triplet structures for retrieval and could serve as a valuable point of comparison. Including a discussion of such methods, as well as adding SubgraphRAG as an experimental baseline for both accuracy and retrieval efficiency, would help position T2RAG’s contribution more clearly within the current RAG landscape.\n\n**Ref:** Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation\n\n2.\tAlthough the paper highlights avoiding graph-construction overhead, it still depends on LLMs to extract triplets, which is conceptually similar to GraphRAG’s reliance on LLMs. Could the authors provide a more detailed analysis of the triplet-extraction step? In particular, do different extraction prompts significantly affect performance?\n3.\tHow does the system handle queries whose triplets are all fuzzy (i.e., contain two or more placeholders)? If there are no searchable triplets, retrieval may fail — is there a fallback or mitigation strategy for this case?\n4.\tRegarding the fairness of comparisons: multi-round settings use N = 3, k = 5, which can retrieve up to 15 chunks for answering, while the direct chunk-retrieval baseline sets k = 5. This creates unequal information budgets. The authors should consider reporting the average number of chunks T2RAG actually uses and using that as a cap for other methods to ensure parity.\n5.\tWhen reporting token and time overheads for T2RAG, does the measurement include the cost of repairing or refining triplets, or does it only account for the final answer-generation phase? Please clarify.\n6.\tTypo: A space is missing in line 145 after \"into multi-round\".\n\nIf the authors can appropriately address the above issues, I would consider raising my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sPqwYH91lH", "forum": "yxJzmoEb48", "replyto": "yxJzmoEb48", "signatures": ["ICLR.cc/2026/Conference/Submission20184/Reviewer_jjQY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20184/Reviewer_jjQY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894749960, "cdate": 1761894749960, "tmdate": 1762933692853, "mdate": 1762933692853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes T2RAG, a framework to conduct GraphRAG without actually building knowledge graphs (KGs), which may help avoid the costly, time-consuming, and error-prone process of offline KG construction. This is done by extracting triplets from the corpus and then storing these triplets directly.\nTo store these triplets, T2RAG converts each triplet into natural language, embeds them as dense vectors, and stores them in vector databases. Given a question, the LLMs would be asked to decompose the query into triplets, and these triplets are then embedded and thus used to search relevant triplets in the triplet vector datasets to resolve the questions. Experiments show that T2RAG can improve some QA datasets significantly."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of using purely triplet-based databases for multi-hop reasoning with RAG is interesting.\n- The proposed online retrieval method is also interesting. With those placeholders, the query triplets can be semantically closer to the relevant triplets in the vector database.\n- For QA datasets that do not require that many hops, the proposed method may improve accuracy significantly."}, "weaknesses": {"value": "- One reason to use graph data is that it can be more friendly when dealing with multi-hop reasoning. Building databases without entity links but with only triplets essentially gives up graph structures during offline building. So, during the online process, the method would, in principle, need to somehow reconstruct the multi-hop links. \n    - This can be especially hard for long-hop reasoning, and this may also be the reason why T2RAG mostly improves datasets with fewer hops, e.g., PopQA, 2Wiki.\n    - So, it would be more interesting to see whether T2RAG can still perform decently for reasoning with even longer hops. And in such cases, what the costs would be.\n- In the meantime, even though offline building of KGs can have some issues, storing things in triplet embedding format would also cause issues, especially when dealing with super large corpora.\n    - For example, the number of triplets can grow fast, and the embedding quality would then affect the retrieval quality more significantly. With methods like FAISS for efficiency, more noise would also be introduced.\n    - Therefore, it should also be required to test T2RAG on super large corpora."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Q3Wey35SqB", "forum": "yxJzmoEb48", "replyto": "yxJzmoEb48", "signatures": ["ICLR.cc/2026/Conference/Submission20184/Reviewer_ySAV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20184/Reviewer_ySAV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962356746, "cdate": 1761962356746, "tmdate": 1762933692488, "mdate": 1762933692488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}