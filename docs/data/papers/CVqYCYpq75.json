{"id": "CVqYCYpq75", "number": 25238, "cdate": 1758365592512, "mdate": 1763576409987, "content": {"title": "Dem-HEC: High-Entropy Contrastive Fine-Tuning for Countering Natural Corruptions", "abstract": "Neural networks are highly susceptible to natural image corruptions such as noise, blur, and weather distortions, limiting their reliability in real-world deployment. The prime reason to maintain the high integrity against natural corruptions is that these distortions are the primary force of distribution shift intentionally (compression) or unintentionally (blur or weather artifacts). For the first time, through this work, we observe that such corruptions often collapse the network's internal feature space into a high-entropy state, causing predictions to rely on a small subset of fragile features. Inspired by this, we propose a simple yet effective entropy-guided fine-tuning framework, Dem-HEC, that strengthens corruption robustness while maintaining clean accuracy. Our method generates high-entropy samples within a bounded perturbation region to simulate corruption-induced uncertainty and aligns them with clean embeddings using a contrastive loss. In parallel, cross-entropy on both clean and high-entropy samples, combined with knowledge distillation from a teacher snapshot, ensures stable predictions. Dem-HEC is evaluated with numerous neural networks trained on multiple benchmark datasets, demonstrating consistent gains across diverse corruption types and their severities (noise strength), with strong transferability across backbones, including CNNs and Transformers. Our approach highlights entropy regularisation as a scalable pathway to bridging the gap between clean accuracy and real-world robustness.", "tldr": "", "keywords": ["Corruption", "Convolution", "Transformer", "Robustness", "Explainability"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8bf43b23f29bb4962d57f963f148c2b1d225c5e0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles robustness to natural/common corruptions (noise, weather, pixelate, JPEG) and makes the empirical observation that, unlike UAPs that tend to make internal features low-entropy, natural corruptions often push later-layer activations into a high-entropy state, which hurts prediction stability. Based on this, the paper proposes Dem-HEC, a fine-tuning framework that (i) generates high-entropy samples via entropy-maximizing PGA inside an ℓ∞ ball, (ii) pulls them back to the clean representation with a contrastive loss, and (iii) stabilizes clean performance with KD from a frozen teacher plus CE on clean and high-entropy views. Experiments on CIFAR-10/100 and Tiny-ImageNet, across CNNs and ViTs, show noticeable gains on CIFAR-C/Tiny-ImageNet-C corruptions while keeping clean accuracy roughly intact on the larger dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "a) The motivation is well grounded. The paper first shows that many common corruptions push deep features into a high-entropy state (instead of the low-entropy pattern seen in UAP-oriented work), so the training objective is directly tied to an observed failure mode, not an assumed one.\n\nb) The contrastive term between clean and HE views makes the model learn a corruption-invariant embedding, rather than only becoming tolerant to a fixed set of corruptions.\n﻿\nc) Stability design is explicit. Adding KD / CE on clean keeps the model from drifting after HE training, addressing the usual clean–robust trade-off that many corruption/adversarial trainings suffer from."}, "weaknesses": {"value": "a) Limited comparison to strongest corruption baselines. The paper does not directly compare against well-known corruption-robust recipes such as AugMix, DeepAugment, or recent style/noise diversification methods.\n\nb) Robustness is tied to a single corruption mechanism. The approach assumes “corruption ⇒ high-entropy feature,” but some real-world corruptions (sensor banding, motion blur, structured artifacts) don’t necessarily raise entropy in the same way, so the learned invariance may be narrower than claimed. \n\nc) Ablation granularity is not fully shown. We don’t clearly see how much each part (HE-PGD, contrastive, KD) contributes in isolation on the same benchmark, which makes it harder to judge whether the main gain actually comes from the entropy-specific part or just from having stronger data diversity."}, "questions": {"value": "a) For ViT, where the baseline is already relatively corruption-tolerant, do you think the main benefit is from KD or from the HE view itself?\n﻿\nb) How sensitive is the method to the choice of ε and number of PGA steps. Is there a “cheap” setting that still improves CIFAR-C noticeably, or does it basically need the full inner loop to work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SIzEacqtFv", "forum": "CVqYCYpq75", "replyto": "CVqYCYpq75", "signatures": ["ICLR.cc/2026/Conference/Submission25238/Reviewer_UqCm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25238/Reviewer_UqCm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935578923, "cdate": 1761935578923, "tmdate": 1762943377261, "mdate": 1762943377261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Dem-HEC, an entropy-guided fine-tuning framework aimed at enhancing the robustness of deep neural networks against natural corruptions. Its core motivation, which centers on addressing the high-entropy feature space collapse caused by natural corruptions, is clear and aligns with the practical challenges of deploying deep neural networks in real-world scenarios. The framework design integrates high-entropy sample generation, symmetric InfoNCE contrastive loss, cross-entropy loss, and knowledge distillation, following a logical path derived from the stated motivation. Experimental evaluations cover multiple datasets (CIFAR10, CIFAR100, Tiny-ImageNet) and architectures (CNNs, Transformers), showing consistent improvements in corruption accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear Problem Definition with Strong Motivation: The paper accurately identifies the vulnerability of deep neural networks to natural corruptions and attributes it to high-entropy feature space collapse. It further distinguishes natural corruptions from universal adversarial perturbations (which induce low entropy), providing a solid theoretical foundation for the proposed method.\n2. Logical Framework Design: Dem-HEC directly addresses the identified high-entropy issue. High-entropy sample generation simulates the uncertainty caused by corruptions, contrastive loss aligns the semantics of clean and high-entropy features, knowledge distillation prevents catastrophic forgetting, and partial fine-tuning retains general features. Each component serves a clear purpose, forming a coherent technical system.\n3. Broad Experimental Coverage: The paper evaluates Dem-HEC on three benchmark datasets with different resolutions (low-resolution CIFAR series, high-resolution Tiny-ImageNet) and seven architectures (CNNs of varying sizes, Vision Transformer). This design verifies the method’s scalability across data scales and model types, with notable performance gains in high-severity corruption scenarios.\n4. Practical Utility: The framework adopts partial fine-tuning and uses pre-trained models as teachers, avoiding the high computational cost of training from scratch. It also provides implementation details such as code, training parameters, and hardware environment, laying a foundation for potential reproducibility."}, "weaknesses": {"value": "1. Insufficient Analysis of Clean Accuracy Drop on CIFAR Datasets: The paper notes a 2.5–4.4% drop in clean accuracy on CIFAR10/CIFAR100 but fails to clarify whether this drop is a common issue in the field (i.e., if existing robustness-enhancing methods also show similar drops on low-resolution datasets) or a limitation specific to Dem-HEC. It also lacks technical analysis of the causes behind the drop, such as whether high-entropy sample generation introduces noise that confuses the model on clean data or if the parameter settings of the contrastive loss over-constrain the representation of clean features.\n2. Missing Comparisons with Mainstream Baselines: The manuscript only compares Dem-HEC with the original pre-trained model (before fine-tuning) and does not include comparisons with state-of-the-art robustness-enhancing methods. In particular, it omits comparisons with data augmentation methods, which are widely used and effective for improving corruption robustness, as well as entropy-related or distillation-based robustness methods.\n3. Lack of Ablation Studies for Key Components and Hyperparameters: The manuscript’s experimental design is incomplete, with no ablation studies on core components or hyperparameters. There is no evaluation of the impact of removing individual loss components (clean cross-entropy, high-entropy cross-entropy, contrastive loss, knowledge distillation) on performance, making it impossible to quantify the contribution of each component. Additionally, there is no analysis of the sensitivity of hyperparameters.\n4. Inadequate Validation of High-Entropy Sample Generation: The manuscript claims that high-entropy samples simulate natural corruptions but provides no evidence that these generated samples are consistent with real natural corruptions in the feature space. There is no comparison of entropy distributions between generated high-entropy samples and real corrupted samples (e.g., CIFAR10-C samples) across different network layers, nor qualitative analysis (such as visualizations) to confirm that generated high-entropy samples retain semantic information and avoid becoming meaningless noise."}, "questions": {"value": "Your paper notes UAPs reduce hidden layer entropy (via feature dominance) and natural corruptions increase feature space entropy. Could you clarify: Is it because natural corruptions are non-directional (unintended real-world disturbances) that they disperse features and boost entropy—unlike directional UAPs that hijack decisions via dominant features to cut entropy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9Qc7Af1lxR", "forum": "CVqYCYpq75", "replyto": "CVqYCYpq75", "signatures": ["ICLR.cc/2026/Conference/Submission25238/Reviewer_KUNd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25238/Reviewer_KUNd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999270548, "cdate": 1761999270548, "tmdate": 1762943377072, "mdate": 1762943377072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the corruption robustness of pre-trained vision models. The authors first observe a correlation between input corruptions and the collapse of the model's internal feature space. Based on this observation, they propose an entropy-guided fine-tuning framework called Dem-HEC, which combines contrastive learning with knowledge distillation to enhance the corruption robustness of vision models while preserving accuracy on clean data. Experiments are conducted on several models (e.g., ResNet-20, ViT-L) and datasets (e.g., CIFAR-10, CIFAR-100). The results demonstrate that the proposed method can improve the performance of pre-trained models on corrupted data."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors observe the correlation between input corruptions and the collapse of the model's internal feature space.\n2. The proposed method is evaluated on multiple models and downstream datasets.\n3. The authors employ the knowledge distillation technique to preserve the original capabilities of pre-trained models."}, "weaknesses": {"value": "1. Fig. 1 is ambiguous and confusing. Why does the author use half of the space to illustrate the obvious fact that the \"repaired model can correctly classify corrupted samples\"? Additionally, why do the two loss functions point to the pre-trained model rather than the repaired model? The confusion in the figure seriously hinders readers' understanding of the proposed method.\n2. The datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet) for analysis and evaluation are too small. It remains unclear why the authors did not employ the full ImageNet-C dataset, which would provide a more rigorous and representative assessment. \n3. The evaluation relies on pre-trained models such as ResNet and RepVGG, which have limited image understanding capabilities and therefore may not adequately reflect the effectiveness of the proposed method when applied to modern architectures like Swin and ConvNeXt.\n4. The authors solely compared the proposed method with the original model, without considering existing approaches designed to improve model robustness against corruption. As a result, the evaluation can not adequately demonstrate the superiority of the proposed method.\n5. This paper lacks reproducibility. The authors do not specify the version of the pre-trained models. Their datasets and the strategies used for pre-training are unclear.\n6. This paper completely lacks ablation studies for the proposed method. For example, to what extent do contrastive learning and knowledge distillation individually contribute to the final performance? Additionally, how do the hyperparameter coefficients of different loss functions in Equation 12 affect model performance?\n7. As Fig. 4 shows, the proposed method results in significant performance degradation on clean data, limiting its practical applicability."}, "questions": {"value": "1. Does the effectiveness of the proposed method gradually diminish as the pre-trained model's capabilities improve?\n2. Compared to enhancing a pre-trained model's robustness to corrupted images, an alternative approach involves improving the quality of an input image through an auxiliary image processing model before feeding it into the pre-trained model. Could this strategy yield better generalization performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yIu4VHdUlA", "forum": "CVqYCYpq75", "replyto": "CVqYCYpq75", "signatures": ["ICLR.cc/2026/Conference/Submission25238/Reviewer_dMQr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25238/Reviewer_dMQr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762342674966, "cdate": 1762342674966, "tmdate": 1762943376877, "mdate": 1762943376877, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of corrupted image classification, and proposes a contrastive loss to stabilise the predictions of noisy images."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The analysis of corrupted layer features is interesting and insightful, and the contrastive loss is a good idea."}, "weaknesses": {"value": "The results show promising performance. However, there are no comparisons to any competing methods, which renders the results uninformative. There is extensive related works that could have been compared against.\n\nThe results only consider datasets with small images, which is just not sufficient anymore. The paper needs to include full ImageNet results, or similar."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4kTo30pX5c", "forum": "CVqYCYpq75", "replyto": "CVqYCYpq75", "signatures": ["ICLR.cc/2026/Conference/Submission25238/Reviewer_bSDc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25238/Reviewer_bSDc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762467533744, "cdate": 1762467533744, "tmdate": 1762943376683, "mdate": 1762943376683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}