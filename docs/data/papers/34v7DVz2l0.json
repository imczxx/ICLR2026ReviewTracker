{"id": "34v7DVz2l0", "number": 24655, "cdate": 1758359049886, "mdate": 1759896756768, "content": {"title": "FlowSearcher: Synthesizing Memory-Guided Agentic Workflows for Web Information Seeking", "abstract": "Web search is a cornerstone for deep research agents, enabling them to acquire and reason over knowledge beyond static corpora. Yet most existing systems follow rigid ReAct-style tool chains locked into fixed workflow structures, which hinders their ability to flexibly handle diverse query types and tool-use strategies. We introduce $\\textbf{FlowSearcher}$, a novel web search framework built on agentic workflow synthesis. FlowSearcher decomposes queries into sub-goals, each orchestrated by a tailored workflow graph that adapts the depth and order of tool use, giving the system structural flexibility to handle diverse sub-goals ranging from simple lookups and focused navigation to multi-hop information synthesis. Complementing this, a hierarchical memory distills past workflows into structured experience, providing reusable context that improves orchestration and guides tool use on new queries. This shift from reactive tool calls to memory-driven workflow design and execution marks a principled step toward deliberative web research.  Empirical results on GAIA, BrowseComp, and GPQA show consistent improvements over state-of-the-art baselines, validating the benefits of query-specific workflow synthesis and hierarchical memory integration.", "tldr": "FlowSearcher is the first to reframe web search as query-specific agentic workflow synthesis with structured planning and hierarchical memory.", "keywords": ["Large Language Model Reasoning", "Structured Planning", "Task Adaptability"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/832b251d98f739c5c696aaa809b3227e2d5754c7.pdf", "supplementary_material": "/attachment/3e5a4e93bdee08c1c9af70a7f4b9332a755e7456.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces FlowSearcher, a framework designed to overcome the structural rigidity and lack of experience reuse in conventional ReAct-style web agents. The core idea is \"agentic workflow synthesis,\" where the system decomposes complex queries into sub-goals and dynamically orchestrates a tailored, non-linear workflow graph for each.\nA key innovation is its hierarchical memory (at task, graph, and node levels), which distills past execution traces into structured experience. An \"instructor\" module then uses these insights to guide both high-level workflow orchestration (structural design) and low-level tool execution (behavioral refinement).\nExperiments on GAIA, BrowseComp, and GPQA show that FlowSearcher consistently outperforms strong agentic baselines. The authors argue this demonstrates that structural flexibility, achieved via memory-guided planning, is more decisive and cost-efficient than expensive RL fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Flexible Workflow Synthesis: The paper effectively moves beyond rigid, linear ReAct-style paradigms. Its core contribution—dynamically synthesizing tailored workflow graphs for each sub-goal—provides significant structural flexibility to handle diverse and complex queries.\n\n- Novel Hierarchical Memory Mechanism: The introduction of a three-level (task, graph, node) memory is a key strength. This allows the agent to learn from structural experience (i.e., how it solved a problem), not just content, enabling genuine experience reuse and adaptation.\n\n- Strong Empirical Results without Fine-Tuning: FlowSearcher achieves consistent, significant gains over strong baselines on difficult benchmarks (GAIA, BrowseComp). It does so purely through experience-driven planning, demonstrating a more cost-efficient and scalable alternative to expensive RL fine-tuning methods."}, "weaknesses": {"value": "1. Lack of Direct Efficiency Evaluation: The paper's primary argument for efficiency is one of cost-efficiency, asserting that its experience-driven planning approach avoids the high costs associated with RL fine-tuning (as seen in baselines like WebThinker-RL). While this is a valid point, the methodology (Section 2.1) also claims the system is designed to enhance \"efficiency and effectiveness\". However, the experimental results (Section 4) are entirely missing direct quantitative metrics to support this claim. There is no evaluation of:\n - End-to-end Latency: The total time taken to answer a query.\n - Token Cost: The total number of tokens consumed by the orchestrator, instructor, and executor modules.\n - Computational Steps: The total number of LLM inferences or tool calls required to reach a solution.\nWithout these metrics, it is impossible to assess whether the proposed hierarchical framework, with its added complexity of memory retrieval, instruction distillation, and graph synthesis, is actually more computationally efficient at runtime than a simpler, linear ReAct-style agent.\n\n2. Limited Novelty of Core Components: While the integration of the components is well-executed, the core ideas themselves: task decomposition, hierarchical memory, and DAG-based workflow execution, are not fundamentally new. The contribution appears to be more of a sophisticated engineering and system-building effort rather than the introduction of a novel algorithm or principle. The paper could be strengthened by more clearly positioning its contribution relative to existing works that use these individual concepts, justifying why this specific combination provides a breakthrough.\n\n3. Questionable Generalization and Over-reliance on Pre-defined Blocks: The system's entire capability is strictly bounded by its pre-defined library of \"building blocks.\" The ablation study (Table 2) demonstrates this clearly: when the set of available blocks is restricted, performance plummets. This raises two major concerns about generalization: (1) Task-level Generalization: It is unclear how FlowSearcher would perform on a fundamentally new task that requires a tool or workflow not representable by the existing blocks. (2) Block Synthesis: The framework does not include any mechanism for learning, discovering, or synthesizing new building blocks. This limits its long-term autonomy and adaptability.\n\n4. Vagueness of the \"Instructor\" Module: A critical component, the \"Instructor\" module (Section 2.3), is treated as a black box. This module is responsible for \"distilling\" raw execution traces from memory into \"concise insights\" that are then \"injected\" into the orchestrator and executor prompts. The paper fails to explain how this distillation process works. Is it another LLM call with a specific prompt? Is it a rule-based summarizer? This lack of detail obscures a key mechanism that bridges memory and action, making the work difficult to reproduce and its effectiveness hard to analyze.\n\n5. Unverified Effectiveness of Memory Retrieval: The entire \"memory-guided\" premise hinges on the ability of the retrieval mechanism (Section 2.2) to fetch relevant and high-quality experiences from memory. The paper states this is done via textual embedding similarity (a standard approach) but provides no analysis to validate its effectiveness. Key questions are left unanswered:\n- Retrieval Quality: What is the hit rate or precision@k of the memory retrieval?\n- Impact of Poor Retrieval: How does the system perform when retrieval fails or, worse, retrieves irrelevant or misleading (e.g., from a failed-but-structurally-similar task) exemplars? This could actively harm the orchestrator's planning.\nThe paper assumes the retrieved memory is always beneficial, which is hard to be true in practice."}, "questions": {"value": "Same as the weeknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5AlBhKdD8Z", "forum": "34v7DVz2l0", "replyto": "34v7DVz2l0", "signatures": ["ICLR.cc/2026/Conference/Submission24655/Reviewer_iEBS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24655/Reviewer_iEBS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24655/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761535073787, "cdate": 1761535073787, "tmdate": 1762943148855, "mdate": 1762943148855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "FlowSearcher introduces a novel framework for web information seeking that replaces rigid, linear tool-use patterns with dynamic, memory-guided workflow synthesis. It employs a hierarchical memory system to reuse past execution traces, enabling adaptive planning and execution for complex, multi-step queries. By learning from experience rather than relying on fine-tuning, FlowSearcher achieves strong performance across benchmarks like GAIA and BrowseComp."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- It precisely identifies the rigidity and memorylessness of prevailing ReAct-style agents as a core bottleneck for complex web-search tasks.\n- A three-level (task/graph/node) compositional memory enables fine-grained reuse of both successful and failed execution traces, going far beyond simple retrieval augmentation.\n- Consistent gains over strong baselines (WebThinker, WebDancer, Search-o1) on GAIA, BrowseComp and GPQA-Diamond demonstrate clear practical impact."}, "weaknesses": {"value": "- The memory-retrieval function uses a cosine similarity threshold that is fixed across all query types, it's not clear whether or not the  hyper-parameter works when transfer the framework to other domains.\n- Lack of cost and latency analysis as it's a prompt-based method and the context may be extremely long."}, "questions": {"value": "- How does FlowSearcher handle catastrophic memory accumulation or aliasing across unrelated tasks? Are there retrieval errors or long-term drift issues, and how are these handled? (For example, when the retrieved memory is wrong, or it needs a larger K in top-K retrieve algorithm)\n- Can this memory algorithm transform to general agentic tasks such as WebShop, WebArena?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "W09spbmtup", "forum": "34v7DVz2l0", "replyto": "34v7DVz2l0", "signatures": ["ICLR.cc/2026/Conference/Submission24655/Reviewer_kcjm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24655/Reviewer_kcjm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24655/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761823989027, "cdate": 1761823989027, "tmdate": 1762943148624, "mdate": 1762943148624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "It decomposes a complex query into subgoals and for each of them synthesizes a tailored workflow graph that determines how to search, browse, summarize, or verify information. A contribution here is its hierarchical memory, storing past workflows and tool executions at three levels and reuses them to guide future planning and execution. The performance of the system is significantly higher as compared to baselines considered."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- I like how the paper brings in a multi-level memory which guides the synthesis and execution of future trajectories by using experience from the past\n- Further the paper brings in multiple different research principles such as self-evolution (reusing past experiences), tool reasoning, query decomposition and hierarchical planning, memory etc into a single system that works quite well\n- the results are quite impressive, as well the ablations are good enough\n\n\nThat being said, I have some concerns, please see the weakness section"}, "weaknesses": {"value": "1. The paper has a lot going on, and an illustrative example would help the reader. For example a simple illustration showing the structure of the memory visually would help a lot. It was hard to parse what the authors are trying to say at multiple places\n\n2. I want to see cost comparison here, because the context is much more dense (more tokens) than simple react - without seeing the cost and latency of doing this operation, it is hard to justify such a complicated system\n\n3. Line 118 - the authors claim that this offers a cost-effective solution - but if this only talks about cost as compared to train an agent, that argument ignores the long-term cost of inferencing with a complex system which has really long prompts. The overall token consumption could be really high. \n\n4. I have some serious concerns in the writing of the paper. I feel that multiple places could have been phrased in much simpler words , and are unnecessarily verbose, making it very difficult for a reader. (lines 46-49 for example). I would urge the authors to rephrase things to address a larger audience, at the current shape, it is quite hard to follow"}, "questions": {"value": "Please see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3BoOTB576B", "forum": "34v7DVz2l0", "replyto": "34v7DVz2l0", "signatures": ["ICLR.cc/2026/Conference/Submission24655/Reviewer_kvwa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24655/Reviewer_kvwa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24655/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059396640, "cdate": 1762059396640, "tmdate": 1762943148381, "mdate": 1762943148381, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces FlowSearcher, a web search framework that performs dynamic workflow generation overcoming the limitations of step-wise workflows prevalent in React-style web search agents. Further, the approach retrieves structured workflows from previous episodes to enable to the model to leverage insights from past experiences. Experimental results show that the proposed memory-augmented workflow design approach outperforms vanilla and trained React-style agentic approaches on various Deep Research benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The methodology for generating structured workflows and storing historic episodes is well-designed and thoroughly explained.\n2) The approach to leverage past workflows by generating insights from these experiences is very interesting and can generalize to other agentic tasks, apart from Deep Research."}, "weaknesses": {"value": "1) The ablation analysis (mainly centered around workflow generation) does not show any controlled experiments demonstrating the benefit of incorporating memory by leveraging historic episodes, which has been claimed as one of the key contributions of the paper. There are a lot of questions here that need to be answered. For e.g. How many structured workflows from past episodes are useful? \n\n2) The paper doesn't discuss the cost/latency considerations of the proposed approach. Do the new workflows have more tool calls / steps than existing React-sytle approches? Also, how much cost/token usage does the memory creation + augmentation add to overall inference cost."}, "questions": {"value": "1) The authors store both successful and unsuccessful episodes in the memory. What doesthe performance looks like from using only successful vs only unsuccessful episodes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b71rYJbEtC", "forum": "34v7DVz2l0", "replyto": "34v7DVz2l0", "signatures": ["ICLR.cc/2026/Conference/Submission24655/Reviewer_oxdo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24655/Reviewer_oxdo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24655/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762159180537, "cdate": 1762159180537, "tmdate": 1762943148176, "mdate": 1762943148176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}