{"id": "zMAIP3FZ6g", "number": 9937, "cdate": 1758150710871, "mdate": 1763764677380, "content": {"title": "Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors", "abstract": "Learning disentangled representations, where semantic features are captured by independent variables, is dominated by the Variational Autoencoder (VAE) which uses the Kullback-Leibler (KL) penalty to learn a factorized representation in the latent space. In this paper, we provide direct visual and quantitative evidence that the VAE-based methods consistently fail to enforce this target distribution on the aggregate posterior, subsequently falling short of a mutually independent representation -- the training objective of unsupervised disentanglement. We quantify this failure and resulting entanglement using a stable, unsupervised Latent Predictability Score (LPS). To address this, we propose the Programmable Prior Framework: a non-parametric method built on the Maximum Mean Discrepancy (MMD). We verify our framework allows practitioners to explicitly sculpt the latent space, achieving (1) state-of-the-art unsupervised statistical independence (measured by LPS), (2) alignment to semantic features using an internal semi-supervised mechanism, and (3) aggregate posterior distribution shaping (validated through quantization-aware training), all without reconstruction trade-offs. Ultimately, the framework is one of a kind in that it provides a reliable foundational tool for balancing these three key training objectives, opening new avenues for model identifiability, interpretability, causal reasoning, and efficient compression.", "tldr": "Utilizing MMD loss to regularize the aggregate posterior of the latent space enables learning features with tailored and mutually independent distributions leading to improved disentangled representation.", "keywords": ["Disentanglement", "Non-Linear Independent Component Analysis (NICA)", "Maximum Mean Discrepancy (MMD)", "Autoencoder", "Representation Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b85f6e8bc181357ef48184ceb0cdd4f1a5a20548.pdf", "supplementary_material": "/attachment/e4f3dd634e58ca1f59cd10085fa0821828d4b2e0.zip"}, "replies": [{"content": {"summary": {"value": "This manuscript presents a method to improve learning of disentangled latent space. The key component is using MMD instead of KL for regularization. The paper also proposes a metric LPS, latent predictability score."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper tries to address an important and open challenge. \n2. The paper is written reasonably well, easy to follow."}, "weaknesses": {"value": "The manuscript has the following issues:\n\n1. It is well understood that MMD is better than KL in many applications. However the motivation in Fig 1, which empirically shows the proposed method learns better Gaussian latent space, is insufficient. Learning isotropic Gaussian latent space is closely related to learning disentangled latent space, but not the same. Especially for VAE and $\\beta-$VAE, since latent space is subject to rotation, a more rigorous study is needed.\n2. The paper is highly questionable in terms of execution. It's acceptable to propose a new metric, while propose a new method. But the new metric should be thoroughly examined before using it to champaign the proposed method. This manuscript failed to achieve this.\n3. Missing an important reference. The proposed LPS is very similar to a recent paper Yeats et al, especially the concept of using reconstruction loss $d-1$ dimensions. \n4. Lack of commonly used experimental benchmarks."}, "questions": {"value": "1. Using a newly defined metric, LPS, to demonstrated the superiority of a proposed method needs to be executed thoroughly. The authors need to first establish the fact that the new metric is better than the existing metrics (e.g., MIG, DCI), in terms of consistency and robustness, across major existing disentanglement methods and datasets. I would encourage the authors to conduct such a comprehensive study before using the same metric to champaign the new method proposed by the same set of authors.\n\n2. The details of LPS bear a close resemblance to a recent paper on disentanglement:\n\nYeats, E., Liu, F., Womble, D. and Li, H., 2022, October. Nashae: Disentangling representations through adversarial covariance minimization. In European Conference on Computer Vision (pp. 36-51). Cham: Springer Nature Switzerland.\n\nwhich is not included in the reference section. \n\n3. In LPS, \"a regression model is trained to predict $z_i$\", however there is no mentioning on how this model is trained, and more importantly, whether the quality of this model can be trusted to calculate LPS.  This is a much more nuanced usage of the regression model than in Yeats et al, where the purpose of the regression model is to **encourage** the disentanglement, not as a final yardstick to **evaluate the quality of disentanglement**. Again this brings up the question whether the LPS should be used to champaign the proposed method.\n\n4. The experimental results are weak. As in Higgins et al, CelebA is commonly accepted as one of the baseline benchmarks. There is also a small datasets with known generating factors in Yeats et al. These benchmarks should be included in the manuscript."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WbJZ4AKWDC", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_28ua"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_28ua"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789489580, "cdate": 1761789489580, "tmdate": 1762921387246, "mdate": 1762921387246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Summary of Changes and Edits (Phase 1 of discussion)"}, "comment": {"value": "In response to the reviewers' constructive feedback, we have revised the paper to clarify our theoretical positioning and demonstrate the practical utility of our method. Our core revision reframes the Programmable Prior Framework not just as an unsupervised  tool for disentanglement, but as a **Unified Representation Engineering Tool** that simultaneously addresses three distinct training objectives: (1) Statistical Independence, (2) Semantic Alignment, and (3) aggregate posterior distribution shaping (validated with training-aware quantization (QTA) experiments).\n\n* **Reframed Contribution: A Unified 3-in-1 Framework (Abstract, Intro, Section 3):**\n    * We have rewritten the introduction to frame disentanglement through the lens of **Nonlinear ICA (NICA)**, explicitly separating the goal into two distinct objectives: (1) unsupervised Independence and (2) semi-supervised Alignment.\n    * *Addressing e3ck & F6R6:* We clarify that our unsupervised MMD objective (Eq. 5) solves Part 1 (Independence), while our new semi-supervised mechanism solves Part 2 (Alignment). All within the same Programmable Prior Framework (no additional regularization term etc.).\n    * *Addressing 28ua & NjmS:* We clarified the theoretical distinction between our deterministic, regularized objective and the stochastic VAE ELBO.\n    * **[See Edits]:** We invite reviewers to see the new \"Contributions\" list (https://prnt.sc/QqN_Nx9hB0rA) and the revised Section 3.1 (\"Disentanglement and the Programmable Prior\", https://prnt.sc/DSJbHSL0GvSN) which details this 3-part unification.\n\n* **New Mechanism for Semantic Alignment (Section 3.1 and Section 4.4):**\n    * *Addressing e3ck & F6R6 (Practical utility/Alignment):*\n    * We introduced a semi-supervised mechanism that targets a joint distribution p(z, f(u)). This allows us to inject inductive bias (via pseudo-labels) to solve the NICA identifiability problem, ensuring alignment to semantically meaningful features while maintaining mutual independence.\n    * **New Result (Fig 5):** We demonstrate that alignment (DCI) improves drastically as we align more pseudo-labels, confirming our framework can bridge the gap between unsupervised independence and semi-supervised interpretability. In fact, we observe that the peak alignment occurs with less than all pseudo labels testifying to our framework's ability to find mutually independent features.\n    * **[See Edits]:** Please refer to the new **Section 3.1** (https://prnt.sc/DSJbHSL0GvSN) and **Section 4.4** (https://prnt.sc/SJdU5OLC6v_u) in the main text.\n\n* **New Application: Validating Distribution Shaping with Out-of-the-Box Quantization (Section 4.5):**\n    * *Strengthening Contribution (General Utility):*\n    * We added experiments showing that by sculpting the aggregate posterior to match a quantizer's domain (e.g., Uniform or Gaussian), our model achieves approximatively 2-7 dB better reconstruction at low bit-rates compared to baselines.\n    * **[See Edits]:** Please refer to the new **Section 4.5** (https://prnt.sc/W8PRiwQ56v9v) in the main text.\n\n* **New Benchmark: CelebA Dataset (Table 1 & Table 6):**\n    * *Addressing 28ua (Experimental weakness):*\n    * We added the large-scale CelebA dataset to our main results (Table 1), demonstrating that our SOTA independence results hold on complex, real-world faces (LPS 0.08 vs around 0.4 baseline).\n    * **[See Edits]:** New results are integrated into **Table 1** (Main Text) and detailed in **Table 6**.\n\n* **Theoretical Clarifications & Related Work (Section 2 & 4.1):**\n    * *Addressing 28ua (Yeats et al.) & NjmS (Lower Bound):*\n    * We explicitly credit and cite **Yeats et al. (NashAE)** in our contributions and Section 4.1. We clarify that our LPS is an unsupervised *metric* for mutual independence (addressing stability/robustness in Appendix C), whereas theirs is a *training objective*.\n    * We clarified in Section 3 that our objective (Eq. 5) is a standard regularized objective, distinct from the VAE's ELBO.\n\n* **Stability & Robustness Analysis (Appendix D):**\n    * *Addressing e3ck (Kernel tuning) & NjmS (Sensitivity):*\n    * We added a comprehensive ablation study verifying that our MMD regularizer is robust to latent dimensionality, training batch size, regularization coefficient, bandwidths, and kernel choice.\n    * **[See Edits]:** Please refer to the completely new **Appendix D** and **Figures 10, 11, 12**.\n\nWe trust that these comprehensive revisions fully address the reviewers' concerns, solidifying the novelty, utility, and consequence of our work for the field of representation learning. We respectfully invite the reviewers to re-evaluate our submission in light of these improvements.\n\nTo strictly adhere to the double-blind policy, we are currently unable to release our code, as it is protected under a license that would compromise our anonymity. However, we can confirm that we intend to release the code upon acceptance."}}, "id": "Weyfzbudng", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763764945690, "cdate": 1763764945690, "tmdate": 1763770028411, "mdate": 1763770028411, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a critique of the conventional Variational Autoencoder (VAE) framework for learning disentangled representations, arguing that its Kullback-Leibler (KL) divergence penalty is an unreliable mechanism for enforcing a factorized prior on the latent space. To address this, the authors introduce the Programmable Prior Framework, which replaces the KL divergence with a non-parametric Maximum Mean Discrepancy (MMD) regularizer. This MMD-based approach allows VAEs to sculpt the distribution of posterior for latent space which samples can be drawn from any target distribution, such as Gaussian, Uniform, or even Gaussian Mixture Models.\nThe authors further propose a novel unsupervised metric, the Latent Predictability Score (LPS), to quantify the mutual independence of latent features by measuring how well one latent dimension can be predicted from the others using a regression model. A lower score indicates greater independence."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies and provides compelling visual evidence (Figure 1) for a critical weakness in VAE-based disentanglement methods—the failure of the KL term to shape the aggregate posterior.\n2. The proposal of the Latent Predictability Score (LPS) is a significant contribution. Its unsupervised nature makes it applicable to real-world datasets where ground-truth factors are unavailable. Furthermore, the authors convincingly demonstrate its superior stability compared to the high variance of alignment-based metrics like DCI, which is a crucial point for reliable model evaluation."}, "weaknesses": {"value": "1. The paper's primary strength—the programmability of the prior—is also its main practical limitation. How to determine a proper target distribution for posterior remains unsolved. We can see the significant performance drop for choosing a wrong distribution from Table 12. The gaussian prior may not be the best one, but is robust for the most cases.\n2. Due to the non-linearity of deep  neural networks, a gaussian distribution can be mapped to arbitrary distributions. Therefore, the posterior distribution is not a emergent problem in disentanglement learning.\n3. From table 5, the proposed methods (AE-MMD) have lower MIG scores, low SAP, and so on. The methods did not exhibit strong disentangled representations on dSprites."}, "questions": {"value": "Why AE-MMD has a high Covariance Ratio but low number of MIG or SAP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bU08NnCXLE", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_F6R6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_F6R6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927714661, "cdate": 1761927714661, "tmdate": 1762921386632, "mdate": 1762921386632, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors tackle the limitations of KL-divergence-based VAE methods for learning disentangled representations. It introduces a flexible, architecture-agnostic framework using Maximum Mean Discrepancy to explicitly sculpt the latent space to match arbitrary priors, enabling what the authors term a programmable prior” The framework achieves state-of-the-art statistical independence of latent features without sacrificing reconstruction quality and provides a novel unsupervised metric, the Latent Predictability Score, to quantify disentanglement. Experiments across synthetic and real-world datasets demonstrate that MMD regularization can enforce both marginal and joint properties of latent distributions, allow alignment with interpretable features, and scale across varying latent dimensions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper makes a significant contribution to the field of disentangled representation learning by directly addressing the limitations of KL-divergence-based VAE regularization. The proposed MMD-based framework is architecture-agnostic and provides a flexible, sample-based mechanism for sculpting the latent space to match arbitrary priors. This programmability is a clear strength, allowing practitioners to inject task-specific inductive biases into the representation, which is demonstrated through strong empirical results on complex datasets like CIFAR-10 and TinyImageNet. The framework also achieves state-of-the-art statistical independence of latent features, as measured by the novel Latent Predictability Score, without sacrificing reconstruction quality—a common trade-off in prior work.\n\nAdditionally, the introduction of the unsupervised LPS metric is an important methodological advance. By evaluating mutual independence without relying on ground-truth factors, LPS provides a robust and widely applicable tool for quantifying disentanglement. The experiments convincingly demonstrate that MMD regularization consistently enforces true statistical independence across diverse datasets and latent dimensions, highlighting the scalability and generality of the approach. The visualization and latent space copying experiments further illustrate the precision and flexibility of the programmable prior framework."}, "weaknesses": {"value": "Despite its strengths, the framework has limitations in real-world applicability due to the challenge of selecting an optimal prior. While simple priors like factorized Gaussians are effective for achieving statistical independence, engineering priors that align with semantically meaningful features often requires domain knowledge that may not be available. This limits the ease of deploying the method in fully unsupervised scenarios where the underlying generative factors are unknown.\nAnother potential weakness lies in the computational complexity of MMD regularization in high-dimensional latent spaces. Although the paper demonstrates strong empirical performance, fitting complex priors may require careful kernel selection and tuning, which could hinder scalability or reproducibility for very large datasets. Furthermore, while the framework excels at matching marginal and aggregate distributions, it does not guarantee learning identical latent representations across models, which may limit its effectiveness in applications like knowledge distillation or causal representation learning"}, "questions": {"value": "How sensitive is the framework’s performance to the choice of kernel in the MMD regularizer, especially for high-dimensional latent spaces?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "w61DfooLMd", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_e3ck"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_e3ck"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971171661, "cdate": 1761971171661, "tmdate": 1762921386199, "mdate": 1762921386199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework for learning disentangled representations by replacing the traditional KL divergence penalty in VAEs with the Maximum Mean Discrepancy (MMD). The authors argue that the per-sample KL-divergence is an unreliable mechanism for enforcing the desired factorized structure on the aggregate posterior distribution. By leveraging MMD, the proposed Programmable Prior Framework is claimed to be architecture-agnostic and non-parametric, allowing practitioners to \"sculpt\" the latent space to match any target prior distribution. The method demonstrates disentanglement performance on datasets like CIFAR-10 and Tiny ImageNet without the reconstruction quality trade-off common in $\\beta$-VAE. Additionally, the authors introduce Latent Predictability Score (LPS), a unsupervised metric for quantifying mutual independence."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Clarity: Overall the paper is clearly written.\n\nNovel Unsupervised Metric: The Latent Predictability Score (LPS) offers a new tool for quantifying mutual independence without relying on ground-truth factor labels."}, "weaknesses": {"value": "Limited Theoretical Grounding & Novelty: The core technical idea is closely related to a lot of VAE variants e.g. WAE framework. The paper also need to formally justify the claim that $L_{ours}$ (Eq 5) is a lower bound on the log-likelihood.\n\nUnsupported Claim Regarding Prior Flexibility: The paper claims that the proposed method supports \"any prior\", but the standard VAE objective is also theoretically valid for any analytic prior. The paper's strength is that MMD is empirically and practically more effective at sculpting the aggregate posterior to a non-Gaussian geometry due to its non-parametric nature. This distinction must be made clearer.\n\nMMD Implementation Challenges: MMD is sensitive to the choice and tuning of the kernel function. A discussion or experiment on the robustness of the results to kernel choice would strengthen the practical utility.\n\nReproducibility: The provided code link is empty."}, "questions": {"value": "Can the authors provide a rigorous theoretical derivation or reference for the claim that the objective ${L}_{ours}$ (Eq 5) is a lower bound on the log-likelihood?\n\nMMD performance can be sensitive to the kernel function (e.g., Gaussian RBF) and its parameters. Could the authors include a robustness study?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VeXItUz24C", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_NjmS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_NjmS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762173283773, "cdate": 1762173283773, "tmdate": 1762921385814, "mdate": 1762921385814, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}