{"id": "zMAIP3FZ6g", "number": 9937, "cdate": 1758150710871, "mdate": 1759897684382, "content": {"title": "Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors", "abstract": "Learning disentangled representations, where distinct factors of variation are captured by independent latent variables, is a central goal in machine learning. The dominant approach has been the Variational Autoencoder (VAE) framework, which uses a Kullback-Leibler (KL) divergence penalty to encourage the latent space to match a factorized Gaussian prior. In this work, however, we provide direct evidence that this KL-based regularizer is an unreliable mechanism, consistently failing to enforce the target distribution on the aggregate posterior. We validate this and quantify the resulting entanglement using our novel, unsupervised Latent Predictability Score (LPS). To address this failure, we introduce the Programmable Prior Framework, a method built on the Maximum Mean Discrepancy (MMD). Our framework allows practitioners to explicitly sculpt the latent space, achieving state-of-the-art mutual independence on complex datasets like CIFAR-10 and Tiny ImageNet without the common reconstruction trade-off. Furthermore, we demonstrate how this programmability can be used to engineer sophisticated priors that improve alignment with semantically meaningful features. Ultimately, our work provides a foundational tool for representation engineering, opening new avenues for model identifiability and causal reasoning.", "tldr": "Utilizing MMD loss to regularize the aggregate posterior of the latent space enables learning features with tailored and mutually independent distributions leading to improved disentangled representation.", "keywords": ["Disentanglement", "Non-Linear Independent Component Analysis (NICA)", "Maximum Mean Discrepancy (MMD)", "Autoencoder", "Representation Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/36bd03da76867fa9287c37c7252b0da64d315359.pdf", "supplementary_material": "/attachment/e4f3dd634e58ca1f59cd10085fa0821828d4b2e0.zip"}, "replies": [{"content": {"summary": {"value": "This manuscript presents a method to improve learning of disentangled latent space. The key component is using MMD instead of KL for regularization. The paper also proposes a metric LPS, latent predictability score."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper tries to address an important and open challenge. \n2. The paper is written reasonably well, easy to follow."}, "weaknesses": {"value": "The manuscript has the following issues:\n\n1. It is well understood that MMD is better than KL in many applications. However the motivation in Fig 1, which empirically shows the proposed method learns better Gaussian latent space, is insufficient. Learning isotropic Gaussian latent space is closely related to learning disentangled latent space, but not the same. Especially for VAE and $\\beta-$VAE, since latent space is subject to rotation, a more rigorous study is needed.\n2. The paper is highly questionable in terms of execution. It's acceptable to propose a new metric, while propose a new method. But the new metric should be thoroughly examined before using it to champaign the proposed method. This manuscript failed to achieve this.\n3. Missing an important reference. The proposed LPS is very similar to a recent paper Yeats et al, especially the concept of using reconstruction loss $d-1$ dimensions. \n4. Lack of commonly used experimental benchmarks."}, "questions": {"value": "1. Using a newly defined metric, LPS, to demonstrated the superiority of a proposed method needs to be executed thoroughly. The authors need to first establish the fact that the new metric is better than the existing metrics (e.g., MIG, DCI), in terms of consistency and robustness, across major existing disentanglement methods and datasets. I would encourage the authors to conduct such a comprehensive study before using the same metric to champaign the new method proposed by the same set of authors.\n\n2. The details of LPS bear a close resemblance to a recent paper on disentanglement:\n\nYeats, E., Liu, F., Womble, D. and Li, H., 2022, October. Nashae: Disentangling representations through adversarial covariance minimization. In European Conference on Computer Vision (pp. 36-51). Cham: Springer Nature Switzerland.\n\nwhich is not included in the reference section. \n\n3. In LPS, \"a regression model is trained to predict $z_i$\", however there is no mentioning on how this model is trained, and more importantly, whether the quality of this model can be trusted to calculate LPS.  This is a much more nuanced usage of the regression model than in Yeats et al, where the purpose of the regression model is to **encourage** the disentanglement, not as a final yardstick to **evaluate the quality of disentanglement**. Again this brings up the question whether the LPS should be used to champaign the proposed method.\n\n4. The experimental results are weak. As in Higgins et al, CelebA is commonly accepted as one of the baseline benchmarks. There is also a small datasets with known generating factors in Yeats et al. These benchmarks should be included in the manuscript."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WbJZ4AKWDC", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_28ua"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_28ua"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789489580, "cdate": 1761789489580, "tmdate": 1762921387246, "mdate": 1762921387246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a critique of the conventional Variational Autoencoder (VAE) framework for learning disentangled representations, arguing that its Kullback-Leibler (KL) divergence penalty is an unreliable mechanism for enforcing a factorized prior on the latent space. To address this, the authors introduce the Programmable Prior Framework, which replaces the KL divergence with a non-parametric Maximum Mean Discrepancy (MMD) regularizer. This MMD-based approach allows VAEs to sculpt the distribution of posterior for latent space which samples can be drawn from any target distribution, such as Gaussian, Uniform, or even Gaussian Mixture Models.\nThe authors further propose a novel unsupervised metric, the Latent Predictability Score (LPS), to quantify the mutual independence of latent features by measuring how well one latent dimension can be predicted from the others using a regression model. A lower score indicates greater independence."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies and provides compelling visual evidence (Figure 1) for a critical weakness in VAE-based disentanglement methods—the failure of the KL term to shape the aggregate posterior.\n2. The proposal of the Latent Predictability Score (LPS) is a significant contribution. Its unsupervised nature makes it applicable to real-world datasets where ground-truth factors are unavailable. Furthermore, the authors convincingly demonstrate its superior stability compared to the high variance of alignment-based metrics like DCI, which is a crucial point for reliable model evaluation."}, "weaknesses": {"value": "1. The paper's primary strength—the programmability of the prior—is also its main practical limitation. How to determine a proper target distribution for posterior remains unsolved. We can see the significant performance drop for choosing a wrong distribution from Table 12. The gaussian prior may not be the best one, but is robust for the most cases.\n2. Due to the non-linearity of deep  neural networks, a gaussian distribution can be mapped to arbitrary distributions. Therefore, the posterior distribution is not a emergent problem in disentanglement learning.\n3. From table 5, the proposed methods (AE-MMD) have lower MIG scores, low SAP, and so on. The methods did not exhibit strong disentangled representations on dSprites."}, "questions": {"value": "Why AE-MMD has a high Covariance Ratio but low number of MIG or SAP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bU08NnCXLE", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_F6R6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_F6R6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927714661, "cdate": 1761927714661, "tmdate": 1762921386632, "mdate": 1762921386632, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors tackle the limitations of KL-divergence-based VAE methods for learning disentangled representations. It introduces a flexible, architecture-agnostic framework using Maximum Mean Discrepancy to explicitly sculpt the latent space to match arbitrary priors, enabling what the authors term a programmable prior” The framework achieves state-of-the-art statistical independence of latent features without sacrificing reconstruction quality and provides a novel unsupervised metric, the Latent Predictability Score, to quantify disentanglement. Experiments across synthetic and real-world datasets demonstrate that MMD regularization can enforce both marginal and joint properties of latent distributions, allow alignment with interpretable features, and scale across varying latent dimensions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper makes a significant contribution to the field of disentangled representation learning by directly addressing the limitations of KL-divergence-based VAE regularization. The proposed MMD-based framework is architecture-agnostic and provides a flexible, sample-based mechanism for sculpting the latent space to match arbitrary priors. This programmability is a clear strength, allowing practitioners to inject task-specific inductive biases into the representation, which is demonstrated through strong empirical results on complex datasets like CIFAR-10 and TinyImageNet. The framework also achieves state-of-the-art statistical independence of latent features, as measured by the novel Latent Predictability Score, without sacrificing reconstruction quality—a common trade-off in prior work.\n\nAdditionally, the introduction of the unsupervised LPS metric is an important methodological advance. By evaluating mutual independence without relying on ground-truth factors, LPS provides a robust and widely applicable tool for quantifying disentanglement. The experiments convincingly demonstrate that MMD regularization consistently enforces true statistical independence across diverse datasets and latent dimensions, highlighting the scalability and generality of the approach. The visualization and latent space copying experiments further illustrate the precision and flexibility of the programmable prior framework."}, "weaknesses": {"value": "Despite its strengths, the framework has limitations in real-world applicability due to the challenge of selecting an optimal prior. While simple priors like factorized Gaussians are effective for achieving statistical independence, engineering priors that align with semantically meaningful features often requires domain knowledge that may not be available. This limits the ease of deploying the method in fully unsupervised scenarios where the underlying generative factors are unknown.\nAnother potential weakness lies in the computational complexity of MMD regularization in high-dimensional latent spaces. Although the paper demonstrates strong empirical performance, fitting complex priors may require careful kernel selection and tuning, which could hinder scalability or reproducibility for very large datasets. Furthermore, while the framework excels at matching marginal and aggregate distributions, it does not guarantee learning identical latent representations across models, which may limit its effectiveness in applications like knowledge distillation or causal representation learning"}, "questions": {"value": "How sensitive is the framework’s performance to the choice of kernel in the MMD regularizer, especially for high-dimensional latent spaces?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "w61DfooLMd", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_e3ck"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_e3ck"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971171661, "cdate": 1761971171661, "tmdate": 1762921386199, "mdate": 1762921386199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework for learning disentangled representations by replacing the traditional KL divergence penalty in VAEs with the Maximum Mean Discrepancy (MMD). The authors argue that the per-sample KL-divergence is an unreliable mechanism for enforcing the desired factorized structure on the aggregate posterior distribution. By leveraging MMD, the proposed Programmable Prior Framework is claimed to be architecture-agnostic and non-parametric, allowing practitioners to \"sculpt\" the latent space to match any target prior distribution. The method demonstrates disentanglement performance on datasets like CIFAR-10 and Tiny ImageNet without the reconstruction quality trade-off common in $\\beta$-VAE. Additionally, the authors introduce Latent Predictability Score (LPS), a unsupervised metric for quantifying mutual independence."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Clarity: Overall the paper is clearly written.\n\nNovel Unsupervised Metric: The Latent Predictability Score (LPS) offers a new tool for quantifying mutual independence without relying on ground-truth factor labels."}, "weaknesses": {"value": "Limited Theoretical Grounding & Novelty: The core technical idea is closely related to a lot of VAE variants e.g. WAE framework. The paper also need to formally justify the claim that $L_{ours}$ (Eq 5) is a lower bound on the log-likelihood.\n\nUnsupported Claim Regarding Prior Flexibility: The paper claims that the proposed method supports \"any prior\", but the standard VAE objective is also theoretically valid for any analytic prior. The paper's strength is that MMD is empirically and practically more effective at sculpting the aggregate posterior to a non-Gaussian geometry due to its non-parametric nature. This distinction must be made clearer.\n\nMMD Implementation Challenges: MMD is sensitive to the choice and tuning of the kernel function. A discussion or experiment on the robustness of the results to kernel choice would strengthen the practical utility.\n\nReproducibility: The provided code link is empty."}, "questions": {"value": "Can the authors provide a rigorous theoretical derivation or reference for the claim that the objective ${L}_{ours}$ (Eq 5) is a lower bound on the log-likelihood?\n\nMMD performance can be sensitive to the kernel function (e.g., Gaussian RBF) and its parameters. Could the authors include a robustness study?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VeXItUz24C", "forum": "zMAIP3FZ6g", "replyto": "zMAIP3FZ6g", "signatures": ["ICLR.cc/2026/Conference/Submission9937/Reviewer_NjmS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9937/Reviewer_NjmS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762173283773, "cdate": 1762173283773, "tmdate": 1762921385814, "mdate": 1762921385814, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}