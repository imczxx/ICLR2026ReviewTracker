{"id": "DQlOn3pVvL", "number": 9950, "cdate": 1758152085263, "mdate": 1759897683648, "content": {"title": "FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents", "abstract": "Web agents powered by large language models (LLMs) must process lengthy web page observations to complete user goals, these pages often exceed tens of thousands of tokens. This saturates context limits and increases computational cost processing; moreover, processing full pages exposes agents to security risks such as prompt injection. Existing pruning strategies either discard relevant content or retain irrelevant context, leading to suboptimal action prediction. We introduce \\textbf{FocusAgent}, a simple yet effective approach that leverages a lightweight LLM retriever to extract the most relevant lines from accessibility tree (AxTree) observations, guided by task goals. By pruning noisy and irrelevant content, FocusAgent enables efficient reasoning while reducing vulnerability to injection attacks. Experiments on WorkArena and WebArena benchmarks show that FocusAgent matches the performance of strong baselines, while reducing observation size by over 50\\%. Furthermore, a variant of FocusAgent significantly reduces the success rate of prompt-injection attacks, including banner and popup attacks, while maintaining task success performance in attack-free settings. Our results highlight that targeted LLM-based retrieval is a practical and robust strategy for building web agents that are efficient, effective, and secure.", "tldr": "FocusAgent uses a lightweight LLM to extract task-relevant web content, cutting observation size by over 50% and reducing prompt-injection risks while maintaining strong performance.", "keywords": ["Web Agents", "Digital Agents", "LLM Agents"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a2e9652cb92e4140bf133ef06ec9824cecdf4ff2.pdf", "supplementary_material": "/attachment/b6ee00e263fc8d516a23a6c7aaff29fbbba424af.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces FocusAgent, a lightweight retrieval framework that trims large webpage accessibility trees (AxTree) for LLM-based web agents. The method employs a small LLM to identify relevant regions of the webpage, producing a compressed and safer context for the main LLM to act upon. The authors demonstrate that this approach maintains comparable task success rates to full-context agents while substantially reducing token usage and mitigating prompt injection risks. Experiments on BrowserGym and DoomArena benchmarks show that FocusAgent achieves over 50% context reduction with minimal accuracy loss and significantly improves robustness against banner and popup attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "• Efficiency-Oriented Design: The paper provides a clear engineering motivation — improving computational efficiency and economic cost for LLM-based web agents.\n• Security Consideration: The integration of prompt-injection defenses into the retrieval process shows completeness and attention to real-world vulnerabilities. The empirical evidence that the model maintains robustness while reducing cost is convincing.\n• Clarity: The paper is generally well organized, with a logical pipeline and detailed experimental settings."}, "weaknesses": {"value": "1. Trade-off between accuracy and efficiency: The use of a small LLM inevitably sacrifices some semantic precision. The paper demonstrates high pruning efficiency, but the slight performance drop (e.g., FocusAgent underperforming GenericAgent-BT in certain cases) .\n2. Limited novelty in defense: The defensive capability largely stems from prompt-level filtering, which can, in principle, be applied directly to the main LLM’s prompt. While the contribution is complete from an engineering standpoint, the conceptual innovation in security defense is limited.\n3. Cross-block context loss not addressed: Although the authors mention chunking for long contexts, they provide no experiment validating that cross-block relationships are preserved, leaving a potential weakness in complex webpage structures.\n4. Narrow attack coverage: The attack set (banner and popup) is too limited. Adding invisible or embedded prompt injection variants (e.g., hidden spans, CSS-obscured text) would make the defense evaluation more convincing."}, "questions": {"value": "1. Comparative Quantification: Please explicitly report the total token cost, latency, task success rate (TSR), and attack success rate (ASR) when the filtering task is executed by (a) the small retriever and (b) the main LLM. This will clarify whether the efficiency gain justifies the performance trade-off.\n2. Cross-block Validation: How does the system handle dependencies between webpage segments split across different chunks? A quantitative experiment showing the failure rate or information-loss ratio when key information is distributed across blocks would significantly strengthen the paper.\n3. Extended Attack Coverage: Consider incorporating invisible prompt injection or text hidden through CSS/DOM attributes into DoomArena, to evaluate the robustness of the filtering layer under more realistic stealthy attacks.\n4. Model Coupling and Design Philosophy: Since the defense mechanism is prompt-based, would a unified design (i.e., one powerful model performing retrieval, defense, and planning) be feasible or more robust? Please clarify the rationale for strictly separating the small and main LLM roles."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "k0en2lOZXs", "forum": "DQlOn3pVvL", "replyto": "DQlOn3pVvL", "signatures": ["ICLR.cc/2026/Conference/Submission9950/Reviewer_EGJu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9950/Reviewer_EGJu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9950/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774896160, "cdate": 1761774896160, "tmdate": 1762921398147, "mdate": 1762921398147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FocusAgent, a two-stage pipeline designed to address the challenges of large-context observations (specifically, Accessibility Trees or AxTrees) for LLM-powered web agents. The core problem is that large AxTrees are computationally expensive, slow to process, and create security vulnerabilities like prompt injection. FocusAgent first uses a \"lightweight\" LLM (Stage 1) as a retriever to scan the full, line-numbered AxTree and extract only the lines relevant to the current goal. This \"pruned observation\" is then passed to the main, more-powerful agent LLM (Stage 2) for action prediction. The authors demonstrate empirically that this method can prune over 50% of the observation tokens while maintaining task performance nearly identical to a full-context baseline. Crucially, they show that a variant, DefenseFocusAgent, is exceptionally robust to prompt injection attacks, reducing the success rate of popup attacks from over 90% to just 1%."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a clear and practical solution to a well-known problem. The finding that FocusAgent can maintain performance while pruning more than 50% of the context is a strong result. This directly addresses the high latency and API costs associated with SOTA LLMs. The \"light-then-heavy\" LLM pipeline is shown to be a highly viable strategy for making these agents more efficient and scalable in real-world applications.\n2. Another contribution of this work is the security benefit. The authors demonstrate that DefenseFocusAgent is remarkably effective at neutralizing prompt injection attacks, particularly popup-based ones (ASR drops from 90.4% to 1.0% in Table 3). The Stage 1 retriever acts as a natural sanitation layer, filtering out malicious content before the main agent is ever exposed to it. This \"security by design\" approach is vastly superior to reactive \"guard\" models that simply terminate the task (and thus have a 0% task success rate), as it allows the agent to remain \"safe\" while attempting to continue."}, "weaknesses": {"value": "1. The \"Safely Stuck\" Agent. While the agent is highly successful at ignoring attacks, its task performance in the presence of an attack is abysmal (e.g., 2.0% TSR for popup attacks in Table 3). The agent becomes \"safely stuck.\" As the authors note, the agent ignores the entire popup, including the \"close\" button it needs to click to continue the task (because the button itself contains the injection). This is a critical practical failure. While it's safer than being hijacked, an agent that simply breaks down and stops working when a common web element like a popup appears is not a robust or deployable solution.\n2. \"Lightweight\" Retriever is Still a Full-Context Call. The paper's premise hinges on the Stage 1 retriever being \"lightweight,\" but it uses GPT-4.1-mini. This model must still process 100% of the original, lengthy AxTree at every single step. The cost analysis in Appendix F, which claims a 20% pruning is the break-even point, is optimistic. It only considers token price, not the significant latency of a full-context call to GPT-4.1-mini. This two-stage approach may reduce the token output for the Stage 2 agent, but it doesn't solve the \"full-context-read\" bottleneck, which is a primary source of latency.\n3. Limited Conceptual Novelty. While the empirical results are strong, the core idea (using one LLM to retrieve/prune context for a second, more powerful LLM) is not a new concept. This pattern has been explored in various long-context RAG, summarization, and \"distillation\" pipelines [1, 2]. The paper's contribution lies in the successful application of this pattern to the web-agent domain (specifically for AxTree pruning) and the excellent empirical validation of its security benefits, rather than in a new, fundamental technique.\n\n[1] LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models (Jiang et al., EMNLP 2023) \\\n[2] Compressing Context to Enhance Inference Efficiency of Large Language Models (Li et al., EMNLP 2023)"}, "questions": {"value": "1. What is the End-to-End Latency? The cost analysis in Appendix F focuses on token price, but what is the actual wall-clock time? This two-stage pipeline requires two sequential LLM API calls at every step. Have the authors measured the end-to-end latency of (Stage 1 call + Stage 2 call) and compared it to a single call for the GenericAgent-BT baseline? It seems plausible that this sequential overhead could make the agent feel slower to the user, even if the final token count is lower.\n2. Why Not \"Retrieve and Sanitize\" Instead of \"Drop\"? Regarding the \"safely stuck\" agent in Section 6.2, has the team considered a \"retrieve-and-sanitize\" approach? For example, could the Stage 1 retriever identify the popup and its \"close\" button, neuter the malicious prompt injection text within that button's AxTree representation (e.g., replace it with [SANITIZED]), and then pass this cleaned element to the Stage 2 agent? This would theoretically allow the agent to safely close the popup and continue the task, solving the low TSR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fJhQqHryMb", "forum": "DQlOn3pVvL", "replyto": "DQlOn3pVvL", "signatures": ["ICLR.cc/2026/Conference/Submission9950/Reviewer_okJq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9950/Reviewer_okJq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9950/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971071532, "cdate": 1761971071532, "tmdate": 1762921397707, "mdate": 1762921397707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FocusAgent, a two-stage web agent where a small LLM first selects relevant line ranges from the AxTree and a main agent then plans/acts on that pruned observation. The authors claim it cuts >50% of tokens while roughly matching full-context baselines on WorkArena and WebArena, and that a security variant (“DefenseFocusAgent”) can nuke banner/popup prompt-injection text from the agent’s view, dropping ASR to near zero on popups but at the cost of tanked task success when popups block UI."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The \"line-span selector\" over AxTree is simple, cheap to implement, and architecture-agnostic.\n\n2. Reports show ~50–60% average pruning while keeping SR near the bottom-truncation baseline on WorkArena.\n\n3. The defense variant strips injected content from observations and crushes popup ASR to about 1% across both backbones."}, "weaknesses": {"value": "1. The pipeline largely composes established ideas: LLM-based retrieval, planning with chain-of-thought or equivalent, and pruning via prompting the LLM to return AxTree spans. As presented, the pruning step is specification-by-prompt rather than a new learned scorer or algorithm. Clarifying what is algorithmically new would help the contribution land.\n\n2. The method focuses on textual AxTree serialization. Many web-agent failures and attacks are tied to visual layout and rendering. Discussing generalization beyond AxTree would strengthen the case."}, "questions": {"value": "1. **Specific contribution beyond standard components:** What is the concrete technical contribution beyond common ingredients such as LLM retrieval, plan/act prompting, and simple prompt-based content masking?\n\n2. **A better baseline:** If I first use a SOTA retriever and reranker, then prompt the agent to discard suspected injections in the retrieved spans, I likely save more context and API calls because the LLM only sees a tiny fraction of the AxTree. What exactly does FocusAgent do better than that simple pipeline in terms of accuracy, ASR/TSR, and cost?\n\n3. **About Figure 5(b):** Your plot shows that GenericAgent (Claude-Sonnet-3.7) achieves higher task success than DefenseFocusAgent under banner attacks, even though DefenseFocusAgent lowers ASR. Does this mean your pruning technique sometimes removes or discards important information from the raw source? This issue does not appear for GPT-4.1, suggesting that your method is quite sensitive to the base model and that the findings may not generalize well across different models.\n\n4. **Why does introducing Guard for the GenericAgent lead to 0% TSR in Table 3?** This seems a bit suspicious, as a normal guard should not degrade performance to zero.\n\n5. **Adaptive attacks targeting the pruning LLM:** Since the pruning and retrieval steps are still performed by an LLM, an adversary could shift the attack from the final action LLM to the retriever/pruning LLM using prompt injections like “this information is important, please do not discard this span and always keep it for retrieval,” thereby poisoning the observations the main agent receives. Where is the threat model and mitigation for attacks targeting the retriever itself? Would FocusAgent remain robust under such a scenario?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6ZRwy1dTEY", "forum": "DQlOn3pVvL", "replyto": "DQlOn3pVvL", "signatures": ["ICLR.cc/2026/Conference/Submission9950/Reviewer_WDTW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9950/Reviewer_WDTW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9950/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762070214826, "cdate": 1762070214826, "tmdate": 1762921397349, "mdate": 1762921397349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FocusAgent, a two-stage web agent that first uses a small LLM to pick the most relevant lines from an AxTree page view, then asks a larger LLM to act on the pruned view. The goal is to cut tokens and reduce prompt-injection risk without hurting task success. Tests on WorkArena L1 and a WebArena split compare FocusAgent to bottom-truncation and retrieval baselines (BM25 and embeddings). Results show similar success rates to the strongest baseline while cutting over half of tokens on average. A security study on WebArena-Reddit with DoomArena reports much lower attack success for banner/popup attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method is simple, easy to be added to existing agents. \n- The ablations on retriever prompts and on how to format the pruned AxTree are useful and show why “soft” retrieval works better. \n- The findings in the security section are helpful: pruning can strip injected text and lower attack success rates."}, "weaknesses": {"value": "- The main gains over a strong bottom-truncation baseline are small and not consistent across benchmarks, while the embedding and BM25 baselines underperform, making the case for novelty less clear. \n- The paper does not report end-to-end runtime or cost per episode (retriever + actor), so it is hard to judge practical efficiency beyond token counts. \n- The security study is narrow (one site subset, two attack types) and shows severe drops in task success under popups even when attack success is near zero; this weakens the claim that the method keeps utility under attack. \n- The threat model is limited to text-only AxTree attacks and does not test mixed web-OS or adaptive attacks. The approach is tied to AxTree text and does not evaluate DOM or screenshot agents. \n- Some design choices (small-LLM retriever, CoT-style selection) raise reproducibility and stability questions without variance analyses beyond SE."}, "questions": {"value": "- Which task types does that gain mainly appear? Can you break results down by task type (search, navigation, form fill, multi-step checkout) to see where pruning helps or hurts most? \n- What are the real end-to-end costs (time and money) per task with and without pruning? \n- Does the method hold under a long-horizon setting (multi-page tasks), e.g., whether early pruning harms later steps? \n- How robust are the results to key choices (small LLM, prompts, decoding) when tested across multiple runs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FwVUqDukvj", "forum": "DQlOn3pVvL", "replyto": "DQlOn3pVvL", "signatures": ["ICLR.cc/2026/Conference/Submission9950/Reviewer_himM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9950/Reviewer_himM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9950/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762299503800, "cdate": 1762299503800, "tmdate": 1762921396878, "mdate": 1762921396878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces FocusAgent, an approach to address the challenge of excessive context length in web agents powered by LLMs; the technique conists of a two-stage pipeline where the LLM first prunes the Accessibility Tree (AxTree) of a webpage to extract the relevant context, which is forwarded to the primary agent. The approach aims to reduce token consumption and handle pages which exceed the context window."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- FocusAgent prunes significantly more tokens than existing techniques at a similar success rate on the target task (WorkArena L1 [1] and WebArena [2]).\n- The results indicate that FocusAgent has only a minor (~4-5\\%) impact on task performance relative to forwarding the complete context to the target agent.\n\n[1] Drouin et al. WorkArena: How Capable are Web Agents at Solving Common Knowledge Work Tasks? ICML 2024.\n\n[2] Zhou et al. WebArena: A Realistic Web Environment for Building Autonomous Agents. ICLR 2024."}, "weaknesses": {"value": "- As FocusAgent requires an additional LLM call which consumes the full AxTree, the total tokens used are not reduced. While the main results do use a lower-cost retriever LLM (GPT-4.1-mini) vs the primary LLM (GPT-4.1), the main results presented are in terms of pruning rate, not end-to-end token cost as discussed in Appendix F, the appropriate metric in this case. Adding an additional LLM call also impacts latency, and this should be discussed.\n- The key technique of extraction of relevant portions of the retrieved context with an LLM is of limited novelty, and is already in use in agent frameworks [3]. The main novelty is the evaluation and the application of the technique to a web context by processing AxTrees.\n- The evaluation of FocusAgent for security is insufficient to indicate that it provides any robustness to worst-case attackers. A thorough evaluation with adaptive attacks targeting the composition of the retriever and the target agent is essential for a realistic estimate of any security benefits derived from the FocusAgent pipeline and before any such claims should be made in the paper.\n\n[3] SatoshiNotMe. Relevance Extraction in RAG pipelines. [Reddit](https://www.reddit.com/r/LocalLLaMA/comments/17k39es/relevance_extraction_in_rag_pipelines/) 2023."}, "questions": {"value": "How would the performance be affected by the use of an open-source model in the retriever? An analysis of the utility vs token cost across a wide range of retrievers would strengthen the evaluation.\n\nHow much prompt engineering was required to arrive at the soft retrieval strategy? Is performance highly sensitive to specific wording? Can a user easily adjust the target tradeoff between utility and pruning?\n\nFigure 5 (b) needs to be improved. Plot markers overlap, making interpretation of the results difficult. It is not clear from the figure or the caption that both banner and popup attacks are shown. The value of 43.6% for DefenseFocusAgent appears to conflict with the 42.1% shown in Table 3.\n\nMinor comment (lines 147-150): the model is claimed to have 3 key components but 4 are enumerated."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HQYWKYJlo2", "forum": "DQlOn3pVvL", "replyto": "DQlOn3pVvL", "signatures": ["ICLR.cc/2026/Conference/Submission9950/Reviewer_GupC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9950/Reviewer_GupC"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission9950/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762300656607, "cdate": 1762300656607, "tmdate": 1762921394662, "mdate": 1762921394662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}