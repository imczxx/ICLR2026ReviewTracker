{"id": "fP7XF1KdYf", "number": 2037, "cdate": 1756979860368, "mdate": 1759898172800, "content": {"title": "IntSR: An Integrated Generative Framework for Search and Recommendation", "abstract": "Generative recommendation has emerged as a promising paradigm, demonstrating remarkable results in both academic benchmarks and industrial applications. However, existing systems predominantly focus on unifying retrieval and ranking while neglecting the integration of search and recommendation (S&R) tasks. What makes search and recommendation different is how queries are formed: search uses explicit user requests, while recommendation relies on implicit user interests. As for retrieval versus ranking, the distinction comes down to whether the queries are the target items themselves. Recognizing the query as central element, we propose IntSR, an integrated generative framework for S\\&R. IntSR integrates these disparate tasks using distinct query modalities. It also addresses the increased computational complexity associated with integrated S&R behaviors and the erroneous pattern learning introduced by a dynamically changing corpus. IntSR has been successfully deployed across various scenarios on a large internet platform serving hundreds of millions of users, leading to substantial improvements: +9.34% GMV, +2.76% CTR, and +7.04% ACC in three distinct scenarios.", "tldr": "", "keywords": ["Generative Framework", "Unification of Recommendation and Search", "Time-Aware Negative Sampling"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e7e1780e1633e837ba063991d202301c29962d97.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes IntSR, an integrated generative framework for search and recommendation (S&R) that unifies both tasks and their sub-problems (retrieval and ranking). The model is evaluated on two public datasets (Amazon, KuaiSAR) and an industrial dataset. However this evaluation contains several flaws."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* The paper is well written and easy to follow.\n* The figures help to understand the methodology described.\n* Good ablation studies."}, "weaknesses": {"value": "* The mathematical formulation is unclear because some symbolic notations are not introduced in the main body of the article, but in the appendix. The main body of the article should be self-contained.\n* Some related works are missing eg : \n   * https://arxiv.org/pdf/2504.06714\n   * https://arxiv.org/pdf/2504.05730 \n* The evaluation section is unclear: the reported results appear very similar to those in Table 3 of this paper. While the authors share their own code, they do not provide access to the code of their competitors, which raises the concern that the results might have been copied from that table, with their own model simply added, rather than rerunning all baselines under the same conditions.\n* No statistical tests are present. \n* Only two datasets are used.\n* The evaluation has been carried out with 99 negatives and one positive, despite the paper “Widespread Flaws in Offline Evaluation of Recommender Systems” shows that it is better to use all the items as negatives."}, "questions": {"value": "1. Could you please add another dataset and the statistical tests?\n2. Could you please add the evaluation using all the items as negatives?\n3. Could you clarify how the model addresses the cold start problem?\n4.To convert natural language user search queries into embedding, why did you choose exactly the Qwen 0.6B model for the without trying any other?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K86qCqjAJH", "forum": "fP7XF1KdYf", "replyto": "fP7XF1KdYf", "signatures": ["ICLR.cc/2026/Conference/Submission2037/Reviewer_pYA5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2037/Reviewer_pYA5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762085535551, "cdate": 1762085535551, "tmdate": 1762916002545, "mdate": 1762916002545, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "his paper proposes IntSR, an integrated generative framework that unifies search and recommendation (S&R) tasks along with their retrieval and ranking sub-tasks. The key innovation is treating queries as the central distinguishing element - using explicit natural language queries for search and implicit behavioral patterns for recommendation. The framework introduces a Query-Driven Block (QDB) with customized masking to reduce computational complexity, and addresses temporal vocabulary misalignment through a candidate alignment strategy. The model has been deployed at scale, serving hundreds of millions of users with reported improvements of +9.34% GMV, +2.76% CTR, and +7.04% ACC across three scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "--Practical Impact: The successful deployment at scale with significant business metrics improvement demonstrates real-world value beyond academic contributions.\n\n\n--Comprehensive Framework: The paper addresses multiple aspects - unification, efficiency, and temporal dynamics - in a coherent framework rather than treating them as isolated problems.\n\n\n--Temporal Alignment Innovation: The identification and solution of temporal vocabulary misalignment is an important contribution that has been overlooked in prior work. Table 3 convincingly shows consistent improvements across all negative sampling strategies.\n\n\n--Thorough Experimental Validation: The paper includes experiments on public datasets, proprietary data, ablation studies, and online A/B tests, providing multiple angles of validation.\n\n\n--Computational Efficiency: The detailed complexity analysis and optimization in Appendix D shows careful engineering consideration for practical deployment."}, "weaknesses": {"value": "--Limited Baseline Comparisons: For the temporal alignment experiments (Table 3), only basic negative sampling strategies are compared. No comparison with recent advanced sampling methods or other temporal-aware approaches.\n\n\n--Unclear Architectural Choices:\n\n\n  * Why is DSFNet necessary when QDB already handles multi-scenario aspects through query types?\n  * The relationship between the 3-layer QDB and DSFNet modules is not well justified\n  * The choice of Qwen3-0.6B for query encoding seems arbitrary\n\n--Dataset Limitations:\n\n* KuaiSAR requires separate training for recommendation and search due to sparse search behaviors, suggesting the unified approach may not work well when data is imbalanced\n* Amazon dataset uses synthetic search queries, limiting the validity of search task evaluation\n* Industrial dataset details are too vague for reproducibility"}, "questions": {"value": "-- Query Generation Strategy: In Section 3.2, you mention using probability β to populate non-search Q positions. How sensitive is the model to this hyperparameter? What values were used in experiments?\n\n\n-- Temporal Alignment Overhead: Does maintaining temporal availability information (It) for all items introduce significant storage/computation overhead in production? How do you handle items with complex availability patterns?\n\n\n-- Cold Start Performance: How does IntSR perform for new users or items with limited interaction history? The unified approach might exacerbate cold start issues.\n\n\n-- Search Query Quality: Table 4 shows a dramatic drop when removing search queries for the search task (HR@1: 0.5678→0.4023). Does this suggest the model is overly dependent on explicit queries rather than learning implicit patterns?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o7WHgIrfxn", "forum": "fP7XF1KdYf", "replyto": "fP7XF1KdYf", "signatures": ["ICLR.cc/2026/Conference/Submission2037/Reviewer_spp9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2037/Reviewer_spp9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762155407727, "cdate": 1762155407727, "tmdate": 1762916002284, "mdate": 1762916002284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents IntSR, a unified generative framework aiming to jointly handle both search and recommendation tasks, as well as their retrieval and ranking subcomponents. The core idea is to model user-item interactions—both search and recommendation—within an autoregressive generative model, distinguishing the task modality through query representations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. IntSR achieves excellent results in both offline experiments and online A/B tests.\n\n2. The authors conducted comprehensive ablation studies that demonstrate the effectiveness of each design of IntSR.\n\n3. The paper is well-written, and the figures are clear and illustrative."}, "weaknesses": {"value": "1. No direct efficiency experiments. The paper claims computational speed-up but only provides theoretical complexity analysis. It would be much stronger to include a table comparing actual inference latency throughput against baselines.\n2. What about scaling? The introduction mentions scalability as a key motivation. How does IntSR's performance scale with model size or data volume? Any experiments or insights on its scaling behavior would be great.\n2. Missing discussion of recent work. There's no comparison or discussion with relevant concurrent work, such as [1]. Briefly discussing this would better position the paper.\n\n[1] Shi, Teng, et al. \"Unified Generative Search and Recommendation.\""}, "questions": {"value": "Given the impressive online performance and successful deployment of IntSR, I'm particularly interested in which scenarios the advantages of a unified search-and-recommendation approach are most pronounced？"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O4nSvhFL7N", "forum": "fP7XF1KdYf", "replyto": "fP7XF1KdYf", "signatures": ["ICLR.cc/2026/Conference/Submission2037/Reviewer_JC9a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2037/Reviewer_JC9a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762527459494, "cdate": 1762527459494, "tmdate": 1762916001109, "mdate": 1762916001109, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}