{"id": "KznJt9Fhjc", "number": 6952, "cdate": 1758003231671, "mdate": 1759897882085, "content": {"title": "Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "abstract": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn, multi-step interactions, often involving complex function calls and dynamic user-agent exchanges. Existing simulation-based data generation methods for such scenarios rely heavily on costly autoregressive interactions between multiple LLM agents, thereby limiting real-world performance of agentic tasks. In this paper, we propose a novel Non-Autoregressive Iterative Generation (NAIG) framework for constructing high-quality multi-turn agentic dialogues. NAIG generates full conversational trajectories through three stages: coarse-grained initialization, iterative refinement, and offline verification. The initialization phase builds a structurally complete yet semantically coarse dialogue skeleton; the iterative refinement phase introduces realistic complexities and continued refinement via mask-and-fill operations; and the offline verification phase ensures correctness and coherence via rule- and model-based checks. Experiments demonstrate that NAIG enables efficient, effective and generalizable agentic data generation, offering a new paradigm for high-quality data construction in tool-augmented LLM scenarios.", "tldr": "", "keywords": ["Agentic Data Synthesis", "Non-Autoregressive Generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6f61ec11a1b408a3200a9f3700f12b35d961a457.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a non-autoregressive iterative generative framework (NAIG) for constructing high-quality multi-agent dialogues. NAIG consists of three main phases: coarse-grained dialogue structure initialization, iterative refinement, and offline verification. NAIG first globally initializes a fully structured multi-agent dialogue. Iterative refinement uses masking and padding to continuously refine dialogue details. The offline verification phase verifies the correctness and consistency of the dialogue. Experiments show that, using the same base model, training on data generated by NAIG achieves better accuracy and efficiency than traditional multi-agent simulations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This work makes the following contributions to synthesizing complex agent task data:  \n(1) It proposes a framework for generating complex agent task data, focusing on refining conversation details while maintaining the overall task through masking and padding.  \n(2) It splits initialization and refinement into two phases, allowing for the definition and selection of task complexity to be completed at a low cost in the initialization phase, while controlling complexity and budget by the number of iterations in the iterative refinement phase.  \n(3) The NAIG framework offers a straightforward approach that addresses the following motivations: (a) When using autoregressive methods, trajectories often exhibit undesirable shifts (especially in long-range scenarios). Employing the mask-fill method allows LLMs to perceive the full context of trajectories, mitigating inconsistencies arising from modifications to some extent. (b) During initial trajectory generation, NAIG enables explicit control over length and complexity, thereby facilitating more controllable data design."}, "weaknesses": {"value": "(1) The article mentions (Table 4) that NAIG is less expensive than traditional MAS. I understand this refers to the number of API calls. Although the number of API calls is less than MAS, since operations such as iterative optimization may consume a lot of tokens, is the total token cost still lower than MAS?\n(2) In Section 4.3, the authors mention that there is a significant performance gap between GPT-4o-mini and GPT-4o. This highlights that the quality of initial generation is still crucial. I don't understand why only the quality of initial generation is mentioned here.\n(3) I would like to know the specific steps of the MAS experiment in the article. How is it different from NIAG, which only uses the initialization phase and offline verification phase?"}, "questions": {"value": "(1) Is there comparative data on the total token consumption for NAIG and MAS?  \n(2) I would like to know the specific steps of the MAS experiment in the article. How is it different from NIAG, which only uses the initialization phase and offline verification phase?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nNHvt2RbrN", "forum": "KznJt9Fhjc", "replyto": "KznJt9Fhjc", "signatures": ["ICLR.cc/2026/Conference/Submission6952/Reviewer_JVVr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6952/Reviewer_JVVr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761564311126, "cdate": 1761564311126, "tmdate": 1762919179206, "mdate": 1762919179206, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Non-Autoregressive Iterative Generation for Agentic Multi-Turn Interaction. The authors address the need for high-quality multi-turn, multi-step dialogues involving function calls and user-agent interaction in tool-augmented LLM settings. They argue that existing multi-agent simulation approaches rely on costly autoregressive generation across multiple agents. To improve efficiency and control, they introduce a three-stage data construction framework: coarse-grained initialization, iterative refinement, and offline verification. The initialization produces a structurally complete but semantically rough dialogue skeleton; the refinement injects complexity and uses mask-and-fill operations to improve the trajectories; the verification filters for correctness and coherence via rule-based and model-based checks. Experiments on multiple benchmarks show that models fine-tuned on data generated by their framework outperform MAS-generated data in downstream function-calling tasks while reducing API-call cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper addresses an important problem: generating realistic, tool-augmented agentic dialogues for training LLMs with function-calling and multi-turn behaviour.\n- The framework is clearly presented. The three-stage design offers a practical pipeline that balances structure, refinement and quality control.\n- The experimental evaluation is reasonably broad. Multiple benchmarks, different model backbones, cost vs quality trade-off are all considered.\n- The authors attempt to quantify cost savings (via API-call count) and show downstream performance improvements, which strengthens the applied relevance of the work."}, "weaknesses": {"value": "1. Lack of human evaluation and direct quantitative assessment of the generated data itself. The paper focuses on downstream model performance improvements, but fails to report metrics such as diversity (Distinct-n), structural repetition (how many dialogue skeleton templates were reused), naturalness/human preference, or other data-intrinsic quality measures.\n2. Cost evaluation metric is limited. While the paper reports that API calls drop from ≈ 275k (MAS) to ≈ 188k (their method), there is no breakdown of token consumption, compute hours, or monetary cost. Thus the claim of “cost reduction” lacks transparency and might not reflect real-world resource savings.\n3. Failure case analysis could be provided. The paper does not include a detailed look at failed/generated invalid samples: which trajectories failed verification, what error modes occurred (parameter mismatch, tool-call misordering, semantic incoherence), or how many were discarded. Without this, it is hard to judge the robustness or failure modes of the proposed pipeline.\n4. The initialization stage lacks transparency and poses risks of structural homogenization or unrealistic data distribution. The “coarse-grained initialization” phase is described at a high level but lacks detail on how skeletons are generated, how varied they are, whether templates are reused, or whether sub-tasks are meaningfully correlated as in real distributions. This raises concerns that many samples might share the same skeleton, reducing diversity, or that sub-tasks may be arbitrarily concatenated in ways rare in real user-agent dialogues.\n5. The novelty is somewhat incremental. The combination of non-autoregressive generation + iterative mask-and-fill + simulation for data generation is practically useful, but from a model-research perspective, it is more of a pipeline engineering effort than a conceptual leap in generation modelling."}, "questions": {"value": "1. Can you provide quantitative metrics on the generated dataset itself: e.g., number of unique skeleton templates used, duplication rate of structures, Distinct-n diversity scores, or human preference judgments?\n2. Could you report token counts, compute hours and/or monetary cost estimates for the data generation process (initialization + refinement + verification) to strengthen the cost-reduction claim?\n3. Do you have statistics on how many samples were discarded during offline verification, and what the major categories of failure were? Could you share sample failure cases?\n4. How do you ensure that sub-task sequences in each dialogue reflect realistic correlations rather than random concatenations? Did you compare your generated task‐structure distribution with that of real agent dialogues?\n5. Are there template or skeleton reuse effects in the initialization phase? How many skeleton variants were used, and how did you guard against structure homogenization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ylEYam7tmX", "forum": "KznJt9Fhjc", "replyto": "KznJt9Fhjc", "signatures": ["ICLR.cc/2026/Conference/Submission6952/Reviewer_9xQr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6952/Reviewer_9xQr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761874642807, "cdate": 1761874642807, "tmdate": 1762919178912, "mdate": 1762919178912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of generating high-quality multi-turn, multi-step dialogues for agentic task-solving with LLMs, where existing simulation-based methods rely on costly autoregressive interactions and often limit task performance. To tackle this, the authors propose NAIG (Non-Autoregressive Iterative Generation), a three-stage framework that constructs complete conversational trajectories through coarse-grained initialization, iterative refinement via mask-and-fill operations, and offline verification to ensure semantic coherence, contextual consistency, and correctness. Rich experiments were conducted to prove the method's effectivenes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. This work identifies three important challenges in simulation-based data generation for agentic multi-turn interactions.\n2. The dataset has the potential to significantly contribute to research on agentic LLMs, provided it can be publicly released.\n3. The paper is clearly written, and the methodology is described in sufficient detail."}, "weaknesses": {"value": "1. The multi-agent simulation process does not incorporate offline verification, and such verification is not an inherent requirement for non-autoregressive methods. This raises concerns about the fairness of comparing NAGI with methods that include offline verification.\n2. The improvement of NAIG over Multi-Agent Simulation appears to be marginal. Considering Weakness 1, the core component of the non-autoregressive framework (i.e., NAIG without offline verification) does not seem to provide a meaningful improvement.\n3. The reported computational cost may be misleading, as it appears to consider only API calls without accounting for the tokens required for model training and inference. In particular, NAGI likely requires more tokens for both inputs and outputs per API call, which could further increase the actual computational cost.\n4. The conclusion that the NAIG generation paradigm supports more effective overall task planning may not be fully supported by the assistant turn counts. Notably, the maximum number of assistant turns in the NAIG training data is higher than in the MAS training data, and the analysis is limited to models trained on τ-Bench. Additional analyses would help strengthen this claim."}, "questions": {"value": "1. The authors mention three key issues in back-and-forth interaction generation. If a single LLM generates the entire interaction via a well-designed prompt and then is refined interactively, would these issues persist, or would new ones emerge?\n2. The abbreviation \"MAS\" is commonly used to refer to multi-agent systems. To avoid potential confusion, I suggest using a different short name for multi-agent simulations.\n3. In Figure 4, why is the maximum number of assistant turns in the NAIG training data larger than that in the MAS training data? Could the authors clarify this observation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5JNkg7wq8y", "forum": "KznJt9Fhjc", "replyto": "KznJt9Fhjc", "signatures": ["ICLR.cc/2026/Conference/Submission6952/Reviewer_TB5g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6952/Reviewer_TB5g"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903274252, "cdate": 1761903274252, "tmdate": 1762919178469, "mdate": 1762919178469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NAIG (Non-Autoregressive Iterative Generation), a novel framework for generating multi-turn dialogues involving function-calling and agentic behavior in large language models (LLMs). Inspired by Non-Autoregressive Translation (NAT) and masked diffusion language models, NAIG generates full conversational trajectories through a non-autoregressive pipeline consisting of three stages. First, a coarse-grained initialization step produces a structurally complete but semantically shallow dialogue skeleton. Second, an iterative refinement stage enhances complexity and semantic coherence using a mask-and-fill strategy inspired by masked language models. Third, an offline verification step applies a combination of rule-based and model-based checks to filter out inconsistent or hallucinated samples. The authors evaluate NAIG on several benchmarks, demonstrating significant improvements over multi-agent simulation (MAS) approaches in multi-turn function-calling accuracy, data generation efficiency, and model generalizability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. NAIG produces more coherent, context-aware, and complex multi-turn dialogues by combination of structured initialization and iterative refinement.\n2. Their method reduces reliance on expensive multi-agent autoregressive interactions, lowering API costs\n3. Offline verification enhances data reliability by catching structural and semantic inconsistencies that are hard to detect during generation.\n4. Models trained on NAIG-generated data significantly outperform both MAS-based on multi-turn benchmarks."}, "weaknesses": {"value": "1. NAIG generation quality significantly drops when using smaller models (e.g., GPT-4o-mini), limiting its applicability in low-resource settings.\n2. Models trained on NAIG-generated data may over-optimize for multi-turn planning, potentially at the expense of performance on single-turn or one-shot queries.\n3. The experiments only compare NAIG against a single model despite the diversity of baselines available for tool-calling dialogue generation, raising concerns about the sufficiency and generalizability of the evaluation. \\"}, "questions": {"value": "1. Please provide detailed statistics of the dataset, such as the number of tools, average number of turns per dialogue, and the average number of tool-calling events per dialogue.\n2. Is NAIG extendable to multimodal agentic tasks, such as those involving visual inputs? \n3. It would be helpful to include additional comparative analysis against other state-of-the-art tool-based dialogue generation methods to better contextualize NAIG's performance. (e.g. ToolDial: Multi-turn Dialogue Generation Method for Tool-Augmented Language Models, ICLR 2025)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dAIeHiux2c", "forum": "KznJt9Fhjc", "replyto": "KznJt9Fhjc", "signatures": ["ICLR.cc/2026/Conference/Submission6952/Reviewer_HKC7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6952/Reviewer_HKC7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762044737077, "cdate": 1762044737077, "tmdate": 1762919178132, "mdate": 1762919178132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}