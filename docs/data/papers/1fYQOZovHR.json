{"id": "1fYQOZovHR", "number": 9868, "cdate": 1758145035868, "mdate": 1759897690677, "content": {"title": "MOLM: Mixture of LoRA Markers", "abstract": "Generative models can generate photorealistic images at scale. This raises urgent concerns about the ability to detect synthetically generated images and attribute these images to specific sources. While watermarking has emerged as a possible solution, existing methods remain fragile to realistic distortions, susceptible to adaptive removal, and expensive to update when the underlying watermarking key changes. We propose a general watermarking framework that formulates the encoding problem as key-dependent perturbation of the parameters of a generative model. Within this framework, we introduce  Mixture of LoRA Markers (MOLM), a routing-based instantiation in which binary keys activate lightweight LoRA adapters inside residual and attention blocks. This design avoids key-specific re-training and achieves the desired properties such as imperceptibility, fidelity, verifiability, and robustness. Experiments on Stable Diffusion and FLUX show that MOLM preserves image quality  while achieving robust key recovery against distortions, compression and regeneration, averaging attacks, and black-box adversarial attacks on the extractor.", "tldr": "", "keywords": ["Watermarking", "Diffusion models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9ea8bbb64cabd759af1be2db860b90d45d1142d2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "MOLM repurposes multiple LoRA adapters as watermark “markers” and uses key-dependent routing (MoLE-style) to embed a bitstring while keeping the backbone frozen. A learned extractor recovers bits. Experiments on SD-1.5 and FLUX report near-zero inference overhead, small FID changes, and robustness to common distortions and selected white-box attacks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.Practicality. Lightweight LoRA adapters, no architecture changes, negligible runtime overhead.\n2.Coverage. Evaluation on SD-1.5/FLUX with ~28-bit default capacity and higher-capacity variants; ablations on placement/configuration.\n3.obustness. High bit accuracy under JPEG/crop/resize and diffusion regeneration; PGD-style white-box results show resilience."}, "weaknesses": {"value": "1. The method is a straightforward combination of existing techniques (LoRA + MoE routing).\n2. Fails to compare with recent state-of-the-art watermarking methods."}, "questions": {"value": "1.Novelty. The core idea of MOLM is to repurpose LoRA adapters as watermark carriers and use key-driven routing to activate specific adapters for embedding. This is essentially a composition of mature techniques: 1) LoRA is a well-established parameter-efficient fine-tuning method; MOLM merely reinterprets it as a watermark carrier. 2) The routing logic follows MoLE, replacing data-gated expert selection with key-gated selection.\n2.Baselines. Include recent watermarks or clearly justify exclusion.\n3.Presentation. Fix typos (e.g., “Deployment”; “~8 days”), align the Table-3 title with its contents ('inference' is not listed, although it is mentioned in the paper), and unify notation/spacing across equations and tables."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TAb1X5bnnK", "forum": "1fYQOZovHR", "replyto": "1fYQOZovHR", "signatures": ["ICLR.cc/2026/Conference/Submission9868/Reviewer_D7NA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9868/Reviewer_D7NA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761530737990, "cdate": 1761530737990, "tmdate": 1762921339002, "mdate": 1762921339002, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MOLM, a watermarking framework for text-to-image diffusion models that views watermarking as key-dependent parameter perturbations of a *frozen* generator. Concretely, the method installs LoRA adapters in selected residual/attention blocks and routes activation through one adapter per block according to chunks of a binary key. Thus, a key defines a deterministic execution path (the perturbation), while the backbone weights remain unchanged. A lightweight extractor network recovers the key from generated images. The training objective balances a perceptual loss for imperceptibility with a bitwise BCE for verifiability. Experiments on Stable Diffusion v1.5 (512×512) and FLUX (1024×1024) show high key recovery, small FID deltas (≤ ~1.5), and robustness to a range of common image distortions, learned compression, diffusion-based regeneration, averaging, and white-box PGD attacks. Default configuration routesL=14 decoder ResNet blocks with P=4 adapters per block, yielding M=28-bit keys; larger capacities are discussed via more blocks or choices"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Casting watermarking as key-conditioned parameter routing over a frozen backbone is elegant, modular, and orthogonal to model architectures. The idea neatly ties together LoRA efficiency with watermarking needs.\n2. Keys correspond to routing masks; adapting capacity does not require retraining the backbone. The paper reports ~1 GPU-day one-time training and no additional inference cost beyond activating chosen LoRA paths."}, "weaknesses": {"value": "1. The paper frames both detection and attribution but largely evaluates bit recovery / TPR against a fixed key/threshold. How MOLM behaves with large key databases (collisions, nearest-neighbor attribution errors, false-match rate under heavy post-processing) is not fully quantified.\n2. The white-box attacks target the extractor in image space. Stronger adversaries could attempt prompt-, noise-, or sampler-level optimization to suppress/flip bits while staying on-distribution (e.g., plug-and-play adversaries).\n3. While MOLM avoids per-key retraining, operational details (e.g., revoking/rotating keys, multi-tenant key assignment, rate-limited leakage scenarios, collusion of users averaging many outputs with heterogeneous keys) are not empirically explored. \n4. The table compares to Stable Signature, AQuaLoRA, WOUAF (bit recovery) and Tree-Ring/ROBIN/Gaussian Shading (detection). Some strong recent defenses/attacks (esp. post-2024 SoK/benchmarks) may warrant a tighter apples-to-apples setup (identical prompts/seeds, extractors retrained with the same aug sets), though the paper cites them. \n5. The robust baselines for watermarking arbitrary images are lacking, such as TrustMark [1], VINE [2], StegaStamp [3]. Incorporating those methods would make the comparison more thorough and robust.\n\n\n[1] TrustMark: Universal Watermarking for Arbitrary Resolution Images\n\n[2] Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances\n\n[3] StegaStamp: Invisible Hyperlinks in Physical Photographs"}, "questions": {"value": "1. If a key leaks, how quickly can you rotate without retraining? Is there support for *soft revocation* (e.g., attenuating adapters) versus installing fresh adapter banks?\n2. You evaluate averaging removal/forgery with the same messages; what about heterogeneous-key collusion across many users? Can mixed-key averaging partially cancel the watermark?\n3. Have you tried prompt/noise optimization targeting the extractor gradient via a differentiable proxy, or classifier-free guidance tuning to hide bits while maintaining content?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mcBu9DFT3I", "forum": "1fYQOZovHR", "replyto": "1fYQOZovHR", "signatures": ["ICLR.cc/2026/Conference/Submission9868/Reviewer_Tahr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9868/Reviewer_Tahr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761568787017, "cdate": 1761568787017, "tmdate": 1762921338706, "mdate": 1762921338706, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses verifying and attributing AI-generated images. The authors propose a watermarking framework inspired by the Mixture of LoRA Experts. They formulate the problem as key-dependent perturbations of frozen generative models, where binary keys are used to route among a mixture of LoRA adapters inserted into the generative model. In addition, the authors consider imperceptibility, fidelity, verifiability, and robustness by incorporating the L_imp​ and L_ver​ losses."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The underlying ideas are reasonable.\n\nThe evaluation demonstrates imperceptibility, fidelity, verifiability, and robustness.\n\nThe paper includes ablation studies supported by experiments and visualization.\n\nThe experimental details are clearly presented."}, "weaknesses": {"value": "The watermarking results do not clearly demonstrate state-of-the-art performance; they are only competitive with previous methods.\n\nThe description of the proposed method is generally ok, but some paragraphs are poorly written and fragmented, which affects readability."}, "questions": {"value": "The authors mention that the proposed method is inspired by Mixture of LoRA Experts (MoLE), but the motivation behind this choice is unclear. It would be helpful to explain the intuition for why MoLE's structure is beneficial for the watermarking problem, beyond the fact that it can be adapted to it.\n\nDiffusion version 3.5 Large (8B) has already been released on Hugging Face. However, this paper still evaluates on version 1.5. It would be more convincing to include results from a more recent version to demonstrate scalability and relevance.\n\nIn Table 1, the bolded values appear to indicate the best and second-best results within each column, but this should be explicitly explained in the table caption. The meaning of the orange-highlighted values should also be clarified.\n\nIt would strengthen the paper if more baseline methods were reimplemented and evaluated on the FLUX architecture and LAION dataset to provide a fair and comprehensive comparison with the proposed approach."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7Q3fljGgFA", "forum": "1fYQOZovHR", "replyto": "1fYQOZovHR", "signatures": ["ICLR.cc/2026/Conference/Submission9868/Reviewer_yLkc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9868/Reviewer_yLkc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762092042532, "cdate": 1762092042532, "tmdate": 1762921338448, "mdate": 1762921338448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}