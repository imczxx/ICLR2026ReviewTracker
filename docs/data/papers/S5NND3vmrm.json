{"id": "S5NND3vmrm", "number": 4866, "cdate": 1757779940987, "mdate": 1759898008075, "content": {"title": "RT-Remover: A Real-Time Video Object Removal by Composing Tracking and Removal in Auto-Regressive Diffusion Transformers", "abstract": "With the rapid advancement of video diffusion, video editing techniques, especially video object removal, have garnered increasing attention. Existing methods generally rely on separate object tracking and inpainting stages, leading to complex and slow pipelines that are unsuitable for real-time and interactive applications. This paper is committed to designing a real-time video object remover with the minimum latency, termed as **RT-Remover**. To this end, we introduce three key innovations in this paper to enable the real-time object removal in videos. First, different from previous methods that perform tracking and inpainting individually, we compose them into a joint process. Our model only requires an initial mask for the first frame from the user and automatically removes the target objects across the whole video. Second, we leverage an auto-regressive diffusion model for a real-time video object remover. We use an auto-regressive form to predict the next chunk based on previous chunks, while use diffusion model to iteratively predict the current chunk. Meanwhile, we incorporate a fixed-length key-value cache to minimize both memory usage and computational overhead. Third, to further speed up the inference, we propose to distill the auto-regressive diffusion model using distribution matching distillation and flow matching loss, and thus reduce the number of sampling steps from 25 to 2 while preserving background consistency. All three contributions significantly simplify the pipeline and enable real-time performance. Our method achieves ***33 FPS*** and ***0.12s latency*** on a 5090 GPU with our trained faster VAE. Extensive experiments show that our approach achieves the lowest latency among existing methods while maintaining competitive visual quality.", "tldr": "", "keywords": ["Streaming Video Object Removal"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/76f1e193a3deee641abb1469404583abae8dcc80.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents RT-Remover, a real-time video object removal system that merges tracking and inpainting into a single auto-regressive diffusion model. It requires only a starting mask for the first frame and uses causal attention with a key-value cache for efficient sequential generation. Through step distillation (distribution matching distillation) and a lightweight VAE, the method reduces sampling steps to two, achieving 33 FPS and 0.12s latency while maintaining strong visual quality and temporal consistency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper introduces a single model that jointly performs tracking and inpainting, removing the need for separate stages and simplifying the pipeline significantly.\n2) By combining auto-regressive diffusion with key-value caching and applying a tailored distillation strategy, the method reduces sampling steps from 25 to 2 while maintaining quality.\n3) The approach achieves 33 FPS and 0.12s latency, making real-time interactive video editing feasible."}, "weaknesses": {"value": "1) Lack of qualitative results: it would be great to see the examples of edited videos (not rolled out frames) to assess the quality of removal by the model (especially temporal consistency).\n2) Lack of qualitative and quantitative comparisons: in Table 3 and Table 4, why not compare to Minimax-Remover?\n3) Minor grammatical errors: for instance, in line 138 \"simplies\" -> \"simplifies\", in lines 280-281 \"togather\" -> \"together\", and so on."}, "questions": {"value": "1) How does the model handle inaccurate initial masks or cases with multiple objects? Is there any quantitative or qualitative analysis on robustness?\n2) Can the authors share video examples of the removal results? Static images are insufficient to judge temporal consistency and overall quality.\n3) Table 7 evaluates fixed window sizes, but have you considered adaptive strategies where the KV cache length changes based on motion or chunk complexity? Could this further optimize efficiency while preserving quality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AL6qjmFGEs", "forum": "S5NND3vmrm", "replyto": "S5NND3vmrm", "signatures": ["ICLR.cc/2026/Conference/Submission4866/Reviewer_AA5H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4866/Reviewer_AA5H"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761776505179, "cdate": 1761776505179, "tmdate": 1762917622668, "mdate": 1762917622668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RT-Remover, a lightweight, low-latency, and autoregressive diffusion-based video object removal model. A key feature of RT-Remover is its ability to remove masked objects from an entire video by only requiring a mask for the first frame. \n\nThe authors propose a two-stage training strategy to realize this model:\n1. Stage 1: A pre-trained Wan2.1 generative model is fine-tuned into an auto-regressive general inpainting model. \n2. Stage 2: The model undergoes distillation using a distribution matching distillation method. This process leverages object removal data generated by Minimax-Remover to transform the model into a lightweight object removal solution that requires only 2 inference steps and can simultaneously track and remove objects based solely on the first-frame mask.\n\nFurthermore, the authors replace the VAE with LeanVAE to achieve further acceleration."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This is the first real-time video object removal model.\n2. The proposed RT-Remover in this paper achieves extremely fast inference speed, which is 14× faster than state-of-the-art models.\n3. The authors integrate both mask tracking and object removal functionalities into a single model, eliminating the need for an additional model to handle mask tracking. This not only enhances user-friendliness but also reduces the model latency."}, "weaknesses": {"value": "1. Table 2 is not referenced or discussed anywhere in the main body of the paper. Additionally, the 'SAM2 Latency (s)' column in Table 2 appears incomplete, with several data missing.\n2. The quantitative and qualitative comparative baselines are all generative models, but it’s unclear if they were trained on object removal datasets, making the fairness of comparison questionable. Additionally, no metrics are compared with mainstream video object removal models. To ensure fair comparison, these mainstream non-autoregressive models could be tested under an autoregressive inference setup (i.e., only inputting causal temporal frames) to align with RT-Remover’s inference logic.\n3. While RT-Remover is designed to track and remove objects using only the first-frame mask, this input setting is unfair when comparing with other video object removal models, as those baselines lack the design to track objects across frames with just the first-frame mask.\n4. Visualized results are limited, with no demos on challenging cases (e.g., target exiting and re-entering the frame). Such edge-case results would better validate robustness."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ec4Xk3W4rK", "forum": "S5NND3vmrm", "replyto": "S5NND3vmrm", "signatures": ["ICLR.cc/2026/Conference/Submission4866/Reviewer_NmWE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4866/Reviewer_NmWE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831776731, "cdate": 1761831776731, "tmdate": 1762917622259, "mdate": 1762917622259, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "RT-Remover is a real-time video object removal system that unifies object tracking and inpainting into a single streamlined process. It employs an auto-regressive diffusion model with distribution-matching distillation to reduce sampling steps from 25 to 2, achieving 0.12s latency and 33 FPS on a 5090 GPU. This approach significantly simplifies the pipeline while maintaining competitive visual quality and achieving the lowest latency among existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "[1] The paper addresses an important problem, as video editing speed is a critical factor for enabling deployment on mobile platforms.\n\n[2] The presented experimental results demonstrate excellent latency and efficiency."}, "weaknesses": {"value": "[1] The paper reads as if various existing methods were simply combined for faster performance, giving the impression of a technical report describing a series of empirical design choices rather than a research paper presenting novel insights.\n\n[2] What exactly is the problem being addressed, and what are the underlying causes of this problem?\n\n[3] What is the proposed contribution for fast distillation? Is the main contribution merely the adoption of DMD2, or is there an additional methodological innovation?\n\n[4] The current writing structure mostly follows a pattern of “problem → apply existing method”, which raises the question of whether this work truly qualifies as a research paper rather than an implementation summary.\n\n[5] Is there any video results?"}, "questions": {"value": "My questions are in the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gkYVzW5SY3", "forum": "S5NND3vmrm", "replyto": "S5NND3vmrm", "signatures": ["ICLR.cc/2026/Conference/Submission4866/Reviewer_WcC6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4866/Reviewer_WcC6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927293616, "cdate": 1761927293616, "tmdate": 1762917621952, "mdate": 1762917621952, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a real-time approach for video object removal by introducing three key innovations:\nJoint tracking and inpainting: The method integrates object tracking and video inpainting into a unified process to improve temporal consistency and efficiency.\nAuto-regressive diffusion with distillation: It leverages an auto-regressive diffusion model enhanced through a distillation technique to achieve high-quality, temporally coherent results in real time.\nFixed-length key-value cache: A fixed-length cache mechanism is employed to manage memory and computation effectively, enabling fast inference across video frames."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Belows are strong points that this paper has:\n\n**1. Comprehensive and well-engineered approach:**\nThe paper demonstrates remarkable research and engineering effort toward achieving real-time video object removal. The authors systematically present a complete methodology that focuses on optimizing both efficiency and speed in the training and inference pipelines.\n\n**2. Extensive experimental validation:**\nThe proposed method is thoroughly evaluated through a wide range of experiments, comparing both performance and efficiency against existing approaches.\n\n**3. Multi-perspective evaluation:**\nThe paper provides convincing evidence of the method’s effectiveness through diverse evaluation metrics—including efficiency benchmarks, quantitative performance measures, GPT-5 assessments, and user studies, offering a well-rounded understanding of RT-Remover’s strengths."}, "weaknesses": {"value": "Belows are weak points that this paper has:\n\n**1. Incomplete performance comparison:**\nThe paper lacks a comprehensive experiment table comparing the proposed RT-Remover with other video object removal models in terms of model performance. Table 2 would be more informative if it combined both efficiency and performance metrics to provide a unified view of trade-offs.\n\n**2. Insufficient methodological details:**\n- The process of fine-tuning LeanVAE to align with the latent space of Wan2.1 VAE is not clearly explained and should be made self-contained for reproducibility.\n- The fixed-length key-value cache mechanism and its impact on performance are not sufficiently detailed; currently, the only reference is Figure 6, which lacks quantitative or descriptive depth.\n- The notation $N$ mentioned around Lines 194–195 is undefined or ambiguous and should be clarified in the text.\n\n**3. Lack of failure case analysis:**\nIt would be valuable for the authors to include examples of failure cases. For instance, scenarios where the target object disappears and reappears within the video could help illustrate the model’s limitations and potential areas for improvement."}, "questions": {"value": "Please check above the questions listed in Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NVK72pSOLf", "forum": "S5NND3vmrm", "replyto": "S5NND3vmrm", "signatures": ["ICLR.cc/2026/Conference/Submission4866/Reviewer_SNRj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4866/Reviewer_SNRj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762282265408, "cdate": 1762282265408, "tmdate": 1762917621574, "mdate": 1762917621574, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}