{"id": "zj2mI9TSF7", "number": 23556, "cdate": 1758345398368, "mdate": 1759896808093, "content": {"title": "Mechanistic evaluation of Transformers and state space models", "abstract": "State space models (SSMs) for language modelling promise an efficient and performant alternative to quadratic-attention Transformers, yet show variable performance on recalling basic information from the context. While performance on synthetic tasks like Associative Recall (AR) can point to this deficiency, behavioural metrics provide little information as to \\textit{why}---on a mechanistic level---certain architectures fail and others succeed.\nTo address this, we conduct experiments on AR, and find that only Transformers and Based SSM models fully succeed at AR, with Mamba and DeltaNet close behind, while the other SSMs (H3, Hyena) fail. We then use causal interventions to explain why.\nWe find that Transformers and Based learn to store key--value associations in-context using induction. By contrast, the SSMs seem to compute these associations only at the last state using a single layer. We further investigate the mechanism underlying the success of Mamba, and find novel evidence that Mamba \\textit{does} implement induction: not via the SSM, but instead via short convolutions.\nFurther experiments on a new hierarchical retrieval task, Associative Treecall (ATR), show that all architectures learn the same mechanism as they did for AR. Furthermore, we show that Mamba can learn Attention-like induction on ATR when short convolutions are removed.\nThese results reveal that architectures with similar accuracy may still have substantive differences, motivating the adoption of mechanistic evaluations.", "tldr": "", "keywords": ["mechanistic interpretability", "language model architectures", "associative recall"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9f81af041140049b345041d2dd6eb3d2c9eebe65.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper performs a mechanistic study on how SSMs and Transformers solve associative recall (AR) and associative treecall (ATR) tasks. The authors use causal interventions as the main tool. They find that for AR, Transformers and Based use induction mechanism, whereas SSMs such as Mamba rely on the convolution component --- without which Mamba fails to learn AR. They also find that similar mechanisms hold for ATR, except that Mamba can also use the Attention-like two-layer induction mechanisms in absence of the convolution component."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It is an interesting idea to use causal intervention as a mechanistic understanding tool to compare SSMs with transformers\n\n2. The paper is clearly organized, with illustrative figures supporting the main claims."}, "weaknesses": {"value": "1. Some claims are not well supported. For example, in line 75-76, the authors claim that ``(Mamba) fails to learn AR at all without this (short convolution component)'', but the experiments (Fig.4) only investigate the Mamba convolution kernel size no greater than $4$, unclear whether Mamba fails with long(er) convolution kernel. \n\n2. Lack of architecture details and analysis. Although the authors provide source code, the paper lacks concrete definitions of the architectures used for study, and thus provides little explanation why certain mechanisms present in one architecture but not the others."}, "questions": {"value": "1. Sec 4.4 Convolution moves information to the next key (line 317-322): This claim arises from the results in Fig.5, where restoring next key at layer 0 gives the best result. But why does the restoration necessarily imply the convolution component moves information to the next key? If my understanding of restoration is correct (which is not very precisely defined in paper, but loosely on Fig.2), restoration means we can arbitrary set any token at the next-key position. Then one easy solution is to set the next-key to be the corrupted key, which does not rely on convolution moving information to the next key. In addition, if the next key is arbitrary far away from the previous key, a short-convolution by definition cannot move information to the next key. Can the authors clarify?\n\n 2. I appreciate the interesting use of causal intervention to mechanistically evaluate the AR mechanisms, but the findings seem to mostly corroborate the existing known results (e.g., short convolution are key to association in SSMs as mentioned by the authors in related work), including some provable solution mechanisms in missing related works [1] [2]. Does the mechanistic study offer novel insights (e.g., identify unknown mechanisms, provide more fine-grained analysis on how  the AR mechanisms interact with the choice of architecture and optimization set-up)?\n\n References:\n\n [1] Bietti et al. \"Birth of a transformer: A memory viewpoint.\" NeurIPS 2023.\n\n [2] Huang et al. \"Understanding Input Selectivity in Mamba: Impact on Approximation Power, Memorization, and Associative Recall Capacity.\" ICML 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b3zMxyaP7z", "forum": "zj2mI9TSF7", "replyto": "zj2mI9TSF7", "signatures": ["ICLR.cc/2026/Conference/Submission23556/Reviewer_bLmn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23556/Reviewer_bLmn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841307305, "cdate": 1761841307305, "tmdate": 1762942711125, "mdate": 1762942711125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper at hand presents a study of associative recall (AR) and associative tree recall (ATR) on various sequence models: from simple convolutions to Mamba and Transformers. The authors claim these models use different methods to solve AR, which they study by intervening on input sequences."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Studying basic performance tasks on transformers vs new sequence models is interesting. The authors train a large set of models and carry out the analysis also on ATR, which is a less common setup that I did not know before, but I find quite insightful. \nThe paper is also pleasant to read and schematic, which helps deliver the message. Plots are clear."}, "weaknesses": {"value": "The findings in the paper have quite a few overlaps with previous works:\n\n- Zoology: https://arxiv.org/abs/2312.04927\n- Based: https://arxiv.org/abs/2402.18668\n- Convolution-augmented transformers: https://arxiv.org/abs/2407.05591\n- Revisiting Associative Recall: https://openreview.net/pdf/f7e9f322ba15e88dcc818ab70866648650a5e319.pdf\n- H3 : https://arxiv.org/pdf/2212.14052\n\nIn light of the findings in the papers above, I did not find the paper very surprising. The authors cite all the papers above, but do not discuss or compare their results to previous literature:\n\n1) performance on AR is reported in (1) \"Zoology\", and (2) with a much finer LR grid in \"Revisiting Associative Recall\". In the latter, the authors claim that LR sensitivity is a big issue in Mamba and Hyena. The authors do not discuss this issue nor seem to take any action to perform careful evaluations. Additionally, betas = (0.9, 0.999) in Adam is the default, but it is not what people typically use in language models. beta2 is too high (0.95 is default in many repos). How do you make sure your results depict what \"each model can achieve\"?\n\n2) It is a bit hard to follow what the authors mean by \"induction\". I think, despite 1k years of philosophical debates, the definition can be a bit arbitrary. I was confused while reading your claims. Please define what you mean! I had an approximate idea at the end of the paper, but this is not formal enough.\n\n3) The reader is not prompted to read the figures correctly, and the tasks are not well defined. Let us consider Figure 2: if you change A to B, the eval always returns A, and 2 returns \"???\". This is very unclear to me. I do not understand the ground truth and I find little explanations in the text. Furthermore, Figure 3 has a similar issue: you never formally define any of the tasks; what is \"Restored @ Key\"? You discuss how these tasks resemble interventions, but I cannot determine their respective importance. What are they individually supposed to test?\n\n4) The role of convolution has been studied thoroughly, in \"power of convolution-augmented transformers\" but also in the H3 paper. In H3, they place a shift + gate exactly to enhance recall (https://arxiv.org/pdf/2212.14052, Fig 1). Again, I do not find surprising the claim about convolution, given also the induction head standard mechanism where the first transformer layer indeed represents a shift (e.g. proof in the Jelassi paper on the copy task, and Figure 1 above).\n\nAll in all, I do not see the level of novelty here to be at the level of acceptance. I ask the authors to please specify which new insights are presented in the paper, and to clarify what their causal interventions are precisely testing."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8edAJwk089", "forum": "zj2mI9TSF7", "replyto": "zj2mI9TSF7", "signatures": ["ICLR.cc/2026/Conference/Submission23556/Reviewer_LJok"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23556/Reviewer_LJok"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761866324680, "cdate": 1761866324680, "tmdate": 1762942710883, "mdate": 1762942710883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a generalized Associative Recall task named Associative Treecall and provide mechanic interpretability for the success of Mamba."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. comprehensively and mechanically evaluate common linear models and transformer.\n2. clear and good writing."}, "weaknesses": {"value": "1. mechanic metric are not used to provide guidance for the design of architecture but can only help understanding. thus its use is limited."}, "questions": {"value": "1. can you provide an example of how mechanic metric helps the design of architecture?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PIAFrwcSpk", "forum": "zj2mI9TSF7", "replyto": "zj2mI9TSF7", "signatures": ["ICLR.cc/2026/Conference/Submission23556/Reviewer_wtMM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23556/Reviewer_wtMM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979417745, "cdate": 1761979417745, "tmdate": 1762942710704, "mdate": 1762942710704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces mechanistic evaluations (causal interchange interventions) to analyze the impact of different architectural components in solving Associative Recall (AR) task, along with a new retrieval task, called Associative Treecall (ATR). The authors show that on AR, Attention and Based architectures exhibit induction while Mamba and DeltaNet perform direct retrieval. The main ablation revolves around the size of the convolution kernels, where the ablations show that short convolution kernels are critical for AR on Mamba and Based architectures. With a detailed analysis on the two tasks, the authors claim that comparable accuracies can hide different internal mechanisms."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The intervention protocol pinpoints the mechanism - more specifically, the QKV positioned restorations at layer input/outputs disambiguate induction from direct retrieval.\n- The kernel size ablation study demonstrates that short receptive-field convolution kernels implement the association needed for AR. \n- With the new task (ATR), the paper verifies that the mechanism transfer to a harder task without positional dependence."}, "weaknesses": {"value": "- The experiment results seem quite noisy. For figure 4, in particular, it is unclear why model dim 128 and Mamba Conv. = 2 suddenly fails. Also, it is unclear why Restored @ Key value for this configuration is notably high compared to other entries. A similar trend is observed for Figure 5, where model configurations that perform well can drastically fail, (~0% accuracy) with learning rates that are slightly modified. This result, unless it can be justified empirically or theoretically, raises a serious concern whether the results are valid conclusions or are due to insufficient sweep in the hyperparameter space.\n- Potential confounds with the parameter count on the models. The models have different parameter counts and FLOPs, and hence presenting the results in one of these dimensions would be much more valuable."}, "questions": {"value": "- Please correct me if I misunderstood, but ATR induces unequal pair frequencies, which may induce a generative prior, allowing the corrupted-key accuracy to stay above 0 in most cases. \n- Replacing Based's short convolution kernel with an implicit long convolution kernel significantly harms AR. Why might this be? Providing heatmaps for the long convolution kernel case to show where association fails could help better understand this phenomenon. Also a more detailed discussion about this phenomenon would strengthen this manuscript.\n- The authors note that Hyena includes a short convolution kernel but it performs poorly on AR. This signals that a convolution kernel is not sufficient to solve this task of AR. Which downstream component could be preventing the convolution kernel from implementing the association step?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vjjys7F5qK", "forum": "zj2mI9TSF7", "replyto": "zj2mI9TSF7", "signatures": ["ICLR.cc/2026/Conference/Submission23556/Reviewer_UuRe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23556/Reviewer_UuRe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983769186, "cdate": 1761983769186, "tmdate": 1762942710513, "mdate": 1762942710513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}