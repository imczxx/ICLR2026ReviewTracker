{"id": "QPg2Fm9bnl", "number": 6233, "cdate": 1757960515420, "mdate": 1759897927769, "content": {"title": "Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models", "abstract": "While the robustness of vision models is often measured, their dependence on specific architectural design choices is rarely dissected. We investigate why certain vision architectures are inherently more robust to additive Gaussian noise and convert these empirical insights into simple, actionable design rules. Specifically, we performed extensive evaluations on 1,174 pretrained vision models, empirically identifying four consistent design patterns for improved robustness against Gaussian noise: larger stem kernels, smaller input resolutions, average pooling, and supervised vision transformers (ViTs) rather than CLIP ViTs, which yield up to 506 rank improvements and 21.6\\%p accuracy gains. We then develop a theoretical analysis that explains these findings, converting observed correlations into causal mechanisms. First, we prove that low-pass stem kernels attenuate noise with a gain that decreases quadratically with kernel size and that anti-aliased downsampling reduces noise energy roughly in proportion to the square of the downsampling factor. Second, we demonstrate that average pooling is unbiased and suppresses noise in proportion to the pooling window area, whereas max pooling incurs a positive bias that grows slowly with window size and yields a relatively higher mean-squared error and greater worst-case sensitivity. Third, we reveal and explain the vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller normalization standard deviations used in CLIP preprocessing amplify worst-case sensitivity by up to 1.91 times relative to the Inception-style preprocessing common in supervised ViTs. Our results collectively disentangle robustness into interpretable modules, provide a theory that explains the observed trends, and build practical, plug-and-play guidelines for designing vision models more robust against Gaussian noise.", "tldr": "We identify four key architectural choices that enhance vision models' robustness to Gaussian noise.", "keywords": ["Vision Transformers", "Architecture", "Gaussian Noise", "Robustness", "CLIP"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a70b4052cc81db0a10544bc5d74ecff5ce4a384e.pdf", "supplementary_material": "/attachment/0f522939a85a728fff51faa3b609b5e6979caf02.zip"}, "replies": [{"content": {"summary": {"value": "The paper investigates why certain vision architectures are naturally more robust to additive Gaussian noise and translates these findings into simple, theoretically grounded design principles. The authors evaluate over 1,100 pretrained models and identify four recurring factors that consistently improve robustness: larger stem kernels, smaller input resolutions, average pooling instead of max pooling, and supervised ViTs rather than CLIP ViTs. They complement these large-scale empirical results with theoretical analyses showing that noise attenuation scales quadratically with kernel size and downsampling factor, that average pooling reduces variance while max pooling introduces bias, and that CLIP’s normalization amplifies sensitivity by up to 1.9× compared to standard preprocessing. Altogether, the paper connects architecture-level design choices to quantifiable noise robustness and provides actionable guidelines for building more stable vision models."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Strengths**\n- Evaluates over a thousand pretrained models, ensuring strong empirical backing.\n- The paper, motivation and insights are clearly written.\n- The practical guidelines are directly usable for robust model design and could influence model architecture choices in industry and academia.\n- A nice overview that includes mathematical rigor and applied insight."}, "weaknesses": {"value": "**Weaknesses:**\n- Could you elaborate more in the differences between the different architecture of ResNet-{C,D,T,S}, maybe highlights the differences with a checkmark system in Table 2 to make the insight of Table 2 clearer because right now the takeaway by looking past the table is not clear. \n- The name in the Table 1 of the models is not very easy to parse, if you could make it clearer having column for each component, if would be much easier to compare. \n- The study focuses solely on Gaussian noise, which, while analytically convenient, may not capture real-world corruptions (e.g., blur, brightness, compression). Extending to more diverse perturbations would strengthen generality. Or at least add a limitation section mentioning that these findings might affect other perturbations in different ways. Building on that, I then find the title borderline misleading. The findings show some architectural changes to make the model robust to gaussian noise, not robust in general. Same for you conclusion:  \"[...] consistently improved * robustness\". l. 413 -> Replace: * = \"**gaussian noise**\" would be less misleading.\nSo, please tone down some claim."}, "questions": {"value": "**Questions:**\n\n- I am slightly bothered by the fact the the ICLR template format is not the same as the original template, any reason for that ? Line spacing seem different than the other papers. \n- Please add a limitation section mentioning the limitations. These architecture changes might work for this specific case, but they are not solution for all corruptions/OOD sources. \n\n\nAddressing these points (**Questions** and **Weaknesses**) would clarify the analysis, make the results more interpretable, and strengthen the positioning of the paper within the broader robustness literature."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HscHVZgoJK", "forum": "QPg2Fm9bnl", "replyto": "QPg2Fm9bnl", "signatures": ["ICLR.cc/2026/Conference/Submission6233/Reviewer_USA8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6233/Reviewer_USA8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6233/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907477767, "cdate": 1761907477767, "tmdate": 1762918562027, "mdate": 1762918562027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors perform an empirical study on the effect of architectural design on the model robustness against Gaussian noise. The authors evaluate a large number of vision models from timm library and identify four design choices for improved robustness: larger stem kernels, smaller input resolutions, average pooling, and supervised ViTs. The authors also provide the theoretical analysis for each choice."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe paper is generally well-written and easy to follow.\n-\tThe experiments are comprehensive, covering a large number of models."}, "weaknesses": {"value": "-\tThe authors mainly focus on Gaussian noise, which makes the scope of the paper somewhat limited. There are many corruptions beyond Gaussian noise. For example, 15 corruptions in [1] are commonly used to evaluate the model robustness. Besides, there are many other robustness benchmarks such as ImageNet-Adversarial, ImageNet-Rendition, ImageNet-Sketch, etc. Broadening the current scope will add more insights to the paper.\n-\tSince the authors focus on architectures, the mode size is also one important dimension that should be considered, where the current analysis is missing.\n-\tApart from ViT and ResNet, there are also many other architectures such as ConvNeXt, Swin, VMamba, Diffusion Classifier, etc. These more recent architectures should be considered and studied as well.\n\n**Reference:**\n\n[1] Benchmarking Neural Network Robustness to Common Corruptions and Perturbations. In ICLR, 2019."}, "questions": {"value": "I am concerned about the questions mentioned above. Given the current status of the paper, I am leaning towards rejection and hope the authors could address my concerns during the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eGYtbyVWuS", "forum": "QPg2Fm9bnl", "replyto": "QPg2Fm9bnl", "signatures": ["ICLR.cc/2026/Conference/Submission6233/Reviewer_RMHn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6233/Reviewer_RMHn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6233/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001929548, "cdate": 1762001929548, "tmdate": 1762918561637, "mdate": 1762918561637, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tries to study the robustness of different image classification models towards Gaussian noise perturbation. By comparing models' performance rank changes in a big leaderboard before and after adding Gaussian noise to the input images, this paper identifies some architectural designs related to the model robustness. Through analyzing the in-domain performance on different dataset, authors claim that ViTs require larger patch size, smaller input resolution and supervised CE loss to be robust to gaussian noise. For ResNet models, average pooling contributes more to the robustness compared to the max pooling and nearest neighbor pooling. For each conclusion, the paper also presents theoretical analysis as explanations."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper presents a way to analyze the model robustness by looking at the rank difference in the leaderboard before and after applying noise.\n2. This paper provides comprehensive theoretical analysis for the observed phenomena."}, "weaknesses": {"value": "1. The organization and the writing for this paper require improvement. \n2. There are some significant factual mistakes in the paper, i.e. the authors claim CLIP is a self-supervised method.\n3. The conclusion in this paper lacks reasonable support and looks unconvincing. For example, the authors claim larger patch size and lower input resolution image can benefit robustness of ViTs by looking at the performance of existing ViT checkpoints. However, the paper doesn't study the relationship between robustness with patch size and resolution on ViTs. Instead, authors try to verify this conclusion on ResNet backbone. I believe there exists some logic gap between the conclusions and the evidence presented in the paper.\n4. This paper only discuss the in-domain setting. It is well known models quite differently for in-domain data and out-of-domain data. Only analyzing model behaviors on in-domain data cannot reflect model's robustness comprehensively."}, "questions": {"value": "Please see the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pXaBKGdBVl", "forum": "QPg2Fm9bnl", "replyto": "QPg2Fm9bnl", "signatures": ["ICLR.cc/2026/Conference/Submission6233/Reviewer_dmMx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6233/Reviewer_dmMx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6233/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762374797810, "cdate": 1762374797810, "tmdate": 1762918561146, "mdate": 1762918561146, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies various vision models to determine architectural choices that are related to higher robustness gaussian noise. The paper finds that larger kernels in the stem network, average pooling and larger normalization standard deviations are related to enhanced robustness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Extensive experiments\n- Mostly clear presentation\n- Good theoretical analysis"}, "weaknesses": {"value": "- It is not surprising, and known, that larger kernel sizes lead to increased robustness to zero-mean gaussian noise. As the kernel grows larger the (weighted) sum of the noise component in the pixels/features approaches 0.\n- Likewise, it is expected that increasing the image resolution, while keeping the kernel size constant, leads to reduced robustness because the number of elements in the downstream feature maps increases, and thus the noise energy in downstream feature map is larger.\n    - Perhaps it would be interesting to plot the kernel size as a %age of the image size.\n- It is portrayed that unsupervised CLiP is more robust than supervised CLiP, but it is revealed that the only factor is the normalization constant, not the nature of the training objective.\n- some clarity issue:\n    1. Add gaussian parameters in 3.1\n    1. Clarify what the patch size in Section 3 refers to. Is it the longest dimension? Or is it, the total number of pixels in the patch?\n    1. In the tables, instead of writing the model name, it would be better to create separate columns for each parameter of the model.\n    1. Add details of ResNet-{C,D,T,S} in 4.1."}, "questions": {"value": "If we measure the size of the kernel size as a percentage of the image size, do the observations regarding robustness hold?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nhEbacsMOk", "forum": "QPg2Fm9bnl", "replyto": "QPg2Fm9bnl", "signatures": ["ICLR.cc/2026/Conference/Submission6233/Reviewer_iYNm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6233/Reviewer_iYNm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6233/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762421594542, "cdate": 1762421594542, "tmdate": 1762918560658, "mdate": 1762918560658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}