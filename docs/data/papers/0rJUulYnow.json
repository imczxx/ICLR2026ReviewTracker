{"id": "0rJUulYnow", "number": 18149, "cdate": 1758284365231, "mdate": 1759897126310, "content": {"title": "EvoMAS : Heuristics in the Loop—Evolving Smarter Agentic Workflows", "abstract": "The rapid development of Large Language Models has driven Multi-Agent Systems (MAS) growth, but constructing efficient MAS requires labor-intensive manual design. Current automation methods generate templated agents, use monolithic optimization, and ignore task complexity gradients. This paper presents Evolutionary MAS (\\textbf{EvoMAS}), a biologically-inspired framework that systematically addresses these limitations through three interconnected dimensions: (1) \\textbf{dynamic and diverse evolutionary strategies} with six biologically-inspired operators (3 exploration, 3 exploitation) and adaptive strategy selection; (2) \\textbf{role-level evolution} that dynamically optimizes agent specialization and collaboration patterns; and (3) \\textbf{curriculum-guided evolution} partitioning tasks by difficulty levels and evolving sequentially from simple to complex with cross-stage stability constraints. Additionally, to resolve the contradiction between the inefficiency of pure evolutionary methods and the limited flexibility of manual design, we developed the \\textbf{\"Cyber Creator\"}, a meta-control system combining dynamic rule formulation with reflective updates. Experimental evaluations demonstrate that EvoMAS consistently outperforms existing methods across multiple domains while maintaining cost efficiency, with agent roles dynamically evolving from homogeneous actors to specialized reasoning ensembles. Codes are available at \\href{https://anonymous.4open.science/r/EvoMAS-DEF4}\n{EvoMAS}.", "tldr": "", "keywords": ["Multi-Agent Systems", "Evolutionary Optimization", "Agentic Workflow", "Large Language Models", "Curriculum Learning", "Meta-Control Mechanism"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/43db88623c9b61a284c649c0bf49eb705dc59ed8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents **EvoMAS**, an evolutionary framework that formulates multi-agent workflow automation as a constrained single-objective optimization problem. It models the “variation–selection–reflection” cycle as a non-homogeneous Markov process and employs a meta-controller, **Cyber Creator**, to adaptively refine strategies and rules. The approach integrates six biologically inspired operators and demonstrates consistent performance gains across diverse benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* Rigorous formalization bridging evolutionary optimization and strategy learning.\n* Well-defined and operational evolutionary cycle (variation–selection–reflection).\n* Rich operator set balancing exploration and convergence.\n* Proven theoretical underpinnings ensuring stability and monotonic improvement.\n* Comprehensive experiments showing consistent gains in performance and efficiency.\n* Transparent reporting and open resources supporting reproducibility."}, "weaknesses": {"value": "* **Incomplete experimental disclosure:** Missing detailed hyperparameters and multiple-run statistics.\n  *Fix:* Add a complete configuration table with mean±std metrics.\n* **Opaque curriculum mechanism:** Quantitative thresholds for difficulty staging are unclear.\n  *Fix:* Define bucketing rules and add an ablation without curriculum.\n* **Unverified theoretical assumptions:** No empirical monitoring of information gain or strategy dynamics.\n  *Fix:* Log empirical statistics of these quantities and compare with theoretical expectations.\n* **Limited comparison with strong graph-retrieval baselines:** End-to-end tests are lacking.\n  *Fix:* Include controlled comparisons under unified corpora and retrieval quality metrics."}, "questions": {"value": "* Does the policy distribution evolve consistently across curriculum stages?\n* How is the reflection interval for Cyber Creator selected, and what is its impact on convergence and cost?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gcSPAZ1ebH", "forum": "0rJUulYnow", "replyto": "0rJUulYnow", "signatures": ["ICLR.cc/2026/Conference/Submission18149/Reviewer_Feh1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18149/Reviewer_Feh1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761779967523, "cdate": 1761779967523, "tmdate": 1762927908490, "mdate": 1762927908490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EvoMAS, a biologically inspired framework to evolve multi-agent workflows along three coupled axes: role-level evolution, dynamic and diverse evolutionary strategies, and curriculum learning. With the developed meta-controller Cyber Creator to adapt rules and operator distributions, EvoMAS achieves SOTA performance across six benchmarks, while maintaining superior cost-efficiency, outperforming both manual designs and automated baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper focuses on an interesting and important topic, MAS evolution, which is significant to drive the future development of AI systems.\n2. The paper clearly classifies the three dimensions of MAS evolution, and novelly proposes a graph-based formulation for the evolution search of MAS. \n3. The experiments in the paper are abundant"}, "weaknesses": {"value": "1. The six operators in exploration and exploitation could be better presented mathematically.\n2. The methodology does not detail discuss scheduling/halting (loop bounds, convergence, deadlock avoidance) for cycles in graph search.\n3. The task difficulty could be improved by adding human evaluations instead of pure LLM-as-a-judge.\n4. EvoMAS improves performance at a higher cost. A detailed cost analysis should be included to justify the significance of using EvoMAS."}, "questions": {"value": "1. What are the concrete termination/halting rules for cycles, and how are deadlocks/oscillations detected?\n2. Does the evolution process only occur in the training process? Or is it dynamically evolving in the inference process as well?\n3. How's the performance deviation in multiple runs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ewEwCtRROt", "forum": "0rJUulYnow", "replyto": "0rJUulYnow", "signatures": ["ICLR.cc/2026/Conference/Submission18149/Reviewer_AMeS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18149/Reviewer_AMeS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971527425, "cdate": 1761971527425, "tmdate": 1762927907897, "mdate": 1762927907897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "EvoMAS is a system that automatically builds better Multi-Agent Systems using ideas from biology. It evolves agents’ roles, teamwork, and learning stages to handle tasks from simple to complex. It employs six biologically inspired strategies: Diversity Expansion, Conceptual Recombination, Cross-domain Hybridization, Fine Optimization, Best Practice Synthesis, and Role Specialization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strong empirical results: Achieves top performance on five of six benchmarks, surpassing prior methods like AFlow and EvoFlow\n\nBroad evaluation coverage: Tested on 8 datasets across diverse domains for robust generalization.\n\nCost-efficiency: Demonstrates favorable Pareto efficiency, i.e., strong performance gains with moderate computational cost\n\nAblations: Provides quantitative ablation studies showing which biologically inspired operators contribute most to performance"}, "weaknesses": {"value": "The meta-agent evaluation process involves multiple sources of randomness, including (1) LLM output variance, (2) error propagation in chained reasoning within agents, (3) sampling variability within the meta-agent, (4) stochasticity in evaluation results for the designed agents, and (5) trajectory-level divergence caused by differences in sampled agent chains and their evaluation scores. While the reported results are averaged over three runs, the overall variability remains higher than that of typical single-LLM evaluations, making performance comparisons across runs and methods less statistically stable.\n\nThe “Cyber Creator” label is somewhat exaggerated, may obscure rather than clarify its technical role."}, "questions": {"value": "How do the contributions of the six biologically inspired strategies interact? Are there synergy effects or diminishing returns when multiple operators are combined?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "37k9NHsKTK", "forum": "0rJUulYnow", "replyto": "0rJUulYnow", "signatures": ["ICLR.cc/2026/Conference/Submission18149/Reviewer_LpNh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18149/Reviewer_LpNh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992283588, "cdate": 1761992283588, "tmdate": 1762927907274, "mdate": 1762927907274, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a three-dimensional evolution (roles, strategies, curricula) for multi-agent systems. The intuition is clear which is from biological evolution.\nThe overall empirical is solid and extensive showing good performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "This paper introduces a three-dimensional evolution (roles, strategies, curricula) for multi-agent systems. The intuition is clear which is from biological evolution.\nThe overall empirical is solid and extensive showing good performance."}, "weaknesses": {"value": "The overall writing is poor and confusing. \nThis paper relies heavily on metaphors (“cross-domain grafting,” “meta-rule induction”) with no algorithmic clarity or pseudocode. \nFor ambiguous definition of “strategy evolution”, it’s unclear what exactly evolves, prompt templates? Or graph structure?\nThe core components (Cyber Creator, rule encoding, variation operators) are underspecified; It’s hard to understand how those components work.\nFor Scalability, this paper mention “scalability” for their proposed method, but only small-scale systems (≤10 agents) tested. Reflection and rule updates could explode computationally. Does the cost record those progress?\nIn AFlow paper it incurs only around $1 of token cost for their workflows (see their paper). However, in the present paper, the reported cost for the authors’ system is much higher (e.g., $20 or more). The authors should clearly explain why the cost difference is so large. I don’t think this is efficient (most MAS with optimization won’t incur so much high cost). $20 is sufficient to support hundreds of thousands of words!"}, "questions": {"value": "1. Strategy Evolution Mechanism:\nWhat is the update rule for the “strategy probability distribution (A_t)”? \n2. For Cyber Creator, is this a separate LLM acting as meta-controller? How is “rule induction” implemented, prompt synthesis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sO6RNaqOsE", "forum": "0rJUulYnow", "replyto": "0rJUulYnow", "signatures": ["ICLR.cc/2026/Conference/Submission18149/Reviewer_cUQc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18149/Reviewer_cUQc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762158250853, "cdate": 1762158250853, "tmdate": 1762927906583, "mdate": 1762927906583, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}