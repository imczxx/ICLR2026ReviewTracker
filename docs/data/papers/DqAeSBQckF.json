{"id": "DqAeSBQckF", "number": 12629, "cdate": 1758209119531, "mdate": 1759897497257, "content": {"title": "BLISS: A Lightweight Bilevel Influence Scoring Method for Data Selection in Language Model Pretraining", "abstract": "Effective data selection is essential for pretraining large language models (LLMs), enhancing efficiency and improving generalization to downstream tasks. However, existing approaches often require leveraging external pretrained models, making it difficult to disentangle the effects of data selection from those of the external pretrained models. In addition, they often overlook the long-term impact of selected data if the model is trained to convergence, primarily due to the prohibitive cost of full-scale LLM pretraining. In this paper, we introduce BLISS (**B**ileve **L** **I**nfluence **S**coring method for data **S**election): a lightweight data selection method that operates entirely \\emph{from scratch}, without relying on any external pretrained oracle models, while explicitly accounting for the long-term impact of selected data. BLISS leverages a small proxy model as a surrogate for the LLM and employs a score model to estimate the long-term influence of training samples if the proxy model is trained to convergence. We formulate data selection as a bilevel optimization problem, where the upper-level objective optimizes the score model to assign importance weights to training samples, ensuring that minimizing the lower-level objective (i.e., training the proxy model over the weighted training loss until convergence) leads to best validation performance. Once optimized, the trained score model predicts influence scores for the dataset, enabling efficient selection of high-quality samples for LLM pretraining. \nWe validate BLISS by pretraining 410M/1B/2.8B Pythia and LLaMA-0.5B models on selected subsets of the C4 dataset. Notably, under the 1B model setting, BLISS achieves $1.7\\times$ speedup in reaching the same performance as the state-of-the-art method, demonstrating superior performance across multiple downstream tasks.", "tldr": "This paper provides a lightweight bilevel influence scoring method for data selection in language model pretraining.", "keywords": ["data selection", "language model", "bilevel optimization"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2c3ca5c719a408302d31902b67cbe9316e84ba29.pdf", "supplementary_material": "/attachment/c1a7f2479bc3cb3a4c0f735ad46c5206144f0ae4.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes BLISS, a data selection method for llm pre-training. Specifically, authors formulate data selection as a bilevel optimization problem, targeting at maximizing llm performance on validation sets. Experiments on C4 dataset and a series of 410M/1B/2.8B llms validate the effectiveness of BLISS."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The research topic of this paper is timely and important.\n- This paper is relatively well-written."}, "weaknesses": {"value": "1. The paper heavily emphasizes operating \"from scratch\" without external pretrained models, yet still requires a warm-up phase using randomly selected data (Section 4.3). Additionally, the bilevel optimization lower-level objective includes KL divergence with a specific LLM, which must already be partially trained to provide meaningful output logits. This fundamentally contradicts the core claim of independence from pretrained models.\n\n2. The paper claims to capture \"long-term impact\" by training the proxy model \"to convergence\" (Equation 1). However, the proxy model is trained for only 3,000 steps per round and is reset to initial parameters at the beginning of each round (line 4, Algorithm 1). This is not convergence in any meaningful sense, and resetting eliminates any accumulated long-term knowledge. Authors should provide empirical evidence (e.g., loss curves, model performance) demonstrating that 3,000 steps represents convergence, or revise claims about capturing \"long-term\" vs. \"medium-term\" impact.\n\n3. Although the paper presents a bilevel optimization formulation but provides no convergence guarantees, no sample complexity analysis, and no theoretical justification for why this formulation should select better data than alternatives. Without theory, it's unclear whether observed improvements are due to the principled framework or implementation details. At least, authors should add theoretical analysis showing: (a) convergence rates of the bilevel optimization algorithm, (b) bounds on the approximation error of using proxy models, (c) conditions under which the selected data provably improves downstream performance.\n\n4. Table 4 shows BLISS uses 8.08×10^19 FLOPs vs. MATES' 8.11×10^19 for 410M models, claiming efficiency. However, this comparison is not reasonable because\n\n- MATES trains per-sample gradients (inherently expensive) while BLISS batches operations differently.\n- The comparison doesn't account for memory overhead of maintaining two additional models.\n- Wall-clock time comparisons are absent.\n- Different parallelization strategies could dramatically affect practical efficiency.\n\n5. Many reported improvements fall within standard error margins. For example, in Table 1 (410M setting):\n\n- SciQ: 68.1±1.5 (BLISS) vs. 65.7±1.5 (MATES), this is potentially overlapping\n- ARC-C: 25.1±1.3 (BLISS) vs. 25.0±1.3 (MATES), this is essentially identical\n- Average: 45.9±1.4 vs. 45.7±1.4, this is a marginal difference\n\n6. The paper uses Pythia models throughout (proxy, score, and target LLM) but only briefly tests LLaMA (Appendix B) with different training procedures (periodic resets, KL divergence removal). No analysis examines what happens when proxy and target architectures differ (e.g., Pythia proxy for LLaMA target, or vice versa).\n\n7.  More recent data selection methods aren't compared. \n- These are highly relevant methods but are not compared:   DataComp-LM[1],  QuRating[2], Meta-rater[3], QUAD[4].\n\n- Also, it is understandable that works like  [2-3] use external LLMs which costs different FLOPs than training from scratch, making direct cost comparison problematic. However, this paper criticizes methods using external models but doesn't fairly account for when this might be practically cheaper than bilevel optimization.\n\n\n[1] https://arxiv.org/abs/2406.11794\n\n[2] https://arxiv.org/abs/2402.09739\n\n[3] https://arxiv.org/abs/2504.14194\n\n[4] https://arxiv.org/abs/2409.16986"}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6jZ4H67M2d", "forum": "DqAeSBQckF", "replyto": "DqAeSBQckF", "signatures": ["ICLR.cc/2026/Conference/Submission12629/Reviewer_X4zu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12629/Reviewer_X4zu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760901031257, "cdate": 1760901031257, "tmdate": 1762923476277, "mdate": 1762923476277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BLISS (Bilevel Influence Scoring Method for Data Selection), a lightweight data selection approach for language model pretraining, aiming to address the limitations of existing methods.\n\nExisting data selection methods often rely on external pretrained models, making it hard to isolate the effects of data selection from those of external models, while also neglecting the long-term impact of selected data when the model is trained to convergence. BLISS tackles these issues through a novel bilevel optimization framework: it uses a small proxy model as a surrogate for the large language model (LLM) and a score model to estimate the long-term influence of training samples. The upper-level objective optimizes the score model to assign importance weights to samples, ensuring that the lower-level objective (training the proxy model to convergence on weighted training loss) achieves optimal validation performance. After optimization, the score model predicts influence scores for the dataset, enabling efficient selection of high-quality samples."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The existing data selection approach (especially Qurating) depend on large external models (e.g., GPT-3.5), which introduces cost, bias, and reproducibility issues. BLISS avoids this entirely.\n\n2. Rather than estimating sample influence based on short-term updates, BLISS uses a proxy model trained to convergence, offering more reliable evaluation of data utility. \n\n3. The use of lightweight proxy and score models significantly reduces computational cost. The total training FLOPs are lower than baseline methods like MATES. Also, across a range of benchmarks (e.g., SciQ, ARC-E, LogiQA), BLISS consistently outperforms baselines, showing generalization benefits from better data selection.\n\n4. Please explain the motivation for performing data selection to retain a small amount of high-quality data during the pretraining phase, rather than preserving a large amount of clean data (e.g. preserving 70%-80% of the full candidate dataset). For details, please refer to the weaknesses section. Also, please show the training performance when using 10%, 20%, ..., up to 70% of the entire candidate data pool selected by BLISS, as well as when using 70% of clean data obtained through a simple filtering method. This would be very interesting."}, "weaknesses": {"value": "1.  I highly commend the authors for providing standard errors but based on Tables 1 and 2, it appears that the improvements on average task accuracy (over MATES) are well within these reported errors? The only result that seems to not be is round 3 for 2.8B scale. Also, for the topic of \"pre-training\", the experiment scale in this paper is not sufficient. How well the BLISS method generalize to larger model is questionable. When the model becomes large enough, do we still need to select a subset of good examples instead of focusing on getting more high quality data? Also, I think the goal of 'pre-training' is to obtain a strong foundation (unaligned) model that can serve well for later-stage post-training or alignment. However, BLISS introduces a manually specified validation set, which may affect the model's generalization to other tasks. The validation set is more appropriately introduced during the SFT (supervised fine-tuning) or continued pretraining stages, rather than during the pretraining stage.\n\n2. Related to the problem setting, in real-world, when will people do 3B-scale (even 7B-scale) model pre-training from scratch? Usually people either start from a pre-trained checkpoint then do post-training/alignment (for a few specific tasks), or do continuous pre-training/tailpatch training (for knowledge enhancement). If we really need a small scale pre-train ckpt, most likely we will distill a large pre-train ckpt to a smaller model. So how useful this problem setting should be further discussed.\n\n3. Another limitation of this study is that the authors do not fully motivate the problem setting. While cleaning noisy data and removing near-duplicate examples are useful for LLM pretraining, I am not fully convinced why you have to select a subset of “quality data” from the full dataset. For example, if we do a coarse-grained filtering of the original dataset to leave around 70%-80% data and use all of them to do LLM pretraining, will the model performance better."}, "questions": {"value": "1. Can you try combining the validation tasks (e.g. take an average of their performances) for the purposes of targeting?\n\n2. Looking at the MATES paper, it seems you report the same exact numbers for their method. Are you using the exact same training implementation as they did? (Mentioned in NIPS)\n\n3. An assumption for the BLISS approach is that you want to model influence based on training to convergence. However, in practice, most LLMs are pre-trained based upon a finite compute budget rather than true “convergence” (due to the sheer quantities of data involved). Perhaps the authors could comment on this potential mismatch?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gJE8eQ5cuL", "forum": "DqAeSBQckF", "replyto": "DqAeSBQckF", "signatures": ["ICLR.cc/2026/Conference/Submission12629/Reviewer_Uq2j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12629/Reviewer_Uq2j"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761462659645, "cdate": 1761462659645, "tmdate": 1762923475889, "mdate": 1762923475889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BLISS (Bilevel Influence Scoring for Data Selection), a lightweight approach for data selection consisting of two key components: a proxy model and a score model. The proxy model approximates the behavior of a large language model (LLM), while the score model assigns an influence score to each data sample. Experimental results indicate that the proposed method achieves superior performance across multiple downstream tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, clearly organized, and easy to follow.\n2. The proposed bilevel influence scoring framework is conceptually novel and interesting.\n3. The method is straightforward and intuitive—evaluating each data sample individually before selection.\n4. Experimental results convincingly demonstrate the method’s effectiveness across several tasks."}, "weaknesses": {"value": "1. The paper lacks a comparison with the state-of-the-art method [1], which also estimates the influence of individual data samples on model performance. Unlike BLISS, that approach computes influence scores directly on the original LLM using the method from [2], without relying on a proxy model.\n2. The differences between BLISS and [1] are not sufficiently discussed, leaving unclear what advantages the bilevel formulation provides.\n3. The motivation for training a proxy model instead of leveraging the original LLM is not well justified.\n4. Experiments are conducted only on the C4 dataset, raising concerns about generalizability to other pretraining corpora.\n5. The paper lacks an ablation study examining the effect of the number of training rounds or other key hyperparameters.\n\n## Minor Issues\n1. Lines 161–163: The functions F(-) and G(-) are mentioned but not introduced.\n\n\n\n[1] Pan, Yanzhou, et al. \"ALinFiK: Learning to Approximate Linearized Future Influence Kernel for Scalable Third-Parity LLM Data Valuation.\" Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). 2025.\n\n[2] Lin, Huawei, et al. \"Token-wise Influential Training Data Retrieval for Large Language Models.\" Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B1BgZsbaXA", "forum": "DqAeSBQckF", "replyto": "DqAeSBQckF", "signatures": ["ICLR.cc/2026/Conference/Submission12629/Reviewer_5Px2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12629/Reviewer_5Px2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907311001, "cdate": 1761907311001, "tmdate": 1762923475398, "mdate": 1762923475398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes BLISS, a novel bilevel optimization framework for data selection in large language model (LLM) pretraining. Unlike prior works that rely on external pretrained models (e.g., GPT-3.5) to assess data quality, BLISS operates entirely from scratch, using two lightweight models—a proxy model and a score model—to estimate the long-term influence of data samples. The proxy model mimics the target LLM’s behavior via KL divergence, while the score model learns to assign sample importance weights that optimize validation performance when the proxy model is trained to convergence. Experiments on Pythia (410M, 1B, 2.8B) and LLaMA-0.5B models show that BLISS outperforms baselines such as MATES, DSIR, and SemDeDup, achieving up to 1.7× faster convergence and 1.4% average accuracy gains on multiple downstream tasks, with reduced computational cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The use of a bilevel influence scoring mechanism for LLM data selection is innovative and theoretically grounded. It elegantly combines influence estimation with bilevel optimization.\n2. BLISS avoids reliance on pretrained LLMs for scoring, addressing a key limitation in existing methods like QuRating and MATES.\n3. Unlike single-step influence approximations, the framework explicitly models how data affects the model trained to convergence.\n4. The authors present experiments across multiple model sizes (410M–2.8B) and architectures (Pythia, LLaMA), with consistent gains across nine downstream benchmarks.\n5. Despite additional components (proxy and score models), BLISS achieves comparable or better performance with lower FLOPs."}, "weaknesses": {"value": "1. Although bilevel optimization is central, the paper lacks a deeper convergence or approximation analysis for the surrogate models’ fidelity to full-scale LLMs.\n2. While KL divergence is used for alignment, it remains unclear how well the proxy truly represents the LLM across domains. Quantitative metrics of proxy fidelity would strengthen the claims.\n3. Training additional models (even small ones) adds complexity. The paper should analyze memory and runtime scalability for billion-scale pretraining setups.\n4. The choice of validation data (e.g., LAMBADA) could bias data selection toward specific linguistic patterns. An analysis of robustness to different validation datasets would be useful.\n5. The learned scores are treated as black boxes; understanding what kinds of data are preferred (e.g., factual, reasoning-heavy, stylistic) would improve interpretability.\n6. Some ablation results (e.g., single-level vs bilevel) show marginal gains; the statistical significance of these improvements should be better substantiated."}, "questions": {"value": "1. Add a theoretical or empirical analysis of proxy model representativeness.\n2. Report runtime and memory scaling for the bilevel loop.\n3. Discuss potential extensions to multimodal or instruction-tuning datasets, as mentioned in the conclusion.\n4. Improve clarity in algorithmic descriptions—especially the stochastic hypergradient update (Eq. 5) which could benefit from pseudocode-level explanations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AFqUvKcsQ4", "forum": "DqAeSBQckF", "replyto": "DqAeSBQckF", "signatures": ["ICLR.cc/2026/Conference/Submission12629/Reviewer_VCPD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12629/Reviewer_VCPD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12629/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991027287, "cdate": 1761991027287, "tmdate": 1762923474715, "mdate": 1762923474715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}