{"id": "KF7sO7S4kG", "number": 12110, "cdate": 1758205720687, "mdate": 1759897531554, "content": {"title": "Pairwise is Not Enough: Hypergraph Neural Networks for Multi-Agent Pathfinding", "abstract": "Multi-Agent Path Finding (MAPF) is a representative multi-agent coordination problem, where multiple agents are required to navigate to their respective goals without collisions. Solving MAPF optimally is known to be NP-hard, leading to the adoption of learning-based approaches to alleviate the online computational burden. Prevailing approaches, such as Graph Neural Networks (GNNs), are typically constrained to *pairwise* message passing between agents. However, this limitation leads to suboptimal behaviours and critical issues, such as attention dilution, particularly in dense environments where group (i.e. beyond just two agents) coordination is most critical. Despite the importance of such higher-order interactions, existing approaches have not been able to fully explore them. To address this representational bottleneck, we introduce HMAGAT (Hypergraph Multi-Agent Attention Network), a novel architecture that leverages attentional mechanisms over directed hypergraphs to explicitly capture group dynamics. Empirically, HMAGAT establishes a new state-of-the-art among learning-based MAPF solvers: e.g., despite having just 1M parameters and being trained on 100$\\times$ less data, it outperforms the current SoTA 85M parameter model. Through detailed analysis of HMAGAT's attention values, we demonstrate how hypergraph representations mitigate the attention dilution inherent in GNNs and capture complex interactions where pairwise methods fail. Our results illustrate that appropriate inductive biases are often more critical than the training data size or sheer parameter count for multi-agent problems.", "tldr": "", "keywords": ["hypergraph", "group interaction modeling", "imitation learning", "MAPF"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4eb9dc2fc82b6a6ee8f252dda163096374d77cce.pdf", "supplementary_material": "/attachment/0b95abd1fb664b5edd9feaf9dec8987a478fc128.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes HMAGAT, a hypergraph neural network-based approach for Multi-Agent Path Finding (MAPF). The authors argue that existing GNN-based methods are fundamentally limited by pairwise message passing, which leads to attention dilution in dense scenarios and fails to capture group interactions. HMAGAT leverages directed hypergraphs with attention mechanisms to explicitly model higher-order agent interactions. The method achieves impressive empirical results, matching or outperforming MAPF-GPT (85M parameters) while using only 1M parameters and training on 100× less data. The paper includes comprehensive experiments across 10 map types, detailed ablation studies, and insightful analyses using attention distributions and Shapley values."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The core motivation is strong and well-articulated. The observation that pairwise interactions are insufficient for highly-coupled multi-agent coordination problems is intuitive and important. Bringing hypergraph representations to MAPF is a natural and valuable direction—recent work has shown promise for hypergraphs in other multi-agent settings (e.g., trajectory prediction, formation control), and this paper extends that thinking to a challenging planning domain. The research question \"Can hypergraphs scale beyond simple group settings to capture complex, highly-coupled multi-agent tasks?\" is well-posed and addresses a real gap in the literature.\n\nThe attention dilution problem is clearly articulated and convincingly demonstrated. Figure 6 shows that GNN models spread attention across many agents in the middle range, preventing high focus on truly critical interactions, while HGNN maintains better differentiation. The hand-crafted Scenario 1 illustrates this effectively—as irrelevant agents are added to less important regions, GNN's attention to important agents becomes increasingly variable, while HGNN remains stable. This is a genuine problem that matters in practice.\n\nThe Shapley value analysis in Scenario 2 provides valuable interpretability. The results effectively demonstrate that the model captures group coordination patterns—showing substantially higher influence for agents involved in coupled interactions compared to isolated ones, despite symmetric spatial positions. This kind of mechanistic understanding is useful and relatively uncommon in multi-agent learning papers.\n\nThe experimental evaluation is comprehensive and well-designed. Testing across 10 diverse map types with varying densities provides solid evidence. The Dense Warehouse results are particularly striking, showing dramatic improvements in success rates at high agent densities where baseline methods struggle significantly. The ablation study properly isolates contributions, and the progression shows consistent improvement. The paper is clearly written with good visualizations, and the promised code release aids reproducibility.\n\nThe parameter efficiency and inference speed improvements are practically significant. These gains matter for real-world deployment in warehouse automation or traffic management scenarios."}, "weaknesses": {"value": "My primary concern is that while the motivation is sound, the execution lacks depth. The architecture in Equations (1)-(4) adopts standard hypergraph attention formulations without meaningful adaptation to MAPF's specific structure. I appreciate that you're bringing hypergraphs to this domain, but the technical contribution feels more like careful engineering than methodological advancement. For instance, you could exploit MAPF-specific structure—agents have goals, there are collision constraints, paths have temporal dynamics—but the hypergraph construction treats this as a generic spatial proximity problem. The Lloyd/k-means/shortest-distance strategies are standard clustering approaches applied fairly directly. Given that hypergraphs have been explored in related multi-agent domains, I'd expect deeper innovation in how the representation is tailored to pathfinding constraints and objectives.\n\nThe training data disparity undermines the paper's central claim. You train on 21K instances while MAPF-GPT uses 3.75M—a 100× difference. The conclusion that \"appropriate inductive biases are often more critical than training data size or sheer parameter count\" is stated boldly but not properly validated. You're comparing two confounded variables simultaneously (architecture AND data scale), making it impossible to isolate the effect. It's entirely plausible that MAPF-GPT is simply undertrained relative to its capacity. I recognize that generating millions of expert trajectories is expensive, but at minimum, you should show MAPF-GPT trained on your 21K instances to establish whether the gap persists under equal data conditions. This is a fundamental experimental control that's missing, and it weakens confidence in the main message.\n\nThe theoretical foundation is thin. You provide no formal analysis of when or why hypergraphs should outperform GNNs beyond intuition and two constructed scenarios. What types of coordination patterns can HGNNs represent that GNNs cannot? Are there expressiveness results or approximation guarantees? The attention dilution observation is insightful but empirical—showing it occurs systematically across many real benchmark instances (not just hand-crafted examples) would be more convincing. The paper would benefit substantially from even informal theoretical characterization of the representational differences.\n\nThe hypergraph generation lacks principled justification. Why these specific strategies? The shortest-distance method shows mixed results across different maps and has higher computational overhead, yet there's no clear guidance on when each strategy is appropriate. The \"soft boundary\" operation (discarding half the colors) appears to be a critical tuning choice but receives minimal discussion—what happens with different percentages? More fundamentally, there's no framework for thinking systematically about hypergraph design for MAPF. Should edges capture potential conflicts? Goal proximity? Historical collision patterns? The approach feels somewhat ad-hoc rather than principle-driven.\n\nThe failure analysis is missing. Even in scenarios where HMAGAT performs best, failure rates remain. What are these failure modes? Are they timeouts, deadlocks, or inefficient paths? Understanding when hypergraphs don't help would provide important insight into the method's limitations and scope."}, "questions": {"value": "1. The 100× training data difference between HMAGAT (21K) and MAPF-GPT (3.75M) is my biggest concern. Can you train MAPF-GPT on your 21K instances and report results? This would isolate whether your gains come from architectural improvements or simply from the baseline being undertrained.\n\n2. Can you provide some theoretical analysis—even informal—about what makes hypergraphs better suited for MAPF?\n\n3. What are the typical failure modes when HMAGAT doesn't succeed? Understanding when hypergraphs fail would help clarify their scope of applicability.\n\n4. Can you demonstrate that attention dilution happens systematically in real benchmark runs, not just the two hand-crafted scenarios? Maybe show attention statistics across many Dense Warehouse episodes?\n\n5. How much wall-clock time does training take for HMAGAT compared to MAGAT? What's the computational overhead of hypergraph construction?\n\n6. What guidance would you give practitioners for choosing between Lloyd, k-means, and shortest-distance strategies? When does each work best?\n\n7. How sensitive is performance to hyperparameters like k (number of colors), R^comm, and R^obs?\n\nThe core idea here is interesting and the paper is generally well-written. The motivation for using hypergraphs in dense coordination scenarios resonates with me, and the empirical results look promising. That said, the training data confound and lack of theoretical grounding  are issues that need addressing. I'm also curious about the failure analysis  and whether attention dilution is a systematic phenomenon  or mainly visible in constructed examples. If the rebuttal can provide satisfactory answers to these concerns, particularly the first two, I'd be happy to reconsider my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DXscMG4SaH", "forum": "KF7sO7S4kG", "replyto": "KF7sO7S4kG", "signatures": ["ICLR.cc/2026/Conference/Submission12110/Reviewer_YpAe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12110/Reviewer_YpAe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790433252, "cdate": 1761790433252, "tmdate": 1762923076647, "mdate": 1762923076647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HMAGAT, a hypergraph-based extension of the MAGAT framework for multi-agent pathfinding. The core idea is to capture higher-order agent interactions beyond pairwise relationships by representing agent dependencies through hyperedges. The method integrates several enhancements, including observation encoding improvements, post-training quality optimization, and temperature-based sampling during inference. The authors evaluate HMAGAT across multiple benchmark MAPF environments, comparing it to state-of-the-art learning-based methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is generally well-written and clearly structured. The graphical illustrations are clear and informativel.\n- The experimental evaluation includes a solid and well-chosen set of test maps.\n- HMAGAT demonstrates strong empirical performance across a diverse set of benchmarks, showing both scalability and robustness."}, "weaknesses": {"value": "W1: The motivational example in Figure 1(c) is unclear, and I do not fully understand what prevents models such as MAPF-GPT from learning an optimal policy when expert data for this case are provided. It would be helpful if the authors clarified what exactly is meant by pairwise interactions in MAPF and why these interactions would limit a learnable model from reproducing the expert’s optimal SoC solution. A formal definition or additional explanation would make the example more convincing.\n\nW2: Based on the ablation results in Figure 5, the final performance appears to stem from multiple components, including Hypergraphs, OE Quality Improvement, Post-Train Quality Improvement, and Temperature Sampling. As a result, the initial motivation regarding pairwise interactions seems less supported, and the impact of the hypergraph component does not appear dominant. This also suggests that the paper’s focus on hypergraphs for highly-coupled multi-agent problems is somewhat overshadowed by the combination of techniques used to outperform current learnable MAPF approaches. \n\nW3: The proposed approach builds on several prior methods and involves a multi-stage, complex pipeline, including the MAGAT base, the addition of Hypergraphs and a mechanism to prepare observations, offline training on expert data, subsequent online fine-tuning, and a separate RL-trained model for temperature sampling. While this combination achieves strong performance, it raises concerns about the overall simplicity and generality of the approach. Relying on heavily staged, task-specific designs may limit scalability and the ability to leverage general computation, suggesting that more unified or end-to-end approaches could be more broadly effective.\n\nW4:  I’m not entirely convinced that collision shielding should be applied to all approaches (as recommended by Veerapaneni et al., 2025). This suggestion is not theoretically motivated, and based on decision-making theory, it effectively changes the policy. We can consider two policies: $\\pi$, the default one, and $sh(\\pi)$, the policy with shielding. When performing imitation learning from an expert, applying shielding introduces a distributional shift. \n\nFor MAPF-GPT-85M, this works well because the model is trained on expert data where no collisions occur, so shielding helps, even with the shift between PIBT and LaCAM. However, for MAPF-GPT-DDG-2M, this is not the case, since the model was fine-tuned and the model performance was influenced by its own behavior.\n\nFormally, since the policy determines the trajectory of states, applying shielding changes the state distribution: $s_{t+1} \\sim P(\\cdot \\mid s_t, a_t), \\quad a_t \\sim \\pi(a_t \\mid s_t)$ versus $s'_{t+1} \\sim P(\\cdot \\mid s'_t, a'_t), \\quad a'_t \\sim sh(\\pi)(a'_t \\mid s'_t),$\n\nwhich implies that $p(s_t) \\neq p(s'_t)$ and consequently $p(o_t) \\neq p(o'_t)$, where $o_t$ denotes agent' observation at time $t$. Thus, shielding induces a distinct observation distribution, on which the model was not trained.\n\nThe proper approach, in my view, is to fine-tune MAPF-GPT-DDG in an environment that includes shielding to eliminate this inconsistency.\n\nW5: Following up on the previous weakness, I believe it is not entirely fair to apply modifications to existing approaches without conducting a proper ablation study. It is not clear how shielding influences the algorithms to which it was applied. While the authors provide some ablation results in Table 5 of the appendix, a more thorough analysis would involve testing all approaches both with and without shielding, and reporting the complete set of metrics (including success rate, SoC, and runtime).\n\nW6: It seems to be an overstatement in the experimental results that HMAGAT consistently outperforms larger models, except for MAPF-GPT-85M. For example, MAPF-GPT-DDG (2M) shows better performance in instances with a large number of agents for the Sparse Maze and Dense Room scenarios, and comparable performance in the Empty Room and Dense Maze environments. Moreover, despite achieving better or similar success rates, MAPF-GPT-DDG exhibits lower performance in terms of SoC, which appears counterintuitive. It would be helpful if the authors investigated this further and provided an explanation of how these plots were generated. \n\nDespite the major concerns raised, I remain open to discussion and willing to adjust my score depending on how the identified weaknesses are addressed."}, "questions": {"value": "Q1: How does adding PIBT shielding affect the model’s runtime performance?\n\nQ2: The runtime spikes observed seem unusual for the MAPF-GPT family (especially on _ost003d_). Did the authors investigate this behavior, and how exactly was runtime measured or computed?\n\nQ3: Were the authors willing to provide the raw testing data or the code  to run a full evaluation (script to run all testing instances) of the proposed approach?\n\nQ4: How much GPU time is required to reproduce the testing results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PeNEEQJpn3", "forum": "KF7sO7S4kG", "replyto": "KF7sO7S4kG", "signatures": ["ICLR.cc/2026/Conference/Submission12110/Reviewer_KnuG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12110/Reviewer_KnuG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929308802, "cdate": 1761929308802, "tmdate": 1762923076200, "mdate": 1762923076200, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes HMAGAT, a hypergraph-based imitation learning framework for Multi-Agent Path Finding (MAPF). It argues that pairwise interaction modeling, as commonly done via GNNs or transformers, is insufficient for capturing the inherently group-based dependencies among agents. By introducing directed hypergraph attention layers, HMAGAT captures higher-order interactions, leading to improved solution quality and scalability. The model achieves strong empirical results, outperforming prior SOTA while using little data and parameters."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper convincingly argues that MAPF requires modeling joint dependencies beyond pairwise interactions. The use of hypergraphs is theoretically justified as a natural representation of group interactions, which is both elegant and underexplored in this context.\n\n2.\tHMAGAT extends the MAGAT architecture by replacing GNN layers with hypergraph attention modules and introducing dynamic hypergraph generation strategies. The directionality and adaptive nature of these hyperedges introduce inductive biases that align well with MAPF’s structure.\n\n3.\tThe experimental section is robust, spanning multiple map types (small, sparse, dense, and large). HMAGAT demonstrates substantial gains in Sum of Costs (SoC) and success rates, especially in high agent-count and dense environments. The runtime analysis shows HMAGAT is faster and more scalable than MAPF-GPT while maintaining solution quality."}, "weaknesses": {"value": "1.\tWhile the motivation is clear, the paper lacks a formal analysis of why and under what conditions hypergraph attention improves over pairwise attention. A discussion of expressivity (e.g., via Weisfeiler-Lehman hierarchy or permutation invariance properties) could strengthen the theoretical foundation.\n\n2.\tAlthough HMAGAT scales better than MAPF-GPT, it is not evident how hypergraph construction costs scale with agent counts beyond the tested benchmarks. The paper would benefit from a complexity analysis or ablation of hypergraph size versus performance.\n\n3.\tAll evaluations are performed on Pogema-like benchmarks. It remains unclear how HMAGAT performs on out-of-distribution environments (e.g., dynamic obstacles, non-grid worlds). Including cross-domain tests or transfer experiments would strengthen the empirical story.\n\n4.\tThe ablation study focuses on performance comparisons but could better disentangle the contributions of hypergraph generation, attention mechanisms, and training data reduction. It’s difficult to isolate which aspect contributes most to the gains."}, "questions": {"value": "1.\tHow are the hyperedges dynamically generated during training and inference? Are they based purely on spatial proximity, or do they incorporate learned attention or communication priors?\n\n2.\tCan the authors formalize or provide intuition for how HMAGAT captures higher-order dependencies that are provably beyond the capacity of pairwise GNNs or transformers?\n\n3.\tWhat is the asymptotic complexity of HMAGAT’s message passing with respect to the number of agents and hyperedges? Is there a practical limit where hypergraph construction becomes prohibitive?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "edLnREQ8ml", "forum": "KF7sO7S4kG", "replyto": "KF7sO7S4kG", "signatures": ["ICLR.cc/2026/Conference/Submission12110/Reviewer_VXsq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12110/Reviewer_VXsq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996756367, "cdate": 1761996756367, "tmdate": 1762923075797, "mdate": 1762923075797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to address the limitation of GNN-based approached for MAPF that relies on message passing between pairs of agents. However, in dense environments, it requires higher-order group interaction where a large number of irrelevant neighbors reduce the focus on critical agents. The paper proposes HMAGAT, which is an imitation learning framework that uses HGNN to model group dynamics. The architecture is a CNN-> HGNN -> MLP. The hyper graph generation strategies include k-mean, Lloyd’s alogirhtm and shortest-distance based heuristics. Empirically, HMAGAT outperforms state-of-the-art with smaller network sizes and less training data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It is a novel application of hypergraphs to scale on large MAPF instances. \n2. The integration of multiple hyper graph generation methods is a new contribution.\n3. The analysis of HGNN vs GNN provides a good insight into why HGNN is better than GNN."}, "weaknesses": {"value": "1. The main weakness is the lack of non-ML baselines, such as simple methods like priority planning and more advanced solvers like Large Neighborhood Search or LACAM mentioned in the paper. Those are very efficient and effective solvers that can scale to instances as large as those evaluated in the paper.\n2. It isn’t clear how the Rel. SoC metric is computed. See questions."}, "questions": {"value": "When you compute the Rel. Soc, how do you deal with the instances that are unsolved, especially when a. different solvers solve a different set of instances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aWyOY6b6kb", "forum": "KF7sO7S4kG", "replyto": "KF7sO7S4kG", "signatures": ["ICLR.cc/2026/Conference/Submission12110/Reviewer_5P7E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12110/Reviewer_5P7E"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762027362119, "cdate": 1762027362119, "tmdate": 1762923075438, "mdate": 1762923075438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}