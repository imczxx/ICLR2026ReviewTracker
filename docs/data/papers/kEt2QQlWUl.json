{"id": "kEt2QQlWUl", "number": 2126, "cdate": 1756994339298, "mdate": 1762941644709, "content": {"title": "ManiCoG: Training-Free Improvement for GUI Grounding via Manipulation Chains", "abstract": "GUI grounding is a critical capability for enabling GUI agents to execute tasks such as clicking and dragging. \nHowever, in complex scenarios like the ScreenSpot-Pro benchmark, existing models often suffer from suboptimal performance. \nUtilizing the proposed Masked Prediction Distribution (MPD) attribution method, we identify that the primary sources of errors are twofold: \nhigh image resolution (leading to precision bias) and intricate interface elements (resulting in ambiguity bias). \nTo address these challenges, we introduce the Manipulation-based Chain of GUI Grounding (ManiCoG), which incorporates two key manipulations, coarse-to-fine focus and candidate selection, to effectively mitigate these biases. \nOur extensive experimental results demonstrate that ManiCoG significantly enhances the accuracy of various GUI grounding models in a training-free setting. \nFor instance, applying our method to the TianXi-Action-7B model boosts its accuracy on the ScreenSpot-Pro benchmark from 51.9\\% to 57.8\\%. \nFurthermore, ablation studies confirm the robustness of the ManiCoG approach across diverse parameter configurations, highlighting its stability and effectiveness.", "tldr": "", "keywords": ["GUI Grounding", "Test-Time Scaling", "GUI Agent"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/923b5639c2327c8a2edf2c14db926a0b4866f1fb.pdf", "supplementary_material": "/attachment/5cb34d6d218cf3bf7fa40a60ba80fc3b3522c528.zip"}, "replies": [{"content": {"summary": {"value": "This research addresses the suboptimal performance of existing models on the GUI grounding task in complex scenarios, such as the ScreenSpot-Pro benchmark. It proposes the Masked Prediction Distribution (MPD) attribution method to identify two core sources of error: precision bias caused by high image resolution and ambiguity bias resulting from intricate interface elements.To tackle these issues, the study introduces the ManiCoG (Manipulation-based Chain of GUI Grounding) framework. This framework enhances model performance without requiring additional training by employing two key operations: coarse-to-fine focusing to mitigate precision bias and candidate selection to alleviate ambiguity bias. For example, ManiCoG improves the accuracy of the TianXi-Action-7B model on the ScreenSpot-Pro benchmark from 51.9% to 57.8%.Furthermore, ablation studies have verified the robustness of this method under various parameter configurations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Proposed the MPD attribution method to systematically diagnose the three primary sources of error in GUI grounding for the first time: knowledge gap, precision bias, and ambiguity bias.\n\n2.Designed coarse-to-fine focusing and candidate selection operations to specifically mitigate precision bias and ambiguity bias, respectively.\n\n3.Validated the effectiveness of the training-free paradigm by achieving stable improvements across 3 models and 2 benchmarks, offering a new direction for the optimization of the inference stage in GUI grounding."}, "weaknesses": {"value": "1.I noticed that the main body of the paper only presents the experimental results on ScreenSpot-pro, while the results for ScreenSpot-v2 are in the appendix. However, the improvement of ManiCoG on ScreenSpot-v2 is quite limited, with UI-TARS-1.5-7B only achieving a 0.1 increase in average accuracy.\n\n2.The entire process is complex. It first goes through a coarse-to-fine region amplification, followed by a selection among candidate boxes. A prerequisite for this candidate box selection is that the correct answer must be generated during the candidate generation stage, which relies to some extent on randomness.\n\n3.The selection of candidate boxes depends on the reasoning and selection of a more powerful external model. However, a crucial consideration in the field of GUI agents is how to enable the agent to complete tasks faster and better. A two-stage refinement at test-time will significantly increase the agent's decision-making latency, leading to a lot of unnecessary overhead."}, "questions": {"value": "please see weakness. If my concerns are addressed, I will consider raising my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ggUHzlZ6IS", "forum": "kEt2QQlWUl", "replyto": "kEt2QQlWUl", "signatures": ["ICLR.cc/2026/Conference/Submission2126/Reviewer_4SEP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2126/Reviewer_4SEP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2126/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760614275872, "cdate": 1760614275872, "tmdate": 1762916042478, "mdate": 1762916042478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "rKaTod7ekM", "forum": "kEt2QQlWUl", "replyto": "kEt2QQlWUl", "signatures": ["ICLR.cc/2026/Conference/Submission2126/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2126/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762939973211, "cdate": 1762939973211, "tmdate": 1762939973211, "mdate": 1762939973211, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a test-time computation scaling strategy to improve GUI grounding accuracy for GUI agents. Their approach leverages Masked Prediction Distribution (MPD) to analyze failure cases in grounding predictions and introduces two strategies: coarse-to-fine focus and candidate selection. These are evaluated on GUI grounding benchmarks using multiple backbones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The method is conceptually straightforward and well-motivated.\n- The manuscript is well-written and clearly structured. \n- The authors provide ablation studies on their two key components, which support their claims empirically."}, "weaknesses": {"value": "- One major concern is that the novelty of the proposed method is highly limited. Unfortunately, the core ideas and findings largely overlap with those of prior work, particularly R-VLM. For instance, R-VLM already adopts a coarse-to-fine grounding strategy and explicitly analyzes precision bias, where the model correctly identifies the target region but exhibits a consistent spatial offset. Furthermore, the ambiguity bias that the authors mentioned is also thoroughly discussed in R-VLM, and closely aligns with the motivation behind its IoU-aware loss function. These conceptual overlaps significantly diminish the originality of the current work. Moreover, regarding the knowledge gap issue, multiple prior works have demonstrated that scaling up pretraining data can effectively mitigate this problem (e.g., OSATLAS, UGround). Similarly, the issue of high-resolution input for accurate GUI understanding has also been emphasized in earlier studies—most notably in CogAgent, which directly addresses this limitation.\n\n- The candidate selection module appears to be the most original component, yet its reliance on hand-crafted heuristics diminishes its impact. If the authors aim to claim originality, they must clearly delineate **how their method differs from existing approaches**. In its current form, Section 2.3 is especially underdeveloped in this regard. A more rigorous positioning within the related literature is strongly recommended.\n\n- Another important limitation is the lack of evaluation on agent tasks. While GUI grounding performance is analyzed, it remains unclear whether improvements in candidate selection or coarse-to-fine focus  translate into downstream agent success (e.g., task completion rates). Evaluation on real-world agent tasks such as AITW, MiniWob, or Mind2Web would strengthen the paper’s practical relevance."}, "questions": {"value": "- One additional point worth considering is whether test-time scaling must be applied uniformly to all test cases. In practice, some instances may already be trivial to resolve without additional computation, and indiscriminate application of scaling strategies may lead to unnecessary overhead. Introducing a selective or adaptive mechanism—for example, based on grounding difficulty—could further enhance the efficiency of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wXpPqPY0cx", "forum": "kEt2QQlWUl", "replyto": "kEt2QQlWUl", "signatures": ["ICLR.cc/2026/Conference/Submission2126/Reviewer_AR8p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2126/Reviewer_AR8p"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2126/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761762526095, "cdate": 1761762526095, "tmdate": 1762916042343, "mdate": 1762916042343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ManiCoG, a training-free inference framework designed to improve the accuracy of GUI grounding models. From observed model failure modes, the authors propose a framework to address the main challenges via a coarse-to-fine grounding process. The empirical results are strong, and the method is effective for many GUI grounding models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Strong motivation. The paper's primary contribution is not just the solution, but the diagnosis of error analysis.\n\n- Good Empirical Results: The method demonstrates clear and consistent performance improvements. The gains are shown to be generalizable across multiple different base models, reinforcing the claim that this is a robust, backbone-agnostic enhancement."}, "weaknesses": {"value": "- Novelty and missing baseline. The method is similar to a method proposed in the ScreenSpotPro benchmark called \"ScreenSeeker\", which also adopts a coarse-to-fine focusing and selection design. It is confusing that the paper uses the benchmark but ignores the method. What is the main difference between ManiCoG and it?\n\n- What is the cost of ManiCoG, time-wise and cost-wise?\n\n- Potentially unfair comparison: The settings of GUI-RC and DiMo-GUI  are not described in the paper, making it hard to compare between the methods. What planning model is used in the \"ManiCoG-7B\" result in Table 2? Do GUI-RC and DiMo-GUI also use extra planning models?"}, "questions": {"value": "Please refer to the points in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bRMUUWq6NI", "forum": "kEt2QQlWUl", "replyto": "kEt2QQlWUl", "signatures": ["ICLR.cc/2026/Conference/Submission2126/Reviewer_Sv89"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2126/Reviewer_Sv89"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2126/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917502092, "cdate": 1761917502092, "tmdate": 1762916041945, "mdate": 1762916041945, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}