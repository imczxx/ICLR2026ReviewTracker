{"id": "kbps463Pdf", "number": 17095, "cdate": 1758272074034, "mdate": 1759897198609, "content": {"title": "Unifying Complexity-Theoretic Perspectives on Provable Explanations", "abstract": "Previous work has explored the computational complexity of deriving two fundamental types of explanations for ML model predictions: (1) *sufficient reasons*, which are subsets of input features that, when fixed, determine a prediction, and (2) *contrastive reasons*, which are subsets of input features that, when modified, alter a prediction. Prior studies have examined these explanations in different contexts, such as non-probabilistic versus probabilistic frameworks and local versus global settings. In this study, we introduce a unified framework for analyzing these explanations, demonstrating that they can all be characterized through the minimization of a unified probabilistic value function. We then prove that the complexity of these computations is influenced by three key properties of the value function: (1) *monotonicity*, (2) *submodularity*, and *supermodularity*. Our findings uncover some counterintuitive results regarding the nature of these properties within the explanation settings examined. For instance, although the *local* value functions do not exhibit monotonicity or submodularity/supermodularity whatsoever, we demonstrate that the *global* value functions do possess these properties. This distinction enables us to prove a series of novel polynomial-time results for computing various explanations with provable guarantees in the global explainability setting, across a range of ML models that span the interpretability spectrum, such as neural networks, decision trees, and tree ensembles. In contrast, we show that even highly simplified versions of these explanations become NP-hard to compute in the corresponding local explainability setting.", "tldr": "", "keywords": ["explainability", "interpretability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/be1da6abada229a434e187d1654098590543a719.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents new findings in the field of formal explainable artificial intelligence (XAI), focusing on the complexity of sufficient and contrastive explanations, including their probabilistic variants. The authors introduce a unified framework that covers both local and global explanations, providing insights into the complexity and approximability of subset-minimal and cardinality-minimal explanations.\n\nThe key takeaway from this study is that global probabilistic explanation problems differ significantly from local ones in terms of computational complexity and approximability. Specifically, the objective function for both sufficient and contrastive global probabilistic explanations is monotone increasing (Proposition 2). Additionally, when dealing with joint distributions, the objective function exhibits supermodularity for sufficient global probabilistic explanations (Proposition 3) and submodularity for contrastive global probabilistic explanations (Proposition 4). In contrast, local probabilistic explanations lack these properties.\n\nThe authors also focus on empirical distributions, where the objective function can be evaluated in polynomial time for various classifiers. They combine the aforementioned properties with standard greedy algorithms to reveal new results. Notably, subset-minimal global explanations can be computed efficiently for empirical distributions (Theorem 2), and cardinality-minimal global explanations are approximable (up to curvature and a logarithmic term) for empirical joint distributions (Theorems 3 and 4)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**S1.** Despite the paper's dense and technical nature, it is well-articulated: the notation is clear, and the results are easy to understand.\n \n**S2.** The related work is well-detailed, including most relevant references. \n\n**S3.** The unified framework that encompasses both local and global explanations, including probabilistic approaches, is intuitive. \n\n**S4.** To my knowledge, Propositions 2, 3, and 4 appear to be novel contributions. In most cases, the negative results are not straightforward."}, "weaknesses": {"value": "**W1.** I find Algorithm 2 confusing, as it seems incorrect; the marginal gain should be maximized. \n\n**W2.** I think that the positive results presented in the main theorems (1-4) are primarily applications of existing findings. \n\n**W3.** Theorem 4 does not truly deliver a constant-factor approximation, as the curvature could be unbounded. \n\n**W4.** The upper bounds for Theorems 3 and 4 appear somewhat loose, and these approximation results lack lower bounds necessary to establish tightness. \n\n**W5.** Finally, the practicality of Theorems 3 and 4 is questionable, given that empirical “joint” distributions are rarely available in real-world scenarios."}, "questions": {"value": "------------------------------\n### Major Comments:\n------------------------------\n\n**C1**. As mentioned earlier, I found Algorithm 2 to be confusing. Typically, a greedy algorithm aims to maximize the marginal gain at each step, which is especially true for the greedy set-cover method. Therefore, unless I missed something, I believe that in Line 3, the `argmin` function should be replaced with an `argmax` function. Consequently, the comment in Line 428 should also be revised accordingly.\n\n**C2**. Essentially, the approximation factor for Theorem 3 consists of a logarithmic term (related to the number of data instances), while the approximation factor for Theorem 4 includes both a logarithmic term and a curvature term. Can we bound the curvature term? If not, the fourth contribution mentioned in the introduction (Lines 120-126) should be rephrased to reflect this.\n\n**C3**. In light of the previous comment, could the authors provide tight lower bounds for Theorems 3 and 4? Specifically, for large datasets, a bound of the form $\\log |D|$ in Theorem 3 seems quite loose. However, if the authors demonstrate that approximating the problem within a factor of $(1 - \\epsilon) \\ln |D|$ is NP-hard, this would strengthen the result. A similar observation applies to Theorem 4, given that the curvature can be significant.\n\n**C4**. In Theorems 2-4, the assumption regarding “empirical” distributions is reasonable; otherwise, the problem could be PP-hard. However, combining this assumption with the condition that $\\mathcal D$ is also a “joint” distribution appears unrealistic in practice. Do the authors envision practical scenarios where we need to globally explain a model trained on a dataset with samples drawn from a joint distribution? At present, I find this result to be primarily of theoretical interest, as I have not identified concrete applications for it.\n\n-----------------\n### Minor Comments:\n------------------\n\n**C5**. In Section 2 (Setting), I suggest introducing the main notation, including the input dimension ($n$), the number of classes ($c$), the underlying distribution ($\\mathcal D$), and the training set ($\\mathbf D$ or $\\mathbf Z$). Additionally, I would like to ask why you are using the subscript $p$ in $\\mathcal D_p$; I would recommend simply using $\\mathcal D$. Throughout the rest of the paper, I suggest maintaining consistent notation (for example, choose either P or PTIME, but not both).\n\n**C6**. Based on the proof provided, I believe that Theorem 1 applies not only to decision trees but also to orthogonal DNF formulas (i.e., \"1-satisfy\" DNF formulas). Given that there exists a Fully Polynomial Randomized Approximation Scheme for counting models of arbitrary DNF formulas, I am also curious whether we could find an approximation result for identifying minimal subset global explanations under the uniform distribution.\n\n**C7**. Section 8 is acceptable, but it could be more informative. I recommend including some key open questions that arise from this theoretical study. For instance, can we establish better approximation bounds for minimal-size global explanations when the classifier is a simple function, such as a decision tree or a linear threshold function?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FK4gPZPLcV", "forum": "kbps463Pdf", "replyto": "kbps463Pdf", "signatures": ["ICLR.cc/2026/Conference/Submission17095/Reviewer_cPWT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17095/Reviewer_cPWT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760807288939, "cdate": 1760807288939, "tmdate": 1762927098387, "mdate": 1762927098387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for unifying two types of explanations: contrastive and sufficient reason explanations. The framework models both explanations as minimisations of a value function."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- Clear research question and contribution\n- A lot of novel (formal) insights are generated, which I consider to be valuable for the XAI community."}, "weaknesses": {"value": "- Readability and accessibility can be improved. Most importantly, it looks to me that sufficient reasons are the same as semi-factual explanation, and global contrastive reasoning seems to describe goup/multi-instance counterfactuals. Since semi and counterfactuals are popular and widely used terms in the XAI community, I suggest clearly relating them to the concepts introduced and discussed in this paper. By this, the paper and its contribution will become accessible to a wider audience.\n\nMinor:\n- Line 232 \"smaller\" in XAI people often talk about \"simpler explanation\". I suggest clarifying the meaning of \"smaller\" and also including \"simpler\" to make the paper more accessible to other researchers"}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "g78DzolaTI", "forum": "kbps463Pdf", "replyto": "kbps463Pdf", "signatures": ["ICLR.cc/2026/Conference/Submission17095/Reviewer_uoPW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17095/Reviewer_uoPW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761555721205, "cdate": 1761555721205, "tmdate": 1762927097641, "mdate": 1762927097641, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified framework for explanation complexity. Global value functions are monotone; under feature independence, sufficient variants are supermodular and contrastive variants submodular. This yeilds polynomial-time algorithms for subset-minimal global explanations and approximations for cardinality-minimal ones. Local explanations remain NP-hard."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The global versus local structural distinction appears to be new. Monotonicity holds without independence. Proofs are rigorous with counterexamples showing the necessity of assumptions."}, "weaknesses": {"value": "Feature independence is required for approximation results. This limits practical applicability where features correlate."}, "questions": {"value": "Could you clarify the candidate set specification in Algorithm 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "8iGw6plVkW", "forum": "kbps463Pdf", "replyto": "kbps463Pdf", "signatures": ["ICLR.cc/2026/Conference/Submission17095/Reviewer_qstK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17095/Reviewer_qstK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825740745, "cdate": 1761825740745, "tmdate": 1762927097195, "mdate": 1762927097195, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}