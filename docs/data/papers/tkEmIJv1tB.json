{"id": "tkEmIJv1tB", "number": 4225, "cdate": 1757642162580, "mdate": 1759898046322, "content": {"title": "OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning", "abstract": "Recent advances in multimodal large language models (MLLMs) have opened new opportunities for embodied intelligence, enabling multimodal understanding, reasoning, and interaction, as well as continuous spatial decision-making. Nevertheless, current MLLM-based embodied systems face two critical limitations. **First, Geometric Adaptability Gap** models trained solely on 2D inputs or with hard-coded 3D geometry injection suffer from either insufficient spatial information or restricted 2D generalization, leading to poor adaptability across tasks with diverse spatial demands. **Second, Embodiment Constraint Gap**: prior work often neglects the physical constraints and capacities of real robots, resulting in task plans that are theoretically valid but practically infeasible. To address these gaps, we introduce **OmniEVA** -- an embodied versatile planner that enables advanced embodied reasoning and task planning through two pivotal innovations: (1) a **Task-Adaptive 3D Grounding** mechanism, which introduces a **gated router** to perform explicit selective regulation of 3D fusion based on contextual requirements, enabling context-aware 3D grounding for diverse embodied tasks. (2) an **Embodiment-Aware Reasoning** framework that jointly incorporates task goals and embodiment constraints into the reasoning loop, resulting in planning decisions that are both goal-directed and executable. Extensive experimental results demonstrate that OmniEVA not only achieves **state-of-the-art** general embodied reasoning performance, but also exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks, including both primitive and composite tasks, confirm its robust and versatile planning capabilities.", "tldr": "", "keywords": ["Embodied AI", "Embodied Reasoning", "Spatial Reasoning", "Multimodal Large Language Models", "3D Large Language Models"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a215feac1bfeca23b6ce7b68c1a66766368b833b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper primarily focuses on improving spatial reasoning, task planning, and embodiment feasibility within vision-language models (VLMs). Specifically, it introduces a gating mechanism to selectively fuse token-wise 2D visual features with their corresponding 3D representations, enhancing the model’s ability to absorb and reason over 3D information. Moreover, it incorporates task reward and embodiment feasibility objectives to strengthen the framework’s awareness of both task completion effectiveness and compliance with embodied physical constraints."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Enhancing the VLM’s understanding of 3D spatial structures is highly necessary, and enabling it to be aware of the robot’s embodiment feasibility is an important and well-motivated goal.\n\nThe introduction of the gating mechanism, task reward, and embodiment feasibility reward is conceptually sound and appears technically reasonable.\n\nThe experimental evaluation is comprehensive—covering diverse benchmarks that include 3D spatial reasoning, sub-goal localization in 3D environments, and 2D embodied reasoning tasks."}, "weaknesses": {"value": "The overall writing quality is poor. Although the structure is generally acceptable, many paragraphs lack clear focus, and several sentences are unnecessarily verbose, leading to poor readability and coherence.\n\nSome key sections lack sufficient detail. For instance, several tasks are introduced without intuitive explanations — while I understand that detailed descriptions are provided in the appendix, a concise and intuitive introduction in the main text is still necessary. Moreover, the design and acquisition process of the newly introduced rewards are not clearly explained.\n\nThe baselines in Table 1 resemble an ablation study, and the effectiveness of the proposed gating mechanism is not convincingly demonstrated by the presented results."}, "questions": {"value": "Could you elaborate on how the task reward and embodied feasibility rewards are specifically designed and obtained?\n\nIn Table 3, did the baseline models also utilize the training datasets from these benchmarks?\n\nIn the real-world experiments, how does the model’s pick-and-place reasoning interface with and control the low-level policy?\n\nSince embodiment awareness depends on hardware characteristics, and different hardware platforms have varying physical constraints, how does the proposed method generalize or adapt to these differences?\n\nCan you provide a comparison of the reasoning time across models or settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eLPBDa19vi", "forum": "tkEmIJv1tB", "replyto": "tkEmIJv1tB", "signatures": ["ICLR.cc/2026/Conference/Submission4225/Reviewer_BYjf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4225/Reviewer_BYjf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794143088, "cdate": 1761794143088, "tmdate": 1762917239224, "mdate": 1762917239224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies two main limitations of current embodied planners (Geometric Adaptability Gap and Embodiment Constraint Gap) and presents a \"embodied versatile planner\" that uses MLLMs for embodied tasks by introducing two innovations: 1. Task-Adaptive 3D Grounding mechanism using a gated router for explicit, selective 3D feature integration, and 2. embodiment-aware reasoning and training framework that explicitly factors in real-world physical constraints during task planning and learning. Experiments on a range of embodied reasoning benchmarks—including 2D, 3D, and physically grounded settings—demonstrate OmniEVA's performance advantages and improved executability in simulated and, to some degree, physical tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. the key analysis of current embodied planner limitations (Geometric Adaptability Gap and Embodiment Constraint Gap) is insightful and the two corresponding solutions make sense\n2.The introduction of the TE-GRPO curriculum addresses the persistent gap between theoretical plans and practical robot feasibility.\n3. OmniEVA consistently achieves or surpasses existing state-of-the-art performance on several challenging embodied tasks\n4. The work is highly relevant to current efforts to bridge the gap between vision-language models and physically interactive, multimodal embodied AI."}, "weaknesses": {"value": "1. While some results for physical robots are reported and select qualitative examples shown (Figures 7–11), the main quantitative results are from simulation and offline metrics. There is mention of real-world deployment in the conclusion and some visuals, but the scalability and generalization of the framework to a variety of robot morphologies or environments is not systematically confirmed.\n2. While OmniEVA delivers strong results, the paper does not sufficiently discuss scenarios or limitations where the dynamic 3D gating may erroneously activate/deactivate or where the model’s embodiment-aware planning might fail or produce brittle outcomes. More failure cases and a nuanced discussion would add value. It would be great make clear the capability boundary of this approach and shed light on areas of improvement.\n\nThese two points lead to to question the claimed generalizability and applicability of the proposed method."}, "questions": {"value": "1. Can the authors clarify whether the gate variable $g$ in TAGR is continuous (soft) or strictly discrete (hard) during inference? If it is sometimes fractional, how does this affect feature fusion, and are there cases where blended (i.e., partially injected) 3D cues yield improved or degraded performance? \n2. Please provide detailed breakdowns of training data composition (custom vs. public), any pre-processing steps, and how 2D and 3D modalities are mixed during training."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Hcd99uDVAW", "forum": "tkEmIJv1tB", "replyto": "tkEmIJv1tB", "signatures": ["ICLR.cc/2026/Conference/Submission4225/Reviewer_5j5y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4225/Reviewer_5j5y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943168413, "cdate": 1761943168413, "tmdate": 1762917238767, "mdate": 1762917238767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address two limitations of current multi-modal large language models (MLLMs): insufficient 3D geometric understanding and the embodiment constraint gap. The authors propose OmniEVA, featuring task-adaptive 3D grounding and embodiment-aware reasoning. OmniEVA achieves state-of-the-art performances across 7 out of 8 public benchmarks, including VQA and navigation tasks. Furthermore, this paper introduces 4 primitive benchmarks to demonstrate the strong embodied capabilities of OmniEVA."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Good motivation. Insufficient geometric understanding is a long-standing problem for MLLMs. And this paper takes one step further to address the gap between MLLMs and embodied AI applications by proposing embodiment-aware learning.\n- Thoughtful model design for the utilization of geometric features. Task-adaptive gated router (TAGR) effectively addresses the information bias between 2D semantics and 3D geometry. And the ablation study demonstrates the advantages of TAGR.\n- Embodiment-aware reasoning (TE-GRPO) is a novel solution to address the embodiment constraint gap, which properly integrates embodiment-specific rewards and reinforcement learning.\n- The experimental results are comprehensive and the authors propose four extra embodiment-oriented benchmarks that can take considerable efforts."}, "weaknesses": {"value": "- The whole training pipeline is not delivered clearly, especially the data front. I cannot find an introduction to how the OmniEVA is trained. I only know that it goes through three stages: TAGR pretraining, SFT, and RFT. But for each stage, what datasets are involved? The terminologies are also confusing, such as general embodied reasoning, omnibodied reasoning, and embodiment-aware reasoning. Moreover, this results in my confusion about which model (stage) is reported in various experiment tables.\n- Limited insights beyond the overall good performance. The underlying factors include base model capability and data scale, which can make the comparisons unfair. The results turn out to be a pretty good performance with extensive training data and three training stages. However, we have no idea what data is significant and how much each stage contributes to the final performance.\n- Despite the efforts regarding embodiment-aware reasoning, I think the claims (such as Line 425) about real-world robotics tasks are not appropriate since there are no real-robot tasks and results."}, "questions": {"value": "- Figure 4 shows the difference in gate activation across some object categories that involve only semantics, e.g., armchair, towel, copier, box, etc. How to explain this? Does this indicate a bias stemming from data distribution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "03dGa8mvRz", "forum": "tkEmIJv1tB", "replyto": "tkEmIJv1tB", "signatures": ["ICLR.cc/2026/Conference/Submission4225/Reviewer_WCjS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4225/Reviewer_WCjS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981588692, "cdate": 1761981588692, "tmdate": 1762917238518, "mdate": 1762917238518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OmniEVA, an embodied planning framework that dynamically fuses 2D and 3D information via a task-adaptive gating mechanism (TAGR) and trains with embodiment-aware rewards (TE-GRPO). The model generates physically feasible plans for robotic manipulation and navigation. Extensive experiments on 8 benchmarks (2D, 3D, video, navigation, simulation, and real robot) show SOTA results with only 8B parameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors identify two critical yet often-ignored issues in embodied reasoning (geometric adaptability and embodiment constraints) and propose well-defined mechanisms to address both.\n\n2. Explicitly integrating robot kinematic limits and workspace awareness into the planner is both novel and useful for real-world applications.\n\n3. The model outperforms state-of-the-art baselines on several benchmarks and demonstrates credible real-robot deployment results."}, "weaknesses": {"value": "1. The overall pipeline still largely follows prior MLLM-based planners, with incremental contributions (the gating and embodiment modules) rather than a fundamentally new paradigm. In addition, the claimed innovation of the gated router seems somewhat redundant, since modern attention layers already allow for selective fusion and weighting of modality-specific features. The paper does not convincingly justify why a separate gating mechanism is needed beyond what cross-attention or learned query routing could provide.\n\n2. While results cover 2D and 3D reasoning, most experiments focus on tabletop or indoor manipulation. It remains unclear how well the approach scales to more complex, dynamic environments.\n\n3. The real-world experiments are promising but relatively limited in scale. Only a few scenarios and robots are tested; cross-platform generalization is not discussed."}, "questions": {"value": "No"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "c2tjLyeOSg", "forum": "tkEmIJv1tB", "replyto": "tkEmIJv1tB", "signatures": ["ICLR.cc/2026/Conference/Submission4225/Reviewer_BSqi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4225/Reviewer_BSqi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999189236, "cdate": 1761999189236, "tmdate": 1762917238258, "mdate": 1762917238258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}