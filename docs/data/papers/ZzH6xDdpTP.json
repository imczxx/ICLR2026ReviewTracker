{"id": "ZzH6xDdpTP", "number": 11450, "cdate": 1758199371522, "mdate": 1759897574688, "content": {"title": "Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks", "abstract": "Large Language Models have demonstrated remarkable capabilities across diverse domains, yet significant challenges persist when deploying them as AI agents for real-world long-horizon tasks. Existing LLM agents suffer from a critical limitation: they are test-time static and cannot learn from experience, lacking the ability to accumulate knowledge and continuously improve on the job. To address this challenge, we propose MUSE, a novel agent framework that introduces an experience-driven, self-evolving system centered around a hierarchical Memory Module. MUSE organizes diverse levels of experience and leverages them to plan and execute long-horizon tasks across multiple applications. After each sub-task execution, the agent autonomously reflects on its trajectory, converting the raw trajectory into structured experience and integrating it back into the Memory Module. This mechanism enables the agent to evolve beyond its static pretrained parameters, fostering continuous learning and self-evolution. We evaluate MUSE on the long-horizon productivity benchmark TAC. It achieves new SOTA performance by a significant margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments demonstrate that as the agent autonomously accumulates experience, it exhibits increasingly superior task completion capabilities, as well as robust continuous learning and self-evolution capabilities. Moreover, the accumulated experience from MUSE exhibits strong generalization properties, enabling zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI agents capable of real-world productivity task automation.\nDemo videos can be found in our supplementary materials.", "tldr": "We built a self-improving agent that can continuously evolve by reflecting on past execution trajectories and learning from experience. It achieved SOTA and showed increasing performance on long-horizon productivity benchmark TAC.", "keywords": ["Agent Framwork", "Self-Evolution", "Memory Mechanism"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/62b70dee2356737b0ac8257c64e485156057fed7.pdf", "supplementary_material": "/attachment/928b13f62f5ea5ce3f553cfb09b2f28eeaff76f2.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose MUSE, a novel self-evolving AI agent framework that enables LLMs to learn continuously from experience on real-world long-horizon tasks. It features a hierarchical memory module where the agent autonomously reflects on trajectories to create and integrate structured experience. This mechanism drives self-evolution, leading to new state-of-the-art performance on the TAC benchmark and demonstrating strong generalization to new tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The experimental results demonstrate strong performance, achieving SOTA results compared to recent LLMs.\n2) The work is well-motivated by the need for LLM agents to continuously learn from experience and overcome their static nature."}, "weaknesses": {"value": "1) I wonder whether the performance gains are primarily derived from leveraging previous successful solutions. It is crucial to explore the framework's ability to learn from and generalize over failures. How about provide more harder questions in the initial and then easier questions, and will the model benifit from initial hard failure samples?\n2) A primary concern for the framework is the computational overhead during inference. Can the authors provide inference time computation on the questions compared to without memory, and without MUSE?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nwCFhBkwin", "forum": "ZzH6xDdpTP", "replyto": "ZzH6xDdpTP", "signatures": ["ICLR.cc/2026/Conference/Submission11450/Reviewer_st2r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11450/Reviewer_st2r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761474589755, "cdate": 1761474589755, "tmdate": 1762922563003, "mdate": 1762922563003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "MUSE proposes an agent framework with 3 modules : strategic, procedural, tool steps which refine knowledge in a predefined operation standard ( plan-execute-reflect-memorize ) scaffolding loop. When using MUSE on TheAgentCompany, it improves by over 20% from prior SOTA using Gemini-2.5-flash model."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "MUSE is the first method to exceed 50% on TAC with a test time continuous learning module. The 3-tier structure (Strategic/Procedural/Tool) is intuitive and well-motivated, providing different levels of abstraction."}, "weaknesses": {"value": "The paper doesn't adequately explain the details of the scaffolding specifically : How memory is deduplicated and pruned at scale? What happens when memories conflict? Computational cost of memory retrieval as size grows? ( These could be resolved with the inclusion of supplementary materials but its not provided )\n\nThe experiment setting is a bit weak with only one single benchmark ( the agent company ) and lacks the commonly used benchmarks such as AppWorld, OSWorld or even simpler task such as SWE-bench.\n\nBut more critically, the framework is not different enough from similar works which learns from trajectories ( ExpeL, Memp, Agent Workflow Memory), making the contributions too weak to justify its novelty."}, "questions": {"value": "Major:\n\n1. Would MUSE be applicable to SWE-bench, OSWorld, WebArena or AFLWorld as well?\n\n2. Could you provide measurements of latency, token costs, or context growth over time? Given memory updates after every sub-task, computational overhead could be prohibitive\n\n3. How sensitive is performance to the quality of the Reflect Agent? What if it extracts poor memories ( by using smaller models on reflect agent)?\n\n4. What’re the error failure case where MUSE still fails to perform successfully? For example in the original TAC benchmark, the author identifies lack of social skills, browsing, self-confusion are one of the 3 major causes of error.\n\nMinor:\n\n5. How long does it take to craft the prompts for each of the modules? Does the time needed to craft each of the module prompts to adapt to new LLMs or tasks hinders the adoption of MUSE?\n\n6. Is there a solid reason why the supplementary material is not provided? Without the code it is impossible to review if the evaluation does not contain any information leak from ground truth during the iterative improvement process.\n\n7. In the paper, it claims MUSE is model-agnostic memory, but were the memories actually tested when transferred to significantly different model families ( deepseek-3.1 -> gemini 2.5 flash )?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8hrNyE5C8L", "forum": "ZzH6xDdpTP", "replyto": "ZzH6xDdpTP", "signatures": ["ICLR.cc/2026/Conference/Submission11450/Reviewer_aGFx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11450/Reviewer_aGFx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761566049020, "cdate": 1761566049020, "tmdate": 1762922562545, "mdate": 1762922562545, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work creates an framework that allows a model to learn from experience for long-horizon tasks using a memory module. They achieve state-of-the-art performance on the TAC benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses timely concern on models being static and not learning as they perform the task\n- Achieves new SOTA on TAC benchmark\n- Demonstrates that memory module is memory-agnostic and can then be plugged into different models"}, "weaknesses": {"value": "- Only use of one domain; while i understand that they need a difficult domain with a long horizon, it would be important to see what how this agent would perform on other problems\n- The questionable choice of baselines, they all use different base models and none of the works in the related works were experimented with\n- It is important to discuss the time completing tasks and the time it takes to train"}, "questions": {"value": "Figure 3 is hard to read"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xTEkgKtQ1Q", "forum": "ZzH6xDdpTP", "replyto": "ZzH6xDdpTP", "signatures": ["ICLR.cc/2026/Conference/Submission11450/Reviewer_jjy4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11450/Reviewer_jjy4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854762057, "cdate": 1761854762057, "tmdate": 1762922562229, "mdate": 1762922562229, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MUSE, an experience-driven agent framework with a hierarchical memory module for self-evolution in long-horizon tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "MUSE achieves a new SOTA on the TAC benchmark using a lightweight model, demonstrating effective continuous learning and generalization."}, "weaknesses": {"value": "1. The limitations of existing methods or the motivation of this paper are not entirely accurate. The limitations of existing methods mentioned in the abstract—\"they are test-time static and cannot learn from experience, lacking the ability to accumulate knowledge and continuously improve on the job\"—can be addressed by an RL-based LLM. \n2. The experimental comparisons are incomplete and unfair."}, "questions": {"value": "1. The limitations of existing methods mentioned in the abstract—\"they are test-time static and cannot learn from experience, lacking the ability to accumulate knowledge and continuously improve on the job\"—can be addressed by LLM based on RL. However, the limitations of existing methods or the motivation in this paper are not entirely accurate.\n2. For experience-driven self-evolving agents, how large is the amount of accumulated experience data? What is the scale of structured experience? How can we ensure that this experience is not forgotten during task switching?\n3. Many self-evolving agents have not been compared. You can search for surveys of Self-Evolving Agents.\n4. Why was only a subset of 18 tasks used for continuous learning experiments, and how does this selection bias affect the claim of general self-evolution capability?\n5. How does the hierarchical memory structure ensure that retrieved experiences are contextually relevant and do not introduce noise or outdated strategies?\n6. Can you justify the fairness of comparing MUSE using Gemini-2.5 Flash against stronger models in baseline methods without ablation on model capacity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "t6RD9xTbSR", "forum": "ZzH6xDdpTP", "replyto": "ZzH6xDdpTP", "signatures": ["ICLR.cc/2026/Conference/Submission11450/Reviewer_SE9S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11450/Reviewer_SE9S"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916632445, "cdate": 1761916632445, "tmdate": 1762922561836, "mdate": 1762922561836, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}