{"id": "W8N4eZ9KSU", "number": 17992, "cdate": 1758282719462, "mdate": 1759897140527, "content": {"title": "Linear Maps, Contrastive Objectives: A Principled Strategy for fMRI Decoding Consistent Across Modalities", "abstract": "A prominent theory in cognitive science suggests that concepts in the brain are organized as high-dimensional vectors, with semantic meaning captured by directions and relative angles in this space. Brain decoding is the effort of reconstructing or retrieving stimuli (or their representations) from neural activity and involves finding a function that approximates how the brain represents concepts. This motivates the investigation of contrastive objectives as biologically plausible candidates to reverse the brain loss function. In this work, we study how functional MRI (fMRI) activity can generally be aligned with the embedding spaces of foundation models in vision, language, and audio. Although neural computations are highly non-linear at the microscale, fMRI measurements average signals across space and time, further smoothed by noise, effectively linearizing the observable representation. Consistent with these views, our experiments across multiple datasets demonstrate that linear contrastive decoders consistently outperform ridge regression and non-linear alternatives, and that these results generalize across images, text, and sound. These findings indicate that decoding gains arise more from the choice of training objective than from architectural complexity, pointing to contrastive-linear models as a principled strategy for brain decoding.", "tldr": "Linear contrastive alignment is the most effective way to decode fMRI activity, by leveraging vectorial representations of concepts and the linearization inherent to fMRI measurements.", "keywords": ["Computational Neuroscience", "Cognitive Science", "fMRI Decoding", "Contrastive Learning"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a52967e5ef80ecfa159e24abcbc140531eb59379.pdf", "supplementary_material": "/attachment/0bf8ea627737897f4f0a23da23cf794c024d0439.zip"}, "replies": [{"content": {"summary": {"value": "The paper argues that when decoding fMRI into the representation spaces of large foundation models, a simple linear mapping trained with a contrastive objective is consistently better than ridge regression and shallow MLPs. The authors evaluate three public datasets, and use retrieval in embedding space as the metric. A small architecture with subject-specific linear alignment followed by a linear projection yields Top-1 gains over ridge and also outperforms their non-linear MLP across all modalities."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper’s key strength is its evidence that a simple linear mapping is adequate for aligning fMRI signals with semantically rich embedding spaces (e.g., from multimodal foundation models). This is a surprising and consequential observation, suggesting that the geometry of brain-recorded activity admits an approximately linear relationship to these representations, thereby refining our understanding of both fMRI signal structure and neural encoding at the population level."}, "weaknesses": {"value": "Although the conclusion—that an efficient linear mapping suffices for fMRI decoding—is intriguing, the experimental design supporting this claim appears insufficiently rigorous:\n\n1. The paper compares ridge regression (trained with an MSE objective and L2 regularization ?) to the proposed linear model trained with a contrastive (InfoNCE-style) objective. Because the target embedding (e.g., CLIP) itself is learned with a contrastive loss, this comparison is not fair: one would expect a method trained with a geometry-aligned contrastive loss to outperform MSE by construction. \n\n2. The paper states that an MLP underperforms the linear model (Table 1), yet Table 2 shows that **Identity** activation yields the best MLP performance. Theoretically, an MLP with identity activations collapses to a linear map; with sufficient training and comparable regularization, it should match (or closely approach) the linear model. So does the comparsion of MLP with identity activation and linear model make sense?\n\n3. The proposed linear model includes a subject-specific adjustment matrix (A_k). It is unclear whether the MLP baseline incorporates an analogous adjustment . The paper should document these details (main text or appendix).\n\nI am willing to increase my score if the authors address the issues above."}, "questions": {"value": "1. Please according to the soundness issues in Weaknesses part\n2. It is recommend that the author could explain more why linear model is better than other more complex methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RgymXZiVn5", "forum": "W8N4eZ9KSU", "replyto": "W8N4eZ9KSU", "signatures": ["ICLR.cc/2026/Conference/Submission17992/Reviewer_Rfki"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17992/Reviewer_Rfki"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761752343926, "cdate": 1761752343926, "tmdate": 1762927788126, "mdate": 1762927788126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates fMRI decoding by mapping brain activity to the embedding spaces of foundation models for three different modalities: vision, language, and audio. The authors systematically compare three types of decoders: ridge regression, a linear mapping trained with a contrastive objective, and a shallow MLP with non-linearities also trained with a contrastive objective. Their experiments across three public datasets show that the linear contrastive model consistently achieves the highest retrieval accuracy, outperforming both ridge regression and the non-linear model. The authors argue that this supports two main ideas: 1) the contrastive objective is more suitable for this task than the point-wise error minimization of ridge regression, and 2) linear models are sufficient and often superior for decoding macroscopic fMRI signals, whose inherent noise and averaging properties effectively linearize the underlying neural computations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper's main strength is its consistent application and evaluation of the same decoding pipeline across three distinct and important modalities (vision, language, music). This provides strong evidence for the generalizability of their findings.\n\n- The work delivers a clear and practical message: a simple, subject-aligned linear model trained with a contrastive loss is a robust and effective strategy for fMRI decoding. This provides a strong baseline for future research.\n\n- The authors ground their approach in plausible theories from cognitive science (vector representations of concepts) and neuroscience (the linear nature of macroscopic fMRI signals), providing a solid theoretical motivation for their empirical results."}, "weaknesses": {"value": "The paper's conclusions, while interesting, are weakened by several methodological omissions, overstated claims, and presentation issues.\n\n- The central claim that the linear contrastive (Linear CL) model \"outperforms\" ridge regression is based solely on retrieval accuracy. This is unsurprising, as the Linear CL model is directly optimized for a retrieval-based contrastive loss, while ridge regression minimizes Mean Squared Error (MSE). A fairer comparison would require evaluating both models on both types of metrics (e.g., reporting MSE for the CL models and showing feature-wise correlation for Ridge in Fig 3b). Without this, the claim of superiority is not fully substantiated.\n\n- The paper makes a strong claim that \"architectural complexity does not translate into performance gains.\" However, this conclusion is based on comparing only to a shallow MLP. The space of non-linear architectures is vast, and other work (e.g., Careil et al., 2025, \"Dynadiff\", Table 3) has shown significant gains with more complex non-linear models for the same task. The current experiments are insufficient to support such a general conclusion.\n\n- Critical methodological details are missing: \n    - The paper never specifies the size of the retrieval set (the reference set Rs) for the Top-k accuracy evaluation. Retrieval accuracy is meaningless without knowing the number of distractors (e.g., Top-1 accuracy of 42% is very different if the pool size is 10 vs. 1000). This is a critical omission that prevents proper interpretation of the main results in Table 1.\n    - The use of a subject-specific alignment layer is mentioned, but its purpose is unclear, especially since the evaluation is then described as being performed \"within subject.\" The details of the inter-subject alignment (e.g., anatomical or functional) and its role in the model are not sufficiently explained.\n    - The paper does not justify why different numbers of voxels were selected for each dataset (15.7k for images, 10k for language, 3k for music), making it difficult to assess the consistency of the approach.\n\nMinor comments\n- The paper is missing citations to highly relevant recent work in fMRI decoding (e.g. Careil et al., 2025; Aggarwal et al., 2024; Thual et al., 2023; Banville et al., 2025; Ye et al., 2025; Tang et al, 2023; Jalouzot et al., 2025).\n- The results in Table 1 are difficult to parse; a bar chart would be much clearer for comparing the three methods across different conditions."}, "questions": {"value": "- Could you clarify the multi-subject alignment procedure and its purpose?\n\n- To provide a fairer comparison with ridge regression, could you report the Mean Squared Error (MSE) for all tested models? This would help disentangle performance gains due to the objective function versus the architectural choice.\n\n- How are the evaluation retrieval sets built and what are their size for the three datasets? This information is essential for interpreting the reported accuracy percentages."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ea9BYecrTu", "forum": "W8N4eZ9KSU", "replyto": "W8N4eZ9KSU", "signatures": ["ICLR.cc/2026/Conference/Submission17992/Reviewer_wpk1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17992/Reviewer_wpk1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815272194, "cdate": 1761815272194, "tmdate": 1762927787804, "mdate": 1762927787804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the role of linear versus non-linear mappings for decoding fMRI activity into the embedding spaces of foundation models (CLIP, CLAP, LLaMA). Across three modalities—vision, language, and music—the authors demonstrate that a simple linear contrastive decoder consistently outperforms both ridge regression and non-linear MLP decoders. The study argues that due to spatial and temporal averaging, fMRI signals behave effectively linearly, making contrastive-linear objectives both biologically plausible and empirically optimal for brain decoding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper builds a principled connection between cognitive theories of vector-based concept representation and the observed linearity of fMRI signals, offering a coherent rationale for why linear contrastive decoders should work.\n\n2. The writing is clear, figures are informative, and the narrative effectively bridges neuroscience and machine learning perspectives."}, "weaknesses": {"value": "1. What is the contribution of the subject alignment layer (Aₖ)? Have ablation experiments been conducted with its removal or freezing?\n\n2. What are the individual contributions of the contrastive learning objective versus the subject alignment module (Aₖ)?  Have ablation experiments been performed to evaluate them?\n\n3. The impacts of hyperparameters such as temperature parameter, negative sampling strategy, and batch size on the results have not been systematically explored, which limits the interpretability and generalizability of the method."}, "questions": {"value": "see Weakness Section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lToIrgGzI0", "forum": "W8N4eZ9KSU", "replyto": "W8N4eZ9KSU", "signatures": ["ICLR.cc/2026/Conference/Submission17992/Reviewer_PmyW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17992/Reviewer_PmyW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894854180, "cdate": 1761894854180, "tmdate": 1762927787063, "mdate": 1762927787063, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates brain decoding from functional MRI (fMRI) across three modalities: images, text, and music. The authors propose that simple linear mappings trained with contrastive learning objectives consistently outperform both ridge regression and non-linear alternatives (shallow MLPs) when mapping brain activity to foundation model embedding spaces (CLIP for images, CLAP for audio, LLaMA for text). The core finding is that a subject-aligned linear transformation trained with NT-Xent contrastive loss achieves 10-15% improvements in Top-1 and Top-3 retrieval accuracy compared to baselines. The authors argue this success stems from: (1) concepts being organized as vectors in the brain where geometric relationships encode meaning, making contrastive objectives biologically plausible, and (2) fMRI measurements effectively linearizing neural dynamics through spatial/temporal averaging and noise, making linear models sufficient at the macroscale."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The consistent 10-15% improvement over ridge regression across all three modalities is a clear result (though statistical testing is needed).\n\n2. Using the same architecture for images, text, and music is elegant and demonstrates generality. This is the paper's strongest contribution.\n\n3. Acknowledging that non-linear architecture space is large and that more exploration could find better models is commendable."}, "weaknesses": {"value": "1. Testing only shallow MLPs (≤5 layers, only ReLU/GELU) is insufficient to claim non-linear models fail. Modern architectures are completely unexplored:\n\n2. Table 1 shows means ± std but no significance tests between ridge and linear CL. Are the improvements statistically significant given the sample sizes? What is the effect size?"}, "questions": {"value": "1. Why only test shallow MLPs with simple activations? Modern fMRI decoding papers use much more sophisticated architectures. Can you compare against MindEye2 (Scotti et al. 2024) or UMBRAE (Xia et al. 2024b) which use non-linear models successfully?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sOqOKiXSnW", "forum": "W8N4eZ9KSU", "replyto": "W8N4eZ9KSU", "signatures": ["ICLR.cc/2026/Conference/Submission17992/Reviewer_iD6T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17992/Reviewer_iD6T"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992574377, "cdate": 1761992574377, "tmdate": 1762927786547, "mdate": 1762927786547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}