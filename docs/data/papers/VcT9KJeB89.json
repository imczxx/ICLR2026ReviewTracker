{"id": "VcT9KJeB89", "number": 5461, "cdate": 1757912135614, "mdate": 1763479282532, "content": {"title": "Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL", "abstract": "Recent advances in large language models (LLMs) and multi-agent systems have demonstrated remarkable capabilities in complex problem-solving tasks such as deep research, vibe coding, and mathematical reasoning. However, most existing multi-agent systems are built upon manual prompt/workflow engineering with sophisticated agent frameworks, making them computationally inefficient, less capable, and unable to benefit from data-centric learning. In this work, we introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables native end-to-end complex problem-solving in the same way as a multi-agent system (i.e., multi-turn problem solving with multiple tools and multiple agents) within one model. In chain-of-agents problem-solving, the model dynamically activates different tool agents and role-playing agents to simulate multi-agent collaboration in an end-to-end fashion. To elicit end-to-end chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent distillation framework to distill state-of-the-art multi-agent systems into chain-of-agents trajectories for agentic supervised fine-tuning. We then use agentic reinforcement learning on verifiable agentic tasks to further improve the models' capabilities on chain-of-agents problem solving. We call the resulting models Chain of Agents Models (CoAMs) . Our empirical studies demonstrate that CoAM establishes new state-of-the-art performance across diverse benchmarks in both search, math, and code settings.", "tldr": "Chain-of-Agents (CoA) distills multi-agent systems into a single end-to-end LLM paradigm, enabling efficient agent-like problem solving and achieving state-of-the-art results with open-sourced Agent Foundation Models (AFMs).", "keywords": ["agent foundation models", "agent frameworks", "LLMs"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c528130f2b10a1a87905d2c9f3bb30b96bdbcbdd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Chain-of-Agents (CoA), a framework for integrating multi-agent reasoning and tool use within a single model and execute end-to-end. Instead of running and orchestrating multiple interacting agents, CoA chain agents together and distills successful trajectories from expert multi-agent systems into a unified model.\n\nThe resulting system coordinates “role-playing agents” (planner, thinker, reflector, verifier) and “tool agents” (web search, wiki search, crawler, code executor), and finetune a base LLM using SFT/RL with synthesized agent trajectories.\n\nEmpirical results on a wide set of benchmarks (GAIA, BrowseComp, HLE, AIME, MATH500, etc.) show strong performance and efficiency gains compared to Tool-Integrated Reasoning (TIR) and multi-agent baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents a well-structured design combining multi-role reasoning and domain-specific tool agents under a single model.\n\n- Extensive benchmarks across search, reasoning, math, and coding show consistent improvements.\n\n- The paper provides substantial implementation details and appendices explaining the tool setup and data processing."}, "weaknesses": {"value": "- The main technical contribution is the Chain-of-Agents architecture. The data synthesis pipeline and training (SFT + RL on distilled trajectories) mostly follows well-established practices.\n\n- The paper demonstrates performance gains but offers limited insight into why it outperforms explicit multi-agent systems or where the improvement come from, as well as why sometimes the performance difference is uneven, why in some dataset improvement is significant while in some cases it is marginal. Or the gap between SFT and RL being different across benchmarks.\n\n- The model is trained on Qwen 2.5, released in September 2024, even though Qwen 3 was public several months before submission (April 2025). This raises questions about the timeliness and potential performance ceiling.\n\n- Some reported numbers are taken directly from prior work rather than rerun. For baselines that depend on web search results or use LLM-as-Judge scoring, direct reuse could compromise strict comparability as they can change over time (search results drift, judgment variance),"}, "questions": {"value": "- Some critical details (training data composition, tool configurations, trajectory sources) are relegated to the appendix; I feel it would be better to include these in main text directly.\n\n- Why use Qwen 2.5 instead of Qwen 3, which was available before submission? Do you expect similar improvements if retrained on the newer backbone?\n\n- For baselines whose results are borrowed rather than rerun, how do you control for changes in web search outcomes and stochastic LLM-as-Judge evaluations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JNjpYoa7Ln", "forum": "VcT9KJeB89", "replyto": "VcT9KJeB89", "signatures": ["ICLR.cc/2026/Conference/Submission5461/Reviewer_fCmh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5461/Reviewer_fCmh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761856130244, "cdate": 1761856130244, "tmdate": 1762918077634, "mdate": 1762918077634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a method for training a single LLM that integrates tool usage, enabled by data generated by multiple agents. The key idea is to create training data using a multi-agent setup, where each agent has access to specific tools. The interactions of these agents can be represented in the training data through special tokens. This data is then used to perform supervised fine-tuning or RL-based post-training on a single distilled LLM, with an LLM-as-a-judge component providing the reward signal for RL training. The effectiveness of the approach is evaluated across multiple backbones of varying sizes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The main strength of this paper lies in its experimental section. The results are compelling, with strong evaluations against numerous baselines and models at different scales, including 32B ones. These elements collectively support the paper’s claims effectively.\n2. The analysis in Section 5 highlights important contributing factors. It is particularly interesting to observe that test-time computation significantly benefits the trained network, although further clarifications would be helpful (see questions below).\n3. The manuscript is well organized and clearly written."}, "weaknesses": {"value": "1. The novelty of the work does not appear to be particularly strong; it seems more like a well-executed engineering contribution. My main concern arises from the comparison with Search-R1. The proposed framework resembles an N-agent extension of Search-R1, where multiple agents with different tools replace the single agent equipped with a search tool. While effective in practice, to me this looks to be quite incremental.\n2. Another limitation is that distilling all capabilities into a single LLM restricts the integration of new tools, a process that is much more straightforward in traditional roleplay-based agentic setups. Is there any possible way to mitigate this limitation?"}, "questions": {"value": "1. Is there any intuition on why test-time adaptation performs better with the proposed approach than with the baselines as claimed?  \n2. Can the authors clarify where the novelty stands relative to Search-R1?\n3. Could the system be made more flexible to accommodate new tools or agent roles? This does not require experiments, but rather a discussion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1w2APCdpfA", "forum": "VcT9KJeB89", "replyto": "VcT9KJeB89", "signatures": ["ICLR.cc/2026/Conference/Submission5461/Reviewer_AH31"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5461/Reviewer_AH31"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910007485, "cdate": 1761910007485, "tmdate": 1762918077395, "mdate": 1762918077395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an agentic pipeline in which a single model can act as multiple agents to simulate a \"multi-agent\" workflow. The proposed procedure involves distilling multi-agent traces into a single model, which the authors refer to as an \"agent foundation model\" (AFM). The proposed chain of agents approach achieves state of the art performance when compared to single-agent tool integrated reasoning (TIR) pipelines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The empirical results of this work are strong, with state-of-the-art performance across a variety of benchmarks across various applications, including deep search, math, and MHQA tasks. \n- The token reduction compared to multi-agent systems is significant, reducing inference cost (as measured in tokens) by an impressive 84%. \n- The ablations suggest that both the SFT and RL components of the training pipeline contribute meaningfully, which is a useful ablation for understanding which components of the proposed technique matter."}, "weaknesses": {"value": "- The framing around AFMs seems to be undermined, to some degree, by the fact that the proposed AFMs are domain-specific, requiring specialized AFMs (specialization is at odds with the colloquial meaning of the term \"foundation model\"). Section 5.3 described one example in which cross-domain generalization was observed, but this does not seem like strong enough evidence to claim that the proposed models are general-purpose agentic foundation models. \n- I may have missed something, but it remains unclear to me whether performance gains stem from the chain of agents technique itself or primarily from higher-quality training data obtained via multi-agent distillation and filtering. A prompting-only baseline applying chain of agents format to existing models would help to disentangle these potential contributions.\n- The method relies heavily on LLM as a judge, which might raise questions about the scalability of the proposed method -- is the performance ceiling capped by the best available frontier model, for a given type of task?"}, "questions": {"value": "- The term \"agent foundation model\" is perhaps overstated, as the proposed agents are still task-specific. Can the authors elaborate on this terminology choice? How are agent foundation models different from foundation models that process text, more generically? \n- Note that most of the citations in the paper are in-text, but many of them should actually be parenthetical."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NZ2IXE5fDH", "forum": "VcT9KJeB89", "replyto": "VcT9KJeB89", "signatures": ["ICLR.cc/2026/Conference/Submission5461/Reviewer_qAjm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5461/Reviewer_qAjm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762127116921, "cdate": 1762127116921, "tmdate": 1762918077107, "mdate": 1762918077107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}