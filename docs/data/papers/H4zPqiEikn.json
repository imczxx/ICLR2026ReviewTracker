{"id": "H4zPqiEikn", "number": 9593, "cdate": 1758129042298, "mdate": 1759897710440, "content": {"title": "The Bayesian Origin of the Probability Weighting Function in Human Representation of Probabilities", "abstract": "Understanding the representation of probability in the human mind has been of great interest to understanding human decision making.\nClassical paradoxes in decision making suggest that human perception distorts probability magnitudes.\nPrevious accounts postulate a Probability Weighting Function that transforms perceived probabilities; however, its motivation has been debated.\nRecent work has sought to motivate this function in terms of noisy representations of probabilities in the human mind.\nHere, we present an account of the Probability Weighting Function grounded in rational inference over optimal decoding from noisy neural encoding of quantities.\nWe show that our model accurately accounts for behavior in a lottery task and a dot counting task. It further accounts for adaptation to a bimodal short-term prior.\nTaken together, our results provide a unifying account grounding the human representation of probability in rational inference.", "tldr": "Our work provides a unifying normative account of human probability perception, showing that classic biases and flexible adaptation to new statistics both emerge from the principle of efficient coding.", "keywords": ["neuroscience; Bayesian inference; probability distortion; probability weighting function; probability perception; decision making; representation of probabilities"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5cc18529fd3e168194f07cd46a616347fef7751d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel account for the origin of the inverse S-shaped probability weighting function, framing it as a consequence of optimal Bayesian decoding from a noisy internal representation. Within this encoding-decoding framework, a true probability $p$ is encoded into a noisy measurement $m$, which is then decoded to produce an estimate $\\hat{p}$. The authors demonstrate that this model provides a superior quantitative fit by reanalyzing human data across multiple domains, including perceptual judgment, economic pricing, and risky choice."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written. It is supported by a rigorous theoretical and mathematical analysis of the Bayesian encoding-decoding framework for probabilities. Moreover, the authors provide compelling empirical support by reanalyzing a range of existing datasets and models, demonstrating that their new model achieves a strong quantitative fit."}, "weaknesses": {"value": "My main comment is about the parameterization of the FreeP and FreeE in the Bayesian model. The non-parametric specification of the prior and encoding function, with 200 free parameters each, grants the model significant flexibility. While the authors note the difficulty in penalizing this complexity, this remains a critical point for model comparison, and a more robust treatment of this issue would strengthen the paper.\n\nA related work also found that LLM embeddings exhibit patterns from probability weighting function when the LLM is pretrained on ecological data of probabilities (i.e., those following a bimodal distribution). See Figure 2 of Zhu, Yan, & Griffiths (2025). Similarly, an alternative Bayesian encoding-decoding may be developed when the $P_{prior}(p)$ is a bimodal distribution. There are some evidence suggesting that the bimodal distribution of subjective probabilities, for example, in English (Stewart et al., 2006).\n\nMinor comment:\n\nLine 1133: \"$\\Delta AICc$\" --> \"$\\Delta AICs$\"?\n\nReferences:\n\nZhu, Yan, & Griffiths (2025) Language Models Trained to Do Arithmetic Predict Human Risky and Intertemporal Choice. ICLR.\n\nStewart, N., Chater, N., & Brown, G. D. (2006). Decision by sampling. Cognitive psychology, 53(1), 1-26."}, "questions": {"value": "The authors briefly mentioned a VLM experiment in the last bit of the Appendix. It shows similar human-like distortion in probability estimation from VLMs. This is an interesting result, and probably way beyond the scope of the existing work. What is the main motivation for running this experiment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YTQKYr7Rq1", "forum": "H4zPqiEikn", "replyto": "H4zPqiEikn", "signatures": ["ICLR.cc/2026/Conference/Submission9593/Reviewer_LsJ6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9593/Reviewer_LsJ6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761495510253, "cdate": 1761495510253, "tmdate": 1762921139840, "mdate": 1762921139840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission proposes an noisy encoding+Bayesian decoding framework as a way of providing a general account for well documented biases in the ability to estimate probabilities in humans. The framework generalizes on a range of recent encoding-decoding models (which can be seen as special cases with the framework) arguing for a few discriminatory signatures in terms of the fisher information of the encoding procedure (U-shaped, usually) and in behavior (bias and across trial variability). The model is tested on several public dataset and a small new human dataset collected specifically to validate model predictions. For these, it shows improvements in model quality against a few chosen alternatives from the literature."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The ability to put together a collection of related models from the literature under a single framing helps the cogsci community make sense of the subfield.\n\nDecomposing the bias into individual contribution from encoding (resource allocation) and decoding (prior) allows for making new predictions about changes in prior, in particular bi-modality, which were then validated using data from a purposefully designed new experiment."}, "weaknesses": {"value": "Clarity of core theoretical results description: The main problem for me was the description of the core theoretical results in section 3. Theorem 1 is opaque in the main text and the proof in the appendix is incomprehensible.  The links between the actual math and the predictions is not spelled out clearly enough to drive the point across that the theory is instrumental in driving the rest of the analysis. The core theoretical result should be understandable to a mathematically educated reader based on the paper text alone and this is very much not happening at the moment. \n\nNovelty: The theoretical framing seems to rely heavily on past bayesian accounts of estimation biases in other perceptual domains, both in conceptualization and in the math (and the authors do reference the links to this work explicitly). It is not clear to me what aspects of the derivation are unique to this specific problem setting rather than  an extrapolation of a well understood broader phenomenon. does the bounded nature of the message being conveyed change anything fundamentally ? does it require a different technical approach to the derivation? It seems that the properties of the Fiser information at the limit were inherited from derivations elsewhere, and outside of the bounds the general framing applies... The variance results seem lifted directly from Hahn et al. (2025) with no added value. But I could be missing something since the appendix derivations are missing critical bits of context and explanation and are largely impossible to follow in the details.  In any case, the text itself should make a stronger case for what exactly is technically and conceptually novel in this particular version, in particular when compared to recent Hahn et al 2024,2025. \n\nComparison to existing models: the introduction mentions a wide range of models, yet BLO is almost invariably used as the straw-man for data comparisons. While it is not reasonable to ask comparisons to many other models at the very minimum one would expect a justification for why the authors deemed this particular model to be the most important to compare to and some thoughts about what one would expect for other models. The other concern I have is about the model complexity correction treatment: it seems like the nonparametric models behave fundamentally differently in terms of the metrics used and they do not get penalized in any way for the additional degrees of freedom. again, i don't necessarily argue for changing the metric but i think the text needs to be more transparent about the implications of the metrics used wrt nonparametric models, just saying that it's hard to do an AIC equivalent for that model class in the appendix doesn't seem sufficient. \n\nThe general conceptualization of the problem is widely used in this community and not due to the authors, but to me is somewhat suspect as a premise; this is a personal opinion and does not affect my scores in any way but i am generally dubious on the idea of treating probability of a world event the same way one would any sensory latent. What the empirical data looks like to me is a general flattening of the agent's posterior beliefs about the latent variable being judged (whose probability is being manipulated) relative to an ideal observer with perfect understanding of the task and no additional sensory uncertainty. So yes, it does seem normatively sensible to be overall more uncertain about what is going on and that then affecting the decision variable resulting in a combination of bias and variance. It is just not clear to me why invoking an arbitrary F nonlinearity (and associated Fiser information) and fitting the data in this parametrization really says anything useful about the mechanistic nature of the process or provide additional insight rather than being a more fancily motivated variation of the descriptive models of old. \n\nModel fitting procedures are described in a very limited way and seem to rely heavily of a public library, enforcing the incremental feel of the work."}, "questions": {"value": "Figure 3: why not show both uniform and U-shaped scenarios in B and C? i think the paper could benefit from helping the reader build more intuition about the tradeoffs that different model choices make in terms of different contributions to the bias (this also applied to the associated main text which could use some expansion and editing for clarity ) \n\nFigure 3 A: there seems to be a tradeoff between capturing bias and variance patterns well in the human data, any intuition for why ?\n\nFigure 5: i am confused why the uniform model shows such a poor model comparison result when the inferred fisher information for the nonparametric model is the flattest of all dataset. more generally, there seems to be a not very intuitive relationship between the metric and the ability of the models to capture qualitative features in the data in the sense defined by the theory, which may need some discussion. \n\nFigure 7: BLO seems to also imply a U shaped fisher information curve, so it's not clear to me if the predictions of the model are generally that qualitatively different from past variants. It seems like differences in variability is where the model improvement quality is coming from. Please comment."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lHaReED3Pe", "forum": "H4zPqiEikn", "replyto": "H4zPqiEikn", "signatures": ["ICLR.cc/2026/Conference/Submission9593/Reviewer_KhJE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9593/Reviewer_KhJE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667606534, "cdate": 1761667606534, "tmdate": 1762921139419, "mdate": 1762921139419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a Bayesian framework for modelling representation of probability in the brain. It accounts for different biases that have been identified and modeled in the literature. The proposed framework is optimal under the assumption that the internal representation of probability distribution is not perfect (there is a noise in this representation). Tested on different tasks that require probability estimation, the authors show that an optimal Bayesian model with imperfect representation of probability outperforms a method based on sub-optimallity (bounded rationality) assumption. While the results are interesting, I had a hard time understanding the contribution of this work in terms of modelling and for the ICLR audience."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper/presented model performed a good job in incorporating different models and biases. The diversity of experiments was also impressive. Furthermore, the proofs/theories were good contributions."}, "weaknesses": {"value": "This might be a presentation issue, but in general I struggled with understanding originality/contribution of the paper specially in terms of modelling. It looks like to me that the framework is the sum of previous models already existed in the literature. The results also suggested that not all of the components are always needed and of course different tasks produces different challenges and biases. Overall, I am not sure about the message of the paper. Is it \"the Bayesian brain\"? If that's the case I don't think showing one non-optimal model, i.e. BLO doesn't work on a few tasks is that interesting for the community."}, "questions": {"value": "Please see Weaknesses section. Also: \n- In the result section likelihood of held out data was used. It looks like the number of free parameters was not considered. What do the results look like considering the complexity of models and their free parameters (e.g. by measures like AIC)\n- What is the contribution of this paper beyond collecting the existing biases/models and/or papers like (Hahn, Wei 2024)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B2YyhvRiVe", "forum": "H4zPqiEikn", "replyto": "H4zPqiEikn", "signatures": ["ICLR.cc/2026/Conference/Submission9593/Reviewer_WQML"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9593/Reviewer_WQML"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952278258, "cdate": 1761952278258, "tmdate": 1762921139066, "mdate": 1762921139066, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce a new Bayesian framework to explain how humans perceive and process probabilities. The authors claim that probability distortion is not deterministic, and that these distortions emerge naturally from how the brain encodes probabilities with noise and them optimally decodes them using Bayesian inference. Throughout their three experiments, the authors empirically demonstrate that their Bayesian framework consistently outperforms alternative models, including the current state-of-the-art BLO models. While the experiments have some limitations, particularly in sample size for the adaptation study and the use of hypothetical scenarios in economic tasks, the consistency of findings across different domains and tasks provides strong support for their theoretical framework. This work not only advances our understanding of how humans process probabilities but also demonstrates how fundamental principles of perception and inference can explain seemingly irrational aspects of decision-making."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper has strong theoretical contributions, backed with consistent empirical results and robust mathematical derivations. The authors provides a unifying Bayesian framework for understanding probability distortion in human cognition, derives clear theoretical predictions, and demonstrates how previous models can be seen as special cases. This theoretical unification is particularly powerful because it doesn't just describe probability distortions but explains why they occur, grounding them in fundamental principles of neural information processing. The framework is tested across multiple domains, showing consistent support for the key predictions laid out ahead of time. Most importantly, the mathematical derivations are sound and the experimental methodology is robust."}, "weaknesses": {"value": "(See questions)"}, "questions": {"value": "1. The paper does not present power analysis to justify its samples sizes for different tasks. In particular, section 4.3's adaptation experiment only had 26 subjects, which roughly a third of what other experiments had (86 in 4.1 and 75 in 4.2). Is there a reason why there is a large difference in the number of subjects between experiments, and some support to show that 26 subjects was sufficient?\n\n2. In 4.2, the decision-making tasks used were one-shot, hypothetical gambles without real consequences. While using actual monetary stakes is probably impractical, these hypothetical scenarios may not adequately capture how humans incorporate risk into their decision-making. In fact, it is a common criticism given to these one-shot, hypothetical gambling tasks often used in behavioral economics studies. Have authors considered using sequential decision-making tasks where time and physical effort could serve as natural proxies for risk and reward? For instance, in a task where completion speed determines when participants can leave, subjects would face real tradeoffs between speed and effort allocation.\n\n3. While the Bayesian framework is more principled, it's also more complex. Could the authors comment on the practicality of using their framework compared to simpler alternatives that may do \"well enough\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ds99WihyjH", "forum": "H4zPqiEikn", "replyto": "H4zPqiEikn", "signatures": ["ICLR.cc/2026/Conference/Submission9593/Reviewer_poyN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9593/Reviewer_poyN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970933421, "cdate": 1761970933421, "tmdate": 1762921138770, "mdate": 1762921138770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}