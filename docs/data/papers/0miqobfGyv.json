{"id": "0miqobfGyv", "number": 2154, "cdate": 1757000559575, "mdate": 1759898166115, "content": {"title": "AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-based Person Anomaly Search", "abstract": "Text-based person anomaly search requires fine-grained alignment between language queries and subtle visual cues, a challenge amplified by the long-tailed nature of anomalous behaviors. While Large Multimodal Models (LMMs) offer powerful visual understanding, their generative pre-training is fundamentally misaligned with the discriminative needs of this retrieval task. Adapting them without costly fine-tuning remains a significant hurdle. We introduce \\textbf{AnomalyLMM}, a training-free, coarse-to-fine framework that effectively repurposes generative LMMs for zero-shot anomaly retrieval. Our method first uses a general retrieval model to produce an initial ranking. To refine this list, we introduce a novel cloze-based re-ranking mechanism with three steps. The first step \\textbf{Cloze Generation} converts the text query into a ``fill-in-the-blank'' prompt. Next, \\textbf{Cloze Completion} compels the LMM to focus on specific visual regions and generate a description of the potential anomaly. The final step \\textbf{Comparison \\& Re-ranking} calculates semantic alignment between the LMM's generated completion and the original query, which serves as a powerful re-ranking score.\nExperiments on the PAB dataset show that AnomalyLMM surpasses the competitive baseline by $+0.96$\\% Recall@1 accuracy. Crucially, our method provides highly interpretable visual-textual alignments without any task-specific training, a vital feature for real-world deployment. The code will be made publicly available.", "tldr": "", "keywords": ["Text-based person anomaly search", "Fine-grained cross-modal alignment", "Long-tail anomaly recognition", "Large multi-modal model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f0e07a5961562c65c16d307f842e0d23b865a149.pdf", "supplementary_material": "/attachment/ba96db74a72e7412877ae600b41c2eba3011a993.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces AnomalyLMM, a training-free framework that leverages the advanced reasoning capabilities of existing LMMs for text-based person anomaly search. The authors propose a novel cloze-based re-ranking method, which encourages LMMs to fill in generated cloze-style text queries and rectifies the initial ranking list based on the filling performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Good Writing**: The paper is well-written and the main contributions are clearly presented, making it easy for readers to follow the core ideas.\n2. **Training-Free**: The proposed training-free post-processing method effectively leverages LMMs to refine the initial ranking list, which could greatly reduce the need for additional model training and resource consumption."}, "weaknesses": {"value": "1. **Task Scope**: The specific problem that AnomalyLMM aims to solve within the text-based person anomaly search domain is not clearly articulated. The Introduction primarily emphasizes the challenge of discriminative retrieval, but such challenges are common across many tasks (e.g., text-based person retrieval). However, the experimental section lacks results on these related tasks. Furthermore, the proposed method appears to be well-suited for general vision-language cross-modal retrieval tasks, but the paper does not explore its generalization to these domains.\n2. **Complexity**: The paper lacks a discussion on computational complexity. The proposed re-ranking method requires multiple LMM inferences for each text-image pair, which could be computationally expensive. According to the experimental results, when using X$^2$VLM as the baseline, the performance improvement is marginal. This raises concerns about whether the computational cost is justified.\n3. **Experiments**: The difference between CMP and CMP-baseline is not clearly explained, and the experimental results show a large performance gap between them. Additionally, the paper lacks results for CMP+Ours, which would help clarify the effectiveness of the proposed method.\n4. **Related Work**: The related work section lacks a discussion of existing research on using LMMs for retrieval tasks. This omission may affect the assessment on the novelty of the proposed approach."}, "questions": {"value": "X$^2$VLM, as a generic vision-language pretrained model proposed in 2024, achieves the best performance after direct fine-tuning. What is the reason for this? Does this imply that the two main challenges described in the paper may not actually exist in this task (or in PAB dataset)? If so, the experimental results provided may not truly reflect the contribution to the text-based person anomaly search field."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No Ethics Concerns"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IspVw4Q4gf", "forum": "0miqobfGyv", "replyto": "0miqobfGyv", "signatures": ["ICLR.cc/2026/Conference/Submission2154/Reviewer_Gy4Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2154/Reviewer_Gy4Y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724224016, "cdate": 1761724224016, "tmdate": 1762916056411, "mdate": 1762916056411, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a training-free, coarse-to-fine framework that adapts Large Multimodal Models (LMMs) for text-based anomaly retrieval tasks. The core idea is to repurpose generative LMMs—traditionally designed for open-ended reasoning—into discriminative retrieval systems via a three-step cloze-based pipeline: (1) Cloze Generation masks key verbs and colors in textual queries using an LLM; (2) Cloze Completion prompts an LMM to fill these blanks based on image evidence; (3) Comparison & Re-ranking semantically compares completions with the original query to refine retrieval results. Experiments on the PAB dataset report modest improvements over strong baselines (e.g., +0.96% Recall@1) and claim enhanced interpretability. While the method is computationally efficient and avoids fine-tuning, its contribution is incremental: it mainly reuses existing LMM/LLM models with handcrafted prompt engineering and minor ranking fusion, offering limited novelty or empirical depth."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tTraining-free design – The method does not require fine-tuning, making it efficient and easy to apply in low-resource or real-world settings.\n2.\tCoarse-to-fine pipeline – The hierarchical retrieval approach (initial ranking + re-ranking) improves interpretability and modularity.\n3.\tNovel use of cloze prompting – Reformulating retrieval as a cloze-completion task provides an intuitive way to guide LMM focus on fine-grained details.\n4.\tEmpirical improvement on benchmark – Shows measurable, though small, gains on the PAB dataset, demonstrating some effectiveness."}, "weaknesses": {"value": "1.\tLimited novelty – The approach mainly combines existing LMM/LLM components and prompt engineering rather than introducing fundamentally new algorithms.\n2.\tMarginal performance gain – The reported +0.96% Recall@1 improvement is too small to justify the claimed contribution.\n3.\tOverly complex pipeline – The multi-step cloze generation, completion, and re-ranking process adds unnecessary complexity for a modest benefit.\n4.\tWeak experimental validation – Only one dataset (PAB) is used, with no cross-dataset or real-world evaluations to test generalization.\n5.\tNo statistical significance analysis – Lacks error bars, confidence intervals, or repeated trials to confirm robustness of the reported results.\n6.\tHeavy reliance on proprietary models – Depends on specific LLM/LMMs (e.g., Qwen, QVQ-Max), making reproducibility and fairness questionable.\n7.\tLack of ablation on design choices – The paper doesn’t analyze the contribution of each prompt design or masking strategy in depth.\n8.\tLimited scalability and efficiency discussion – The inference cost of multiple large model calls is not analyzed, contradicting the claim of deployment practicality."}, "questions": {"value": "Please check weaknesses, and try to argue them, I will definitely read your response, good luck!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2yD56NXKJN", "forum": "0miqobfGyv", "replyto": "0miqobfGyv", "signatures": ["ICLR.cc/2026/Conference/Submission2154/Reviewer_2Qad"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2154/Reviewer_2Qad"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933070599, "cdate": 1761933070599, "tmdate": 1762916055488, "mdate": 1762916055488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces AnomalyLMM, a novel framework designed to address the challenges of text-based person anomaly search. The task involves identifying individuals exhibiting anomalous behaviors (e.g., falling, colliding) from video data using natural language queries. This task is difficult due to fine-grained visual-text alignment and the scarcity of anomaly samples in real-world datasets.\n\nThe authors propose a coarse-to-fine retrieval pipeline to adapt Large Multimodal Models (LMMs) for this discriminative retrieval task without requiring task-specific training or fine-tuning. The method leverages a three-step process:\nCloze Generation: This step converts the text query into a \"fill-in-the-blank\" prompt to isolate key verbs and color descriptors.\nCloze Completion: The model completes the masked query based on the visual content, focusing on relevant visual cues.\nComparison & Re-ranking: The LMM compares the query and image completions, ranking the candidates based on semantic alignment.\nExperiments show that the method outperforms competitive baselines by achieving a +0.96% Recall@1 accuracy. Furthermore, the approach provides interpretability by offering clear alignments between textual queries and visual content, making it suitable for real-world deployment in public safety scenarios like smart surveillance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "No Fine-tuning Required: The proposed method is notable because it does not require additional fine-tuning, making it highly scalable and efficient for real-world applications, especially when anomaly data is scarce.\n\nCoarse-to-Fine Retrieval: The use of a coarse-to-fine pipeline that combines both general retrieval models and fine-grained semantic reasoning through Cloze Generation and Cloze Completion significantly enhances the model’s ability to align nuanced textual queries with subtle visual anomalies."}, "weaknesses": {"value": "Limited Evaluation with Diverse Datasets: While the paper presents results on the PAB dataset, a broader evaluation across multiple datasets would provide a clearer picture of the model's generalizability to various real-world scenarios. This is especially important since real-world anomaly data is often diverse and context-dependent.\n\nPotential Hallucinations in Cloze Completion: While the Cloze Completion step is intended to help LMMs focus on relevant visual regions, there is still a risk of generating incorrect completions, especially when the image-query alignment is weak. The method constrains the model to output \"UNKNOWN\" when uncertain, but this may still limit its ability to handle highly ambiguous or novel anomaly behaviors effectively. A deeper analysis of failure cases could strengthen the discussion.\n\nDependency on Pre-trained Models: Although the method is training-free, it still relies heavily on pre-trained LMMs and text-to-image retrieval models. A more detailed exploration of potential biases or limitations introduced by these models (e.g., hallucinations, errors in alignment) would be beneficial.\n\nComplexity of the Three-Step Process: While the approach is innovative, the three-step pipeline (Cloze Generation, Cloze Completion, and Comparison & Re-ranking) introduces complexity. A clearer breakdown of the computational costs and time complexity involved in each step would help assess its practical deployment feasibility."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vI9jeUM8fl", "forum": "0miqobfGyv", "replyto": "0miqobfGyv", "signatures": ["ICLR.cc/2026/Conference/Submission2154/Reviewer_MucT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2154/Reviewer_MucT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995879911, "cdate": 1761995879911, "tmdate": 1762916055155, "mdate": 1762916055155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}