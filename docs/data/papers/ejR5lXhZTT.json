{"id": "ejR5lXhZTT", "number": 4245, "cdate": 1757646323681, "mdate": 1759898043892, "content": {"title": "Using Noise to Help Reach Global Minima: Turning Matrix Completion into Noisy Matrix Sensing", "abstract": "Matrix completion (MC) is an important yet challenging non-convex problem. In realistic settings, exact recovery of $M^*$ typically requires strong incoherence and an impractically large number of observed entries. Instead of enforcing exact recovery, we inject noise perturbation to construct a closely related surrogate that turns MC into a noisy matrix sensing problem with a more benign landscape. Although this surrogate permits a slight, controllable loss in accuracy, it can be solved effectively via over-parameterization (increasing model size), echoing modern machine learning practices where large models and stochasticity (e.g., SGD, dropout) make hard objectives tractable. Under the assumption that each entry of the matrix is observed independently and uniformly, we establish explicit accuracy–probability trade-offs as functions of the sampling rate $p$ and a user-chosen noise level. Empirically, our approach succeeds in low-observation regimes where classical exact-recovery pipelines are brittle. More broadly, our approach underscores a general paradigm in which noise perturbations are combined with large models to tackle modern ML tasks, and we use MC as a clean benchmark to formalize this perspective and unify noise, over-parameterization, and recoverability within a single framework.", "tldr": "We provide recovery guarantees for matrix completion problems when observations are scarce via connecting to noisy matrix sensing", "keywords": ["non-convex optimization", "low-rank matrix optimization", "matrix sensing", "implicit bias", "tensor", "over-parametrization"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1fb3a19cb8ebf99e8e64782779dc28b102942f4d.pdf", "supplementary_material": "/attachment/b44d2194fedd208e8315585405daf3851f6d85df.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies a surrogate formulation of the classical matrix completion problem, which is inherently non-convex and typically requires strong incoherence and high sensing rates for exact recovery. The authors propose converting the problem into a noisy matrix sensing formulation by injecting controlled noise perturbations, thereby ensuring valid Restricted Strong Smoothness (RSS) and Restricted Strong Convexity (RSC) conditions.\n\nThe paper first establishes conditions under which this surrogate problem, termed $\\epsilon$-MC, admits a global solution close to the ground-truth matrix (Theorem 2.2). A key contribution is the derivation of an explicit accuracy–sampling probability trade-off, parameterized by the sampling rate $p \\in [0,1]$ and the perturbation level $\\epsilon$.\n\nWhile this formulation guarantees valid RSS and RSC constants, it still suffers from large RIP constants, making optimization challenging.\nTo address this, the authors adopt and extend the lifted tensor framework of Ma et al. (2024) to the noisy setting, leveraging overparameterization to guarantee favorable optimization geometry—specifically, that all non-global critical points are strict saddles. Numerical experiments comparing the proposed tensor PCA solver with several baselines (e.g., BM factorization, SDP relaxation, spectral reweighting) demonstrate improved recovery success rates across both independent and structured sampling regimes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The paper introduces a perturbed matrix completion formulation that ensures valid RSS and RSC constants and provides an explicit quantitative relationship between recovery accuracy, sampling rate, and noise level. \n* It extends the lifted tensor framework to the perturbed setting, proving guarantees for local minima and establishing that spurious solutions become strict saddles under the proposed formulation. \n* The inclusion of numerical experiments—though the paper is largely theoretical—adds credibility and demonstrates the practical advantage of the proposed approach over multiple baselines."}, "weaknesses": {"value": "* Scalability: The lifted-tensor solver is memory-intensive and currently applicable only to small-scale matrices. The paper does not discuss possible algorithmic strategies, approximations, or structural assumptions that could make the proposed method practical for large-scale problems. \n* Information-theoretic limits: While the paper derives explicit performance–sampling trade-offs, it does not discuss how close these results are to information-theoretic recovery limits for matrix completion. A comparison or partial converse analysis could provide valuable insight into the tightness and fundamental optimality of the proposed bounds."}, "questions": {"value": "* Are there potential directions that could make the proposed approach more scalable? \n* Can the authors provide any converse-style analysis or information-theoretic lower bounds on recovery accuracy in terms of the sampling rate $p$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ajuT9Pkdop", "forum": "ejR5lXhZTT", "replyto": "ejR5lXhZTT", "signatures": ["ICLR.cc/2026/Conference/Submission4245/Reviewer_oKEv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4245/Reviewer_oKEv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4245/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761800436027, "cdate": 1761800436027, "tmdate": 1762917251850, "mdate": 1762917251850, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors address the matrix completion problem and propose to reformulate it as a noisy matrix sensing problem. They establish theoretical conditions showing that the solution to this reformulated problem remains close to that of the original matrix completion formulation, and they further propose handling the problem through a lifted tensor framework."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Compared with existing approaches, the proposed method enables successful completion even when the sampling rate p is very small, though this comes at the cost of reduced accuracy. The idea is interesting, and the paper is well written, well structured, and clearly presented."}, "weaknesses": {"value": "I have a concern regarding the experimental validation. The authors evaluate the success rate over 20 trials using a fixed estimation error threshold and a fixed noise level. Although an explanation is provided for this choice, the experimental setup, in my view, does not convincingly support the paper’s main claim—that the proposed method enables completion at low p values but sacrifices accuracy, especially with a user-chosen noise level. To substantiate this point, the experiments should be improved, either by including additional results (e.g., varying the noise level or error threshold) or by providing a more detailed justification and interpretation of the current setup."}, "questions": {"value": "The analysis focuses solely on the overall estimation error. It would be interesting to explore where the reconstruction errors occur relative to the ground truth. Are these errors concentrated in specific regions of the estimated matrix, or are they more uniformly distributed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hbaT97ZeY6", "forum": "ejR5lXhZTT", "replyto": "ejR5lXhZTT", "signatures": ["ICLR.cc/2026/Conference/Submission4245/Reviewer_svJS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4245/Reviewer_svJS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4245/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830344441, "cdate": 1761830344441, "tmdate": 1762917251637, "mdate": 1762917251637, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The author studies how to inject noise perturbation to turn matrix completion problem into a noisy matrix sensing problem, which can be easier to solve. They show that the induced matrix sensing problem has a  RIP property and establish the accuracy-probability trade-offs for the noisy matrix sensing problem. Then, they employ the lifted tensor framework to further deal with the matrix sensing problem, to overcome the small RSC constant issue."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-structured and easy to follow. The high-level motivation and the intuitive explanation about the main theoretical results are provided in a clear way. \n\n2. The theoretical contributions are solid. The idea of introducing perturbation noise into a matrix completion problem and reformulating it as a noisy matrix sensing problem is novel. The paper also presents interesting theoretical results, such as the probability–accuracy trade-off, which is a new contribution in this area based on my knowledge."}, "weaknesses": {"value": "The main concern lies in the interpretation of the derived theoretical results. In Theorem 3.1, the upper bound includes the term $1/\\alpha_s$. However, since the transformed matrix sensing problem only has a small RSC constant, $\\alpha_s=\\varepsilon^2$ could be very small. In fact, in your experiment, the $\\varepsilon$ is set to be $1e-5$, which would render the theoretical bound practically meaningless. Similar concerns apply to Theorem 4.1, where the upper bound also contains a $1/\\varepsilon$ term, which is also very large when $\\varepsilon$ is set to be 1e-5.\n\nThen, if the perturbed noise matrix sensing problem has a small RSC constant and will finally lead to a practically meaningless result, the advantage of using this perturbation becomes unclear."}, "questions": {"value": "1. Could the authors clarify that why  the proposed approach still outperforms other baselines even if $\\varepsilon$ is set to be 1e-5 in the experiment? Does this suggest that the theoretical results may leave substantial room for improvement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Upnc8irNaC", "forum": "ejR5lXhZTT", "replyto": "ejR5lXhZTT", "signatures": ["ICLR.cc/2026/Conference/Submission4245/Reviewer_py6p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4245/Reviewer_py6p"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4245/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891792800, "cdate": 1761891792800, "tmdate": 1762917251252, "mdate": 1762917251252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}