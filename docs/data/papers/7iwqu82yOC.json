{"id": "7iwqu82yOC", "number": 11092, "cdate": 1758189001017, "mdate": 1759897609289, "content": {"title": "Adaptive Calibration for Fairer Facial Recognition", "abstract": "We introduce a novel calibration strategy for facial recognition, Adaptive Calibration, which maps  cosine similarity between normalized embeddings to well-calibrated probabilities. By incorporating local embedding context into the calibration process, Adaptive Calibration is able to correct for the fact identical distances correspond to different match probabilities in different embedding regions. This yields improved calibration that adapts to local embedding distributions without requiring demographic metadata.\n\nExperiments with standard benchmarks for face verification across a variety of pretrained models demonstrate that our approach consistently dominates existing methods both on accuracy (AUROC) and fairness metrics. Our method provides a practical solution for more equitable facial recognition systems, without requiring demographic group annotations, and while improving overall performance. Unlike existing approaches that often rely on discrete clustering with additional hyperparameters or cause abrupt calibration shifts at cluster boundaries, our method provides continuous, region-specific calibration that avoids both the algorithmic limitations and the issue of ``leveling down'' whereby fairness is achieved by degrading performance for already disadvantaged groups.", "tldr": "We introduce Adaptive Calibration, a post-hoc method that has sota fairness-accuracy trade-offs for facial recognition.", "keywords": ["facial recognition", "fairness", "calibration"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/87f317fc8214facf0e297f380169866745542bad.pdf", "supplementary_material": "/attachment/e66109c6e5cadda07f11bbd492b4d7cbcbda19a7.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes Adaptive Calibration, a postprocessing approach for recalibrating the heuristic based approaches common to facial recognition. The authors leverage a MLP to integrate local embedding context with cosine similarity scores, producing well-calibrated match probabilities. Experiments prove its effectiveness"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The fundamental idea of this paper is technically correct.\n2. The paper is well written and easy to follow.\n3. The rationale behind each section and the overall motivation are clearly presented and easy to understand."}, "weaknesses": {"value": "1. The core contribution of this work is merely concatenating average embedding positions and cosine similarity into a simple MLP or linear classifier. This \"feature concatenation + simple classifier\" approach is extremely common in machine learning and lacks technical depth or innovation.\n2. The majority of experiments in this paper are conducted on RFW, with limited evaluation on DemogPairs. This raises concerns about the comprehensiveness of the evaluation. What is the rationale behind this imbalanced dataset usage? Conducting extensive experiments across multiple diverse datasets would significantly strengthen the credibility and generalizability of the results.\n3. The authors only compare against post-processing methods. How does the proposed approach perform compared to model-level modifications? \n4. The method lacks explicit fairness objectives during training, relying solely on binary cross-entropy loss without any fairness constraints. This creates two critical issues: (1) no mechanism ensures the learned calibration function is fair across demographic groups, and (2) minimizing BCE loss does not equate to optimizing fairness metrics.\n5. The paper lacks detailed description of how the calibration set is obtained."}, "questions": {"value": "The method essentially combines average embeddings and cosine similarity through a basic MLP, which lacks novelty. The evaluation only compares against post-processing methods while ignoring model-level alternatives. Most critically, the approach lacks explicit fairness objectives."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "eGHOr64AlW", "forum": "7iwqu82yOC", "replyto": "7iwqu82yOC", "signatures": ["ICLR.cc/2026/Conference/Submission11092/Reviewer_bA9X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11092/Reviewer_bA9X"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761643897127, "cdate": 1761643897127, "tmdate": 1762922269735, "mdate": 1762922269735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a calibration technique that concatenates average embeddings and a cosine similarity score as input to a two-layer MLP trained with standard binary cross-entropy loss.\nThey show that the output of this network is more calibrated than the raw similarity scores.\nExperiments with several pre-trained networks on custom evaluation protocols on well-known benchmark datasets using outdated or custom evaluation metrics show improved performance in fairness."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "The proposed method is easy, can be applied to any pre-trained face verification network, and does not require predicting demographics."}, "weaknesses": {"value": "1. The authors employ improper evaluation metrics for verification (AUROC, accuracy) and for fairness evaluation (PE, AUC differences, AUC FNR). The authors need to read and understand the new ISO standards (ISO/IEC 19795-10) for fairness evaluation, and report for example Gini at a False Positive Disparities (FPD) of $10^{-3}$.\n\n2. The mathematical notation is unclear.\n\n   a) In line 207, the authors make use of symbols ($z_i$) where they never explain what they should represent.\n\n   b) In line 208, the authors use $s(.,.)$ as the cosine similarity, while s has been used as the arcface scale before. The authors should select a better symbol (such as $\\cos$) here.\n\n   c) Line 210 uses symbol $y_i$ without explanation. Hw are the pairs selected to train the network with? Are the two classes balanced somehow?\n\n   d) It is mysterious what $N$ means. In line 210, is seems to be the number of samples (or pairs) in the training dataset, while in line 298, it is defined as the number of demographic groups.\n\n   e) In section 5, the authors repeat equations from section 3, using different nomenclature. They should rather reference earlier equations.\n\n\n3. The design of the MLP seems counterintuitive.\n\n   a) Concatenating averaged embeddings (with 512 dimensions) and a similarity score (with 1 dimension) without proper calibration leads to a clear overrepresentation of the embedding average, while the score has little impact. An ablation study is required that shows that adding the similarity score improves performance.\n\n   b) Using ReLU as activation function for a two-layer MLP seems inappropriate. ReLU is designed to to fight against vanishing gradients in deep networks, which is not the case here. Other activation functions should be tested in an ablation study.\n\n   c) Similarly, the authors mention to have used \"one hidden layer\" without providing any intuition on how large this should be. An ablation study showing the impact of this layer size would be helpful.\n\n\n4. The description of the experimental setup is insufficient.\n\n   a) The authors make use of the \"leave-one-out cross-validation\" (line 255), but it is left entirely unclear what the \"one\" is that is left out. One subject, one demographic group? Which demographic groups are used in this work?\n\n   b) In line 262, the authors state that RFW would have ten folds, but the original evaluation protocol defines no such splits. RFW is an evaluation-only dataset, it is not designed to be trained upon. The authors need to train their method on external datasets, and evaluate on the entirety of RFW.\n\n   c) Even for the DemogPairs dataset, the authors developed their own evaluation protocol, which makes their results incomparable to other research.\n\n   d) The description of the \"Level Down\" evaluation metric is unclear, and it is not understandable why this would be a reasonable fairness metric.\n\n   e) None of the evaluated face recognition networks seems to be state-of-the-art. They are either old (FaceNet), small (ResNet-50) or trained on small datasets (VGGFace2, WebFace600k). There exist larger networks trained on more data, even provided by InsightFace.\n\n   f) The \"empirical probability\" shown in figure 3 needs to be explained.\n\n\n5. The authors make use of outdated terminology (such as false rejection rates in line 82). They should use appropriate terms here, as defined by ISO standards (ISO/IEC 19795-8).\n\n6. The authors cite many arXiv papers. They should cite their correct publication venues."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1FkRQ6KGRX", "forum": "7iwqu82yOC", "replyto": "7iwqu82yOC", "signatures": ["ICLR.cc/2026/Conference/Submission11092/Reviewer_EdhT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11092/Reviewer_EdhT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902638252, "cdate": 1761902638252, "tmdate": 1762922269273, "mdate": 1762922269273, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a post-processing calibration method to reduce demographic bias in face verification systems. After extracting face embeddings, the authors compute the cosine similarity between two embeddings and concatenate this value with the average of the two embeddings to form the input to a calibration module. Two variants are tested: a multi-layer perceptron (MLP) and a logistic regression model, both producing a final match probability. Experiments are conducted with several backbone face recognition models: FaceNet (trained on VGGFace2 and Casia-WebFace), ArcFace (trained on WebFace600k and VGGFace2), and GhostFaceNet (trained on MS1M); using the RFW and DemogPairs datasets."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed approach is conceptually simple and easy to implement.\n\n- The method could be practical for improving fairness in face recognition systems without retraining the underlying face models.\n\n- The paper focuses on bias mitigation directly at the embedding space level, which is a very interesting direction."}, "weaknesses": {"value": "- The citation to Cherepanova et al. (2022) appears to be inaccurate; I could not find the quoted statement “This imbalance is caused by minority groups occupying low-density regions of the embedding space...” (line 52) in that paper.\n\n- Figure 1 could be clarified; specifically, the meaning of “match probability” and how it differs from “match rate.”\n\n- Details about the training setup for the calibration modules are missing:\n  - What dataset is used for training the MLP and logistic regression models?\n  - Are embeddings normalized before averaging (would make a difference)?\n  - What is the size of the MLP’s hidden layer?\n\n- Figure 2 (left) is illegible; the curves are too close and colors too similar to differentiate.\n\n- The evaluation setup is unclear and does not follow standard practices in face recognition fairness literature.\n  - Why are fixed FARs of 0.1% and 1% used, when SOTA models typically report metrics in the 1e-4 to 1e-6 range?\n  - The metrics (Global FPR vs. Max Group FNR, Global FPR vs. Group FNR, ..., predictive equity, leveling down) are nonstandard and poorly explained.\n  - Without reporting simple performance gaps between demographic groups, it is hard to interpret the fairness results.\n\n- The paper cites many SOTA models in bias mitigation but evaluates primarily on older models (FaceNet) or little known architectures (GhostFaceNet).\n\n- There are frequent references to the beta calibration, but it is not properly explained.\n\n- In, Figure 3, what is meant by “empirical probability,” and how is it computed? A more natural plot would be \"empirical probability\" in the x-axis and the \"predicted probability\" in the y-axis. The adaptive calibration appears to be missing in the right plot.\n\n- Section 5 (“Theory”) presents interesting ideas but lacks convincing justification. Averaging two embeddings may place the resulting vector in a region that does not belong to either regions, so it doesn't necessarily give the local context of the embeddings. It is unclear whether concatenating the cosine score adds useful information beyond the embeddings (a 512 vector for ArcFace). An ablation study removing the cosine score input would help validate this.\n\n- AdaFace and MagFace are mentioned briefly (Lines 342–345) without context or inclusion in the main text. Only AdaFace appears in the Supplementary."}, "questions": {"value": "**Suggestions for Improvement**\n\n- Provide clear definitions for all fairness and calibration metrics.\n\n- Include standard bias reporting metrics (e.g., demographic FNR/FPR gaps).\n\n- Clarify training details for the calibration models.\n\n- Conduct ablations on the role of cosine score and embedding averaging."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "26PJs2Z0cg", "forum": "7iwqu82yOC", "replyto": "7iwqu82yOC", "signatures": ["ICLR.cc/2026/Conference/Submission11092/Reviewer_EmHe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11092/Reviewer_EmHe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942599560, "cdate": 1761942599560, "tmdate": 1762922268691, "mdate": 1762922268691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Adaptive Calibration (AC) as a post-hoc fairness and score calibration technique for face recognition systems.\nThe method uses cosine similarity and the mean embedding vector of two faces as input to a small  MLP or linear model that outputs calibrated match probabilities. By learning region-specific mappings without demographic labels, the authors claim AC improves both fairness and accuracy compared to prior post-processing methods. The AC is evaluated across several datasets and models reporting improvements in AUROC, fairness AUC metrics, and predictive equity gaps."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation and accessible formulation. The motivation of post training solution is valid and clear. \n- language is clear and the method is easily reproducable. \n- Public release of calibration folds is a positive step for reproducibility."}, "weaknesses": {"value": "- Outdated experimental foundation with heavy reliance on FaceNet (2015) which has no official release and known calibration flaws. This unfortunately makes some conclusions obsolete.\n-The proposed approach is a slight variant of FairCal by learning a monotonic mapping conditioned on embeddings rather than clusters. There is no clear theoretical differentiation from prior post-hoc calibration methods. I suggest adding a table showing this theoretical differences more clearly.\n- even though FTC mention as a very related solution. and is mentioned that it will be part of the comparison, it is not in the comparison tables and it is not mentioned why is that. Very suspicious reporting.  \n- Modern architectures (AdaFace, ArcFace R100) are mentioned but only partially evaluated.  most fairness claims stem from legacy models (different unofficially released facenets)\n-Improvements are within error margins with no formal statistical tests support claims of superiority"}, "questions": {"value": "- Why rely on FaceNet, an outdated model with no official release, for most conclusions?\n- Why is FTC cited and discussed but omitted from all experimental comparisons?\n- How do the authors justify using non-standard fairness metrics rather than community widely accepted ones?\n- Are the improvements over FairCal statistically significant ?\n- Do the reported fairness gains persist for modern models (ArcFace-R100, AdaFace) trained on large datasets like WebFace42M?\n- Does AC’s MLP variant introduce any risk of overfitting given small calibration sets?\n- How does AC perform on fairness metrics that measure disparity at fixed thresholds, rather than integrated AUC values?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PL6MBaQRjW", "forum": "7iwqu82yOC", "replyto": "7iwqu82yOC", "signatures": ["ICLR.cc/2026/Conference/Submission11092/Reviewer_m1FZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11092/Reviewer_m1FZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762185662515, "cdate": 1762185662515, "tmdate": 1762922268037, "mdate": 1762922268037, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}