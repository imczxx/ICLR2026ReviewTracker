{"id": "aoNqu2N8MC", "number": 25077, "cdate": 1758363778286, "mdate": 1763134635601, "content": {"title": "Dexterous Non-Prehensile Manipulation for Ungraspable Objects via Extrinsic Dexterity", "abstract": "Objects with large base areas become ungraspable when they exceed the end-effector’s maximum aperture. Existing approaches address this limitation through extrinsic dexterity, which exploits environmental features for non-prehensile manipulation. While grippers have shown some success in this domain, dexterous hands offer superior flexibility and manipulation capabilities that enable richer environmental interactions, though they present greater control challenges. Here we present ExDex, a dexterous arm-hand system that leverages reinforcement learning to enable non-prehensile manipulation for grasping ungraspable objects. Our system learns two strategic manipulation sequences: relocating objects from table centers to edges for direct grasping, or to walls where extrinsic dexterity enables grasping through environmental interaction. We validate our approach through extensive experiments with dozens of diverse household objects, demonstrating both superior performance and generalization capabilities with novel objects. Furthermore, we successfully transfer the learned policies from simulation to a real-world robot system without additional training, further demonstrating its applicability in real-world scenarios. Project website: https://exdex1.github.io/ExDex/.", "tldr": "", "keywords": ["dexterous manipulation", "reinforcement learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/d59239071da98920c4c955f8132023ef48d41cd5.pdf", "supplementary_material": "/attachment/26bb4d1fed6ca411d46ccd0632c9918a66ff92aa.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces an approach that grasps ungraspable objects via extrinsic dexterity. The core idea is to leverage the environment, including the table edge and the wall, to aid grasping. The framework is composed of a high-level planner, a low-level controller, and a joint fine-tuning framework. The planner takes the environment observation as input and outputs the commands for the low-level policy. The low-level policy is composed of three primitive skills, including pushing, pivoting to the wall, and grasping the object from the table edge. The authors conducted extensive experiments to validate the effectiveness of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Good motivation. The paper is well motivated. Leveraging extrinsic dexterity to aid the process of grasping ungraspable objects is well-motivated. Endowing the policy with the ability to perceive the environment and utilizing the environment to aid the task completion is an interesting research direction.\n- Well-designed method. The whole framework that incorporates the high-level planner and the low-level controller to solve the task is well-designed.\n- Well-written and easy to follow."}, "weaknesses": {"value": "- Limited technical contribution. Utilizing extrinsic dexterity to grasp ungraspable objects is not a new thing. Leveraging a hierarchical framework to solve the problem is also not a new concept. The design of the planner and the design of the low-level policies also lack originality and novelty. \n- Restricted task complexity. For some objects, it seems that grasping with the edge or the well is not a necessity. For instance, to grasp the object shown in Figure 3, the robot only needs to grasp one side of the object. In some cases, pivoting the object using the table and then grasping the object is enough."}, "questions": {"value": "- How do you judge whether the training is successful in the curriculum learning design?\n- Why BC for distillation? Why not use DAgger?\n- Could the method be utilized in more challenging scenarios, like grasping very thin objects?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FNCe8dw4AZ", "forum": "aoNqu2N8MC", "replyto": "aoNqu2N8MC", "signatures": ["ICLR.cc/2026/Conference/Submission25077/Reviewer_BRrQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25077/Reviewer_BRrQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635834182, "cdate": 1761635834182, "tmdate": 1762943316548, "mdate": 1762943316548, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mb3gfUtrAg", "forum": "aoNqu2N8MC", "replyto": "aoNqu2N8MC", "signatures": ["ICLR.cc/2026/Conference/Submission25077/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25077/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763134634838, "cdate": 1763134634838, "tmdate": 1763134634838, "mdate": 1763134634838, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a sim-to-real approach for learning to manipulate objects through extrinsic contacts. To address the challenges of long-horizon execution and complex spatial interactions, the authors propose a hierarchical method that trains a coarse high-level planner and low-level primitive policies in simulation to decompose the manipulation task. The experiments focus on two scenarios: object pivoting against a wall and slide-and-grasp of flat objects on a tabletop."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly written and well-structured.\n\n2. The studied problem—object manipulation via extrinsic contacts—is both interesting and relevant to advancing robotic dexterity.\n\n3. The hierarchical decomposition of planning and control presents a reasonable direction for addressing long-horizon manipulation tasks."}, "weaknesses": {"value": "1. The task decomposition appears to be too domain-specific. For example, training a binary classifier to decide whether to use the wall or the table edge restricts the method’s applicability and limits generalization across unseen environments.\n\n2. The experimental results are not entirely convincing. See below.\n\n(A) In the wall-pivoting experiments, the authors use only soft objects, which oversimplifies the problem. Prior work on object pivoting typically employs rigid objects [1], requiring precise force control and offering a more meaningful evaluation of the RL-based policy. In the current setting, the advantages of learning-based control are unclear, since teleoperation or scripted control could likely achieve similar results. \n\n(B) The edge-slide-and-grasp experiment also appears too simple. The demonstrated behavior—pushing and grasping large, compliant objects—could potentially be achieved through motion planning with heuristic stopping conditions, rather than requiring learned policies.\n\n3. The framework is not novel [2]. However, system papers are often less novel at a high level, so this is acceptable.\n\n4. The terminology could be more precise. For instance, describing the objects as ungraspable is inaccurate—they are conditionally graspable, depending on their configuration. The naming of ExDex as a \"framework\" seems somewhat overstated, as the demonstrated skills remain relatively simple. It would strengthen the paper to showcase a more sophisticated manipulation behavior—e.g., grasping a flat object by leveraging the table as a pivot point to rotate and lift it.\n\n[1] Xu et al. Rotating objects via in-hand pivoting using vision, force and touch. In IROS 2023.\n[2] Zeng et al. Learning synergies between pushing and grasping with self-supervised deep reinforcement learning. IROS 2018."}, "questions": {"value": "I wonder if the authors have tried to use imitation learning or model-based methods. I think the paper can be strengthened significantly by including more challenging setups as stated above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5uUg2G9TMB", "forum": "aoNqu2N8MC", "replyto": "aoNqu2N8MC", "signatures": ["ICLR.cc/2026/Conference/Submission25077/Reviewer_CzW8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25077/Reviewer_CzW8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954790563, "cdate": 1761954790563, "tmdate": 1762943316220, "mdate": 1762943316220, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ExDex, a dexterous arm-hand system that learns to manipulate objects too large to grasp directly. The key idea is to exploit extrinsic dexterity — using environmental features like walls and table edges — to enable grasping through contact-rich, non-prehensile actions. The method combines a hierarchical reinforcement learning framework with a high-level planner (to select external contact goals) and a low-level controller (to execute pushing and grasping skills). The authors demonstrate both simulation and real-world transfer, reporting strong performance on diverse household objects and zero-shot generalization to unseen items."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**1. Real-world experiments add value.** The paper showcases real-world deployments of the system."}, "weaknesses": {"value": "**1. Under-justified use of dexterity.** The paper titles itself with \"Dexterous Non-prehensile Manipulation.\" I, however, do not see that experiments designed in the study are championing the use of dexterity. Even though a multi-fingered robot hand was employed, fingers are never truly used to the fullest extent, let alone the definition of dexterity can extend to the use of whole body surfaces and not limited to just the use of fingers. The poses of fingers in this study remain mostly unchanged throughout the trajectory.\n\n**Therefore, on a problem level, I do not see a special contribution to a novel experimental setting for robot learning.** To me, this is not different from prior works done by Matt Mason and others on studying non-prehensile manipulation with simpler manipulators and grippers. I don't see why the objects are ungraspable; most of them can be grasped by a suction cup or standard grippers. \n\n**2. The method is not addressing a general enough problem** The method proposed in the manuscript conjectures hand-crafted components such as pi_{wall} and pi_{edge}. This can work for a couple of tasks demonstrated in the study, but it will become intractable to implement given the infinite complexity of the physical world.\n\nOverall, the proposed method seems to me like a complicated pipeline tailored for this specific toy task. But the toy task is a human-proposed artifact. There is no strict formal definition of what we mean by \"non-prehensile manipulation.\" Therefore, I am very worried about what insights from this work can contribute to the coming age of robot learning in the long run.\n\nThis is not to mention that there are three stages in the proposed approach. It is unclear how this can scale to a large set of environments where there do not exist walls or edges."}, "questions": {"value": "Please see the weaknesses section, thank you!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xulnYX6FQd", "forum": "aoNqu2N8MC", "replyto": "aoNqu2N8MC", "signatures": ["ICLR.cc/2026/Conference/Submission25077/Reviewer_hNeG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25077/Reviewer_hNeG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955090977, "cdate": 1761955090977, "tmdate": 1762943316020, "mdate": 1762943316020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the challenge of manipulating large, flat, or wide objects that cannot be grasped directly by a dexterous robotic hand. The authors propose ExDex, a hierarchical reinforcement learning framework that enables non-prehensile manipulation by leveraging environmental features such as table edges and walls. The system includes a high-level planner that predicts suitable environmental contact points and a low-level policy that executes dexterous pushing and grasping motions. They are then jointly fine-tuned to align sub-policies for smoother skill transitions. The framework is trained in simulation using domain randomization and transferred to a real-world UR5e + Inspire Hand setup via policy distillation. Experiments demonstrate successful object relocation and grasping on various shapes and configurations, achieving over 80% success rate on real-world trials."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(+) The paper extends the concept of extrinsic dexterity to multi-finger hands. This is a meaningful contribution that bridges environmental affordance exploitation with dexterous control.\n\n(+) Separating high-level contact planning (wall vs. edge) and low-level control (pushing and grasping) leads to interpretable and trainable sub-policies. The joint fine-tuning stage is a thoughtful addition to address state mismatch between phases.\n\n(+) The paper clearly explains training setups, policy structures, and the staged reward mechanism. The figures and diagrams effectively illustrate how each component contributes to the overall pipeline.\n\n(+) The authors demonstrate successful real-world deployment."}, "weaknesses": {"value": "(-) Limited diversity and scale of evaluation. Although 21 simulations and 10 real-world objects are reported, many are similar box-like shapes. The claim of “generalization to diverse objects” feels overstated;\n\n(-) Slow motions. The result videos show relatively slow, quasi-static behaviors. It’s unclear if this limitation arises from the control policy, reward design, or simulation dynamics.\n\n(-) Weak baseline selection and unclear fairness. The “Random Target” baseline unexpectedly achieves non-trivial success rates (50-60%) in Table 1, which suggests that the environment setup or success metric might be forgiving. More rigorous baselines, such as model-predictive control with explicit contact reasoning, would strengthen the evaluation.\n\n(-) Limited analysis of sim-to-real challenges. The paper states a “successful zero-shot transfer,” but does not isolate what makes transfer hard: whether the bottleneck lies in perception (pose estimation), contact dynamics, or actuation latency.\n\n(-) Real-world validation remains qualitative. The real experiments are convincing as proofs of concept, but lack comparative baselines or failure analysis under diverse conditions (e.g., clutter, lighting, or camera noise)."}, "questions": {"value": "What is the primary bottleneck for motion speed? Is it because of policy frequency?\n\nWhy does the Random Target baseline perform reasonably well (success rate)? Does this indicate that the planner’s learned predictions add only marginal benefit?\n\nHow does the method scale to environments with multiple contact affordances or cluttered scenes?\n\nWhat are the dominant failure modes in real-world deployment? Is that pose estimation error, grasp instability, or object dynamics mismatch?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NJYVDL92XO", "forum": "aoNqu2N8MC", "replyto": "aoNqu2N8MC", "signatures": ["ICLR.cc/2026/Conference/Submission25077/Reviewer_b7AY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25077/Reviewer_b7AY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762767055301, "cdate": 1762767055301, "tmdate": 1762943315787, "mdate": 1762943315787, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}