{"id": "ZOuU0udyA4", "number": 3594, "cdate": 1757484517098, "mdate": 1763715398400, "content": {"title": "MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow", "abstract": "Modern clinical diagnosis relies on the comprehensive analysis of multi-modal patient data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in Vision–Language Models (VLMs) and agent-based methods are reshaping medical diagnosis by effectively integrating multi-modal information. However, they often output direct answers and empirical-driven conclusions without clinical evidence supported by quantitative analysis, which compromises their reliability and hinders clinical usability. \nHere we propose MedAgent-Pro, an agentic reasoning paradigm that mirrors modern diagnosis principles via a hierarchical diagnostic workflow, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, a retrieval-augmented generation agent is designed to access medical guidelines for alignment with clinical standards.  For patient-level reasoning, MedAgent-Pro leverages professional tools such as visual models to take various actions to analyze multi-modal input, and performs evidence-based reflection to iteratively adjust memory, enforcing rigorous reasoning throughout the process. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro over mainstream VLMs, agentic systems and leading expert models. Ablation studies and expert evaluation further confirm its robustness and clinical relevance. Anonymized code link is available in the reproducibility statement.", "tldr": "This paper proposed MedAgent-Pro, an evidence-based reasoning agentic system designed to achieve reliable, explainable, and precise medical diagnoses.", "keywords": ["Medical AI", "Agentic AI"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e7110936d04fac257223b380ae256b851b59bfa3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces **MedAgent-Pro**, an agent-based system designed for multi-modal medical diagnosis. The authors identify a key limitation in current Vision-Language Models (VLMs) and agentic systems: they tend to provide direct, empirical-driven answers without the step-by-step, evidence-based reasoning that is fundamental to real-world clinical practice.\n\nTo address this gap, MedAgent-Pro proposes a hierarchical workflow that mimics clinical procedure. This workflow is divided into two main stages: **(i)** Disease-Level Planning: A Retrieval-Augmented Generation (RAG) agent accesses a medical knowledge base to formulate a standardized, multi-step diagnostic plan based on established clinical guidelines. **(ii)** Patient-Level Reasoning: The agent executes this plan step-by-step, analyzing the specific patient's multi-modal data. This execution phase leverages a toolbox of \"professional tools,\" such as segmentation models, to perform quantitative analysis (e.g., calculating the cup-to-disc ratio) alongside qualitative assessments.\n\nThe authors present an extensive evaluation across more than 10 imaging modalities and 50 diseases, claiming that MedAgent-Pro substantially outperforms general VLMs like GPT-4o, other medical agent systems, and task-specific expert models. The system's alignment with clinical workflows is further supported by positive evaluations from clinical experts. Overall, this is a fairly strong paper."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "### **Originality and Significance:** \nThe most significant strength is the novel agentic paradigm itself. By formalizing the clinical diagnostic process into a hierarchical workflow (plan-via-RAG, execute-via-tools), the paper moves the field from \"black-box\" pattern recognition towards auditable, evidence-based reasoning. This directly addresses the critical needs of reliability, safety, and trustworthiness for medical AI.   \n\n\n### **Problem Formulation:** \nThe paper does an excellent job of motivating the work, clearly articulating the gap between current VLM capabilities (which provide \"empirical-driven conclusions\") and the needs of clinical practice (which demands \"quantitative analysis\" and structured reasoning).   \n\n\n### **Experimental Breadth:**\nThe evaluation is a major strength. The authors test their system on a very wide array of tasks, covering over 10 imaging modalities, 20+ anatomies, and 50+ diseases, providing strong evidence for the generalizability of the framework.   \n\n\n### **Clinician Evaluation:** \nThe inclusion of a qualitative evaluation by clinical experts is a crucial addition. Reporting that clinicians rated MedAgent-Pro's outputs higher on dimensions like \"reasoning coherence\" and \"clinical reliability\" provides strong, practical validation of the paper's central thesis."}, "weaknesses": {"value": "### **Inadequate Contextualization with Prior Work:** \n\nThe paper claims that current medical agentic systems \"simply glued all tools together\". This may be an oversimplification that ignores recent, highly relevant work. The authors should cite and differentiate their approach from other multi-modal medical agents like \"SMR-agents\" (Wang et al., [1]) and \"AURA\" (Fathi et al., [2]), which also appear to integrate multi-modal reasoning and tool use in a sophisticated manner. A more nuanced comparison in the Related Work section is needed to clearly establish this paper's specific contributions over the state-of-the-art.\n\n### **The \"ToolBox\" is Underspecified:**\nThe system's performance is critically dependent on its \"Available ToolBox\". The paper mentions \"visual/coding models\" and gives MedSAM as an example, but a comprehensive list of all tools, their specific capabilities, and their individual performance is not provided. Without this, it's impossible to assess the agent workflow independently of the tools. \n\n### **\"Evidence-Based Reflection\" is Unclear:**\n This mechanism is highlighted as a key contribution but is operationally vague. How does the agent \"evaluate the reliability\" of a step's output? Is this a heuristic, a learned classifier, or a VLM self-critique prompt? The \"Evi. Reasoning\" block in Figure 2 is abstract. This core mechanism needs to be formalized.\n\n\n### **Conceptual Limitation to Sequential Reasoning:** \nThe proposed methodology is inherently bounded to sequential reasoning steps. The RAG agent generates a linear plan, and the execution agent follows it. The paper does not discuss or explore scenarios that might require parallel exploration of different diagnostic paths or more complex, branching decision-making. This is a notable limitation, as real-world diagnostics can often be non-linear.\n\n### **Confusing Mathematical Notation:** \nThe mathematical expressions in Section 3.2, such as representing inputs and outputs as key-value pairs (e.g., $\\mathcal{P}i:r_{i}=\\langle k_{r_{i}},v_{r_{i}}\\rangle$), add a layer of formalism that is arguably unnecessary and confusing. A-plainer textual description of how data is passed and transformed between steps would significantly improve clarity and accessibility.\n\n### **RAG Knowledge Base:** \nThe paper relies on a \"Medical Knowledge Base\" sourced from MedlinePlus. The scale, and curation of this knowledge base, as well as the indexing and retrieval process, are mentioned but could be detailed further. The quality of the RAG-generated plan is a critical bottleneck that is not explicitly evaluated.\n\n[1] Wang et al., \"SMR-agents: Synergistic medical reasoning agents for zero-shot medical visual question answering with MLLMs\"\n\n[2] Fathi et al., \"AURA: A Multi-modal Medical Agent for Understanding, Reasoning and Annotation\""}, "questions": {"value": "See \"Weaknesses\" for questions. **Note** that, if the related works section and other problems in Weaknesses are not addressed the rating can be subject to deduction."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xtLHv3rLAA", "forum": "ZOuU0udyA4", "replyto": "ZOuU0udyA4", "signatures": ["ICLR.cc/2026/Conference/Submission3594/Reviewer_ACbS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3594/Reviewer_ACbS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3594/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761541739157, "cdate": 1761541739157, "tmdate": 1762916852942, "mdate": 1762916852942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work explores reasoning agentic system of medical diagnosis. By disease-level standardized plan generation and patient-level personalized step-by-step reasoning, MedAgent-Pro presents modern diagnosis principles via a hierarchical diagnostic workflow. They leverages professional tools such as visual models to take various actions to analyze multi-modal input, and performs evidence-based reflection. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases are conducted."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tEvaluations across 10+ imaging modalities, 20+ anatomies, and 50+ diseases validate its universality.\n2.\tThe proposed system fully leverages existing models in their toolbox to provide clinical evidence.\n3.\tThe proposed model is trustworthy because of more visual cues and indicators compared to vanilla VLMs.\n4.\tComprehensive ablations further validate the effectiveness of major components in the agentic system."}, "weaknesses": {"value": "1.\tThe author proposed evidence-based system. However, the proposed system is more like an engineering product, which lack of architecture innovation and similar to other agentic systems[1,2].\n2.\tThe author should provide analysis in view of visual cues compared to medical world model[3], which was also designed for treatment planning. Is the proposed system providing any visual evidence?\n3.\tWhich part of MedAgent-pro is finetuned? Is the backbone GPT-4o finetuned on downstream data? What about the compared methods? The fairness should be ensured.\n4.\tIn Evidence-based Reflection, is it possible that s_i is always continue, resulting in unexpected dead loop?\n5.\tClinical guidelines may be inconsistent across different areas and hospitals. How can the proposed system overcome such inconsistency?\n\n[1] Zhu Y, He Z, Hu H, et al. MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks[J]. arXiv preprint arXiv:2505.12371, 2025.\n[2] Zhu Y, Qi Y, Wang Z, et al. HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research[J]. arXiv preprint arXiv:2508.02621, 2025.\n[3] Yang Y, Wang Z Y, Liu Q, et al. Medical world model: Generative simulation of tumor evolution for treatment planning[J]. arXiv preprint arXiv:2506.02327, 2025."}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "35Ng4qA7dW", "forum": "ZOuU0udyA4", "replyto": "ZOuU0udyA4", "signatures": ["ICLR.cc/2026/Conference/Submission3594/Reviewer_HerW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3594/Reviewer_HerW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3594/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761558984376, "cdate": 1761558984376, "tmdate": 1762916852720, "mdate": 1762916852720, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MedAgent-Pro, an agentic reasoning workflow designed to emulate evidence-based clinical diagnosis. The system operates on a hierarchical structure, using planning, RAG and reasoning agents to ensure reliability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The primary strength of this work is its alignment with medical practice, from an empirical one-hop VQA to a structured and evidence-based reasoning process."}, "weaknesses": {"value": "My major comments are:\n\n1. The system's effectiveness, particularly its quantitative analysis which drives the performance gains, relies on the availability of specialized visual tools for a given task. The workflow's performance for diseases or modalities lacking such robust, pre-existing tools is less clear. While the NEJM results without tools are still strong, they lack the key quantitative grounding that differentiates the method.\n2. The VLM  remains a single point of failure for several critical steps. The VLM is solely responsible for generating the entire diagnostic plan from guidelines, performing all qualitative analysis, executing the evidence-based reflection, and assigning the final risk-based weights. Any hallucination or error in these steps could compromise the entire workflow.\n3. The main comparison tables compare MedAgent-Pro (with tools) against general VLMs (without tools). This confounds the benefit of the agentic workflow with the benefit of simply having tool access. A more rigorous comparison, presented only in Appendix B.4, shows that while MedAgent-Pro still wins, giving baselines tool access does significantly close the gap. This stronger, more fair comparison should have been centered in the main paper.\n4. The evaluation on the MITEA dataset (heart disease) was simplified from a 7-class problem to a binary classification task (healthy vs. heart disease) due to limited samples per category. This simplification is a significant departure from a realistic clinical scenario, where differentiating between various heart conditions (e.g., amyloidosis vs. hypertrophy) is the critical diagnostic task.\n5. The RAG agent's knowledge base is MedlinePlus. However, clinical-grade diagnosis typically relies on more complex professional guidelines from medical societies (e.g., ACC/AHA, etc.)."}, "questions": {"value": "Please see the weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LdkyammdrX", "forum": "ZOuU0udyA4", "replyto": "ZOuU0udyA4", "signatures": ["ICLR.cc/2026/Conference/Submission3594/Reviewer_nJkL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3594/Reviewer_nJkL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3594/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876480685, "cdate": 1761876480685, "tmdate": 1762916852335, "mdate": 1762916852335, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MedAgent-Pro, an agentic hierarchical workflow system for evidence-based, multi-modal medical diagnosis. The approach separates disease-level planning (standardized per guidelines using a retrieval-augmented generation agent) and patient-level stepwise reasoning empowered by professional tools (e.g., visual models, coding agents), integrating iterative reflection for reliability. MedAgent-Pro is benchmarked on extensive multi-modal datasets, showing performance gains over mainstream VLMs, agentic baselines, and expert models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The hierarchical design effectively mirrors medical diagnostic principles, with disease-level planning driven by retrieval from guidelines and patient-level personalized analysis.\n2. The RAG-based incorporation of external domain knowledge into the planning stage supports clinical transparency."}, "weaknesses": {"value": "1. Although the hierarchical structuring and rigorous evidence focus are valuable, the architecture closely resembles recent work in multi-agent, RAG-augmented, and tool-integrated medical AI (e.g., MedAgents, MMedAgent, MDAgent, and others in Table 1). Moreover, the overall contribution of this work appears rather limited. Many of the claimed innovations rely on techniques that have already become widely adopted or established in the field. As such, the paper seems more like an integration or system-level implementation of several existing popular paradigms, rather than presenting a novel method.\n\n2. Can the authors clarify and mathematically specify the state assessment function $\\phi$ used during patient-level reasoning? How is output reliability judged, is it a learned model, rule-based, or probabilistically estimated?\n\n3. How are risk-based weights $\\mathcal{W}$ in risk score computation (p.5) defined in practice? Are they derived from clinical guidelines directly, learned via validation, or optimized by the system?\n\n4. For clinical expert evaluation, please elaborate on the number of raters, the randomization protocol, inter-rater agreement metrics (such as Cohen’s kappa or ICC), and whether any anchoring or exposure effects could have occurred."}, "questions": {"value": "see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lTZfQMEp9z", "forum": "ZOuU0udyA4", "replyto": "ZOuU0udyA4", "signatures": ["ICLR.cc/2026/Conference/Submission3594/Reviewer_roDJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3594/Reviewer_roDJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3594/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762071287818, "cdate": 1762071287818, "tmdate": 1762916851995, "mdate": 1762916851995, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Replyl by Authors"}, "comment": {"value": "Dear Area Chairs and Reviewers,\n\nWe sincerely thank all reviewers for their time and thoughtful assessment of our submission. We are encouraged by the positive comments shared across the reviews, including t[clinical grounding] and [structured diagnostic workflow] by Reviewers **nJkL** and **ACbS**, [comprehensive evaluation] by Reviewers **HerW** and **ACbS**, [clarity of presentation] from Reviewers **roDJ** and **ACbS**. We greatly appreciate these acknowledgement of the motivation and contributions of our work.\n\nSeveral concerns, especially from *Reviewer roDJ*, seem to arise from a different interpretation of our system’s design. We would like to clarify that our intention is not to introduce a new model, but rather to present a **flexible agentic workflow** for clinically grounded diagnosis. Our main contribution is offering a framework that organizes existing tools in a clinical-grounded way to perform long-chain diagnostic reasoning instead of statically using tools. \nWe also understand that some comments may reflect viewing our tasks as conventional VQA; however, our framework is designed for complex diagnostic scenarios that require *multi-step reasoning* and *tool-based quantitative analysis*, which go beyond typical VQA settings.\nWe have improved the **Introduction** and **Related Work** sections to clearly distinguish our approach from recent systems such as SMR-agents, AURA, MedAgentBoard (NeurIPS 2025), and HealthFlow, as highlighted by the reviewers.\n\nWe have also addressed all remaining concerns point-by-point, including those related to evidence-based reflection, implementation details, and the RAG knowledge base. The revised manuscript incorporates the following updates:\n1. revisions to the **Introduction**, **Related Work**, and **Appendix C.2** to better articulate our motivation and clarify connections to existing systems;\n2. refined descriptions of the RAG pipeline and workflow formulation on **p.4** and **p.5**;\n3. reorganized toolset ablation results into **p.8** of the main text;\n4. additional experimental results for the MITEA sub-tasks in **Appendix A.6**;\n5. additional experiments using different RAG knowledge sources in **Appendix B.2**; and\n6. detailed clarification of the toolset and evidence-based reflection mechanism in **Appendix E.4** and **Appendix E.5**.\n\nWe thank all reviewers again for their valuable feedback, have **highlighted all modifications in blue** in the revised manuscript, and welcome further discussion if needed.\n\nSincerely,\n\nAuthors of Submission 3594"}}, "id": "RJCWivthIo", "forum": "ZOuU0udyA4", "replyto": "ZOuU0udyA4", "signatures": ["ICLR.cc/2026/Conference/Submission3594/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3594/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission3594/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763715358335, "cdate": 1763715358335, "tmdate": 1763715358335, "mdate": 1763715358335, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}