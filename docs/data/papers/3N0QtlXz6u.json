{"id": "3N0QtlXz6u", "number": 14720, "cdate": 1758242412155, "mdate": 1759897352989, "content": {"title": "Data2Decision: A Prescriptive Analytics Data Agent Bridging Enterprise Information and Optimal Decisions", "abstract": "Enterprise business analytics has evolved from simple reporting to sophisticated decision-support systems. Prescriptive analytics, as the most advanced form of business analytics, aims to recommend optimal actions based on data, yet the field lacks standardized benchmarks that reflect real-world complexity where optimization parameters must be extracted from enterprise databases. We present Data2Decision, the first data agent specifically designed for database-grounded prescriptive analytics that produces mathematically optimal decisions, accompanied by Schema2Opt, a comprehensive benchmark simulating enterprise decision environments. Schema2Opt transforms SQL database schemas into realistic optimization problems, providing complete business contexts, operational databases, and verified solutions. Our Data2Decision agent tackles these scenarios through a two-stage pipeline with test-time scaling: first extracting optimization parameters from databases via SQL generation, then formulating and solving optimization models with multi-solver consensus, achieving end-to-end automation without manual preprocessing.", "tldr": "", "keywords": ["Prescriptive Analytics", "NL-to-OPT", "Enterprise Decision-making", "Data Agent"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a67b9b2b8f92498b727ca5ec574231ff8a841c67.pdf", "supplementary_material": "/attachment/6a8dcb9a42771d11de2c64bffe49e584fc86d305.zip"}, "replies": [{"content": {"summary": {"value": "This paper formulates a prescriptive analytic problem in real-world enterprise decision-making scenarios, which requires extracting optimization parameters from enterprise databases. Based on the problem formulation, this paper presents Schema2Opt, a framework for synthetic dataset generation that discovers optimization problems from database schemas. This paper further introduces a Data2Decision framework for database-grounded prescriptive analytics that first extracts optimization parameters from databases and then solves the optimization problem."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper formulates a new prescriptive analytic problem based on real-world enterprise applications with the shift to a bottom-up paradigm. The proposed Schema2Opt dataset generation framework can address the lack of realistic benchmark for database-grounded prescriptive analytics. The paper introduces the first agentic framework Data2Decision to solve database-grounded prescriptive analytic problems. The technical details of Schema2Opt are well presented."}, "weaknesses": {"value": "While the motivation of the paper is clear and Schema2Opt is well presented, the presentation of Data2Decision lacks details, such as the instruction templates for agents. The techniques proposed for Data2Decision seem incremental, such as the one in Section 4.3. It is unclear how some of the techniques would benefit databased-grounded prescriptive analytics.\nThe experimental setting in Section 5.1 is not detailed enough. The information on the backbone model for Data2Decision is not provided. Further information on baselines such as ZeroShot would be appreciated.\nExperimental evaluation is not thorough. Evaluations on some real-world datasets would be helpful for a fairer comparison. The parameter analysis is incomplete. The authors Could perform analysis on adaptive temperature scheduling. It would also be interesting to see which of the two stages in Data2Decision contributes more to the performance gains over baselines.\nI assume the backbone models for Data2Decision are the same as those in Schema2Opt, i.e., GPT-4o and DeepSeek-V3. Would this introduce information leakage and offer extra advantages to Data2Decision? Another concern I have is that most of the problems generated by Schema2Opt are simple ones according to Figure 4, which hampers the usefulness of the benchmark."}, "questions": {"value": "What is the backbone model of Data2Decision in the experiments?\nCould the authors please confirm whether it is GPT-4o, GPT-4o-mini, or both that are used in the experiments?\nWould it be reasonable to also evaluate GPT-4o and DeepSeek-V3 in the end-to-end models?\nTypos, such as the sentence repetition in lines 303-305."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dIBe1DOUi2", "forum": "3N0QtlXz6u", "replyto": "3N0QtlXz6u", "signatures": ["ICLR.cc/2026/Conference/Submission14720/Reviewer_iACw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14720/Reviewer_iACw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761578726162, "cdate": 1761578726162, "tmdate": 1762925082877, "mdate": 1762925082877, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Data2Decision, an LLM-based “prescriptive analytics agent” that supposedly bridges database querying and optimization modeling. The system works in two stages:\n\nIt generates SQL queries to extract parameters (decision variables, coefficients, constraints) from relational databases.\n\nIt converts the extracted content into solver code (e.g., Gurobi, Pyomo) to find optimal decisions.\n\nTo evaluate this, the authors propose Schema2Opt, a synthetic benchmark created by converting SQL schemas (from the Spider dataset) into optimization problems via alternating LLM agents (“OR Expert” and “Data Engineer”). The authors claim this is the first bottom-up benchmark for prescriptive analytics, arguing that prior Text-to-OPT work (e.g., ORLM, OptiMUS, Chain-of-Experts) used oversimplified textbook problems.\n\nExperiments compare Data2Decision against existing Text-to-OPT methods and LLM baselines. The proposed model achieves around 69.5% accuracy on the DeepSeek-V3 test set and 53.8% on the GPT-4o test set, outperforming some baselines but still with relatively low absolute scores."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Timely topic: Addresses the emerging intersection of LLMs, databases, and optimization.\n\nSystem completeness: The two-stage SQL-to-solver pipeline is implemented end-to-end.\n\nAttempt at benchmark creation: Schema2Opt provides a reproducible dataset and detailed appendices."}, "weaknesses": {"value": "Synthetic self-validation loop: Both dataset and evaluation rely entirely on LLM-generated content; no human, real-world, or baseline dataset validation.\n\nLimited realism: Databases with ≤5 tables cannot represent enterprise decision complexity; most tasks reduce to toy LPs.\n\nLow absolute performance: 50–70 % accuracy on synthetic data suggests instability and poor generalization.\n\nOverstated novelty: The “first” claim ignores prior prescriptive or decision-optimization agents (e.g., PresAIse, InsightBench, AutoFormulation).\n\nWeak analysis: No runtime, ablation on SQL errors, or cross-domain transfer tests.\n\nLack of interpretability: The removal of explicit mathematical formulations makes the pipeline less transparent and potentially harder to trust."}, "questions": {"value": "1- How is “accuracy” defined when multiple optimal solutions exist?\n\n2- Could Schema2Opt tasks be manually inspected or validated by OR experts?\n\n3- How large are the databases and optimization problems? Are they solvable in milliseconds or minutes?\n\n4- Would the system still work on non-synthetic corporate data (e.g., ERP or logistics datasets)?\n\n5- What is the runtime overhead of running 10-attempt test-time scaling and multi-solver validation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WunKRX62XX", "forum": "3N0QtlXz6u", "replyto": "3N0QtlXz6u", "signatures": ["ICLR.cc/2026/Conference/Submission14720/Reviewer_vUcr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14720/Reviewer_vUcr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791186520, "cdate": 1761791186520, "tmdate": 1762925082340, "mdate": 1762925082340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes that existing methods usually rely on explicitly provided optimization parameters, which are disconnected from the requirement of extracting parameters from enterprise databases in real-world scenarios. The paper proposes two core innovations: the creation of the Schema2Opt benchmark dataset and the Data2Decision decision optimization framework.\n\nSchema2Opt adopts a bottom-up paradigm. It optimizes the prior schema through iterative dialogues between Operations Research (OR) Experts and Data Engineers, generates real-world data and business descriptions with the involvement of three types of experts, and conducts validation via a voting mechanism across multiple solvers (Gurobipy, DOCplex, and Pyomo). Eventually, it forms a benchmark that includes business documents, database information, and validated solutions.\n\nData2Decision achieves end-to-end automation through a two-stage process. It attains the highest accuracy rates of 53.8% and 69.5% on the GPT-4o and DeepSeek-V3 test subsets of Schema2Opt, respectively. Ablation experiments confirm that the consensus among multiple solvers serves as a key support for its performance.\n\nThe paper also verifies the advantages of Data2Decision by comparing it with baseline methods such as Text-to-OPT and end-to-end large models through experiments, and provides detailed code for validation purposes. However, the study has certain limitations: it only supports linear/mixed-integer programming, relies on static structured data, and is difficult to adapt to scenarios involving multi-objective optimization, dynamic data, and real-time decision-making."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1.A brand-new benchmark dataset generation paradigm is proposed, along with the Schema2Opt benchmark. It adopts a bottom-up approach to explore new optimization scenarios that are not covered in database schemas.\n2.A complete end-to-end automated method design is realized. Data2Decision implements a two-stage process, from SQL generation for parameter extraction to direct generation of optimization code. It innovatively skips the intermediate mathematical modeling step and reduces explicit modeling errors based on latent reasoning research.\n3.Rigorous experiments and academic standardization are ensured: the experimental design is comprehensive, all experimental details are provided, and the performance advantages of Data2Decision are clearly verified; the contributions of multi-solver integration, temperature scheduling, and pipeline architecture are quantified through ablation experiments; meanwhile, detailed code is provided for validation purposes."}, "weaknesses": {"value": "1.It fails to account for dynamic database updates. This solution assumes the database is static and does not handle dynamic scenarios such as real-time data insertion and table structure changes, whereas enterprise decisions often rely on dynamic data.\n2.It only supports single-objective linear/mixed-integer programming and does not cover common real-world enterprise scenarios like multi-objective optimization and dynamic optimization, resulting in limited applicability."}, "questions": {"value": "In the paper, Schema2Opt mainly generates optimization problems based on the schemas of the Spider dataset. Although the schemas of the Spider dataset simulate real-world applications, they still differ from enterprise-level databases. Therefore, how did the authors verify the representativeness of this benchmark for real enterprise scenarios? Are there any comparative analyses with the schemas of real enterprise databases or results of migration tests?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ipEqDVHoZu", "forum": "3N0QtlXz6u", "replyto": "3N0QtlXz6u", "signatures": ["ICLR.cc/2026/Conference/Submission14720/Reviewer_SKcu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14720/Reviewer_SKcu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966786854, "cdate": 1761966786854, "tmdate": 1762925081974, "mdate": 1762925081974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}