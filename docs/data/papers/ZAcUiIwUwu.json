{"id": "ZAcUiIwUwu", "number": 20673, "cdate": 1758308839451, "mdate": 1759896964784, "content": {"title": "Causal Graph Recovery in Neuroimaging through Answer Set Programming", "abstract": "Learning directed causal graphs from time-series data poses significant challenges, especially in fMRI where slow sampling rate obscures fast neural interactions. This temporal mismatch leads to undersampling, which can make multiple graphs equally plausible. We address this problem by explicitly modeling undersampling effects when recovering causal graphs. Our approach employs answer set programming (ASP) to enforce domain-specific constraints and optimize soft observational constraints, thereby identifying a Markov equivalence class for the resulting graph solutions. By customizing an ASP solver to collect multiple near-optimal solutions, we obtain not only the single best-fitting graph but an equivalence class of high-scoring graphs for expert consideration. This method, called Real-world noisy RASL (RnR), can also act as a meta-solver: it refines the output of other causal discovery algorithms by accounting for undersampling biases. In simulations and empirical brain network data, RnR produces more accurate causal graphs than state-of-the-art methods, improving F1-scores by an average of 12\\% by reducing false connections. We demonstrate that RnR is robust to varying undersampling rates – maintaining high precision and recall even as sampling becomes more sparse – whereas baseline methods degrade significantly. Our results suggest that incorporating undersampling-aware constraints via ASP yields more reliable and interpretable brain connectivity estimates from fMRI time series, closing the gap between neural dynamics and observational data.", "tldr": "We propose Real-world noisy RASL (RnR), an ASP-based method that models undersampling in fMRI to recover more accurate and robust causal brain networks, improving F1-scores by 12% over existing approaches.", "keywords": ["answer set programming", "causal learning", "neuroscience", "graph theory"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f6d1b37660e074372609ee594c0b64d03cdf4d27.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces RnR, an ASP-based meta-solver that recovers more accurate causal graphs from undersampled fMRI data by enforcing neuroscientific and structural constraints. It extends prior Rate-Agnostic Structure Learning (RASL/sRASL) methods and bridges the gap between fast neural processes and slow fMRI measurements."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper takes undersampling into account when doing causal discovery and directly encodes the mathematical structure of undersampling (compressed paths and latent confounding) into the ASP formulation.\n\n2. RnR retrieves all graphs within a small cost tolerance, effectively approximating the Markov equivalence class of causal structures compatible with data, which provides more robust solutions. \n\n3. On simulated and real fMRI data, RnR improves F1-scores by an average of ≈12% over state-of-the-art baselines. It maintains high accuracy even when undersampling worsens, while competitors degrade sharply."}, "weaknesses": {"value": "1. RnR does not discover causal edges directly from raw time series. It starts from an input graph generated by another causal discovery algorithm (Granger, PCMCI, FASK, etc.). If the initial graph is not accurate, the output of RnR may be affected.\n\n2. RnR needs to solve a combinatoric problem using ASP. For graphs with a lot of variables, this optimization problem may be intractable."}, "questions": {"value": "1. Can you add a complete pipeline to the overview of your method? It helps readers who are not familiar with the medical settings understand your paper better. For example, I know the input of RnR is the output of some causal discovery algorithm until section 3.5. \n\n2. In practice, how do you decide the size of the tolerance?\n\n3. How do you ensure acyclicity in ASP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "qVH5O0RRQB", "forum": "ZAcUiIwUwu", "replyto": "ZAcUiIwUwu", "signatures": ["ICLR.cc/2026/Conference/Submission20673/Reviewer_sNXs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20673/Reviewer_sNXs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760937478536, "cdate": 1760937478536, "tmdate": 1762934058325, "mdate": 1762934058325, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Real-world noisy RASL (RnR), an extension of solver-based RASL that leverages Answer Set Programming (ASP) for causal graph recovery from undersampled fMRI time-series. By embedding domain-specific constraints and retrieving multiple near-optimal solutions, RnR explicitly models undersampling effects that distort effective connectivity inference. The paper demonstrates improved causal accuracy on simulated and empirical BOLD data, especially compared with traditional approaches (e.g., GIMME, MVAR, FASK, PCMCI). The method can also act as a “meta-solver,” refining graphs produced by other algorithms."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1.\tExceptional clarity and structure.\nThe exposition is unusually well-organized for an fMRI causal paper—each method component (density constraints, adaptive weighting, SCC-DAG decomposition, meta-solver function) is clearly explained and mathematically specified.\n2.\tStrong contextual grounding.\nThe introduction and background display excellent awareness of prior work in fMRI causal discovery—Granger, MVAR, FASK, PCMCI, RASL, and newer deep learning variants. The authors accurately summarize the challenge of undersampling and how it induces structural artifacts.\n3.\tMethodological innovation.\nExtending sRASL to produce an equivalence class of near-optimal graphs via ASP optimization tolerance (Δ) is a genuine contribution  ￼. The addition of density and adaptive-weight constraints reflects good domain insight.\n4.\tConceptual coherence.\nThe argument that causal inference from fMRI must explicitly incorporate undersampling is persuasive. Their use of a meta-solver to adjust outputs from existing algorithms is elegant and pragmatically valuable.\n5.\tReadable and reproducible.\nThe methods are described with sufficient procedural detail (e.g., Clingo code, cost equations, prioritization steps) to permit reproduction, and the empirical sections link cleanly to earlier definitions."}, "weaknesses": {"value": "1.\tLimited empirical scale.\nCurrent experiments involve small networks (≤ 10 nodes in ASP runs, up to 50 nodes in discussion)  ￼. While understandable, it would help to show scaling behavior or runtime analysis beyond toy graphs.\n2.\tQuantitative evaluation scope.\nMost comparisons are against the Sanchez-Romero synthetic dataset and a few standard algorithms. A more diverse benchmark (e.g., larger synthetic networks, real multi-subject fMRI) would better test generality.\n3.\tLack of undersampled-data citations.\nThe paper could more fully engage with recent literature on learning from undersampled or irregularly sampled time-series beyond the fMRI context (e.g., algorithms for compressed or subsampled causal discovery).\n4.\tOpen theoretical questions.\nAlthough the ASP cost structure is clearly defined, the theoretical guarantees (e.g., completeness, correctness of near-optimal equivalence class) are not formally analyzed. A brief discussion of what is and isn’t provably ensured would strengthen confidence.\n5.\tComputational feasibility.\nThe paper notes ASP may slow for 20–50-node graphs. It would be valuable to include wall-time plots or solver statistics to show practical limits, especially since scalability is crucial for fMRI."}, "questions": {"value": "1.\tScaling: What strategies or heuristics do you foresee to make RnR feasible for 100+-node parcellations common in fMRI (e.g., Schaefer or Glasser atlases)?\n2.\tSolver robustness: How sensitive are the retrieved equivalence classes to the choice of tolerance Δ in Equation (1)?\n3.\tEmpirical realism: Have you tested RnR on real multi-subject fMRI datasets (e.g., HCP or resting-state data), and if so, how consistent are the equivalence classes across subjects?\n4.\tConnection to undersampling literature: Could you cite additional work addressing causal inference under irregular or sub-Nyquist sampling outside fMRI, to situate RnR in that broader methodological landscape?\n5.\tMeta-solver evaluation: When refining graphs from other methods (Figure 3), how is improvement quantified—do you compare F1, orientation precision, or overall structure distance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p3JRfbDHtQ", "forum": "ZAcUiIwUwu", "replyto": "ZAcUiIwUwu", "signatures": ["ICLR.cc/2026/Conference/Submission20673/Reviewer_sgoz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20673/Reviewer_sgoz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761695010693, "cdate": 1761695010693, "tmdate": 1762934057794, "mdate": 1762934057794, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses causal discovery in time series with undersampling, where not all timepoints are observed. This setup is heavily motivated by fMRI and causal discovery for neuroscience. The work builds on top of the sRASL framework, with the authors adding various heuristics to this method motivated by their observations and the nature of the settings. The method allows recovery of more graphs by searching graphs within a range rather than only the best score. They add a penalty for not following the expected density and propose not only to use a graph as input but also to incorporate known correlations. They also address how to treat bidirected edges. The findings are evaluated against the previous framework on some data, and then the comparison is made on synthetic and semi-synthetic data against other approaches with various undersampling rates."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* An idea to increase the robustness of the method by recovering multiple solutions\n* An interesting idea to use domain knowledge (about density) as a constraint\n* A very interesting point is made in Section 3.5, where the authors propose to integrate into the process of recovering a graph not only the output graph of some algorithm but also the uncertainty about the edge or knowledge about the strength of the relation. Such an approach seems like a step in a good direction, not to \"waste\" any information.\n* Compared RnR (proposed) to sRASL on an edge deleting experiment.\n* Compared to a broad range of methods."}, "weaknesses": {"value": "* Subsections 3.2 and 3.4 both have a C(G) function, but they have different forms. Can you clarify which one you used?\n* There is no discussion about tuning parameters of this method like δ or λ_d and λ_c.\n* For all experiments, there is no hyperparameter tuning procedure described. However, since this is a heuristics method, I think it would be important to describe how robust they are, what is needed to tune them, and how general these hyperparameters are.\n* Subsection 4.1 - How did you select the final graph? You write \"and then select the final graph by an additional criterion (e.g., best fit on a validation dataset or expert judgment)\" - so was the best fit chosen in this approach? Did you use all optimization steps described? If I understand correctly, the input to this experiment is a graph, so we only use the score component, meaning the modifications involving the adaptive weighting scheme for edges (Section 3.5) were not present?\n* Subsection 4.2 - As far as I understand, the output of Sanchez-Romero's method can also be plugged as an input to sRASL. Why did you not directly compare RnR with this approach? Since these heuristics build on it, it should be compared. If this is not possible, please correct me and possibly explain why this is the case.\n* Also, I think the appendix is missing."}, "questions": {"value": "* Please look at some questions in the weakness section.\n* In Section 3.6, you point out that methods like PC or GES will not output bidirected edges. But then you write it can lead to spurious edges like two-node cycles. However, I do not think that PC or GES will output any cyclic graph, because they output a CPDAG. Can you explain this?Also, in such a setting, is it not mandatory to use a method capable of discovery with confounders?\n* Is there a reason why structural metrics like SHD are not used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Y55i5FR8Rn", "forum": "ZAcUiIwUwu", "replyto": "ZAcUiIwUwu", "signatures": ["ICLR.cc/2026/Conference/Submission20673/Reviewer_o9GW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20673/Reviewer_o9GW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907379959, "cdate": 1761907379959, "tmdate": 1762934057406, "mdate": 1762934057406, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "I liked this paper. Undersampling happens in many cases, and we know our current techniques fail to recover the effective connectivity properly in undersampled settings. I also liked the clear and step-by-step presentation of the strength of the methodology proposed by the authors. That said, I am not sure if I am convinced that the method solves the issues we have. In what follows, I bring the concerns in my mind and I am happy to change the score I give here if the authors bring evidence that the method can address those indeed."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "A quite clear question, clear method, and clear assessment"}, "weaknesses": {"value": "1. The authors claim that the method works for neuroimaging data, but they only test for fMRI. Does this method extend to other modalities e.g., fNIRS?\n\n2. What happens if we remove the constraints of 10-30% density? If the method fails to converge, are we truly finding a causal structure or do we have some level of circularity?\n\n3. When does the method fail completely? I suspect if the u (delay) is varied and long, the method would completely fail. This is important because we know the undersampling does not only happen because of the BOLD dynamics, but also because of the feedback loops in the brain. Could the others test the limits of the method theoretically or at least empirically? This could be possible for instance, when we simulate an arbitrary rich high-dimensional dynamical system with local linearity (e.g., piece-wise linear RNNs) and see if the method proposed here can indeed deliver the effective connectivity for each basin of attraction?\n\n4. What happens to multistable systems? after all, BOLD itself is multistable and connectivity changes in time."}, "questions": {"value": "see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4yyUOqmhO4", "forum": "ZAcUiIwUwu", "replyto": "ZAcUiIwUwu", "signatures": ["ICLR.cc/2026/Conference/Submission20673/Reviewer_oBdh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20673/Reviewer_oBdh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20673/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991269674, "cdate": 1761991269674, "tmdate": 1762934057012, "mdate": 1762934057012, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}