{"id": "hWw269fPov", "number": 12854, "cdate": 1758210972669, "mdate": 1759897481352, "content": {"title": "PAC-Bayes bounds for cumulative loss in Continual Learning", "abstract": "In continual learning, knowledge must be preserved and re-used between tasks, requiring a balance between maintaining\ngood transfer to future tasks and minimizing forgetting of previously learned ones. As several practical algorithms have been\ndevised to address the continual learning setting, the natural question of providing reliable risk certificates has also been raised.\nAlthough there are results for specific settings and algorithms on the behavior of memory stability, generally applicable upper bounds on learning plasticity are few and far between. \n\nIn this work, we extend existing PAC-Bayes bounds for online learning and time-uniform offline learning to the continual learning\nsetting. We derive general upper bounds on the cumulative generalization loss applicable for any task distribution and learning\nalgorithm as well as oracle bounds for Gibbs posteriors and compare their effectiveness for several different\ntask distributions. We demonstrate empirically that our approach yields non-vacuous bounds for several continual learning\nproblems in vision, as well as tight oracle bounds on linear regression tasks. To the best of our knowledge, this is the first general upper bound on learning plasticity for continual learning.", "tldr": "Upper bounds on the loss accumulated during online learning (offline or online)", "keywords": ["Continual Learning", "PAC-Bayes", "Generalization bounds", "Lifelong Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c576a7c82ddbfba157fe399f11bbc97505212195.pdf", "supplementary_material": "/attachment/72b18997bb17fe0b74dc0b2b8d3d2ee609d78e0a.zip"}, "replies": [{"content": {"summary": {"value": "The paper extends existing PAC-Bayes bounds used for online and offline learning to address the setting of continual learning, where tasks arrive sequentially. The authors focus on deriving general upper bounds on cumulative generalization loss applicable to any task distribution and learning algorithm. The paper also addresses oracle bounds for Gibbs posteriors and compares these approaches across various task distributions, as well as testing their empirical validity on vision-based continual learning problems. This work represents the effort to establish upper bounds on learning plasticity within the domain of continual learning, given its unique challenge of balancing knowledge retention and forward transfer."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Rigorous Theory**: The extension of PAC-Bayes bounds to continual learning, especially in providing non-vacuous bounds, is a theoretical contribution.\n    \n2. **Empirical Validation for the Theory**: The authors provide empirical evidence that supports their theoretical claims across various task distributions, including vision-based datasets. Experiments on linear regression tasks demonstrate the effectiveness of their bounds.\n\n3. **Good Presentation:** The paper is well written and easy to follow."}, "weaknesses": {"value": "1. **Use of Cumulative Loss:** The Cumulative Loss is a typical measure in online/continual meta-learning. For continual learning, the bound should be analyzed with the average loss in Definition 4. In contrast, the whole paper focused on cumulative loss. \n\n2. **Novelty and Related Work Discussion:** The paper claims to be the ﬁrst general upper bound on learning plasticity for continual learning, while it missed a lot of theoretical work in continual learning [1, 2, 3], and its most related work is in online/continual meta-learning [4,5,6,7]. In particular, the discussion regarding [4, 5, 6, 7] should be in depth, where these methods also brought novel algorithms to reduce the cumulative loss as well as improve its upper bounds.\n\n3. **Theoretical Limitation:** The proposed bounds depend on $\\mathcal{G}_{\\mathcal{H}} d(\\mathcal{D}_1, \\mathcal{D}_2)$, which are hard to evaluate and the bound could be very loose. In addition, the results require that the number of samples per task should exceed the square root of the total number of tasks, which neglects the positive transfer among tasks.\n\n4. **Limited Experiments:** The experiments are somehow too simple.\n\n[1] Itay Evron, Edward Moroshko, Rachel Ward, Nathan Srebro, and Daniel Soudry. How catastrophic can catastrophic forgetting be in linear regression? In Conference on Learning Theory, pp. 4028–4079. PMLR, 2022.\n\n[2] Hongbo Li, Sen Lin, Lingjie Duan, Yingbin Liang, and Ness Shroff. Theory on mixture-of-experts in continual learning. In The Thirteenth International Conference on Learning Representations, 2025. \n\n[3] Sen Lin, Peizhong Ju, Yingbin Liang, and Ness Shroff. Theory on forgetting and generalization of continual learning. In International Conference on Machine Learning, pp. 21078–21100. PMLR, 2023.\n\n[4] Giulia Denevi, Carlo Ciliberto, Riccardo Grazzi, and Massimiliano Pontil. Learning-to-learn stochastic gradient descent with biased regularization. In International Conference on Machine Learning, pages 1566–1575. PMLR, 2019.\n\n[5] Qi Chen, Changjian Shui, Ligong Han, and Mario Marchand. On the stability-plasticity dilemma in continual meta-learning: Theory and algorithm. Advances in Neural Information Processing Systems, 36:27414–27468, 2023.\n\n[6] Maria-Florina Balcan, Mikhail Khodak, and Ameet Talwalkar. Provable guarantees for gradientbased meta-learning. In International Conference on Machine Learning, pages 424–433. PMLR, 2019.\n\n[7] Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Adaptive gradient-based metalearning methods. arXiv preprint arXiv:1906.02717, 2019."}, "questions": {"value": "As the authors have acknowledged several limitations in the main paper, and considering the questions raised above, I would like to know how the authors plan to address them.\n\nI would expect the authors to adequately resolve most of my concerns; otherwise, I would be reluctant to recommend acceptance, as the limitations appear to be quite significant."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pFZnfzShPf", "forum": "hWw269fPov", "replyto": "hWw269fPov", "signatures": ["ICLR.cc/2026/Conference/Submission12854/Reviewer_9vg7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12854/Reviewer_9vg7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761868517086, "cdate": 1761868517086, "tmdate": 1762923647546, "mdate": 1762923647546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper provides a PAC-Bayes bound on the cumulative loss (loss summed over each retraining of the model) for continual learning, which is an evaluation metric that measures the efficacy of learning algorithms over an entire predictive sequence. The author then demonstrates the efficacy of the proposed bounds on standard continual learning datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written as an extension of previous papers, namely (Haddouche & Guedj, 2022). The writing and proofs are clear and seem technically correct. The formulation of the problem is original as the consideration of CuL is indeed new."}, "weaknesses": {"value": "Minor:\n1. Although the presentation is clear, the writing can be more inviting to readers. E.g, some brief introduction on the setup of PAC-Bayes bounds in general can greatly help the readers with the required background. \n2. The related work section can include some newer papers, e.g [1,2], that propose both empirical methods, but also with the appropriate theoretical analysis on forgetting/knowledge transfer bounds. \n\nMajor:\n1. Some of the assumptions might be unrealistic.\n2. The bounds seem loose in scenarios where a proper continual learning technique was applied in the setting. \n\n[1]: Wu, Yichen, Long-Kai Huang, Renzhen Wang, Deyu Meng, and Ying Wei. \"Meta continual learning revisited: Implicitly enhancing online hessian approximation via variance reduction.\" In The Twelfth international conference on learning representations, vol. 2. 2024.             \n[2]: Yang, Haoming, Ali Hasan, and Vahid Tarokh. \"Parabolic Continual Learning.\" In International Conference on Artificial Intelligence and Statistics, pp. 2620-2628. PMLR, 2025."}, "questions": {"value": "1. In Figure 1, the author used the notation $Q_{1:t}$, but it doesn't seem like this notation is used anywhere else in the analysis. Is this notation the same as $Qt$?\n2. Line 187-188, Can the author address why, in a continual learning context, the upper bounds that converge as the number of tasks increases are vastly preferable? This is an important motivation to motivate the rest of the analysis in the paper. \n3. Line 189-190, Is the assumption that the loss function is upper-bounded by a constant realistic? Most of the loss functions, such as MSE and cross-entropy, are not upper-bounded. The author should provide a few applicable loss functions here as an example. \n4.  In the case of equation 3, can the author explain which part of the bound applying a proper continual learning method reduces? Intuitively, does a buffer-based algorithm help reduce the first term, while a regularization-based algorithm reduces the KL term of the bounds?\n5. In the experiments, error percentage is used to evaluate the efficacy of different methods as a loss function, but it is generally not used to optimize a learning algorithm. Will this violate the assumptions made to prove the bounds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jC1wfA1pQ6", "forum": "hWw269fPov", "replyto": "hWw269fPov", "signatures": ["ICLR.cc/2026/Conference/Submission12854/Reviewer_cjXg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12854/Reviewer_cjXg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762114506453, "cdate": 1762114506453, "tmdate": 1762923647205, "mdate": 1762923647205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper extends PAC-Bayes tools from online/time-uniform settings to derive upper bounds on the cumulative (forward) loss in continual learning. The authors give conditions under which the bounds converge as the number of tasks grows (notably when the per-task sample size scales sufficiently with the number of tasks), and they analyze several controlled scenarios (task repeats, alternation, gradual change) to interpret the oracle bounds. There is some empirical validations of the claims."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides an original contribution by formulating PAC-Bayes bounds on the cumulative error in continual learning, addressing a problem that has received limited theoretical treatment so far.\n- The specialization of the results to different continual learning scenarios (repeated tasks, alternating tasks, gradual changes) is a useful aspect that makes the theoretical framework more interpretable.\n- The proof techniques might be of methodological interest."}, "weaknesses": {"value": "* **Lack of narrative and intuition.**\n  The paper is presented as a sequence of results with limited discussion. The authors should provide more intuition after each main theorem, explain the meaning of the key terms, and discuss when the bounds are informative.\n\n* **Insufficient comparison with prior work.**\n  The relationship with existing results (e.g., Friedman & Meir; Haddouche & Guedj) is not clearly established. A more explicit contrast between this setting and previous PAC-Bayes formulations for continual or online learning is needed.\n\n* **Assumptions and applicability.**\n  Some assumptions (bounded or sub-Gaussian loss, compact hypothesis space, strict minima) are strong and not discussed in detail. The paper should clarify how these assumptions affect the applicability of the results to neural networks.\n\n* **Presentation and readability.**\n  The paper assumes substantial familiarity with PAC-Bayes theory. Proof ideas and key steps should be summarized in the main text. Figures and tables could be improved for clarity.\n\n* **Experimental section.**\n  The experiments are not clearly described. Some results (e.g., high CIFAR10 error) are unexplained. It is unclear whether models were trained to convergence, and how optimization error is handled in the evaluation of bounds. Also, the visualizations are not well annotated.\n\n* **Discussion of overparameterization.**\n  Although the text mentions that overparameterization affects the bounds, this is not explored in detail. A more systematic analysis or clearer interpretation would improve the contribution."}, "questions": {"value": "1. In Corollary 3.1, the constant (K) (and the assumption of bounded loss) should be re-introduced. \n2. Why is the KL divergence measured only with respect to task-shared parameters (line 182)? Would it not be possible to include task-specific parameters by defining them as zero for other tasks?\n3. The empirical results on CIFAR10 show unusually high errors. Could the authors clarify the training procedure and whether models were trained to convergence?\n4. How is optimization error accounted for in the experiments? If models are not trained to convergence, how does this affect the interpretation of the bounds?\n5. Could the authors explain why variational inference yields tighter bounds than EWC or SGD, beyond the observation that it optimizes a PAC-Bayes objective?\n6. The oracle bounds assume strict global minima and compact hypothesis space. Are these assumptions essential, or can the results be extended to more realistic cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DYM0k71yNo", "forum": "hWw269fPov", "replyto": "hWw269fPov", "signatures": ["ICLR.cc/2026/Conference/Submission12854/Reviewer_a1bF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12854/Reviewer_a1bF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762125065792, "cdate": 1762125065792, "tmdate": 1762923646785, "mdate": 1762923646785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General comment on the cumulative loss and previous work"}, "comment": {"value": "Based on the reviews provided, we believe that there is room for general clarification regarding the stability-plasticity dilemma in continual learning and how our contribution relates to existing work (we intend to include this in our revision).\n\n  A key element in continual learning is the trade-off between the ability to preserve performance on previous tasks (AKA maintaining memory stability or avoiding catastrophic forgetting) and the ability to learn new tasks effectively (AKA learning plasticity or forward transfer). Historically, early work in the domain of continual learning mainly focused on the issue of catastrophic forgetting and maintaining high memory stability, while recent work [1,2,3] has paid more attention to the subject of plasticity in continual learning.\n\nOf the related theoretical work in the theory of continual learning, most such as [4,5,6,7] discuss the average loss or related measures of stability. Works focused on the neural tangent kernel (NTK) regime such as [8,9] do offer upper bounds on both cumulative and average loss, but are limited to specific optimization algorithms used during training and on the NTK regime itself. \n\nWe also note that the notion or regret that is sometimes discussed in both meta-learning (e.g. [10]) and online learning [11] is related and similar to the cumulative loss. These settings, however, differ from the continual learning setting in meaningful ways: meta-learning assumes continued access to previous tasks and often requires a shared distribution for tasks, and online learning pessimistically assumes that all samples are taken from different, possibly adversarial tasks. Accordingly, several common strategies from these fields such as online gradient descent and follow-the-leader algorithms are non-ideal or inapplicable to the continual learning domain.\n\n\n[1] Dohare, S., Hernandez-Garcia, J. F., Lan, Q., Rahman, P., Mahmood, A. R., & Sutton, R. S. (2024). Loss of plasticity in deep continual learning. Nature, 632(8026), 768-774.\n\n[2] Wang, M., Michel, N., Xiao, L., & Yamasaki, T. (2024). Improving plasticity in online continual learning via collaborative learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 23460-23469).\n\n[3] Kumar, S., Marklund, H., & Van Roy, B. (2025, February). Maintaining Plasticity in Continual Learning via Regenerative Regularization. In Conference on Lifelong Learning Agents (pp. 410-430). PMLR.\n\n[4] Itay Evron, Edward Moroshko, Rachel Ward, Nathan Srebro, and Daniel Soudry. How catastrophic can catastrophic forgetting be in linear regression? In Conference on Learning Theory, pp. 4028–4079. PMLR, 2022.\n\n[5] Hongbo Li, Sen Lin, Lingjie Duan, Yingbin Liang, and Ness Shroff. Theory on mixture-of-experts in continual learning. In The Thirteenth International Conference on Learning Representations, 2025.\n\n[6] Sen Lin, Peizhong Ju, Yingbin Liang, and Ness Shroff. Theory on forgetting and generalization of continual learning. In International Conference on Machine Learning, pp. 21078–21100. PMLR, 2023.\n\n[7] Lior Friedman and Ron Meir. Data-dependent and oracle bounds on forgetting in continual learning. In Proceedings of The 4nd Conference on Lifelong Learning Agents, 2025.\n\n[8] Bennani, M. A., & Sugiyama, M. Generalisation Guarantees for Continual Learning with Orthogonal Gradient Descent. In 4th Lifelong Machine Learning Workshop at ICML 2020.\n\n[9] Thang Doan, Mehdi Abbana Bennani, Bogdan Mazoure, Guillaume Rabusseau, and Pierre Alquier. A theoretical analysis of catastrophic forgetting through the ntk overlap matrix. In International Conference on Artificial Intelligence and Statistics, pp. 1072–1080. PMLR, 2021.\n\n[10] Qi Chen, Changjian Shui, Ligong Han, and Mario Marchand. On the stability-plasticity dilemma in continual meta-learning: Theory and algorithm. Advances in Neural Information Processing Systems, 36:27414–27468, 2023.\n\n[11] Maxime Haddouche and Benjamin Guedj. Online pac-bayes learning. Advances in Neural Information Processing Systems, 35:25725–25738, 2022."}}, "id": "DnI5xUyAYQ", "forum": "hWw269fPov", "replyto": "hWw269fPov", "signatures": ["ICLR.cc/2026/Conference/Submission12854/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12854/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission12854/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763633270674, "cdate": 1763633270674, "tmdate": 1763633270674, "mdate": 1763633270674, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}