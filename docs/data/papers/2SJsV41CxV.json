{"id": "2SJsV41CxV", "number": 18039, "cdate": 1758283233514, "mdate": 1759897137354, "content": {"title": "DDL: Dynamic Discard Deep Learning for Rice Yield Prediction on Mixed-Accuracy Datasets", "abstract": "Effectively fusing scarce high-accuracy data with massive but noisy low-accuracy data is a common challenge faced by machine learning across various fields, including agriculture, medicine, and remote sensing. Existing methods, which either directly concatenate datasets while ignoring accuracy differences or employ static weighting for training, struggle to achieve optimal performance. To address this, we introduce a deep learning framework incorporating a dynamic discard mechanism (DDL) that manages mixed-accuracy data through the selective, dynamic removal of low-accuracy instances characterized by high Mean Absolute Error (MAE) and the application of an adaptive weighting scheme.Our study validated this approach using rice cultivation data from China's four major rice-growing regions: South, Central, North, and Northeast China. Using site characteristics and nitrogen application rates as feature variables and rice yield as the target variable, we designated the high-accuracy dataset as the test set. Compared to machine learning models that process only single-accuracy datasets and other models designed for mixed-accuracy data, our DDL framework demonstrated a performance improvement of over 10% in metrics such as RMSE, MAE, and MAPE, achieving significantly higher prediction accuracy.A crop yield prediction model capable of handling multiple datasets simultaneously holds significant practical value for policymakers and other stakeholders. The dynamic discard mechanism and adaptive weighting algorithm employed by DDL also have considerable reference value for applications in other domains.", "tldr": "", "keywords": ["deep learning", "dynamic discard mechanism", "yield prediction", "mixed-accuracy data integration"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/509b5b8e3d6e57eabfa5cbd118be2a00e0f5c56a.pdf", "supplementary_material": "/attachment/effd7f5d4bc7ef9033680ba09370c31c277ea000.zip"}, "replies": [{"content": {"summary": {"value": "The paper primarily addresses the problem of fusing scarce high accuracy (HA) (real-world) data with volumnous low accuracy (LA) data (generated data or augmented data). The authors suggest Dynamic Discard Mechanism (DDL) which dynamically discard the less informative LA data from the dataset generated using DeNitrification-DeComposition (DNDC) model. The discarding mechanism calculates discard probability, which is a function of mean absolute error (MAE), of the LA data and discard data under some threshold value. The results of the mechanism outperforms the listed ML models. Extensive experiment on different variants of the mechanism has been performed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides a mechanism to fuse LA data with HA data to generate a large high quality dataset for crop yield prediction, which is a very challenging field. \n2. The obtained large-scale high quality dataset is essential for better generalization of crop yield models.\n3. The adaptive dynamic weight framework helps models to generalize better. \n4. The paper uses attention mechanism, which is computationally in-expensive compared to self-attention, for better model convergence and generalization.\n5. The obtained HA dataset for field-scale rice yield prediction adds significant value to the paper as it is very expensive and taxing task."}, "weaknesses": {"value": "Following are the weakness of the paper:\n1. While the framework/mechanism is quite effective for rice yield prediction, its effectiveness to other crops is questionable without results for other crops.\n2. The result in Table 1 shows that the proposed model outperforms listed ML models, but the RMSE and MAE are still very high. The paper does not answer its cause.\n3. There are many grammar errors (near citations and especially the caption of Figure 2).\n4. The paper claims to have less computation cost without providing any evidence or comparison between the evaluated models and any recent model with self-attention mechanism."}, "questions": {"value": "1.  For the attention gate (260 -261) what is sigma? And why is a small dense layer has been used as attention?\n2. Are there any results for another crop ?\n3. What is the result of the model compared to recent computationally expensive self-attention based models?\n4. The paper is using 10 epochs to train then clip the large dataset. What if we train on HA dataset for some time first and then incorporate the LA data?\n5. How is the initial dynamic weighting coefficient calculated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uPvbpMUV29", "forum": "2SJsV41CxV", "replyto": "2SJsV41CxV", "signatures": ["ICLR.cc/2026/Conference/Submission18039/Reviewer_BKdG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18039/Reviewer_BKdG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761741752438, "cdate": 1761741752438, "tmdate": 1762927827502, "mdate": 1762927827502, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a deep learning framework called Dynamic Discard Learning (DDL) for crop yield prediction using datasets with mixed accuracy levels—high-quality field measurements and large-scale low-quality simulated data. The core idea is to dynamically discard low-accuracy samples with high prediction error during training, combined with an adaptive loss-weighting mechanism that balances regression and auxiliary classification tasks. The model is evaluated on rice yield datasets from multiple Chinese regions, showing improved performance over baseline machine learning and hybrid models such as CNN–GAN and DNDC-based simulations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper addresses an important and realistic issue in agricultural ML—combining high- and low-accuracy data sources—which is a meaningful problem with potential applications beyond agriculture.\n\n2. The proposed DDL reportedly achieves higher accuracy than baselines (≈10% improvement in RMSE/MAE) and includes an ablation study demonstrating that removing key components degrades performance.\n\n3. The authors provide multiple metrics (MAE, RMSE, R², MAPE) and comparisons with both traditional ML and process-based models, contributing to a broad empirical view."}, "weaknesses": {"value": "1. The core idea—discarding low-quality samples based on error thresholds—is not new and closely resembles well-known techniques such as curriculum learning, hard example mining, or robust sample reweighting. The paper rebrands these as “Dynamic Discard,” but without theoretical justification or algorithmic differentiation. The discard probability function is heuristic and lacks proof of convergence, stability, or advantage over standard robust loss functions (e.g., Huber, Tukey biweight).\n\n2. The authors define high-accuracy data as both training and testing targets, creating data leakage and self-validation bias. Since the model dynamically filters simulated data using high-accuracy supervision, it effectively overfits to the high-accuracy distribution rather than demonstrating genuine cross-domain generalization.\n\n3. Comparisons with deep regression models are superficial (only one “Deep Learning Regression” baseline, apparently underperforming). Modern architectures like Transformers, temporal attention networks, or physics-informed models are not considered. The paper’s claim of generalizability beyond agriculture is speculative and unsupported by evidence.\n\n4. The manuscript exhibits verbose exposition and redundant sections (e.g., repeating definitions of modules and formulas). It reads more like a project report than a polished ICLR submission. Furthermore, several claims (e.g., “DDL provides a generalizable methodological advance”) are overstated relative to the empirical evidence."}, "questions": {"value": "1. How do you ensure that high-accuracy data used for dynamic filtering does not create implicit leakage into the test set, thereby inflating the reported performance? \n\n2. Have you validated DDL on a domain-shifted dataset (e.g., a different crop or region)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H1DZE6VB3n", "forum": "2SJsV41CxV", "replyto": "2SJsV41CxV", "signatures": ["ICLR.cc/2026/Conference/Submission18039/Reviewer_3PX5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18039/Reviewer_3PX5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894175439, "cdate": 1761894175439, "tmdate": 1762927826937, "mdate": 1762927826937, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Dynamic Discard Learning (DDL), a deep learning framework that utilize and dynamically filters out noisy, low-accuracy samples from mixed-accuracy datasets during learning process. The approach is validated on rice-yield prediction tasks, where it shows improved performance over several baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of combining high-accuracy and low-accuracy datasets in a dynamic fashion is practical. The application to agricultural yield prediction is meaningful and demonstrates the framework’s potential value.\n2. The dynamic discard mechanism, which progressively removes low-quality samples during training, is conceptually simple yet effective and clearly contributes to improved performance.\n3. The paper is generally well organized, with ablation studies and comparisons provided for each modules in method."}, "weaknesses": {"value": "1. Relation to prior work:\nThe proposed dynamic discard mechanism is conceptually close to dynamic sample weighting [1] and to Population Based Augmentation [2], which dynamically adjust data or augmentation schedules over epochs.\nThe authors should clearly articulate the key differences between DDL and these related approaches, ideally including direct experimental or conceptual comparisons.\n\n2. Method clarity:\nIn Equation ( P = \\gamma * (1 − exp( − N_L * e_i / sum_i(e_i) )) ), P depends on the per-sample error e_i. What is difference between P and P_i? \n\n3. Experimental evaluation:\ni. In the “generalization ability” section, the claim that “prediction accuracy is insensitive to variations in quantities of high-accuracy data” appears inconsistent with Table 3: performance improves when more high-accuracy samples are used (Case B vs Case A). \nii. Figure 4 is titled “Prediction performance among four regions,” but lacks quantitative metrics (e.g., RMSE, R²) to indicate prediction quality.\niii Given the relatively small test set, the authors should repeat experiments and report mean ± standard deviation to show statistical significance.\n\nMinor issues:\n1. In Figure 4, the South China panels in (1) and (2) appear to contain identical numbers—please verify if this is an error.\n\nReference: \n[1] Ren, Mengye, et al. \"Learning to reweight examples for robust deep learning.\" International conference on machine learning. PMLR, 2018.\n[2] Ho, Daniel, et al. \"Population based augmentation: Efficient learning of augmentation policy schedules.\" International conference on machine learning. PMLR, 2019."}, "questions": {"value": "1. Dataset details:\ni. The 11 input features should be explicitly listed and described.\nii. SOC is undefined when first mentioned.\niii. The size and sampling procedure of the test set are unclear. How was the test subset drawn from the high-accuracy dataset?\niv. Does the low/high accuracy apply to input features, labels, or both?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SVJw4Q8ucP", "forum": "2SJsV41CxV", "replyto": "2SJsV41CxV", "signatures": ["ICLR.cc/2026/Conference/Submission18039/Reviewer_JGCi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18039/Reviewer_JGCi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963530877, "cdate": 1761963530877, "tmdate": 1762927826380, "mdate": 1762927826380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Dynamic Discard Learning, a deep learning framework designed to improve rice yield prediction using mixed-accuracy dataset that combines scarce high-quality field data with abundant low-accuracy simulated data. DDL employs a dynamic discard mechanism to progressively filter out low-accuracy samples with high errors during training and an adaptive weighting scheme to balance learning between regression and data-source classification tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The key strength of the paper lies in its innovative integration of mixed-accuracy datasets through the proposed DDL framework, which effectively addresses a common challenge in agricultural modelling balancing data quality and quantity. The framework’s modular design demonstrates strong methodological rigor and adaptability."}, "weaknesses": {"value": "No literature is given on previous attempts to process mixed-accuracy datasets.\nThe approach heavily leverages generated data (43k samples). If the simulation is biased, the proposed model may amplify these biases despite the dynamic discard process i.e., its performance may depend on representativeness and realism of the simulated data.\nThe paper does not include interpretability or feature sensitivity analysis. i.e., which agronomic or climatic features influence the most.\n\nThe evaluation the proposed model is limited as  it does not include evaluation on (i) other crops (ii) geographically different locations.\n\nThe details of dataset are not given. Meteorological data important for crop yield prediction. Whether it has been included or not.\n\nThe method is not compared with newer DL models."}, "questions": {"value": "As above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sZepZFIzEk", "forum": "2SJsV41CxV", "replyto": "2SJsV41CxV", "signatures": ["ICLR.cc/2026/Conference/Submission18039/Reviewer_U4CY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18039/Reviewer_U4CY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002213607, "cdate": 1762002213607, "tmdate": 1762927825705, "mdate": 1762927825705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}