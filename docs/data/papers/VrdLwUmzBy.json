{"id": "VrdLwUmzBy", "number": 8696, "cdate": 1758095291421, "mdate": 1759897769193, "content": {"title": "DistDF: Time-series Forecasting Needs Joint-distribution Wasserstein Alignment", "abstract": "Training time-series forecast models requires aligning the conditional distribution of model forecasts with that of the label sequence. The standard direct forecast (DF) approach seeks to minimize the conditional negative log-likelihood  of the label sequence, typically estimated using the mean squared error. However, this estimation proves to be biased in the presence of label autocorrelation.  In this paper, we propose DistDF, which achieves alignment by alternatively minimizing a discrepancy between the conditional forecast and label distributions. Because conditional discrepancies are difficult to estimate from finite time-series observations, we introduce a newly proposed joint-distribution Wasserstein discrepancy for time-series forecasting, which provably upper bounds the conditional discrepancy of interest. This discrepancy admits tractable, differentiable estimation from empirical samples and integrates seamlessly with gradient-based training. Extensive experiments show that DistDF improves the performance diverse forecast models and achieves the state-of-the-art forecasting performance. Code is available at https://anonymous.4open.science/r/DistDF-F66B.", "tldr": "", "keywords": ["time-series forecasting"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e1ec715ce7af140f9468ac80df8fb90c45fbdda0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Distribution-aware Direct Forecast (DistDF), which achieves alignment by minimizing joint-distribution Wasserstein discrepancy between conditional forecast and label distributions to enhance forecast accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is well written and polished. Notations and equations are clearly presented and explained.\n2. This paper is well-motivated and offers an extremely thorough explanation.\n3. Experiments are comprehensive."}, "weaknesses": {"value": "1. Experimental comparison (Tab. 2) lacks some most recent works, e.g., [*1]. The proposed method might not outperform these new works. TQNet [*1] achieves **0.377** MSE, **0.393** MAE on ETTm1.\n2. Experimental results could not fully support the significance of the method. The improvement is marginal when compared to prior art, e.g., TimeBridge, Time-o1, and TQNet [*1]. \n3. Improvement on presentation:\n - For results in the table, should not use **Bold** and $\\underline{\\text{Underline}}$ when two numbers are the same, use Bold for both.\n - (minor) In Section 4.3, the reference to Table 4 should be changed to Table 2.\n - (minor) Use consistent table style. Use \\toprule for Tab. 5 & 6\n\n\n[*1] Lin, Shengsheng, et al. \"Temporal Query Network for Efficient Multivariate Time Series Forecasting.\" Forty-second International Conference on Machine Learning."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hyiIQ6BzMR", "forum": "VrdLwUmzBy", "replyto": "VrdLwUmzBy", "signatures": ["ICLR.cc/2026/Conference/Submission8696/Reviewer_6qSb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8696/Reviewer_6qSb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931235247, "cdate": 1761931235247, "tmdate": 1762920504115, "mdate": 1762920504115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DistDF, a new training objective for time-series forecasting that aims to align the conditional distributions of forecasts and labels, rather than relying on point-wise MSE. Since conditional discrepancies are difficult to estimate from limited data, the authors introduce a joint-distribution Wasserstein discrepancy, optimized between the distributions of (history, labels) and (history, predictions). The method is model-agnostic and can be plugged into existing forecasting models. Experiments show performance improvements on multiple benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Strong and clearly articulated motivation regarding autocorrelation bias in likelihood-based objectives.\n- Solid theoretical foundation, including alignment guarantees and non-negativity properties of the objective.\n- Method is architecture-agnostic, enabling integration with a broad range of forecasting models.\n- Extensive benchmarking shows consistent improvements, supported by ablation studies demonstrating contribution of components.\n- Generally clear writing and clean presentation of the mathematical formulation."}, "weaknesses": {"value": "- A key limitation is that the proposed discrepancy objective lacks guaranteed convergence or clear interpretability during training, making its practical effect on conditional alignment somewhat uncertain. Because the loss must be combined with MSE, the discrepancy may act more like a regularizer than a principled stand-alone objective. Additional empirical analysis of its optimization dynamics and correlation with performance would strengthen the claims.\n- More comprehensive experiments are needed to isolate the contribution of the proposed objective. Given that the method relies on a weighted combination with MSE, it should be compared not only against plain MSE training but also against other established time-series learning objectives (e.g., Dilate, Soft-DTW) when similarly combined with MSE. Such comparisons would help determine whether the observed gains stem from the specific discrepancy formulation or simply from augmenting the loss with an auxiliary term.\n- Evaluation is restricted to direct forecasting, limiting evidence of robustness across different training paradigms. Additional experiments under an autoregressive setting would be valuable to validate whether the proposed objective is broadly applicable across different forecasting architectures and training pipelines.\n- In Table 1, it is unclear which underlying model architectures DistDF is applied to. Since DistDF is a learning objective rather than a new architecture, and the table compares against architectural baselines, the presentation may confuse readers regarding what is being evaluated. Clarifying the base model used for each dataset would improve readability. Explicitly specifying the base architecture for each dataset (e.g., as done in Scaleformer, ICLR 2023) would improve clarity and ensure a fair interpretation of the reported gains.\nref. Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting, ICLR 2023"}, "questions": {"value": "- Since the proposed objective must be combined with MSE for stable training, can the authors provide evidence that the improvement does not simply arise from a regularization effect? For example, how does the discrepancy term alone behave, and how strongly does its reduction correlate with forecasting accuracy?\n- The distinction between DistDF and existing learning-objective methods such as Time-o1, FreDF, Koopman-based losses, and Soft-DTW remains somewhat unclear. Can the authors more explicitly highlight the conceptual and practical differences, particularly regarding theoretical guarantees and optimization behavior?\n- The discussion of likelihood bias focuses primarily on MSE. Do similar issues arise in probabilistic forecasting frameworks using alternative objectives (e.g., quantile loss, CRPS)? If so, is DistDF compatible with or beneficial under such setups?\n- How well does DistDF extend to multivariate forecasting, probabilistic output formulations, or multi-scale architectures? Providing results or analysis in these more general settings would help verify that the proposed approach is broadly applicable beyond the current scope."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oln3e5zXMt", "forum": "VrdLwUmzBy", "replyto": "VrdLwUmzBy", "signatures": ["ICLR.cc/2026/Conference/Submission8696/Reviewer_c2pc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8696/Reviewer_c2pc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941916994, "cdate": 1761941916994, "tmdate": 1762920503731, "mdate": 1762920503731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Wasserstein-based discrepancy measure for time series that captures label autocorrelation and demonstrates the benefits of using it for time series alignment compared to established methods. Several experiments were conducted to support this claim."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The presented Wasserstein discrepancy seems original and effective. The experiments seem comprehensive and well carried out."}, "weaknesses": {"value": "I think the paper should discuss the assumption of Gaussian distributed data more. It seems absolutely necessary to derive the discrepancy measure and yet I suppose the benchmark datasets do not satisfy this property.\n\nI consider this a mild weakness but the theory regarding the general Wasserstein metric is presented mostly for discrete measures. Given that a Gaussian data distribution is assumed, it could be discussed how the presented results for empirical measures relate to the original Gaussian data distribution.\n\nMinor\n-------\nThe Bures-Wasserstein discrepancy is spelled as “Bruce-Wasserstein” in Lemma 3.5. Also in this Lemma, the equality to the W_2 metric should be made clear."}, "questions": {"value": "Perhaps I am missing something, but Table 1 seems confusing. DistDF, which is a discrepancy measure, is compared to other models. It should be pointed out which model was used with DistDF loss."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns."}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mXMpxnggqC", "forum": "VrdLwUmzBy", "replyto": "VrdLwUmzBy", "signatures": ["ICLR.cc/2026/Conference/Submission8696/Reviewer_aY9s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8696/Reviewer_aY9s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995816573, "cdate": 1761995816573, "tmdate": 1762920503410, "mdate": 1762920503410, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses time series forecasting and proposes aligning the predictive conditional distribution with the true conditional distribution by minimizing the joint-distribution Wasserstein discrepancy. This approach mitigates the bias introduced by autocorrelation when using maximum log-likelihood objectives to train forecasting models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* Good observation that both frequency and PCA components exhibit autocorrelation, which affects their learning bias; this provides a well-motivated basis for applying optimal transport theory.\n\n* The incorporation of DistDF in existing frameworks is straightforward\n\n* Comprehensive experiments; I appreciate the effort to compare with other distributional discrepancies and the application of DistDF to other approaches"}, "weaknesses": {"value": "* The central hypothesis of this work is that aligning conditional distributions is beneficial, and the authors provide theoretical justifications along with empirical evidence through forecasting error metrics. However, it is unclear whether the conditional distributions actually align for the best alpha values reported in Tables 5 and 6. In other words, the hypothesis is not directly evaluated in the experiments through distributional discrepancy, but rather indirectly through forecasting performance.\n\n* Improvements wrt to existing SOTA methods look rather small; however, they are consistent across models and datasets"}, "questions": {"value": "Please address my first point in the weaknesses. If no distributional discrepancy needs to be shown in the experiments, please elaborate why."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Njf2thwuIT", "forum": "VrdLwUmzBy", "replyto": "VrdLwUmzBy", "signatures": ["ICLR.cc/2026/Conference/Submission8696/Reviewer_ZpGW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8696/Reviewer_ZpGW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010737997, "cdate": 1762010737997, "tmdate": 1762920502936, "mdate": 1762920502936, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}