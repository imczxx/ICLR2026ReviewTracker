{"id": "TVSPV6D0co", "number": 9389, "cdate": 1758120830584, "mdate": 1763468309505, "content": {"title": "Fast, Secure, And High-Capacity Image Watermarking With Text Autoencoded Text Vectors", "abstract": "Most image watermarking systems focus on robustness, capacity, and imperceptibility while treating the embedded payload as meaningless bits. This bit-centric view imposes a hard ceiling on capacity and prevents watermarks from carrying useful information. We propose LatentSeal, which reframes watermarking as semantic communication: a lightweight text autoencoder maps full-sentence messages into a compact 256-dimensional unit-norm latent vector, which is robustly embedded by a finetuned watermark model and secured through a secret, invertible rotation.\nThe resulting system hides full-sentence messages, decodes in real time, and survives valuemetric and geometric attacks. It surpasses prior state of the art in BLEU-4 and Exact Match on several benchmarks, while breaking through the long-standing 256-bit empirical payload ceiling. It also introduces a statistically calibrated score that yields a ROC AUC score of 0.97-0.99, and practical operating points for deployment.\nBy shifting from bit payloads to semantic latent vectors, LatentSeal enables watermarking that is not only robust and high-capacity, but also secure and interpretable, providing a concrete path toward provenance, tamper explanation, and trustworthy AI governance. Models, training and inference code, and data splits will be available upon publication (code available in a the supplementary zip file).", "tldr": "LatentSeal turns watermarking into semantic communication: encode a sentence into a 256-D unit-norm latent, secure it via key-conditioned rotation, embed robustly to survive common edits, decode in real time with calibrated AUROC 0.97–0.99.", "keywords": ["Computer Vision", "Watermarking", "Autoencoder", "Security", "Representation Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9a21c9c2311e9add648be43bea8ab3f974587cb0.pdf", "supplementary_material": "/attachment/3b116136a555b6803bf4199f7e90703a72b4109e.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a novel image watermarking method called LatentSeal, which shifts the watermarking paradigm from the traditional \"bitstream\" approach to a \"semantic communication\" model. It introduces a key-based latent-space rotation encryption mechanism, achieving a unified balance of high capacity, robustness, security, and semantic interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The method embeds meaningful textual information within the watermark, enhancing its interpretability.\n2. The effectiveness and robustness of the watermarking scheme have been validated across multiple datasets and attack scenarios."}, "weaknesses": {"value": "1. The structure of the proposed model is relatively simple and seems to be a combination of existing works.\n2. The experimental metrics only consider BLEU-4 and EM, without incorporating measures related to watermark strength."}, "questions": {"value": "1. The text encoder and watermark embedding model used in this work are based on existing approaches. Where does the core innovation of this paper lie?\n2. The watermark model and text autoencoder in this work require staged training. Could an end-to-end training approach be considered instead?\n3. The paper claims to \"break the 256-bit payload limit,\" but this is achieved by compressing the text into a continuous vector space, which seems to differ from the traditional definition of \"bits\" in information theory. Could you clarify this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o9dkjNy8oO", "forum": "TVSPV6D0co", "replyto": "TVSPV6D0co", "signatures": ["ICLR.cc/2026/Conference/Submission9389/Reviewer_era7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9389/Reviewer_era7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760607104102, "cdate": 1760607104102, "tmdate": 1762920999625, "mdate": 1762920999625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LatentSeal, a watermarking method that embeds a message sentence into an image. LatentSeal encodes a message into a unit vector, applies a secret rotation, and embeds it into the image. The message is later decoded by extracting the embedded vector. Building upon VideoSeal, the embedder of LatentSeal is empirically shown to be robust against common image edits."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation and overall method are clearly presented and easy to follow.\n\n2. Using semantically meaningful vectors as watermarks is a natural and appealing idea."}, "weaknesses": {"value": "This paper proposes LatentSeal, a watermarking method that embeds a message sentence into the image. LatentSeal encodes a message into a unit vector, applies a secret rotation, and embeds it to an image. The message is decoded after extracting the embedded vector. Building upon VideoSeal, the embedder of LatentSeal is empirically shown to be robust to common image edits. \n\n\n\n**Strengths:**\n\n1. The motivation and main method are clearly explained and easy to follow. \n2. Using sematic meaningful vectors as watermark seems to be a natural and appealing idea. \n\n\n\n\n**Concerns:**\n\n1. Comparison to existing work. My understanding is that LatentSeal is autoencoder + VideoSeal. It is helpful to further explain the difference and innovation compared to VideoSeal. \n2. Watermark detection. The detection mechanism and its justification remain unclear. Specifically, in Figure 1, $\\hat{y}$ denotes the latent vector extracted from an image, and $\\hat{y}{\\mathrm{rec}} = E \\odot D(\\hat{y})$, where $E$ and $D$ represent the encoder and decoder, respectively. The authors claim that an image is authentic if $\\hat{y}$ is close to $\\hat{y}{\\mathrm{rec}}$. However, for any in-distribution latent vector $y$, a well-trained autoencoder typically satisfies $E \\odot D(y) \\approx y$. This suggests that closeness between $\\hat{y}$ and $\\hat{y}_{\\mathrm{rec}}$ alone may not imply authenticity, as the relationship between $\\hat{y}$ and the true latent vector $y$ remains unknown. Could the authors clarify how the confidence score in Equation (4) effectively captures this relationship?\n3. Secret Rotation. What is the motivation for introducing the secret rotation layer? Please provide an example or real-world scenario where this component is necessary or advantageous for security or robustness.\n4. How does the method’s performance change if the latent vector dimensionality is altered (e.g., not fixed at 255)? Some empirical evidence would strengthen the claims of generality. \n5. I would suggest add more basline methods such as DwtDct [1], Stable Signature [2], RAW [3], and etc. Comparing with them in terms of the AUC-ROC score helps to understand the cost of embedding meaningful messages. \n\n[1] Cox I J, Miller M L, Bloom J A, et al. Digital watermarking[J]. Morgan Kaufmann Publishers, 2008, 54: 56-59.\n\n[2] Fernandez P, Couairon G, Jégou H, et al. The stable signature: Rooting watermarks in latent diffusion models[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 22466-22477.\n\n[3] Xian X, Wang G, Bi X, et al. Raw: A robust and agile plug-and-play watermark framework for ai-generated images with provable guarantees[J]. Advances in Neural Information Processing Systems, 2024, 37: 132077-132105."}, "questions": {"value": "Please see Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cpICdfIF8c", "forum": "TVSPV6D0co", "replyto": "TVSPV6D0co", "signatures": ["ICLR.cc/2026/Conference/Submission9389/Reviewer_AGKw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9389/Reviewer_AGKw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761688816981, "cdate": 1761688816981, "tmdate": 1762920999264, "mdate": 1762920999264, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an image watermarking framework called LatentSeal that, instead of embedding arbitrary bits, embeds a 256D vector, which represents full-sentence textual messages (actually a set of tokens, e.g., 30). The mapping is performed with a text auto-encoder, where the encoder is derived from ModernBERT.  \nThe latent vector is robustly embedded into the image using a finetuned watermarking model adapted from VideoSeal. \nTo ensure secrecy, the latent vector is secured through a secret, invertible rotation conditioned by a key, meaning only authorized decoders can correctly reverse the rotation and recover the message\n\nThe paper claims that the system is fast, secure, and offer a higher capacity than traditional bit-centric watermarking methods, while maintaining robustness against image attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The problem related to data protection in the era of foundation models is quite important, and watermarking is certainly a key stream of research to that end. \n\nThe paper is well written and the contribution seems reasonable, to the best of my judgement (I have not followed closely the literature on this topic recently). \n\nThe lightweight design of the decoder should enable fast, real-time decoding, making it practical for real-world deployment\n\nThe code is actually provided in the supplemental material. 1"}, "weaknesses": {"value": "The paper explicitly states a major limitation: the robustness of the system against powerful, image-editing models is not addressed. The authors acknowledge that these models may be able to strip their watermark.\n\nMinor: The font is two small in Figure 2."}, "questions": {"value": "What happens if you encode random ids with your text auto-encoder?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EBZzlGjPCm", "forum": "TVSPV6D0co", "replyto": "TVSPV6D0co", "signatures": ["ICLR.cc/2026/Conference/Submission9389/Reviewer_zc4C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9389/Reviewer_zc4C"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762262364927, "cdate": 1762262364927, "tmdate": 1762920998891, "mdate": 1762920998891, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Author Response: Summary of Revisions and Updates"}, "comment": {"value": "We thank the reviewers for their helpful and constructive feedback. Below we summarize the main changes made in the revised manuscript.\n\n**Main paper**\n\n- **Abstract**  \n  We clarify that the reported 256-bit payload ceiling for existing multibit watermarking methods is an *empirical* observation, and thus our claim of “breaking the 256-bit limit” is made in this practical, baseline-relative sense.\n\n- **Section 3.2**  \n  We increase the font size in Figure 2 to improve readability.\n\n- **Section 3.3 (Security with secret key-based rotation)**  \n  We add a concrete real-world use case for the secret rotation layer (provenance verification by a content creator), explain why this mechanism fits our framework (post-training, cheap, supports many keys), and explicitly connect it to the standard use of secret keys in watermarking systems for security, referring to Cox et al. [1].\n\n- **Section 4 (Training)**  \n  We complete the existing paragraph to explain our design choice to *avoid* end-to-end training of the autoencoder and watermarker: the watermarker is trained on random unit vectors and already achieves high fidelity, joint training would reduce modularity and generality, and would significantly complicate optimization. We also state more explicitly that “finetuning VideoSeal” in our setting means aligning it with the substantial architectural and objective changes described in Section 3.1 (continuous unit-sphere latents, cosine loss, etc.).\n\n- **Section 4.1 (Watermark strength / imperceptibility).**  \n  We make explicit that watermark perturbation strength is measured via PSNR between the original and watermarked images. We introduce the scalar factor $\\alpha$ that controls the watermark residual, describe its role, and add a new experiment in Table 3 showing how perceptual metrics (PSNR, SSIM, LPIPS) and cosine similarity of the recovered latent vary as a function of $\\alpha$, thus clarifying how watermark power is controlled and reported in our experiments.\n\n- **Section 4.4 (Effect of latent dimensionality).**  \n  We summarize our sweep over latent dimensionalities $ {128, 256, 384}\\ $ for the text autoencoder (Appendix former Table 7, now Table 8 ) and explain how these results motivate our choice of a 256-dimensional latent as the best trade-off between reconstruction quality and robustness under latent noise. We also clarify that, in principle, the watermarking component can operate with other latent sizes, even though we focus on 256 dimensions in the main experiments.\n\n**Appendix**\n\n- **Updated comparison table (former Table 12, now Table 13).**  \n  We extend the table summarizing watermarking methods to include DwtDct, StableSignature, and RAW, together with their payload regimes and typical PSNR ranges. This clarifies that (i) DwtDct and StableSignature operate at significantly lower payloads (32–48 bits), and (ii) RAW is a zero-bit, detection-only scheme with AUC-ROC targeting watermark presence rather than message recovery.\n\n- **Section A.3 (Additional experiments on the text autoencoder).**  \n  We study the behaviour of our text autoencoder under fully randomized token selection at the input (uniformly sampled token IDs). We report quantitative metrics (exact-match rate and BLEU-4) and provide qualitative examples. These results show that the autoencoder, as expected, is not suited for encoding arbitrary random identifiers: it projects such out-of-distribution inputs toward the natural-language manifold and fails to reliably reconstruct the original random token sequences, reflecting its design assumptions about natural-language distributions.\n\n[1] I. J. Cox, M. L. Miller, J. A. Bloom, et al. *Digital Watermarking*. Morgan Kaufmann Publishers, 2008."}}, "id": "dABEOCVKdf", "forum": "TVSPV6D0co", "replyto": "TVSPV6D0co", "signatures": ["ICLR.cc/2026/Conference/Submission9389/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9389/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission9389/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763468789009, "cdate": 1763468789009, "tmdate": 1763468789009, "mdate": 1763468789009, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}