{"id": "6YEW4KMfgF", "number": 8039, "cdate": 1758054155753, "mdate": 1759897812440, "content": {"title": "Boosting Federated Model Convergence with Anomaly Detection and Exclusion", "abstract": "Federated Learning (FL) is becoming increasingly important in AI training, particularly for privacy-sensitive applications.\nAt the same time, it has become a subject of malicious action and needs better protection against adversarial attacks causing\ndata corruptions or other anomalies. \nIn this work, we show that, in contradiction to a popular point of view, if properly introduced security enhancement does improve FL convergence and performance. \nTaking inspiration from the classical PID control theory, we develop a novel anomaly detection and exclusion approach. \nUnlike other aggregation techniques that rely solely on current round Euclidean distances between clients, we compute a PID-based history-aware score, which is used to detect anomalies that exceed a statistically defined threshold. Our adaptive exclusion mechanism removes the need for predefined attacker counts, and its server-side linear computational complexity of $O(nd)$ ensures its scalability and practical significance, while existing methods remain superlinear in complexity. We prove theoretically and experimentally verify faster convergence and computational efficiency on several benchmark datasets of various modalities, including non-iid scenarios and different model architectures such as CNNs and LLMs, and show that our method maintains effectiveness while boosting convergence. Our approach is generalizable across diverse task domains and aggregation methods, and is easily implementable in practice.", "tldr": "", "keywords": ["federated learning", "security", "convergence", "anomaly detection"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f814f05b263be4f361844f47cfc4fe77c6fe20c9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes **PID-MADE**, a history-aware anomaly detection and exclusion rule for federated learning (FL). Each client gets a PID-style score (proportional + integral + derivative of its distance to a round centroid), and clients above a threshold $\\tau = \\bar u_t + k \\sigma_t$ are excluded before aggregation. the method is claimed to have faster convergence than FedAvg/Krum/Bulyan/RFA on several small image datasets and one LLM MLM setting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The **problem is interesting and important**: robust FL with attention to **convergence speed**, not only emprical resutls.\n- Method is **simple** and **practical** to implement; server cost $O(nd)$ is good for scale."}, "weaknesses": {"value": "- **(Major) Lack of strong theory for a security-style contribution.**  \n  The acceleration/convergence argument largely reduces to a **variance reduction** factor $\\sqrt{\\lvert G\\rvert / \\lvert A\\rvert}$ after filtering outliers. This is close to what I would call the **trivial bound** you get by dropping extremes;, this theory feels too weak.\n- **Adaptive attacker not considered.**  \n  The defense can likely be **gamed** by an adversary who shapes updates to keep the PID score under $\\tau$ (e.g., keep integral small, smooth derivative, small proportional spikes). As argued by *‚ÄúThe Attacker Moves Second‚Äù* (Nasr et al; different setting but very relevant message), defenses must anticipate attacker adaptivity. Here, only static/simple attacks are tested.\n- **Missing comparisons against SOTA robust FL methods.**  \n  The paper does not compare to several recent SOTA algorithms specifically designed for Byzantine robustness under heterogeneity, such as:  \n  - **Karimireddy, He, Jaggi (ICLR 2022)** ‚Äî *Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing*.  \n  - **Allouah et al. (AISTATS 2023)** ‚Äî *Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity*.  \n  - **Allouah et al. (ICML 2024)** ‚Äî *Byzantine-Robust FL: Impact of Client Subsampling and Local Updates*.  \n  - **Gorbunov et al. (ICLR 2023)** ‚Äî *Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression*.  \n  Without head-to-head comparisons, the empirical claims are not convincing for NeurIPS level.\n- **No test against SOTA attacks.**  \n  Evaluation is mostly **label-flip**  and one simple LLM case with a single malicious client. There is no evaluation against **LIE (A Little Is Enough)**, **Fall of Empires**, or other adaptive/stealthy/colluding attacks (e.g., min-max/ALIE/AGR or angle-constrained attacks) that are known to be stronge. This weakens the empirical message."}, "questions": {"value": "see weeknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "s1HjDIKkfS", "forum": "6YEW4KMfgF", "replyto": "6YEW4KMfgF", "signatures": ["ICLR.cc/2026/Conference/Submission8039/Reviewer_XcVV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8039/Reviewer_XcVV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760706287183, "cdate": 1760706287183, "tmdate": 1762920032951, "mdate": 1762920032951, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PID-MADE, a proportional‚Äìintegral‚Äìderivative-based anomaly detection and exclusion mechanism for federated learning (FL). The method computes a PID-style score for each client‚Äôs model update, using current, cumulative, and differential deviations from the global model. Clients exceeding a statistical threshold (Chebyshev or Gaussian-based) are excluded before aggregation. The authors claim the approach maintains $O(nd)$ complexity, requires no prior knowledge of the number of malicious clients, and even accelerates convergence compared to standard robust aggregation rules."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem formulation, motivation, and algorithmic steps are clearly described with pseudocode and complexity discussion.\n2. The detection mechanism is lightweight, running in ùëÇ(ùëõùëë) time, which makes it attractive for large-scale synchronous FL.\n3. Addressing robust FL without knowing attacker proportions is relevant and valuable for real-world deployments.\n4. The inclusion of convergence arguments and threshold derivations shows an effort to formalize the approach, albeit at a basic level."}, "weaknesses": {"value": "1. The PID-based formulation is essentially a weighted temporal smoothing of client deviation scores. Similar temporal and distance-based anomaly detection mechanisms have appeared in many robust FL works (e.g., FLTrust). The ‚ÄúPID‚Äù framing is metaphorical rather than a genuine control-theoretic contribution without stability or control analysis.\n\n2. The ‚Äúconvergence proof‚Äù relies on standard convex, bounded-gradient assumptions already sufficient for FedAvg; the PID terms are not meaningfully analyzed in that context. Claims of ‚Äúaccelerated convergence‚Äù are empirical and lack any formal rate improvement. The threshold derivation using Chebyshev or Gaussian statistics is standard textbook material, not a contribution. No analysis of false-positive or false-negative rates for client exclusion is provided.\n\n3. Evaluations are limited to simple datasets (MNIST, CIFAR) with artificially induced label-flip or scaling attacks. No experiments under modern or stealthy attack models (e.g., backdoor, gradient manipulation, model replacement). Reported improvements are minor and lack statistical significance (no confidence intervals or variance reporting). Experiments primarily show faster convergence, but not improved robust accuracy, which is the real metric of interest for Byzantine resilience.\n\n4. The proposed method assumes fully synchronous, homogeneous clients. System heterogeneity (asynchronous updates, delayed clients, stragglers) is completely ignored; the PID derivative term would be invalid when client updates arrive at different frequencies. Model heterogeneity is not supported as the distance metric presumes identical architectures and parameter shapes. Statistical heterogeneity (non-IID data) is treated only via trivial toy splits (2‚Äì3 classes per client). The method‚Äôs sensitivity to rare but legitimate client behavior is neither measured nor mitigated. In short, PID-MADE is not generalizable to realistic heterogeneous FL environments ‚Äî precisely where robust aggregation is most needed.\n\n5. Statements such as ‚Äúfaster convergence‚Äù or ‚Äúuniversally applicable to LLM fine-tuning‚Äù are overreaching given the scale and simplicity of experiments. No ablation study shows the individual contribution of the P/I/D components or the sensitivity to their hyperparameters $K_p, K_I, K_d$. The claimed scalability and universality are speculative rather than demonstrated."}, "questions": {"value": "1. Can the authors explain what fundamentally new insight the PID structure provides beyond being a heuristic temporal extension of existing trust-score schemes?\n\n2. How can the authors guarantee theoretical stability or convergence once updates are filtered dynamically by PID scores?\n\n3. How would PID-MADE handle real-world FL heterogeneity, both statistical (non-IID) and system (asynchronous or straggler) cases?\n\n4. Why are stronger or stealthier attacks (e.g., adaptive backdoor or model-replacement) not included to validate robustness claims?\n\n5. What measurable advantage in robustness, convergence rate, or computational efficiency, does PID-MADE demonstrate over FLTrust under the same attack ratio and non-IID setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uWfJSNW2BJ", "forum": "6YEW4KMfgF", "replyto": "6YEW4KMfgF", "signatures": ["ICLR.cc/2026/Conference/Submission8039/Reviewer_cefq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8039/Reviewer_cefq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761780355891, "cdate": 1761780355891, "tmdate": 1762920032524, "mdate": 1762920032524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PID-MADE, a proportional‚Äìintegral‚Äìderivative-based anomaly detection and exclusion mechanism for federated learning (FL). The method computes a PID-style score for each client‚Äôs model update, using current, cumulative, and differential deviations from the global model. Clients exceeding a statistical threshold (Chebyshev or Gaussian-based) are excluded before aggregation. The authors claim the approach maintains $O(nd)$ complexity, requires no prior knowledge of the number of malicious clients, and even accelerates convergence compared to standard robust aggregation rules."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem formulation, motivation, and algorithmic steps are clearly described with pseudocode and complexity discussion.\n2. The detection mechanism is lightweight, running in ùëÇ(ùëõùëë) time, which makes it attractive for large-scale synchronous FL.\n3. Addressing robust FL without knowing attacker proportions is relevant and valuable for real-world deployments.\n4. The inclusion of convergence arguments and threshold derivations shows an effort to formalize the approach, albeit at a basic level."}, "weaknesses": {"value": "1. The PID-based formulation is essentially a weighted temporal smoothing of client deviation scores. Similar temporal and distance-based anomaly detection mechanisms have appeared in many robust FL works (e.g., FLTrust). The ‚ÄúPID‚Äù framing is metaphorical rather than a genuine control-theoretic contribution without stability or control analysis.\n\n2. The ‚Äúconvergence proof‚Äù relies on standard convex, bounded-gradient assumptions already sufficient for FedAvg; the PID terms are not meaningfully analyzed in that context. Claims of ‚Äúaccelerated convergence‚Äù are empirical and lack any formal rate improvement. The threshold derivation using Chebyshev or Gaussian statistics is standard textbook material, not a contribution. No analysis of false-positive or false-negative rates for client exclusion is provided.\n\n3. Evaluations are limited to simple datasets (MNIST, CIFAR) with artificially induced label-flip or scaling attacks. No experiments under modern or stealthy attack models (e.g., backdoor, gradient manipulation, model replacement). Reported improvements are minor and lack statistical significance (no confidence intervals or variance reporting). Experiments primarily show faster convergence, but not improved robust accuracy, which is the real metric of interest for Byzantine resilience.\n\n4. The proposed method assumes fully synchronous, homogeneous clients. System heterogeneity (asynchronous updates, delayed clients, stragglers) is completely ignored; the PID derivative term would be invalid when client updates arrive at different frequencies. Model heterogeneity is not supported as the distance metric presumes identical architectures and parameter shapes. Statistical heterogeneity (non-IID data) is treated only via trivial toy splits (2‚Äì3 classes per client). The method‚Äôs sensitivity to rare but legitimate client behavior is neither measured nor mitigated. In short, PID-MADE is not generalizable to realistic heterogeneous FL environments, precisely where robust aggregation is most needed.\n\n5. Statements such as ‚Äúfaster convergence‚Äù or ‚Äúuniversally applicable to LLM fine-tuning‚Äù are overreaching given the scale and simplicity of experiments. No ablation study shows the individual contribution of the P/I/D components or the sensitivity to their hyperparameters $K_p, K_I, K_d$. The claimed scalability and universality are speculative rather than demonstrated."}, "questions": {"value": "1. Can the authors explain what fundamentally new insight the PID structure provides beyond being a heuristic temporal extension of existing trust-score schemes?\n\n2. How can the authors guarantee theoretical stability or convergence once updates are filtered dynamically by PID scores?\n\n3. How would PID-MADE handle real-world FL heterogeneity, both statistical (non-IID) and system (asynchronous or straggler) cases?\n\n4. Why are stronger or stealthier attacks (e.g., adaptive backdoor or model-replacement) not included to validate robustness claims?\n\n5. What measurable advantage in robustness, convergence rate, or computational efficiency, does PID-MADE demonstrate over FLTrust under the same attack ratio and non-IID setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uWfJSNW2BJ", "forum": "6YEW4KMfgF", "replyto": "6YEW4KMfgF", "signatures": ["ICLR.cc/2026/Conference/Submission8039/Reviewer_cefq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8039/Reviewer_cefq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761780355891, "cdate": 1761780355891, "tmdate": 1763098477603, "mdate": 1763098477603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studied the effect of anomaly detection and exclusion on learning efficiency in federated learning (FL). Vis theoretical analysis, the authors demonstrated how FL anomaly exclusion mechanisms contribute to faster convergence of the global model. In adddition, the authors introduced PID-MADE, operating without requiring the estimate of expected anomalies and achieving linear computational complexity. However, there existing some concerns, including baseline selection and poor performance of  PID-MADE."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper studied the effect of anomaly detection and exclusion on learning efficiency in federated learning (FL). Vis theoretical analysis, the authors demonstrated how FL anomaly exclusion mechanisms contribute to faster convergence of the global model. In adddition, the authors introduced PID-MADE, operating without requiring the estimate of expected anomalies and achieving linear computational complexity."}, "weaknesses": {"value": "I have some concerns as follows.\n1. The aggregation strategies shown in Tab. 1 is incomplete, such as 1) FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation; 2) Federated Learning with Sample-level Client Drift Mitigation.\n2. The proposed PID-MADE shows a poor performance in Fig. 2 for FEMNIST. The authors should conduct the experiments on more datasets, not just these four datasets.\n3. The baselines used in experiments are Krum, MKrum, RFA, Bulyan. I think that these baselines are not enough and the authors should add some state-of-the art baselines.\n4. In addition, the robustness of the PID-MADE is not well evaluated in experiments. The authors should evaluate the the robustness of the PID-MADE under the state-of-the art poisoning attacks."}, "questions": {"value": "1. The aggregation strategies shown in Tab. 1 is incomplete, such as 1) FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation; 2) Federated Learning with Sample-level Client Drift Mitigation, and etc.\n2. The proposed PID-MADE shows a poor performance in Fig. 2 for FEMNIST. The authors should conduct the experiments on more datasets, not just these four datasets.\n3. The baselines used in experiments are Krum, MKrum, RFA, Bulyan. I think that these baselines are not enough and the authors should add some state-of-the art baselines.\n4. In addition, the robustness of the PID-MADE is not well evaluated in experiments. The authors should evaluate the the robustness of the PID-MADE under the state-of-the art poisoning attacks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7M0lP8TbHU", "forum": "6YEW4KMfgF", "replyto": "6YEW4KMfgF", "signatures": ["ICLR.cc/2026/Conference/Submission8039/Reviewer_acqF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8039/Reviewer_acqF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761870798872, "cdate": 1761870798872, "tmdate": 1762920032143, "mdate": 1762920032143, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}