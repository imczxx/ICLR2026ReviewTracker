{"id": "n1rsWhJf8B", "number": 16994, "cdate": 1758271001617, "mdate": 1759897205774, "content": {"title": "Enhancing Cross-Lingual Embedding Alignment with Additive Keywords for International Trade Product Classification", "abstract": "Cross-lingual embedding alignment plays an important role in enabling effective multilingual classification tasks. Although multilingual pretrained language models and fine-tuning techniques are increasingly adopted, current approaches inadequately address specialised domains, where domain-specific terminology and mixed-language content present unique challenges that hinder classification accuracy. This work considers the problem of automatically classifying text-based descriptions of international trade transactions with respect to an international standard Harmonized System (HS) code taxonomy. We propose a novel method that incorporates mixed-language keyword embeddings to improve cross-lingual alignment, focusing on bilingual models, and subsequently leverages this alignment for downstream classification tasks, with particular applicability to low-resource domains. Using a supervised learning framework implemented through neural network architectures, the model is trained on pairs of product descriptions and their corresponding extracted keywords. Experimental results on benchmark bilingual datasets demonstrate significant and consistent improvements in classification performance over baseline models, including in low-resource target language scenarios. The findings demonstrate the effectiveness of incorporating additive keywords as a strategy for cross-lingual embedding alignment, thereby enhancing representation quality and improving classification accuracy.", "tldr": "", "keywords": ["Bilingual classification", "Cross-lingual embedding alignment", "Low-resource languages", "International trade classification", "Harmonized System codes"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a12e627af28b1459536725fe2a6d9c9887b44336.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper describes an architecture and experiment in NLP for a low resource language -- Indonesian.  The main task is to classify products using Indonesian text.  The paper describes an architecture that builds on DistilBERT, and fuses with an Indonesian models focusing on extracted keywords.  This method works very well in the one experiment, and I think could generalize to other low-resource languages.  Notably it outperforms mBERT, an Indonesian specific model, and other obvious baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Extended amazing success of English LLMs to much lower resource languages is a key challenge the ML community is facing.  The idea of focusing on the better represented features (high term frequency words) to fuse the English and Indonesian models is something that might generalize to other languages."}, "weaknesses": {"value": "On the downside, this paper is really about a single experiment on one data set.  There is not evidence that it will be a broadly general approach.  It is not just that it is only on a single language, but it is only on the product classification task.  Half the gains come from careful treatment of the products.  \n\nI have mixed thoughts on this.  I think the problem is important, the result on the one experiment is very strong, and it may generalize -- but because it is more limited in experiments than a traditional ICLR paper, I have low confidence to advocate for the paper."}, "questions": {"value": "Can you provide evidence that this approach applies more generally to problems with low resource language?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U1YC2Fb7ZL", "forum": "n1rsWhJf8B", "replyto": "n1rsWhJf8B", "signatures": ["ICLR.cc/2026/Conference/Submission16994/Reviewer_epe2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16994/Reviewer_epe2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761423986212, "cdate": 1761423986212, "tmdate": 1762927018308, "mdate": 1762927018308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is about cross-lingual embedding alignment, in particular for english and indonesian languages in the setting of product classification. The authors propose a model that combines inputs for product descriptions and keywords to classify products in a setting of international trade.\n\nThe model that the authors build is bilingual, able to make classification in english or indonesian.\n\nThe contributions are:\n- A training process for a model taking two inputs, product descriptions and cross-lingual keywords to represent product categories.\n- A bilingual model (english and indonesian) and architecture consisting of dual encoders, fusion layers and classification layers. This model achieves good performance in low resource settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and easy to follow.\n- The problem seems to be difficult, to classify a product according to a trade standard based on description/keywords in english and local language (indonesian in this case), so this seems to be a real-world problem that can produce insights in ML and linguistics.\n- The evaluation seems to be correct (except for results in Figure 5), there is a good selection of baselines, and results on one dataset of english and indonesian products. Overall the conclusion that the model outperforms the baselines seems to be correct.\n- There are ablation results with the different input languages and the two inputs (product and keyword or both), which shows the advantage of using both inputs.\n- The model seems to perform well in a low resource setting."}, "weaknesses": {"value": "- The bilingual model architecture does not seem novel to me, it looks like a common architecture for cross-lingual modelling. I do not see this as a strong negative, just that the authors claim this architecture as a novelty.\n- The results presented in Figure 5 are a bit puzzling, as this experiment varies the number of data points in indonesian language, including zero data points, which I would expect to obtain close to random (50%?) performance since the model does not know indonesian language, but it obtains around 92% F1, which the authors do not explain, how is it possible if the model has not been trained in indonesian language?\n- The dataset used for training and evaluation is not clear, there are multiple references pointing to use of a dataset, but not a clear dataset name, the text  in lines 252-256 seems to hide which dataset is being used, please make this information very clear for reproducibility and trustworthiness.\n- I believe the results are not really surprising, the authors do mention that results are consistent with the literature (lines 359-363) about importance of keyword features, I believe the authors should highlight the novelty of this paper relative to the state of the art.\n\nSome minor improvements:\n- Table 4, there is no need to use abbreviations since there is plenty of space in the table for PO, KO, MK, etc.\n- Figure 4, the text looks blurry since it is presented in a raster image, always present text as text, not as images. Additionally I would recommend to include multiple qualitative examples for completeness, similarly for Table 2, these qualitative examples are interesting for the reader.\n- Figure 3 would be best presented as vector figures (PDF) from the source."}, "questions": {"value": "- Can you explain the results in Figure 5, specifically the first set of results with zero indonesian data points? How can the model score much higher than random chance if has not been trained in the indonesian language?\n- Can you clarify the novelty with respect to the state of the art?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8Ok64cPUQJ", "forum": "n1rsWhJf8B", "replyto": "n1rsWhJf8B", "signatures": ["ICLR.cc/2026/Conference/Submission16994/Reviewer_ysaW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16994/Reviewer_ysaW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773217770, "cdate": 1761773217770, "tmdate": 1762927017798, "mdate": 1762927017798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work focus on the international trade product classification. The aim of this problem it to predict the HS code based on the mixed-language texts in trade documents. The authors propose a framework to tackle this problem. It consists of keywords extraction and configuration, in which the keywords in English and Indonesian are paired to mixed keywords (MK) as additive information for product classification. Experiments and ablation demonstrate the effectiveness of the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The task of international trate production classfication is a real application with technical challenges.\n2. The paper is well-written and easy to follow. The challenges of international trade product classfication is clearly introduced.\n3. The proposed framework is reasonable and can intuitively address the chanlleges that the documents are in mixed languages.\n4. The experiments are comprehensive and ablation is valid to demonstrate the effectiveness of the framework."}, "weaknesses": {"value": "1. The scope of this research is a bit limited, and experiments only include English and Indonesian languages.\n2. The proposed framework is not novel. The keyword extraction and configuration steps are reasonable but straighforward. The classification module is also a natural design. The overall framework is more like a standard solution.\n\nOverall, the limited scope and incremental design in this work is obvious. My concern is that how much insights this work could provide to a broader community. The contribution of this work can be futher improved with either datasets contribution, such as new datasets on international trade, or in-depth study on international trade scenarios in more languages or more fundamental challenges. But those improvements can be out of the scope of this work, and I acknowledge the contribution in the current manuscript as mentioned above in strength section and would recommend a positive rating.\n\nMinor comments:\n1. Illustration and examples can improve the readability as international trade is a vertical application for cross-lingual embedding, as far as I know.\n2. Is the proposed approach related to word alignment task [1] in machine translation? \n\n[1] https://en.wikipedia.org/wiki/Bitext_word_alignment"}, "questions": {"value": "See weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "STN7RFVqWH", "forum": "n1rsWhJf8B", "replyto": "n1rsWhJf8B", "signatures": ["ICLR.cc/2026/Conference/Submission16994/Reviewer_khEL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16994/Reviewer_khEL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008188105, "cdate": 1762008188105, "tmdate": 1762927012704, "mdate": 1762927012704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies on using mixed-language keywords to enhance cross-lingual embedding alignment for a challenging, real-world task: bilingual HS code classification. The proposed method demonstrates consistent improvements over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-  The proposed method is intuitive and demonstrates performance improvements over several multilingual baselines on bilingual trade classification tasks.\n- The method also shows effectiveness in low-resource scenarios, addressing a key limitation in current multilingual classification systems."}, "weaknesses": {"value": "- Limited Justification of Cross-Lingual Alignment: Given the strong inherent capabilities of modern multilingual LLMs to process and align multilingual text, focusing on explicit cross-lingual embedding alignment may have constrained practical value. State-of-the-art LLMs often natively achieve effective cross-lingual understanding and representation.\n- The baselines used in the paper are primarily BERT and its variants, which are increasingly outdated. The paper lacks comparative analysis with the latest multilingual and reasoning-oriented LLMs (e.g., Qwen, LLaMA), making it difficult to convincingly demonstrate the proposed method's advantage relative to the current state-of-the-art.\n- Experiments are confined to the English-Indonesian language pair and the specific domain of international trade product classification. The methodâ€™s effectiveness and transferability to other language pairs, more diverse multilingual settings (such as code-switching or morphologically rich languages), and applications remain uninvestigated.\n- The keyword extraction relies heavily on frequency-based methods (e.g., TF), which may miss nuanced or context-specific terms crucial in complex real-world trade data."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "znnYbpRzlX", "forum": "n1rsWhJf8B", "replyto": "n1rsWhJf8B", "signatures": ["ICLR.cc/2026/Conference/Submission16994/Reviewer_4G7R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16994/Reviewer_4G7R"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762099366471, "cdate": 1762099366471, "tmdate": 1762927011482, "mdate": 1762927011482, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}