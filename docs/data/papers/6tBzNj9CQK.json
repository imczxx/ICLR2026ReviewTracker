{"id": "6tBzNj9CQK", "number": 5499, "cdate": 1757915717448, "mdate": 1759897970963, "content": {"title": "Autonomous Source Knowledge Selection in Multi-Domain Adaptation", "abstract": "Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named Autonomous Source Knowledge Selection (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.", "tldr": "An autonomous source knowledge selection method for multi-domain adaptation.", "keywords": ["transfer learning", "domain adaptation", "machine learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1f9e90f27a9cf77b300791b3a9798afd1ed0e5f5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an unsupervised multi-domain adaptation method named Autonomous Source Knowledge Selection (AutoS), which aims to address the challenge of redundant or irrelevant information from massive source domains. The method autonomously selects relevant source training samples and models through a density-driven selection strategy, while employing a pseudo-label enhancement module based on a pre-trained multimodal model to reduce target label noise and enhance self-supervision. Experiments are conducted on the Office31, OfficeHome, DomainNet126 and DomainNet datasets."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The research motivation of this paper is clearly articulated, and the framework diagram is well-designed.\n\n2. The paper includes comprehensive ablation studies and visualizations, which strengthen the presented work."}, "weaknesses": {"value": "1. The performance advantage of the proposed method over the state-of-the-art ones is marginal. On the four benchmark datasets, the highest improvement over the state-of-the-art is only 0.4%, and the method even underperforms some baselines in certain cases. This raises serious doubts about the method's practical effectiveness and its overall contribution.\n\n2. The ablation study presented in Table 3 fails to provide compelling evidence for the effectiveness of the individual components. The performance gain of the full model over the base model is merely 0.3%. Such a minuscule improvement makes it difficult to convincingly argue that the added modules contribute significantly to the overall framework.\n\n3. The methodology section suffers from a critical lack of clarity. Numerous symbols used in the mathematical formulations are not defined or explained, which severely hinders the reader's ability to understand the technical details and reproduce the work. A thorough review and supplementation of all mathematical notation throughout the paper is strongly recommended."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UqCaGNBtqw", "forum": "6tBzNj9CQK", "replyto": "6tBzNj9CQK", "signatures": ["ICLR.cc/2026/Conference/Submission5499/Reviewer_vFzD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5499/Reviewer_vFzD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761485908181, "cdate": 1761485908181, "tmdate": 1762918094585, "mdate": 1762918094585, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an autonomous source knowledge selection framework for multi-source domain adaptation. The method progressively filters out unhelpful source domains and samples via a density-driven selection strategy, and adapts a target model by fusing selected source models and pseudo-labels from a external CLIP. The overall design reduces noise from redundant sources and enhances cross-domain generalization through cross-modal supervision and prompt tuning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The method is modular and integrates several known techniques (e.g., density estimation, prompt tuning, CLIP supervision).\n2. This paper shows some promising empirical results on standard benchmarks."}, "weaknesses": {"value": "1. The method assumes the availability of domain labels for all source domains. In practice, especially with large-scale web or industrial data, domain boundaries are often unknown or ambiguous. The entire framework depends on identifying and discarding full source domains, which is risky.\n2. The problem of transferring from multiple labeled domains to an unlabeled target is a classic transfer learning setting. However, the method relies on CLIP, itself already mitigates many of the traditional domain shift issues. This creates a mismatch between the paper‚Äôs motivation and its solution. (and CLIP prompt tuning has been studied to overcome dataset shift already, It feels somewhat excessive to use prompt tuning here, given that it‚Äôs only used for generating better guidance.)\n3. Recent works are not compared [1]. PACS is a well-established testbed for domain selection and is notably missing here. ImageNet family can also be considered (ImageNet, ImageNet-C, ImageNet v2, etc)\n4. The method reads as a combination of existing ideas (density filtering, prompt tuning, model averaging) without a unifying intuition. There is no concrete observation or empirical motivation driving the design of the multi-step pipeline. Why density? Why federated aggregation vs. others? Why this specific prompt tuning strategy? \n5. Source selection can be risky e.g., wrongly discarding helpful domains or reinforcing spurious alignment. \n6. With the rise of strong foundation models that already exhibit strong zero-shot and transfer capabilities, the need for complex multi-source adaptation pipelines has reduced significantly. In this context, it would be helpful for the authors to clarify the motivation and relevance of their setting in modern real-world scenarios, especially where domain boundaries are often unknown and data is unstructured or unlabeled.\n\n[1] Training multi-source domain adaptation network by mutual information estimation and minimization"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DnfOINOZDQ", "forum": "6tBzNj9CQK", "replyto": "6tBzNj9CQK", "signatures": ["ICLR.cc/2026/Conference/Submission5499/Reviewer_JdHR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5499/Reviewer_JdHR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809534292, "cdate": 1761809534292, "tmdate": 1762918094367, "mdate": 1762918094367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- Task: Unsupervised multi-domain adaptation\n- Goal: To solve a target task in an unlabeled target domain by leveraging source information obtained from multiple source domain.\n- The paper proposes a selection strategy to determine which source domains are most useful for learning in unsupervised multi-domain adaptation.\n- To mitigate label noise, the authors introduce a multi-modal model along with a novel prompt tuning loss designed to train it.\n- The effectiveness of the two proposed contributions is demonstrated through experiments, showing consistent performance improvements and validating the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Recognizing that not all source information is equally useful in unsupervised multi-domain adaptation, the authors propose a selection strategy.\n   - Each source domain is assigned a weight according to its relevance, enabling the model to selectively utilize information that is more beneficial for target domain adaptation.\n- In parallel with employing a multi-modal model, the authors propose a loss function designed to enhance the alignment of the target adaptation model."}, "weaknesses": {"value": "- Lack of analysis\n   - While  the assumption that not all source information is useful is understandable, the paper would be more convincing if experimental evidence supporting this claim were provided.\n   - The proposed loss function $\\mathcal{L}_{\\mathrm{ex}}$\n appears to designed for the prompt tuning objective of a foundation model, but its precise mathematical definition and formulation should be explicitly stated.\n   - Additional experiments are needed to justify the validity of the hyperparameter settings used in the proposed method.\n   - The interpretation and significance of the proposed components are generally underexplained and lack in-depth analysis.\n- Representation quality\n   - In Eq. (1), the position of $(x_k^{s}, \\hat{y}_k^{s}) \\in \\mathcal{D}_k^{S}$ within the argmin expression appears to be incorrect.\n   - Although the meaning of ùúá in Eq. (1) can be inferred, it should be explicitly described in the text to improve clarity.\n   - The dataset used in Fig. 3 should be clearly specified.\n   - The overall quality of the figures in experiments section is relatively low and should be improved.\n      - The font size in Fig. 4 is too small for readability."}, "questions": {"value": "- Assumption and experimental evidence\n   - The assumption that not all source information is useful in unsupervised multi-domain adaptation is understandable; however, the paper would be stronger if this assumption were supported by empirical evidence through experiments.\n- Clarification and validation of the proposed loss\n   - Among the proposed loss functions, $\\mathcal{L}_{\\mathrm{ex}}$  appears to represent a learning objective for prompt tuning within a foundation model. Its precise definition and mathematical formulation should be clearly stated.\n- Hyperparameter justification\n   - Additional experiments are required to justify the chosen hyperparameter settings and demonstrate their robustness across different configurations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qPzJMdZIiw", "forum": "6tBzNj9CQK", "replyto": "6tBzNj9CQK", "signatures": ["ICLR.cc/2026/Conference/Submission5499/Reviewer_r5bP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5499/Reviewer_r5bP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906224844, "cdate": 1761906224844, "tmdate": 1762918094014, "mdate": 1762918094014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a two‚Äëstage source knowledge selection method for multi‚Äësource unsupervised domain adaptation (MS‚ÄëUDA). The proposal can: 1. autonomously select and collect transferable samples via a density‚Äëcontrolled, target‚Äëdriven criterion, and 2. adapt to the target with prompt‚Äëtuning. Experiments on several cross-domain vision datasets show competitive accuracy among several recent baselines, with lower running time and GPU memory. Ablations suggest that different components of the proposal contribute."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper targets a practical scalability issue in MS‚ÄëUDA, i.e., addresses a valid and important research gap that is significantly important.\n\n Design of selection signal and two‚Äëstage training with prompt‚Äëonly fine-tuning can conceptually reduce the overall complexity.\n\nAblations indicate that each component of the proposal contributes to the performance."}, "weaknesses": {"value": "The paper‚Äôs novelty might be the specific density-aware keep/drop rule coupled with federated aggregation. Other core components, such as source/domain selection or weighting, are better explored.\n\nThe absolute performance gains compared with other baselines appear to be marginal.\n\nPotential dependence on a foundation model for pseudo-label production. Gains may partially stem from CLIP priors rather than the selection scheme, especially when referring to Tables 1 and 2; performance may degrade in domains where CLIP is weak. \n\nTable 5 lacks units for running time and GPU memory, while only empirical results are given, lacking theoretical evidence. This makes the assessment of the actual trade-off difficult.\n\nThe quality of visualization (aspect ratio, font size, etc.) needs improvement starting from Fig. 3; similarly, there are some writing errors, e.g., multi-modal ‚Äúmodal‚Äù in the abstract."}, "questions": {"value": "Elaborate further to potentially address the CLIP‚Äôs related worries, as in the Weakness section.\n\nTo help Table 5 make more sense, please specify units and provide more complete information about the computational platform. A few more benchmarks are desired for this part. Please also elaborate on theoretical complexity where applicable.\n\n Regarding the experimental configuration, please at least add the related information of the federated learning setup. Moreover, please specify if an ideal federated learning scenario is assumed.\n\nOn Office-Home, the source-free variant can slightly beat the ‚Äúdefault‚Äù setting. With source information, such results appear to be counterintuitive. Please elaborate on this.\n\nCheck the manuscript carefully to avoid small writing errors and update figures for easier reading. Other minor suggestions include enlarging Fig.1‚Äôs font size and updating Fig.2‚Äôs upper part to directly contain the information of federated learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YBzaXMsikU", "forum": "6tBzNj9CQK", "replyto": "6tBzNj9CQK", "signatures": ["ICLR.cc/2026/Conference/Submission5499/Reviewer_brPv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5499/Reviewer_brPv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058805923, "cdate": 1762058805923, "tmdate": 1762918093772, "mdate": 1762918093772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new method for selecting source domains which are relevant to a specific target domain under a multi-source domain adaptation setting. Specifically, they introduce a closeness measure based on how source domains match a defined density distribution to target samples and re-weight the source domain accordingly. They also introduce a self-supervised learning strategy that uses a pre-trained foundation model to bootstrap the learning using the selected source domains. Experiments show positive improvements of this method over prior methods."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles an important problem of selecting relevant source domains for a target domain. \n\n- The idea of using pre-trained models to sub-select the source domains instead of re-training the source domains separately is very interesting."}, "weaknesses": {"value": "- The paper lacks any sound intuition of technical depth as to why the proposed framework should work. The sequence of steps are just presented without adequate explanation as to what each of those are supposed to achieve, and why no other good alternatives exist. For example, L216-240 in Sec 3.3 has many successive equations but none of the notations are explained. $\\Gamma, \\pi, \\sigma, \\lambda$ are all used but none of them are grounded in previous notation or explained what they mean, without which they just seem like runaway arguments. \n\n- In addition to above, the paper does not adequately support the hypothesis on why the gating function in Eq 8 should work. At the very least, it should be explained what does $\\frac{1}{K}-\\sigma$ means, and why is it a good threshold. while theoretical justification is out of the scope, intuition behind this should atleast be explained. \n\n- Use of foundational model in Sec 3.4 is not clear, and Eq 13 is not supported well in the rest of the arguments."}, "questions": {"value": "- The paper uses a VLM foundational model, so it should be specified what other compared models also use the foundation model and what do not. In addition, the zero-shot accuracy using the foundation model on the target domain also has to be presented as a comparison. \n\n- Is the source domain selection done once before training or is it done continuously during training? As the features are learnt, it might happen that few source domains which were removed might again become relevant, how do the authors address this case?\n\n- are there any examples of what source domains are considered \"related\" in datasets like say, DomainNet? Also, if source Domain A is considered to be \"relevant\" for target Domain B, then will this also be the case when source is B and target is A? are the operations commutative?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aqzQl1iZ4P", "forum": "6tBzNj9CQK", "replyto": "6tBzNj9CQK", "signatures": ["ICLR.cc/2026/Conference/Submission5499/Reviewer_8WjH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5499/Reviewer_8WjH"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission5499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762450456072, "cdate": 1762450456072, "tmdate": 1762918093473, "mdate": 1762918093473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}