{"id": "p0hLWIPCri", "number": 22185, "cdate": 1758327361381, "mdate": 1762981115662, "content": {"title": "GRID: Scalable Task-Agnostic Prompt-Based Continual Learning for Language Models", "abstract": "Prompt-based continual learning (CL) provides a parameter-efficient approach for adapting large language models (LLMs) across task sequences. However, most existing methods rely on task-aware inference and maintain a growing set of task-specific prompts, which introduces two major challenges: (1) severe performance degradation on earlier tasks under task-agnostic inference, and (2) limited scalability due to prompt memory accumulation as task sequences grow.\nIn this paper, we present GRID, a unified framework designed to address these challenges. GRID incorporates a decoding mechanism that enhances backward transfer by leveraging representative inputs, automatic task identification, and constrained decoding. Furthermore, it employs a gradient-guided prompt selection strategy to compress less informative prompts into a single aggregated representation, ensuring scalable and memory-efficient continual learning. Extensive experiments on long-sequence and negative transfer benchmarks show that GRID improves average accuracy and backward transfer, achieves competitive forward transfer, and substantially reduces prompt memory usage.", "tldr": "GRID improves continual learning for LLMs by reducing prompt memory and exposing latent forgetting in task-agnostic settings", "keywords": ["Continual Learning", "Prompt Tuning", "Large Language Models", "Backward Knowledge Transfer"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/889b1ed0172ef57144f368609450aedd4d13eac8.pdf", "supplementary_material": "/attachment/e321fa539ee7e16c468529c4ef680ad500141171.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a prompt-based continual learning method for preserving model performance on old tasks and optimizing the memory usage in task-agnostic scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This work tries to address the challenging task of continual learning in task-agnostic settings, achieving good results on long-sequence and negative transfer benchmarks.\n\n2. The intuition of using gradient to determine the usefulness of prompts is interesting."}, "weaknesses": {"value": "1. I am doubtful whether label mapping is still widely adopted in the mainstream decoder-only models. It looks to me that although the performance of decoder-only models may slightly underperform the encoder-decoder models, decoder-only models are scalable and do not require specific mapping strategies. Moreover, I am wondering why the authors do not apply thier method on decoder-only models such as Llama and Qwen.\n\n2. There is redundency in writing. Both the introduction section and section 2.3 mention Lack of Task Awareness and Prompt Growth, which is unnecessary. Moreover, S4 and S5 in Figure 1 are not introduced in the paper.\n\n3. The authors claim that their method reduces the memory storage. However, the calculation of the gradient requires more GPU memory than direct inference, which makes the claim not solid enough."}, "questions": {"value": "1. Could you please provide some cases where the task id is not available during inference?\n\n2. The authors mention a label set L_i in line 224. However, I do not see a related definition of L_i."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jnIW89eGdV", "forum": "p0hLWIPCri", "replyto": "p0hLWIPCri", "signatures": ["ICLR.cc/2026/Conference/Submission22185/Reviewer_9iSF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22185/Reviewer_9iSF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761504832507, "cdate": 1761504832507, "tmdate": 1762942107407, "mdate": 1762942107407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "A6NO8E88wR", "forum": "p0hLWIPCri", "replyto": "p0hLWIPCri", "signatures": ["ICLR.cc/2026/Conference/Submission22185/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22185/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762981114959, "cdate": 1762981114959, "tmdate": 1762981114959, "mdate": 1762981114959, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GRID, a scalable and task-agnostic prompt-based continual learning framework for large language models. GRID enables task-agnostic inference by combining two key components: (1) a constrained decoding pipeline that leverages representative input sampling, automatic task identification, and restricted output spaces to mitigate label drift and latent forgetting; and (2) a gradient-guided prompt selection and compression mechanism that merges redundant prompts to ensure memory efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses an underexplored but practically important setting where task identities are unknown at inference time. By integrating task identification and constrained decoding, GRID effectively mitigates label drift and latent forgetting—issues largely ignored in prior prompt-based continual learning works such as ProgPrompt and SHLPT.\n\n2. The proposed gradient-guided prompt compression provides a simple yet effective mechanism to control prompt pool growth, reducing memory usage by over 60% without compromising performance. This contributes to the scalability and practical deployability of prompt-based continual learning in large language models."}, "weaknesses": {"value": "1. **Lack of theoretical analysis.**\nFor example, the gradient-based prompt selection in Eq. (1–4) is heuristic: prompts with smaller gradient norms are merged by a simple weighted average. However, the paper provides no theoretical justification for why the gradient magnitude correlates with “informativeness”. \n\n2. **Limited experimental evidence supporting the core claim on task-agnostic inference and constrained decoding.**\nAlthough the paper claims that GRID enables task-agnostic continual learning through its constrained decoding mechanism, the experiments do not fully isolate or quantify this effect. For example, Tables 2–5 are conducted under fixed task sequences (L1–L6, NT1–NT3), where the model still implicitly follows task boundaries during training and testing. There is no experiment showing inference under truly mixed or unknown-task inputs, where samples from multiple tasks are presented without task labels."}, "questions": {"value": "1. Could the authors provide more theoretical analysis to better justify the effectiveness of the gradient-based prompt selection mechanism?\n\n2. Could the authors provide additional empirical evidence to further demonstrate the effectiveness of the constrained decoding mechanism, particularly in task-agnostic inference scenarios?\n\n3. Have the authors explored or compared alternative dynamic selection or compression strategies beyond the gradient-based approach described in Equation (1)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "puX8NoFeyp", "forum": "p0hLWIPCri", "replyto": "p0hLWIPCri", "signatures": ["ICLR.cc/2026/Conference/Submission22185/Reviewer_mf3C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22185/Reviewer_mf3C"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900779328, "cdate": 1761900779328, "tmdate": 1762942107094, "mdate": 1762942107094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GRID which cleanly targets task-agnostic continual learning with a bounded prompt pool and offers a practical, well-engineered framework. The representative input sampling with task identification stabilizing decoding and constrained decoding curbs label drift and a gradient guided prompt selection cutting memory together improve prompt efficacy on downstream tasks. The authors also present ablations and runtime/memory. However, the conceptual novelty is modest as clustering, label remapping + constrained decoding, gradient scoring or prompt aggregation are widely known to everyone in this community."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem is very clear for task-agnostic inference with a bounded prompt pool.\nThe synergy of representative-input sampling + task ID and constrained decoding and gradient-guided prompt selection/merging. It cuts prompt memory $\\approx \\frac{2}{3}$ with better BWT/FTC than ProgPrompt/SHLPT, and includes ablations and runtime/memory reporting."}, "weaknesses": {"value": "Useful engineering but the conceptual novelty is modest and the evaluation might be too simple.\nEach component is well-known: representative sampling/clustering, label remapping + constrained decoding, and gradient-norm scoring. The “gradient-weighted merging” is a straightforward heuristic.\nEven though the amount of tasks is large, most tasks are short-label classification (BoolQ, MNLI, SST-2, etc.). No open-ended generation, no tool use, no long-context or instruction-following streams, little domain/format shift, and few tasks where prompts truly interfere.\nThe threshold $\\tau = \\mu_{g} + \\alpha \\sigma_{g}$ is not analyzed.  \nModels are limited to T5/Flan-T5. The gains are not clear for modern chat LLMs or multimodals. Can the authors run larger and more recent models?"}, "questions": {"value": "Sensitivity to $\\alpha$, cluster count, similarity cutoff, and representative-set size; show curves, not single points.\nAny results on instruction-following models/tasks (e.g., FLAN mixtures, BIG-bench tasks), multi-label/structured outputs, multilingual, or tool-augmented tasks? Harder reasoning tasks? Long-form generation?\nAre gains statistically significant across seeds? How many trials authors run? At least 5 trials should be repeated per setting for statistical significance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LsuDJBv2iX", "forum": "p0hLWIPCri", "replyto": "p0hLWIPCri", "signatures": ["ICLR.cc/2026/Conference/Submission22185/Reviewer_Zano"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22185/Reviewer_Zano"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972781293, "cdate": 1761972781293, "tmdate": 1762942106750, "mdate": 1762942106750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "GRID is a prompt-based continual learning framework tackling two key challenges: severe performance degradation under task-agnostic inference and prompt memory accumulation as task sequences grow. It introduces a novel decoding mechanism—leveraging automatic task identification and constrained decoding—to enhance backward knowledge transfer. Additionally, GRID uses a gradient-guided prompt selection strategy that merges less informative prompts into a single representation for scalable, memory-efficient learning. Experiments on long-sequence and negative transfer benchmarks show improved average accuracy and backward transfer, competitive forward transfer, and substantially reduced prompt memory usage."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem is interesting, there are a lot of literature for the CL in the visual domain but limited work in the NLP domain, this work maybe beneficial for the NLP community.\n\n2. The proposed architecture seems novel, gradient norm based prompt pool selection looks interesting. The gradient-guided prompt selection and merging to prevent unbounded prompt growth, maintaining high performance with over 60% reduced memory compared to prior prompt-based continual learners.\n\n3. Paper does not require the task id during inference, it follow CIL setting\n\n4. GRID achieves superior accuracy with fewer parameters, no rehearsal data, and stable performance, offering a unified, scalable, and task-agnostic framework for real-world continual learning in NLP."}, "weaknesses": {"value": "1. In the vision domain, the CIL setting is very common for the prompt based continual learning, here author highlights its key challenge, why? On the high level once tokenization is done both the language and vision model are similar, then why same concept [a,b,c] can not be applied here?\n\n2. The task identification method in section 3.1 looks violates the CL setting, here paper use the pretrained (say Phi) model for the task id prediction, which is much powerful and mostly it know all the sequence of task earlier. \n\n3. The result are shown on the T5 architecture only and over a single dataset which is not sufficient to defend the proposed model. I think other recent model and diverse dataset are needed to validate the proposed approach robustness and performance.\n\n4. The model is not robust to the task order, which is a challenge to the proposed model.\n\n**References**\n\n[a] Coda-prompt: Continual decomposed attention-based prompting for rehearsal-free continual learning, CVPR-23\n[b] Dualprompt: Complementary prompting for rehearsal-free continual learning, ECCV-22\n[c] Convolutional Prompting meets Language Models for Continual Learning, CVPR-24"}, "questions": {"value": "The problem addressed in the paper is interesting; however, the evaluation is limited, making it difficult to comprehensively assess the model’s effectiveness. \n\nAdditionally, recent vision-based continual learning models employing prompt-based techniques implicitly select suitable prompts from a prompt pool without explicit task supervision. It remains unclear why achieving similar task-agnostic prompt selection poses a greater challenge in the NLP domain."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1Tt1qhrJDa", "forum": "p0hLWIPCri", "replyto": "p0hLWIPCri", "signatures": ["ICLR.cc/2026/Conference/Submission22185/Reviewer_t1ow"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22185/Reviewer_t1ow"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762047424350, "cdate": 1762047424350, "tmdate": 1762942106443, "mdate": 1762942106443, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}