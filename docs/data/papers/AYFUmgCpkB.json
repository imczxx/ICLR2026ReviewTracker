{"id": "AYFUmgCpkB", "number": 10635, "cdate": 1758178188997, "mdate": 1759897638990, "content": {"title": "Zero-Sacrifice Lifelong Adversarial Defense for Pre-Trained Encoders", "abstract": "The widespread use of publicly available pre-trained encoders from self-supervised learning (SSL) has exposed a critical vulnerability: their susceptibility to downstream-agnostic adversarial examples (DAEs), which are crafted without knowledge of the downstream tasks but capable of misleading downstream models. While several defense methods have been explored recently, they rely primarily on task-specific adversarial fine-tuning, which inevitably limits generalibility and causes catastrophic forgetting and deteriorates benign performance.\nDiffer with previous works, we propose a more rigorous defense goal that requires only a single tuning for diverse downstream tasks to defend against DAEs and preserve benign performance.\nTo achieve this defense goal, we introduce **Ze**ro-Sacrifice **L**ifelong **A**dversarial **D**efense (**ZeLAD**), which is inspired by the inherent sensitivity of neural networks to data characteristics. Specifically, ZeLAD is a dual-branch structure, which consists of a Multi-Pattern Adversarial Enhancement Branch (MPAE-Branch) uses two adversarially fine-tuned encoders to strengthen adversarial resistance. The Benign Memory Preservation Branch (BMP-Branch) is trained on local data to ensure adversarial robustness does not compromise benign performance. Surprisingly, we find that ZeLAD can directly detect DAEs by evaluating branch confidence, without introducing any adversarial sample identification task during training. Notably, by enriching feature diversity, our method enables a single adversarial fine-tuning to defend against DAEs across downstream tasks, thereby achieving lifelong robustness. Extensive experiments on 11 SSL methods and 6 datasets validate its effectiveness. In certain cases, it achieves a 29.20\\% improvement in benign performance and a 73.86\\% gain in adversarial robustness, highlighting its zero-sacrifice property.", "tldr": "", "keywords": ["adversarial robustness", "self-supervised learning", "pretrained models", "security vulnerability"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dbebe07a51d775db47fd39f7c9d800cc3d9c7aba.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes ZeLAD, a “Zero-Sacrifice Lifelong Adversarial Defense” framework that integrates multiple adversarial and benign branches to achieve both clean accuracy and robustness without further tuning. The method designs a Robust Federal Decision Mechanism (RFDM) to adaptively weight branch predictions based on confidence, aiming to provide a single-tuning defense applicable across tasks. Experiments are conducted on multiple datasets and architectures."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The experiments are relatively comprehensive, covering several datasets, model scales, and attack types.\n2. The paper is logically organized, and most sections follow a clear structure.\n3. The proposed method is systematic and addresses the problem of balancing robustness and generalization in a targeted manner."}, "weaknesses": {"value": "1. Core claim overstatement: The claim of “lifelong + zero-sacrifice with single tuning” is not well supported. Although the paper emphasizes a one-time tuning process, in practice each new downstream task still requires training local classifiers and possibly branch adaptation. The experiments only test cross-dataset transfer, not true lifelong learning without any retraining, making the central claim over-stated.\n2. Over-packaged novelty: The technical novelty is limited. ZeLAD essentially combines multiple encoder branches with a handcrafted confidence-weighted ensemble (RFDM). The exponential weighting is heuristic, and there is no comparison with simpler ensemble or calibration baselines. The contribution is more about system integration than a fundamentally new defense principle.\n3. Experimental and analysis issues:\n    - It is suggested to include a comparison with a three-encoder average ensemble or PGD-AT baseline to validate RFDM’s effectiveness.\n    - Hyperparameter choices (e.g., weighting coefficients, confidence scaling) and sensitivity analysis are not explained.\n4. Writing and presentation problems:\n    - Figure 2 should be moved to Section 3.2.2.\n    - Eqs. (5) and (6) are unclear in mathematical form and explanation.\n    - Unify terminology: use adversarial example consistently.\n    - The introduction mentions RFDM, but later sections use inconsistent terms.\n    - The PGD-AT citation is incorrect; it should be *“Towards Deep Learning Models Resistant to Adversarial Attacks”*, ICLR 2018, not the CW attack paper.\n5. Mathematical writing issues:\n    - Use calligraphic letters (e.g., $\\mathcal{D}$) for datasets, not $D$; and use $D$ for distance.\n    - Keep notations of encoder and classifier consistent ($E,F$ in Section 3.1 while $\\mathcal{E},\\mathcal{F}$ in Section 3.2).\n    - Avoid blank lines after \\begin{equation}.\n    - Rewrite Eqs. (5) and (6) with explicit meaning of each symbol.\n    - Annotate dimensionality for key notations if possible.\n    - For clarity, it is suggested to include corresponding notation for each component in Figure 1.\n6. Typos and minor language errors:\n    - “generalibility” → “generalizability” (p.1 l.16)\n    - “differ with” → “different from” (p.1 l.18)\n    - “... uses two” → “that uses two” (p.1 l.23)\n    - “task-specfic” → “task-specific” (p.2 l.75)\n    - “taht” → “that”; “branche” → “branches” (p.9 l.446)\n    - Algorithm 1 needs a thorough proofreading.\n7. Related work limitations: The related work section is short and somewhat outdated. Please include more recent adversarial defense papers, such as:\n    - *Probabilistic Margins for Instance Reweighting in Adversarial Training*, NeurIPS 2021.\n    - *DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain*, NeurIPS 2024"}, "questions": {"value": "See Weaknesses. If the authors address my concerns, I am willing to raise the score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "u8KakOVEnA", "forum": "AYFUmgCpkB", "replyto": "AYFUmgCpkB", "signatures": ["ICLR.cc/2026/Conference/Submission10635/Reviewer_pqbZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10635/Reviewer_pqbZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10635/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654073848, "cdate": 1761654073848, "tmdate": 1762921890923, "mdate": 1762921890923, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the vulnerability of self-supervised learning (SSL) models to downstream-agnostic adversarial examples (DAEs). The authors propose Zero-Sacrifice Lifelong Adversarial Defense (ZeLAD), a dual-branch framework designed to achieve adversarial robustness without sacrificing benign performance. ZeLAD integrates a Multi-Pattern Adversarial Enhancement branch and a Benign Memory Preservation branch to balance robustness and benign performance. It detects DAEs by evaluating branch confidence, eliminating the need for adversarial sample training. Extensive experiments on 11 SSL methods and 6 datasets show substantial improvements in both benign accuracy and adversarial resistance, validating its “zero-sacrifice” property."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces ZeLAD, the first lifelong adversarial defense for pre-trained encoders that achieves robustness across multiple downstream tasks with a single tuning. Unlike prior task-specific adversarial training methods, ZeLAD generalizes effectively across SSL models and datasets, marking a substantial conceptual advancement in adversarial robustness research.\n2. A major strength is ZeLAD’s dual-branch architecture: the Multi-Pattern Adversarial Enhancement (MPAE) branch for robustness and the Benign Memory Preservation (BMP) branch for maintaining clean-sample accuracy. This design enables the model to enhance adversarial defense without degrading benign performance, a key limitation of previous methods."}, "weaknesses": {"value": "1. Although the paper compares ZeLAD to several classic defenses (e.g., TRADES, MART, Gen-AF), it does not include enough comparisons with the most recent or SSL-specific adversarial defense methods (only Table 7). This omission makes it harder to gauge ZeLAD’s relative progress within the latest research landscape.\n2. The proposed approach requires multiple encoders and dual-branch inference, which could increase computational and memory overhead compared to single-encoder defenses. The paper provides limited discussion or quantitative evaluation of training/inference efficiency. I think it is very important for real world deployment. \n3. Although the paper claims “lifelong” robustness, the experiments only cover a limited number of sequential tasks. There is no long-term continual learning evaluation (e.g., over dozens of tasks or domain shifts), so the claim of lifelong adaptation remains somewhat speculative."}, "questions": {"value": "1. The paper introduces a weighting parameter $\\lambda$ in the loss function (Eq. 3), but its value or tuning procedure is not specified. \n2. Some hyperparameters (e.g., lambda, learning rate) are not explicitly stated.\n   Will the authors release code or configuration files to ensure experimental reproducibility?\n3. The paper uses a dual-branch architecture with independent encoders. Have the authors considered some techniques to reduce redundancy while preserving robustness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Hsby1qP35S", "forum": "AYFUmgCpkB", "replyto": "AYFUmgCpkB", "signatures": ["ICLR.cc/2026/Conference/Submission10635/Reviewer_gcvV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10635/Reviewer_gcvV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10635/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722652020, "cdate": 1761722652020, "tmdate": 1762921890436, "mdate": 1762921890436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ZeLAD, a lifelong defense framework that protects self-supervised encoders from downstream-agnostic adversarial examples (DAEs) with a single tuning. ZeLAD employs dual branches to enhance adversarial robustness while preserving benign performance, and can even detect DAEs via branch confidence without explicit training."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1、The paper proposes a zero-sacrifice, lifelong adversarial defense method that not only maintainsbut also improves benign performance, while enhancing adversarial robustness.\n\n2、Extensive experimental results demonstrate the effectiveness of the proposed method.\n\n3、The paper is easy to follow."}, "weaknesses": {"value": "1、The paper claims to build on the inherent sensitivity of neural networks to data characteristics, yet this idea is only briefly mentioned in the introduction (L54–57) without deeper investigation. No experimental validation, theoretical analysis, or concrete insight is provided to support this claim, which substantially undermines the rationale and validity of the proposed method. A more thorough analysis through exploratory experiments or theoretical justification is necessary.\n\n2、The first and second claimed contributions both emphasize lifelong adversarial defense, which appear conceptually identical. I suggest merging them for conciseness and clarity.\n\n3、The paper inconsistently uses adversarial sample and adversarial example. The terminology should be unified using the widely accepted adversarial example to maintain professional consistency.\n\n4、The Related Work section remains too high-level and lacks discussion of key concepts (e.g., “Pre-trained encoders”， “pre-trained paradigm”) as well as core algorithmic ideas of representative methods—such as self-supervised learning approaches (SimCLR, MoCo) and DAEs on pre-trained encoders (PAP, AdvEncoder).\n\n5、The Threat Model is essential for any security-related study and should appear in the main text rather than the appendix. Similarly, the discussion of challenges addressed by the proposed method would be better placed before the methodology section for improved logical flow.\n\n6、The reported RA results (Tables 2 and 4) show large discrepancies compared to baseline values, raising concerns about correct reproduction of baseline methods. The causes of these gaps should be clarified.\n\n7、The proposed method demonstrates higher time and storage costs than the baselines (Table S3, L899–916).\n\n8、The overall writing quality requires improvement, particularly in table captions, many of which contain grammatical errors. For instance, “Table 1: BA(%) Baseline vs. ZeLAD in the semi-black-box scenario” is ungrammatical and should be revised for correctness and clarity."}, "questions": {"value": "Given that the proposed method is claimed to build on a general property of deep neural networks — “neural networks inherently exhibit higher confidence in inputs that resemble the training data, a behavior attributed to the memorization of the data’s characteristics” — two questions arise.\n\n1. Whether the method can be applied to multimodal pre-trained models such as CLIP or BLIP remains unclear. Experiments are needed to verify its scalability.\n\n2. It is also unclear whether the method can generalize beyond image classification, for example to image retrieval, semantic segmentation, or object detection."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "QRjR1jdcgf", "forum": "AYFUmgCpkB", "replyto": "AYFUmgCpkB", "signatures": ["ICLR.cc/2026/Conference/Submission10635/Reviewer_2cmk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10635/Reviewer_2cmk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10635/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880902947, "cdate": 1761880902947, "tmdate": 1762921890098, "mdate": 1762921890098, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **ZeLAD (Zero-Sacrifice Lifelong Adversarial Defense)**, a framework aimed at defending pre-trained self-supervised encoders against **Downstream-Agnostic Adversarial Examples (DAEs)**. Unlike prior task-specific fine-tuning approaches, ZeLAD claims to provide a single, lifelong adversarial defense applicable across diverse downstream tasks while maintaining or improving benign accuracy.\n\nZeLAD employs a dual-branch architecture:\n- MPAE-Branch (Multi-Pattern Adversarial Enhancement Branch): Combines multiple adversarially fine-tuned pre-trained encoders trained with diverse SSL methods to enhance robustness through representational diversity.\n- BMP-Branch (Benign Memory Preservation Branch): Trained solely on clean data to preserve benign performance.\n\nDuring inference, a Robust Federal Decision Mechanism (RFDM) fuses branch outputs by comparing confidence scores. The model also demonstrates the ability to detect adversarial samples based purely on branch confidence disparities, without explicit adversarial detection training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novelty and Conceptual Contribution:**\n- The paper introduces the idea of “zero-sacrifice lifelong adversarial defense”, reframing adversarial robustness as a feature combination problem rather than a tradeoff problem.\n- The dual-branch design (MPAE + BMP) and the federated confidence fusion mechanism are novel and well-motivated.\n2. **Comprehensive Empirical Evaluation:**\n- Extensive experiments across multiple SSL encoders (e.g., SimCLR, BYOL, MoCo, DINO) and datasets (CIFAR10, ImageNet, STL10, etc.) demonstrate the generality of the method.\n- Results consistently show significant improvements over baselines and other defenses (e.g., TRADES, MART, Gen-AF).\n3. **Strong Practical Relevance:**\n- Addresses a genuine and underexplored problem: the vulnerability of pre-trained encoders to DAEs in a downstream-agnostic setting.\n- The claim of “single tuning for all downstream tasks” has significant implications for scalable and resource-efficient deployment.\n4. **Adversarial Detection Without Supervision:**\n- The method’s ability to detect adversarial samples using confidence asymmetry without explicit training is an elegant byproduct.\n5. **Clarity and Organization:**\n- The paper is generally well-written and logically structured, with helpful figures (e.g., the overall ZeLAD architecture diagram and confidence distributions)."}, "weaknesses": {"value": "1. **Methodological Clarity and Rigor:**\n- While conceptually interesting, some mathematical formulations (e.g., hybrid loss and cosine distance adjustment) lack detailed derivations and theoretical justification.\n- The Robust Federal Decision Mechanism (RFDM) is empirically defined, but its weighting function (Eq. 8) seems heuristic and not theoretically grounded.\n- There is no formal analysis of why confidence alignment is a robust signal or how it generalizes across tasks.\n\n2. **Evaluation Limitations:**\n- Most experiments focus on classification tasks; it’s unclear whether ZeLAD extends to non-classification downstream tasks (e.g., segmentation, detection).\n- The adversarial attack diversity could be further improved—results rely heavily on AdvEncoder; other recent black-box attacks are not deeply explored.\n\n3. **Scope of “Lifelong” Claim:**\n- The “lifelong” aspect mainly refers to single fine-tuning across multiple tasks rather than continuous adaptation. There is no evidence of incremental task adaptation or continual learning capability, making the “lifelong” terminology somewhat overstated.\n\n4. **Computational Cost and Practicality:**\n- Maintaining multiple encoders (two adversarially fine-tuned and one benign) increases inference-time complexity and memory usage, which could hinder scalability."}, "questions": {"value": "**1. Clarification on the “Lifelong” Claim**\nYou define ZeLAD as a *“lifelong adversarial defense”* requiring only a single tuning. However, lifelong learning typically implies *continuous adaptation to new tasks* without full retraining.  \n**Could you clarify how ZeLAD satisfies the lifelong learning property beyond single multi-task applicability?**  \nHave you tested whether ZeLAD can handle incremental task addition or domain shifts without catastrophic forgetting?\n\n **2. Justification for the “Zero-Sacrifice” Property**\nThe paper claims that ZeLAD achieves robustness improvements *without sacrificing benign accuracy*.  \n**What theoretical or empirical evidence supports this “zero-sacrifice” claim?**  \nDoes this property hold under stronger perturbation budgets or adaptive attacks that target both branches simultaneously?\n\n **3. Robustness of the Confidence-Based Fusion (RFDM)**\nThe Robust Federal Decision Mechanism (RFDM) fuses branch outputs using confidence-based weighting.  \n**How reliable is this mechanism under confidence miscalibration, label noise, or adaptive attacks explicitly designed to manipulate confidence distributions?**  \nHave you compared this heuristic to alternative fusion schemes (e.g., entropy weighting, temperature scaling)?\n\n **4. Computational and Practical Efficiency**\nZeLAD employs multiple encoders (two adversarially fine-tuned and one benign), which could increase inference cost.  \n**What is the computational and memory overhead of ZeLAD compared to single-encoder fine-tuning methods?**  \nCan you comment on its scalability to larger SSL encoders (e.g., ViT-L/16, CLIP) in real-world applications?\n\n~PS: Any chance you want to name the paper ZeLDA: Zero sacrifice Lifelong Defence against Adversaries?~"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CfWkDLEdSJ", "forum": "AYFUmgCpkB", "replyto": "AYFUmgCpkB", "signatures": ["ICLR.cc/2026/Conference/Submission10635/Reviewer_vmRw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10635/Reviewer_vmRw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10635/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928324951, "cdate": 1761928324951, "tmdate": 1762921889572, "mdate": 1762921889572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}