{"id": "KBNvtUfjZL", "number": 18185, "cdate": 1758284816027, "mdate": 1763649529670, "content": {"title": "EfficientRefiner: An Efficient Refinement Method over Black-Box Optimization in Macro Placement", "abstract": "A refinement stage on macro placements generated by state-of-the-art methods can further improve the layout quality, as this stage compensates for the sub-optimality arising from lack of full-layout awareness in RL-based methods, as well as the quality degradation resulting from the overlap-resolving legalization step in analytical approaches. \nHowever, existing RL-based refinement techniques often incur high computational cost. To reduce the computation overhead introduced by the additional refinement stage, this paper proposes EfficientRefiner, which leverages the efficiency of analytical framework to refine macro layout from existing placement approaches.\nEfficientRefiner encodes macro positions as learnable vectors and optimizes an objective function that integrates both target metrics and placement constraints via gradient descent.\nIt introduces a novel fine-grained pairwise overlap formulation tailored for macro refinement, which overcomes the limitations of prior density-based objectives in analytical methods by effectively minimizing overlaps without inducing excessive spreading that could degrade layout quality. Moreover, EfficientRefiner enhances efficiency and scalability through pruning algorithms and GPU acceleration.\nExperimental results show that, when considering both HPWL and regularity metrics for optimization, it improves average HPWL by **7.20%–34.71%** within 10 minutes on the ISPD2005 benchmark, and achieves **20% WNS and 29% TNS** gains on PPA-supported ChiPBench circuits.", "tldr": "", "keywords": ["Chip Placement", "Refinement", "Gradient Descent"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3d768b4dbac9566e0a8ed75e475cf3351551e052.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces EfficientRefiner, an analytical refinement method designed to enhance macro placements generated by existing Black-Box Optimization (BBO) approaches. A key contribution is a novel fine-grained, module-pair-based overlap formulation that effectively minimizes macro overlaps without causing excessive spreading, which is a limitation of traditional coarse-grained density-based methods in analytical placers. The method is computationally efficient, leveraging GPU acceleration and a pruning strategy to scale to large designs. Experimental results on benchmarks like ISPD2005, ICCAD2015 and ChiPBench demonstrate improvements in Half-Perimeter Wirelength (HPWL) and Power, Performance, and Area (PPA) metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper is well-structured and clearly written. The proposed EfficientRefiner method demonstrates consistent improvements across multiple benchmarks. \n2.\tThe analytical formulation for macro overlapping, which operates on a fine-grained, module-pair basis, presents a technically sound approach."}, "weaknesses": {"value": "1.\tWhile the idea of using an analytical method specifically for macro refinement is novel, its advantages over established 2-stage mixed-size placers could be more thoroughly justified. The latter inherently considers macro placement with awareness of standard cells, a paradigm well-regarded in the physical design community. The proposed macro-centric refinement, focusing primarily on macro HPWL, might be more susceptible to local optima and yield marginal gains in a full-chip context. The reported significant improvements in mixed-size HPWL are indeed notable but require further explanation to align with the macro-only optimization focus.\n\n2.\tAs illustrated in Figures 5-7, the regularity metric does not exhibit consistent convergence; for instance, it increases on the superblue1 circuit. This appears counter-intuitive when contrasted with the significant improvement in timing metrics (WNS, TNS) for the same circuit reported in Table 3. The authors should provide an analysis of these observations.\n\n3.\tIn Table 2, only DREAMPlace is compared on ChiPBench / OpenROAD cases. \n\n4.\tThere is a potential inconsistency in terminology. The paper positions EfficientRefiner as a refiner for \"any Black-Box Optimization (BBO) method,\" yet a primary baseline used for initialization is DREAMPlace, an analytical placer. Analytical methods like DREAMPlace are typically considered \"white-box\" due to their explicit, differentiable objective functions."}, "questions": {"value": "1.\tTo facilitate a comprehensive evaluation and better understand the trade-offs involved, could you provide the results of regularity, macro HPWL, mixed-size HPWL, and PPA metrics in one table? \n2.\tIf permitted by the conference proceedings, including visualizations of the placement results before and after refinement (e.g., for a representative circuit like superblue1) would greatly enhance the intuitive understanding of the improvements achieved by EfficientRefiner."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "isMx6uevLm", "forum": "KBNvtUfjZL", "replyto": "KBNvtUfjZL", "signatures": ["ICLR.cc/2026/Conference/Submission18185/Reviewer_dKCW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18185/Reviewer_dKCW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761395450321, "cdate": 1761395450321, "tmdate": 1762927937044, "mdate": 1762927937044, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel refinement method for the layout outputs of macro placement, an essential procedure of the chip placement. Compared to traditional analytical methods (quantifying the density but cannot prevent macro overlapping) and RL-based methods (using position mask to indicate the overlap location), this paper proposes to directly minimize the overlap areas. Furthermore, it proposes an acceleration mechanism for calculation. Experimental metrics (HPWL, PPA metrics) clearly show the efficiency of EfficientRefiner."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of directly optimizing the overlap areas is novel and interesting. The areas objective can be viewed as a relaxation of the overlap, and experiments in Appendix A.4.6 show that EfficientRefiner can also prevent macro overlap as the refinement process progresses.\n- The efficient calculation and optimization of the proposed objective is reasonable, and the experiments show the efficiency in both refinement performance and operation time.\n- The experimental evaluation seems solid, showing improvements in both wirelength and PPA metrics."}, "weaknesses": {"value": "- I don’t understand why the manuscript claims that EfficientRefiner is a refinement method over black-box optimization methods. It can also be applied to the final layouts of other methods like RL-based methods (MaskPlace and Chipformer in your experiments) or analytical methods (DreamPlace in your experiments), isn’t that?\n- Typos:\n    - line 016: “degradation resulted from” → “degradation resulting from”;\n    - line 049: “overlaps which has to be” → “overlaps which have to be”;\n    - line 113: “ChipFormer, improve” → “ChipFormer improves”;\n    - line 115: “the most effective RL method require” → “the most effective RL method requires”;\n    - line 121: “through numerous adjustment” → “through numerous adjustments”;\n    - line 123: “LaMPlace … but guide” → “LaMPlace … but guides”;\n    - line 136: “learns a adjustment policy” → “learns an adjustment policy”;\n    - line 153: “The optimization objective include” → “The optimization objectives include”;\n    - line 156: “smaller HPWL may indicates” → “smaller HPWL may indicate”;\n    - line 170: “EfficientRefiner first represent” → “EfficientRefiner first represents”;\n    - line 175: “optimizes a joint objective function consist of” → “optimizes a joint objective function consisting of”;\n    - The term *DreamPlace* is not unified over the manuscript, while in Section 2.2, it is *Dreamplace*.\n    - line 196: “it refine the” → “it refines the”;\n    - line 208: “along with prunning” → “along with pruning”;\n    - line 400: “efore and after” → “before and after”;\n    - line 452: “Effectiveness of the Fine-grained Overlap Modeling” → “Effectiveness of the Fine-grained Overlap Modeling.”;\n    - line 463: “Parameter Analysis” → “Parameter Analysis.”;\n    - line 477: “it accelerate” → “it accelerates”;\n    - line 729: “Return: $ \\hat{Overlap} _ {xij} $, $\\hat{Overlap} _ {xij}$” → “Return: $\\hat{Overlap} _ {xij}$, $\\hat{Overlap} _ {yij}$”;\n    - line 755: “Return: $\\delta\\hat{Overlap} _ {xij}$, $\\delta\\hat{Overlap} _ {xij}$” → “Return: $\\delta\\hat{Overlap} _ {xij}$, $\\delta\\hat{Overlap} _ {yij}$”;\n    - line 817: “8192 models” → “8192 modules” ;\n    - line 885: “not accessible fot us” → “not accessible for us”;\n    - line 892: “the results shows” → “the results show”."}, "questions": {"value": "- In Eq. (6), the condition should be $|x_i-x_j|<\\frac{w_i}{2} + \\frac{w_j}{2}$, instead of $|x_i-x_j|<\\frac{w_j}{2} + \\frac{w_j}{2}$?\n- In line 1052, you mentioned that “Fig.8-11 show the overlap growth before and after legalization”. It should be HPWL growth?\n- Based on my understanding, from the illustration in the manuscript, the reference of LaMPlace seems wrong. Do you aim to cite [1] instead?\n\n## References\n\n[1] LaMPlace: Learning to Optimize Cross-Stage Metrics in Macro Placement. ICLR 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qP4d7FMbbN", "forum": "KBNvtUfjZL", "replyto": "KBNvtUfjZL", "signatures": ["ICLR.cc/2026/Conference/Submission18185/Reviewer_TgZh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18185/Reviewer_TgZh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839759833, "cdate": 1761839759833, "tmdate": 1762927936292, "mdate": 1762927936292, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EfficientRefiner, a gradient-based refinement method that improves macro placements produced by any black-box optimizer. It introduces a pairwise overlap function that exactly measures macro-to-macro overlaps and yields non-zero gradients. Also a boundary-oblivious encoding that maps legal positions to unconstrained learnable vectors. So optimization is box-free until a final legalization step. EfficientRefiner drops HPWL by 7%-35%, boosts WNS by 20% and TNS by 29%. While running <=10 mins outperforming recent RL refiners without any training tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- EfficientRefiner replaces coarse grid-density penalties with an exact macro-pair overlap function whose gradients stay non-zero until every overlap vanishes, so legalization needs <1 % HPWL movement instead of 8–60 %.\n- GPU-parallel overlap evaluation plus bin-pruning cuts runtime 1000× versus naive loops, refining 8 k macros in ~130 s—no training, no placer-specific tuning.\n- It plugs as a black-box post-process to any placer, delivering 7–35 % HPWL savings and 20 % WNS / 29 % TNS gains on standard benchmarks with stable, dataset-independent hyper-parameters."}, "weaknesses": {"value": "EfficientRefiner currently focuses only on macro placement and treats standard cells as fixed, so it cannot simultaneously optimize mixed-size layouts and may miss macro-cell coupling opportunities. Its pairwise overlap model, although pruned, still scales quadratically with macro count, risking memory and compute growth for future designs with tens of thousands of macros. Finally, the method relies on simplified HPWL and regularity proxies rather than true routed timing or congestion metrics, which could limit the correlation with final PPA on advanced nodes."}, "questions": {"value": "- How does the pairwise overlap formulation handle macros of vastly different sizes (e.g., a large memory block next to a small IP) without introducing imbalance in gradient magnitudes?\n- The boundary-oblivious representation maps legal positions to unbounded learnable vectors. How sensitive is the optimization trajectory to the initial values of these vectors, and could a poor initialization trap the solver in a high-overlap region?\n- The overlap weight α is set to 10^5 for all experiments. Is there a systematic way to choose α based on design characteristics (utilization, macro count, aspect ratio) rather than relying on a single fixed value?\n- While pruning reduces quadratic growth, the worst-case memory still scales as O(n²). What is the largest macro count the authors have tested, and what are the projected bottlenecks for 100 k-macros designs?\n- All reported PPA numbers are either pre-route estimates (OpenTimer) or surrogate metrics (HPWL, regularity). Has the team run any confidential full-flow experiments to verify that the 20 % WNS and 29 % TNS gains survive detailed routing and clock-tree synthesis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jp8Luhm1RM", "forum": "KBNvtUfjZL", "replyto": "KBNvtUfjZL", "signatures": ["ICLR.cc/2026/Conference/Submission18185/Reviewer_4rZs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18185/Reviewer_4rZs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924301770, "cdate": 1761924301770, "tmdate": 1762927935870, "mdate": 1762927935870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the macro placement refinement stage in EDA, addressing two key issues in state-of-the-art methods: RL-based approaches lack full-layout awareness, leading to suboptimal results, while analytical methods suffer quality degradation from overlap-resolving legalization. The goal is to reduce computational overhead in the refinement stage while improving layout quality, compensating for the limitations of existing BBO placement methods. The proposed EfficientRefiner uses an analytical framework that encodes macro positions as unbounded learnable vectors, optimizes an objective integrating target metrics (HPWL, regularity) and a novel fine-grained module-pair-based overlap function, and enhances efficiency through pruning algorithms and GPU acceleration. Experiments on ISPD2005, ICCAD2015, and ChipBench benchmarks show that EfficientRefiner significantly improves PPA metrics."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1. Comprehensive background and related work.\n2. Novel fine-grained overlap formulation solves critical limitations of existing methods.\n3. High efficiency and scalability via GPU acceleration.\n4. EfficientRefiner seamlessly integrates with RL-based (MaskPlace, Chipformer), BBO (WireMask-EA), and analytical (DreamPlace, NTUPlace3) placement methods, demonstrating consistent improvements across most baselines."}, "weaknesses": {"value": "1. I recommend providing detailed analysis of key parameter sensitivity, such as how to adapt $\\alpha$ for different cases with various scales, as well as the influence of bin size.\n2. The presentation should be improved. For example, please consider moving some information in Figure 1 to the wrapped figure embedded in the main context for easier understanding.\n3. (Minor) I appreciate the efficiency of the proposed method and believe it is a remarkable advantage. The corresponding analysis should be included in the main text.\n4. (Minor) Use \\mathrm{} for the text in equations, such as Overlap and HPWL."}, "questions": {"value": "The paper acknowledges that ICCAD2015 PPA results are pre-routing estimates using OpenTimer (not including routing effects), and commercial tools are unavailable for accurate evaluation. Could you analyze the correlation between pre- and post-routing results? For example, analyze the cases from ChipBench."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ctArTIijkn", "forum": "KBNvtUfjZL", "replyto": "KBNvtUfjZL", "signatures": ["ICLR.cc/2026/Conference/Submission18185/Reviewer_pvFu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18185/Reviewer_pvFu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762164701683, "cdate": 1762164701683, "tmdate": 1762927935562, "mdate": 1762927935562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}