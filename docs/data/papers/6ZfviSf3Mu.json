{"id": "6ZfviSf3Mu", "number": 2779, "cdate": 1757247778622, "mdate": 1759898127705, "content": {"title": "Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration", "abstract": "Large Language Models (LLMs) often expend significant computational resources generating boilerplate responses, such as refusals, simple acknowledgements and casual greetings, which adds unnecessary cost and latency. To address this inefficiency, we propose a simple yet highly effective method for detecting such responses after only a single generation step. We demonstrate that the log-probability distribution of the first generated token serves as a powerful signal for classifying the nature of the entire subsequent response. Our experiments, conducted across a diverse range of small, large, and reasoning-specialized models, show that the first-token log-probability vectors form distinctly separable clusters for different response types. Using a lightweight k-NN classifier, we achieve high accuracy in predicting whether a response will be a substantive answer or a form of boilerplate response, including user-specified refusals. The primary implication is a practical, computationally trivial technique, optimizing LLM inference by enabling early termination or redirection to a smaller model, thereby yielding significant savings in computational cost. This work presents a direct path toward more efficient and sustainable LLM deployment.", "tldr": "We present a method to predict an LLM's entire response type by analyzing the log-probability distribution of only the first generated token, thus significantly reducing computational cost and latency in LLM inference.", "keywords": ["LLMs", "optimization", "sustainability", "boilerplate responses", "costs reduction"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e35f22eeee10c21e73be5977baa585e3cde53132.pdf", "supplementary_material": "/attachment/41af822bc718bbd51f71cbe6bfc4e4abc0362239.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a simple approach to predict the response type of a large language model (LLM) using the log-probability of the first generated token. The goal is to prevent LLMs from producing boilerplate or low-information responses, thereby saving computational resources."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The problem of avoiding boilerplate responses is a valid and practically relevant one, as it relates to the efficiency and quality of LLM outputs.\n2. The authors release a dataset, which may be useful for further exploration of response-type prediction tasks."}, "weaknesses": {"value": "1. **Presentation quality:** The paper’s presentation requires substantial improvement. There are noticeable formatting issues (e.g., excessive white space in Figures 2–4), and the absence of a main figure illustrating the overall method makes it difficult for readers to grasp the approach at a glance. Improving the paper’s structure and visual clarity would make it more accessible.\n2. **Experimental design and analysis:** The experiments are insufficiently detailed and lack comprehensive analysis. The evaluation setup is minimal, with limited discussion of baselines, ablation studies, or error cases. As it stands, the submission reads more like a preliminary project report than a mature research contribution.\n3. **Limited novelty and depth:** The proposed method is conceptually simple and appears to be a straightforward heuristic. Without stronger theoretical grounding, comparative baselines, or empirical justification, the contribution seems too limited for acceptance at a top-tier venue like ICLR.\n\nOverall, the work feels incomplete and underdeveloped. The core idea is relevant but not explored in sufficient technical or empirical depth to warrant publication at this stage."}, "questions": {"value": "1. How does the proposed method compare with simple baselines such as classifying response types directly from the first few generated tokens, rather than relying solely on its log-probability?\n2. The dataset used contains prompts with widely varying characteristics and frequencies. Could the authors justify why this dataset serves as a valid benchmark, and how it reflects real-world distributions of LLM interactions?\n3. Have the authors considered extending the method to use information from the first few tokens instead of just the first one? This might provide a more stable and reliable signal for response-type prediction."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7Mkjsfzd6b", "forum": "6ZfviSf3Mu", "replyto": "6ZfviSf3Mu", "signatures": ["ICLR.cc/2026/Conference/Submission2779/Reviewer_5tsL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2779/Reviewer_5tsL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2779/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760793839342, "cdate": 1760793839342, "tmdate": 1762916374480, "mdate": 1762916374480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes using first-token log-probability distributions to classify LLM responses as either substantive (\"Chat\") or boilerplate (refusals, greetings, acknowledgements), with the goal of early termination or routing to smaller models to save costs."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Addresses a practical problem of reducing inference costs for predictable responses"}, "weaknesses": {"value": "* **Fundamentally unsound task definition**: The paper groups refusals, greetings, and acknowledgements together as \"boilerplate responses\" that can be handled uniformly. This is deeply problematic. Refusals are safety-critical responses that embody the model's alignment training, not \"boilerplate waste\" to be optimized away. Replacing careful safety mechanisms with a k-NN classifier trained on 3k synthetic examples is inappropriate and potentially dangerous. The proposed solution of routing refusals to smaller models requires futher justification - do you really want safety decisions made by weaker models with degraded alignment? The paper doesn't explain what you would do after detecting a refusal.\n* **Why use machine learning for trivial patterns?** For simple responses like \"Hello\", \"Hi\", or \"You're welcome\", why not just use string matching or simple heuristics? These patterns are deterministic and don't require log-probability analysis or k-NN classification. Using complex ML methods for trivial pattern matching is over-engineering.\n* **Severe data imbalance makes results unreliable** The dataset has only ~30 \"Hello\" examples and ~250 \"Thanks\" examples out of ~3k total samples. The \"Hello\" class represents only 1.4% of the dataset, yet the paper reports 100% F1 scores on it. These numbers are statistically meaningless with so few samples. The reported 99%+ accuracies may overlooked the minority label."}, "questions": {"value": "see weakness above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "R900588WR4", "forum": "6ZfviSf3Mu", "replyto": "6ZfviSf3Mu", "signatures": ["ICLR.cc/2026/Conference/Submission2779/Reviewer_CpyZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2779/Reviewer_CpyZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2779/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701863730, "cdate": 1761701863730, "tmdate": 1762916374136, "mdate": 1762916374136, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the computational inefficiency of LLMs generating boilerplate responses, such as refusals or greetings. The proposed method is simple and effective: classifying the entire response type by analyzing the log-probability distribution of only the first generated token using a k-NN classifier. Experiments across a few models, demonstrate that these first-token vectors form distinct clusters for categories like 'Chat', 'Refusal', 'Thanks', and 'Hello', achieving high classification accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The proposed method is extremely simple and computationally lightweight, as it only requires a single forward pass to get the first token's probabilities and a fast k-NN lookup.\n\nIt uses the entire log-probability vector with a k-NN classifier rather than a manually selected subset of tokens, and extends this classification from just \"Refusal\" to also include \"Thanks\" and \"Hello\""}, "weaknesses": {"value": "The primary weakness of this paper is its limited novelty and contribution. The core idea that the first token's probabilities can predict the subsequent response, especially for refusals, is not new. The authors themselves cite related work (Arditi et al., 2024) which already derived a \"refusal metric\" by summing probabilities of \"refusal tokens\" at the first token position.\n\nThe reliance on a k-NN classifier is sensitive to the training data. It's unclear how this approach would generalize to new, unseen types of boilerplate or how it would cope with model updates, which could shift the entire log-probability space and render the saved vectors obsolete."}, "questions": {"value": "N.A."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2ZjUnMFxM3", "forum": "6ZfviSf3Mu", "replyto": "6ZfviSf3Mu", "signatures": ["ICLR.cc/2026/Conference/Submission2779/Reviewer_5vu3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2779/Reviewer_5vu3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2779/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799072014, "cdate": 1761799072014, "tmdate": 1762916373730, "mdate": 1762916373730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the compute waste caused by LLMs producing boilerplate text. The key idea is strikingly simple: use only the log-probability vector of the very first generated token to predict the eventual response type, then early-stop or re-route generation to save cost and latency. The authors show that common response types (Refusal/Thanks/Hello/Chat) form separable clusters in the first-token log-prob space, and that a lightweight k-NN classifier suffices to achieve high accuracy across several model scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Direct Approach. Reading a single first-token log-probability vector and classifying with k-NN delivers useful discrimination among boilerplate types.\n- Clear Motivation. Framing the work around early stopping/routing aligns with real-world needs.\n- Experimental Transparency. The paper describes data construction, fixed k in k-NN, and cross-validation, which helps readers reproduce the general setup."}, "weaknesses": {"value": "- Adversarial Mixed Intents and False Positive. The dataset design around hello, refusal and thanks is reasonable, but it overlooks adversarial or mixed-intent prompts that can blur class boundaries. For example, a user input like “Hello, nice to meet you. How’s the weather today?” will likely elicit a first token such as “Hello,” followed only then by substantive content about weather. A first-token classifier is severely stressed in such cases, and the paper does not analyze this reliability gap. Similarly, larger models sometimes begin with a refusal and then pivot to supportive guidance (e.g., for self-harm queries). Such trajectories can produce ambiguous logprob signals that the method may misread.\n\n- Missing Comparisons. The Related Work section lists adjacent lines of research, but the paper offers no head-to-head comparisons.\n\n- Efficiency in Practice. Beyond inference, efficiency trade-offs are underexplored. Because tokenizers and vocabularies differ across model families, each model (or family) needs its own k-NN built on its own token space, which raises training and maintenance cost. Moreover, the targeted classes (refusals, greetings, thanks) are typically very short replies; in realistic deployments, the end-to-end cost of extracting first-token logprobs and running the k-NN router can approach the cost of just letting the model emit the short reply. Without concrete latency numbers, it’s unclear that the method consistently yields net wins."}, "questions": {"value": "Please refer to Weaknesses for points requiring further clarification."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zkUkNZ5JdZ", "forum": "6ZfviSf3Mu", "replyto": "6ZfviSf3Mu", "signatures": ["ICLR.cc/2026/Conference/Submission2779/Reviewer_fyke"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2779/Reviewer_fyke"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2779/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931207305, "cdate": 1761931207305, "tmdate": 1762916373487, "mdate": 1762916373487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}