{"id": "URMih4CWyR", "number": 12618, "cdate": 1758209031122, "mdate": 1763135071456, "content": {"title": "WGREC: Weakly Supervised Generalized Referring Expression Comprehension Empowered by Large Language Model", "abstract": "Weakly Supervised Referring Expression Comprehension (WREC) aims to locate the target object described by a given expression using weak supervision signals, such as image-text pairs. \n%\nExisting WREC methods typically assume that for every expression, there is always a corresponding object in the image or each frame of a video, ignoring scenarios where multiple objects or no objects match the expression. \n%\nAdditionally, current WREC methods primarily rely on contrastive learning, using numerous positive and negative pairs to construct the loss. This approach has drawbacks: it incurs high computational and memory costs, reduces training efficiency, and is highly sensitive to pair selection, which can lead to unstable convergence or overfitting to specific pairs.\n%\nIn this paper, we introduce a new task, Weakly Supervised Generalized Referring Expression Comprehension (WGREC), which extends traditional WREC to handle more realistic and complex scenarios. \n%\nTo address this task, we design a novel graph-based knowledge distillation network (GKDN) guided by a large language model (LLM). \nBy using the LLM, we obtain two types of information: (1) descriptions of object candidates and their relationships, and (2) pseudo-target positions for single or multiple objects mentioned in the expression. This information helps our network build attention graphs that model the link between objects and the expression while filtering out irrelevant candidates.\nFinally, a concise objective function is designed, leveraging predictions, expressions, and pseudo target positions, to distill the capabilities of the LLM into our network. Extensive experiments on gRefCOCO, RefCOCO, RefCOCO+, and RefCOCOg datasets demonstrate that our method achieves state-of-the-art (SoTA) performance, highlighting the effectiveness of our approach and its potential to advance the field of WGREC.", "tldr": "", "keywords": ["Weakly Supervised Referring Expression Comprehension", "Weakly Supervised Generalized Referring Expression Comprehension", "graph-based knowledge distillation network", "large language model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/7fb120089a3a46068f157e5aa9cb6f9ffa2561aa.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper frames weakly supervised generalized referring expression comprehension, where an expression may match zero, one, or many objects and proposes GKDN, a student model trained with an LLM teacher that, given detector proposals plus the image and expression, generates object/relationship descriptions and pseudo target boxes for distillation; at inference, only the compact student runs (no VLM/LLM), using a single-threshold scorer to decide cardinality. The student builds visual, categorical, and description graphs, fuses them with cross-modal attention, and learns via a concise objective combining matching, box regression, and negative-case penalties. Experiments on gRefCOCO and RefCOCO/+/g show competitive WGREC performance and an average +2.84% over APL on WREC, while ablations indicate that teacher quality materially affects the distilled student and that both categorical and description graphs add complementary gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Graph-centric reasoning that reflects language structure. Three graphs (visual/category/description) + one-step reasoning per Ke et al. are fused and iterated; ablations show each graph contributes (Table 4) and that reasoning/fusion helps (Table 5).\n\n2. Practical evaluation tweak. A single-threshold matcher replaces the two-stage existence-check in prior GREC work, simplifying training/eval without hurting MiniGPT-v2 performance. \n\n3. Solid performance from GKDN compared with previous methods. \n\n4. The paper is well-written and easy to follow"}, "weaknesses": {"value": "1. Teacher quality matters and might be more important that proposed  Graph-centric reasoning modules. Table 3 shows strong dependence on the chosen teacher (MiniGPT-v2 trained > untrained; Grounding DINO in between). Distillation quality bounds student performance.\n\n2. Compute/latency not reported. Graph construction + pairwise relations + reasoning can be costly; O(K²) edges suggest practical limits—no fps/memory table yet."}, "questions": {"value": "1. Could you report GKDN trained with two different teachers (MiniGPT-v2 vs. Grounding DINO) under identical proposal prompts to isolate teacher effects on WGREC? (Table 3 hints at this but mixes conditions.)\n\n2. What are K (proposals per image), edge counts, and end-to-end latency/memory for training and inference? A small table would help position GKDN vs APL/RefCLIP. \n\n3. You set T=3 based on Table 6; can you expose an early-exit rule when the top-K stabilizes to save compute at inference?\n\n4. Your matcher hinges on a single score threshold (0.7 in App. A.1); how sensitive are WGREC metrics to this choice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "U0ddxY5aKB", "forum": "URMih4CWyR", "replyto": "URMih4CWyR", "signatures": ["ICLR.cc/2026/Conference/Submission12618/Reviewer_11sh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12618/Reviewer_11sh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12618/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760894009043, "cdate": 1760894009043, "tmdate": 1762923466864, "mdate": 1762923466864, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "4ZA4muu1vH", "forum": "URMih4CWyR", "replyto": "URMih4CWyR", "signatures": ["ICLR.cc/2026/Conference/Submission12618/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12618/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763135070548, "cdate": 1763135070548, "tmdate": 1763135070548, "mdate": 1763135070548, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes the Weakly Supervised Generalized Referring Expression Comprehension (WGREC) task, which can cover multi-target and no-target matching scenarios, and explicitly returns \"no target\" when there is no match. Meanwhile, it designs a Graph-based Knowledge Distillation Network (GKDN), with a Large Language Model (LLM) serving as the teacher model to generate key information. GKDN distills the capabilities of the LLM into the network through its core modules."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method outperforms traditional approaches and establishes the first baseline. The pipeline of the proposed method is clear."}, "weaknesses": {"value": "1. This paper primarily combines several existing works and applies them to a new scenario. In addition, incorporating LLMs through knowledge distillation lacks significant novelty in terms of methodological design. \n\n2. The first and second contributions appear highly similar, and the third contribution is not clearly explained.\n\n3. The paper presents extensive implementation details, but lacks sufficient motivation and justification for the proposed design choices. It remains unclear why the method should work as intended.\n\n4. There is a typo in the task name: the description of Figure 3 refers to the \"GWREC task,\" while the core task proposed in the paper is \"WGREC (Weakly Supervised Generalized Referring Expression Comprehension).\"  \n\n5. The evaluation strategy adopts a single threshold—has the basis for selecting this threshold been fully demonstrated? (For instance, the reason for choosing 0.7 is not explained, and the impact of different thresholds on the results is not mentioned.)  \n\n6. Although the paper conducts ablation experiments, it only compares scenarios with and without the description reconstruction and graph fusion strategies. (It fails to further analyze the interaction and impact between the visual graph, categorical graph, and description graph.)  \n\n7. The paper only focuses on performance metrics (e.g., Pr@(F1=1, IoU≥0.5)) and does not compare the computational cost (e.g., training time) between GKDN and existing methods.  \n\n8. Although a baseline has been established for the WGREC task, its performance is inferior to that of MiniGPT-v2. The reasons for this performance gap have not been analyzed in depth—for example, whether the gap stems from issues with the model structure or pre-trained data."}, "questions": {"value": "Refer to the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k9pzcIgUMB", "forum": "URMih4CWyR", "replyto": "URMih4CWyR", "signatures": ["ICLR.cc/2026/Conference/Submission12618/Reviewer_Kho9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12618/Reviewer_Kho9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12618/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761638461102, "cdate": 1761638461102, "tmdate": 1762923466018, "mdate": 1762923466018, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This work introduce a new setting, Weakly Supervised Generalized Referring Expression Comprehension (WGREC), which extends traditional WREC to handle more realistic and complex scenarios. \n- To address this task, this work designs a graph-based knowledge distillation network (GKDN) guided by a large language model (LLM). This information by LLM helps the designed network build attention graphs that model the link between objects and the expression while filtering out irrelevant candidates and achived better performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- This work introduce a new setting, Weakly Supervised Generalized Referring Expression Comprehension (WGREC), which extends traditional WREC to handle more realistic and complex scenarios. \n\n- this work designs a graph-based knowledge distillation network (GKDN) guided by a large language model (LLM). This information by LLM helps the designed network build attention graphs that model the link between objects and the expression while filtering out irrelevant candidates and achived better performance."}, "weaknesses": {"value": "- The writing of this work is quite poor\n  - In Table-3, the author describes that GKDN w/ G represent GKDN using Grounding DINO as teacher model, but I don't find the GKDN w/ G. Is it GKDN w/ L?\n  - Line-218 describes that `the resulting region is then fed into the description construction module for description generation`. How do the generated descriptions used for network learning? This is quite confusing.\n  - What does MULTI-DYNARECON means ? The authors do not give a detailed introduction.\n\n\n- The technical conribution and insight is weak.\n  - The work `GRES`~[A] has proposed similar setting, which decreased the originality of this work.\n  - The core idea is to utilize the MLLM to generate more reliable supervision information for training the proposed graph network, which lacks technical innovation.\n  -  The author claims that the proposed evaluation strategy enables their method to better adapt to the diverse scenarios in GREC. It is very strange that the evaluation strategy is be specially designed for the current method. The authors even do not provide a explanation about the evaluation metric.\n  - The performance of network distilled from LLM is far behind the LLM and even some zero-shot methods (e.g., `GroundVLP` ~[B] and `LocalizationHeads` ~[C]). This makes it uncertain whether the work is actually feasible. Also, the authors do not provide any code for reproduce their work.\n\nOverall, I find this paper to be rather rough in both writing and content insight, falling below the bar for conference acceptance.\n\n[A] CVPR2023, GRES: Generalized Referring Expression Segmentation\n\n[B] AAAI2024, GroundVLP: Harnessing Zero-shot Visual Grounding from Vision-Language Pre-training and Open-Vocabulary Object Detection\n\n[C] CVPR2025, Your Large Vision-Language Model Only Needs A Few Attention Heads For Visual Grounding"}, "questions": {"value": "Refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BWwLhPVwJd", "forum": "URMih4CWyR", "replyto": "URMih4CWyR", "signatures": ["ICLR.cc/2026/Conference/Submission12618/Reviewer_AEhY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12618/Reviewer_AEhY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12618/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761767453353, "cdate": 1761767453353, "tmdate": 1762923464991, "mdate": 1762923464991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limitations of the traditional weakly supervised referential expression comprehension (WREC) task and proposes a new task: weakly supervised generalized referential expression comprehension (WGREC). The authors design a graph-based knowledge distillation network (GKDN), using a large language model (LLM) as the teacher model. The LLM generates descriptions and pseudo-target locations to assist in constructing an attention graph, thereby providing localization and comprehension capabilities. It outperforms the existing state-of-the-art techniques on the WREC task and shows potential in the WGREC task."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe traditional WREC task ignores the \"multi-target\" and \"no target\" scenarios, while the WGREC task is proposed for the first time in this paper. The core goal of WREC is to locate all the targets described by the expression and return null results when there is no match, which extends the application scope of the coreference understanding task and meets the requirements of real world applications.\n2.\tWREC task only relies on image-expression pairs without precise object location annotations. The existing VLM model has strong detection ability, and it is very reasonable and smooth to use the pseudo-target location and description generated by it as auxiliary information.\n3.\tGKDN outperforms most SOTA methods on the WREC task. Ablation experiments verify the effectiveness of each part, including key variables such as LLM selection, number of inference steps, and effectiveness of graph structure."}, "weaknesses": {"value": "1.\tThe description of the experimental scene is not clear, and the content of the diagram is not rigorous enough. Are the LLM models in Table 3 the experimental results under the WGREC task or WREC task? \"Using a larger model such as Grounding DINO may further improve GKDN s performance.\" mentioned in 4.2, but not found results using Grounding DINO. Should \"GKDNw/L\" in Table 3 be \"GKDNw/G\"?\n2.\tAlthough GKDN is the first baseline for WGREC, its weakly supervised version (GKDN w/ W) performs much worse than the teacher model MiniGPT-v2 on the gRefCOCO dataset, and the core reasons for the performance gap are not analyzed.\n3.\tThere is a lack of comparison of experimental results in WGREC task scenarios, such as with some existing large models Qwen-VL-2.5 or Qwen-VL-3. If there is a gap in accuracy, the advantages of existing methods in other aspects can be analyzed, such as the number of parameters, training time, inference speed, etc.\n4.\tThe authors point out the \"high computational cost\" of traditional contrastive learning, but do not quantify the efficiency advantage of GKDN."}, "questions": {"value": "1.\tIs GroundingDINO in Table 3 a trained or untrained model?\n2.\tWhy choose MiniGPT-v2 and GroundingDINO as teacher models? Is it possible to select some newer large models to provide more accurate pseudo-object location and description?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Lw0NE3HMcT", "forum": "URMih4CWyR", "replyto": "URMih4CWyR", "signatures": ["ICLR.cc/2026/Conference/Submission12618/Reviewer_dpBj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12618/Reviewer_dpBj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12618/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805429868, "cdate": 1761805429868, "tmdate": 1762923464207, "mdate": 1762923464207, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}