{"id": "BjElYlJKMj", "number": 11242, "cdate": 1758194179432, "mdate": 1759897599052, "content": {"title": "TRACE: Your Diffusion Model is Secretly an Instance Edge Detector", "abstract": "High-quality instance and panoptic segmentation has traditionally relied on dense instance-level annotations such as masks, boxes, or points, which are costly, inconsistent, and difficult to scale. Unsupervised and weakly-supervised approaches reduce this burden but remain constrained by semantic backbone constraints and human bias, often producing merged or fragmented outputs. We present TRACE (TRAnsforming diffusion Cues to instance Edges), showing that text-to-image diffusion models secretly function as instance edge annotators. TRACE identifies the Instance Emergence Point (IEP) where object boundaries first appear in self-attention maps, extracts boundaries through Attention Boundary Divergence (ABDiv), and distills them into a lightweight one-step edge decoder. This design removes the need for per-image diffusion inversion, achieving 81× faster inference while producing sharper and more connected boundaries. On the COCO benchmark, TRACE improves unsupervised instance segmentation by +5.1 AP, and in tag-supervised panoptic segmentation it outperforms point-supervised baselines by +1.7 PQ without using any instance-level labels. These results reveal that diffusion models encode hidden instance boundary priors, and that decoding these signals offers a practical and scalable alternative to costly manual annotation.", "tldr": "TRACE turns pretrained diffusion models into annotation-free instance edge generators for instance and panoptic segmentation.", "keywords": ["diffusion", "unsupervised instance segmentation", "weakly-supervised panoptic segmentation", "inference dynamics", "attention"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8b982fbb98082993c073464805a3d33f9f385d6b.pdf", "supplementary_material": "/attachment/09f92450f95761d469b05751d9629bb76da0053f.zip"}, "replies": [{"content": {"summary": {"value": "TRACE shows that text-to-image diffusion models already encode sharp instance boundaries in their self-attention maps at a special denoising step (the Instance Emergence Point, IEP). By harvesting these “secret” edges with a simple, KL-based Attention Boundary Divergence (ABDiv) and distilling them into a one-step edge decoder, TRACE delivers: +5.1 AP on unsupervised COCO instance segmentation, +1.7 PQ on tag-supervised panoptic segmentation (no boxes/masks), 81× faster than per-image diffusion inversion\nAll without a single manual instance label."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. First to treat diffusion self-attention as a free instance-edge oracle.\n2. Introduces IEP + ABDiv, two lightweight, non-parametric cues that any diffusion backbone yields.\n3. Exhaustive ablations (Tab. 3, 4, 5) and 5 backbones; KL beats MSE/MAE by > 5 AP.\n4. Clear pipeline figure (Fig. 4); every symbol defined; 81× speed-up quantified.\n5. Annotation-free edge seeds outperform point-supervised panoptic models (Tab. 2)."}, "weaknesses": {"value": "1. Only one 1-layer CNN decoder is tried; U-Net, light transformer, or multi-scale may sharper edges.\n2. Paper shows success cases (Fig. 2, 9); no figure of merged/fragmented predictions when IEP fails.\n3. TRACE claims “no prompt needed”, but null-text vs. descriptive prompt may shift t* or edge quality."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "IFlepXwcXi", "forum": "BjElYlJKMj", "replyto": "BjElYlJKMj", "signatures": ["ICLR.cc/2026/Conference/Submission11242/Reviewer_JkD6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11242/Reviewer_JkD6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11242/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620157225, "cdate": 1761620157225, "tmdate": 1762922402916, "mdate": 1762922402916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes **TRACE** (TRAnsforming diffusion Cues to instance Edges), a novel framework revealing that diffusion models inherently encode *instance-level boundary information* within their self-attention maps.  \nThe authors identify the Instance Emergence Point (IEP)—the timestep where object structures first appear—and introduce Attention Boundary Divergence (ABDiv) to extract instance edges without any annotation.  \nThrough one-step edge distillation, TRACE achieves real-time inference and demonstrates strong results on unsupervised and weakly-supervised segmentation tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. **Novel Insight** – The discovery that diffusion models internally encode instance boundaries is original and insightful.  \n2. **Elegant Design** – The approach leverages self-attention statistics (KL divergence) without requiring extra supervision or training labels.  \n3. **Strong Empirical Results** – TRACE significantly outperforms state-of-the-art methods like MaskCut and ProMerge on COCO and VOC datasets.  \n4. **Interpretability** – The visualization of attention evolution (IEP phenomenon) provides an interpretable window into diffusion model internals.  \n5. **Efficiency** – The one-step distillation achieves ~81× inference acceleration, demonstrating practical usability."}, "weaknesses": {"value": "1. **Limited Theoretical Explanation** – While IEP is clearly defined using KL divergence peaks, the underlying cause of such emergence remains described qualitatively. A lightweight theoretical or statistical discussion (e.g., how noise levels influence attention entropy) could enhance the argument.  \n\n2. **Negative Analysis** – The paper focuses on successful examples; adding a few failure visualizations or robustness analyses (e.g., under cluttered scenes or overlapping objects) would provide a more balanced evaluation.  \n\n3. **Fine-Grained Analysis of IEP** – The phenomenon of IEP is intriguing, but its quantitative behavior (e.g., variance across images, layers, or diffusion steps) is not deeply examined. A more detailed statistical characterization—such as distributional patterns or consistency metrics—could enrich understanding and further substantiate the discovery."}, "questions": {"value": "1. How consistent is the identified IEP across diffusion timesteps, model scales, or datasets?  For example, does the same timestep correspond to “edge emergence” across all classes and diffusion models?  \n2. Could the KL divergence criterion for IEP detection be replaced or augmented by other measures (e.g., entropy, mutual information)?  \n3. How sensitive is the distilled edge decoder to the choice of teacher diffusion backbone? Could it generalize across unseen models or domains (e.g., medical, satellite images)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "otRTmvQQGk", "forum": "BjElYlJKMj", "replyto": "BjElYlJKMj", "signatures": ["ICLR.cc/2026/Conference/Submission11242/Reviewer_KrZ9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11242/Reviewer_KrZ9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11242/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645531153, "cdate": 1761645531153, "tmdate": 1762922402494, "mdate": 1762922402494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors observe that self-attention in diffusion models encodes instance-level structure during denoising. Based on this observation, the authors propose to decode instance boundaries directly from pre-trained text-to-image diffusion models. This is achieved by identifying the Instance Emergence Point, extracting boundaries through Attention Boundary Divergence, and distilling them into a lightweight one-step edge decoder. Experimental results on unsupervised instance segmentation and weakly-supervised panoptic segmentation demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-\tThe proposed method is well motivated. The authors start from the interesting observation that instance-level structure emerges from self-attention in diffusion models, which motivates the authors to decode instance boundaries from diffusion models to enable annotation-free instance and panoptic segmentation.\n-\tThe paper is generally well-written and easy to follow.\n-\tThe experiments are extensive and the results seem promising."}, "weaknesses": {"value": "-\tSome related works are missing. For example, [1, 2] are diffusion-based instance/semantic segmentation methods that also leverage the attention maps directly from diffusion models without relying on any label supervision. The authors should discuss these works as well.\n-\tThe experimental settings mainly focus on the closed set. Given the open-set nature of diffusion models, I am curious about the effectiveness of the proposed method for open-vocabulary segmentation.\n-\tHow to measure the quality of instance boundaries? Currently, it somewhat manifests through the downstream segmentation performances. Would it be possible to have a metric to directly evaluate instance boundaries before downstream training?\n-\tWhat are the failure cases of the proposed method? Adding more analysis on failure cases will add more insights to the paper.\n\n**References:**\n\n[1] MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation. In IJCV, 2024.\n\n[2] EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models. In ICLR, 2024."}, "questions": {"value": "See the questions mentioned above. Given the current status of the paper, I am leaning towards borderline accept and hope the authors could address my concerns during the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JpphBX32IS", "forum": "BjElYlJKMj", "replyto": "BjElYlJKMj", "signatures": ["ICLR.cc/2026/Conference/Submission11242/Reviewer_rCqE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11242/Reviewer_rCqE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11242/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761868430509, "cdate": 1761868430509, "tmdate": 1762922401724, "mdate": 1762922401724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes TRACE (TRAnsforming diffusion Cues to instance Edges), a framework for decoding instance boundaries from the self-attention of pre-trained text-to-image diffusion models. It aims to solve the problem of difficult instance separation in unsupervised and weakly-supervised segmentation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.The idea that instance-level structural information (not just semantic information) is hidden in the self-attention (rather than cross-attention) of pre-trained diffusion models is interesting. \n2. As a plug-and-play module, TRACE shows consistent and significant performance improvements when integrated into various existing segmentation frameworks."}, "weaknesses": {"value": "1. It seems that the proposed method depends on specific diffusion model backbones. The discussion on detailed generalizability across model scales and architectures is required. Whether this dependency might limit its application in resource-constrained scenarios.\n2. The paper compares TRACE with alternatives like Canny/HED/PiDiNet/Depth-based methods in tables/figures in Fig. 10, but it lacks the direct edge quality evaluation."}, "questions": {"value": "1. Although the authors claim that the IEP timestep distribution is \"model-agnostic,\" the results in Table 5 indicate that TRACE's final performance is strongly correlated with the chosen diffusion model backbone. For example, SD3.5-L (8.1B parameters) achieves an $AP^mk$ of 8.2, while SD1.5 (0.8B parameters) only reaches 6.8. The authors should discuss in more detail the method's generalizability across model scales and architectures, and whether this dependency might limit its application in resource-constrained scenarios.\n2. In Section 3.4, it is ambiguous when describing the one-step self-distillation. The authors do not explicitly state how the \"uncertain\" pixels (value -1) are handled (or \"excluded\") within this loss function. This lack of critical implementation detail could hinder reproducibility. It does not sufficiently explain the specific impact of this threshold choice on the results (edge connectivity, false positives, false negatives), nor why $\\mu+\\sigma$ is robust across various scenarios. This step directly impacts the quality of the distillation supervision.\n3. The paper compares TRACE with alternatives like Canny/HED/PiDiNet/Depth-based methods in tables/figures, showing TRACE's advantages. However, it lacks: a) Edge quality metrics (e.g., Precision/Recall/F1, ODS/OIS) on standard edge detection benchmarks (like BSDS, or COCO edge annotations if available); and b) Quantitative connectivity/topological metrics for the output edges. Currently, the quality of the edges is primarily demonstrated indirectly through downstream segmentation metrics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FNQf9xQQdL", "forum": "BjElYlJKMj", "replyto": "BjElYlJKMj", "signatures": ["ICLR.cc/2026/Conference/Submission11242/Reviewer_inKu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11242/Reviewer_inKu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11242/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991284485, "cdate": 1761991284485, "tmdate": 1762922401324, "mdate": 1762922401324, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}