{"id": "bZBJFrxH1H", "number": 18866, "cdate": 1758291618577, "mdate": 1763748002846, "content": {"title": "Distillation of Large Language Models via Concrete Score Matching", "abstract": "Large language models (LLMs) deliver remarkable performance but are costly to deploy, motivating knowledge distillation (KD) for efficient inference. Existing KD objectives typically match student and teacher probabilities via softmax, which blurs valuable logit information. While direct logit distillation (DLD) mitigates softmax smoothing, it fails to account for logit shift invariance, thereby restricting the solution space. We propose Concrete Score Distillation (CSD), a discrete score-matching objective that overcomes both softmax-induced smoothing and restrictions on the optimal solution set. We resolve the training instability and quadratic complexity of discrete score-matching in autoregressive LLMs, and the resulting CSD objective aligns relative logit differences across all vocabulary pairs between student and teacher with flexible weighting. We provide both mode-seeking and mode-covering instances within our framework and evaluate CSD on task-agnostic instruction-following, task-specific, and general chat capability distillation using GPT-2-1.5B, OpenLLaMA-7B, and Gemma-7B-IT, Qwen2.5-7B-IT, and Gemma2-9B-IT teachers. Experiments show that CSD consistently surpasses recent KD objectives, achieves favorable fidelity–diversity trade-offs, and yields complementary gains when combined with on-policy techniques, demonstrating its scalability and effectiveness for LLM distillation.", "tldr": "This paper performs distillation between two autoregressive language models via score matching, thereby defining the loss directly at the logit level.", "keywords": ["Large Language Models", "Knowledge Distillation", "Score Matching"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f3e73808e649a3cea497045a5a9ae9ab1c716e79.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Concrete Score Distillation (CSD), a novel training objective for improved large language model's knowledge distillation. Based on the observation that softmax is invariant to constant addition, the proposed method extends direct logit distillation (DLD) by allowing student's logits to be matched to the teacher's logits shifted by an arbitrary constant. The paper further introduces and experiments with various weighting functions to balance the output accuracy and diversity of the trained student. Experiments show that the proposed method outperforms prior approaches compared to divergence-based loss function, and that it achieves complementary gains when used in combination with recent on-policy KD methods."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper, including the algorithm, theoretical analyses and proofs, is well-written and easy to follow.\n1. The idea of enhancing logit matching distillation by accounting for the logit shift invariance is well-motivated and reasonable.\n1. The author's extension to DLD theoretically and empirically achieves the target of logit shift invariance.\n1. The experimental results show improvements compared to the baselines, across multiple model families and model sizes.\n1. The paper is well placed in existing literature, and prior works considered are thorough."}, "weaknesses": {"value": "1. The authors claim that one of their motivations is that vanilla KLD gives almost identical and very low probabilities and gradients to the low-probability tokens in the tail. While their method, with uniform weighting (w1,w2=U) would indeed achieve their target of \"overcoming the softmax-induced smoothing of teacher knowledge\", most of their results use w1,w2 as either student or teacher probabilities. As these values are very small and almost zero, a very similar smoothing is also present in the proposed method.\n1. Comparison with DLD: since the method is an extension to DLD, I believe it would be more appropriate to compare the method with variants of logit matching methods. Currently, only the comparison between DLD and CSD on GPT2-0.1B for the five benchmarks is given. It would be great to see how CSD compares against DLD at larger model sizes, different datasets, etc.\n1. Weighting function: not using weighting function (corresponding to the (u, u) setting in the paper) performs significantly worse compared to other divergence-based baselines, and the overall performance seems to be heavily impacted by the choice of the weighting function. Furthermore, with S as a weighing function, DLD performance seems to be only slightly worse than the proposed method. This makes me wonder if similar performance improvement can be made to the divergence-based methods by adding similar weighting function to those.\n1. The method is only tested on relatively small datasets (eg. 15000 samples), its effectiveness in longer training horizon is unexplored.\n1. Most of the experiments were performed on a relatively weak model (GPT2), with only some experiments on Openllama/gemma. It is uncertain if the results will hold with newer/stronger models."}, "questions": {"value": "1. In figure 4, \"Ours\" refers to which exact model/setting for the two model sizes? Just CSD, or perhaps ImitKD+Ours, or something else? Could the authors share the GPT evaluation scores of vanilla CSD, GKD+ours, DistilLLM+ours,ImitKD+ours if these were also evaluated?\n1. For results in Table 3, w1,w2 were used as (t,s) (as mentioned in line 879) compared to the \"default\"(as mentioned in line 312) of (s,s) elsewhere. Can the authors elaborate on why were w1,w2 changed for these experiments? If the authors tried (s,s) first, could they share these results?\n1. In figure 8 (a) and (b), could the authors also share the KL-divergence/MSE/some other divergence metric between the teacher and student probabilities corresponding to y1 to y10? This will prove that the student probabilities with CSD maintain similarity to teacher inspite of logit shift."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pJGJfZwmUM", "forum": "bZBJFrxH1H", "replyto": "bZBJFrxH1H", "signatures": ["ICLR.cc/2026/Conference/Submission18866/Reviewer_5noZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18866/Reviewer_5noZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886284682, "cdate": 1761886284682, "tmdate": 1762930833696, "mdate": 1762930833696, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Reply to All Reviewers"}, "comment": {"value": "# **Revision Summary**\n\nWe sincerely thank all the reviewers for their valuable feedback. We have made our best efforts to incorporate all questions, suggestions, and comments into the revised version of our paper. All modifications in the manuscript are highlighted in blue. For newly added rows in the tables, only the method names are marked in blue. The captions of newly added figures are marked in blue. The text describing the added or modified content has also been updated accordingly.\n\n----\n\n### **Revisions in the Main Paper**\n\n-\t**Table 2, Table 3**: Added DLD baselines.\n\n-\t**Table 4 (Section 4.3)**: New experiments using Qwen2.5-7B-IT and Gemma2-9B-IT for general chat capabilities\n\n-\t**Table 5, Figure 5 (a)**: Added DLD-variant baselines\n\n-\t**Figure 5 (b)**: Calibration error ablation results\n\n-\t**Figure 5 (c)**: Convergence comparison results\n----\n\n### **Revisions in the Appendix**\n\n- **Section A.4**: Mathematical formulation of DLD variants\n\n- **Section A.5**: Mathematical formulation of the weighted divergence objective\n\n- **Section C.3**: Experimental details for the Qwen2.5-7B-IT and Gemma2-9B-IT experiments\n\n- **Section C**: Algorithms for Monte Carlo estimation\n\n- **Section D.1**, Figure 9, Table 6, Table 11: Analysis of logit offsets\n\n- **Figure 10**: Probability calibration error evaluated with additional metrics\n\n- **Figure 12 (Section D.2)**: Adaptive weighting loss and related experiments\n\n- **Figure 13 (Section D.3)**: Analysis of gradient coefficient diversity\n\n- **Table 8**: Empirical evaluation of weighting strategies for divergence-based objectives\n- **Table 9**: Comprehensive evaluation of training speed and memory usage\n\n- **Table 10**: Added DLD baselines for task-specific experiments\n\n----\n\n### **Highlighting new experimental results**\n\nWe would like to emphasize once again that **Table 4** in the modified manuscript presents newly added experiments evaluating general chat capability using recent, stronger models.\n\n|| | Qwen2.5-IT (7B$\\rightarrow$1.5B) | | |Gemma2-IT (9B$\\rightarrow$2B) | |\n|-|:-:|:-:|:-:|:-:|:-:|:-:|\n| Benchmark| MT-Bench| MT-Bench | AlpacaEval | MT-Bench | MT-Bench| AlpacaEval |\n| Judge| GPT4| GPT4-Turbo | GPT4-Turbo | GPT4| GPT4-Turbo | GPT4-Turbo |\n| | |  |  | |  |  |\n| Teacher | 8.59 | 7.52 | 88.69 | 8.91 | 7.66 | 94.60 |\n| | |  |  | |  |  |\n| DPKD (Li et al., 2024) | 1.04 | 1.09 | 0.32 | 6.30 | 4.89 | 71.18 |\n| DistiLLM2 (Ko et al., 2025) | 7.28 | 5.75 | **70.42** | 7.81 | 6.45 | 89.91 |\n| DLD (T) | 7.25 | 5.56 | 69.80 | 5.85 | 4.45 | 31.24 |\n| DLD (S) | 7.28 | 5.74 | 67.67 | 7.58 | 6.53 | 89.84 |\n| **CSD (T, S)** | 7.42 | 5.90 | **70.42** | **7.85** | **6.55** | 89.92 |\n| **CSD (S, S)** | **7.69** | **5.95** | 69.64 | 7.77 | 6.43 | **90.05** |"}}, "id": "ZqA6HWl2LB", "forum": "bZBJFrxH1H", "replyto": "bZBJFrxH1H", "signatures": ["ICLR.cc/2026/Conference/Submission18866/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18866/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18866/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763748104048, "cdate": 1763748104048, "tmdate": 1763752174723, "mdate": 1763752174723, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Concrete Score Distillation (CSD), a knowledge-distillation objective for autoregressive LLMs that addresses two core issues: (1) probability-matching objectives (e.g., KL) lose fine-grained information at the logit level due to softmax smoothing; (2) while direct logit distillation (DLD) avoids softmax, its objective implicitly forces the student logits to match the teacher exactly, ignoring logit shift invariance (i.e., an additive constant does not change probabilities), which restricts the optimal solution set. CSD adapts score matching from energy-based modeling to a discrete setting and matches pairwise relative logit differences across the vocabulary, thereby being inherently shift-invariant and expanding the attainable solution set. The paper further addresses training instability and computational overhead when applying score matching to autoregressive LLMs by deriving an O(|V|) analytic gradient (from a naïve O(|V|2) formulation). Experiments show that CSD outperforms recent probability-matching and direct-logit objectives on both task-agnostic instruction following and task-specific distillation (summarization, math, and translation), offers a controllable fidelity–diversity trade-off, and yields complementary gains when combined with on-policy techniques, indicating good scalability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Precise problem framing and strong motivation. The paper clearly identifies fundamental shortcomings of existing approaches—probability matching loses logit information; DLD over-constrains the solution set by ignoring shift invariance.\n2. Theory-grounded contribution. CSD is derived from score matching with key guarantees: Proposition 1 (consistency) and Theorem 2 (solution set is a superset of DLD). This provides principled justification for the objective.\n3. Clear, controllable objective design. Equation (9) reveals a gradient structure based on centering, factorized weighting, and role swapping; the (w1,w2) design smoothly tunes the fidelity–diversity trade-off (as illustrated in Figure 3)."}, "weaknesses": {"value": "1. Underpowered DLD baselines. DLD does not appear in the main comparison table and is shown only once in ablations (Table 4). Stronger DLD variants—e.g., mean-centered, temperature-scaled, or otherwise shift-aware formulations—are missing, as are several recent logit-distillation variants. This makes it hard to assess CSD’s margin over the strongest DLD baselines.\n2. Practical computational burden. Although Theorem 3 reduces complexity from O(|V|2) to O(|V|), real-world LLMs with very large vocabularies (e.g., 50k+) still require computing and normalizing all token logits per step. The paper shows that a Monte-Carlo estimator performs worse, so the efficient implementation currently relies on full-vocabulary passes, which may become a bottleneck at scale."}, "questions": {"value": "1. Stronger DLD comparisons. If DLD is augmented with mean-centering, temperature scaling, or an explicit shift-invariant formulation, does CSD still retain the advantages reported in Tables 1 and 3? Could you include strong DLD in the main results and report variance?\n2. On the solution space. Since CSD allows a global additive shift on logits, how does this offset behave during training—does it converge to a stable value? Are there systematic differences across tokens? Does this flexibility introduce any extra instability compared to DLD?\n3. Scaling characterization. For vocabularies of 32k–100k and sequence lengths of 4k–8k, what are the peak memory, step time, and convergence trade-offs of CSD (analytic vs. MC) versus KL/DLD? Is there a practical heuristic for choosing analytic vs. MC estimators at different scales?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hvenVeFBjG", "forum": "bZBJFrxH1H", "replyto": "bZBJFrxH1H", "signatures": ["ICLR.cc/2026/Conference/Submission18866/Reviewer_8hoT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18866/Reviewer_8hoT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762095674155, "cdate": 1762095674155, "tmdate": 1762930832982, "mdate": 1762930832982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of distilling large language models. To address some of the limitations of Direct Logit Distillation, the authors propose leveraging score matching for discrete variables. They thus propose a new objective for knowledge distillation named Concrete Score Distillation. The main idea is to replace the dataset data distribution ($p_{\\textrm{data}$) in the score matching objective with the teacher probability $p_T$. To address training instability, they propose using a logarithm function. They also propose an efficient approach for computing gradients. A complete experimental validation is provided for different setups: task-agnostic instruction-following distillation and task-specific distillation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**originality**\n + The idea of using the generalized score function for LLM knowledge distillation is new and original.\n + The proposed approach is technically sound, and the claims are supported by both theoretical aspects and by the experimental part.\n\n**quality**\n + The effectiveness of the proposed approach is validated on multiple KD settings.\n\n**clarity**\n+ The paper is well-written, with a clear formalization of the proposed approach.\nThe approach is also well-motivated.\n+ The annexes of the paper contain important additional information, such as proofs, derivations, and additional experimental details.\n\n**significance**\n+ LLM Knowledge distillation is a crucial issue for the real-world deployment of LLMs. The proposed approach clearly advances the state of the art on LLM Knowledge distillation."}, "weaknesses": {"value": "+ Some minor remarks on equation 5 and 6 : $p_{\\textrm{data}}$ is not defined. \n+ Proposition 1 and Theorem 2 assume a sufficient model capacity. This should be detailed. What is a sufficient model capacity in this particular case? \n+ In Theorem 3, an assumption is that we can write the weighting function $w(y_t,x) = w_1(y_t) w_2(x)$. The authors do not justify this assumption. This rewriting of the weighting function is important in the proposed approach and in the experimental part. The paper does not explain how to build $w_1$ and $w_2$."}, "questions": {"value": "+ A key assumption of the proposed approach is that the teacher and student models share the same vocabulary. We know that, in practice, this hypothesis is not satisfied due to the differences between the different tokenizers. How can this issue be addressed in the proposed approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NdT8pluvFt", "forum": "bZBJFrxH1H", "replyto": "bZBJFrxH1H", "signatures": ["ICLR.cc/2026/Conference/Submission18866/Reviewer_Pedf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18866/Reviewer_Pedf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096284503, "cdate": 1762096284503, "tmdate": 1762930832064, "mdate": 1762930832064, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Concrete Score Distillation (CSD), a discrete score-matching objective for LLM distillation that avoids softmax-induced smoothing and is invariant to constant logit shifts, which are two limitations of common KD and direct-logit losses. It resolves the quadratic cost of pairwise score matching with an analytic, linear-time gradient and provides formal guarantees. Experiments on instruction following and task-specific settings (e.g., summarization, translation) show CSD consistently outperforms recent KD objectives and delivers favorable fidelity-diversity trade-offs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proves consistency and that CSD’s optimum set strictly contains DLD’s, leveraging invariance to constant logit shifts\n\n- It derives an Algorithm 1 for keeping compute/memory in line with standard KD\n\n- The method consistently surpasses strong KD baselines across tasks and yields complementary gains when combined with on-policy techniques, suggesting good scalability."}, "weaknesses": {"value": "- The paper claims linear-time gradients, but lacks systematic reporting of GPU memory, tokens/sec, and wall-clock per step versus KL/SKL/DLD across vocabulary sizes (e.g., 32k to 128k). Adding end-to-end cost curves and scaling ablations would strengthen adoption\n\n- While the paper shows that weights modulate mode-seeking/covering, default choices, schedules, or adaptive schemes are not well-justified; more guidance (or learning the weights) would aid practitioners.\n\n- Since CSD replaces softmax normalization with centered logits, its impact on probability calibration warrants measurement. (Related to shift-invariance.)"}, "questions": {"value": "Can you report throughput, peak memory, and step time for CSD vs. KL/SKL/DLD on matched setups, plus scaling with vocab size? (This directly tests the linear-time gradient claim and Algorithm 1 practicality.)\n\nCan you provide defaults, schedules, or an adaptive/learned weighting (e.g., driven by confidence or gradient variance)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UrQYJHEdGN", "forum": "bZBJFrxH1H", "replyto": "bZBJFrxH1H", "signatures": ["ICLR.cc/2026/Conference/Submission18866/Reviewer_TcP2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18866/Reviewer_TcP2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762111604409, "cdate": 1762111604409, "tmdate": 1762930831676, "mdate": 1762930831676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}