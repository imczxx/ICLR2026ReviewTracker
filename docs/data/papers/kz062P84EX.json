{"id": "kz062P84EX", "number": 6514, "cdate": 1757987577100, "mdate": 1759897910337, "content": {"title": "Actively Enlarging Feature Norms with Universal Adversarial Training and Channel Calibration for Superior OOD Detection", "abstract": "Out-of-distribution (OOD) detection is an increasingly essential component for ensuring the safety and reliability of machine learning systems. A key insight in this area is that the feature norm gap between in-distribution (ID) and OOD data serves as a strong signal for identifying anomalous inputs. Building on this, we propose an innovative Universal Adversarial Training (UAT) framework that actively enlarges this norm gap. Our method introduces a single, learnable Universal Adversarial Map (UAM) that acts as a global regularizer to address shared vulnerable directions in the model. By regularizing the decision boundaries, this approach enlarges the gaps between ID classes, which enhances the model's generalization and its ability to distinguish OOD data. To further enhance detection at inference, we introduce a Channel-Calibrated Feature Norm (CCFN) scoring mechanism that refines the feature norm by suppressing irrelevant background activations. Our comprehensive experiments and ablation studies demonstrate that these innovations lead to substantial performance gains across various benchmarks.", "tldr": "We propose a universal adversarial training framework and a channel-amplified scoring strategy to actively enlarge the feature norm gap between in-distribution and out-of-distribution (OOD) data, significantly improving OOD detection performance.", "keywords": ["Out-of-distribution (OOD) detection", "Adversarial Training"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/24b3f5cb2e1a8ae3b17b9895ed7b286a172534f5.pdf", "supplementary_material": "/attachment/d0901861887c5c221d1226a097617dfd99205c67.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel framework aimed at improving out-of-distribution (OOD) detection by focusing on the feature norm gap between in-distribution (ID) and OOD data. The authors propose Universal Adversarial Training (UAT) combined with a Channel-Calibrated Feature Norm (CCFN) scoring mechanism. UAT leverages a universal adversarial map (UAM) to enhance class separation during training, while CCFN improves the performance at inference by emphasizing informative features and suppressing irrelevant ones. The proposed method demonstrates significant improvements in OOD detection across several benchmarks, including CIFAR-10, CIFAR-100, and ImageNet, achieving state-of-the-art results."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of UAT and CCFN is a novel method that fills a significant gap in OOD detection methods.\n\n2. This method has a solid theoretical foundation and is validated through comprehensive experiments.\n\n3. This paper provides a clear description of the method, with sufficient detail in both the theoretical and experimental sections."}, "weaknesses": {"value": "1. While the theoretical framework is solid, the section involving the proofs (especially Lemmas 1 and 2) may be difficult for some readers to follow without sufficient context or explanation.\n\n2. The paper could balance the theoretical content with more practical insights or intuitive examples to make it more accessible for a broader audience.\n\n3. While the experiments show clear advantages, additional comparisons with more recent OOD detection techniques, such as [1] and [2], could further solidify the proposed methodâ€™s superiority.\n\n4. The paper does not provide a link to an anonymized code repository, which could hinder future efforts for replicating or building upon the work. Open-sourcing the implementation would not only facilitate reproducibility but also contribute to the broader research community.\n\n5. While the method shows strong performance on image datasets, the paper does not provide sufficient analysis on how well the approach generalizes to other domains, such as time-series or textual data. Given the importance of OOD detection in various fields, exploring the adaptability of the method beyond images would be valuable.\n\nReferences\n\n[1] Xu, K., Chen, R., Franchi, G., & Yao, A. (2023). Scaling for training time and post-hoc out-of-distribution detection enhancement. arXiv preprint arXiv:2310.00227.\n\n[2] Liu, Y., Tian, C. X., Li, H., Ma, L., & Wang, S. (2023). Neuron activation coverage: Rethinking out-of-distribution detection and generalization. arXiv preprint arXiv:2306.02879."}, "questions": {"value": "1. Does the proposed method generalize to other domains beyond image data? Could it be applied to, for example, time-series or text data for OOD detection?\n\n2. Could the results in Table 6 be further improved with different strategies for updating the adversarial map during training, or is the chosen frequency optimal across all datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cDdPGMtY2C", "forum": "kz062P84EX", "replyto": "kz062P84EX", "signatures": ["ICLR.cc/2026/Conference/Submission6514/Reviewer_Zdr8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6514/Reviewer_Zdr8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6514/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906208593, "cdate": 1761906208593, "tmdate": 1762918877283, "mdate": 1762918877283, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new method for OOD detection, which actively enlarges the feature norm gap between ID and OOD data through Universal Adversarial Training (UAT) and Channel-Calibrated Feature Norm (CCFN). UAT employs a learnable universal adversarial map (UAM) as a regularizer during training; CCFN optimizes the OOD score at inference time by re-weighting channel activations. The authors demonstrate the superiority of their method over existing techniques through extensive experiments on CIFAR-10, CIFAR-100, and ImageNet."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method achieves state-of-the-art or near-SOTA performance on all reported benchmarks, with particularly significant reductions in the FPR95 metric.\n2. Compared to traditional per-sample adversarial training, UAT only needs to optimize a single, global UAM, which is computationally more efficient. The appendix also shows this approach is more effective for OOD detection.\n3. The paper provides an in-depth analysis of the method's key components, including the impact of UAT on the norm ratio, the UAM update frequency, and the perturbation location, all of which strengthen the study's claims."}, "weaknesses": {"value": "1.  Although the proposed method improves OOD detection performance, the paper lacks an analysis of its computational efficiency. The introduction of the learnable universal adversarial map (UAM) and the channel-calibrated feature norm (CCFN) scoring mechanism likely adds computational overhead. A discussion on the method's efficiency, including training time and inference speed, would provide a clearer understanding of its practical applicability in resource-constrained environments.\n2.  The proposed adversarial training method introduces a universal adversarial map to regularize the model. However, this may lead to overfitting, especially if the model becomes too adapted to this specific adversarial perturbation.\n3.  The OOD for the newly trained model is no longer the OOD for the original model, it's just easier to detect on the new model. If I want to detect the OOD for the original model, this is not applicable. In many cases, OOD is not only for defense, but also a means to adjust the model, thus losing an important tool.\n4.  How can this method be extended beyond classification models? OOD detection is not limited to classification models, is it?"}, "questions": {"value": "1. Can the authors provide specific data on the computational overhead introduced by UAT (vs. standard training) and CCFN (vs. standard L2 norm scoring)? For example, by what percentage does training time increase, and what is the added inference latency (ms/image) on ResNet-50 for ImageNet?\n2. If the model overfits to $L_{adv}$, does its robustness against other types of unseen adversarial perturbations or data corruptions decrease compared to a standard-trained model?\n3. If my goal is to evaluate the OOD robustness of an existing, pre-trained model that cannot be retrained, is the proposed method still applicable?\n4. Have the authors considered how the UAT framework could be extended to OOD detection in non-classification tasks, such as object detection or semantic segmentation, where the loss functions and feature norm definitions might need adaptation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8DMU4rUAYt", "forum": "kz062P84EX", "replyto": "kz062P84EX", "signatures": ["ICLR.cc/2026/Conference/Submission6514/Reviewer_roTf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6514/Reviewer_roTf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6514/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993377843, "cdate": 1761993377843, "tmdate": 1762918876781, "mdate": 1762918876781, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework for OOD detection. The core idea is to actively enlarge the feature norm gap between ID and OOD data via two main contributions. First, the authors introduce Universal Adversarial Training (UAT), which learns a single, learnable Universal Adversarial Map (UAM) as a global regularizer to smooth decision boundaries and enhance the separability of ID classes. Second, to further enhance detection at inference, the paper proposes a Channel-Calibrated Feature Norm (CCFN) scoring mechanism, which purifies the feature norm signal by suppressing irrelevant background activations. Experimental results demonstrate that this method achieves significant performance improvements on several OOD detection benchmarks, including CIFAR-10/100 and ImageNet."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Unlike methods that passively rely on the feature norm gap, the proposed UAT framework actively enlarges this gap during training. The use of a single, learnable UAM as a global regularizer is an innovative point.\n2. The experimental results are very strong. The proposed method (UAT + CCFN) consistently outperforms existing baselines on AUROC and FPR95 metrics across multiple backbones (ResNet, VGG, WRN) and datasets.\n3. The paper provides a theoretical foundation for UAT, theoretically analyzing how UAT amplifies the norm ratio by enhancing intra-class compactness and inter-class separability.\n4. The ablation study shows that UAT not only improves OOD detection but also enhances the classification accuracy of ID data."}, "weaknesses": {"value": "1.  In Equation (2), the optimization objective of UAT is formulated as a max-min problem, which learns the universal adversarial map $L_{adv}$. However, the interaction between the cross-entropy loss and the adversarial perturbation in the objective function is not sufficiently explained, especially regarding how the perturbation alters the decision boundary. The method aims to regularize the model by pushing the decision boundary outwards, but the specific mechanism by which the adversarial map affects the decision boundary, particularly concerning class separation and feature compactness, is not fully articulated.\n2.  The paper introduces a channel-wise feature norm recalibration method in Equation (5), where the feature norm is calculated by averaging the squared norms of each rescaled channel. While the idea of emphasizing channels with high activation values is intuitive, the paper does not explain why this specific norm aggregation method (i.e., averaging across channels) is the most effective. Specifically, using the maximum activation value ($w_{c}=max_{h,w}ReLU(f_{c,h,w})$) to rescale the contribution of each channel may not always capture the most discriminative features, especially in complex datasets where activation values might vary more subtly across spatial locations. An alternative approach, such as considering the variance or higher-order moments of activations, might provide a more robust recalibration. A deeper exploration of why this specific method was chosen and a comparison with other possible aggregation strategies would help clarify its effectiveness.\n3.  The paper focuses on improving OOD detection performance but does not discuss the model's interpretability. Given the involvement of adversarial training, understanding how the universal adversarial map and channel recalibration affect the model's decision-making process would be beneficial."}, "questions": {"value": "1. Can the authors provide a more in-depth analysis or visualization to specifically demonstrate how $L_{adv}$ (as described in Lemmas 1 and 2) leads to more compact intra-class features and more separated inter-class features?\n2. The use of the maximum activation $w_{c}$ as a weight in CCFN is one choice. Did the authors try other aggregation statistics (e.g., mean, variance, or L2-norm) instead of $max$? How did their performance compare to the current method?\n3. Can the authors provide some analysis on interpretability? For instance, do the patterns learned by the UAM ($L_{adv}$) help in identifying specific input features? The activation maps in Figure 3 show differences for CCFN on ID and OOD samples, but does this translate to an interpretable change in the model's decision logic?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7BdOGN0icj", "forum": "kz062P84EX", "replyto": "kz062P84EX", "signatures": ["ICLR.cc/2026/Conference/Submission6514/Reviewer_dj6D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6514/Reviewer_dj6D"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6514/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993673338, "cdate": 1761993673338, "tmdate": 1762918876245, "mdate": 1762918876245, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a  framework for  OOD detection by  enlarging the feature norm gap between in-distribution ID and OOD data. The core of the method is a Universal Adversarial Training  method, which uses a single, learnable Universal Adversarial Map  as a global regularizer. This UAT process regularizes the model's decision boundaries, which enlarges the gaps between ID classes and enhances generalization. Authors claim this improves ability to distinguish ID classes  translates into a superior ability to detect OOD samples, which are less likely to fall within the ID class boundaries. Then the authors introduce a Channel-Calibrated Feature Norm  scoring mechanism for test time. CCFN refines the feature norm by suppressing irrelevant background activations and emphasizing important channels, leading to a more accurate OOD score."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "OOD detection is an important task specifically in real world setup.\n\nThe paper is generally well written and clear in its problem definition."}, "weaknesses": {"value": "W1) Given that OOD detection in vision is a deployment-oriented task, I expect evaluation on larger, more challenging, real-world datasets. The experiments use CIFAR-10/100 and ImageNet as ID datasets; these are aging benchmarks for OOD detection. I expect consideration of application-driven datasets (e.g., medical imaging) and inclusion of comparisons to recent SOTA methods [E,F]. For instance, see [E], which reports ~100% AUC on CIFAR-10 vs. CIFAR-100. What does your work contribute over such baselines?\n\n\nW2) How does the approach extend to ViT or other non-CNN backbones? The paper appears to report results only with CNNs.\n\n\nW3) There are prior works at the intersection of adversarial perturbations and OOD detection [A,B,C]. The paper should cite and discuss these, and clearly articulate conceptual and algorithmic differences from the proposed framework. (I know they are designed specifically for robust OOD detection, but their frameworks share a lot of similarity.)\n\n\nW4) The perturbation budget and norm used and the value of epsilon, are not sufficiently discussed.\n\n\n\n[A] ATOM: Robustifying Out-of-distribution Detection Using Outlier Mining\n\n[B] RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples  \n\n[C] Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings\n\n[E] Deep Hybrid Models for Out-of-Distribution Detection\n\n[F] Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jegWSl01rI", "forum": "kz062P84EX", "replyto": "kz062P84EX", "signatures": ["ICLR.cc/2026/Conference/Submission6514/Reviewer_LHzD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6514/Reviewer_LHzD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6514/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105321688, "cdate": 1762105321688, "tmdate": 1762918875712, "mdate": 1762918875712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}