{"id": "voB9vaGcx1", "number": 20084, "cdate": 1758302263135, "mdate": 1759897002618, "content": {"title": "Conditional Deontics over Terminals: A Mildly Context-Sensitive Formal Grammar for Constrained Decoding", "abstract": "Constrained decoding researchers have recently thought to extend context-free constrainers to context-sensitive constraints such as matching selected columns to tables in text-to-sql.\n\nThis is challenging, because context-sensitivity is achieved by cross referencing different subtrees in the syntactic structure, which is only partially available during LLM generation.\n\nRecent frameworks such as IterGen gain some context sensitivity but with drawbacks including the need for expensive backtracking or speculative lookahead of LLM, overly permissive semantics risking over-constrain, and complication in interfacing with works on improving running speed such as XGrammar.\n\nTo address these concerns, we propose a new mildly-context-sensitive formal grammar called Conditional Deontics over Terminals (CDoT).\n\nIts incremental parser has O(n^3) time complexity each step and allows for GPU acceleration, compared to the O(n^8) of mildly context-sensitive tree-adjoining grammars and the O(n^2) of context-free grammars.\n\nThis new formal grammar is strong enough to implement the unit propagation algorithm, which we employ to assist an LLM during solving of a logical puzzle called \"Knight and Knave\", achieving substantially improved performance at reduced output token budget.\n\nWe also evaluate on the traditional constrained decoding evaluation task of text-to-sql.", "tldr": "", "keywords": ["constrained decoding; formal grammar; parsing theory; formal language theory"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0821d7c86fa5a35af730792706715bb58e067268.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a formalism for mildly context-sensitive grammar constrained decoding.  It addresses limitations of existing methods that require expensive backtracking or speculative lookahead by offering context-sensitive constraints with O(n³) time complexity and GPU acceleration. CDoT allows Python function invocation without requiring users to modify parser states. The paper shows improved performance on logical puzzles (\"Knight and Knave\") and text-to-SQL tasks while reducing computational costs compared to unconstrained decoding."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The paper attempts to solve challenging context-sensitive grammar constrained-decoding problem. This is an important problem and any contribution in this direction can be impactful.\n\n* The related work is reasonably comprehensive and covers most recent works constrained-semantic decoding. Although, I would suggest the authors to include more discussion context-free grammar decoding techniques."}, "weaknesses": {"value": "## Presentation of Technical Contribution\n\n> we design a new formal grammar for constrained-decoding  \n\n* What do you mean by design a new grammar? Do you mean a new class of grammars and a parser?\n\n\n* The technical contribution of the paper is described in short section 4 with minimal detail. The exact technical contribution of the paper in comparison to the existing works on CYK parsing is unclear. \n\n\n## Empirical results\n\n* The evaluation considers two benchmarks. “Knight and Knave” and text-2-sql. I do not think both of these experiments sufficiently show the contribution improves over existing works. The comparison made in the paper is only against the unconstrained LLM and not against the existing SOTA baselines.\n\n* Why were PICARD, Synchromesh or IterGen not considered for the experiment? What are practical advantages of proposed technique over the existing techniques?\n\n* What class of practical constraints that cannot be handled by techniques that use backtracking or speculative lookahead such as PICARD, Synchromesh or IterGen?\n\n* The experiments are limited to 4 small models\n\n## Minor\n\n> Text-to-SQL test: Execution accuracy of constrained vs non-constrained models over 3 runs and 10 epochs\n\nWhat are epochs in this experiment?"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a3iXOUdJfV", "forum": "voB9vaGcx1", "replyto": "voB9vaGcx1", "signatures": ["ICLR.cc/2026/Conference/Submission20084/Reviewer_Sgbm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20084/Reviewer_Sgbm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761697057372, "cdate": 1761697057372, "tmdate": 1762932980227, "mdate": 1762932980227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Conditional Deontics over Terminals (CDoT), a new formal grammar extending context-free grammars with deontic operators  to capture conditional relationships between terminals during generation.\nThe authors build an incremental CYK-like parser capable of enforcing such constraints with O(n³) step complexity, and demonstrate applications to reasoning (“Knight and Knave”) and text-to-SQL constrained decoding.\nThe main claim is that CDoT enables a balance between tractability, context-sensitivity, and practical constrained decoding for large language models (LLMs).\n\nThe paper is clearly written and technically rigorous; however, it raises deep questions about the relevance and integration of symbolic grammar formalisms with modern neural generation. The work would benefit from reframing, empirical grounding, and conceptual modernization."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The formalization of conditional deontic rules is novel and internally consistent. The distinction between necessary and permitted terminal conditions is both intuitive and flexible, providing an expressive way to encode hierarchical dependencies in symbolic grammars.\nThe examples (balanced meals, food–drink pairings) make the semantics accessible.\n* The incremental parser is carefully designed, and the paper demonstrates solid knowledge of parsing theory (e.g., CYK, Valiant recognizer). The authors correctly maintain valid-prefix properties and discuss reachability states in detail.\nThe technical craftsmanship deserves credit even if the overall direction is debatable.\n* The Knight and Knave setup is a creative use of logical reasoning to showcase constraint propagation, and the text-to-SQL experiment shows some awareness of practical downstream relevance. The integration of symbolic constraints with LLM inference is implemented competently."}, "weaknesses": {"value": "* The biggest issue is not the internal coherence of the formalism but its ontological fit with LLMs.\nGrammars operate over explicit derivations; LLMs operate over continuous, implicit distributions.\nThe CDoT framework effectively constrains token-level emissions post hoc, whereas current trends emphasize embedding-level control, latent constraint learning, or differentiable planning.\n\n* Instead of presenting CDoT as a “new grammar formalism,” maybe more appropriate to reframe it as a constraint specification interface for LLM decoding, i.e., a structured programming API for safety or consistency enforcement.\nThat shift would make the work less about “reviving parsing” and more about interpretable constraint enforcement that complements modern decoding (e.g., beam search, logit masking, or self-consistency sampling).\n\n\n* The “mildly context-sensitive” label feels borrowed from formal linguistics, but the paper never proves or empirically motivates that this level of context sensitivity is the right tradeoff for constrained decoding.\nThe O(n³) complexity result is mathematically elegant but not practically evaluated, and there’s no runtime data or ablation study demonstrating when the parser is faster, slower, or more expressive than existing systems like PICARD, IterGen, or XGrammar.\n\n\n* In the Knight and Knave task, the CDoT parser performs reasoning itself (through unit propagation), which confounds whether the improvement comes from the model or from symbolic scaffolding.\nThis makes it hard to assess whether the grammar enhances LLM reasoning or replaces it.\n\n\n* The paper risks sounding like it’s trying to “bring parsing back.” That narrative will face skepticism because the community has largely moved beyond discrete syntax control.\nHowever, the idea of interpretable constraint management, especially for safety, correctness, or verifiability, is timely and highly relevant."}, "questions": {"value": "* What is the precise motivation for using a formal grammar abstraction rather than a constraint graph or differentiable rule network?\nMany modern decoding constraints are expressed at the token or semantic level (e.g., via logit masking, classifier guidance, or constraint satisfaction in embedding space). What unique representational advantage does the grammar formalism provide in this context?\n* The paper claims that CDoT is mildly context-sensitive.\nCan you formally characterize the class of languages it generates?\nDoes it strictly subsume CFGs but remain less powerful than full context-sensitive grammars?\nA formal proof or even an intuitive inclusion diagram would clarify whether the “mildly” label is theoretically justified or purely descriptive.\n* Why retain discrete syntactic machinery when LLMs already model syntax implicitly?\nCould CDoT be reframed as an interpretable constraint layer that interacts with neural probability distributions, instead of a separate parsing engine?\n* You mention that the parser involves “~20 modified incremental Valiant recognizers.”\nCould you provide a clearer explanation or pseudocode outlining how these recognizers interact?\nIn particular, which components are responsible for deontic propagation, and which for structural validity?\nIt would help readers assess computational cost and reproducibility.\n* The complexity claim (O(n³)) is interesting, but what is the constant factor in practice?\nDo you have runtime comparisons against IterGen or XGrammar on equivalent decoding tasks, ideally using GPU-based implementations?\nSuch data would substantiate the claimed efficiency advantage.\n* The LF_ALIVE, LF_REACHABLE↑, and LF_REACHABLE↓ states are key to your approach.\nHow do these attributes scale in memory usage as the sentence length or number of constraints grows?\nAre there cases where they explode combinatorially, and how are these mitigated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZrcEul4dw7", "forum": "voB9vaGcx1", "replyto": "voB9vaGcx1", "signatures": ["ICLR.cc/2026/Conference/Submission20084/Reviewer_S4gW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20084/Reviewer_S4gW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761859645187, "cdate": 1761859645187, "tmdate": 1762932979498, "mdate": 1762932979498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new context-sensitive grammar formalism, dubbed conditional deontics over terminals (CDoT). This type of grammars are intended to provide semantic control over the constrained LLM generation process. The authors also present a new incremental parser for the grammars based on Cocke–Younger–Kasami algorithm. They report cubic complexity with respect to the length of the parsed string. The experiments are performed on “Knight and Knave” logical puzzle and constrained decoding task of text-to-SQL."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* Presenting the concept of extending the context free grammars with additional constrains can be used for semantic constraining of LLM outputs."}, "weaknesses": {"value": "* The presentation of the technique is incomplete. \n* The time complexity bounds have not been  proved in the paper. \n* The experiments are done on simple examples; a more comprehensive set of benchmarks is required\n* The paper does not compare to the existing approaches."}, "questions": {"value": "I appreciate that the paper brings up the techniques from context-sensitive grammars for constraining LLM generation. These techniques have often been overlooked for the complexity of specifying properties and time complexity. \n\nHowever, the presentation of the proposed technique is incomplete, making it difficult to appreciate the contribution:\n- The parser description is terse and does not give intuition about the correctness of the approach. It would be valuable to provide a “soundness” theorem, stating that the parser will accept the text that follows the user-specified rules. \n- The interface of the parser to the LLM is not discussed.\n- The translation from the domain specific language used for the examples to regular expressions is not discussed. \n- The expressive power of deontic rules (i.e., what properties they can express) is not discussed\n- The time bound of O(n^3) for a sequence length n is not proved in the paper. \n\nThe evaluation is performed on several simple examples. On the positive side, they give an indication that the approach can work, and produce better results than fully unconstrained generation on small open-source LLMs. However the evaluation does not compare to any existing work (even though some tools such as Itergen have been mentioned). The results for the test-to-SQL problem are presented as figures, but the paper provides only a brief description of the results and leaves out the conclusion of the benefits of the proposed approach. \n\nMy recommendation for the next revision of the paper is to extend the evaluation with additional benchmarks, compare the approach experimentally to existing tools, and present scaling of the parsing+checking for different sizes 'n'. Further, a closer comparison to the theoretical underpinning of existing constraint generation tools would highlight the unique aspects of your approach."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fUJbIlNJqu", "forum": "voB9vaGcx1", "replyto": "voB9vaGcx1", "signatures": ["ICLR.cc/2026/Conference/Submission20084/Reviewer_rcnF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20084/Reviewer_rcnF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880950016, "cdate": 1761880950016, "tmdate": 1762932978622, "mdate": 1762932978622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address challenges in constrained decoding for Large Language Models (LLMs)—such as the difficulty of implementing context-sensitive constraints, high computational costs, poor compatibility, and semantic risks of existing frameworks (e.g., IterGen)—this paper proposes CDoT (Conditional Deontics over Terminals), a lightweight context-sensitive formal grammar. Its incremental parser operates with a time complexity of \\(O(n^3)\\) per step and supports GPU acceleration. By leveraging deontic rules to constrain the necessary and permitted conditions of terminal instances, CDoT significantly improves the accuracy of LLMs and reduces token consumption in the \"Knight and Knave\" logical puzzle task, while also enhancing the accuracy of most tested LLMs in the Text-to-SQL task."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "It accurately addresses the key challenges in constrained decoding for Large Language Models (LLMs): On one hand, it breaks through the bottleneck in implementing context-sensitive constraints. Through the design of \"deontic rules + lightweight grammar\", it avoids the complex logic of traditional solutions that rely on cross-reference across subtrees; on the other hand, it directly targets the shortcomings of existing frameworks (such as IterGen), solving problems including high computational costs, poor compatibility with speed optimization solutions (such as XGrammar), and the risk of over-constraints caused by overly permissive semantics. Its technical positioning is clear and practical."}, "weaknesses": {"value": "- In the Text-to-SQL task, the Qwen3-1.7B model did not benefit from the CDoT constraint, and the paper did not clearly explain the core reason for this phenomenon, so its universality needs further verification.\n- Although CDoT simplifies constraint definition through the \"anchor + deontic function\" design, for complex tasks (such as multi-turn logical reasoning and nested SQL generation), the design of deontic rules may require refined adjustments (e.g., conditional association of multiple antecedent terminals, writing of regular expressions for complex necessary conditions), which means users need to have a certain level of proficiency in grammar design and logical modeling."}, "questions": {"value": "It is necessary to compare some of the latest related works, such as: \n\nSun, Xintong, et al. \"Earley-Driven Dynamic Pruning for Efficient Structured Decoding.\" Forty-second International Conference on Machine Learning.\n\nRegarding constraints on nested structures (e.g., the matching between subquery columns and outer query tables in SQL), can the \"left-foot state tracking\" mechanism of CDoT effectively cover cross-hierarchical terminal associations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "barH4M6IlK", "forum": "voB9vaGcx1", "replyto": "voB9vaGcx1", "signatures": ["ICLR.cc/2026/Conference/Submission20084/Reviewer_wDPe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20084/Reviewer_wDPe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893854078, "cdate": 1761893854078, "tmdate": 1762932977602, "mdate": 1762932977602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}