{"id": "hkF7ZM7fEp", "number": 21372, "cdate": 1758316821476, "mdate": 1763320097511, "content": {"title": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators", "abstract": "A core challenge in scientific machine learning, and scientific computing more generally, is modeling continuous phenomena which (in practice) are represented discretely. Machine-learned operators (MLO) have been introduced as a means to achieve this modeling goal, as this class of architecture can perform inference at arbitrary resolution. In this work, we evaluate whether this architectural innovation is sufficient to perform “zero-shot super-resolution,” namely to enable a model to serve inference on higher-resolution data than that on which it was originally trained. We comprehensively evaluate both zero-shot sub-resolution and super-resolution (i.e., multi-resolution) inference in MLOs. We decouple multi-resolution inference into two key behaviors: 1) extrapolation to varying frequency information; and 2) interpolating across varying resolutions. We empirically demonstrate that MLOs fail to do both of these tasks in a zero-shot manner.\nConsequently, we find MLOs are not able to perform accurate inference at resolutions different from those on which they were trained, and instead they are brittle and susceptible to aliasing. To address these failure modes, we propose a simple, computationally-efficient, and data-driven multi-resolution training protocol that overcomes aliasing and that provides robust multi-resolution generalization.", "tldr": "Machine-learned operators fail to perform zero-shot super-resolution and are susceptible to aliasing; we propose a multi-resolution training scheme to enable accurate cross-resolution inference.", "keywords": ["Partial differential equations", "Neural operators", "super-resolution", "zero-shot super-resolution", "multi-resolution training"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8bf76ba0d386ca8f8bbd42da7613ca30acb1c808.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper evaluates the hypothesis that Fourier Neural Operators (FNOs) and similar Machine-Learned Operators (MLOs) can generalize across resolutions, i.e., perform \"zero-shot super-resolution\", when trained on low-resolution data. They test the hypothesis on Darcy flow, Burgers', and Navier-Stokes equations and show that FNOs fail to generalize to unseen resolutions or frequency bands. They contribute these failurs as aliasing phenomena and propose a simple fix: multi-resolution training, mixing low- and high-resolution samples, which improves generalization without major cost increase."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The work has clear, well-motivated experiments\n- The systematic decomposition of the problem (frequency extrapolation vs resolution interpolation) is nice"}, "weaknesses": {"value": "- \"zero-shot super-resolution\" phrasing misleads readers from computer vision/image SR domains; the task is not SR in the standard sense.\n- The insight that trained models don't extrapolate beyond training distribution is general ML knowledge and the work contributes only limited conceptual novelty.\n- The proposed solution (multi-resolution training) is expected and straightforward with limited novelty for the ML community."}, "questions": {"value": "The main claims appear to echo the insights of the following work:\n[1] Neural Operator: Learning Maps Between Function Spaces With Applications to PDEs, Kovachki et al., JMLR 2023\n[2] Discretization-invariance? On the Discretization Mismatch Errors in Neural Operators, Gao et al., ICLR 2025\n\nCould you clearly explain how your analysis provides new insight beyond these works? In particular, is the aliasing perspective quantitatively novel, or primarily a reinterpretation of previously reported resolution-mismatch failures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sAeulsy8PW", "forum": "hkF7ZM7fEp", "replyto": "hkF7ZM7fEp", "signatures": ["ICLR.cc/2026/Conference/Submission21372/Reviewer_eXr2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21372/Reviewer_eXr2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761493662938, "cdate": 1761493662938, "tmdate": 1762941728300, "mdate": 1762941728300, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper validates the ability of trained MLOs to generalize beyond their training resolution and shows that accurate zero-shot multi-resolution inference is unreliable.\n\nThey find that neither approach, incorporating physics-informed constraints during\ntraining and performing band-limited learning, enables reliable multi-resolution generalization.\n\nAlso, the authors propose and test multi-resolution training, where they include training data of varying\nresolutions (in particular, a small amount of expensive higher-resolution data and a larger\namount of cheaper lower-resolution data)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. They systematically analyze the zero-shot multi-resolution abilities of FNO (Fourier Neural Operator) with several methods including resolution interpolation and information extrapolation\n\n2. The paper visualizes the results and their findings clearly which leads to better readability of the paper."}, "weaknesses": {"value": "1. The paper does not show how the findings in the paper can be applied to real applications including deep learning-based training/inference."}, "questions": {"value": "1. How the findings in the paper can be applied to the real-world problem?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "MWbzVHFaLv", "forum": "hkF7ZM7fEp", "replyto": "hkF7ZM7fEp", "signatures": ["ICLR.cc/2026/Conference/Submission21372/Reviewer_2rDL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21372/Reviewer_2rDL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886605774, "cdate": 1761886605774, "tmdate": 1762941727894, "mdate": 1762941727894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper interrogates the widely circulated claim that mesh‑invariant machine‑learned operators (MLOs)—notably Fourier Neural Operators (FNOs)—can do zero‑shot multi‑resolution inference: train on one grid and generalize to higher (or lower) resolutions without additional data. It decomposes the problem into two behaviors: resolution interpolation (same frequency content, new sampling rate) and information extrapolation (same sampling rate, new frequency content). Carefully controlled experiments on Darcy (2D), Burgers (1D), and incompressible Navier–Stokes (2D) from PDEBench reveal that FNOs fail at both: residual energy spectra spike exactly in bands that should remain quiet under the experimental controls, evidencing aliasing; artifacts grow through time‑rollouts for Navier–Stokes. “Zero‑shot fixes”—adding physics‑informed losses or adopting band‑limited approaches (CNO, CROP)—do not rescue multi‑resolution generalization: physics terms usually hurt, and band‑limited models fit low frequencies but drop high‑frequency content by design. The authors then propose a simple multi‑resolution training recipe (mix mostly low‑res with a small fraction of high‑res), documenting a favorable cost–accuracy Pareto front across tasks. Figures and appendices provide spectral diagnostics, max‑modes ablations, and resolution×resolution heatmaps that collectively undermine the zero‑shot super‑resolution narrative and replace it with an actionable practice."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Good conceptual framing: Separating resolution interpolation from information extrapolation clarifies why “train low, test high” fails and grounds the evaluation in sampling theory.\n\nRigorous diagnostics: Normalized residual energy spectra consistently reveal aliasing when resolution or frequency content shift, time‑rollout visuals show error compounding in Navier–Stokes.\n\nBreadth of evaluation: Three canonical PDEs, systematic train/test grids, and resolution×resolution loss heatmaps; max‑modes ablations show failures persist across spectral truncation choices.\n\nActionable guidance: Multi‑resolution training (mostly low‑res + some high‑res) improves robustness with modest cost, forming a clean Pareto front between average data size and error.\n\nThe study complements claims of discretization invariance in operator learning (FNO, DeepONet, mesh‑invariant variants) and recent aliasing/anti‑aliasing discussions by providing decisive, controlled counter‑evidence and a practical alternative."}, "weaknesses": {"value": "1. Most conclusions rest on FNO (plus CNO/CROP wrappers). Including non‑Fourier operator learners (e.g., DeepONet/U‑NO/multiwavelet or graph‑kernel operators) would better support claims that span “MLOs” broadly.\n\n2. Results appear single‑seed without confidence intervals or standard deviation reporting, negative conclusions look stable but would benefit from variance reporting across seeds and data resamplings.\n\n3. In turbulence, band‑limited methods can achieve competitive MSE while failing spectrally; adding physics‑aware diagnostics (e.g., enstrophy/energy spectra errors, divergence) would clarify practical significance.\n\n4. While max‑modes are ablated, there is no explicit test of antialiased nonlinearity/resize operations (well‑known in vision/GANs) inside FNO blocks; this could disentangle architecture‑ vs. data‑pipeline‑driven aliasing.\n\n5. The study focuses on resolution/frequency shifts; it would be useful to probe parameter OOD (e.g., viscosity/forcing) to test whether the proposed multi‑resolution recipe transfers to broader distribution shifts.\n\n6. There is a qualitative data‑size vs. epoch‑time trend, but a more explicit accounting (wall‑clock, memory, FLOPs) for the zero‑shot baselines vs. multi‑resolution training would sharpen the practical trade‑offs."}, "questions": {"value": "1. Evaluation is limited primarily to Fourier-based operator architectures. Including at least one non-Fourier, mesh-invariant operator (e.g., DeepONet, U-NO, or multiwavelet neural operator) would strengthen the generality of the findings and demonstrate whether the observed zero-shot failure modes persist across different operator families.\n\n2.  For the Navier–Stokes experiments, additional quantitative diagnostics—such as errors on enstrophy, energy spectra, or divergence and conservation measures—are needed to clarify the apparent discrepancy between low mean-squared error and degraded spectral fidelity in band-limited models.\n\n3. An explicit investigation of anti-alias filtering around nonlinearities, or of antialiased up-/down-sampling within the operator pipeline, can determine whether the reported interpolation and extrapolation failures are due to architectural aliasing rather than inherent data-distribution shifts.\n\n4. The study shows that physics-informed losses underperform across weighting choices. Testing alternative formulations—such as residual-only constraints, adaptive weighting or curriculum schemes, or discretization-matched residuals—could be informative to rule out optimization artifacts and isolate the underlying cause of this degradation.\n\n5.  Reporting mean ± standard deviation across multiple random seeds for key figures and tables, together with an ablation of the low-/high-resolution data ratios in the multi-resolution training protocol, are needed for more robust evidence and practical guidance for determining data-budget trade-offs.\n\n6. It remains unclear whether the proposed multi-resolution training improves robustness to out-of-distribution conditions beyond discretization changes, such as shifts in physical parameters (e.g., viscosity, forcing, boundary conditions). \n\n7.  Public release of scripts for generating controlled low-pass and resampled datasets, computing normalized residual spectra, and reproducing the reported Pareto-front trade-off plots are required for areproducibility and transparency."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "acay5zsmcQ", "forum": "hkF7ZM7fEp", "replyto": "hkF7ZM7fEp", "signatures": ["ICLR.cc/2026/Conference/Submission21372/Reviewer_MdwW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21372/Reviewer_MdwW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931005084, "cdate": 1761931005084, "tmdate": 1762941727529, "mdate": 1762941727529, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper empirically investigates whether Machine-Learned Operators (MLOs) can reliably generalize across different resolutions when modeling Partial Differential Equations (PDEs), a capability often referred to as zero-shot super-resolution or sub-resolution. Through well-structured experiments covering interpolation, extrapolation, and super-resolution scenarios, the authors demonstrate that Fourier Neural Operators (FNOs) consistently fail when evaluated at unseen resolutions, largely due to aliasing and out-of-distribution effects. The study further shows that physics-constrained optimization and band-limited training, do not address these issues. As a mitigation strategy, the authors propose a simple multi-resolution training protocol, which substantially improves accurate results but still falls short under severe resolution mismatches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "It is clearly written, well-structured, and addresses an important yet often overlooked question in the MLOs. The authors effectively decompose the problem into resolution interpolation, information extrapolation, and both, providing a rigorous framework for analysis. The work’s key contribution lies in extensive empirical evaluation under different settings."}, "weaknesses": {"value": "While the title refers broadly to “Machine-Learned Operators (MLOs),” the experiments primarily focus on the FNOs. Given that FNOs represent only one class of MLO architectures, extending the analysis or discussion to other operator-learning models would help clarify how general these findings truly are."}, "questions": {"value": "- A single consolidated table summarizing final model configurations (e.g., number of modes, hidden dimensions, etc.) for each dataset would improve clarity and ease of implementation.\n\n- Since aliasing is highly sensitive to data resampling, the paper should more clearly specify the interpolation and filtering operations used in generating different resolutions.\n\n- While the empirical evidence is compelling, the paper would benefit from a brief theoretical discussion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "93TTDz79XK", "forum": "hkF7ZM7fEp", "replyto": "hkF7ZM7fEp", "signatures": ["ICLR.cc/2026/Conference/Submission21372/Reviewer_am35"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21372/Reviewer_am35"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762063531172, "cdate": 1762063531172, "tmdate": 1762941727224, "mdate": 1762941727224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}