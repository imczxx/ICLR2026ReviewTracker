{"id": "FIn2pl238r", "number": 21605, "cdate": 1758319567624, "mdate": 1759896912758, "content": {"title": "WaveDiffusion: Joint Latent Diffusion for Physically Consistent Seismic and Velocity Generation", "abstract": "Full Waveform Inversion (FWI) is a critical technique in subsurface imaging, aiming to reconstruct high-resolution subsurface properties from surface measurements. Acoustic FWI involves two physical modalities, seismic waveforms and velocity maps, which are governed by the acoustic wave equation. Prior works primarily focus on the inverse problem, modeling the relationship between seismic and velocity as an image-to-image translation task. In this work, we study their relationship from a generative perspective. Our aim is to explore and characterize the latent space structure, and identify latent vectors that generate seismic–velocity pairs consistent with the governing partial differential equation (PDE). Specifically, we model seismic and velocity data jointly from a shared latent space via a diffusion process. In experiments, we find that diffusion progressively refines arbitrary latent vectors into ones that yield approximately physics-consistent seismic–velocity pairs, even without explicit physics constraints. This provides empirical evidence of PDE-consistency in latent diffusion, where sampling is biased toward PDE-valid solutions. In latent space, satisfying the acoustic wave equation can be approximated through sampling and gradient descent. We formalize this physics-consistent latent modeling task and quantify it through extensive experiments. On large-scale OpenFWI benchmarks, our approach produces high-fidelity, diverse, and physically consistent seismic–velocity pairs, demonstrating the potential of a data-driven latent diffusion for physically consistent generation in a complex scientific domain.", "tldr": "", "keywords": ["Full Waveform Inversion", "Joint Diffusion", "Physics Consistent", "Deviation from PDE"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d59ab8981e37b50981b36b9e646465fc293dad3b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces WaveDiffusion, a diffusion-based framework for FWI that jointly models seismic waveforms and subsurface velocity maps through a shared latent diffusion process. Unlike traditional inversion methods that treat FWI as a deterministic image-to-image translation, WaveDiffusion learns a latent space where both modalities satisfy the acoustic wave equation, ensuring physical consistency between generated pairs. The model uses a two-stage design: first, and encoder-decoder establishes a shared latent representation; second, a joint diffusion model refines latent samples toward PDE-consistent solutions without explicit physical constraints. Experiments on the OpenFWI benchmark show that the approach yields high-fidelity, diverse, and physically valid seismic-velocity pairs, improving upon state-of-the-art models like BigFWI-B in both reconstruction accuracy and generalization. Furthermore, the generated data enhances the training of supervised inverse models, demonstrating that latent diffusion inherently encodes physics-aware structure, providing a promising bridge between generative AI and scientific modeling."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides comprehensive experimental validation, comparing the proposed approach across multiple settings, and visualizing the progressive process, demonstrating its robustness and consistency.\n\n2. The method effectively refines latent representations through a progressive diffusion process, offering new insights into how latent diffusion can enforce physical consistency in high-dimensional scientific data."}, "weaknesses": {"value": "1. The approach appears to require retraining when observed geometries differ from those used in training, which may limit its applicability in real-world seismic scenarios with varying acquisition setups. \n\n2. As acknowledged by the authors, the method lacks a theoretical guarantee for PDE satisfaction or convergence to physically consistent solutions. To strengthen the work, the authors should include comparisons or at least a discussion with related diffusion-based inverse modeling studies, such as [1], which address theoretical and empirical aspects of physics-constrained diffusion. \n\n[1] H. Zheng, et. al., InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences, ICLR, 2025."}, "questions": {"value": "1. While the framework performs well on FWI, could the authors clarify why the study focuses exclusively on seismic inversion rather than extending the approach to other physics-based forward/inverse problems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ai7dIwdnZU", "forum": "FIn2pl238r", "replyto": "FIn2pl238r", "signatures": ["ICLR.cc/2026/Conference/Submission21605/Reviewer_7gNb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21605/Reviewer_7gNb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761576123419, "cdate": 1761576123419, "tmdate": 1762941852032, "mdate": 1762941852032, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "WaveDiffusion is a way to improve the joint distribution of seismic and velocity images that is learned by autoencoder-style image-to-image solvers (which map from seismic images to velocity images). Specifically, a diffusion model is trained in the latent space. The authors find that sampling from the latent diffusion model gives more physically-consistent (in terms of PDE agreement) samples than sampling from the original learned latent space. In their experiments, the authors show that WaveDiffusion can improve the performance of BigFWI-B, a state-of-the-art network for full waveform inversion. They also show that synthetic data generated with WaveDiffusion can help improve the performance of FWI models on challenging datasets."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The proposed method is sound and appears to generally give more physically consistent samples than the original latent space of a FWI network."}, "weaknesses": {"value": "* The authors only compare to BigFWI-B and are missing a diffusion-model-based baseline. See InverseBench (Zheng et al. ICLR 2025) for a comparison of state-of-the-art diffusion inverse solvers on the FWI task. According to their findings, DiffPIR (Zhu et al. ICCV 2023) would give the most accurate results. It is important to compare to a diffusion-based baseline since it is hard to tell whether WaveDiffusion is the best way to utilize a diffusion model for this problem. \n* I struggle to understand one of the main motivations of the paper, which is that “most latent points do not correspond to PDE solutions.” First, it would be good to quantify this claim by sampling many times from the original distribution and reporting the percentage of samples that satisfy the PDE solution (within some error tolerance). Second, the original latent distribution was specifically trained for the task of inversion, so I wouldn’t expect it to perform particularly well for unconditional generation anyways. Perhaps I am missing something about why we should expect the inversion network to give a good generative distribution.\n* According to Figure 2, there are some datasets where WaveDiffusion doesn’t improve upon BigFWI-B. It would be good for the authors to discuss why some of these datasets might be more challenging.\n* In general a lot of the figures could use more explanation. For Figure 3, I guess the point is that the stage 2 velocity is better than the stage 1 velocity, but it’s hard to tell that by just looking at the image. For Figure 6, showing the entire t-SNE plot does not seem to be necessary, unless the authors can comment on any interesting features of the t-SNE plots themselves.\n* I do not understand the point of Figure 5. It doesn’t seem to be either surprising or concerning that deviation from the PDE would be large at high noise levels. The important thing is whether the PDE deviation is low at a near-zero noise level.\n* The authors claim that diffusion models implicitly guide samples to be PDE-compliant. It would be nice if they could offer some explanation as to why this might be the case."}, "questions": {"value": "* Please comment on why we should expect the latent distribution of an inversion network to perform well for unconditional generation.\n* Please compare your method to another plug-and-play diffusion-based inverse solver (see InverseBench for methods that were successfully applied to FWI).\n* Please comment on why the experiment on PDE deviation vs. diffusion noise level is useful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2hVVaUXPdr", "forum": "FIn2pl238r", "replyto": "FIn2pl238r", "signatures": ["ICLR.cc/2026/Conference/Submission21605/Reviewer_zkSB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21605/Reviewer_zkSB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869615884, "cdate": 1761869615884, "tmdate": 1762941851671, "mdate": 1762941851671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes WaveDiffusion, a joint latent diffusion framework for generating physically consistent seismic-velocity pairs in Full Waveform Inversion. While the empirical observation that diffusion refines latent codes toward PDE-consistent solutions is interesting, the work suffers from unsubstantiated claims about physical consistency, lacks ML novelty beyond applying standard latent diffusion, uses unrealistically small synthetic datasets, and makes conclusions that overreach what the results actually demonstrate."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "Writing is mostly clear"}, "weaknesses": {"value": "- The paper repeatedly claims generated pairs \"satisfy the governing PDE\" but only measures L2 distance between decoded seismics and finite-difference solutions, which remains non-trivial (0.002) even after diffusion. No rigorous definition of what constitutes \"satisfying\" the PDE is provided, and the threshold ε in the validity criterion is never specified or justified.\n\n- The approach is a straightforward application of VQ-VAE + latent diffusion (Rombach et al. 2022) to paired seismic-velocity data. The only architectural modification is adding a second decoder branch, which is a trivial extension. No new diffusion techniques, training objectives, or theoretical insights are contributed.\n\n- All experiments use synthetic OpenFWI data (400K samples) with simple geological structures and perfect acoustic assumptions. Real seismic data involves noise, complex elastic wave propagation, acquisition artifacts, and missing low frequencies—none of which are addressed. The elastic FWI experiment (Appendix A.4) uses only a single subdataset (6K samples), making generalization claims unjustified.\n\n- The claim that diffusion \"implicitly evaluates the latent space\" and \"naturally enforces physical consistency\" is not supported. The model is trained purely on data pairs without any physics loss or PDE constraints, so any PDE adherence is correlation from data distribution, not causal enforcement. The paper conflates sampling from a learned data distribution with satisfying physical laws.\n\n- The BigFWI-B baseline is described as having \"approximately aligned\" training volume and parameters (24M vs 19M), but details on training procedures, data augmentation, and hyperparameter tuning for fair comparison are missing. The Stage 2 diffusion refinement for FWI (Section 3.3) uses a cherry-picking procedure (selecting best of 100 samples per denoising step) that is computationally prohibitive and not practical.\n\n- Table 2 shows models trained purely on generated data significantly underperform those trained on real data (e.g., CVB: 0.2030 vs 0.0933 MAE), indicating the generated samples are far from matching real data distribution despite low FID scores. This contradicts claims about high-fidelity generation and raises questions about what FID actually measures in this domain.\n\n- The comparison between 1VQ and 2VQ configurations (Table 1) lacks explanation of why shared codebooks improve physical consistency. The interpolation/random sampling experiments (A.3) are relegated to the appendix and don't clearly separate the effects of distribution mismatch vs. inherent decoder limitations. No analysis of what latent dimensions encode physical vs. spurious correlations.\n\n- The paper states prior work focuses on \"inverse problems\" while this work takes a \"generative perspective,\" but doesn't articulate why jointly generating both modalities is a meaningful task. Real FWI applications need to invert seismic-velocity, not generate paired synthetic data. The physics-consistent latent modeling task (Section 2.1) is formalized but its practical utility beyond data augmentation is unclear.\n\n- The two-stage training requires first training a VQ-VAE encoder-decoder (8000 GPU hours on 128 GH200 GPUs) then training a diffusion model (12000 GPU hours), totaling ~20,000 GPU hours for 400K samples. Scaling to realistic 3D seismic volumes (currently 2D cross-sections) or real field data would be computationally prohibitive, yet no discussion of computational costs, inference time, or scalability limitations is provided.\n\n- The paper uses imprecise language (e.g., \"emergent property,\" \"implicitly biases,\" \"sparse subset\") without quantification. Figure 1's caption claims diffusion maps \"non-solution points (gray squares in valleys) to valid solutions (colored stars at peaks)\" but this visualization is metaphorical and not derived from actual analysis. The completeness and PDE satisfaction properties (Section 2.1) are introduced but never rigorously evaluated in experiments."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cnUZykIgVM", "forum": "FIn2pl238r", "replyto": "FIn2pl238r", "signatures": ["ICLR.cc/2026/Conference/Submission21605/Reviewer_mNJb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21605/Reviewer_mNJb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922632345, "cdate": 1761922632345, "tmdate": 1762941851419, "mdate": 1762941851419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}