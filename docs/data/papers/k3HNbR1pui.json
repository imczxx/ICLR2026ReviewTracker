{"id": "k3HNbR1pui", "number": 7286, "cdate": 1758014308362, "mdate": 1759897861872, "content": {"title": "The Price of Explainability for Kernel $k$-means", "abstract": "The explainability of the machine learning model has received increasing attention recently for security and model reliability reasons. Recently, there has been a surge of interest in interpreting the clustering results of $k$-means and kernel $k$-means algorithms. In this paper, we study explainable kernel clustering and compare the explainable performance of kernel $k$-means algorithms based on different kernels. In particular, we show that kernel $k$-means clustering with the Laplacian kernel has lower price of explainability than that with the Gaussian kernel, which is consistent with the experimental findings of \\citet{fleissnerexplaining}. In addition, we propose a new kernel $k$-means interpretability algorithm that directly constructs a dual-threshold tree in the original space to achieve interpretable kernel $k$-means, and experimentally show that it outperforms KIMM, which constructs the threshold tree in the kernel space.", "tldr": "", "keywords": ["kernel  $k$-means", "explainable clustering", "threshold tree"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/40371fc6491ea65dd0510310eccf8e53bb97e228.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the Price of Explainability for kernel k-means clustering. It systematically analyzes the trade-off between explainability and clustering performance across different kernel functions, with a particular focus on the Gaussian kernel and Laplacian kernel. The authors propose a novel \"Dual-Threshold Tree (DT²)\" algorithm that enables the direct construction of interpretable clustering models in the original space without kernel approximation. Theoretical and experimental results demonstrate that kernel k-means based on the Laplacian kernel incurs a lower explainability cost, and the DT² algorithm outperforms the existing KIMM method on multiple datasets. The study further reveals the intrinsic connections between the Laplacian kernel and k-medians, as well as between the Gaussian kernel and k-means, thereby providing a new perspective for interpretable clustering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Strong Innovation: It is the first study to systematically analyze the \"Price of Explainability\" of different kernel functions from both theoretical and experimental perspectives, and proposes the DT² algorithm to reduce interpretability loss.\n\n2. Tight Integration of Theory and Experiment: The paper verifies findings through rigorous theorem derivation and experimental evidence, achieving high consistency between theoretical results and experimental outcomes.\n\n3. High Method Practicality: The DT² algorithm eliminates the need for kernel approximation, enabling direct construction of interpretable models in the original space and demonstrating good scalability.\n\n4. Novel Research Perspective: It reveals the connections between the Laplacian kernel and k-medians, as well as between the Gaussian kernel and k-means, expanding the theoretical framework for clustering interpretability."}, "weaknesses": {"value": "1. Insufficient Discussion on Limitations: It only analyzes three types of kernels (linear, Gaussian, and Laplacian) and fails to conduct an in-depth exploration of other kernel functions (e.g., neural tangent kernel).\n\n2. Overly Strong Theoretical Assumptions: Some theorems rely on ideal conditions, such as \"the existence of an invertible center or order-preserving points,\" which may be difficult to satisfy in real-world data.\n\n3. Limited Experimental Scale: The verification is only carried out on five small-to-medium-sized datasets, lacking tests in large-scale and high-dimensional scenarios."}, "questions": {"value": "1. Experiments only selected five small-scale datasets. Have you tested high-dimensional or real-scenario data (such as images or text), and do the results remain consistent?\n\n2. The DT² algorithm constructs a dual-threshold tree in the original space to avoid kernel approximation. How does its time complexity compare to that of the KIMM method?\n\n3. The theorem assumes the \"existence of order-preserving points\". Is this condition verifiable or approximately satisfiable in the distribution of actual high-dimensional data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KStzPtcgMQ", "forum": "k3HNbR1pui", "replyto": "k3HNbR1pui", "signatures": ["ICLR.cc/2026/Conference/Submission7286/Reviewer_tfcv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7286/Reviewer_tfcv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7286/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761382624117, "cdate": 1761382624117, "tmdate": 1762919410957, "mdate": 1762919410957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies approximation guarantees for decision trees in clustering with kernel $k$-means. The guarantees are given in terms of the ratio between the clustering cost of a tree, and the optimal cost. This ratio is referred to as the price of explainability (POE). The paper begins by stating the POE for the linear kernel, which reduces the problem to $k$-means. Then, the paper introduces assumptions on the data distribution to derive bounds on the POE. Firstly, it is assumed that the cluster mean in the RKHS has a pre-image in the input space. Secondly, the authors introduce the notion of order-preserving points. For both, the POE is claimed to be $\\mathcal{O}(k \\ln \\ln k)$ for the Gaussian kernel. Thirdly, if such points do not exist, the cost is claimed to depend on and the radius of the dataset. According results are derived for the Laplace kernel. Finally, the paper proposes a greedy cost-minimizing algorithm and evaluates it on a few datasets."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Studying kernel clustering and its interpretability under assumptions on the distribution is interesting, as is the notion of order-preserving points."}, "weaknesses": {"value": "The paper lacks clarity and I have concerns regarding the theory.\n\n(1) The notion of an interpretable threshold tree is not formally defined. The paper probably takes the same notion of axis-aligned trees as in prior works, but this should be formalized.\n\n(2) For the Gaussian or Laplace kernel, there can never exist a pre-image for cluster means unless all points in a cluster are identical. \nProof: Take any \n$(x_i)_{ i=1,\\ldots,n}$. \n\nThen, with $\\psi$ denoting the feature map, the mean in RKHS is $\\mu = \\frac{1}{n} \\sum_{i=1}^n \\psi(x_i)$. Therefore, $\\|\\mu\\|^2 = \\frac{1}{n^2} \\sum_{i,j=1}^n \\kappa(x_i, x_j) < 1$. However, for any $\\rho$ in the input domain, $\\| \\psi(\\rho)\\| = \\kappa(\\rho,\\rho) = 1$. Unfortunately, this makes a relevant part of the theory void.\n\n(3) For the case of order-preserving points, the proof of Theorem 3.6 is confusing (Appendix H). Essentially, the proof starts with $(I) = \\sum_j \\sum_x \\| \\psi(x) - \\mu_j \\|^2$, and upper bounds it by $(II) = c \\cdot \\mathcal{O}(k \\ln \\ln k) \\cdot cost_{opt}$. Unless I am missing something, $(I)$ is already the cost of clustering w.r.t. the means in RKHS, not the cost of clustering with a tree. It is not apparent where in the proof a tree is analyzed. Furthermore, the term $\\mathcal{O}(k \\ln \\ln k)$ appears in several derivations without justification.\n\n(4) The paper also mentions the cost of explainability. How does it give us insight into the price, as alluded to after Theorems 3.7 and 3.8?\n\n(5) It is not clear how order-preserving points would be found in practice, or what are natural conditions for them to exist."}, "questions": {"value": "See questions in weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PirPiXodXs", "forum": "k3HNbR1pui", "replyto": "k3HNbR1pui", "signatures": ["ICLR.cc/2026/Conference/Submission7286/Reviewer_ThGX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7286/Reviewer_ThGX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7286/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761630266249, "cdate": 1761630266249, "tmdate": 1762919410419, "mdate": 1762919410419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the price of explainability in kernel k-means clustering. The authors theoretically analyze explainability costs under linear, Gaussian, and Laplacian kernels with and without bijective or order-preserving points. Furthermore, the paper introduces DT2 ,  avoiding kernel approximations used in KIMM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces two concepts, Bijective Center and Order-Preserving Points, in the explainability analysis of kernel k-means, which are used to examine the mapping relationship between the RKHS and the original feature space.\n2. The proposed Dual-Threshold Tree (DT2) algorithm is a direct improvement over KIMM."}, "weaknesses": {"value": "1. The paper would benefit from a clearer articulation of its research motivation. Clarifying whether the primary aim is to enhance the performance or the explainability of kernel k-means would help readers better appreciate the contribution and positioning of the work.\n2. The logical flow of the writing could be further refined. Introducing the concept of kernel k-means explainability before discussing the explainability cost, and explicitly connecting this analysis to the proposed Dual-Threshold Tree algorithm, would make the overall narrative more coherent and accessible.\n3. The discussion on explainability itself could be further deepened. While the paper focuses on the price of explainability, it provides limited theoretical insight into what constitutes a “good” or “faithful” explanation. A more explicit exploration of how the proposed method enhances or measures explainability would be highly valuable and is something the community would look forward to seeing.\n4. While the current experimental results show modest improvements, especially in Figure 5, the study presents a promising foundation. A deeper investigation into scenarios or datasets where the Dual-Threshold Tree can achieve more pronounced gains would strengthen the empirical impact of the paper.\n5. The experimental evaluation could be expanded to better illustrate the interpretability advantages of the proposed method. Including visualizations of explanation results or quantitative comparisons (e.g., Rand index against ground truth) would enrich the assessment of explanation quality.\n6. The contribution could be further broadened. Although the paper builds thoughtfully on “Explaining Kernel Clustering via Decision Trees,” extending the theoretical analysis beyond Gaussian and Laplacian kernels—such as to dot-product, polynomial, or other translation-invariant kernels—would make the findings more comprehensive and impactful."}, "questions": {"value": "1. The feature mapping of an RKHS is not always invertible. When the feature mapping of kernel k-means is non-invertible, how does the analysis based on Bijective Centers and Order-Preserving Points still apply?\n2. For kernel functions without explicit feature mappings other than the Gaussian kernel, how can their Bijective Centers be identified?\n3. Line 160: What are the specific expressions for cost(T, X) and minT(T, X)?\n4. The experiments are conducted only on low-dimensional and small-scale datasets. Can DT2 be applied to high-dimensional features and large-scale datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}, "details_of_ethics_concerns": {"value": "No ethics review needed."}}, "id": "TvoQlJGvTH", "forum": "k3HNbR1pui", "replyto": "k3HNbR1pui", "signatures": ["ICLR.cc/2026/Conference/Submission7286/Reviewer_iUgn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7286/Reviewer_iUgn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7286/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761676287429, "cdate": 1761676287429, "tmdate": 1762919409915, "mdate": 1762919409915, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The explainability of the machine learning model has received increasing attention recently for security and model reliability reasons. This paper studies explainable kernel clustering and compares the explainable performance of kernel k-means algorithms based on different kernels. In particular, this paper shows that kernel k-means clustering with the Laplacian kernel has a lower price of explainability than that with the Gaussian kernel. In addition, this paper proposes a new kernel k-means interpretability algorithm that directly constructs a dual-threshold tree in the original space to achieve interpretable kernel k-means, and experimentally shows that it outperforms KIMM, which constructs the threshold tree in the kernel space."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The structure of the paper is relatively clear, though the writing quality is slightly lacking. \n2. The theoretical derivation and proof in the paper are quite thorough. \n3. The interpretability of KKM represents a promising research direction with significant academic value."}, "weaknesses": {"value": "1. There are punctuation errors and typos in the formula expressions. \n2. The experimental section is excessively simplistic, and the datasets used are almost toy datasets with a tiny data scale. \n3. Compared with KIMM, the performance or price improvement of the proposed method is very minimal and marginal.\n4. I believed that the paper fails to adequately elaborate on how the interpretability of KKM should be explained and how it can guide kernel clustering algorithms. In terms of the paper’s contributions, the first one is not sufficient to be listed independently; the second merely involves calculations and derivations; the third is a simple algorithmic illustration. Overall, this paper significantly lacks innovation and is not qualified for publication in ICLR."}, "questions": {"value": "As above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "C9qInQRTvT", "forum": "k3HNbR1pui", "replyto": "k3HNbR1pui", "signatures": ["ICLR.cc/2026/Conference/Submission7286/Reviewer_sfxZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7286/Reviewer_sfxZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7286/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762416090978, "cdate": 1762416090978, "tmdate": 1762919409577, "mdate": 1762919409577, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}