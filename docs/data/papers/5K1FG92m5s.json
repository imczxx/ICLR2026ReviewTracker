{"id": "5K1FG92m5s", "number": 14878, "cdate": 1758244973569, "mdate": 1763683539260, "content": {"title": "The Hidden Lattice Geometry of LLMs", "abstract": "We uncover the hidden lattice geometry of large language models (LLMs): a symbolic backbone that grounds conceptual hierarchies and logical operations in embedding space. Our framework unifies the Linear Representation Hypothesis with Formal Concept Analysis (FCA), showing that linear attribute directions with separating thresholds induce a concept lattice via half-space intersections. This geometry enables symbolic reasoning through geometric meet (intersection) and join (union) operations, and admits a canonical form when attribute directions are linearly independent. Experiments on WordNet sub-hierarchies provide empirical evidence that LLM embeddings encode concept lattices and their logical structure, revealing a principled bridge between continuous geometry and symbolic abstraction.", "tldr": "We uncover the hidden lattice geometry of LLMs, showing that linear attribute directions induce concept lattices that support symbolic reasoning via meet and join operations", "keywords": ["Interpretability", "formal concept analysis", "language models", "ontology"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a59c97a9d0b5470ab5de74f57fb94b94bd3c7167.pdf", "supplementary_material": "/attachment/e68301100e4c36c03c78df4cebfa00ef9379a38f.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a novel framework that uncovers a hidden symbolic and logical structure within the continuous embedding spaces of Large Language Models. By bridging the Linear Representation Hypothesis with Formal Concept Analysis (FCA), they demonstrate that linear directions representing attributes can be modeled as separating half-spaces, whose intersections naturally induce a concept lattice. This \"lattice geometry\" provides a principled link between continuous geometry and symbolic abstraction. The paper's primary contributions are threefold: a theoretical framework formalizing this connection, a \"concept algebra\" that defines logical meet (intersection) and join (union) operations directly on embeddings, and strong empirical evidence from WordNet datasets showing that this structure can effectively recover conceptual hierarchies and enable meaningful compositional reasoning. Ultimately, the work suggests that symbolic abstraction is not an emergent accident but a structured geometric property of LLMs, opening new avenues for interpretability and control."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "Originality:\n- The application of formal concept analysis is an ingenious and original idea that seems to provide the missing key to the problem the authors are approaching\n\nClarity: \n- The introduction is very well written and explains what the paper does well, even for someone with very little background in the related work\n\nSignificance:\n- Although I am not familiar with the related work for this paper, it seems like the authors have found a concrete way to unify discrete/symbolic representations with the continuous representation space of LLMs, which has profound implications for both interpretability and AI safety"}, "weaknesses": {"value": "Typos:\n- Line 37: these them\n- Figure 2: Discreate concept lattice\n\nIn general, I think the presentation could use some work:\n- Figure 1 and 2 (especially figure 2) look almost like draft figures, and just by looking at the figures/captions it is hard to understand what they are conveying\n\nFor table 3, it would be good to know how these A and B concept pairs are selected? Are they cherrypicked? Randomly chosen? Are there any failure examples of these join and meet operations?\n\nI think the paper could benefit from more experiments on other words than animals, plants, and food. These are all very concrete and real-world concepts where these concept relations make sense, but how does the framework handle more abstract concepts? If it doesn't handle them well this is fine but should be discussed as a limitation\n\nI also think the paper should provide more discussion on how this method can be used in combination with existing neuro-symbolic/interpretability methods, as well as how the framework might apply to other kinds of concepts (grammatical relationships, etc.)."}, "questions": {"value": "My questions and suggestions are listed in the \"Weaknesses\" section. I just want to make clear that I am open to raising my score if all my weaknesses are addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "g12ahHrvnb", "forum": "5K1FG92m5s", "replyto": "5K1FG92m5s", "signatures": ["ICLR.cc/2026/Conference/Submission14878/Reviewer_hstW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14878/Reviewer_hstW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14878/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760569047354, "cdate": 1760569047354, "tmdate": 1762925227680, "mdate": 1762925227680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new framework for understanding conceptual knowledge in LLMs by unifying the Linear Representation Hypothesis with Formal Concept Analysis (FCA). The central claim is that LLMs implicitly encode a \"lattice geometry.\" In this framework, semantic attributes (e.g., \"can fly\") are represented as linear directions, which define separating half-spaces. Concepts (e.g., \"bird\") are then represented \"intensionally\" as the geometric intersection of these attribute half-spaces (i.e., a convex polyhedral cone).\n\nThis geometric structure naturally induces a concept lattice, allowing for symbolic operations like meet (intersection, e.g., \"bird\" $\\land$ \"predator\" $\\rightarrow$ \"bird of prey\") and join (union/generalization). The authors derive soft, projection-based measures for concept inclusion and these lattice operations. Empirical evidence using WordNet sub-hierarchies demonstrates that attribute directions induce the half-spaces, and that the projection-based inclusion model correlates strongly with the ground-truth WordNet hierarchy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper provides a valuable theoretical connection between the extensional view of concepts and a more structured intensional view based on Formal Concept Analysis (FCA). This shift from \"sets of tokens\" to \"intersections of attributes\" is both compelling and logically sound.\n\nThe experimental results, particularly those reported in Tables 1 and 2, are strong. The high F1 scores provide substantial empirical evidence that the \"half-space\" and \"projection-profile\" models are not merely theoretical constructs, but reflect genuine geometric structure in the models."}, "weaknesses": {"value": "1. Missing Geometric Visualization: The paper’s title and central thesis emphasize \"lattice geometry.\" While Figure 2(b) presents an excellent illustration of this idea, the paper does not provide an equivalent visualization for real, recovered data. We observe 1D projection distributions (Figure 3), but not the actual geometric arrangement of attribute directions and concept embeddings (e.g., via PCA or a similar projection) to visually confirm the half-space intersections. This represents a significant missed opportunity to make the core claim more tangible.\n\n2. Limited Novelty over Existing Frameworks: The paper relies heavily on the foundations laid by Park et al. (2024, 2025). The core idea that a linear direction represents a feature (and thus defines a half-space) is a direct logical consequence of the Linear Representation Hypothesis, as discussed in that prior work. In particular, the vector representation for a single feature in Park et al. (2025) is arguably more precise than the half-space construction. The primary contribution of this paper appears to be the application of Formal Concept Analysis (FCA) as a descriptive label for this pre-existing geometric structure, rather than the discovery of a new structure. The paper does not clearly articulate what new insights are gained by this FCA-based \"intensional\" reframing that were not already present in the \"extensional\" view (Park et al., 2025).\n\n3. Lack of Intervention Experiments: A stronger test of the proposed framework would involve using the lattice geometry for an intervention or model editing task. For example, could the authors construct a representation for a new concept by geometrically performing a meet operation (e.g., meet(bird, live in water)) and then demonstrate that the model can reason about this novel concept? Without such experiments, the work remains descriptive, rather than demonstrating a practical mechanism.\n\n4. Arbitrary Distinction Between 'Attributes' and 'Concepts': The framework relies on a strict distinction between 'attributes' (e.g., 'can fly') and 'concepts' (e.g., 'bird'), which feels somewhat arbitrary. In the linear representation framework (Park et al.), 'bird' could itself be treated as a single feature direction, similar to 'can fly'. The paper does not justify why its 'intensional' view (concepts as intersections of attributes) is fundamentally more valid or distinct from a simpler 'extensional' view, in which 'bird' and 'bird of prey' are simply hierarchical feature directions."}, "questions": {"value": "1. Motivation for Eq. 6 (min/max): Could the authors elaborate on the theoretical motivation for using min/max as the soft measures for meet/join profiles? While this t-norm/co-norm is a standard choice in fuzzy logic, it is unclear how this operation on projection profiles relates to the geometric intersection of half-spaces defined in Definition 7. Why not estimate meet/join directly from the intersection of context embeddings? A more natural alternative might be Eq. (4), applied to the context embeddings for the concepts A $\\land$ B.\n\n2. Quantitative Evaluation of Meet/Join: The paper defines a \"degree of equality\" (Eqs. 8 and 9), but only provides a qualitative evaluation of meet/join in Table 3. Could the authors provide a quantitative evaluation using these metrics? For example, how well does the embedding for \"eagle\" (as concept C) match the deg(C = A $\\land$ B) score, where A = \"bird\" and B = \"predator\"? It is unclear whether this metric demonstrates anything non-trivial, as one might expect high alignment simply from the set-inclusion properties of the underlying hierarchy.\n\n3. Ambiguity in Embedding Definition: To clarify the experimental setup (Section 4.1): What exactly is $\\text{Emb}(s)$? Is it the token unembedding vector $\\gamma(s)$ from the original model, the re-parameterized vector $g(s)$ from the \"unified semantic space\" mentioned in Section 2.1, or some context embeddings $\\lambda(s)$? Additionally, how are synonyms defined, and how were they obtained? More details on the experimental setup would be helpful.\n\n4. Disconnect in Theoretical Machinery: Section 2.1 introduces the 'causal inner product' and 'causal selectivity' (Definition 2) as key preliminaries. Why was the causal inner product used? While it connects the geometry of the space to relationships between concepts, is there any orthogonality theory within the proposed lattice geometry? Furthermore, what was the intended role of Definition 2, and was causal selectivity applied in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d9E3dzOK9e", "forum": "5K1FG92m5s", "replyto": "5K1FG92m5s", "signatures": ["ICLR.cc/2026/Conference/Submission14878/Reviewer_gkW1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14878/Reviewer_gkW1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14878/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786609889, "cdate": 1761786609889, "tmdate": 1762925227256, "mdate": 1762925227256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors unify two perspectives: the linear representation hypothesis from LLM representation literature and formal concept analysis from information science. They describe a useful formal framework which allows one to reason about concept lattices in LLMs and extract them accordingly. The work is novel, very well organized, thorough, and well-motived by the literature. Although the experimental section is rather light (just 3 LLMs and 3 ground truth concept lattices), it is convincing, and the findings support the main theoretical claims made in the paper. Overall, this is a good paper that makes useful contributions and would be of high interest at ICLR. It should be accepted.\n\nMinor Comments:\n\nLine 135 – it would be helpful to introduce the pair (A,B) prior to defining A’ & B’\n\nLine 172 – “Discreate” should probably be “Discrete”"}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "Well organized, thorough treatment of related work and preliminaries, easy to follow, clear\n\nNovel combination of the Linear Representation Hypothesis with a formal, well-defined framework\n\nThe claims introduced in the theoretical section (Section 3) are substantiated by the lattice extraction results from the experiment section (Section 4)\n\nVery good reproducibility information, particularly in section 4.1"}, "weaknesses": {"value": "Limited number of datasets and LLMs used in the evaluation (3 datasets, 3 LLMs)\n\nLittle to no discussion on which types of concepts (e.g., those arranged on a curved manifold such as months of the year or days of the week) could or could not be represented by this framework. Somewhat recent work has indicated that “Not All Language Model Features are One-Dimensionally Linear” (Engels et al 2025)"}, "questions": {"value": "Are there cases of concept structures in LLMs for which this concept hierarchy would not be appropriate?\n\nHow does LLM size impact the ability of LLM representations to match the ground truth lattice? I would think that higher dimensional embeddings would make it easier to extract a clean lattice."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0xX2pbFV5A", "forum": "5K1FG92m5s", "replyto": "5K1FG92m5s", "signatures": ["ICLR.cc/2026/Conference/Submission14878/Reviewer_Ej1E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14878/Reviewer_Ej1E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14878/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761863251557, "cdate": 1761863251557, "tmdate": 1762925226298, "mdate": 1762925226298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes to unify Linear Representation Hypothesis with Formal Concept Analysis to project the discrete symbolic abstraction in a continuous embedding space. The authors formulate a half-space model of concepts and operations based on soft inclusion to introduce a lattice geometry in language models. They empirically evaluate the existence and partial order correlations using WordNet subhierarchical data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. I think the authors are targeting an important and ambitious question to resolve the conflicts between continuous representation space in neural language models and symbolic abstractions. While I am not an expert in the related set theory to judge the rigor and correctness of the framework,  I appreciate the principled approach. \n\n\n2. While limited, the authors attempted to empirically validate their theoretical statements with the controlled dataset. \n\n3. The paper is generally well written, especially the motivation and its contribution are clearly developed."}, "weaknesses": {"value": "1. I am unclear about the WordNet experiment; how exactly is the $v_g$? Is it simply a token-embedding output? While the theoretical framework is presented as a general account of “the hidden lattice geometry of LLMs”, I am concerned that the empirical experiments with WordNet appear to rely exclusively on static token embeddings. It is unclear if the experiment concerns contextual forward passes or layer-wise activations. Consequently, the experiments probe the lexical geometry of the embedding table rather than the representational geometry arising from the LLM’s contextual computations.\nAlso, I think the explanation for soft-inclusion parameters is lacking - what alpha is for the experiment, and how it was chosen. \nThe authors did not discuss the limitations of the framework. \n\n2. The authors did not discuss the limitations of the framework."}, "questions": {"value": "1. Can the framework recover non-hierarchical or cross-cutting concept structures (e.g., color vs. shape in objects)? \n\n2. Could you note the possible correlations between the attributes?\n\nMy score is mostly based on my lack of understanding of the experiment's validity. I’m willing to update my score as authors clarify this point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UlGgQnfxet", "forum": "5K1FG92m5s", "replyto": "5K1FG92m5s", "signatures": ["ICLR.cc/2026/Conference/Submission14878/Reviewer_Lfek"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14878/Reviewer_Lfek"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14878/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999518276, "cdate": 1761999518276, "tmdate": 1762925225870, "mdate": 1762925225870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}