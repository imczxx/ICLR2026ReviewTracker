{"id": "QIN5GrCB7d", "number": 18412, "cdate": 1758287427074, "mdate": 1762973834813, "content": {"title": "GRAPE: Graph Reasoning with Anonymous Path Encoders", "abstract": "Since the introduction of retrieval-augmented generation (RAG), a standard component of large language model (LLM) reasoning pipelines has been the navigation of a knowledge base (KB) to generate answers grounded in retrieved sources. However, recent studies show that LLMs struggle with complex queries requiring deep reasoning and interdependent knowledge, often leading to hallucinations. While several methods have been proposed to mitigate this issue, most rely on multiple additional calls to the LLM to decompose and validate reasoning steps, thereby increasing inference cost and latency. In this paper, we introduce GRAPE (Graph Reasoning with Anonymous Path Encoders), a framework that leverages path encodings over uncertain nodes and relations in knowledge graphs (KGs) to heuristically guide KB navigation. Rather than depending on a fully LLM-native retrieval pipeline, GRAPE replaces repeated model calls with encoder-only models that act as a semantic fuzzy query-matching engine. Experiments across multiple multi-hop QA benchmarks show that GRAPE achieves up to 85% faster inference than LLM-based pipelines, while consistently matching or exceeding state-of-the-art accuracy. These results demonstrate that encoder-only hybrid reasoning pipelines provide a practical and scalable alternative to expensive LLM-native retrieval, combining efficiency, robustness, and strong generalization.", "tldr": "In this paper, we introduce GRAPE, an encoder-only framework for multi-hop QA that replaces extra data navigation calls in LLM-based RAG pipelines with path encodings, matching state-of-the-art accuracy while reducing inference time by up to 85%.", "keywords": ["Question Answering", "Knowledge Driven Reasoning", "Retrieval Augmented Generation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/aacde60a9362e868959821f501e593cacd038f5d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes GRAPE, a knowledge-graph-centric alternative to LLM-agent style KGQA systems. Instead of driving every traversal step through an LLM, GRAPE reformulates reasoning as fuzzy anonymous graph matching: questions are parsed into an Anonymous Knowledge Graph (AKG), then resolved via encoder-only retrieval and completeness classification, with only one final LLM call for aggregation. By offloading traversal entirely to encoders, GRAPE achieves up to 85% faster inference while matching or beating SOTA accuracy on ten KGQA, fact-checking, and open-domain QA datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. It proposes a novel framework that relieves LLMs from the burden of multi-step graph traversal in KGQA tasks with a lightweight path retrieval and classification module.\n2. This approach significantly improves inference efficiency while maintaining or improving accuracy compared to SOTA LLM-agent methods."}, "weaknesses": {"value": "1. Limited novelty: The proposed framework shares similarities with existing retrieval-augmented methods in KGQA by developing a efficient ranking module to select relevant paths from knowledge graphs for expansion. \n2. Limited generalizability: As the path retrieval module is trained specifically for datasets, it may not generalize well to unseen knowledge graphs or domains without retraining or fine-tuning.\n3. Lack of strong baselines: The experiments mainly compare against LLM-agent methods, but do not include strong training-based methods like GNN-based approaches [1,2]. Thus it is unclear how GRAPE compares to these alternatives in terms of accuracy and efficiency.\n4. Lack of ablation studies: The paper does not include ablation studies to analyze the contributions of different components, especially the path retrieval and classification modules. Can we achieve similar performance with some existing retrieval methods like BM25 or dense retrieval like Qwen3-emb/ranker?\n5. Lack of proper metrics: The paper focuses on Hits@1 but does not report other important metrics like F1, which are commonly used in KGQA to evaluate overall answer coverage.\n6. Mis-citations / Incomplete Citations: AdvHotpotQA seems to be mis-cited. RRKG citation is missing. Citations of line 088 is missing.\n\n[1] Mavromatis, Costas, and George Karypis. \"Gnn-rag: Graph neural retrieval for efficient large language model reasoning on knowledge graphs.\" Findings of the Association for Computational Linguistics: ACL 2025. 2025.\n\n[2] Li, Mufei, Siqi Miao, and Pan Li. \"Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation.\" The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "Please see my weaknesses 1-5."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nxPGzAbct6", "forum": "QIN5GrCB7d", "replyto": "QIN5GrCB7d", "signatures": ["ICLR.cc/2026/Conference/Submission18412/Reviewer_TFcT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18412/Reviewer_TFcT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761541655066, "cdate": 1761541655066, "tmdate": 1762928113789, "mdate": 1762928113789, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mbM0UQqjmD", "forum": "QIN5GrCB7d", "replyto": "QIN5GrCB7d", "signatures": ["ICLR.cc/2026/Conference/Submission18412/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18412/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762973833988, "cdate": 1762973833988, "tmdate": 1762973833988, "mdate": 1762973833988, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GRAPE (Graph Reasoning with Anonymous Path Encoders), a framework that leverages path encodings over uncertain nodes and relations in knowledge graphs (KGs) to heuristically guide KB navigation. Rather than depending on a fully LLM-native retrieval pipeline, GRAPE replaces repeated model calls with encoder-only models that act as a semantic fuzzy query-matching engine. Experiments across multiple multi-hop KGQA benchmarks show that GRAPE achieves substantial speedup compared with LLM-based pipelines while achieving state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**S1.** The paper is overall easy to follow.\n\n**S2.** The paper experiments with a large number of datasets.\n\n**S3.** Empirical studies report standard deviations across five runs.\n\n**S4.** The paper performs ablation studies for various components.\n\n**S5.** The paper performs efficiency evaluation in terms of LLM calls and wall clock time."}, "weaknesses": {"value": "**W1.** The paper fails to cite, discuss and / or compare against (verbally or empirically) many highly relevant and impactful works, which is crucial for evaluating the paper's contributions, e.g., novelty of the proposed approach.\n\n- Efficient encoder-based KG retrieval without LLM-based explorations ([1], [2], [3]), which aligns with the idea of encoder-based efficient graph exploration of the proposed approach.\n\n- KG-based RAG with semantic parsing, which generates templates for relation path matching similar to the idea of Anonymous Knowledge Graph Matching. E.g., [4] fine-tunes an LLM to predict anonymized relation paths for matching in the KG, which is very similar to the idea of GRAPE. [5] also employs LLMs like ChatGPT to generate SQL queries for searching over the KG.\n\n- Other related RAG approaches: [6], [7], [8]\n\n[1] He et al. G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering. NeurIPS 2024.\n\n[2] Mavromatis et al. GNN-RAG: Graph Neural Retrieval for Efficient Large Language Model Reasoning on Knowledge Graphs. ACL Findings 2025.\n\n[3] Li et al. Simple Is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation. ICLR 2025.\n\n[4] Luo et al. Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning. ICLR 2024.\n\n[5] Li et al. Chain-of-knowledge: Grounding large language models via dynamic knowledge adapting over heterogeneous sources. ICLR 2023.\n\n[6] Chen et al. Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs. NeurIPS 2024.\n\n[7] Luo et al. Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models. ICML 2025.\n\n[8] Chen et al. PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths. arXiv 2025.\n\n**W2.** The methodology (Section 3.2) discussion assumes that all queries can be represented as anonymous chain graphs while in practice multi-hop queries can have parallel branching substructures, leading to general directed acyclic graphs. How to order sub-queries / anonymous variables in such cases is not discussed at all.\n\n**W3.** The cluster representative selection mechanism can be inferior for sub-queries with multiple valid answers. E.g., which books were authored by XXX.\n\n**W4.** The empirical studies do not consider the F1 metric, which is also widely adopted for KGQA and KG-based RAG evaluation that reflects precision and recall.\n\n**W5.** Minor presentation issues.\n- The format of in-text citations needs to be corrected throughout the paper with proper use of ~\\citep{} and ~\\citet{}. E.g., Petroni et al. (2021) should be (Petroni et al., 2021).\n- There are in-text citations not properly rendered, displayed as \"?\" in the text. E.g., \"retrieval pipelines require repeated LLM calls Chen et al. (2023); Oche et al. (2025); Wang et al. (2024); ?.\""}, "questions": {"value": "**Q1.** How do you combine the scores obtained by the retriever and reranker? The introduction in Section 3.3 is not clear enough.\n\n**Q2.** Why did you not also experiment with alternative KGs like Freebase?\n\n**Q3.** Why not report the efficiency study of RoG in Table 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tL7KOHyZqA", "forum": "QIN5GrCB7d", "replyto": "QIN5GrCB7d", "signatures": ["ICLR.cc/2026/Conference/Submission18412/Reviewer_awUu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18412/Reviewer_awUu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761694876553, "cdate": 1761694876553, "tmdate": 1762928113453, "mdate": 1762928113453, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "For knowledge graph question answering tasks, a method is proposed that uses embeddings to match entities sequentially to find paths, which is faster than existing methods that repeatedly execute using LLM."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The method proposed in the paper indeed shows good consideration for efficiency, and effectively improving efficiency is a significant advancement."}, "weaknesses": {"value": "W1. Limited Methodological Novelty and High Complexity. The proposed method's workflow is highly complex and consists largely of orchestrating existing, pre-trained models, including embedding models and LLMs. This limits its methodological novelty. In fact, prior to the advent of LLMs, many approaches in the Knowledge Graph Question Answering (KGQA) domain employed key steps that are conceptually similar to this method. The proposed approach appears to be more of a hybrid combination of pure LLM-based reasoning and pure embedding-based matching, rather than a fundamentally new framework.\n\nW2. Gaps in Experimental Performance. In terms of experimental results, the proposed method still demonstrates a noticeable performance gap when compared to the current state-of-the-art on several mainstream benchmarks, such as WebQSP, CWQ, and Simple Questions. While it achieves commendable results on some other datasets, its performance on these key, widely-used benchmarks indicates that it has not yet surpassed the leading methods in the field.\n\nW3. Potentially Unfair Experimental Configuration. The paper's use of GPT-4o as the foundation model may create an unfair comparison with existing work. Many prior LLM-dependent methods were benchmarked using earlier, less capable models. This discrepancy makes it difficult to assess the true contribution of the proposed methodology, as a portion of the performance gains may be attributable to the superior capabilities of the more advanced base model rather than the novelty of the method's design itself."}, "questions": {"value": "Q1. Justification for Knowledge Graph-based Answering. The paper needs to better justify the necessity of using a Knowledge Graph (KG) for question answering. Could the questions not be answered directly by a contemporary LLM augmented with web retrieval? It is well-known that many existing KGs contain a significant number of errors. In contrast, modern LLMs already possess vast internal knowledge, and when combined with real-time web search, they may achieve performance that exceeds that of an LLM relying on a potentially flawed KG. I request that the authors respond to this point, ideally by providing experimental results and specific case studies that demonstrate the advantages of the KG-based approach over a strong LLM+retrieval baseline.\n\nQ2. Missing Equation Numbers. The equations presented in the manuscript lack numbering, which makes them difficult to reference and discuss. Please add equation numbers throughout the paper for clarity.\n\nQ3. Flawed Definition of KGQA. The definition of KGQA provided in the equations on lines 153 and 154 appears to be problematic and incomplete. Specifically:\nWhat is the meaning of the expression q \\wedge e = e_k? This notation is unclear.\nThe term e_0 is used without a prior definition. Please clarify what it refers to.\nFurthermore, the formulation seems to imply that KGQA is limited to querying for entities, while ignoring the querying of relations. This appears to be an overly narrow definition of the KGQA task. Please revise and complete this definition.\n\nQ4. Limitations of the Anonymous Entity Solving Approach. While the authors propose the concept of \"anonymous entity solving on a graph,\" this approach does not seem fundamentally different from existing methods where an LLM sequentially determines the entities along a path. More importantly, this method appears to be designed only for scenarios where the entities are uncertain but the relations are known. How would the framework handle the inverse situation, where the relationship itself is uncertain? For example, in a question like, \"What is the relationship between Kobe Bryant and LeBron James?\" the entities are known, but the relation is the object of the query. Additionally, how does the method handle queries that require reasoning over multi-hop relations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0b8qMaCxbA", "forum": "QIN5GrCB7d", "replyto": "QIN5GrCB7d", "signatures": ["ICLR.cc/2026/Conference/Submission18412/Reviewer_TwUU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18412/Reviewer_TwUU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761739605195, "cdate": 1761739605195, "tmdate": 1762928113036, "mdate": 1762928113036, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces graph reasoning with anonymous path encoder (GRAPE) framework, which leverages path encodings over uncertain nodes and relations in the knowledge graphs to heuristically guide KB navigation. To be specific, GRAPE uses encoder-only models to act as a semantic fuzzy query-matching engine. Extensive experiments show the effectiveness of the proposed method."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.\tIntegrating LLMs with KGs is a critical research area.\n2.\tExtensive experiments show the effectiveness of the proposed method."}, "weaknesses": {"value": "1.\tThere may lack some representative recent baseline methods for comparison, such as GNN-RAG-RA [1], SubgraphRAG [2].\n2.\tIt would be beneficial to further refine the figures and tables to enhance readability. For instance, the font size in Figure 1 is relatively small.\n3.\tFor efficient analysis experiments, it would be beneficial to include retrieved-based methods (e.g., RoG) for comprehensive comparison.\n\n\n[1] Mavromatis, Costas, and George Karypis. \"Gnn-rag: Graph neural retrieval for large language model reasoning.\" arXiv preprint arXiv:2405.20139 (2024).\n\n[2] Li, Mufei, Siqi Miao, and Pan Li. \"Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation.\" The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "Please refer to the **weaknesses** section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XWwQQikOrq", "forum": "QIN5GrCB7d", "replyto": "QIN5GrCB7d", "signatures": ["ICLR.cc/2026/Conference/Submission18412/Reviewer_XLQY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18412/Reviewer_XLQY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909306607, "cdate": 1761909306607, "tmdate": 1762928112475, "mdate": 1762928112475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}