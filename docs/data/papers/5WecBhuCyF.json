{"id": "5WecBhuCyF", "number": 25006, "cdate": 1758363056587, "mdate": 1759896738457, "content": {"title": "Curing the Transitivity Curse: Shortcut Logical Reasoning via A Priori Knowledge Compilation", "abstract": "While large language models (LLMs) have shown remarkable reasoning abilities, they often fail at multi-hop logical reasoning tasks that require chaining inferences, struggling to deduce transitive relations like $(P \\to R)$ from $(P \\to Q) \\land (Q \\to R)$. This fundamental limitation, which we term the \\textbf{``Transitivity Curse''}, leads to brittle reasoning chains and significant error propagation. Existing reasoning frameworks, often based on Chain-of-Thought, attempt to traverse these long paths sequentially, a process that is both inefficient and prone to failure as complexity increases. To cure this curse, we introduce a novel mechanism designed to be integrated into existing logical reasoners. Our mechanism shifts the paradigm from passively traversing reasoning chains to proactively compiling them through a process we call \\textbf{A Priori Knowledge Compilation (APKC)}. This process unfolds in two critical phases. First, it employs a goal-oriented backward analysis to identify a focused, relevant subgraph of the knowledge base. Subsequently, within this constrained boundary, our mechanism performs a systematic forward-chaining process to synthesize new knowledge in the form of both foundational \\textbf{derived facts} and powerful \\textbf{composite rules}. This compiled knowledge collapses multi-step inferences into fewer, more robust steps.By allowing a host framework to leverage this compiled knowledge, our mechanism enables a more direct form of \\textbf{Shortcut Reasoning}, drastically reducing the required depth of runtime inference. Experiments show that when integrated into state-of-the-art reasoning frameworks, our mechanism consistently and significantly boosts their performance on several logical reasoning benchmarks. Our findings demonstrate that APKC, as a plug-in mechanism, is a critical component for making existing LLM-based reasoners more robust, efficient, and trustworthy.", "tldr": "Our work introduces a mechanism that performs A Priori Knowledge Compilation—proactively deriving foundational facts and composing powerful new rules—to enable robust Shortcut Reasoning and cure the Transitivity Curse in LLMs.", "keywords": ["Logical Reasoning", "Large Language Models", "Knowledge Compilation"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8e3f771644e66caffb1439f4806c9d9c2f8d2f98.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper identifies the “Transitivity Curse”, referring to the difficulty that large language models (LLMs) face when deducing transitive relations in logical reasoning tasks. To address this, the authors propose APKC, a two-phase approach designed to reduce the search depth of logical reasoning problems. Experimental results demonstrate that APKC improves upon state-of-the-art logical reasoning baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The idea is interesting\n\n- Paper is generally clear and easy to follow."}, "weaknesses": {"value": "- While the motivation and core idea are clear, the writing could be further refined for clarity and emphasis. The key contribution to me is reducing the search space in logical reasoning tasks to achieve conclusions with less computation. I would recommend to state it more explicitly.\n\n- The methodology requires additional clarification. In particular, Sections 4.1 and 4.2 are ambiguous: are these steps performed using LLMs, or implemented through another mechanism?\n\n- Deeper analysis and discussion would enhance the paper, particularly regarding the implications and limitations of the approach.\n\n- Typo:\nLine 42: Graph-of-Thought lacks a citation.\nLines 71–72, 75, and 315: citations are also missing or inconsistent."}, "questions": {"value": "- Are the proposed methods compatible with all reasoning baselines?\n\n- Specifically, can they be integrated with CoT or ToT approaches?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bCkpSVo8la", "forum": "5WecBhuCyF", "replyto": "5WecBhuCyF", "signatures": ["ICLR.cc/2026/Conference/Submission25006/Reviewer_Zciy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25006/Reviewer_Zciy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761213416323, "cdate": 1761213416323, "tmdate": 1762943280324, "mdate": 1762943280324, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces \"Transitivity Curse\", which refers to the hypothesis that LLMs struggle to deduce transitive relations like \"from $(P \\rightarrow Q) \\wedge (Q \\rightarrow R)$ inferring $(P \\rightarrow R)$\". Then it proposes \"A Priori Knowledge Compilation\" (APKC), a process that employs (1) a goal-oriented backward analysis for subgraph identification of a knowledge base and (2) systematic forward-chaining to synthesize new knowledge. It enhances LLMs' reasoning abilities and improves their performance on several logical reasoning benchmarks."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Logical reasoning limitation is an important problem for LLMs both in theory and in practice, and this work aims to improve LLM logical reasoning.\n- The empirical evaluations of this paper are done with several different models and datasets, indicating generality and external validity.\n- The work aims to go beyond performance by analyzing scaling behaviors with reasoning depth."}, "weaknesses": {"value": "- The biggest weakness of this paper is about the notion of Transitivity Curse. The authors claim that LLMs have this problem but do not cite any concrete evidence. Nor do the authors carry out any targeted experiments to confirm the Transitivity Curse hypothesis. As a result, the premise of this work is unsound.\n- I find the writing quality of this work unsatisfactory. There are many missing cites in the paper, represented by empty parentheses and (??). The writing significantly lacks precision. For example, methods like Tree-of-Thoughts (the paper incorrectly uses the singular form) are no longer \"state-of-the-art\" (Sec. 2). In general, many of the sentences seem to lack coherence.\n- Much work has done in the space of LLM and logical reasoning. The Related Work section (Sec. 2) is really incomplete. In fact no single paper from 2025 is cited---this is not acceptable given how much work comes out this year on language models and (logical) reasoning."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Cw0EONHaWE", "forum": "5WecBhuCyF", "replyto": "5WecBhuCyF", "signatures": ["ICLR.cc/2026/Conference/Submission25006/Reviewer_aWyS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25006/Reviewer_aWyS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762166480236, "cdate": 1762166480236, "tmdate": 1762943279692, "mdate": 1762943279692, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a weakness in LLMs called the transitivity curse, the tendency for LLMs to fail at multi-hop logical reasoning tasks that require chaining inferences (e.g., deducing P→R from P→Q and Q→R). The authors propose A Priori Knowledge Compilation (APKC), a plug-in mechanism that transforms reasoning from passive \"path following\" to proactive \"path creation.\"by operateing in two phases:\n1: Priori Relevance Scoping: Uses backward analysis from the query to identify relevant rules, pruning the reasoning space 2: Constrained Shortcut Compilation: Performs forward-chaining to synthesize new derived facts and composite rules that create \"shortcuts\" across the knowledge graph."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The method works as a plug-in for different reasoning frameworks (SymbCoT and Aristotle), demonstrating architectural flexibility."}, "weaknesses": {"value": "1. **Insufficient Literature Review and Positioning**: \n   - The paper lacks comprehensive coverage of recent advances in LLM reasoning. While the term \"Transitivity Curse\" may be novel, the underlying challenge is well-documented in recent literature on proactive reasoning, multi-hop inference, and long-horizon reasoning tasks, none of which are adequately discussed.\n   - The related work section and baseline comparisons are limited to CoT and its variants (Tree-of-Thought, Graph-of-Thought), which represent somewhat dated approaches from 2022-2023. The paper fails to engage with more recent reasoning frameworks and techniques.\n   - Despite mentioning neuro-symbolic methods and external symbolic solvers (e.g., Logic-LM, LINC), the paper provides no empirical comparison with these approaches, leaving a critical gap in understanding how APKC compares to existing solutions that also address multi-hop reasoning challenges.\n\n2. **Limited Novelty and Scope**:\n   - The A Priori Knowledge Compilation approach bears strong resemblance to existing work in agentic memory systems and RAG (Retrieval-Augmented Generation) frameworks, which similarly involve pre-computing knowledge structures and rules for improved reasoning. The paper fails to differentiate its contribution from these established approaches.\n   - The method relies entirely on prompting techniques without exploring how post-training approaches (e.g., fine-tuning, RLHF, or specialized training objectives) could enhance the reasoning capabilities. This represents a missed opportunity to demonstrate deeper integration with model training.\n   - The evaluation is restricted to formal logical reasoning benchmarks, leaving questions about the method's applicability to real-world reasoning tasks, commonsense reasoning, or other domains where transitivity and multi-hop inference are important.\n   - These limitations collectively diminish the paper's novelty and impact, as it appears to be an incremental application of known techniques rather than a fundamental advance in addressing reasoning challenges."}, "questions": {"value": "1. How does APKC scale with knowledge base size? The paper shows results on small benchmarks (300-600 examples), but real-world knowledge bases can contain millions of facts and rules. What is the computational complexity of the exhaustive forward-chaining in Phase 2, and at what point does the compilation become intractable? Please provide runtime analysis and experiments on larger knowledge bases.\n\n2. If LLMs struggle with multi-hop transitive reasoning (the \"Transitivity Curse\"), why should we trust the same LLMs to correctly perform the compilation steps that require similar transitive reasoning? Isn't this circular - using an LLM's reasoning to fix its own reasoning limitations? How do you ensure the compilation process doesn't introduce or propagate errors?\n\n3. How does APKC differ from classical forward-chaining algorithms or modern RAG/memory systems that similarly pre-compute and cache derived knowledge? \n\nAlso, multiple citation formatting errors appear throughout the paper (lines 42, 71, 123) please double check it."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nvnwHT5IqK", "forum": "5WecBhuCyF", "replyto": "5WecBhuCyF", "signatures": ["ICLR.cc/2026/Conference/Submission25006/Reviewer_ZEoX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25006/Reviewer_ZEoX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762567278910, "cdate": 1762567278910, "tmdate": 1762943279409, "mdate": 1762943279409, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors point out that large language models suffer from the \"Transitivity Curse\" in multi-hop logical reasoning—they struggle to deduce P→R from (P→Q)∧(Q→R) and are prone to error accumulation. To address this, it proposes the A Priori Knowledge Compilation (APKC) mechanism. APKC first filters relevant rules through goal-oriented backward analysis, then synthesizes derived facts and composite rules via constrained forward chaining to shorten reasoning chains. Experiments show that when integrated as a plug-in into mainstream reasoning frameworks like SymbCoT, APKC significantly improves performance on five logical reasoning benchmark datasets. The advantage becomes more pronounced as reasoning depth increases, and it is compatible with models of different scales, effectively alleviating the Transitivity Curse."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. In general, the idea is interesting and possibly useful.\n2. The authors introduced a new logic reasoning paradigm."}, "weaknesses": {"value": "1. Lacks of experiments to support the main motivation: the authors strive to solve the problem of Revision Curse, yet this paper lacks of comparisons with the reasoning-related work of current state-of-the-art approaches, and the comparative results with some existing reasoning methods are also unconvincing.\n2. Unclear and incomplete paper writing: there is a lot of places missing appropriate citations, and the quality of the tables is also not very good."}, "questions": {"value": "Please see the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "88zvIwTVnB", "forum": "5WecBhuCyF", "replyto": "5WecBhuCyF", "signatures": ["ICLR.cc/2026/Conference/Submission25006/Reviewer_uoXY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25006/Reviewer_uoXY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25006/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763649788724, "cdate": 1763649788724, "tmdate": 1763649788724, "mdate": 1763649788724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}