{"id": "LdGAtMRJaM", "number": 12074, "cdate": 1758205519638, "mdate": 1763717873016, "content": {"title": "InfoDisent: Explainability of Image Classification Models by Information Disentanglement", "abstract": "In this work, we introduce InfoDisent, a hybrid approach to explainability based on the information bottleneck principle. InfoDisent enables the disentanglement of information in the final layer of any pretrained model into atomic concepts, which can be interpreted as prototypical parts. This approach merges the flexibility of post-hoc methods with the concept-level modeling capabilities of self-explainable neural networks, such as ProtoPNets. We demonstrate the effectiveness of InfoDisent through computational experiments and user studies across various datasets using modern backbones such as ViTs and convolutional networks. While InfoDisent achieves competitive performance within the class of interpretable models, we observe an accuracy-interpretability trade-off when compared to black-box counterparts, especially visible in CNNs. Notably, InfoDisent generalizes the prototypical parts approach to novel domains (ImageNet).", "tldr": "Method transforming any NNs to prototypical parts, also on ImageNet", "keywords": ["interpretability; prototypical parts; XAI"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6176d15d5446b03c05bc2cf838ca73c0b8551d67.pdf", "supplementary_material": "/attachment/4d12793663a8ef705b6d467f46ad07dbd6230ef4.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents InfoDisent, a post-hoc explainability method that disentangles features from a frozen pretrained backbone through an orthogonal decomposition of the channels. The goal is to identify prototypical parts that explain the model's decisions. The paper provides multiple experiments showcasing that the approach is applicable to a wide range of models, from CNNs to Transformer architectures, with classification performance on several datasets. It also includes an evaluation of interpretability on the FunnyBirds dataset and two user studies assessing confidence in predictions and ambiguity in explanations."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- **Significance**: \n\t- The proposed approach is flexible and can be effectively applied to various pretrained backbones, which is a significant advantage over methods limited to specific architectures or that needs to retrain the model.\n\t- The results demonstrate that the method largely preserves the accuracy of the original pretrained backbone, especially compared to some other prototypical part methods.\n- **Originality**: The decomposition into prototypical parts through the orthogonal matrix and its optimization process, is original. The reformulation of the optimization problem using skew-symmetric matrices is clever and an interesting technical contribution, although hidden  and only mentioned in the appendix."}, "weaknesses": {"value": "- **Clarity**: \n\t- The paper's overall structure and clarity needs to be improved. Several key discussions and technical details, such as the full optimization process, are briefly mentioned or only detailed in the appendix. Describing the overall training and optimization process more comprehensively in the main paper would significantly enhance understanding.\n\t- The positioning of tables and figures within the paper is confusing, and detracts from the reading flow.\n- **Quality**: The supplementary material includes a section labeled \"ablation study\" which, in its current form, does not present a true ablation of the method's components. The method involves multiple design choices beyond a \"default classification head\", the orthogonal decomposition, max pooling, and the non-negative coefficients matrix. A proper ablation study for each of these components is missing, making it difficult to assess their individual importance and contribution to the method.\n- **Significance**: While the method offers flexibility across architectures, the quality of interpretation, from the evidence presented, appears to be similar to existing prototypical part methods. The paper could better articulate how InfoDisent's interpretability provides a distinct advantage or deeper insights beyond its architectural flexibility."}, "questions": {"value": "- How consistent are the prototypes found across different classes and samples? Does the same channel consistently link to the same \"concept\" or \"prototype,\" or do these interpretations vary significantly?\n- It is mentioned in the section about \"optimizing U and W\" that the goal is to find a product of a sparse and unitary matrix. Are there any explicit sparsity constraints or regularization terms added to the optimization objective, other than optimizing for an orthogonal matrix, to encourage this desired sparsity?\n- Can the method be effectively applied when transferring from one dataset to another (e.g., using a backbone trained on ImageNet and applying InfoDisent to explain predictions on a medical imaging dataset)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vjPWEsbqY5", "forum": "LdGAtMRJaM", "replyto": "LdGAtMRJaM", "signatures": ["ICLR.cc/2026/Conference/Submission12074/Reviewer_WmEX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12074/Reviewer_WmEX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12074/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840983063, "cdate": 1761840983063, "tmdate": 1762923045228, "mdate": 1762923045228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The proposed method InfoDisent is a post-training classification head designed to enhance the interpretability of frozen image-based model backbones.\nThe underlying idea that pretrained features already contain the necessary atomic concepts, is plausible and well motivated.\nThe method combines an orthogonal transformation, sparse pooling of the most positive and negative activations per channel, and a nonnegative linear classifier, to isolate channel-wise representations that correspond to salient semantic cues.\nThe authors interpret this mechanism as an information bottleneck that disentangles latent features into concept-like channels and enables prototype-based explanations in a single forward pass.\nExperiments on several vision datasets demonstrate comparable accuracy and visually coherent explanations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method is technically simple and broadly applicable. It can be attached to any frozen backbone without finetuning, offering post-training interpretability with minimal computational overhead. The model produces explanations in a single forward pass, which is computationally efficient compared to gradient-based saliency approaches and aligns with the idea of self-explainable architectures. The qualitative results are intuitive and visually consistent across datasets, and the experiments demonstrate reasonable generality of the method."}, "weaknesses": {"value": "**1.**\nL57: The paper claims that InfoDisent “leverages the information bottleneck principle” to ensure each channel encodes an atomic concept, but no mutual information quantity (e.g., (I(X;T)), (I(T;Y))) is defined or measured. The idea of “information bottleneck” is used rhetorically, not mathematically.\n\n**2.**\nL155: The method section introduces “extremely sparse pooling” and “unitary map (U)” yet provides no justification for how these operations realize an information bottleneck. There is also no ablation showing the effect of each component.\n\n**3.**\nL164: The explanation of sparse pooling uses notation (K \\to \\text{mx_pool}(K) = \\max(\\text{ReLU}(K)) - \\max(\\text{ReLU}(-K))). The presentation is algebraically correct but conceptually vague. \n\n**4.**\nL175: The notation (I = (I_{rs})*{rs} \\to J = (U I*{rs}) \\to v_J = \\text{mx_pool}(J)) is confusing. Indices (I, J, r, s) are inconsistently used to denote both spatial positions and transformed tensors. This ambiguity makes even simple tensor operations difficult to follow.\n\n**5.**\nL64, Table 3: ImageNet experiments are introduced as the first generalization of prototypical parts to large-scale datasets, yet Table 3 \nshows a performance drop. Although the performance–explainability tradeoff is understandable, the observed performance gap between CNN and ViT backbones on ImageNet should be further investigated. The method yields a noticeably larger accuracy drop for CNNs, while transformers retain most of their baseline performance. This difference likely reflects how the proposed orthogonal transformation and sparse pooling interact with backbone representations, but the paper provides no analysis or hypothesis. A deeper examination of this effect would strengthen the claims about scalability and general applicability.\n\n**6.**\nMuch of the essential methodological and quantitative content resides in the appendix, while the main text remains largely descriptive. Core analyses, e.g.,  disentanglement metrics and quantitative evaluation of interpretability, are only referenced but not summarized. As a result, the paper’s main body does not provide enough self-contained evidence for the claims. The authors should bring key results and analyses into the main text to ensure scientific transparency.\n\n**7.**\nHeatmaps are compared qualitatively, but the text asserts that “our approach yields more focused heatmaps.” This claim is unsupported by any numeric localization score or overlap measure.\n\n**8.**\nL1509: Theoretical explanation of sparsity seems important but no ablation or analysis demonstrates causal relation between orthogonalization and sparsity. Orthogonalization alone does not guarantee sparsity, and the claim remains speculative without quantitative evidence.\n\n**9.**\nThe claimed novelty of InfoDisent is somewhat overstated. Similar prototype-based interpretability approaches already explore post-hoc or semi-post-hoc explanations using frozen backbones. The main contribution here lies in a streamlined architectural design, which is technically neat but conceptually incremental. The introduction would benefit from a clearer articulation of what gap in interpretability research this specific formulation addresses.\n\n**10.**\nThe term “atomic concept” is commonly used in the interpretability literature to denote minimal, human-recognizable visual units. I accept this usage as conventional. However, in this paper, the notion is treated as an achieved property rather than a descriptive goal. The authors should clarify that “atomic” here refers to qualitative observations, not a formally verified characteristic, and avoid implying theoretical guarantees.\n\n**11.**\nFigures are numerous but lack quantitative caption summaries. The prose often mixes conceptual justification with qualitative description, making it difficult to distinguish evidence from interpretation."}, "questions": {"value": "**Q1.**  You state that InfoDisent “leverages the information bottleneck principle,” yet no mutual information quantity (e.g., (I(X;T)), (I(T;Y))) is defined or measured.\nCan you formally specify what information quantity is being constrained, and how your loss function or architecture approximates an information bottleneck objective?\nIf the term is used metaphorically, please clarify this explicitly.\n\n\n**Q2.**\nThe method section introduces the “extremely sparse pooling” and “unitary map (U)” but provides no justification for how these operations achieve an information bottleneck.\nCould you provide a theoretical argument or an ablation experiment showing how removing either component affects information compression or interpretability?\n\n\n**Q3.** \nYour sparse pooling function (L165) selects only two scalars per channel.\nWhat statistical or information-theoretic reasoning supports this choice?\nHave you compared it to alternatives such as top-(k) pooling or soft log-sum-exp pooling, and can you report how these affect sparsity and accuracy?\n\n\n**Q4.** \nThe notation in L177-184 is hard to follow.\nCan you provide a clearer tensor formulation, explicitly defining the dimensions of each variable to make the method reproducible?\n\n\n**Q5.**\nThe ImageNet experiments show a noticeable performance drop, particularly for CNNs.\nAlthough some tradeoff between interpretability and accuracy is expected, could you investigate why the degradation differs between CNN and ViT backbones?\nFor example, does orthogonal transformation interact differently with convolutional versus attention features?\nPlease include a diagnostic or ablation study to analyze this effect.\n\n\n**Q6.**\nYou claim that InfoDisent “matches classical models,” but no error bars or variance estimates are shown.\nCould you report statistical confidence intervals or repeat runs to substantiate the claim of comparable performance?\n\n\n**Q7.**\nMuch of the methodological and quantitative content is relegated to the appendix.\nCan you summarize key results (e.g., disentanglement metrics, quantitative interpretability scores) in the main paper to make it self-contained?\nIn particular, which quantitative evidence best supports your central claims?\n\n\n**Q8.**\nThe text claims that InfoDisent produces more focused heatmaps than Grad-CAM or LRP, but no numeric localization or overlap metrics are shown.\nCould you provide quantitative comparisons (e.g., IoU, pointing-game accuracy, or deletion/insertion scores) to support this statement?\n\n\n**Q9.**\nYou attribute sparsity to the combination of a frozen backbone and an orthogonal transformation, but no analysis demonstrates this causality.\nCould you add an ablation experiment showing activation sparsity with and without orthogonalization, or visualize activation histograms to quantify the effect?\n\n\n**Q10.**\nPrototype-based interpretability methods such as ProtoPNet and PIP-Net already explore post-hoc interpretability using frozen backbones.\nCan you clarify what precise gap InfoDisent fills beyond simplified architecture?\nIn what aspect does your approach advance the understanding of interpretability rather than streamline prior designs?\n\n\n**Q11.**\nThe paper frequently refers to “atomic concepts” as if they are achieved properties.\nCould you clarify how you define atomicity in measurable terms?\nIs there any quantitative analysis (e.g., concept purity, mutual information, or ablation sensitivity) showing that channels correspond to minimal, non-overlapping semantic units?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KUqKHgf17k", "forum": "LdGAtMRJaM", "replyto": "LdGAtMRJaM", "signatures": ["ICLR.cc/2026/Conference/Submission12074/Reviewer_xG6k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12074/Reviewer_xG6k"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12074/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930910421, "cdate": 1761930910421, "tmdate": 1762923044109, "mdate": 1762923044109, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces InfoDisent, a method for explainability (XAI) that disentangles information in the final layer of pretrained models into interpretable atomic concepts. It’s a hybrid approach combining the flexibility of post-hoc methods with the concept-based transparency of ante-hoc models (like ProtoPNet). The method applies an orthogonal transformation and information bottleneck (using sparse pooling) to produce prototype-like channel activations without retraining the backbone. It demonstrates interpretability and competitive performance on datasets including CUB-200-2011, Stanford Cars, Stanford Dogs, and ImageNet, and includes user studies for human interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. It unifies the interpretability of ProtoPNet-like models with the flexibility of post-hoc XAI, taking the best of the both worlds.\n2. Evaluation spans five datasets, including the challenging ImageNet, where most prototype-based methods fail."}, "weaknesses": {"value": "1. First of all, the authors should cite concept bottleneck models - related papers. That includes fully interpretable concept bottleneck models to post hoc-based concept bottleneck models.\n\n2. One big critcism is how to relate these prototypes to human-readable concepts. Often, these prototypes resemble to something unusual which does not match any known concept. I am coming from a medical imaging background, and I have seen this a lot in medical images where these prototypes often select a patch that is not related to any human anatomy. The interpretability community need to solve this challenge to actually produce plausible interpretation of a deep model. This is both true at a local and global level.\n\n3. The paper's central concept, \"information disentanglement\", is not well-defined or rigorously evaluated. The authors claim the channels represent \"atomic concepts\" , but this is a subjective claim based on cherry-picked qualitative examples (e.g., Fig 1's \"strawberry texture\" ). The primary quantitative metric for disentanglement (RV coefficient) is relegated to the appendix (Table 14)  and shows mixed results, with InfoDisent performing worse than the baseline in several cases (e.g., ConvNeXt-L on ImageNet). For a paper with \"Disentanglement\" in the title, this core concept needs a much stronger theoretical grounding and more convincing quantitative support.\n\n4. The paper introduces a trainable orthogonal transformation ($U$) and a sparse pooling operation, claiming this leads to \"atomic concepts\". However, it lacks a dedicated loss term to enforce this. There is no equation equivalent to a variational bottleneck's KL-divergence (like in $\\beta$-VAE) or a mutual information maximization term that would mathematically compel the channels to represent independent, non-overlapping concepts. \n\n5. The paper never formally defines what \"disentanglement\" means in this context. It is used as a qualitative descriptor for the desired outcome (interpretable prototypes), but the process of how the transform and bottleneck actually achieve this separation of information is not rigorously explained or validated.\n\n6. The main paper presents Figure 2 as the model architecture. This figure is incomplete and misleading, as it shows a simple max(ReLU(...)) operation, which is non-differentiable and cannot be trained as-is. As you correctly point out, Figure 9 (in the Appendix) reveals the actual training architecture. SO, Fig 9 has to be in the main section.\n\n7. The authors are not fully transparent about the performance-interpretability trade-off. Table 3  clearly shows that InfoDisent's accuracy is lower than the original (non-interpretable) backbone. For example, ResNet-50 drops from 76.1% to 67.8%, and Swin-S drops from 83.4% to 81.4%. This is a critical trade-off. However, the authors claim their approach \"not only matches the performance of these classical models but also offers enhanced explainability\". This is verifiably false; it doesn't match the performance. This trade-off is the cost of interpretability and should be discussed as such, not to be deemed as a non-issue. Also, Table 1 and Table 2 shows info-dissect falls short to many competitive methods."}, "questions": {"value": "1. Could you please provide a formal, technical definition of \"disentanglement\" as it applies to this work?\n2. There appears to be a significant discrepancy between the method's presentation in the main paper and the appendix. Figure 2 shows a simple, non-differentiable \\textt{mx_pool} operation , while Figure 9 in the appendix reveals the actual, more complex training-time architecture, which relies on a Gumbel-Softmax estimator. This is a critical, non-obvious detail. Can you confirm that the Gumbel-Softmax-based architecture in Figure 9 is, in fact, the reproducible method, and will you move this to the main paper in a final version?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CoLOb5CXxr", "forum": "LdGAtMRJaM", "replyto": "LdGAtMRJaM", "signatures": ["ICLR.cc/2026/Conference/Submission12074/Reviewer_FCXn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12074/Reviewer_FCXn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12074/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932568873, "cdate": 1761932568873, "tmdate": 1762923043661, "mdate": 1762923043661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors proposed InfoDisent, an interpretable image classification framework based on information disentanglement and sparse concept reasoning.\nIt applies an orthogonal transformation to decorrelate feature channels and a deterministic max–min pooling mechanism to extract positive and negative evidential activations, forming disentangled atomic concepts.\nThese concepts serve as interpretable units that link model decisions to localized object parts while maintaining scalability through channel sparsity and a frozen backbone.\nUnlike conventional prototype models that rely on large prototype sets or end-to-end fine-tuning, InfoDisent achieves interpretability and efficiency simultaneously across both CNN and transformer backbones.\nComprehensive experiments, including quantitative interpretability benchmarks, user studies, and robustness tests, demonstrate that InfoDisent yields human-recognizable explanations and reasonable classification consistency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **S1. Scalable and sparse prototype reasoning**\n\nThe proposed method effectively addresses the scalability problem common in prototype-based XAI methods, where an excessive number of prototypes limits applicability to large datasets.\nThrough an orthogonal transformation that decorrelates feature channels and a deterministic max–min pooling bottleneck, it prunes redundant or non-discriminative activations, leaving only a compact set of meaningful concept channels.\nThis sparse and disentangled design reduces the effective number of prototypes while preserving interpretability and classification consistency.\nEmpirical results confirm that InfoDisent uses far fewer active channels than prior models yet maintains competitive accuracy, showing that scalability and interpretability can be achieved simultaneously.\n\n- **S2. Comprehensive and rigorous experimental design**\n\nThe current InfoDisent framework demonstrates a clear improvement in experimental scope and rigor.\nAcross Sec 4 and 5 and the appendix, the authors integrate a broad range of evaluations covering classification performance, interpretability, robustness, and efficiency.\nBeyond standard accuracy tests, the study includes multi-backbone benchmarking, user-study validation, and quantitative interpretability metrics using the FunnyBirds and Spatial Misalignment datasets.\nAdditional analyses in the appendix--such as ablation, sparsity, efficiency, and robustness tests--further confirm the model’s stability and scalability.\nTogether, these additions transform the evaluation into a well-rounded and reproducible experimental framework supporting the method’s reliability and generality."}, "weaknesses": {"value": "- **W1. Moderate performance gap, backbone sensitivity, and residual background influence**\n\nThe proposed method achieves strong interpretability and sparsity, yet its classification accuracy remains slightly below that of the best-performing prototype and concept-based approaches, as reported in Tables 1 and 2.\nIts performance also appears dependent on the underlying backbone: results are generally higher with ResNet, where localized convolutional priors align well with the method’s spatial disentanglement, but less competitive with transformer architectures such as ViT or Swin, which rely on global attention patterns.\n\nFurthermore, the FunnyBirds evaluation (Fig. 7) indicates that while the model obtains the highest overall interpretability score, its Background Independence (B.I.) metric is somewhat lower than that of certain baselines. This may suggest that a portion of the learned concepts still captures contextual or texture cues inherited from the frozen backbone--such as background elements around target objects--rather than purely object-centric information.\n\nMy questions would be:\n- To what extent is the observed accuracy and backbone variation driven by architectural inductive bias, with convolutional locality favoring InfoDisent’s pooling and disentanglement design?\n- Could the orthogonal disentanglement mechanism interfere with globally distributed representations in ViTs?\n- Does the frozen-backbone configuration limit adaptability to transformer-based features?\n- Would incorporating explicit background suppression mechanisms--such as object masks, counterfactual interventions, or background-invariance regularizers--help improve B.I. while preserving sparsity and accuracy?"}, "questions": {"value": "Most of my main concerns or questions have been outlined in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "R8CQw3eBlk", "forum": "LdGAtMRJaM", "replyto": "LdGAtMRJaM", "signatures": ["ICLR.cc/2026/Conference/Submission12074/Reviewer_3ACv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12074/Reviewer_3ACv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12074/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762123918163, "cdate": 1762123918163, "tmdate": 1762923043329, "mdate": 1762923043329, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}