{"id": "lqCvR0BDss", "number": 14057, "cdate": 1758227720477, "mdate": 1759897393079, "content": {"title": "Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling", "abstract": "Text-to-image diffusion models remain computationally intensive: generating a single image typically requires dozens of passes through large transformer backbones (for example, SDXL uses about 50 evaluations of a 2.6B-parameter model). Few-step variants reduce the step count to 2–8, but still rely on large, full-precision U-Net/DiT backbones, making inference impractical on resource-constrained platforms, both on-device (latency/energy) and in data centers with multi-instance GPU (MIG) style partitioning (limited memory/throughput per slice). Existing post-training quantization (PTQ) methods are further hampered by dependence on full-precision calibration.\n\nWe introduce Q-Sched, a scheduler-level PTQ approach that adapts the diffusion sampler rather than the model weights. By adjusting the few-step sampling trajectory with quantization-aware preconditioning coefficients, Q-Sched matches or surpasses full-precision quality while delivering a 4x reduction in model size and preserving a single reusable checkpoint across bit-widths. To learn these coefficients, we propose a reference-free Joint Alignment–Quality (JAQ) loss, which combines text–image compatibility with an image-quality objective for fine-grained control; JAQ requires only a handful of calibration prompts and avoids any full-precision inference during calibration.\n\nEmpirically, Q-Sched yields substantial gains: a 15.5% FID improvement over the FP16 4-step Latent Consistency Model and a 16.6% improvement over the FP16 8-step Phased Consistency Model, demonstrating that quantization and few-step distillation are complementary for high-fidelity generation. A large-scale user study with more than 80,000 annotations further validates these results on both FLUX.1[schnell] and SDXL-Turbo. Code will be released.", "tldr": "Scheduler Adaptation for Quantized Few-Step Diffusions", "keywords": ["Quantization", "Diffusion Models", "Diffusions", "Text-to-Image", "Compression", "Model Compression", "Image Quality Assessment"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8135f7cd02afe3d7ad657359b38ecf4909e546c6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Few-step diffusion models with quantization brings both quantization error and accuracy loss due to reduced steps, causing more severe deviation in diffusion trajectories. To tackle this problem, the authors propose Q-Sched, a scheduler that learns lightweight coefficients per timestep to correct the drift between the quantized model's sampling trajectory and full precision trajectory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This approach is lightweight, which aligns with the purpose of quantization and few-step diffusion. \n2. The motivation is strong -- intuitively, generation quality can be much worse if combining few-step and quantization in diffusion."}, "weaknesses": {"value": "1. Evaluation may need clarifications. \n2. The methods are relatively simple. \n3. Relying on a calibration set."}, "questions": {"value": "1. Why can the FID drop below FP16 baseline by this much as Table 2(b) shows? Are the FID numbers evaluated over multiple generations? What's the error bar like?\n2. If apply this paper's approach on FP16 baseline, can the FID of FP16 also be improved? \n3. Are the two coefficients expressive enough? What are the limitations and under what condition do you need more coefficients or seek other approaches?\n4. Do you think the calibration set can cause potential issues like overfitting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Uape0jScDM", "forum": "lqCvR0BDss", "replyto": "lqCvR0BDss", "signatures": ["ICLR.cc/2026/Conference/Submission14057/Reviewer_aN57"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14057/Reviewer_aN57"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761174757628, "cdate": 1761174757628, "tmdate": 1762924542134, "mdate": 1762924542134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Q-Sched, a quantization-aware scheduler designed for few-step diffusion models.\nInstead of modifying model weights or activations, Q-Sched adapts the sampling scheduler itself to mitigate trajectory drift caused by quantization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel Perspective. The idea of addressing quantization artifacts at the scheduler level rather than the model level is interesting and practically elegant.\n\n2. Experiments span multiple diffusion families (LCM, PCM, SDXL-Turbo, FLUX.1), and include both objective metrics (FID, CLIPScore) and large-scale human evaluations."}, "weaknesses": {"value": "1. The proposed scheduler-level correction resembles existing bias/variance scaling approaches such as PTQD. The distinction between Q-Sched and these prior works is not clearly articulated.\n\n2. Several figures are rasterized screenshots instead of scalable vector graphics, resulting in unclear visuals and text artifacts in the PDF.\n\n3. The method’s scalability to models with longer trajectories (e.g., > 8 steps) or higher-resolution datasets is not analyzed. It remains uncertain how the grid-search complexity grows with timestep count or calibration-set size."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "I1Fr111tPX", "forum": "lqCvR0BDss", "replyto": "lqCvR0BDss", "signatures": ["ICLR.cc/2026/Conference/Submission14057/Reviewer_mdUQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14057/Reviewer_mdUQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619021210, "cdate": 1761619021210, "tmdate": 1762924541600, "mdate": 1762924541600, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of the degradation of generation fidelity when diffusion models are applied using low quantization. The paper proposes Q-Sched, which identifies two parameters in the scheduling of the quantized diffusion steps, to mitigate the degradation from quantization. As only two parameters are required, Q-Sched utilizes grid search and proposes to find the parameter that best optimizes a JAQ loss, which is a combination of the text-image matching metric and image quality metric. In experiments, the paper shows that Q-Sched can improve the FID and CLIP score of the quantized model compared to no-modification or baseline scheduling, especially under the setting of low quantization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a simple approach that only tunes two parameters of the diffusion schedule to improve the performance of the quantized model.\n\n2. The paper gives intuitive theoretical justification for the design of the two parameters.\n\n3. The proposed method improves CLIP and FID, especially under the setting of low quantization."}, "weaknesses": {"value": "1. More qualitative comparisons or essentially visual comparisons between images generated by different methods should be provided.\n\n2. Conceptually, the metric for the adapted schedule should be to match the output of the non-quantized model. However, the paper proposes to use the JAQ loss as the target for the grid search. Even though JAQ could be a comprehensive metric, it is not clear why it could serve as the ideal judgment for tuning the scheduling for the quantized model.\n\n3. More details of the grid search results could be added. Since there are only two parameters, we could clearly see what the trend is and how sensitive the JAQ loss is with respect to the parameters. This could also justify why the proposed method requires few prompts for tuning to achieve good performance.\n\nminor:\n1.  line 265: a those"}, "questions": {"value": "1. What if we apply Q-Sched on the non-quantized model? Could it be the case that we see better performance because JAQ is better aligned with the metrics?\n\n2. How to explain in Table 2 (b), Q-Sched has a quite lower FID compared to the FP16 model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PljBYuX8lW", "forum": "lqCvR0BDss", "replyto": "lqCvR0BDss", "signatures": ["ICLR.cc/2026/Conference/Submission14057/Reviewer_pBRf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14057/Reviewer_pBRf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761693193087, "cdate": 1761693193087, "tmdate": 1762924541185, "mdate": 1762924541185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenges to adopting quantized text-to-image diffusion models for few-step inference by proposing a novel scheduler-level PTQ approach that adapts the sampler rather than the model weights.\n\nThe key idea behind Q-Sched is to introduce two lightweight, learnable preconditioning coefficients ($c^x, c^{\\epsilon}$) per timestep, which are applied to the scheduler's inputs.\n\nTo optimize these coefficients, the authors introduce the Joint Alignment-Quality (JAQ) loss, a reference-free objective that combines text-image compatibility with a pure image quality score, and apply grid search for these coefficients.\n\nExperimental results show that Q-Sched can match or even surpass the quality of FP16 baselines (e.g., 15.5% FID improvement over 4-step LCM) and outperform other PTQ methods like MixDQ and SVDQuant in human preference."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The motivation of this paper that combining few-step inference and quantized model is well established and matches real-world application.\n1. This proposed Q-Sched acheives promising experimental perfomance on FID improvement and CLIPScore.\n1. The core idea of reframing the quantization problem as a trajectory drift issue and solving it by adapting the scheduler instead of the weights  is novel and elegant.\n1. The JAQ loss is also a well-motivated and practical contribution for this reference-free optimization task.\n1. The writing is clear, concise, and easy to follow. The core problem of \"scheduler mismatch\"  is intuitively explained and provides a strong motivation for the proposed solution."}, "weaknesses": {"value": "1. Lack of latency comparison: one common motivation of model quantization and few step inference is to reduce model latency, however, this paper does not show comparision between Q-Sched and other models on model latency.\n1. There is an ablation study that determine how to choose $k$ for the JAQ Loss, but it does not include ablation study that use pure $\\text{TC}(\\cdot)$ or pure $\\text{IQ}(\\cdot)$, or-not reference-free loss.\n1. The Algorithm 1 should be a grid search algorithm that uses $c_{min}$ and $c_{max}$, but it is instead an unexplained search optimizer `opt` with `opt.step`.\n1. The Q-Sched is well motivated and justificated by math, but it misses the intuition why Equation (4) is designed as such a form."}, "questions": {"value": "1. In Algorithm 1, it seems that the $(\\mathbf{c^x}, \\mathbf{c^\\epsilon}):=(c_t^x, c_t^\\epsilon)_{t=0}^T$ are optimized simutenously. How about optimizing each $t$ independently (or they have to be linspaced)?\n1. Why $\\sigma_{s'}$ is combined with $c_t^\\epsilon$ but not $c_{s'}^\\epsilon$? Any justification?\n1. I notice there is a model named SANA-sprint that proposes a training-free approach that transforms a pre-trained flow-matching model for continuous-time consistency distillation (sCM), any comparision with it and Q-Sched?\n1. Is the grid search of Q-Sched (Algorithm 1) faster than full-presicion calibration used by other methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K8tSrtg00G", "forum": "lqCvR0BDss", "replyto": "lqCvR0BDss", "signatures": ["ICLR.cc/2026/Conference/Submission14057/Reviewer_53Sq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14057/Reviewer_53Sq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894385910, "cdate": 1761894385910, "tmdate": 1762924540452, "mdate": 1762924540452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}