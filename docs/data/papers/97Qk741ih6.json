{"id": "97Qk741ih6", "number": 5980, "cdate": 1757949351041, "mdate": 1759897941500, "content": {"title": "CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering", "abstract": "Knowledge graphs provide structured context for multi‑hop question answering, but deployed systems must balance answer accuracy with strict latency and cost targets while preserving provenance. Static $k$‑hop expansions and ``think‑longer'' prompting often over‑retrieve, inflate context, and yield unpredictable runtime. Thus, we introduce CLAUSE, an agentic three-agent neuro‑symbolic framework that treats context construction as a sequential decision process over knowledge graphs, deciding what to expand, which paths to follow or backtrack, what evidence to keep and when to stop. Latency (interaction steps) and prompt cost (selected tokens) are exposed as user‑specified budgets or prices, allowing per‑query adaptation to trade‑offs among accuracy, latency, and cost without retraining. CLAUSE employs the proposed Lagrangian‑Constrained Multi‑Agent Proximal Policy Optimization (LC‑MAPPO) algorithm to coordinate three agents: Subgraph Architect, Path Navigator, and Context Curator, so that subgraph construction, reasoning paths discovery, and evidence selection are jointly optimized under per‑query's resource budgets on edge edits, interaction steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields higher EM@1 while reducing subgraph growth and end-to-end latency at equal or lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline (GraphRAG), CLAUSE achieves $+39.3$ EM@1 with 18.6% lower latency, and 40.9% lower edge growth. The resulting contexts are compact, provenance‑preserving, and deliver predictable performance under deployment constraints.", "tldr": "", "keywords": ["multi-hop KGQA", "neuro-symbolic reasoning", "agentic system", "context engineering"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/265de038781838ddc2d8ddfcc60e146a229d7f00.pdf", "supplementary_material": "/attachment/d033ded9ca9309be94ccb20a3314ea63e0781787.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a method for question answering (QA) based on retrieval from a knowledge graph. In contrast with heuristics for KG retrieval based on k-hop neighborhoods and their expansion, the authors frame the problem as a constrained reinforcement learning task with tree cost objectives based on minimizing subgraph selection, neighborhood expansion, and token usage. Experiments show that the approach is accurate, while effectively optimizing for their proposed three-way cost."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem is well-motivated: many existing approaches for RAG over KGs are based on heuristics that can result in high costs when applied uniformly for all questions. Optimizing this step is therefore a task is likely to positively impact the cost of deploying such methods.\n2. The work is well-positioned with respect to prior work, ranging from QA over KGs to specific reinforcement learning methods.\n3. The formulation of the problem seems well-motivated, as it frames question answering as a constrained RL problem with QA accuracy as the reward, and constraints related to retrieval cost\n4. The experiments are comprehensive, considering a broad range of baselines, and more importantly, evaluating the methods on the axes of accuracy, latency, and edge budget. In most cases (except latency) they demonstrate the effectiveness of the method."}, "weaknesses": {"value": "The paper mostly suffers from exposition issues that make it difficult to assess important parts of the paper that are needed to judge its impact and soundness.\n\n1. The contributions (L075) are mostly a description of the proposed method, rather than a description of what the fundamental problem being solved is, how the proposed method differs fundamentally from prior work, and its advantages over prior work. A similar issue appears in the related work section (L130) which seems like a brief survey of different RL methods that is not positioned in the context of the paper.\n2. The problem definition (L159) is imprecise: a knowledge graph is K = (V, R, E), but what are V, R, and E? Similarly a question q is defined. Are there any assumptions on q, e.g. it is always a question that seeks to retrieve an entity from the KG? Is it assumed to be already parsed such that mentions of relations and entities are linked to specific ones in the KG? Or is there an intermediate model that takes care of this? L227 seems to suggest both (\"Anchored by entity/alias mentions in q (with a lightweight dense-retrieval fallback)\"), while still leaving many crucial details out.\n3. The question conditioned subgraph is $G_t = (V_t,E_t)$, now a tuple with two elements (rather than three, as the KG is defined). Does this mean that $G_t$ drop relational information? Furthermore, $\\mathcal{F}_t$ is introduced as a \"traversal frontier\". It is not clear what this means (why traversal? why frontier?). If part of the state is $G_t$, which already contains $V_t$, why does $\\mathcal{F}_t\\subseteq V_t$ need to be made a separate part of the state? Lastly, $\\mathcal{C}_t$ is undefined in the definition of the state (L165).\n4. The description of CLAUSE contains gaps. Some are related to the motivation of the approach: the architect maintains a \"frontierized subgraph\" yet it is not clear what \"frontierized\" is, and what \"frontier candidates\" are. More importantly, while it is clear that there are three agents, each with a specific goal, it is not clear *what* they are. The architect computes question-entity, relation-text matches, etc. but how? Does it rely on neural networks? If so, what is their architecture and their number of parameters? There is a \"light encoder\" in the path navigator, yet it is not clear what it encodes, how, and how light it actually is.\n5. The actual novelty or need of LC-MAPPO is unclear, given that there are several works studying the use of Lagrangian methods in reinforcement learning. Why is LC-MAPPO needed, and what if instead we used one of the existing works in this area?\n6. The EM@1 evaluation metric is unclear. Since it is not known what type of questions the method supports (see weakness 2) it is difficult to infer from context what it actually measures.\n7. Important experimental details are missing: what is the actual shared LLM used for retrieval and reading? And importantly, what is the KG? Is the KG the same for all datasets? What is its scale?\n8. While the experiments are comprehensive, it is not true that CLAUSE is the most effective (as implied by the bolding in Table 2), where LightRAG is actually better.\n9. The proof of convergence (App. G) seems incomplete. It is based on a list of assumptions that does not appear anywhere in the paper."}, "questions": {"value": "1. Can you please provide a more descriptive definition of the KG, the question q, and the question-conditioned subgraph that does not leave symbols undefined?\n2. What is \"frontierized\" subgraph? What are frontierized candidates?\n3. What is the architecture of the subgraph architect, path navigator, and context curator?\n4. Can you please expand on important experimental details (see W7)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ulFkRqilg9", "forum": "97Qk741ih6", "replyto": "97Qk741ih6", "signatures": ["ICLR.cc/2026/Conference/Submission5980/Reviewer_Aqnr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5980/Reviewer_Aqnr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761647089397, "cdate": 1761647089397, "tmdate": 1762918388758, "mdate": 1762918388758, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes  CLAUSE, an agentic three-agent neuro-symbolic framework that treats context construction as a sequential decision process over knowledge graphs, deciding what to expand, which paths to follow or backtrack, what evidence to keep and when to stop. The three agents include subgraph architecture, path navigator and context curator. These agents are trained jointly with Lagrangian Constrained Multi-Agent Proximal Policy Optimization, so that subgraph construction, reasoning paths discovery, and evidence selection are jointly optimized under per-query’s resource budgets on edge edits, interaction steps, and selected tokens"}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This paper has novel approach of formulating knowledge graph questions answering (KGQA) as a learnable context construction. CLAUSE demonstrates strong empirical results and achieves the best accuracy on all datasets and hops (71.7 on HotpotQA, 84.2 on FactKG, and 91.0/87.3/85.5 on MetaQA 1/2/3-hop), surpassing both RAG baselines (e.g., HybridRAG 66.0 on HotpotQA) and agent baselines (e.g., KG-Agent 68.7 on HotpotQA, 87.3/78.0/75.4 on MetaQA) maintaining an impressive efficiency."}, "weaknesses": {"value": "The system involves three agents and MARL training pipeline which may potentially increase the computational complexity. Additional discussion on training cost may be helpful. The framework needs to be tested at scale on large and real world noisy knowledge graph."}, "questions": {"value": "How would CLAUSE handle large and real world noisy knowledge graph and if it fails what would be the next step"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "SRA76imhkO", "forum": "97Qk741ih6", "replyto": "97Qk741ih6", "signatures": ["ICLR.cc/2026/Conference/Submission5980/Reviewer_aDuz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5980/Reviewer_aDuz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761868068627, "cdate": 1761868068627, "tmdate": 1762918388444, "mdate": 1762918388444, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents CLAUSE, a neuro-symbolic three-agent framework for efficient multi-hop question answering over knowledge graphs. Unlike static k-hop expansion or overlong prompting, CLAUSE formulates context construction as a sequential decision process, dynamically determining which subgraphs to expand, paths to explore, and evidence to retain under user-specified latency and cost budgets. Powered by the proposed Lagrangian-Constrained Multi-Agent PPO (LC-MAPPO) algorithm, three coordinated agents—Subgraph Architect, Path Navigator, and Context Curator—jointly optimize subgraph growth, reasoning efficiency, and evidence selection. Experiments on HotpotQA, MetaQA, and FactKG show that CLAUSE significantly improves accuracy and efficiency, achieving +39.3 EM@1, 18.6% lower latency, and 40.9% reduced edge growth over GraphRAG, while preserving provenance and ensuring predictable, deployment-friendly performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes CLAUSE, a neuro-symbolic multi-agent framework that dynamically balances accuracy, latency, and cost through user-specified budgets—enabling per-query adaptation without retraining.\n- The authors introduce the Lagrangian-Constrained Multi-Agent PPO (LC-MAPPO) algorithm to jointly optimize subgraph construction, reasoning path navigation, and evidence selection in a unified decision process.\n- The prposed method achieves substantial gains in accuracy (+39.3 EM@1 on MetaQA-2-hop) while reducing latency and subgraph growth, producing compact, provenance-"}, "weaknesses": {"value": "- The contribution in section 1 is somewhat overclaimed. It is suggested to merge the points to highlight the key contribution of the proposed method."}, "questions": {"value": "Please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kvqC7A6Ix0", "forum": "97Qk741ih6", "replyto": "97Qk741ih6", "signatures": ["ICLR.cc/2026/Conference/Submission5980/Reviewer_L2iz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5980/Reviewer_L2iz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919159028, "cdate": 1761919159028, "tmdate": 1762918387970, "mdate": 1762918387970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CLAUSE, a novel multi-agent, neuro-symbolic framework for multi-hop Knowledge Graph Question Answering (KGQA). The core contribution is transforming the context-building process as a constrained sequential decision problem. The framework therefore uses three agents (Subgraph Architect, Path Navigator, and Context Curator) and jointly optimize them. Within this process, the cost is explicitly expressed by the Lagrangian-constrained. Experiments on HotpotQA, MetaQA, and FactKG show that CLAUSE outperforms strong RAG and agent-based baselines in accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe idea of creating three agents(Subgraph Architect, Path Navigator, and Context Curator) is intuitive and easy to follow. The paper explains its motivations and methods clearly.\n2.\tThe CLAUSE is interpretable as it is a neural symbolic framework and every step is explicit.\n3.\tThe methodology has very sound theoretical guarantees and the paper has provided the full proof of its convergence. \n4.\tThe empirical results are extensive and impressive as it outperforms all baselines in accuracy while maintaining good efficiency at the same time."}, "weaknesses": {"value": "1.\tThe methodology part is filled with notations with some not very clearly explained. For example, what does $C_t$ stands for is not explained when it’s firstly introduced in this paper in the top of the 4th page. I strongly suggest that the author to take notice of whether the notation has been explained carefully.\n2.\tThe experiment part is solely conducted with Qwen3-32B, I wonder whether the author has tried as LLM?"}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YlsyRIkyn4", "forum": "97Qk741ih6", "replyto": "97Qk741ih6", "signatures": ["ICLR.cc/2026/Conference/Submission5980/Reviewer_2uqG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5980/Reviewer_2uqG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012520474, "cdate": 1762012520474, "tmdate": 1762918387602, "mdate": 1762918387602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}