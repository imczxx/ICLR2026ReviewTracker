{"id": "yMMb3rCuNM", "number": 7818, "cdate": 1758037436628, "mdate": 1759897830346, "content": {"title": "Constant Degree Matrix-Driven Incomplete Multi-View Clustering via Connectivity-Structure and Embedding Tensor Learning", "abstract": "Tensor-based incomplete multi-view clustering has attracted significant research attention due to its capability to exploit high-order correlations across different views for revealing underlying cluster structures from partially observed multi-view data. However, most existing approaches construct tensors from adjacency matrices, which necessitate post-processing operations (e.g., singular value decomposition, SVD) and thereby introduce additional computational overhead and potential errors. Some approaches instead employ latent embedding tensors to avoid post-processing, but they often fail to capture the geometric structure of the underlying graph. To address these limitations, we propose **C**onst**A**nt degree **M**trix-driv**E**n incomp**L**ete multi-view clustering via connectivity-structure and embedding tensor learning (**CAMEL**). Specifically, CAMEL jointly learns view-specific latent embeddings under structured constraints and organizes them into a tensor with an ${\\ell_{\\delta}}$ low-rank constraint, thereby enabling coordinated optimization of graph connectivity and high-order correlations. To further mitigate the $\\mathcal{O}(n^2)$ or ever higher complexity complexity associated with conventional connectivity constraints, CAMEL approximates the variable Laplacian degree matrix with a constant-degree matrix, reducing the computational cost to $\\mathcal{O}(1)$. Clustering assignments are subsequently derived via $k$-means on the concatenated embeddings, eliminating the need for post-processing operations on adjacency matrices such as SVD.  Extensive experiments on nine benchmark datasets demonstrate the superior effectiveness and efficiency of CAMEL.", "tldr": "", "keywords": ["Multi-view clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8f71b206a2a4662ef19ceb2e9af66de5da79037a.pdf", "supplementary_material": "/attachment/037f3f0c1b105bddfe268977a8bd4319909ae39c.zip"}, "replies": [{"content": {"summary": {"value": "To effectively model the rich information in multi-view data while improving computational efficiency, this paper develops a constant-degree matrix-based framework for incomplete multi-view clustering. View-specific latent embeddings are learned under structured constraints and organized into a tensor with an $\\ell_\\delta$ low-rank constraint, enabling joint optimization of graph connectivity and high-order correlations. CAMEL further reduces the $O(n^2)$ complexity of traditional connectivity constraints by approximating the variable Laplacian degree matrix with a constant-degree matrix. Theoretical analysis and extensive experiments validate the method’s effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written and presents the work in a clear and rigorous manner.\n2. By approximating the variable Laplacian degree matrix with a constant-degree matrix, the proposed method avoids the $O(n^2)$ or higher computational complexity associated with traditional connectivity constraints, thereby improving overall efficiency. The authors also validate the approach on large-scale datasets, demonstrating its practical applicability.\n3. The CAMEL consistently achieves superior clustering performance compared to baseline methods across multi-view datasets of different types."}, "weaknesses": {"value": "1. One of the core contributions of this work is the use of the latent representation H instead of the subspace representation Z for clustering. It would be helpful if the authors could clarify in which aspects H provides advantages over Z, such as representation quality, or clustering performance.\n2. The paper replaces the traditional Laplacian matrix $L_v = I - (D_v)^{-1/2} S_v (D_v)^{-1/2}$ with a constant form $L_v = I - \\beta (Z_v)^\\top Z_v$, but the underlying mechanism and justification for this approximation are insufficiently discussed.\n3. The parameter sensitivity analysis uses different ranges for $\\lambda_1$ and $\\lambda_2$, but the rationale for selecting these ranges is not clearly justified.\n4. The construction of incomplete multi-view data is insufficiently described. It is unclear whether the missing elements are consistent across different datasets and compared methods, and whether the randomly removed elements are the same across experimental runs.\n5. The paper refers to the dataset as \"Still2\", while other references consistently use \"Still-DB\". Could the authors clarify whether these names refer to the same dataset or different ones?"}, "questions": {"value": "Please refer to the weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JxZZUd4alQ", "forum": "yMMb3rCuNM", "replyto": "yMMb3rCuNM", "signatures": ["ICLR.cc/2026/Conference/Submission7818/Reviewer_Q7LQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7818/Reviewer_Q7LQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7818/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761721797884, "cdate": 1761721797884, "tmdate": 1762919864831, "mdate": 1762919864831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a tensor-based method for incomplete multi-view clustering named CAMEL. CAMEL jointly learns view-specific latent embeddings under structured constraints and organizes them into a low-rank tensor, enabling coordinated optimization of graph connectivity and high-order correlations while avoiding costly post-processing (e.g., SVD). Extensive experiments on nine benchmark datasets demonstrate its superior effectiveness and efficiency compared to existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The proposed method learns view-specific embeddings under structured constraints and organizes them into a low-rank tensor, effectively overcoming the limitation of traditional methods that cannot simultaneously capture graph connectivity and high-order correlations.\n\n2.The manuscript presents extensive experiments that demonstrate the effectiveness and efficiency of the proposed method.\n\n3.The manuscript provides detailed theoretical derivations and proofs, which theoretically validate the effectiveness of the proposed model."}, "weaknesses": {"value": "1. The hyperparameters $\\lambda_1$ and $\\lambda_2$ in Equations (1)--(3) are not defined, leaving their values and roles unclear.\n\n2. The manuscript lacks experimental comparisons between the $\\ell_\\delta$-norm and the conventional tensor nuclear norm in terms of performance.\n\n3. The authors state that Equation (2) involves quadratic computational complexity; however, since Equation (2) is based on an anchor method, it should already have low complexity. It is unclear where the quadratic complexity arises. \n\n4. Lines 259--262 contain a repeated statement, which affects the manuscript’s clarity."}, "questions": {"value": "See Weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bLA9ZlNayz", "forum": "yMMb3rCuNM", "replyto": "yMMb3rCuNM", "signatures": ["ICLR.cc/2026/Conference/Submission7818/Reviewer_q5uJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7818/Reviewer_q5uJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7818/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790209372, "cdate": 1761790209372, "tmdate": 1762919864245, "mdate": 1762919864245, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel incomplete multi-view clustering method that seamlessly integrates the low-rank tensor learning, latent learning, anchor learning as one unified framework. However, this paper is with limited contributions, since the proposed method is the combination of existing methods such as \"Tensorized multi-view subspace representation learning\", \"Generalized latent multi-view subspace clustering\", and so on."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well-written.\nThe authors also illustrate the motivations, details, and optimization of the proposed method."}, "weaknesses": {"value": "1、In Figure 1, what is the function of “Constant degree matrix”? How to communicate with other modules of the proposed method?\n2、Many incomplete and complete multi-view clustering methods assume that there exists some sparse noise such as deadline. The authors select the ||.||_F as the regularizer for noise removal. How to deal with the datasets with sparse noise?\n3、How to extend the l_\\sigma norm from the matrix format into the tensor format? How to define the l_\\sigma tensor norm? There are many nonconvex surrogates such as l_p norm, Schatten l_p norm, and so on, for nonconvex low-rank tensor learning. The authors failed to compare the proposed method with other representative nonconvex surrogates for high-order modeling. \n 4、Small-scale testing datasets. The testing datasets are relatively small-scale! I want to see the performance of the proposed method on the large-scale dataset."}, "questions": {"value": "In Equation ( 3), the authors have added the \"Tr[(Hv )⊤(I − 1β (Zv )⊤Zv )Hv\" into the objective of the proposed model. The author states that the proposed model could reduce the running times. However, I think the introduction of  \"Tr[(Hv )⊤(I − 1β (Zv )⊤Zv )Hv\"  could yield a heavy computational burden, rather than reduce the running times."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Da7Z5HZF8D", "forum": "yMMb3rCuNM", "replyto": "yMMb3rCuNM", "signatures": ["ICLR.cc/2026/Conference/Submission7818/Reviewer_MEf5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7818/Reviewer_MEf5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7818/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806355655, "cdate": 1761806355655, "tmdate": 1762919863815, "mdate": 1762919863815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript develops a novel tensor-based approach for incomplete multi-view clustering tasks. The main ideas of the work are:\n* Employ view-specific connectivity constraints and tensor learning to capture high-order cross-view correlations;\n* Perform clustering on the learned embeddings to eliminate additional post-processing;\n* Introduce a approximation of Laplacian matrix for efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The work improves clustering performance and meanwhile enhances algorithm efficiency;\n* Detailed theoretical analyses are provided, and experimental results are sufficient;\n* The paper is well-written."}, "weaknesses": {"value": "* Why the authors adopt the norm of $\\ell_\\delta$-norm (i.e., $f(x) = \\frac{(1+\\delta)x}{\\delta + x}$) ? What its specific advangates?\n* Some details require further explanation. For example, what is the clear definition of the \"post-processing-free\" methods? It seems that some post-processing-free methods still requires an extra clustering procedure on the learned features.\n* The ablation study requires a deeper analyses, and current discussion cannot well illustrate the contribution of each component.\n* Some typos should be corrected."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zGgZGW1v4u", "forum": "yMMb3rCuNM", "replyto": "yMMb3rCuNM", "signatures": ["ICLR.cc/2026/Conference/Submission7818/Reviewer_bSK1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7818/Reviewer_bSK1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7818/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995877002, "cdate": 1761995877002, "tmdate": 1762919863270, "mdate": 1762919863270, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}