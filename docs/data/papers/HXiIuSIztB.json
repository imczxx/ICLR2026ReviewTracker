{"id": "HXiIuSIztB", "number": 365, "cdate": 1756736656942, "mdate": 1759898264962, "content": {"title": "MINED: Probing and Updating  with Multimodal Time-Sensitive Knowledge for Large Multimodal Models", "abstract": "Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal pre-training, yet their static representations struggle to maintain an accurate understanding of time-sensitive factual knowledge. Existing benchmarks remain constrained by static designs, inadequately evaluating LMMs' ability to understand time-sensitive knowledge. To address this gap, we propose MINED, a comprehensive benchmark that evaluates temporal awareness along 6 key dimensions and 11 challenging tasks: cognition, awareness, trustworthiness, understanding, reasoning, and robustness. MINED is constructed from Wikipedia by two professional annotators, containing 2,104 time-sensitive knowledge samples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED shows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07, while most open-source LMMs still lack time understanding ability. Meanwhile, LMMs perform best on organization knowledge, whereas their performance is weakest on sport. To address these challenges, we investigate the feasibility of updating time-sensitive knowledge in LMMs through knowledge editing methods and observe that LMMs can effectively update knowledge via knowledge editing methods in single editing scenarios.", "tldr": "We construct a multidimensional framework and comprehensive benchmarks to evaluate the time awareness ability of LMMs.", "keywords": ["multimodal time-sensitive knowledge，multimodal knowledge editing，large multimodal model"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/201c2574a445bc51c161dde49e3c21f0e89a6155.pdf", "supplementary_material": "/attachment/6dd657d1e894f7edc7adc586dce40bd49968007e.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes MINED, a comprehensive benchmark that evaluates temporal awareness along 6 key dimensions and 11 challenging tasks: cognition, awareness, trustworthiness, understanding, reasoning, and robustness. MINED is constructed from Wikipedia by two professional annotators, containing 2,104 time-sensitive knowledge samples spanning six knowledge types."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses a highly underexplored area—temporal awareness in Large Multimodal Models\n2. The MINED benchmark is multi-dimensional, encompassing 6 core capabilities with comprehensive benchmark design\n3. The analysis of the experimental conclusions is very meticulous"}, "weaknesses": {"value": "1. In Section 5, both the knowledge-editing methods and the backbone models are rather outdated. I suggest the authors experiment with more recent backbone models such as Qwen2.5-VL and adopt newer knowledge-editing techniques.\n2. To make the experimental conclusions easier to grasp, the authors should provide more detailed case studies, using them to elaborate on the seven observations they draw."}, "questions": {"value": "Please refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iFAnsinww6", "forum": "HXiIuSIztB", "replyto": "HXiIuSIztB", "signatures": ["ICLR.cc/2026/Conference/Submission365/Reviewer_3CwJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission365/Reviewer_3CwJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761187260159, "cdate": 1761187260159, "tmdate": 1762915504676, "mdate": 1762915504676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MINED, a new benchmark designed to systematically evaluate the performance of multimodal large language models on time-sensitive questions and dynamic knowledge updating capabilities. The benchmark assesses six dimensions. Using MINED, the paper evaluates several recent models and further investigate the performance of classical knowledge editing methods on updating time-sensitive knowledge."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "MINED offers a comprehensive benchmark of dynamic knowledge understanding in LMMs, with extensive evaluations of recent models and a systematic study of knowledge-editing methods for time-sensitive updates. By jointly leveraging text and images to probe temporal awareness and misalignment, it takes a crucial step toward realistic multimodal evaluation."}, "weaknesses": {"value": "1. Although the evaluation dimensions have increased, it seems that the proposed dataset is not more challenging than other datasets.\n2.Missing inter-annotator agreement (e.g., Cohen’s κ) and conflict resolution details. These should be reported for transparency.\n3.The automatically generated misaligned contexts might encode stylistic artifacts; human-written or multi-source variants are needed."}, "questions": {"value": "1. Is the dataset updated over time?\n2. The maximum answer length is 13, but the average answer length is only 2. Are most of the answers single words?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JhEUQL2jgB", "forum": "HXiIuSIztB", "replyto": "HXiIuSIztB", "signatures": ["ICLR.cc/2026/Conference/Submission365/Reviewer_cs3Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission365/Reviewer_cs3Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761642764381, "cdate": 1761642764381, "tmdate": 1762915504514, "mdate": 1762915504514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MINED, a comprehensive benchmark designed to evaluate large multimodal models’ (MLLMs) ability to understand and update time-sensitive knowledge.\nUnlike prior static or text-only temporal benchmarks, MINED focuses on multimodal temporal awareness—how models perceive, reason about, and update factual knowledge that evolves over time.\n\nThe benchmark contains 2,104 time-sensitive knowledge samples and 4,208 questions, spanning six capability dimensions (Cognition, Awareness, Trustworthiness, Understanding, Reasoning, and Robustness) and six knowledge types (e.g., sport, organization, company).\nExtensive evaluations over 15 popular LMMs reveal that even state-of-the-art closed-source models (e.g., Gemini-2.5-Pro) struggle with implicit and misaligned temporal knowledge.\nFurthermore, the authors explore knowledge editing methods (FT-LLM, FT-VIS, MEND, SERAC, IKE) to update outdated time-sensitive facts in LMMs, demonstrating that single-editing is effective, while lifelong editing suffers from catastrophic forgetting.\n\nOverall, MINED aims to bridge temporal reasoning, multimodal grounding, and model updating—offering a unified platform for evaluating time-sensitive understanding and editing in LMMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Comprehensive benchmark design.**\n   - The benchmark is organized into six orthogonal capability dimensions, forming a well-structured framework that captures not only factual recall but also temporal awareness, reasoning, and robustness.\n   - The inclusion of *temporal misalignment* and *unanswerable-date* subtasks realistically simulates real-world temporal inconsistencies that often occur in dynamic factual knowledge.\n2. **High-quality dataset and clear evaluation protocol.**\n   - All data are manually verified, and the benchmark supports *evolvability* through quarterly Wikipedia updates, which ensures long-term relevance.\n   - The proposed *Prompt Agreement* scheme is a thoughtful methodological design that effectively mitigates prompt-induced variance during evaluation.\n3. **Strong experimental depth and breadth.**\n   - Evaluation across 15 large multimodal models (both open- and closed-source) provides rich comparative insights into current model limitations.\n   - The experimental analysis includes detailed error breakdowns, cross-model comparisons, and multiple editing paradigms, offering a well-rounded understanding of temporal sensitivity in LMMs."}, "weaknesses": {"value": "1. **Limited novelty and motivation.**\n   - The paper mainly focuses on dataset construction, while the necessity and motivation for studying this particular task could be discussed more clearly.\n   - There is little exploration of potential methodological improvements or model-side strategies for enhancing temporal sensitivity beyond the dataset itself.\n2. **Relatively small scale of data.**\n   - The benchmark includes 4,208 questions divided into seven categories, with only 450 unique images.\n   - It remains somewhat unclear whether such a dataset size is sufficient to comprehensively probe multimodal temporal sensitivity, especially given the complexity of real-world temporal reasoning.\n3. **Brief analysis of lifelong editing.**\n   - The section on “lifelong editing” is rather concise, and the underlying causes of catastrophic forgetting are not deeply analyzed.\n   - A more systematic examination of how editing interacts with multimodal representations would strengthen this part.\n4. **Evaluation metric limitations.**\n   - Heavy reliance on the *Correct Exact Match (CEM)* metric may underestimate partial correctness.\n   - Although F1 scores are reported in the appendix, the main results still depend primarily on strict matching, which might not fully reflect model understanding."}, "questions": {"value": "1. **On the necessity of multimodal extension:**\n    The motivation for extending temporal reasoning to multimodal settings could be further clarified.\n    If the underlying language model in a multimodal system already possesses temporal sensitivity, does the multimodal extension inherently inherit such ability?\n    What makes the multimodal setting particularly challenging or unique in this context?\n2. **On the temporal validity of images:**\n    Would it be more meaningful to incorporate visual changes over time—such as variations in a person’s appearance (childhood, adulthood, aging) or environmental transformations (seasons, locations)?\n    What is the essential difference between the temporal sensitivity problem in MINED and that in purely text-based temporal knowledge benchmarks?\n3. **On the simplicity of the knowledge representation:**\n    The benchmark relies on a quadruple-based knowledge structure $$(S,H,P,A)$$.\n    While this design enables systematic probing along the six dimensions introduced in Section 3.1, it might oversimplify the complexity of temporal evolution in real-world multimodal data.\n    Could the authors discuss whether this abstraction limits the benchmark’s ecological validity, and how future work might move toward more realistic, context-rich temporal scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BvHAyitkhG", "forum": "HXiIuSIztB", "replyto": "HXiIuSIztB", "signatures": ["ICLR.cc/2026/Conference/Submission365/Reviewer_oQfe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission365/Reviewer_oQfe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877418143, "cdate": 1761877418143, "tmdate": 1762915504294, "mdate": 1762915504294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose MINED, a comprehensive benchmark that evaluates temporal awareness along 6 key dimensions and 11\nchallenging tasks: cognition, awareness, trustworthiness, understanding, reasoning, and robustness. MINED is constructed from Wikipedia by two professional annotators, containing 2,104 time-sensitive knowledge samples spanning six knowledge types. The authors also evaluate more than 10 widely used LMMs in the proposed dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. In this paper, the authors propose MINED, a comprehensive benchmark that evaluates temporal awareness along 6 key dimensions and 11 challenging tasks: cognition, awareness, trustworthiness, understanding, reasoning, and robustness.\n\n2. MINED is annotated by professional annotators, containing 2,104 time-sensitive knowledge samples spanning six knowledge types"}, "weaknesses": {"value": "1. In this paper, I didn't find how to build such a dataset.  The authors only mention that To construct the foundational data for MINED, we employ two professional annotators to gather time-sensitive knowledge from Wikipedia across six domains: Country, Sport, Company, University, Organization, and Competition.\n\n2. Only two professional annotators are invovled in the annotation, How to deal with situations where two people have different opinions?\n\n3. In this paper, how to control the quality of the proposed dataset is unknown"}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bNlmSn5Ik6", "forum": "HXiIuSIztB", "replyto": "HXiIuSIztB", "signatures": ["ICLR.cc/2026/Conference/Submission365/Reviewer_bwJS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission365/Reviewer_bwJS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959032638, "cdate": 1761959032638, "tmdate": 1762915504116, "mdate": 1762915504116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}