{"id": "adIRd7KZsw", "number": 3821, "cdate": 1757537569657, "mdate": 1762944160186, "content": {"title": "The N-Body Problem: Predicting Parallel Execution from Single-Person Egocentric Video", "abstract": "Humans can intuitively parallelise complex activities, but can a model learn this\nfrom observing a single person? Given one egocentric video, we introduce the\nN-Body Problem: how N individuals, can together perform the same set of tasks\nobserved in this video. The goal is to maximise speed-up, but naive task allocation\noften violates real-world constraints, leading to physically impossible scenarios\nlike two people using the same object or occupying the same space. To address\nthis, we formalise the N-Body Problem and propose a suite of metrics to evalu-\nate both performance (speed-up, task coverage) and feasibility (spatial collisions,\nobject conflicts). We then introduce a structured prompting strategy that guides a\nVision-Language Model (VLM) to reason about the 3D environment, object us-\nage, and temporal dependencies to produce a viable parallel execution. On 100\nvideos from EPIC-Kitchens and HD-EPIC, our method for N = 2 boosts action\ncoverage by 45% over a baseline prompt for Gemini 2.5 Pro, while simultaneously\nslashing collision rates by 55% and object conflicts by 45%.", "tldr": "Given a single video, we predict how all tasks in that video can be carried out by multiple collaborating agents, allowing parallel task execution, using a VLM with prompts that encode the goals and constraints.", "keywords": ["Egocentric Video", "Activity Understanding", "Video Understanding"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/d4d19d23e2d81fa8b3faf1a528d4cf009893a846.pdf", "supplementary_material": "/attachment/3a315003da4d5e84ead838f73551e70c2ec10a54.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel framework for decomposing egocentric videos of single-agent tasks into parallelizable multi-agent execution plans, coined as the N-body problem for video understanding. Leveraging structured prompting with a Vision-Language Model (VLM), the authors demonstrate that collaborative execution plans (e.g., 2-body and 3-body) can be synthesized with consideration for physical, spatial, and causal constraints. Experimental evaluations on HD-EPIC and EPIC-KITCHENS datasets show that their prompting-based approach outperforms heuristic baselines and achieves better trade-offs between coverage, speed-up, and constraint violations."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* Novel Perspective: The core idea of transforming sequential task demonstrations into collaborative execution plans is both creative and timely, especially for robotics, home assistants, or collaborative AI systems.\n\n* Scalable Prompting Strategy: The structured prompt engineering is cleverly designed and shows practical effectiveness without requiring model finetuning.\n\n* Empirical Insight: The paper provides compelling qualitative and quantitative analysis, particularly the trade-off between speed-up and constraint violations as the number of agents increases (e.g., from 2-body to 3-body)."}, "weaknesses": {"value": "* No Explicit Modeling of Multi-Agent Orchestration: While the paper tackles multi-agent execution planning, it does so implicitly through VLM-driven segmentation and allocation. There is no explicit mechanism or learned model that handles orchestration dynamics such as role assignment.\n\n* Evaluated Plans Are Static: The output plans are static and non-adaptive. In real-world multi-agent orchestration, plans often need to be robust to execution variance (e.g., one agent moving slower, object unavailability), which is not addressed in this work. That said, this limitation seems more aligned with future work directions rather than a fundamental flaw."}, "questions": {"value": "* Agent-level Orchestration Modeling: Have you considered incorporating an explicit orchestration module (e.g., centralized or decentralized planner) to better model inter-agent dependencies and coordination, rather than relying entirely on the VLM's prompt-based reasoning?\n\n* Plan Adaptability: The current output plans appear static and offline. Do you envision integrating online feedback mechanisms or real-time adaptation (e.g., replanning based on agent delays or failures)?\n\nWhile the proposed approach introduces several valuable and creative design choices, some parts of the system remain unclear to me. I outline a few questions below to better understand the method's assumptions and practical implications."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "irKzNllpJi", "forum": "adIRd7KZsw", "replyto": "adIRd7KZsw", "signatures": ["ICLR.cc/2026/Conference/Submission3821/Reviewer_YiaF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3821/Reviewer_YiaF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3821/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761736176508, "cdate": 1761736176508, "tmdate": 1762917051409, "mdate": 1762917051409, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "8Zu6BN3IH8", "forum": "adIRd7KZsw", "replyto": "adIRd7KZsw", "signatures": ["ICLR.cc/2026/Conference/Submission3821/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3821/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762944158384, "cdate": 1762944158384, "tmdate": 1762944158384, "mdate": 1762944158384, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new task, the N-Body Problem, which aims to infer multi-agent parallel execution plans from single-person egocentric videos. The authors propose using a commercial vision-language model (Gemini 2.5 Pro) guided by structured prompts to assign task segments to hypothetical agents under spatial, object, and causal constraints.\nThe paper evaluates this setup using pseudo-metrics (coverage, speed-up, collision rate, etc.) on HD-EPIC and EPIC-Kitchens datasets, showing that structured prompting improves these numbers over baselines.\n\nThe idea is interesting in spirit — learning collaborative affordances from single-person data — but the current formulation and methodology raise significant concerns."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The high-level motivation (inferring potential collaboration from egocentric data) is original and thought-provoking."}, "weaknesses": {"value": "- **The proposed “N-Body Problem” feels largely problem-driven rather than insight-driven.**\nIn my view, the more fundamental and meaningful research problem lies in robustly extracting and representing a task graph - one that faithfully captures the temporal, spatial, and object-level dependencies among subtasks in egocentric video - rather than in defining the so-called “N-Body Problem.”\nIf such a task graph were reliably constructed (with each node representing a subtask and edges encoding temporal order, resource constraints, and spatial exclusivity), then the downstream scheduling of N agents becomes a deterministic problem. Classical methods in multi-processor scheduling, constraint optimization, or resource-constrained project scheduling (RCPSP) can already solve it efficiently and transparently.\nIn that sense, the “N-Body Problem” as introduced here seems to be a problem created for the sake of having a new formulation. It bypasses the more substantive challenge - learning or inferring the task graph itself - and instead focuses on generating pseudo-parallel plans from a single demonstration using heuristic prompting. The result feels less like addressing a fundamental research question, and more like constructing an artificial benchmark to justify prompt-based reasoning.\n\n- **Lack of Ground Truth and Proper Evaluation**\nFor such a synthetic and unconventional setup, ground truth data are essential.\nThe paper repeatedly mentions that no multi-agent parallel executions exist, and therefore resorts to pseudo-metrics like “coverage” and “speed-up” computed from the same single-person videos.\nThis undermines the credibility of the evaluation:\n  - The model is tested on its own synthetic metrics, not on real-world validation.\n  - There is no behavioral, human, or even simulated ground truth to measure whether the generated plans are feasible or efficient.\n  - Metrics like “speed-up” and “coverage” are uncalibrated and may not correlate with meaningful parallelism.\n\n  If the authors wish to define a new problem, they should also define a minimal benchmark with genuine ground truth — e.g., recording the same tasks performed collaboratively by multiple humans — rather than relying on self-referential measures.\n\n- The central “method” is essentially a handcrafted prompting template with additional CSV-based spatial context.\nWhile this may yield qualitative improvements, it is not a novel algorithmic contribution and depends entirely on a closed-source proprietary model (Gemini 2.5 Pro)."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nc9tFbYp2V", "forum": "adIRd7KZsw", "replyto": "adIRd7KZsw", "signatures": ["ICLR.cc/2026/Conference/Submission3821/Reviewer_DGvi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3821/Reviewer_DGvi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3821/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898147924, "cdate": 1761898147924, "tmdate": 1762917051051, "mdate": 1762917051051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces and formalizes a new task called the N-Body Problem. The core question is: given a single egocentric video of one person performing a complex set of tasks, can a model generate a valid plan for N people (or agents) to perform the same set of tasks in parallel? The goal is to maximize speed-up and task coverage and respect 1. Spatial constraints; 2. Object constraints; 3. Causality constraints. To solve this, they propose a structured prompting strategy to guide a state-of-the-art Vision-Language Model (VLM), Gemini 2.5 Pro. The key to their method is providing the VLM with explicit spatial and temporal information. They discretize the 3D environment into \"zones\" on the ground plane and provide the VLM with a CSV file detailing the time segments the original agent spent in each zone. The prompt then explicitly instructs the VLM to avoid scheduling two agents in the same zone at the same time. The authors evaluate their method on 100 long videos (avg. 25 min) from the EPIC-Kitchens and HD-EPIC datasets. Results show their full method significantly outperforms baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The “N-body problem” is novel and well-defined task that pushes video understanding from passive observation to active, generative reasoning and planning. This has clear implications for robotics, simulation, and embodied AI.\n2. The formalization of this paper is a key strength. The clear and distinct separation of **Goals** (to maximize) from **Constraints** (to minimize)  creates a robust framework that is highly valuable for structuring future research in this area."}, "weaknesses": {"value": "1. While the paper introduces a novel and compelling \"N-Body Problem,\" its current solution relies on a set of idealized assumptions and \"privileged\" information. As you've noted, these strong prerequisites significantly limit the method's applicability and feasibility in real-world scenarios.\n    1. Dependency on Ground-Truth Camera Poses: This is the most significant limitation. The method's ability to achieve low collision rates is almost entirely dependent on the Spatial Prompt, which is generated from ground-truth camera poses. In any practical application (e.g., a robot learning from a web video), this perfect, noise-free 3D trajectory is unavailable.\n    2. Simplistic \"No Extra Objects\" Assumption: The work evaluates object conflicts using an unrealistic \"closed-world\" assumption. It assumes that only the specific *instances* of objects used in the video exist (e.g., if one knife is used, the model assumes only one knife is available in the entire kitchen) in L195. This is fundamentally not how real-world environments work, as kitchens often contain multiple instances of common tools (spoons, bowls, knives).\n    3. Rigid and Unrealistic Handling of \"Wait\" Times: As you pointed out in L200, the model's handling of \"process\" tasks (like an oven baking, water boiling, or a microwave running) is deeply flawed and inconsistent with human behavior.\n2. Lack of Technical Contribution and Reliance on a Non-Deterministic \"Black Box\".\n    1. Minimal Technical Novelty: The paper's core method is not a new algorithm, model architecture, or learning technique. It is a \"prompt engineering\" solution that relies entirely on the pre-existing, proprietary capabilities of Gemini 2.5 Pro. While defining the problem and metrics is a contribution, the *solution* itself lacks technical depth and novelty.\n    2. No Guarantees of Optimality or Correctness: The solution is non-deterministic and lacks formal guarantees. As you rightly noted, VLMs are prone to hallucination and logical errors. There is no way to *ensure* the VLM's generated plan is correct, let alone optimal. The problem of task scheduling is a classic (NP-hard) optimization problem, yet this method replaces verifiable algorithms with a probabilistic, \"black-box\" heuristic that may fail in subtle or unpredictable ways (e.g., missing a less-obvious causal dependency) without any recourse.\n3. For the N-body problem for a given video, how do you determine what the optimal solution is? It seems there could be multiple solutions; how would you evaluate the diversity of these solutions?"}, "questions": {"value": "My main concerns focus on the problem definition, reliance on VLMs and the evaluation of the method. I acknowledge the contribution of the paper for proposing the “N-body” problem, yet I believe that the current version is inadequate for practical applications."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZpBGvSIfFj", "forum": "adIRd7KZsw", "replyto": "adIRd7KZsw", "signatures": ["ICLR.cc/2026/Conference/Submission3821/Reviewer_km5W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3821/Reviewer_km5W"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3821/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990139522, "cdate": 1761990139522, "tmdate": 1762917050232, "mdate": 1762917050232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel task called the N-Body task, which explores how N individuals can collaboratively perform the same set of actions observed in a given video. The authors claim that the primary goal of this task is to maximize speed-up. To tackle this problem, the authors first propose a set of metrics to evaluate both performance and feasibility. Additionally, they introduce a structured prompting strategy to guide Vision-Language Models (VLMs) in generating viable parallel executions. The authors validate the effectiveness of their proposed method through experiments on the EPIC-Kitchens and HD-EPIC datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The writing and structure of the paper are clear and easy to follow.\n- The proposed N-Body Problem is intriguing and likely has real-world applications.\n- The proposed evaluation metrics appear reasonable and capable of effectively measuring the goals and constraints."}, "weaknesses": {"value": "- Although the authors propose a structured prompting strategy to guide VLMs in addressing this problem, I believe it is unnecessary to have the VLM directly infer the final task execution results. A more reasonable approach would be to use VLMs and expert models to identify sub-actions and establish causal relationships between them, followed by traditional optimization algorithms to derive the final solution. I do not think that relying on prompt engineering to have the VLM solve this in one step offers practical value.\n- This work lacks substantial technical contributions. It primarily introduces a problem and devotes significant space to defining and describing evaluation metrics, while the proposed prompt design lacks technical innovation. This resembles a technical report rather than an academic paper.\n- The authors only conduct experiments on a single VLM. To demonstrate the effectiveness of the method, I believe it is necessary to test the proposed approach on more models and additional tasks."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HDOn9N0L3T", "forum": "adIRd7KZsw", "replyto": "adIRd7KZsw", "signatures": ["ICLR.cc/2026/Conference/Submission3821/Reviewer_br3n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3821/Reviewer_br3n"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3821/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762619872588, "cdate": 1762619872588, "tmdate": 1762917049967, "mdate": 1762917049967, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}