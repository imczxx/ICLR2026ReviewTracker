{"id": "UD4Rw8MOEK", "number": 19696, "cdate": 1758298505190, "mdate": 1759897025088, "content": {"title": "Verifier-free Test-Time Sampling for Vision Language Action Models", "abstract": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance in robot control. However, they remain fundamentally limited in tasks that require high precision due to their single-inference paradigm. While test-time scaling approaches using external verifiers have shown promise, they require additional training and fail to generalize to unseen conditions. We propose Masking\nDistribution Guided Selection (MG-Select), a novel test-time scaling framework for VLAs that leverages the model's internal properties without requiring additional training or external modules. Our approach utilizes KL divergence from a reference action token distribution as a confidence metric for selecting optimal action from multiple candidates. We introduce a reference distribution generated by the same VLA but with randomly masked states and language conditions as inputs, ensuring maximum uncertainty while remaining aligned with the target task distribution. Additionally, we propose a joint training strategy that enables the model to learn both conditional and unconditional distributions by applying dropout to state and language conditions, thereby further improving the quality of the reference distribution. Our experiments demonstrate that MG-Select achieves significant performance improvements, including a 28\\%/35\\% improvement in real-world in-distribution/out-of-distribution tasks, along with a 168\\% relative gain on RoboCasa pick-and-place tasks trained with 30 demonstrations.", "tldr": "We propose MG-Select, a masking distribution–guided test-time scaling method that enhances precision of Vision-Language-Action models in robotic manipulation.", "keywords": ["Vision-Language-Action Models", "Test-Time Scaling", "Robotic Manipulation"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3c6d97f58310a607809b353098ffd4690197b2d5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Masking Distribution Guided Selection (MG-Select), a verifier-free test-time scaling framework for Vision-Language-Action (VLA) models that enhances robotic action precision without additional training or external verifiers. MG-Select computes a confidence score based on the KL divergence between the model’s predicted action-token distribution and a reference distribution generated by masking input conditions (language or state), allowing the model to identify the most reliable action among multiple sampled candidates. A joint imitation learning strategy further improves this reference distribution by randomly dropping conditions during fine-tuning. Experiments on RoboCasa, SIMPLER-WidowX, LIBERO, and real-world Franka tasks show consistent gains—up to 168% relative improvement in low-data regimes—demonstrating that MG-Select effectively boosts precision and robustness while remaining computationally efficient and generalizable."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes Masking Distribution Guided Selection (MG-Select), a verifier-free test-time scaling approach for Vision-Language-Action (VLA) models. The method leverages internal condition-masking distributions to construct a self-generated confidence metric, which is a timely and meaningful contribution to the emerging direction of verifier-free test-time optimization.\n\n2. The methodology section (Section 3) is well structured and logically divided into sampling, confidence estimation, and joint training components.\n\n3. The experiments are comprehensive, spanning multiple simulation benchmarks (RoboCasa, SIMPLER-WidowX, LIBERO) and real-world setups (Franka Research 3). The results demonstrate consistent improvements, indicating good generality.\n\n4. The comparisons include strong baselines such as RT-1-X, Octo, RoboVLM, and SpatialVLA, which enhances credibility.\n\n5. Table 5 provides a detailed ablation over candidate number, masking variant, and aggregation strategy.\n\n6. The writing is clear, the structure follows ICLR standards, and Figure 1 effectively conveys the pipeline."}, "weaknesses": {"value": "1. The boundary of innovation is somewhat vague. The proposed confidence estimation is closely related to recent “self-certainty” or “TrustScore” approaches in LLMs (e.g., Zheng et al., 2024). The paper does not clearly articulate how MG-Select differs conceptually or theoretically—whether it introduces a new mathematical formulation, or provides theoretical guarantees for its confidence metric.\n\n2. Equation (2) for joint imitation learning is intuitively reasonable but lacks explanation regarding the fixed 10%/10%/10% masking ratio. No sensitivity analysis or theoretical rationale is provided for this choice. Similarly, the effect of the regularization temperature in the KL divergence is discussed empirically but not theoretically.\n\n3. Despite extensive experiments, there is a lack of qualitative or failure-case analysis. The method is only evaluated on pick-and-place tasks, while scenarios requiring language reasoning or multi-step planning are absent.\n\n4. Some baseline results are quoted from original papers, while MG-Select models are fine-tuned or re-trained under new settings, potentially introducing data or optimization biases.\n\n5. The paper gives only empirical explanations for why aggregating the first five tokens yields the best performance, without analyzing how this relates to the FAST tokenizer structure or action semantics.\n\n6. There are repeated phrases (e.g., “achieves significant performance improvements”), and the abstract’s statement of “168% relative gain” may be misleading without specifying the baseline reference."}, "questions": {"value": "1. Include a theoretical justification of why the KL divergence from a masked reference distribution correlates with action optimality. Formal statements or lemmas demonstrating its reliability would strengthen the novelty claim.\n\n2. Add more mathematical insight or justification in the appendix—for instance, derivations of how temperature regularization affects the entropy of the reference distribution, or an ablation on different masking ratios to validate robustness.\n\n3. Include representative failure cases or visualizations to illustrate limitations (e.g., when MG-Select slightly underperforms in LIBERO-Goal). Consider adding evaluations on more complex, compositional manipulation tasks to assess generalization breadth.\n\n4. Clearly specify which baselines are reproduced and which are cited from prior work. Provide full reproduction details (training steps, batch sizes, learning rates) in the appendix to ensure fair comparison.\n\n5. Add a visualization of token-level KL divergence over time or provide statistics on token-wise confidence contributions to improve interpretability and transparency.\n\n6. Tighten the abstract by focusing on conceptual insights rather than numeric claims, and clarify how relative improvements are computed. The conclusion could also better articulate MG-Select’s potential to shape future verifier-free test-time scaling paradigms in robotics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A8rn7pGQbC", "forum": "UD4Rw8MOEK", "replyto": "UD4Rw8MOEK", "signatures": ["ICLR.cc/2026/Conference/Submission19696/Reviewer_CKBD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19696/Reviewer_CKBD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760582911111, "cdate": 1760582911111, "tmdate": 1762931538427, "mdate": 1762931538427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MG-Select, a self-verifying test-time selection mechanism for Vision-Language-Action (VLA) models. Instead of relying on an external verifier or value function, MG-Select computes KL divergence between masked and unmasked modality predictions as a measure of epistemic uncertainty. The approach enables verifier-free scaling at inference and is evaluated on multiple robot manipulation datasets (RoboCasa, LIBERO, DROID). The authors claim performance improvements on OOD (out-of-distribution) tasks while reducing verifier overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper identifies a key bottleneck in large multimodal agent systems: dependency on external verifiers during test-time scaling. To solve this, this paper attempts to replace it with a lightweight, self-contained mechanism. The idea of using internal divergence between masked/unmasked representations as a proxy for self-consistency is an intellectually interesting alternative to ensemble- or verifier-based uncertainty estimation. This motivation aligns well with emerging trends in verifier-free inference for embodied models like OpenVLA or RT-2.\n\n2.\tMG-Select’s implementation is refreshingly simple: sample multiple candidate actions, compute divergences under masked inputs, and select the candidate with the smallest divergence. The method avoids retraining or architectural modification, making it plug-and-play for deployed VLAs. This simplicity could enable fast adoption in practical robotic systems.\n\n3.\tThe experiments span multiple datasets and include an ablation study on the number of samples and masking strategies. The consistency of improvement across different settings suggests the metric is robust to domain variation. Particularly, the evaluation on DROID with real-robot rollouts adds credibility to the claim of practical deployability."}, "weaknesses": {"value": "1.\tThe KL divergence between masked and unmasked predictions is treated as an uncertainty signal, but the paper does not connect it to a formal epistemic uncertainty framework. For example, there’s no derivation relating it to Bayesian variance, entropy-based uncertainty, or self-consistency under dropout. Without such justification, it remains an empirical heuristic.\n\n2.\tWhile MG-Select eliminates external verifiers, it performs multiple forward passes (one per candidate), which could offset computational gains. The authors mention this but provide no latency or throughput benchmarks. In real-time control, inference latency often dominates, and without such metrics, claims of “efficiency” are weak.\n\n3.\tAll evaluated tasks involve short-horizon manipulation with static visual backgrounds. The method’s efficacy under long-horizon planning, sequential reasoning, or language ambiguity (e.g., temporal grounding) remains unexplored."}, "questions": {"value": "1.\tHave you considered the effect of model scale—does MG-Select generalize across small and large VLAs?\n\n2.\tHow sensitive is performance to the number of candidates (N)? Does uncertainty estimation saturate after a threshold?\n\n3.\tCould masked divergence be integrated into learning-time regularization to improve robustness, rather than only test-time selection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EC0tKTsNDw", "forum": "UD4Rw8MOEK", "replyto": "UD4Rw8MOEK", "signatures": ["ICLR.cc/2026/Conference/Submission19696/Reviewer_6QZo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19696/Reviewer_6QZo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996292604, "cdate": 1761996292604, "tmdate": 1762931537805, "mdate": 1762931537805, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Masking Distribution Guided Selection (MG‑Select) to do test‑time scaling method for VLAs. \n\nThe idea is to generate N action candidates with stochastic decoding and then pick the one with the highest distributional confidence, defined as a KL divergence between the model’s conditional next‑action distribution and a reference distribution produced by the same model with certain inputs masked (text, state, or both). Experiments on RoboCasa, SIMPLER‑WidowX, LIBERO, and a Franka arm show consistent gains, especially in low‑data regimes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Simple and practical: Uses only the base VLA; no external verifier or extra training objective at inference time. Easy to bolt on to existing autoregressive policies\n\nGood performance gain especially in low-data and OOD settings."}, "weaknesses": {"value": "This method adds some latency due to increased compute"}, "questions": {"value": "1. Why choose main baseline as pi-0-fast? Which is not the best performing model by itself. What if applied on other model such as OpenVLA-OFT\n2. How does it compare to some test time training baseline such as simple entropy minimization methods?\n3. Can you provide more details about the masking strategy and aggregation design."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rw9chBt86u", "forum": "UD4Rw8MOEK", "replyto": "UD4Rw8MOEK", "signatures": ["ICLR.cc/2026/Conference/Submission19696/Reviewer_wMxK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19696/Reviewer_wMxK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762060965715, "cdate": 1762060965715, "tmdate": 1762931537044, "mdate": 1762931537044, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MG-Select, a verifier-free test-time scaling framework for Vision-Language-Action (VLA) models in robotics. Instead of relying on external verifiers or further model training, MG-Select leverages a KL-based confidence metric between a conventional model distribution and a reference distribution generated by masking certain language or state inputs. The method incorporates a novel joint training strategy to improve representations for both conditional and unconditional inputs, and is validated through comprehensive experiments on simulation and real-world benchmarks, achieving substantial improvements in both in-distribution and out-of-distribution robotic tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Verifier-free paradigm: The work addresses a clear practical limitation of prior VLA test-time scaling methods by eschewing external verifiers and any additional model components, simplifying deployment.\n\n- Elegant use of KL divergence: The use of KL divergence as a confidence measure between the “full information” and “condition-masked” distributions is both theoretically motivated and practically appealing, connecting well with recent LLM self-consistency work but tailored for the robotics domain."}, "weaknesses": {"value": "1. While the masking variants (text, state, both) and truncation (first 5 tokens in Table 5f) offer empirical benefit, the rationale for these choices is left at the level of intuition/hypotheses. Given that “naive summation” (Table 5f) performs quite poorly, a more careful analysis—perhaps formalizing when/why these aggregation choices yield confident actions—should be pursued.\n\n2.  The paper defines the action-level confidence as $C_{\\mathbf{a}}=\\sum_{i \\in \\mathcal{I}} \\mathrm{KL}(P_i | Q_i)$ (Section 3.2), but is not explicit about (i) whether KL is computed at each timestep over the full action token vocabulary or just next-token distributions, (ii) how $\\mathcal{I}$ is selected when token chunking is variable, and (iii) whether the reference $Q_i$ is static or recalculated for each sampled action sequence. The choices in Table 5f (Sum, Avg, First 5) are empirical, but the paper lacks a principled definition for $\\mathcal{I}$ in general VLA architectures."}, "questions": {"value": "1. Can the authors provide a direct, quantitative comparison or ablation with recent external-verifier methods (e.g., RoVer, RoboMonkey) on any of the main tasks or with open-sourced baselines, so as to substantiate claims of equal or better performance (and efficiency) of MG-Select?\n\n2. Table 5 shows that “Text-masking” performs best for most tasks—can the authors formalize or empirically analyze why this is the case, and whether this result holds if tokenization schemes or action domains are changed? How robust is this preference for “text masking” versus other possible masking strategies?\n\n3. The confidence metric $C_{\\mathbf{a}}$ is calculated over the first 5 tokens (Table 5f). Is this choice robust? Does aggregation over different token span sizes appreciably affect the selection quality, or is this a dataset-specific artifact?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cDVBbiWMNu", "forum": "UD4Rw8MOEK", "replyto": "UD4Rw8MOEK", "signatures": ["ICLR.cc/2026/Conference/Submission19696/Reviewer_jiih"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19696/Reviewer_jiih"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19696/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762152230507, "cdate": 1762152230507, "tmdate": 1762931536487, "mdate": 1762931536487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}