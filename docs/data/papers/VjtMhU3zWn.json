{"id": "VjtMhU3zWn", "number": 24445, "cdate": 1758356967241, "mdate": 1759896765708, "content": {"title": "SchemaRAG: Enhancing Knowledge-Intensive Reasoning of LLMs via Inference-Time Adaptive Schema", "abstract": "Retrieval-Augmented Generation (RAG) often struggles with integrating fragmented knowledge for complex reasoning tasks. Recent efforts introduce structural templates—such as graphs or knowledge-based organizations—to improve multi-document reasoning. However, they are constrained by their rigidity, failing to adapt to diverse, task-specific information structures and often omitting critical dependencies. To address this, we propose SchemaRAG: an adaptive schema-guided RAG framework. Instead of predefined formats like graphs, tables and chunks, SchemaRAG adaptively organize the factual information across documents based on query-specific requirements. Given the input query and documents, it first parses the query into sub-problems and generate strategies for schema constructions, then utilize the organized knowledge to generate final answer. Extensive experiments on real-world benchmarks demonstrate that SchemaRAG consistently outperforms state-of-the-art baselines in knowledge-intensive reasoning and generation quality. Our work highlights the importance of adaptive schema-guided strategies for advancing the capabilities of RAG systems in complex, domain-specific tasks.", "tldr": "", "keywords": ["Knowledge Intensive Reasoning", "RAG", "LLM"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c5208622cc7259f9f701f701b1473a3b7af41583.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SchemaRAG, an adaptive, schema-guided framework to improve multi-document reasoning in Retrieval-Augmented Generation. Unlike prior approaches that rely on rigid structural templates (e.g., fixed graphs, tables, or chunking), SchemaRAG dynamically organizes factual evidence according to the query’s needs. Given a query and retrieved documents, the system decomposes the query into sub-problems, devises strategies for constructing a fit-for-purpose schema, and then uses that organized knowledge to generate the final answer."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Better multi-document integration: Organizes evidence to capture critical dependencies that static templates often miss, improving cross-document reasoning.\n\n2. Interpretability: The constructed schema provides an explicit intermediate representation.\n\n3. Empirical strength: Demonstrates gains over strong baselines."}, "weaknesses": {"value": "1. The advantage over StructRAG is unclear. The paper doesn’t clearly isolate what SchemaRAG adds beyond StructRAG’s sub-questioning and format selection. Table 1’s “composite structures / construction / utilization” aren’t rigorously defined. Why and how each of “composite structures,” “construction,” and “utilization” impacts performance. The case study in Figure 3 seems driven by StructRAG’s graphing error, not by a principled limitation.\n\n2. Many steps rely on LLM prompts, but prompts (and prompt engineering choices) aren’t provided (even in appendix). The prompts may help to make the method clearer.\n\n3. Whether multiple full documents are first retrieved and then reorganized for utilization. If so, it seems bring large overhead compared to the ones retrieve a piece of knowledge. Table 4 shows no significant extra cost, especially in the Construction phase. Could you provide more explanation?"}, "questions": {"value": "Sea the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "irNCrKfDvf", "forum": "VjtMhU3zWn", "replyto": "VjtMhU3zWn", "signatures": ["ICLR.cc/2026/Conference/Submission24445/Reviewer_mGUh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24445/Reviewer_mGUh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24445/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826149493, "cdate": 1761826149493, "tmdate": 1762943085115, "mdate": 1762943085115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes SchemaRAG, a schema-guided Retrieval-Augmented Generation framework that adapts to the requirements determined from the query and the set of documents. SchemaRAG has been designed to improve knowledge-intensive reasoning tasks in Large Language Models. In contrast to previous works that used fixed templates like graphs and tables to represent queries and documents for indexing and generation purposes, the proposed SchemaRAG adapts the construction of the composite knowledge schema depending on the query and the set of documents. Formula-based indices are used as the knowledge structure. SchemaRAG consists of three main components: Schema Thinking, Schema Construction, and Schema Utilization. Experiments conducted in the Loong benchmark set, involving the legal, financial, and academia sectors, reveal the effectiveness of the proposed SchemaRAG compared to other competitive methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. In contrast to previous methods that considered only a limited set of structural choices, the proposed scheme assembles the structures of knowledge and indexes based upon the requirements of each query.\n\n2. Table 3's ablation study highlights the role of schema thinking, construction, and usage. In Figures 4-6, the visualization of schema distributions and case studies increases the clarity of the results.\n\n3. Figures 1 and 2 are highly informative in contrasting SchemaRAG’s adaptability against traditional, rigid methods and in depicting the pipeline of the proposed system."}, "weaknesses": {"value": "1. There is a contradiction between Definition 1 and Equation 5. Definition 1 implies U is built from a single document D. However, Equation 5 in Section 3.2 states U=K(D^1,D^2,...,D^n), which suggests the entire document collection is passed to the operator K to produce a single document's structure U. U^i appear derived from all documents, rather than per-document (U^i=K(D^i), expected). \n\n2. The entire framework's performance hinges on a predefined candidate set of knowledge structures K and index structures I. The paper does not discuss how this set was curated or how a user might extend it for a new domain with different structural properties.\n\n3. There is no direct, structured, or objective evaluation of schema correctness or interpretability. For example, how often are constructed schemas semantically appropriate (e.g., does a table schema capture real-world relationships), and could automated metrics for schema validity be provided?\n\n4. The cost comparison for GraphRAG (Table 4) reports a \"Construction Phase\" time of 215.3 minutes. This implies a per-query index construction, which is an unconventional and highly inefficient way to use a graph index (which is typically pre-computed over the corpus). If it is pre-computation, it should not be included in the per-query \"Total Phase\" time. This ambiguity makes the cost-benefit analysis versus GraphRAG difficult to interpret.\n\n5. The authors only compare SchemaRAG against original GraphRAG baselines. Several key and highly relevant baselines [1-6] are missing from the main results table (Table 1), which makes it difficult to assess the true contribution of SchemaRAG.\n\n[1] HippoRAG2: From RAG to Memory: Non-Parametric Continual Learning for Large Language Models\n\n[2] ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation\n\n[3] KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG\n\n[4] PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation\n\n[5] KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation\n\n[6] RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval \n\n6. As the authors mention in Appendix C.2, the experiments concentrate nearly exclusively on the legal, financial, and academic domains, as given in the Loong benchmark. Experiments are not given for open-domain tasks, conversation tasks, nor multi-modal tasks. This restricts the generalizability of SchemaRAG only to highly structured domains.\n\n7. No shared code, and this paper is not clear enough to reproduce the results."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wyyigMPWuh", "forum": "VjtMhU3zWn", "replyto": "VjtMhU3zWn", "signatures": ["ICLR.cc/2026/Conference/Submission24445/Reviewer_Urh7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24445/Reviewer_Urh7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24445/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967486242, "cdate": 1761967486242, "tmdate": 1762943084860, "mdate": 1762943084860, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SchemaRAG, an adaptive schema-guided Retrieval-Augmented Generation (RAG) framework designed to enhance the knowledge-intensive reasoning capabilities of Large Language Models (LLMs). Traditional RAG approaches, especially those augmented with structured templates (such as graphs or tables), often suffer from rigidity and a lack of adaptability to domain-specific or query-specific needs, leading to missed critical dependencies or the inclusion of irrelevant information. SchemaRAG addresses this by adaptively constructing a “knowledge schema” tailored to the particular query and associated documents at inference time. This schema is built through three modules: (1) Schema Thinking, which decomposes queries into sub-problems and generates schema strategies; (2) Schema Construction, which adaptively assembles domain-appropriate composite structures organizing facts within and across documents; and (3) Schema Utilization, which employs a hierarchical retrieval-merge mechanism to aggregate and synthesize information for answer generation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The writing and figures in the paper are clear.\n- The discussion of task-specific, especially query-specific, information in RAG is meaningful.\n- Compared to existing works that focus on improving structure-data construction, the proposed approach of building a schema for each query to facilitate retrieval is novel."}, "weaknesses": {"value": "- The main concern is the efficiency of the proposed method in real-world applications. Traditional structure-based RAG and GraphRAG incur a high cost during the initial graph construction, but after the knowledge is structured over the corpus, it rarely changes. During inference, they only need to perform retrieval and generation per query, which ensures efficiency. In contrast, SchemaRAG requires constructing knowledge schemas for each query and the overall corpus at inference time, meaning that construction, retrieval, and generation are all performed for every new query. This could introduce significant efficiency issues.\n\n- Another concern is how to avoid error accumulation during the schema construction phase, since a new schema tailored for each query and corpus is built at inference time. In traditional structure-based RAG and GraphRAG, inference and construction are separated, allowing structured knowledge to be updated and improved using external tools after construction. This is not possible in SchemaRAG, as all components are performed during inference.\n\n- Additionally, the baselines chosen from the GraphRAG domain in the experiments are not very representative. The paper does not compare against stronger and more efficient methods such as RAPTOR [1] and HIPPORAG2 [2], which are more competitive graph-based RAG baselines. Comparing SchemaRAG with these baselines, both in terms of accuracy and efficiency, would strengthen the paper.\n\n[1] RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\n\n[2] From RAG to Memory: Non-Parametric Continual Learning for Large Language Models"}, "questions": {"value": "As noted in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z6ix0Z2VXb", "forum": "VjtMhU3zWn", "replyto": "VjtMhU3zWn", "signatures": ["ICLR.cc/2026/Conference/Submission24445/Reviewer_9vpC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24445/Reviewer_9vpC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24445/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975737172, "cdate": 1761975737172, "tmdate": 1762943083956, "mdate": 1762943083956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SchemaRAG, an adaptive schema-guided framework for improving knowledge-intensive reasoning in large language models. Unlike prior structure-based RAG methods that rely on fixed templates such as graphs or tables, SchemaRAG dynamically constructs query- and domain-specific schemas at inference time, enhancing flexibility and contextual relevance. The approach consists of three main components: Schema Thinking, which analyzes the query and retrieved documents to determine schema strategies; Schema Construction, which builds hierarchical composite structures integrating knowledge and index information; and Schema Utilization, which employs a hierarchical retrieval–merge mechanism for final answer generation. Experiments on the Loong benchmark across legal, financial, and academic domains demonstrate that SchemaRAG outperforms other baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ The paper presents SchemaRAG, a multi-stage, adaptive schema-guided framework that effectively enhances knowledge-intensive reasoning in large language models.\n+ The modular pipeline design  from parsing, strategy formulation, construction to utilization,  provides flexibility and interpretability, addressing the rigidity of fixed-structure RAG methods.\n+ Experimental results demonstrate strong reasoning performance and scalability to large contexts, validating the effectiveness of the proposed schema construction and utilization process."}, "weaknesses": {"value": "- The framework’s multi-step pipeline raises concerns about error propagation across stages. It is unclear how the system handles upstream errors. For instance, if the schema planning or task parsing stage incorrectly decomposes a query, can later stages recover, or does this inevitably degrade the final reasoning outcome?\n- The main drawback of SchemaRAG lies in its resource consumption. The multi-stage reasoning, construction, and hierarchical utilization processes introduce additional inference steps, leading to higher token usage and API call overhead, particularly during the utilization stage.\n- Although the framework emphasizes adaptive schema generation, the “schema thinking” module does not appear to directly guide or optimize the retrieval process. For instance, if the module identifies a “tabular” schema, it could prompt the retriever to prioritize documents containing financial tables or structured data, thereby improving the efficiency and relevance of schema construction."}, "questions": {"value": "How does the system behave when the schema generation step fails to capture the correct task structure? Could incorporating uncertainty estimation or schema verification improve the stability and interpretability of the reasoning process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CBhF0GEgRV", "forum": "VjtMhU3zWn", "replyto": "VjtMhU3zWn", "signatures": ["ICLR.cc/2026/Conference/Submission24445/Reviewer_Vc2h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24445/Reviewer_Vc2h"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24445/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996821546, "cdate": 1761996821546, "tmdate": 1762943083761, "mdate": 1762943083761, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}