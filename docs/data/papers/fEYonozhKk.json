{"id": "fEYonozhKk", "number": 18724, "cdate": 1758290427069, "mdate": 1759897084686, "content": {"title": "AP-OOD: Attention Pooling for Out-of- Distribution Detection", "abstract": "Out-of-distribution (OOD) detection, which maps high-dimensional data into\na scalar OOD score, is critical for the reliable deployment of machine learning\nmodels. A key challenge in recent research is how to effectively leverage\nand aggregate token embeddings from language models to obtain the OOD\nscore. In this work, we propose AP-OOD, a novel OOD detection method\nfor natural language that goes beyond simple average-based aggregation by\nexploiting token-level information. AP-OOD is a semi-supervised approach\nthat flexibly interpolates between unsupervised and supervised settings,\nenabling the use of limited auxiliary outlier data. Empirically, AP-OOD\nsets a new state of the art in OOD detection for text: in the unsupervised\nsetting, it reduces the FPR95 (false positive rate at 95% true positives) from\n27.77% to 5.91% on XSUM summarization, and from 75.19% to 68.13% on\nWMT15 En–Fr translation.", "tldr": "", "keywords": ["out-of-distribution detection", "attention pooling", "nlp", "language models"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/89a6977119a13412871d80ebdc96327c634b7fe1.pdf", "supplementary_material": "/attachment/9932de467d574bf01db5b3134f42b19480cf2e35.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes AP-OOD, an iteration on OOD detection using Mahalanobis distance with token embeddings [1]. In particular, by replaces mean pooling of token embeddings with learnable attention pooling to improve OOD detection in text models. The authors provide rigorous theoretical background as well as empirical evaluations to showcase the validity of AP-OOD. Additionally, the paper presents the methodology in both its supervised formulation (leveraging auxiliary data) and unsupervised formulation.\n\n[1] Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, and Peter J Liu. Out-of-distribution detection and selective generation for conditional language models. In The Eleventh International Conference on Learning Representations, 2023."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The reviewer notes the following strengths:\n- The paper presents a very clear motivation, with clear justifications on why its nessacary to leverage token-level information beyond mean-pooling.\n- The paper is backed with sound theoretical background which helps frame the entire work and adds valuable contribution to the OOD detection field.\n- The empirical analysis showcases meaningful improvements upon the baseline, with indications that the methodology can be applicable beyond the base text modality (given audio classification evaluations)."}, "weaknesses": {"value": "The reviewer notes the following weakness:\n- Although the improvement is measurable, the incorporation of learnable attention pooling into Mahalanobis distance is not conceptually groundbreaking and may hinder the novelty of the overall work.\n- The paper presents few intuitive explanations for overall observations leading to difficulties in finding the novelty of the work.\n- The lack of experiments on larger, more realistic language models, potentially makes the work less applicable in real-world settings."}, "questions": {"value": "The reviewer would like to encourage the authors to revisit the presentation of the overall work. In particular, much of the background can be attributed to Ren et al's paper and could be instead used to visit some of the ablations experiments presented in the appendix [1]. Additionally, more focus on the novelty of the underlying work whether that be the theoretical or algorithmic contribution would help improve the overall quality of the paper.\n\n[1] Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, and Peter J Liu. Out-of-distribution detection and selective generation for conditional language models. In The Eleventh International Conference on Learning Representations, 2023."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2LofC5OSJk", "forum": "fEYonozhKk", "replyto": "fEYonozhKk", "signatures": ["ICLR.cc/2026/Conference/Submission18724/Reviewer_QF7M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18724/Reviewer_QF7M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624903010, "cdate": 1761624903010, "tmdate": 1762928432752, "mdate": 1762928432752, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AP-OOD, a novel method for out-of-distribution (OOD) detection in natural language tasks that leverages token-level information instead of simple average-based embedding aggregation. Operating in a semi-supervised framework, AP-OOD flexibly combines unsupervised and supervised approaches by using limited auxiliary outlier data."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation for using standard Gaussian-based averaging is well explained.\n- The paper presents an interesting and original idea.\n- The authors thoughtfully explore multiple use cases to demonstrate the method’s applicability."}, "weaknesses": {"value": "- The paper suffers from clarity and presentation issues. The introduction does not sufficiently articulate the limitations of existing methods or explain how the proposed approach addresses them. The methodology section is overly condensed and lacks precision, with several symbols insufficiently defined. Moreover, the authors do not reference the accompanying pseudocode. Overall, the manuscript appears hastily written and insufficiently polished.\n\n- Although the approach is presented as semi-supervised, the paper merely demonstrates a transition between supervised and unsupervised scenarios without providing a clear formulation or justification for the semi-supervised setting. Additionally, the proposed supervised out-of-distribution scenario appears limited in practical applicability, as it does not reflect realistic deployment conditions.\n\n- The experimental setup is restricted to a simplistic baseline where embeddings are averaged across sequences, effectively assuming a Gaussian distribution. This assumption is unnecessarily restrictive, as the embedding distribution could be more accurately modeled using mixture models or more expressive probabilistic frameworks such as normalizing flows.\n\n- The concatenation of Z-embeddings (Algorithm 1, line 8) is likely infeasible for larger datasets due to significant memory constraints, which raises concerns about the scalability of the proposed approach.\n\n- The proposed model assumes access to the training data during OOD detection, which severely limits its applicability in realistic or privacy-sensitive scenarios where such access is unavailable.\n\n- The experimental comparison is incomplete. The authors evaluate primarily against standard baselines while omitting several important domain-specific OOD detection methods, such as:\n\nDirected Sparsification – Yiyou Sun and Yixuan Li (2022), DICE: Leveraging Sparsification for Out-of-Distribution Detection.\n\nVirtual-logit Matching – Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang (2022), VIM: Out-of-Distribution Detection with Virtual-Logit Matching (NeurIPS).\n\nGradNorm – Rui Huang, Andrew Geng, and Yixuan Li (2021), On the Importance of Gradients for Detecting Distributional Shifts in the Wild (NeurIPS)."}, "questions": {"value": "Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NKtXgaqcSZ", "forum": "fEYonozhKk", "replyto": "fEYonozhKk", "signatures": ["ICLR.cc/2026/Conference/Submission18724/Reviewer_M9r8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18724/Reviewer_M9r8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761688828276, "cdate": 1761688828276, "tmdate": 1762928431962, "mdate": 1762928431962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors address the problem of out-of-distribution (OOD) detection in natural language processing, highlighting the limitation of mean pooling approaches that lose token-level information. To overcome this, the authors propose AP-OOD, a novel OOD detection method that uses attention pooling to assign higher weights to informative tokens within a sequence. The method builds upon the Mahalanobis distance and introduces attention pooling to better utilize token-level information during OOD scoring. AP-OOD can operate in unsupervised, semi-supervised, and supervised settings and demonstrates improvements over existing baselines across various tasks, including summarization, translation, and audio data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper moves beyond prior OOD detection approaches that focused on summarizing the entire sentence through mean pooling, introducing a new method that leverages token-level information via attention pooling.\n\n2. By using a toy experiment to intuitively illustrate why attention pooling outperforms mean pooling, the paper clearly and convincingly conveys the core idea of the proposed method."}, "weaknesses": {"value": "1. The model requires extensive grid search over β, M, T, and λ, which significantly increases computational cost. Since AP-OOD relies on an attention pooling mechanism, each configuration must be trained separately, making the search process expensive. This can limit scalability and practicality when applied to large datasets.\n\n2. Although the paper claims that the unsupervised setting does not use AUX data for training, it still leverages AUX samples for hyperparameter selection. Moreover, the model’s performance appears highly sensitive to hyperparameter choices. This effectively makes the selection process semi-supervised and may introduce bias if the AUX distribution differs from the OOD distribution encountered at test time. As a result, the chosen model may not generalize reliably across unseen OOD scenarios."}, "questions": {"value": "1. Attention weights indicate where the model is “looking,” but they do not necessarily reflect the tokens that causally contribute to the OOD decision. Could the authors empirically verify whether higher attention values actually correspond to greater influence on the final OOD score? Could the authors show if tokens with higher attention are indeed more important for the model’s OOD detection?\n\n2. In Section A.2, the paper states that the Mahalanobis distance and the proposed decomposition are “equivalent”.  However, this statement seems mathematically ambiguous. It is unclear whether this equivalence truly holds for arbitrary linearly independent w_j. As currently written, the derivation seems to assume equivalence without sufficient justification. Could the authors explain this step in more detail?\n\n3. The authors set the number of parameters in AP-OOD to match that of the Mahalanobis baseline for a fair comparison. However, it would be interesting to see how much further the performance could improve if the model were allowed to use a larger capacity.\n\n4. AP-OOD employs multiple heads and multiple queries per head to capture diverse token-level informations. However, it remains unclear whether different heads and queries actually learn distinct OOD-related patterns or if they are largely redundant. Could the authors provide qualitative or quantitative evidence showing the contribution of each head to OOD detection? Such analysis would help clarify whether the attention structure learns meaningful diversity rather than merely increasing model capacity.\n\n5. The authors mention that they ensure a fair comparison by matching the number of parameters between AP-OOD and the Mahalanobis baseline. However, this fairness applies only to model size, not necessarily to computational complexity or inference cost. It would be helpful to clarify how much additional computational overhead AP-OOD introduces in practice and whether this extra cost is justified by the observed performance improvements.\n\nPlease answer the questions in the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NH0bQpgXJD", "forum": "fEYonozhKk", "replyto": "fEYonozhKk", "signatures": ["ICLR.cc/2026/Conference/Submission18724/Reviewer_WMzy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18724/Reviewer_WMzy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961202995, "cdate": 1761961202995, "tmdate": 1762928430463, "mdate": 1762928430463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper points out the limitations of mean pooling for sequence representations and proposes Attention Pooling (AP-OOD) to compute OOD scores while preserving token-level information. The method uses attention (i) within each sequence and (ii) corpus-wide to estimate representative embeddings, then computes a distance/score between the input sequence’s token embeddings and the pooled corpus statistics.\n\nDuring training, the backbone LM is frozen and only the AP-OOD module is trained; the approach applies seamlessly from unsupervised (ID-only) to semi-supervised settings using AUX data. The evaluation covers summarization (PEGASUS-LARGE trained on XSUM), translation (Transformer-base trained on WMT15 En–Fr), and audio (MIMII-DG), and reports both input-OOD (encoder embeddings) and output-OOD (decoder embeddings).\n\nIn experiment results, the paper shows improved AUROC and reduced FPR@95TPR, with especially large gains over embedding-based alternatives on summarization and audio."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Replaces mean pooling with a learned attention-pooling formulation for OOD scoring; the paper clearly decomposes Mahalanobis into attention pooling and illustrates the failure mode of mean pooling with an intuitive toy example.\n\n- Broad empirical coverage across two NLG tasks and one audio task; AP-OOD improves AUROC/FPR95 in unsupervised, semi-supervised, and supervised regimes, with consistent AUX scaling curves. The audio experiment demonstrates modality generality (MIMII-DG)."}, "weaknesses": {"value": "- (W1) Scope limited to task specific backbone models: \nThe models used (PEGASUS-LARGE or Transformer-base) do not consider modern LLMs (e.g., Llama, Qwen, Phi, etc.). Even if one assumes task-specific language models, today’s practice allows fine-tuning LLMs or few-shot (in-context) learning. Defining ID vs. OOD simply as “training data vs. domain-shifted datasets” can be somewhat unrealistic for contemporary LLM usage.\n\n- (W2) Does not directly address hallucination:\nHallucination is a central issue in language generation. While OOD detection is related to hallucination mitigation, the paper offers no empirical evidence or discussion of how AP-OOD might help reduce hallucinations."}, "questions": {"value": "**Please provide responses to the reviews mentioned in the Weaknesses section.**\n\n**Additional questions**\n\n(Q1) Application to modern LLMs & hallucination mitigation:\n- Why wasn’t AP-OOD validated on advanced open-source LLMs such as Llama, Qwen, or Phi?\n\n(Q2) Input-/Output-OOD for unsafe or malicious prompts:\n- (Q2-1) How should AUX be constructed to enable reliable detection of unsafe prompts (e.g., jailbreaks or prompts that solicit illegal activity)?\n- (Q2-2) Based on the method and the reported results, do you expect AP-OOD to be effective for blocking malicious inputs (and, by extension, for detecting unsafe outputs)? If so, under what conditions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DKnptU9WQO", "forum": "fEYonozhKk", "replyto": "fEYonozhKk", "signatures": ["ICLR.cc/2026/Conference/Submission18724/Reviewer_18Vp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18724/Reviewer_18Vp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971997093, "cdate": 1761971997093, "tmdate": 1762928429186, "mdate": 1762928429186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}