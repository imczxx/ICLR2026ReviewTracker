{"id": "G6scrBvQCL", "number": 20052, "cdate": 1758301908352, "mdate": 1759897004151, "content": {"title": "Deep Progressive Training: scaling up depth capacity of zero-layer model", "abstract": "Model depth is a double-edged sword in deep learning: deeper models achieve higher accuracy but require higher computational cost. To efficiently train models at scale, progressive training -- an effective strategy where model capacity scales up during training, has emerged to significantly reduce computation with little to none performance degradation.\nIn this work, we study the depth expansion of large-scale models through the lens of optimization theory and feature learning, offering insights on the initialization of new layers, hyperparameter transfer, learning rate schedule, and timing of model expansion. Specifically, we propose zero-layer single-stage progressive training for the optimal tradeoff between computation and loss (and accuracy). For example, zero-layer progressive training on GPT2 can save $\\approx 80\\%$ compute, or equivalently accelerate by $5\\times$, and achieve a loss comparable to a fully trained 60-layer model with 7B parameters.", "tldr": "Progressive training by expanding a zero-layer model to multi-layer model is the most efficient without loss degradation.", "keywords": ["deep leaning", "progressive training", "model growth", "optimization", "feature learning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/26d1d90e771dfd3dc473b18eb8d6db6257921ebd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a zero-layer progressive training framework to improve training efficiency for large-scale deep models. Instead of training a full-depth network from scratch, the method begins with a minimal (“zero-layer”) model and progressively expands its depth during training. The authors provide both theoretical analysis (based on convex optimization and feature learning theory) and empirical validation on GPT2, ResNet, and MoE architectures."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a novel and practical zero-layer progressive training paradigm that reduces computation cost by up to 5× with minimal accuracy loss.\n2. The convergence analysis rigorously connects progressive training to convex optimization and projected gradient descent, adding rare theoretical depth.\n3. Experiments across ResNet, GPT2, and MoE comprehensively validate the method under various initialization, expansion, and scheduling settings."}, "weaknesses": {"value": "1.  The paper contains minor spelling mistakes such as “progrssive training” instead of progressive [L79] and “initialziation” instead of initialization [L214].\n2. The paper does not include quantitative comparisons with related progressive or model expansion baselines (e.g., Net2Net, Gong et al. 2019, Yang et al. 2020, Wang et al. 2023a, Tan et al. 2024), which are discussed in Section 1.1–1.2 but not experimentally compared. This limits the ability to assess improvements over prior methods.\n3. The experiments mainly evaluate GPT2 and ResNet models (Sections 2 and 7), but scalability to models larger than GPT2-7B or to other architectures such as multimodal or recurrent networks is not analyzed. Potential failure cases and computational constraints are not discussed."}, "questions": {"value": "1. How does the proposed method perform when expanding both width and depth simultaneously? \n2. Can the authors discuss potential instability in architectures without residual connections? \n3. Is the WSD schedule critical, or could cosine warm restarts or adaptive schedulers achieve similar effects?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ajhm4FQgrm", "forum": "G6scrBvQCL", "replyto": "G6scrBvQCL", "signatures": ["ICLR.cc/2026/Conference/Submission20052/Reviewer_2adh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20052/Reviewer_2adh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20052/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761293777336, "cdate": 1761293777336, "tmdate": 1762932946964, "mdate": 1762932946964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a progressive training strategy called Deep Progressive Training (DPT), which dynamically expands model depth during training to improve efficiency in large-scale model training. The authors analyze the depth expansion process from an optimization-theoretic perspective, offering insights into initialization strategies, hyperparameter transfer, and the timing of expansion. Experiments on GPT-2 and ResNet demonstrate that the proposed method achieves substantial improvements in training efficiency while maintaining competitive performance.\n\nKey Reasons:\n1. The paper presents a novel and practical direction in progressive training, particularly with the proposed zero-layer depth expansion strategy.\n2. Combining theoretical insights with thorough experimental validation, the work provides meaningful inspiration and practical value for efficient large-scale training.\n\n\nSupporting Arguments\n\nThe proposed zero-layer progressive training redefines conventional notions of “small models” in progressive training and offers a fresh conceptual perspective. The experimental design is rigorous, with validations across multiple models, scales, and stages, enhancing confidence in the approach. A simple and practical training recipe is also provided, which offers clear guidance for practitioners. However, the method has not yet been tested on popular large-scale LLM architectures such as LLaMA or Qwen, which would strengthen its impact."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides convergence analysis grounded in convex optimization theory, offering an interpretable framework for understanding progressive depth expansion.\nExtensive experiments on GPT-2, ResNet, and MoE models demonstrate the generality and effectiveness of the approach across diverse architectures.\n2. The proposed method achieves comparable or better performance with significantly reduced computational costs through a single-stage depth expansion strategy."}, "weaknesses": {"value": "1. The convergence analysis is based on convex loss assumptions, which may limit its applicability to realistic non-convex deep learning settings.\n2. The paper lacks direct comparisons with related efficient training methods such as knowledge distillation, model compression, or MoE-based strategies, which limits the comprehensiveness of the evaluation.\n3. The ablation studies are limited — for example, the definition and impact of “mixing time,” and the stability of different initialization strategies at larger scales are not thoroughly explored.\n4. The proposed method has not been evaluated on more recent large-scale architectures (e.g., LLaMA, Qwen), which would further validate its generality."}, "questions": {"value": "1. Can zero-layer progressive training maintain the reported 5× acceleration at larger scales (e.g., >10B parameters) or on other architectures such as LLaMA or Qwen?\n2. Have you considered integrating your approach with other efficient training techniques such as knowledge distillation, model compression, or MoE? Are there potential synergies or conflicts?\n3. Since your theoretical analysis assumes convex loss functions, do you plan to extend the analysis to non-convex settings or derive tighter convergence bounds?\n4. Has the method been evaluated on other modalities or task domains (e.g., multimodal learning)? If so, do you have preliminary evidence of its effectiveness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "FHsj1hAOkn", "forum": "G6scrBvQCL", "replyto": "G6scrBvQCL", "signatures": ["ICLR.cc/2026/Conference/Submission20052/Reviewer_v2fW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20052/Reviewer_v2fW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20052/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761532196798, "cdate": 1761532196798, "tmdate": 1762932946431, "mdate": 1762932946431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies deep progressive training in neural network pretraining. Extensive experiments including ResNets, transformers, and MoEs show the how, when, and which to perform depth expansion. Proposed configuration, which expands from zero-layers, provides 80% computational savings. The authors also provide theoretical justification for the insights with convex and Lipschitz continuous conditions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The experiments are extensive, including different architectures, different learning rate schedules, and different expansion methods, which should provide great insights for researchers in the field. Authors also provide recommendations in Section 7 that are easy to implement."}, "weaknesses": {"value": "1. The main concern is that there is possibly a derivation flaw in Section 4. More specifically, the authors try to obtain the difference of two losses by substracting two upper bounds. However, from 4.3,4.4 to 4.5, we cannot substract inequalities in opposite directions to get a valid bound on the difference. Hence, the theoretical justification as presented is incorrect and undermines the paper's theoretical contributions. (It is possible that I missed some intermediate steps, authors, please correct me if I am wrong.) Moreover, the condition of the derivation is too strong with convex and Lipschitz settings.\n2. There are many typos and formatting issues in the paper, see questions. Zero-layer is also not defined in the paper."}, "questions": {"value": "1. Figure 2 title: Left and right subfigures are mislabeled.\n2. There are some citing format issues where \\citet is used rather than \\citep.\n3. See weaknesses 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7iwEN5mlN7", "forum": "G6scrBvQCL", "replyto": "G6scrBvQCL", "signatures": ["ICLR.cc/2026/Conference/Submission20052/Reviewer_Q6T9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20052/Reviewer_Q6T9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20052/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761539343217, "cdate": 1761539343217, "tmdate": 1762932946045, "mdate": 1762932946045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}