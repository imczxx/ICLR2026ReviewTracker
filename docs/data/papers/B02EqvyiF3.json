{"id": "B02EqvyiF3", "number": 16991, "cdate": 1758270985572, "mdate": 1763660828761, "content": {"title": "A Spectral-Grassmann Wasserstein metric for operator representations of dynamical systems", "abstract": "The geometry of dynamical systems estimated from trajectory data is a major challenge for machine learning applications. Koopman and transfer operators provide a linear representation of nonlinear dynamics through their spectral decomposition, offering a natural framework for comparison. We propose a novel approach representing each system as a distribution of its joint operator eigenvalues and spectral projectors and defining a metric between systems leveraging optimal transport. The proposed metric is invariant to the sampling frequency of trajectories. It is also computationally efficient, supported by finite-sample convergence guarantees, and enables the computation of Fréchet means, providing interpolation between dynamical systems. Experiments on simulated and real-world datasets show that our approach consistently outperforms standard operator-based distances in machine learning applications, including dimensionality reduction and classification, and provides meaningful interpolation between dynamical systems.", "tldr": "A state-of-the-art operator-based metric for dynamical systems, robust to sampling, opening up to machine learning applications, and meaningful interpolation.", "keywords": ["dynamical system", "optimal transport", "transfer operator", "koopman operator"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/71b83efc93a9c2ba251eeddfd89f21a9f560c596.pdf", "supplementary_material": "/attachment/545c96bd6a13a2a7dddcd7bc644a45253996ffec.zip"}, "replies": [{"content": {"summary": {"value": "The authors proposed a representation of each dynamical system as a probability distribution over its joint operator eigenvalues and spectral projectors on the Grassmann manifold. They defined a metric between systems using optimal transport with a cost function that balances spectral information and geometric information, i.e., the eigenspace distances on the Grassmann manifold."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a new metric called Spectral-Grassmann Optimal Transport (SGOT) distance for comparing dynamical systems through their Koopman or transfer operator representations. Its main strength lies in integrating spectral and subspace information within an optimal transport framework, which is an original formulation that helps address several limitations of prior operator-based metrics. The theoretical analysis includes finite-sample guarantees, and the presentation is generally clear. The experiments provide evidence supporting the method’s potential usefulness in practical applications."}, "weaknesses": {"value": "(1) All experiments use linear kernels. There is no exploration of RBF, polynomial, or learned kernels;\n(2) Assumption (A3) requires a shared RKHS $\\mathcal{H}$ that simultaneously contains the low-rank images of all Koopman operators. It is unclear how one could construct or validate such a space in real applications. Different dynamical systems may have very different scales and smoothness properties;"}, "questions": {"value": "(1) In Theorem 2, how would you verify the conditions $[(C_x^k)^{\\dagger}]^{\\frac{\\alpha - 1}{2}}T_k$ and $\\lambda_i(C_x^k)^{\\dagger}$ by data?\n(2) Theo theory replies on assumptions A1-A3, which is convenient to compare between the operator from different systems, but are they assured in practical cases?\n(3) When $\\lambda_j$ has multiplicity $m_j>1$, how is the space $V_j$ uniquely defined?\n(4) Do we also need to show that $V_j$ is independent of basis choice?\n(5) Is $d_{\\mathcal{S}}(T, T')$ independent of the choice of bi-orthogonal basis used to represent spectral decompositions? It is unclear whether $d_{\\mathcal S}(T, T')$ is intrinsic, i.e., independent of the choice of bi-orthogonal basis used to represent the spectral decomposition when eigenvalues have multiplicity > 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bG4DVfqAzD", "forum": "B02EqvyiF3", "replyto": "B02EqvyiF3", "signatures": ["ICLR.cc/2026/Conference/Submission16991/Reviewer_AGY8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16991/Reviewer_AGY8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16991/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760772968721, "cdate": 1760772968721, "tmdate": 1762927009185, "mdate": 1762927009185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global response"}, "comment": {"value": "We thank all reviewers for their constructive feedback. Several comments touched on aspects: (i) the generality of our framework, and its dependence on operator estimators, (ii) the role of the common functional space assumption, (iii) computational scalability and (iv) experimental validation of the method. We address these key points here.\n\n### **1. SGOT is a *comparison* framework, not an estimation method**\n**SGOT is an estimator-agnostic, principled, and computationally efficient metric for comparing (stochastic) dynamical systems.** Importantly, SGOT is **not** a method for estimating transfer or Koopman operators.\n\nPractitioners may use any relevant kernel method, EDMD variant, dictionary learning, or neural architectures to learn a **finite-rank spectral representations** of the underlying transfer operators and then use our SGOT metric to compare them.\n\n**Once operators are estimated in a shared functional space, SGOT offers a fast and well-behaved metric to compare them.**\n\nOur theoretical analysis is developed in the RKHS + RRR setting for comparing systems at equilibrium because this framework offers sharp well-understood spectral guarantees for estimation of the operators, **not** because SGOT depends on RKHS methodology nor because it is limited to systems at equilibrium.\n\n### 2. Why a *common functional space* (A3) is needed\nSGOT compares **spectral subspaces** via Grassmannian geometry, which is only meaningful if all subspaces lie in the *same* ambient space. This is why Assumption (A3) is required: it ensures that operators are compared on the part of their action that is consistently represented across systems.\n\nThis corresponds to projecting operators onto a **shared functional space**. If this projection is accurate, so that the missing components are small, then SGOT provides an accurate comparison. Violations of A3 can be diagnosed through the metric distortion between the chosen common subspace and the true operator domain, a phenomenon quantified in Kostic et al. (2023), where an efficient estimator of this distortion is provided.\n\nFinally, we would like to draw attention of the reviewers to lines 167-173 of our original subission, and stress out that our A3 is significanly weaker compared to the regularity assumption under which SOTA guarantees from the above cited work were obtained.\n\n* Kostic et al. (2023). Sharp spectral rates for Koopman operator learning, NeurIPS (2023).\n\n**Practical construction of the common space can be:**\n\n* **Any RKHS with a universal bounded kernel (e.g., RBF)**, whose closure is well known to be contained in every $L^2_\\pi(\\mathcal{X})$ associated with ergodic dynamical systems, or\n* **A learned shared embedding** produced by representation-learning methods, designed so that all operators are represented in a common finite-dimensional space that minimizes projection biases. \n\nMany existing approaches correspond to the cases above. We will make this clearer in the revision.\n\n### 3. SGOT is computationally efficient\nSGOT is very fast once spectral decompositions are available. In particular:\n\n* rank-1000 operators with pre computed cost matrices can be compared in **less than 100 ms** with exact OT solvers,\n* SGOT is **≈40× faster** than Hilbert–Schmidt and **≈100× faster** than the operator norm (Appendix C.2).\n\nIf RKHS methods are used, then approximation techniques (Nyström, RFF, low-dimensional embeddings) provide further scalability when needed.\n\n### 4. Additional Experiments\nWe added three additional experiments to the paper:\n1. **Classification using operators estimated with RBF kernels (App. G.3)**\n2. **Classification using operators estimated with kernel based on learned deep features (App. G.4)**\n3. **Sensitivity analysis of the parameter controlling the trade-off between eigenvalue and eigensubspace costs (App. G.5)**\n\n**Classification results:** Across all classification settings, the **SGOT metric consistently outperforms all alternative metrics** on most datasets, as shown in the average-rank table:\n\n**Average rank (lower is better)** *(OP-RBF not computed)*\n\n||HS|OP|Martin|SOT|GOT|SGOT|\n|-|-|-|-|-|-|-|\n|Linear| 3.29 | 3.92 | 5.3 | 4.49 | 2.66 | **1.34** |\n|RBF| 3.74 | NA | 4.02 | 3.28 | 2.48 | **1.48**  |\n|Deep| 3.33 | 4.14 | 5.06 | 3.84 | 2.94 | **1.71**|\n\nRelative ranking of all metrics remains stable across all estimation methods. These results show that SGOT is a robust and well-behaved metric for comparing operators, regardless of the estimation method. Detailed results are provided in the paper's appendices G.3-4 and in the next paragraph: *5. Detailed Experimental Results*. \n\n**Sensitivity results:** SGOT’s performance varies smoothly with respect to the trade-off parameter $\\eta$, and a simple $\\eta$-heuristic based on the Nyquist frequency achieves performance close to the optimum. Combined with SGOT’s low computational cost, this smooth behavior and heuristic enable efficient hyperparameter tuning via fast grid-search strategies."}}, "id": "hYHNsA7Gcr", "forum": "B02EqvyiF3", "replyto": "B02EqvyiF3", "signatures": ["ICLR.cc/2026/Conference/Submission16991/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16991/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16991/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763658661331, "cdate": 1763658661331, "tmdate": 1763658661331, "mdate": 1763658661331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of quantifying and comparing the geometry of dynamical systems from trajectory data, a central challenge in machine learning for dynamical systems. The authors build on the Koopman and transfer operator framework, which provides a linear representation of nonlinear dynamics via spectral decomposition.\nThey propose a new operator-based metric that represents each system as a joint distribution over operator eigenvalues and spectral projectors, and defines distances between systems using optimal transport theory. The resulting metric is invariant to the sampling frequency of trajectories, computationally efficient, and theoretically supported by finite-sample convergence guarantees. Furthermore, it allows the computation of Fréchet means, enabling smooth interpolation between dynamical systems.\nComprehensive experiments on both synthetic and real-world datasets demonstrate that the proposed method consistently outperforms standard operator-based distances in machine learning tasks such as dimensionality reduction and classification, while also yielding meaningful interpolations between dynamical systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper tackles a fundamental and timely problem in machine learning for dynamical systems — defining a theoretically sound, interpretable, and computationally tractable metric between data-driven operator representations of nonlinear and stochastic dynamics. The proposed Spectral-Grassmann Optimal Transport (SGOT) framework elegantly combines spectral theory, Grassmannian geometry, and optimal transport, yielding a true metric that is invariant to sampling frequency and robust to operator estimation errors. The method is mathematically principled, supported by finite-sample convergence guarantees, and remains computationally efficient, overcoming the typical trade-off between theoretical rigor and practicality. Extensive experiments demonstrate that SGOT outperforms existing operator-based similarities in both unsupervised and supervised learning tasks, and its ability to compute Fréchet means enables meaningful interpolation between dynamical systems — a capability with broad implications for model comparison, system identification, and generative modeling of dynamics. Overall, the paper makes a significant and original contribution to bridging operator-theoretic dynamical systems and modern machine learning."}, "weaknesses": {"value": "While the proposed SGOT framework is theoretically elegant and empirically strong, the paper could be further strengthened by a clearer characterization of its practical limits. In particular, it remains unclear how strongly nonlinear systems the approach can accurately handle, and how robust the method is under varying levels of stochastic noise in trajectory data. Although the finite-sample convergence guarantees are valuable, the mathematical conditions quantifying robustness to nonlinearity and noise are not explicitly derived. Providing such analyses — for example, bounds on operator estimation errors or perturbation stability with respect to noise amplitude — would help clarify the method’s applicability range and further enhance its theoretical completeness."}, "questions": {"value": "1.\tTo what extent do the theoretical properties of the Koopman operator, such as boundedness or continuity, play a critical role in the proposed SGOT framework?\n2.\tRegarding the domain and codomain of the Koopman operator, what kind of function spaces are suitable for ensuring the validity of the spectral–Grassmann representation? For example, does the analysis require specific regularity, integrability, or compactness assumptions on observables?\n3.\tCan the proposed approach be extended to highly complex dynamical systems, such as stochastic nonlinear partial differential equations (SPDEs), where both randomness and infinite-dimensional state spaces come into play? If so, what are the main theoretical or computational challenges expected in such settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6vBt8H9MLP", "forum": "B02EqvyiF3", "replyto": "B02EqvyiF3", "signatures": ["ICLR.cc/2026/Conference/Submission16991/Reviewer_vMWN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16991/Reviewer_vMWN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16991/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761198276454, "cdate": 1761198276454, "tmdate": 1762927004427, "mdate": 1762927004427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Spectral-Grassmann Optimal Transport (SGOT), a metric that represents each linear operator by its eigenvalue subspace atoms and compares operators by a Wasserstein distance. The authors show how to compute this metric via kernel representations, provide statistical guarantees for finite-sample estimation, and propose a parametric formulation to compute barycenters in practice. Empirical results on synthetic systems and fluid flow data illustrate that SGOT responds to changes in frequency, decay and subspace structure compared with the baselines, better performances in ML tasks, and can produce visually meaningful interpolated modes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper proposes a coherent, high-level framework that combines spectral information (eigenvalues) with subspace geometry (Grassmann) under an optimal-transport view, which is an original and conceptually clean way to compare linear dynamical operators.\nMethodologically, the authors introduce a concrete, computable metric (SGOT), give a parametric barycenter formulation and an optimization scheme that bridges the abstract definition and practical computation.\nExperiments demonstrate the metric’s sensitivity to controlled changes, its usefulness for ML tasks (classification/embedding), and the interpolation behavior on physical flow data."}, "weaknesses": {"value": "The paper’s choice of distances is only one possible design: Eqs. (4)  and (6) are reasonable, but the authors do not justify them or compare to clear alternatives. The empirical claims may need clear explanations. Finally, there are some poor presentation issues. Please see the questions below in detail."}, "questions": {"value": "1. I agree that summing an eigenvalue distance and a subspace distance in Eq. (4) is reasonable, but it’s just one possible choice. For example, distances based on Koopman trace/determinant kernels (Fujii et al., 2017) could also be defined. Please explain why you chose the current form and mention other viable alternatives.\n\n2. Similarly, the second term in Eq. (6) is only one concrete realization of a subspace distance. Eq. (6) evaluates subspace differences as a quadratic form with kernel matrices and effectively uses a trace kernel-like representation. Why did you select this particular form? Please discuss alternatives (e.g. principal angles) and comment on related prior work (e.g. Kawahara et al., 2016 [a]), which is not cited but is relevant to distances in Koopman spectral decomposition.\n\n3. The results in Fig. 1 can be interpreted, but the current explanation lacks enough information for a reader to judge whether SGOT is truly better. In particular, please justify the claim that “grows linearly with the shifts almost everywhere” is a desirable property and explain why this behavior indicates superiority.\n\n4. Figure 5 may visualize the intermediate modes computed by SGOT, but a barycenter does not necessarily correspond to a physically realizable intermediate system. To make Fig. 5 more convincing, please evaluate the barycenter against concrete metrics that relate to physical realism. For example, mode frequencies, decay rates, and reconstruction/forecast RMSE.\n\n5. The experiments report that Koopman operators are estimated with a linear kernel (including Appendix H). Please state why you chose a linear kernel (interpretability, computational reasons, or data suitability) and discuss the relationship with non-linear kernels such as RBF.\n\nMinor points\n6. From Section 2 onward you use \\cite where \\citep would be appropriate.\n\n7. Line 308 contains two periods in a row.\n\n8. Figure 2 appears after Fig. 5 and a label seems to be “ilbert”."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pCDeXbmGw8", "forum": "B02EqvyiF3", "replyto": "B02EqvyiF3", "signatures": ["ICLR.cc/2026/Conference/Submission16991/Reviewer_WDpQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16991/Reviewer_WDpQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16991/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811787472, "cdate": 1761811787472, "tmdate": 1762927003241, "mdate": 1762927003241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel metric, named the Spectral-Grassmann Optimal Transport (SGOT) metric, for comparing dynamical systems represented by Koopman or transfer operators. The core idea is to represent each dynamical system as a probability distribution over its joint spectral data, specifically its eigenvalues and corresponding spectral projectors (viewed as points on a Grassmann manifold). The distance between two systems is then defined as the Wasserstein distance between these two distributions. The ground metric for the optimal transport problem is a weighted combination of the distance between eigenvalues and a Grassmannian metric between the projector subspaces. The authors provide theoretical guarantees for the metric, including finite-sample convergence rates for its estimation. They also propose an algorithm to compute the Fréchet mean (barycenter) of a set of dynamical systems under this metric, enabling interpolation. The method's effectiveness is demonstrated through experiments on simulated and real-world datasets, where it is shown to outperform other operator-based metrics in tasks like dimensionality reduction and classification, and provides more meaningful interpolations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  **Principled Metric Definition:** The SGOT metric is well-founded in theory, combining optimal transport with the geometry of Grassmann manifolds. It offers a holistic comparison of operators by considering both their spectral values (eigenvalues) and their geometric structure (eigenspaces).\n2.  **Theoretical Guarantees:** The paper provides finite-sample convergence guarantees (Theorem 2), which is a significant theoretical result that adds rigor to the proposed data-driven metric.\n3.  **Key Invariances:** The metric is designed to be invariant to the sampling frequency of trajectories and permutations of the spectral decomposition, which are desirable properties for a robust similarity measure.\n4.  **Enables Geometric Operations:** The framework naturally allows for the computation of barycenters, providing a principled way to average and interpolate between dynamical systems. The experimental results show this leads to more meaningful interpolations than simpler methods."}, "weaknesses": {"value": "1.  **Strong and Potentially Impractical Assumptions:** The requirement of a \"Common functional space\" (A3) is a major limitation. It is not clear how one would verify this assumption in practice or how to choose a suitable RKHS when comparing a diverse set of dynamical systems. The paper does not address the sensitivity of the method to violations of this assumption.\n2.  **Limited Generality of Guarantees:** The statistical guarantees are tied to a specific operator estimation method (RRR) and kernel type. It is unclear if these guarantees would extend to other popular and powerful estimation methods, such as those based on neural networks.\n3.  **Scalability Concerns:** The metric computation involves calculating a cost matrix and solving an OT problem. While the paper claims it is computationally efficient for small ranks (`r`), the complexity `O(n^2 * r^2)` can be prohibitive for high-resolution data (large `n`) or when a large number of modes are needed to accurately represent the system (large `r`). The barycenter computation adds another layer of iterative optimization.\n4.  **Limited Experimental Scope for Barycenters:** The interpolation experiments are primarily demonstrated on simple 1D linear systems. The single fluid dynamics example is more compelling, but a more extensive evaluation on a wider range of complex, nonlinear systems is needed to fully validate the claimed superiority of SGOT for interpolation and averaging tasks."}, "questions": {"value": "1.  How can a practitioner verify or enforce the \"Common functional space\" assumption (A3) when given a collection of time-series datasets from potentially very different underlying systems? What are the consequences for the metric if this assumption is violated (i.e., the relevant eigenspaces do not lie in the chosen RKHS)?\n2.  Your statistical guarantees are derived for the RRR estimator. Could you comment on the challenges of extending these guarantees to Koopman operator estimators based on deep neural networks, which are widely used for complex systems? Does the metric `ds` remain well-behaved if the estimated operators `T_k` come from different model classes?\n3.  Regarding scalability: What is the practical limit on the number of samples (`n`) and the rank (`r`) for which the SGOT metric and its barycenter can be computed in a reasonable amount of time? How does this compare to the scale of problems typically found in fields like fluid dynamics or climate science?\n4.  In Figure 1, the SGOT metric shows a desirable linear-like response. However, this is dependent on the hyperparameter `η`. The paper mentions a sensitivity analysis in the appendix but could you elaborate on how `η` should be chosen in practice? Does it require extensive cross-validation, and does the optimal `η` vary significantly across different tasks and datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l5Ni3W1Pft", "forum": "B02EqvyiF3", "replyto": "B02EqvyiF3", "signatures": ["ICLR.cc/2026/Conference/Submission16991/Reviewer_Tstr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16991/Reviewer_Tstr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16991/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919881835, "cdate": 1761919881835, "tmdate": 1762927002309, "mdate": 1762927002309, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}