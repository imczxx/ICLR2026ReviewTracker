{"id": "Y4YtKEJheR", "number": 17054, "cdate": 1758271654861, "mdate": 1759897201671, "content": {"title": "CCPO: Execution Consistent Preference Optimization through Computational Pacts", "abstract": "Execution-based verification has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to its computational soundness guarantees and dependency-aware filtering. Previous works involving preference optimization often include reward models that utilize Bradley-Terry assumptions, which fail to capture the logical dependencies and execution consistency requirements essential for scientific and computational reasoning tasks. In this paper, we introduce a novel method for generating computationally sound solutions accompanied with corresponding dependency graphs for execution-consistent preference optimization. Our approach begins with the construction of a high-quality scientific reasoning dataset by incorporating UltraFeedback prompts, base model generations, computational verification, and execution consistency results. Next, we construct dependency graphs by extracting reasoning step expressions, the computational prerequisites needed for the expressions, and the derivability relationships of the expressions from the previously collected dataset. Based on this extracted information, we generate corresponding execution consistency scores to accurately capture the mathematical verification process. Appending the generated execution consistency scores to each reasoning step results in data consisting of paired filtered reasoning steps and their corresponding execution consistency scores. Training Llama-3-8B and DeepSeekMath-7B with this corpus achieves substantial improvements across scientific reasoning domains: +17.0\\% on MATH, +15.1\\% on GSM8K, while extending our Scientific Feasibility Control framework to achieve 50.1\\% accuracy on PhyX multimodal physics reasoning—outperforming DeepSeek-R1 (49.8\\%) and OpenAI o3-mini (48.2\\%)—with 91.7\\% scientific validity coverage at $\\alpha = 0.10$ confidence level and 73\\% reduction in scientific law violations across architectures, leading to the creation of the CCPO family of models.", "tldr": "", "keywords": ["mathematical reasoning", "preference optimization", "large language model", "RLHF"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1f8bb929c7a56b8b16377a6ca32ca0280fb9a08a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces CCPO (Execution-Consistent Preference Optimization through Computational Pacts), a framework that aims to align large language models’ reasoning with computational correctness rather than subjective human preference."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Addresses a relevant problem: current preference optimization methods ignore logical or computational consistency."}, "weaknesses": {"value": "*(Updated and expanded based on the author rebuttal.)*\n\n> 1.  **Severe Reproducibility Concerns & Internally Inconsistent Results:**  The paper suffers from profound reproducibility issues that invalidate its claims.\n    * **(a) Internally Contradictory Results:** The paper's own reported numbers are contradictory, making evaluation impossible. **In Table 2, `Llama3-8B-base` is reported with a GSM8K score of 54.8. However, in Table 4, `Llama3-8B-Base` (presumably the same model) is reported with a score of 80.1.** This is a massive, unexplained discrepancy that undermines all reported gains and suggests a complete lack of rigorous evaluation.\n    * **(b) Inconsistent Baselines:** The baseline numbers used in the paper are questionable. For example, `Llama3-8B-instruct` is reported in Table 3 with a GSM8K score of 76.6, which is dramatically lower than the 84.5 reported in the official Llama 3 technical report. This suggests the paper's reported gains (e.g., +9.2%) are heavily inflated by comparing against a flawed or under-tuned baseline.\n    * **(c) Critical Missing Details:** The paper omits all critical implementation details. The appendix (e.g., Appendix I) contains only standard boilerplate (e.g., \"AST Parsing,\" `batch_size=128`, `lr=5e-5`) while completely failing to describe the core novel components, such as the algorithm for **\"dependency-graph extraction\"** or the **\"filtering thresholds.\"** The claim that this appendix provides \"comprehensive\" details is demonstrably false.\n    * **(d) No Code Provided:** Neither code nor verification scripts were provided. A promise to release code \"upon acceptance\" is not a substitute for providing artifacts for review, especially when results are this inconsistent and poorly documented.\n\n> 2.  **Lack of Credible and Transparent Baselines:** The paper's evaluation against competing methods is wholly insufficient.\n    * **(a) Poor Organization & Missing Comparisons:** The paper fails to provide direct, \"apple-to-apple\" comparisons against DPO and IPO in its main tables. Key results are hidden in the appendix (e.g., Figure 3), which itself is incomplete—it shows DPO/IPO results only for DeepSeekMath but *not* for the Llama models. This non-standard organization severely hinders proper review.\n    * **(b) Missing Modern Baselines:** The evaluation completely omits comparisons against numerous modern, relevant preference optimization methods (e.g., **CPO, KTO, ORPO, R-DPO, SimPO**), making it impossible to assess the actual advance over the current state-of-the-art.\n\n> 3.  **Weak Theoretical Rigor:** The paper's central theoretical claim of a \"conformal guarantee\" is practically meaningless. It relies on an assumption of \"deterministic execution,\" which the authors state is enforced via a \"fixed random seed.\" This is not a statistical guarantee for a *stochastic* process (i.e., LLM decoding with sampling/non-zero temperature); it is merely a statement of *reproducibility* for a single, fixed decoding path. It does not provide any guarantee over the distribution of possible outputs.\n\n> 4.  **No Ablation or Isolation Study:** There is no evidence showing which part of CCPO (dependency graph extraction, execution filtering, or conformal calibration) drives the reported gains. This is a critical omission for a paper introducing a multi-component framework."}, "questions": {"value": "Refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sbj2tLlCho", "forum": "Y4YtKEJheR", "replyto": "Y4YtKEJheR", "signatures": ["ICLR.cc/2026/Conference/Submission17054/Reviewer_3Zzd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17054/Reviewer_3Zzd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761692148199, "cdate": 1761692148199, "tmdate": 1762997550094, "mdate": 1762997550094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method for generating computationally sound solutions accompanied with corresponding dependency graphs for execution-consistent preference optimization. The paper conducts experiments on several mathematical reasoning benchmarks to evaluate the method."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The extensive similarities in core ideas and presentation to the prior work \"Conformal Language Model Reasoning with Coherent Factuality\" (ICLR 2025) undermine the meaningful assessment of this paper's unique strengths or originality."}, "weaknesses": {"value": "This paper fundamentally replicates the key idea introduced in the paper \"Conformal Language Model Reasoning with Coherent Factuality, ICLR 2025”. The similarities extend beyond the conceptual core to the very structure and phrasing of the argument, despite the use of different surface-level concepts. However, the authors also fail to cite the original paper."}, "questions": {"value": "see the weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}, "details_of_ethics_concerns": {"value": "The submitted paper is very similar with the ICLR 2025 paper \"Conformal Language Model Reasoning with Coherent Factuality,\" \nThe similarities extend beyond the conceptual core to the very structure and phrasing of the argument, despite the use of different surface-level concepts. And the authors also fail to cite the original paper.\n\nI will not list every example in detail but will provide a few instances, such as:\n(1) Definition 1 (Computational Reasoning Step) is similar to Definition 1 (Claim) in the ICLR 2025 paper, and the following uses similar terms like \"decomposes\" vs. \"splitting.\" \\\n(2) Definition 2 (Scientific Validity Base) vs. Definition 2 (Ground truth) in the ICLR 2025 paper, and it also follows a similar Remark 1. \\\n(3) The section \"Background: Execution-based verification guarantees\" vs. \"Background: Conformal prediction guarantees for LM generations\" in the ICLR 2025 paper. \\\n(4) Similar Definition 3 \"Definition 3 (Computationally Consistent Reasoning)\" vs. \"Definition 3 (Coherent factuality),\" and also Remark 2 vs. Remark 2 in the ICLR 2025 paper. \\\n(5) The section \"4 A PROTOCOL FOR EXECUTION-CONSISTENT PREFERENCE\" vs. \"4 A Protocol for Coherent Factuality\" in the ICLR 2025 paper, with even the same algorithm \"Algorithm 1 CCPO Subgraph Generator\" vs. \"Algorithm 1: Subgraph Generator.\""}}, "id": "8XfrlmLKNd", "forum": "Y4YtKEJheR", "replyto": "Y4YtKEJheR", "signatures": ["ICLR.cc/2026/Conference/Submission17054/Reviewer_F1Li"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17054/Reviewer_F1Li"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813443827, "cdate": 1761813443827, "tmdate": 1763011733872, "mdate": 1763011733872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Code Consistency Preference Optimization (CCPO), a preference-training framework for mathematical/scientific reasoning that enforces execution consistency at the level of individual reasoning steps. CCPO constructs dependency graphs over extracted steps, verifies steps via code execution, and filters outputs using conformal prediction to guarantee calibrated coverage. The method uses multiplicative-weights self-play with graph-aware scoring, and integrates execution verification during training rather than only at inference. On MATH, GSM8K, and PhyX, the authors report gains (e.g., +17.0% MATH, +15.1% GSM8K; 50.1% PhyX with 91.7% validity coverage) for Llama‑3‑8B and DeepSeekMath‑7B variants."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper has a clear formal goal and calibration guarantee. The authors define execution-consistent preference and provide a conformal‑prediction guarantee that the filtered output is computationally sound with probability ≥ 1 − \\alpha. This offers a principled control knob absent from prior PO works. \n\n- Algorithm 1 builds induced subgraphs by thresholding node scores and removing nodes with missing prerequisites, aligning filtering with derivational structure. Definition 4  formalizes an execution consistency score over induced subgraphs, connecting scores to which steps survive (p. 7).\n\n- Empirical gains show consistency across tasks. Results report +17.0% (MATH) and +15.1% (GSM8K) along with 91.7% validity coverage and a 73% reduction in scientific‑law violations. Progressive learning table shows monotonic improvements over iterations.\n\n- The paper has a technical breadth cross math, physics, formal, and coding."}, "weaknesses": {"value": "- Some mathematical specification lacks some clarity or consistency. Approximate dependency graphs are invoked in Theorem 1’s upper bound and in App. F, but their construction/quality metrics and impact on guarantees are only sketched without a concrete end‑to‑end bound on task‑level error. \n  \n- The role and calibration of \\beta in dependency‑aware scoring (eq. (4)) are not fully motivated; the text says \\beta is calibrated via conformal prediction but does not show how this interacts with coverage guarantees.\n\n- Execution‑consistency score r() depends on induced subgraph selection. Aadmissible UT sets and their completeness are not rigorously characterized. \n\n-  Results emphasize within‑model gains and a few external models on PhyX, but do not include strong PO baselines augmented with step‑wise execution filters (e.g., DPO+exec or SPPO+exec) under identical compute and prompts.\n\n- The claim of “superior performance without external supervision” is strong, yet CCPO still relies on verified oracles and dependency construction; comparisons against alternative self‑supervised filtering schemes are limited.\n\n- MiniF2F/HumanEval summaries are brief; it’s unclear whether improvements persist under stricter decoding/time budgets and verifier ablations.\n\n- No statistical testing (e.g., CIs) is reported for key benchmarks; effect sizes might overlap with variance. **No direct evidence found in the manuscript."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "JoYQz2Jg9O", "forum": "Y4YtKEJheR", "replyto": "Y4YtKEJheR", "signatures": ["ICLR.cc/2026/Conference/Submission17054/Reviewer_WXnV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17054/Reviewer_WXnV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861125934, "cdate": 1761861125934, "tmdate": 1762927066229, "mdate": 1762927066229, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Code Consistency Preference Optimization (CCPO), a novel framework for improving mathematical reasoning in large language models through execution-based verification and dependency-aware preference optimization. The key innovation is formulating preference learning as a game-theoretic optimization problem while incorporating computational verification constraints through dependency graph construction and conformal prediction guarantees. The authors train Llama-3-8B and DeepSeekMath-7B models, achieving substantial improvements on mathematical reasoning benchmarks: +17.0% on MATH, +15.1% on GSM8K, and 50.1% on PhyX physics reasoning. The method constructs dependency graphs by extracting reasoning steps, identifying computational prerequisites, and generating execution consistency scores, then filters reasoning steps based on these scores to maintain both logical coherence and computational soundness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel Problem Formulation**: Combining execution verification with preference optimization through dependency graphs is creative and well-motivated for mathematical reasoning.\n\n2. **Strong Empirical Results**: Consistent improvements across diverse benchmarks (MATH, GSM8K, OCW, PhyX) and multiple base models demonstrate practical effectiveness.\n\n3. **Theoretical Framework**: Applying conformal prediction to provide coverage guarantees for reasoning step filtering is innovative.\n\n4. **Comprehensive Evaluation**: The paper includes extensive ablations, error analysis, and comparisons with relevant baselines."}, "weaknesses": {"value": "Complexity: The method is theoretically and computationally intensive. Real-time execution and graph construction may limit scalability in resource-constrained settings."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SX0dZHktLQ", "forum": "Y4YtKEJheR", "replyto": "Y4YtKEJheR", "signatures": ["ICLR.cc/2026/Conference/Submission17054/Reviewer_qEyt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17054/Reviewer_qEyt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884039742, "cdate": 1761884039742, "tmdate": 1762927065799, "mdate": 1762927065799, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Hi, everyone\n\nThe AC disagrees with Reviewer 3Zzd’s comments that, while the code submission may be potentially beneficial for reviewers’ assessment, **the code submission is NOT mandatory during the review process** to prevent potential misuse. Reviewers should not lower their scores simply because the authors did not provide code.\n\nHowever, the authors are suggested to address the other concerns raised by the reviewers, such as the comparison issues raised by Reviewer 3Zzd, and Reviewer F1Li’s concerns regarding similarities with the ICLR 2025 paper."}}, "id": "WKqHLpRqEE", "forum": "Y4YtKEJheR", "replyto": "Y4YtKEJheR", "signatures": ["ICLR.cc/2026/Conference/Submission17054/Area_Chair_CnG3"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17054/Area_Chair_CnG3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17054/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763018731652, "cdate": 1763018731652, "tmdate": 1763019181276, "mdate": 1763019181276, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}