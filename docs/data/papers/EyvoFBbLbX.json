{"id": "EyvoFBbLbX", "number": 16630, "cdate": 1758266964251, "mdate": 1759897228610, "content": {"title": "Towards Anomaly Detection on Text-Attributed Graphs", "abstract": "Graph anomaly detection (GAD), which aims to identify abnormal nodes that differ from the majority in graphs, has attracted considerable research attention. In real-world GAD scenarios, such as reviews in e-commerce platforms, the original features in graphs are raw text. Existing methods only treat these texts with a simple context embedding, without a comprehensive understanding of semantic information. In this work, we propose TAGAD, a novel Text-Attributed Graph Anomaly Detection framework that jointly trains the context feature and the semantic feature of texts with graph structure to detect the anomaly nodes. TAGAD consists of a global GAD module and a local GAD module, respectively for detecting global anomaly nodes and local anomaly nodes. In the global GAD module, we employ a contrastive learning strategy to jointly train the graph-text model and an autoencoder to compute the global anomaly scores. In the local GAD module, an ego graph and a text graph are constructed for each node. Then, we devise two different methods to compute local anomaly scores based on the difference between the two subgraphs, respectively for the zero-shot settings and the few-shot settings. Extensive experiments demonstrate the effectiveness of our model under both zero-shot and few-shot settings on text-attributed GAD scenarios. Codes are available at https://anonymous.4open.science/r/TAGAD-1223.", "tldr": "The first anomaly detection framework towards Text-Attributed Graph.", "keywords": ["Text attributed graph", "graph anomaly detection", "low-resource learning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ae644cc823ccb2aabfd7436e801ee8656a6048f3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies the problem of text-attributed graph anomaly detection and proposes a framework termed TAGAD. The proposed method consists of two modules, i.e., the global and local GAD module, which utilizes contrastive learning and graph similarity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The studied problem is practical and interesting.\n\n2. The proposed method is straightforward and easy to follow.\n\n3. The code is released, enhancing the reproducibility."}, "weaknesses": {"value": "1. The paper is not well structured. A specific subsection on current works on TAGs should be added to the related work.\n\n2. More datasets should be employed for comparison.\n\n3. In the few-shot setting, how many labeled nodes are used?\n\n4. When using contrastive learning for alignment, the GNN generates aggregated representations while Bert outputs the individual representations. More analysis should be provided on the rationality of this alignment.\n\n5. For Eq.9, \\lambda is used to combine the local and global scores. How to determine its optimal value in practice.  \n\n6. Why can GNN not use the embeddings generated by LM?"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CXP0fUBYcw", "forum": "EyvoFBbLbX", "replyto": "EyvoFBbLbX", "signatures": ["ICLR.cc/2026/Conference/Submission16630/Reviewer_UYkH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16630/Reviewer_UYkH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761292944172, "cdate": 1761292944172, "tmdate": 1762926696947, "mdate": 1762926696947, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of anomaly detection on text-attributed graphs (TAGs), where nodes contain rich textual information (e.g., e-commerce reviews). The authors propose TAGAD, a unified framework that jointly learns context (BOW), semantic (LM), and graph (GNN) node features, and comprises: (1) a global module using contrastive alignment between GNN and LM embeddings with a graph autoencoder for global anomaly scoring; and (2) a local module that detects local anomalies by comparing a node's ego-graph against a \"text graph\" based on semantic similarity, including a mechanism for amplifying local deviations under few-shot settings. Experimental results on both synthetic and real datasets (Cora, Arxiv, Pubmed, Yelp) show TAGAD outperforms a wide array of unsupervised and supervised GAD baselines in zero-shot and few-shot scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly motivates the need to combine both shallow context (BOW) and deep semantic (LM) information with graph structure for anomaly detection in text-rich graphs, an area where prior TAG methods for classification are not directly applicable.\n\n2. TAGAD presents a well-integrated architecture: Figure 1 effectively illustrates the interplay of the global (contrastive and autoencoder-based) and local (ego vs. semantic-text graph comparison) components, making the system modular and interpretable.\n\n3.The theoretical analysis in Appendix B is welcome, offering formal support for the intuition that ego/text graph mismatches (structural and feature-wise) are indicative of anomalies; the proof of Theorem 1 is concise and relevant.\n\n4.Figure 4 provides an accessible case-study, clarifying the tangible differences detected by the global and local modules on actual data.\nThe code release and detailed description of datasets and synthetic anomaly injection (Appendix C) enhance reproducibility."}, "weaknesses": {"value": "1. The experimental results in Table 1 and Table 2 omit these strong GAD competitors, which is a limitation for assessing the empirical significance of TAGAD. These papers propose alternative mechanisms for anomaly scoring in attributed graphs, which could provide a much tougher baseline and, if inferior, would further bolster TAGAD's contribution.\n\n2. While the paper asserts (Contribution 1) that it is \"the first attempt\" at anomaly detection on text-attributed graphs, there is substantive overlap between the core ideas here (e.g., deep feature/graph integration, autoencoding, alignment losses) and established body of literature, particularly multi-view, one-class, and representation learning-based anomaly detection on attributed graphs. The paper's true contribution is closer to a specific and well-engineered unification of these ideas for TAGs, rather than a first-of-its-kind conceptual leap.\n\n3. In Section 4.1.2, the temperature parameter $\\tau$ in the contrastive loss ($e^\\tau$) is never justified or explored; it would benefit from a more detailed sensitivity analysis or ablation, as this parameter can strongly affect contrastive alignment.\nThe sampling strategy and thresholding used in the construction of the text graph (Eq. for $A_T^u(i,j)$ in Section 4.2.1) are only partially specified; the impact of the threshold $\\epsilon$ is explored in a later figure but the choice of similarity metric (cosine? dot-product?) should be reiterated for clarity. Additionally, the use of Gumbel-softmax for few-shot settings is presented as a drop-in solution without much discussion of its stability or potential bias.\n\n4. The joint loss in Eq. for $L^G$ (global stage) mixes two loss types via $\\alpha$, but the annealing or scheduling between alignment-only and full loss across epochs is only vaguely described (“alignment for some epochs... then reconstruction”), and the pseudocode in Appendix A is terse. Detailed algorithmic schedules would be beneficial for reproducibility.\n\n5. The experimental section relies heavily on synthetic anomalies for Cora, Arxiv, Pubmed, while only Yelp provides a real-world use case. The injected anomalies (Appendix C.1) may not match real anomaly distributions, potentially inflating effectiveness on benchmarked scenarios. The inclusion of more real-world datasets or demonstration on naturally-occurring anomalies would strengthen the empirical case.\n\n6. The ablation results in Table 1 are informative, but do not report on possible failure modes (e.g., when TAGAD(L) may perform better than the full model, or under which anomaly types the model struggles). Analysis of negative cases, or more granular breakdowns (e.g., per anomaly type) would further strengthen the work."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YTUyflzoOO", "forum": "EyvoFBbLbX", "replyto": "EyvoFBbLbX", "signatures": ["ICLR.cc/2026/Conference/Submission16630/Reviewer_paPh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16630/Reviewer_paPh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761387844901, "cdate": 1761387844901, "tmdate": 1762926696533, "mdate": 1762926696533, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a novel problem setting: text-attributed graph anomaly detection. The authors propose a framework consisting of global and local anomaly detection modules and employ a reconstruction-based loss to derive anomaly scores. Experimental results demonstrate consistent performance improvements across all experiment settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Text-attributed graph anomaly detection is a valuable and timely research direction. This paper is one of the earliest attempts in this area, alongside [1, 2].\n\n2. Basically, the paper has a clear organization.\n\n[1] Xu, Y., Hua, X., Peng, Z., Shi, B., Chen, J., Fu, X., ... & Dong, B. (2025). Text-Attributed Graph Anomaly Detection via Multi-Scale Cross-and Uni-Modal Contrastive Learning. arXiv preprint arXiv:2508.00513.\n\n[2] Xu, Y., Chen, J., Peng, Z., Chen, Z., Lin, Q., Ma, L., ... & Dong, B. (2025). Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection. In Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)."}, "weaknesses": {"value": "1. Lack of grounded motivation\nThe motivation of this work is not sufficiently substantiated. In the introduction, the authors claim the existence of a specific type of anomaly, global anomaly nodes, whose features deviate from those of the majority of nodes. However, despite the extensive study of datasets such as Cora, Pubmed, Arxiv, and Yelp, no prior work has reported such anomalies. The authors also fail to provide references, empirical analyses, or motivation experiments to justify the existence of global anomalies in these datasets.\n\nFurthermore, authors state that they follow the widely accepted anomaly injection procedures for Cora, Arxiv, and Pubmed. Yet, as described in Appendix C.1, these procedures only inject feature and structural anomalies, which do not support the existence of global anomalies.\n\nNotably, [1] also introduces the concept of global anomalies, referring to cases such as cheaters hiding within large underground communities. However, this definition aligns more closely with structural anomalies, where anomalous nodes form dense cliques, rather than with the definition used in this paper.\n\n\n2. Limited novelty\nThe methodological novelty of this work appears limited. The proposed approach essentially extends the conventional reconstruction-based paradigm with additional modules to handle text-attributed graphs, including a feature alignment module and text-attributed based reconstruction in the local anomaly detection module. \n\n3. Inadequate experimental validation\nThe experimental setup is insufficient to substantiate the claimed performance advantages. Several recent and relevant baselines—such as PREM [4], TAM [5], and ADA-GAD [6]—are missing. Moreover, in Table [1], the baseline performances are considerably lower than those reported in their original papers. TThe author mentioned they utilize BOW features for this experiment. However, the original Cora dataset already employs BoW attributes [7], and prior works have achieved significantly better performance with them. It is unclear why the authors constructed a different BoW representation rather than using the standard, commonly accepted implementation. \n\n4. Presentation issues\nThe paper contains several presentation and writing issues. For example, line 053 includes the phrase “it is meaningless to compute...,” which does not reflect appropriate academic tone.\n\n[1] Xu, Y., Hua, X., Peng, Z., Shi, B., Chen, J., Fu, X., ... & Dong, B. (2025). Text-Attributed Graph Anomaly Detection via Multi-Scale Cross-and Uni-Modal Contrastive Learning. arXiv preprint arXiv:2508.00513.\n\n[2] Xu, Y., Chen, J., Peng, Z., Chen, Z., Lin, Q., Ma, L., ... & Dong, B. (2025). Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection. In Proceedings of the 33rd ACM International Conference on Multimedia (MM '25). \n\n[3] Jin, M., Liu, Y., Zheng, Y., Chi, L., Li, Y. F., & Pan, S. (2021, October). Anemone: Graph anomaly detection with multi-scale contrastive learning. In Proceedings of the 30th ACM international conference on information & knowledge management (pp. 3122-3126).\n\n[4] Pan, J., Liu, Y., Zheng, Y., & Pan, S. (2023, December). Prem: A simple yet effective approach for node-level graph anomaly detection. In 2023 IEEE International Conference on Data Mining (ICDM) (pp. 1253-1258). IEEE.\n\n[5] Qiao, H., & Pang, G. (2023). Truncated affinity maximization: One-class homophily modeling for graph anomaly detection. Advances in Neural Information Processing Systems, 36, 49490-49512.\n\n[6] He, J., Xu, Q., Jiang, Y., Wang, Z., & Huang, Q. (2024, March). Ada-gad: Anomaly-denoised autoencoders for graph anomaly detection. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 38, No. 8, pp. 8481-8489).\n\n[7] https://www.geeksforgeeks.org/machine-learning/cora-dataset/"}, "questions": {"value": "Please refer to the issues discussed in the Cons section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9ByytiQyy9", "forum": "EyvoFBbLbX", "replyto": "EyvoFBbLbX", "signatures": ["ICLR.cc/2026/Conference/Submission16630/Reviewer_G6cd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16630/Reviewer_G6cd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954505033, "cdate": 1761954505033, "tmdate": 1762926696140, "mdate": 1762926696140, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses anomaly detection on text-attributed graphs (TAGs), where nodes contain textual information. Existing methods inadequately leverage semantic text features. The authors propose ​​TAGAD​​, a framework combining global and local modules. The global module uses a triple encoder (contextual, semantic, graph) with contrastive alignment between text and graph embeddings. The local module compares self-graphs and text-graphs for anomaly scoring. Experiments on synthetic  and real-world  datasets show TAGAD outperforms baselines by up to +44.6% AUC in low-resource settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.Local text-graph comparison enables zero/few-shot detection, critical for practical applications.\n\n2.Outperforms supervised methods  with minimal labels.\n\n3.There is relatively little work on anomaly detection in text attribute graphs, which is an interesting area to explore."}, "weaknesses": {"value": "1. The analysis of the problem is too superficial. While this paper points out that existing methods are not designed for text graphs, it doesn't delve into the unique challenges of anomaly detection in text graphs, lacking theoretical derivation or experimental verification, making the motivation unclear.\n\n2. The paper still uses BOW-based context encoding, but the dimensionality of BOW depends on the vocabulary, which may be limiting in large datasets. Furthermore, the shortcomings pointed out in the paper are not fundamentally addressed.\n\n3. BOW requires a predefined vocabulary, but the paper doesn't provide this information. Also, can BOW handle dynamic environments?"}, "questions": {"value": "Why not use LLM for text processing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "usyz5GQunv", "forum": "EyvoFBbLbX", "replyto": "EyvoFBbLbX", "signatures": ["ICLR.cc/2026/Conference/Submission16630/Reviewer_izLX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16630/Reviewer_izLX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971054566, "cdate": 1761971054566, "tmdate": 1762926695513, "mdate": 1762926695513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}