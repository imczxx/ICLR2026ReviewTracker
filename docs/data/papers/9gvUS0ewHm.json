{"id": "9gvUS0ewHm", "number": 3561, "cdate": 1757474890974, "mdate": 1759898081212, "content": {"title": "Fair Out-of-Distribution Detection", "abstract": "Out-of-Distribution (OOD) detection prevents models from misclassifying OOD data that fall outside the in-distribution (ID) classes as ID categories. However, existing OOD detection methods ignore a critical metric, i.e., fairness metric. This oversight could result in unreliable predictions due to sensitive attributes in the data. To fill this gap, we introduce a novel and challenging problem termed \\textit{Fair OOD Detection} in this paper, which simultaneously considers OOD detection and bias induced by Fairness Confusion (FC) caused by sensitive attributes and their induced Feature Shifts (FS). Furthermore, we propose a novel metric termed Fair-OOD to identify FC phenomena in OOD detection, and a theoretically guaranteed semi-supervised solution named Predictive Adaptive Calibration (PACT) to simultaneously enhance OOD detection capability, ensure fairness, and mitigate FC without requiring the label of sensitive attribute for OOD data. Extensive experiments demonstrate that: (a) Fair-OOD can identify FC issues in models that existing fairness metrics fail to detect; (b) PACT effectively improves OOD detection performance while eliminating both FC and unfairness issues.", "tldr": "This work first uncovers fairness confusion in out-of-distribution detection due to sensitive attributes, proposing a novel metric and solution, with extensive experiments validating their effectiveness.", "keywords": ["Out-of-distribution", "Trustworthy Machine Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/03ab52d0d54a95e881d8e151b813888edbd137b5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes predictive adaptive calibration, a method that combines feature distribution regularization and predictive distribution calibration to simultaneously improve OOD detection, mitigate \"fairness\" confusion caused by \"sensitive\" attribute."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed PACT framework includes both theoretical guarantees and practical algorithmic design (FDR + PDC), showing an attempt to bridge theory and implementation.\n- The idea of addressing spurious correlations or feature shifts in OOD detection could be valuable for improving generalization and reliability."}, "weaknesses": {"value": "- My major concern is that while the paper frames its problem as “Fair OOD Detection” and introduces sensitive attributes to define fairness confusion, the issue it addresses is fundamentally different from conventional fairness concerns (in the fairness literature, the fairness issue typically refers to concerns about minority groups defined by sensitive attributes such as gender, race, or age.). The so-called sensitive attributes, such as image background, are better understood as sources of spurious correlations that affect OOD generalization rather than attributes tied to social fairness (e.g., race or gender) and the proposed method (PACT) primarily mitigate the impact of these spurious correlations on OOD detection, improving model generalization across distribution shifts. Therefore, the work is more accurately interpreted as addressing OOD robustness under spurious correlations rather than true fairness.\n- The second point is the experimental setup does not align with established fairness research. The datasets used are not fairness-related, they do not involve socially sensitive or legally protected attributes such as race, gender, or age, which are typically central to fairness evaluation. Instead, the paper treats non-social attributes (e.g., image background) as “sensitive attributes,” which conceptually correspond more to spurious correlations or contextual biases rather than true fairness concerns. While the authors report results on fairness metrics like DP, EO, and EOD, applying these criteria in such settings may be misleading, as it conflates distributional robustness with social fairness."}, "questions": {"value": "- The main loss (Eq. 13) contains four terms. Why doesn’t the paper include any ablation studies to demonstrate the effectiveness of each term? (showing only the effects of tuning the parameters $\\alpha$ and $\\beta$ is not sufficient.)\n- Is fairness the right conceptual lens here, or would this be better framed as robustness to spurious correlations?\n- How does “background” qualify as a sensitive attribute under the fairness framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "na"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wgHjJzAxHR", "forum": "9gvUS0ewHm", "replyto": "9gvUS0ewHm", "signatures": ["ICLR.cc/2026/Conference/Submission3561/Reviewer_jx7G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3561/Reviewer_jx7G"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3561/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760950209946, "cdate": 1760950209946, "tmdate": 1762916824574, "mdate": 1762916824574, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper shows how to make OOD detection fair: it adds a new score and a training method so models catch unseen data without treating any group worse."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "pro:\nGood experiment;\n\nEnd-to-end design as a framework;\n\nDetails for replication;"}, "weaknesses": {"value": "con:\nFairness problems typically arise from biased outcomes or mislabeling, for example, women may be 50% of applicants but only 10% of hires, not because those cases are unseen. Framed this way, the paper reads more like a class-imbalance/selection-bias treatment than an OOD issue.\n\nThe core challenge is that problematic data are heterogeneous—you can’t tell them apart by just using part of the data. As a result, the paper leans on hand-tuned parameters (or hand-picked training sets) to label OOD vs. normal, which undermines the objectivity that fairness demands.\n\nIf we already know the sensitive feature, why not just ignore it when we compute OOD? Maybe unawareness fairness, proxy features? I think the paper needs to investigate more on the use case."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jqbS313KLe", "forum": "9gvUS0ewHm", "replyto": "9gvUS0ewHm", "signatures": ["ICLR.cc/2026/Conference/Submission3561/Reviewer_5acM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3561/Reviewer_5acM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3561/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400587365, "cdate": 1761400587365, "tmdate": 1762916824341, "mdate": 1762916824341, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the first study on constructing a fairness-aware OOD detection framework, which incorporates the consideration of the fairness metric into OOD detection. To address this challenge, the study introduces a novel metric, Fair-OOD, to identify the Fairness Confusion issue in OOD detection. Furthermore, it proposes a novel algorithm, the Predictive Adaptive Calibration, which is a theoretically guaranteed semi-supervised solution. Extensive experiments on real-world datasets demonstrate that PACT effectively improves OOD detection performance while simultaneously mitigating bias and resolving unfairness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "o\tThe Clear Definition of Fairness Confusion (FC) and the Approach to its Two Contributing Factors. The paper clearly defines Fairness Confusion (FC), which is the bias induced by sensitive attributes and their induced Feature Shifts (FS). The approach is strong as it introduces the challenging problem of Fair OOD Detection by simultaneously considering both the sensitive attributes and the Feature Shifts.\no\tThe Meaningful proposal of the Fair-OOD Metric. The proposed Fair-OOD metric is significant because it accounts for both sensitive attributes and Feature Shifts, explicitly addressing factors overlooked by conventional fairness metrics. Existing fairness metrics fail to reliably detect unfairness in OOD detection due to their inability to address FC induced by FS. Fair-OOD is proven effective as it can identify FC issues in models that existing fairness metrics fail to detect.\no\tThe Effective Solution through FDR and PDC terms. The paper proposes the Predictive Adaptive Calibration (PACT) algorithm. It utilizes two key components designed for specific roles: \n\tFeature Distribution Regularization (FDR): This term constrains the model to extract highly compact feature representations, encouraging it to focus exclusively on class-related features while disregarding sensitive attributes and their induced shifted features, thus demonstrating debiasing capability.\n\tPredictive Distribution Calibration (PDC): This term mitigates the FC issue by maximizing the divergence (discrepancy) between the prediction distributions of ID and OOD data. Theoretical guarantees confirm that optimizing PDC reduces the impact of FS on prediction distributions, mitigating induced FC.\no\tVerification of Superiority through Extensive Experimental Results. Extensive experiments on real-world datasets confirm the method's superiority. The results demonstrate that PACT effectively improves OOD detection performance while simultaneously eliminating both FC and unfairness issues. Furthermore, PACT not only mitigates bias and resolves FC but also achieves substantially closer ACC-U and ACC-B values across different sensitive attributes, indicating robust performance."}, "weaknesses": {"value": "o\tIt remains uncertain whether the method’s effectiveness will be robustly maintained in scenarios involving multi-categorical sensitive attributes, necessitating additional verification.\no\tIt can be questioned whether the threshold-based binary classification method used to determine Feature Shift is sufficient for capturing subtle variations in features.\no\tThe lack of a theoretical justification or empirical evidence for using fixed ID to OOD class split ratios across datasets, such as the 7:3 ratio applied to CIFAR-10-C and ImageNet-100-C, constitutes a weakness.\no\tThe practice of using the exact same set of classes for ID and OOD partitions across every experimental run seems less convincing.\no\tIt is less convincing to use a simple binary classification based merely on the presence or absence of corruption, especially since datasets like CIFAR-10-C are composed of diverse noise types (e.g., Gaussian noise, blurs). This simplification, while facilitating formal analysis, potentially masks critical differences in Fairness Confusion (FC) caused by specific corruption categories.\no\tThe proposed methodology is primarily geared toward fair OOD detection. It is questionable whether its effectiveness can be maintained and verified on existing, generalized OOD benchmarks that lack sensitive attribute definitions."}, "questions": {"value": "o\tWhy are the sensitive attribute and feature shift binary? In actual fairness research, sensitive attributes often have multiple properties. And also curious why feature shift was determined simply as binary. Is binary classification using a threshold actually more effective at representing feature change?\no\tIs there an ablation study that investigates the resulting performance changes when this ID:OOD class ratio is varied?\no\tWouldn't changing the specific classes designated as ID and OOD (e.g., using different class combinations for ID/OOD split) for each experiment lead to a more fair and generalizable result for the same dataset?\no\tGiven the authors' claim that the framework can be easily generalized to categorical sensitive attributes, and assuming the current binary setup was chosen for 'convenience in formal analysis,' what results would be expected, or obtained, if the experimental setup were complicated to evaluate performance across multi-categorical attributes defined by specific corruption types?\no\tGiven that the proposed PACT method is a semi-supervised solution, can it still be effectively applied to standard OOD datasets where the OOD samples do not have sensitive attribute labels?\no\tWhich dataset and setup were used for the ablation study conducted in Section 5.3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ojzGChEoS4", "forum": "9gvUS0ewHm", "replyto": "9gvUS0ewHm", "signatures": ["ICLR.cc/2026/Conference/Submission3561/Reviewer_RRg2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3561/Reviewer_RRg2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3561/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824332789, "cdate": 1761824332789, "tmdate": 1762916823981, "mdate": 1762916823981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Fair OOD Detection in this paper, which simultaneously considers OOD detection and bias induced by Fairness Confusion (FC) caused by sensitive attributes and their induced Feature Shifts (FS). Furthermore, they propose a metric termed\n Fair-OOD to identify FC phenomena in OOD detection, and a theoretically guaranteed semi-supervised solution named Predictive Adaptive Calibration (PACT) to simultaneously enhance OOD detection capability, ensure fairness, and mitigate FC without requiring the label of sensitive attribute for OOD data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- consider fairness and out-of-distribution simultaneously.\n- introduce two regularizers -- predictive distribution calibration and predictive distribution calibration."}, "weaknesses": {"value": "- This paper is a combination of fairness and out-of-distribution, which is through two regularizers. The novelty is low.\n- The introduction and definitions are 4+ pages. The method about this paper is about 1 page."}, "questions": {"value": "- The FDR term may not be appropriate. When $x^I_j\\in D^+$, it is acceptable; however, outside this domain, the term tends to $\\infty$. The minimization of the FDR term is for what? \n- In FDR term, all $x^I_j$ should compare with some $x^+$, not all?\n- In Definition 1, what about $S'_a,S'_{a'}$? Are there 4 possible choices in feature shift $S$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "naoaOxRLAb", "forum": "9gvUS0ewHm", "replyto": "9gvUS0ewHm", "signatures": ["ICLR.cc/2026/Conference/Submission3561/Reviewer_o9ip"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3561/Reviewer_o9ip"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3561/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988293199, "cdate": 1761988293199, "tmdate": 1762916823726, "mdate": 1762916823726, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}