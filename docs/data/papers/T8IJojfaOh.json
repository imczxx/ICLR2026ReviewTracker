{"id": "T8IJojfaOh", "number": 11498, "cdate": 1758200412741, "mdate": 1759897571694, "content": {"title": "Next-ToBE: Probabilistic Next Token-Bag Exploitation for Activating Anticipatory Capacity in LLMs", "abstract": "Auto-regressive large language models (LLMs) have achieved remarkable success recently. Though trained to predict only one token at a time, LLMs intriguingly exhibit longer-term foresight and a degree of anticipatory capacity. Yet, how to profile, enhance and leverage this capacity to improve reasoning performance remains an open question. In this paper, we propose Next Token-Bag Exploitation (Next-ToBE), a simple yet effective method to tackle the challenges. Next-ToBE quantifies LLM’s anticipatory capacity by measuring how well tokens in the future window are pre-captured within the model’s current prediction. Empirically, this capacity strongly correlates with the model’s generative quality, but it is often suppressed by the rigid one-hot objective in next-token prediction. To address this, Next-ToBE replaces the **one-hot target vector** in the next-token prediction paradigm with a **soft target distribution** spanning additional future tokens beyond the current step. In this formulation, the immediate next token retains the highest importance, while more distant \"look-ahead tokens\" are also included to enrich supervision, with their importance dynamically determined by temporal and semantic relevance patterns. Furthermore, the fitting process emphasizes the model’s intrinsic anticipatory tendencies, thus preserving the confidence and fidelity of the original pre-trained model while also improving training stability. Overall, Next-ToBE effectively activates the anticipatory capacity of LLMs, yielding up to a 3.9\\% absolute accuracy gain over MTP baselines on complex reasoning benchmarks (math, code, and commonsense reasoning), while reducing peak memory consumption by as much as 68\\%. This highlights its value as a scalable and lightweight strategy  to make LLM see further and reason more effectively.", "tldr": "Next-ToBE introduces a soft-target distribution that activates and refines anticipatory capacity in LLMs, improving reasoning performance by looking ahead beyond the immediate next token.", "keywords": ["Large language models", "anticipatory capacity"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f2c5e11fac64359539eddfacaa395cd062504402.pdf", "supplementary_material": "/attachment/21b512509f97cb133d18a8b3ac0cff34dc5ea958.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Next-ToBE, a new fine-tuning objective as an alternative to vanilla NTP. \n\nThe paper points out that regular LLMs only focus on predicting the very next word/token, which stops them from actually thinking ahead (but it does already exist to a certain extent).\n\nThe authors created their new training method, Next-ToBE that teaches the model to predict not just the next token, but also a few tokens down the line at the same time. Instead of simply predicting the next work, it predicts a probability of the next few words.\n\nThe key idea is that this helps the model develop better planning skills by making it look further ahead during training.\n\nThe authors demonstrate Next-ToBE's effectiveness by fine-tuning Qwen and Llama models on tasks in mathematical, code, and commonsense reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well written, motivated, an executed\n- The empirical results (Table 1) look solid. In the ran experiments, Next-ToBE is clearly the best method.\n- The proposed Future-tokens Hit Rate (FtHR) is a nice metric\n- I appreciate the detail in training method, data, eval pipeline"}, "weaknesses": {"value": "- My biggest concern is that it's only done on models that are already post-trained. Pure NTP/MTP is typically done for pretraining, so I'm not sure why this is done on post-trained models. I think the results would be a lot more convincing if it was done on base models, on pretraining data, with full model tuning (not just lora).\n- The conclusion claims that it is \"simple to implement\", the method is quite complicated, especially compared to MTP. Particularly the part about the random walk on the graph. In its current form, it will likely not be adopted by many.\n- A lot of the method is heuristically driven. E.g. chosen values of lambda. How can others use this method? Will it always work out of the box on any model with the fixed hyperparams? I think more ablations of the hyperparams (alpha, beta, lambda) are necessary\n- It's unclear how much more efficient Next-ToBE is than other methods. There is overhead from computing the values for the lookahead tokens, but not sure how much."}, "questions": {"value": "- Why are all experiments/results shown on post-trained models? Why not evaluate this on a base model? Do the same properties hold there? I would consider raising my score if this can be answered.\n- How expensive is the random-walk weighting calculation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NUEm9RPUrE", "forum": "T8IJojfaOh", "replyto": "T8IJojfaOh", "signatures": ["ICLR.cc/2026/Conference/Submission11498/Reviewer_f6SD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11498/Reviewer_f6SD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938716215, "cdate": 1761938716215, "tmdate": 1762922600905, "mdate": 1762922600905, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a loss function that encourages an autoregressive LM’s prediction to include more information about future tokens, without changing the underlying Transformer architecture or compromising inference accuracy or speed. The idea is to use a **mixture of two cross-entropy losses**: (i) between the LM head and the correct **next** token (one-hot), and (ii) between the model’s **bag-renormalized** prediction over the next (k) tokens and a set of importance weights over those tokens. Next-ToBE **nearly unanimously** outperforms NTP, MTP, and MuToR across numerous math, code, and commonsense reasoning benchmarks. Since there is only one LM output distribution per position, inference speed stays comparable to NTP (unlike MTP). The appendix contains many additional informative experiments."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "Clearly written, strong and extensively evaluated results, and an improvement on a central topic (raw language modeling itself)."}, "weaknesses": {"value": "The weighting scheme seems ad hoc and complicated, containing several hyperparameters (lambda, k, epsilon, gamma, h, rho) and the fusion of W_tau and W_s). However, the random-walk matrix is backed up by ablations, and upon reflection, the random walk here may not be so ad hoc.\nMissing some minor distributional diagnostics (see questions)."}, "questions": {"value": "1. How many tokens of CoT were used in the math evaluation protocols (a maximum is provided, but not mean/SD)? I would like to understand why autoregressive sampling does not appear to pull the Next-ToBE model off the token-by-token distribution. Conceptually, since the loss divides by the probability mass assigned to the future (k)-bag, the auxiliary term should mainly reshuffle probabilities **within** that set, but I would still expect the opposite effect from what Figure 3b shows.\n2. Does long-term Next-ToBE **autoregressive** sampling diverge from the training distribution—e.g., as measured by KL **to/from** a stronger language model?\n3. Does this technique still work if you train from scratch rather than fine-tuning a pretrained baseline? I ask in part because the alpha weights focus on tokens that already receive probability mass, which will start **at random** when training from scratch."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "stSfulmbN6", "forum": "T8IJojfaOh", "replyto": "T8IJojfaOh", "signatures": ["ICLR.cc/2026/Conference/Submission11498/Reviewer_ianY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11498/Reviewer_ianY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997331874, "cdate": 1761997331874, "tmdate": 1762922600527, "mdate": 1762922600527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Next-ToBE, a training objective to improve the anticipatory capability in LLMs. Next-ToBE modifies the standard next-token prediction objective in LLM training by replacing the one-hot target vector with a soft distribution over additional future tokens. The model incorporates a weighting scheme that assigns a dominant weight for the immediate next token, preserves the model's own anticipatory preferences, and dynamically adjusts future token weights based on temporal and semantic importance. Experiments on diverse reasoning settings (math reasoning, code generation, and common-sense reasoning) using Qwen and Llama models show consistent accuracy improvement over NTP and MTP baselines. The approach requires no architectural change and reduces peak memory usage compared to MTP methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The method is well-motivated by the two key empirical observations. The defined future token hit rate metric and the corresponding analysis provide valuable insights into LLMs' intrinsic anticipatory behavior and how it's linked to generative accuracies.\n- The objective is straightforward, and the design choices are well-motivated and supported by theoretical justification and ablation studies.\n- The method is simple and requires no architectural or inference changes. It reduces peak memory usage compared to MTP methods.\n- The paper provides extensive experiments across diverse reasoning tasks and model families and demonstrates consistent improvements."}, "weaknesses": {"value": "- The scope of baselines could be limited. The related work section acknowledges connections to label smoothing and other MTP-related baselines, but they are not evaluated as baselines, including ProphetNet, token order prediction, and label smoothing.\n- Direct quantitative and qualitative comparison with NTP is unclear. For example, the computational overhead for the weighting scheme and potential side effects (e.g., hallucinations) of Next-ToBE are not discussed. \n- Experiments are confined to relatively small models (8B), and how well the proposed method scales to larger models is unclear. Evaluation of larger models could strengthen the claims."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xx4THghJ39", "forum": "T8IJojfaOh", "replyto": "T8IJojfaOh", "signatures": ["ICLR.cc/2026/Conference/Submission11498/Reviewer_9ScA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11498/Reviewer_9ScA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762047410385, "cdate": 1762047410385, "tmdate": 1762922598992, "mdate": 1762922598992, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a novel training objective that adds a more learning signal at every time step by training to model to predict future tokens as well as the next token using the same output projection from the model. Empirically authors show how existing models are already capturing this sort of information about the future in the next token distribution and call it anitcipatory knowledge. Then they hypothesize that improving anticipatory capability in the next token distribution will improve generative performance of the model.\n\nAuthors design the objective with careful balancing between next token and future tokens learning; where they introduce weights that are based on the look-ahead distance as well as other scaling params.\nExperiments show that their proposed method gives slightly better performance across the deck in most of benchmarks they consider compared to both next token and multi token prediction alternatives."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* well grounded motivation with empirical data point showing anticipatory knowledge already existing in the models.\n* experiments are clearly described and adequate baselines and related work methods were considered."}, "weaknesses": {"value": "* the balancing weights and added renormalization make the whole objective a bit cumbersome. Not very clear what might be the optimal value of K i.e. either we want to get as much anticipatory as possible or how do we optimize it? \n\n* its known that MTP shows the substantial gains at scaling; so this method might as well show much more gains at scale. While this might be infeasible for authors due to compute constraints, absence of larger models and on more data is a minor weakness."}, "questions": {"value": "How do you think anticipatory information can be further utilized ? e.g. during inference?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PG44814cnx", "forum": "T8IJojfaOh", "replyto": "T8IJojfaOh", "signatures": ["ICLR.cc/2026/Conference/Submission11498/Reviewer_rAwF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11498/Reviewer_rAwF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762224203801, "cdate": 1762224203801, "tmdate": 1762922598556, "mdate": 1762922598556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}