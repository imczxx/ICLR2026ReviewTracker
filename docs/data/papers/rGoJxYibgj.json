{"id": "rGoJxYibgj", "number": 1491, "cdate": 1756887263642, "mdate": 1759898206159, "content": {"title": "Stop Guessing: Choosing the Optimization-Consistent Uncertainty Measurement for Evidential Deep Learning", "abstract": "Evidential Deep Learning (EDL) has emerged as a promising framework for uncertainty estimation in classification tasks by modeling predictive uncertainty with a Dirichlet prior. Despite its empirical success, prior work has primarily focused on the probabilistic properties of the Dirichlet distribution, leaving the role of optimization dynamics during training underexplored.  In this paper, we revisit EDL through the lens of optimization and establish a non-trivial connection: minimizing the expected cross-entropy loss over the Dirichlet prior implicitly encourages solutions akin to multi-class Support Vector Machines, maximizing decision margins. Motivated by this observation, we introduce the \\emph{optimization-consistency principle}, which deems an uncertainty measure valid if its value decreases as samples approach the global optimum of the training objective. This principle provides a new criterion for evaluating and designing uncertainty measures that are consistent with the optimization dynamics. Building on this foundation, we further propose a novel measure, \\emph{Margin-aware Predictive Uncertainty (MPU)}, which directly captures the separation between target and non-target evidence. Extensive experiments on out-of-distribution detection and classification-with-rejection benchmarks demonstrate the effectiveness of our propositions.", "tldr": "", "keywords": ["uncertainty estimation;"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4bfb7bfd518e081930bc552a05acd79f82e3c820.pdf", "supplementary_material": "/attachment/53600139084136a795a3728c819207c4796e7a9e.zip"}, "replies": [{"content": {"summary": {"value": "The paper derives a connection between evidential deep learning and multi-class support vector machines when the former considers an entropy-based objective.\nAdditionally, it proposes a new uncertainty measure and evaluates the proposal on a range of vision-based experiments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The margin-aware predictive uncertainty (MPU) measure is relatively well motivated.\n- The approach provides improvements on some vision-based datasets.\n- An implementation is available."}, "weaknesses": {"value": "- Section 2.1 claims that the UCE's similarity to SVMs is a \"unique property\" without further evidence. The proof simply shows that there exists a lower bound, not that such a bound cannot exist for other cases.\n- In general, the connection to SVMs remains rather vague, both in the theoretical contribution, which merely shows that one can interpret a bound in that way, and in the simple visual examples that show similar results. It also lacks a further step explaining why such a connection would be interesting and what can be learned from the fact that margin-based approaches look similar.\n- The experiments consist simply of training a regular EDL approach and evaluating different metrics.\n\n### Minor weaknesses\n- l036 \"classical Bayesian methods\": MC-Dropout can be interpreted as following a certain Bayesian approach, and ensembles are often used as a way of uncertainty quantification, but neither is a \"classical\" Bayesian method in the sense that a Bayesian neural network would be.\n- The citation system is broken throughout the paper; please use `citet` and `citep` correctly and consistently.\n\n\nIn summary, the paper shows some initial potential, but both the theory and the empirical results seem rather half-finished in their current state."}, "questions": {"value": "- Q1: How would the corresponding Figure 1 look for any other margin-based classifier, e.g., the baselines in this approach or a simple multi-class logistic regression, as well as for the remaining uncertainty measures (DE, MI, MPU)?\n- Q2: Do the authors have an intuition as to why PostN and NatPN, which optimize essentially the same objective, perform so much worse? Have all hyperparameters been tuned properly for each baseline?\n- Q3: Why are the UCE-based baselines omitted from Table 3? This seems to be a major omission, especially given the claim in l454 that UCE losses consistently induce an order in the uncertainty measures. This would require results showing that the same holds for these baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iLRrPgwxCi", "forum": "rGoJxYibgj", "replyto": "rGoJxYibgj", "signatures": ["ICLR.cc/2026/Conference/Submission1491/Reviewer_6f5n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1491/Reviewer_6f5n"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760953310425, "cdate": 1760953310425, "tmdate": 1762915784134, "mdate": 1762915784134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents the finding that performing evidential deep learning on a cross entropy loss maximizes the decision margin, thereby enables a learning regime similar to a support vector machine. The paper introduces a lower bound to the cross-entropy variant of an evidential loss which has demonstrable margin maximization properties. The paper also identifies a monotonicity relationship between this loss and the uncertainty score learned by the evidential model. Linking these two outcomes, the paper arrives at the central claim that EDL works well because it learns uncertainty scores that are inversely proportional to the distance of the data points to the decision boundaries. Combined with the inherent max-margin property, it learns accurate predictors with reliable uncertainty estimates. The paper develops a new learning rule based on its theoretical findings. In particular, it suggests training EDL with the cross-entropy loss using exponent function for output activations and without post-hoc KL-based regularization. The paper demonstrates in comprehensive experiments that this learning rule can reach competitive accuracies and uncertainty quantification scores."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The paper's presentation is particularly clear. It illustrates key notions both as visuals as in Figures 1 and 2 and with simple and intuitive analytical results such as Proposition 1.\n * The theoretical findings prescribe a learning rule and this rule is shown to perform competitively on a diverse set of experiments. These experiments contain a comparison to a wide set of baselines that cover a representative set of earlier EDL variants as well as alternative approaches.\n * Section 5 links experiment results to concrete take-home messages, such as the existence of an uncertainty ranking within the studied UCE loss.\n * The paper identifies the limitations of the contribution openly and precisely, such its not being equally applicable to small class sizes.\n * Proposition 1 and the gradient analysis provided in Appendix C.3 are novel and they support the main claim of the paper appropriately."}, "weaknesses": {"value": "* My main concern is that the results reported in Tables 2 and 3 do not demonstrate a concrete improvement in accuracy or uncertainty-based scores (e.g. MisDetect and AUPR). This weakens the claim that the knowledge sought about the max-margin character of EDL has a utility.\n * A large portion of the theoretical material is either prior work (whole Appendices A and B) or rather straightforward conclusions such as Lemma 1 of Appendix C.2. \n * I also have a few critical questions below which stops me from suggesting a clear accept at this stage, as they have a big impact on the main claim of the paper."}, "questions": {"value": "* Is the monotonicity relationship suggested in Proposition 1 one sided only? Is the order between sample pairs preserved also in the backward direction from entropies to UCE losses?\n * Is the claim about the lack of an alignment between EDL and OvR in Figure 1 (b) a bit of an exaggeration? The two model still appear to work quite similarly in this problem and the uncertainties created by EDL are similar to the left panel.\n * Figure 2 appears to suggest that the uncertainty should increase as the sample moves from the center to, say, bottom left corner as it moves away from the observation and climbs in the loss landscape. However the in left panel it appears to decrease. Is this not against the main argument of the paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "B8QPq2HpwE", "forum": "rGoJxYibgj", "replyto": "rGoJxYibgj", "signatures": ["ICLR.cc/2026/Conference/Submission1491/Reviewer_WeXo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1491/Reviewer_WeXo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761059721188, "cdate": 1761059721188, "tmdate": 1762915784016, "mdate": 1762915784016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits Evidential Deep Learning (EDL) from an optimization perspective, revealing that minimizing the expected cross-entropy under a Dirichlet prior implicitly leads to margin-maximizing behavior similar to multi-class SVMs. Based on this insight, the authors propose an optimization-consistency principle, which defines a valid uncertainty measure as one that decreases when samples approach the training objective’s optimum. Guided by this principle, they introduce a new uncertainty metric—Margin-aware Predictive Uncertainty (MPU)—that explicitly reflects class separation. Experiments on out-of-distribution detection and classification-with-rejection tasks show that MPU achieves strong empirical performance, supporting the paper’s theoretical findings."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper presents strong theoretical originality by revisiting Evidential Deep Learning (EDL) from an optimization perspective and uncovering its intrinsic connection to the maximum-margin principle in Support Vector Machines (SVMs). This offers a fresh and insightful theoretical interpretation of EDL beyond its traditional probabilistic formulation.\n\n2. The introduction of the optimization-consistency principle provides a novel and principled criterion for evaluating and designing uncertainty measures. This concept effectively bridges the gap between optimization objectives and predictive uncertainty, contributing to a deeper understanding of uncertainty modeling.\n\n3. The proposed Margin-aware Predictive Uncertainty (MPU) metric is well-motivated and theoretically grounded. By explicitly capturing the margin between target and non-target evidence, it aligns uncertainty estimation with the underlying training dynamics.\n\n4. The experimental validation is comprehensive, covering both out-of-distribution detection and classification-with-rejection benchmarks. The results convincingly demonstrate the empirical benefits of aligning uncertainty estimation with optimization objectives."}, "weaknesses": {"value": "1. Some theoretical analyses rely on relatively strong assumptions, such as convergence to or proximity to global optima, which may not always hold in practical deep learning scenarios.\n\n2. The experimental scope remains somewhat limited to classification tasks. Further evaluation in more complex or multimodal settings would strengthen the generality and applicability of the proposed framework."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ED3nd2AzYZ", "forum": "rGoJxYibgj", "replyto": "rGoJxYibgj", "signatures": ["ICLR.cc/2026/Conference/Submission1491/Reviewer_N3WT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1491/Reviewer_N3WT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876978633, "cdate": 1761876978633, "tmdate": 1762915783895, "mdate": 1762915783895, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Evidential Deep Learning (EDL) is currently a promising approach for modeling predictive uncertainty in classification tasks. However, previous works on uncertainty estimation have largely overlooked the role of optimization dynamics.This paper first provides a clear and insightful analysis showing that the optimization objective of EDL implicitly encourages SVM‐like solutions.Based on this observation, the authors introduce the optimization‐consistency principle, which states that an uncertainty measure is valid if its value decreases as samples approach the global optimum of the training objective.Finally, motivated by this principle, the paper defines a new uncertainty metric termed Margin-aware Predictive Uncertainty (MPU). Extensive experiments demonstrate the effectiveness of this metric."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper convincingly establishes the connection between EDL and SVM, supported by rigorous theoretical proofs and reasonable assumptions.\n2 The proposed Optimization-Consistency Property is intuitively sound and well aligned with optimization dynamics."}, "weaknesses": {"value": "1. In terms of content organization, the authors devote a large portion of the paper to explaining the relationship between EDL and SVM, as well as the optimization-consistency property, but do not provide a sufficiently detailed discussion of the proposed uncertainty metric itself—its characteristics, advantages, and deeper connections to the preceding theory.\n2. The relationship between the Optimization-Consistency of Differential Entropy and the final MPU metric is not clearly explained.\n3. Neither the main text nor the experimental section specifies what training loss was used. Did the authors employ only the UCE loss? Was the proposed MPU-related loss incorporated into training?\n4. Some comparable works, such as I-EDL and R-EDL, include experiments under few-shot and noisy settings, but such evaluations are missing in this paper."}, "questions": {"value": "Please refer to the Weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VPfkEbQ5WZ", "forum": "rGoJxYibgj", "replyto": "rGoJxYibgj", "signatures": ["ICLR.cc/2026/Conference/Submission1491/Reviewer_PQRx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1491/Reviewer_PQRx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925328735, "cdate": 1761925328735, "tmdate": 1762915783769, "mdate": 1762915783769, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}