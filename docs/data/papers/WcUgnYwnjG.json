{"id": "WcUgnYwnjG", "number": 17202, "cdate": 1758273402564, "mdate": 1759897191138, "content": {"title": "Exploring Effective Terminal State: A Null-Model-Guided Graph Diffusion Model", "abstract": "Graph diffusion models have shown promise in generating complex networks, but they often suffer from two critical limitations: On the one hand, terminating the forward diffusion in pure Gaussian noise graph erases the intrinsic structural signatures of the original network, leading to sub-optimal generative outcomes. On the other hand, the unconstrained diffusion trajectory progressively obliterates topological characteristics, resulting in complete structural degradation. To address these issues, we propose Null-Model-Guided Graph Diffusion (NMG-GD), a principled framework with tailored designs for graph generation. \nFirst, we claim that traditional isotropic priors (e.g., Gaussian or fully structured graphs) distort salient topological features. Instead, we adopt a null-model distribution as the forward diffusion endpoint, which explicitly preserves critical network statistics such as degree sequences and clustering coefficients—ensuring global consistency. \nSecond, we derive a null-model-guided continuous-time stochastic differential equation (SDE) and introduce the Position-enhanced Graph Score Network (PGSN). PGSN ingests both continuous and quantized adjacencies, fusing random-walk, shortest-path and null-model cues in a permutation-equivariant encoder,which can significantly elevates sample quality. Extensive experiments on three public datasets (including social and biological networks) demonstrate that NMG-GD achieves state-of-the-art performance. It shows the significant advantages in structural similarity and generation efficiency.", "tldr": "Null-Model-Guided Graph Diffusion replaces Gaussian noise with a null-model prior and global topological constraints, enabling more accurate and efficient graph generation.", "keywords": ["graph diffusion model", "null-model", "graph generation", "continuous-time SDE"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/37ceeab11eb05b0b89e3f1801f63f8ebd4bb7bad.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel graph diffusion model, NMG-GD, that addresses that existing graph diffusion methods use an unstructured or overly simplistic terminal state, which erases crucial topological properties of the original graph, forcing the model to reinvent complex statistics during the reverse process. NMG-GD guides the forward diffusion process to terminate at a first-order null model graph, preserving essential global statistics.  Extensive experiments on synthetic and real-world biological networks demonstrate that NMG-GD achieves competitive performance across multiple structural and neural network-based metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper conducts comprehensive experiments on multiple datasets, showing that NMG-GD consistently outperforms a wide range of baselines, including recent diffusion models, across both classical structural metrics and modern neural metrics.\n\n2. This paper conducts an ablation study comparing a variant without the full noise design and a parameter sensitivity analysis, helping to understand the contribution of its components.\n\n3. The derivation of the null-model-guided SDE for both the forward and reverse processes is detailed and appears sound."}, "weaknesses": {"value": "1. The paper emphasizes the use of directional noise as a key contribution over prior work. However, the connection between the proposed method and the concept of directionality is not fully clarified. The introduced noise $ε^'$ remains Gaussian, albeit with a shifted mean. It is better to discuss how this constitutes directional guidance rather than isotropic noise.\n\n2. The paper does not explain why the proposed NMG-GD works so well. Is the primary benefit simply that it provides a better-initialized starting point for the reverse process? Or does it fundamentally reshape the loss landscape of the score function, making it easier to learn? It is better to conduct a deeper analysis, for example, by visualizing the diffusion trajectory.\n\n3. The paper does not discuss the computational complexity or the practical overhead of NMG-GD compared to other baselines."}, "questions": {"value": "1. Why is the discretization threshold set at 0.3 for converting the continuous adjacency matrix into a discrete graph? What was the rationale behind selecting this specific value? Was this threshold fine-tuned, and how sensitive is the model's performance to it?\n\n2. NMG-GD uses a continuous adjacency matrix and applies a fixed threshold of 0.3 for discretization. What are the potential effects of exploring other discretization strategies, such as sampling edges from a Bernoulli distribution that is parameterized by the continuous values? Additionally, how does the choice of the discretization method influence the quality of the final discrete graph?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IutsAkYn6J", "forum": "WcUgnYwnjG", "replyto": "WcUgnYwnjG", "signatures": ["ICLR.cc/2026/Conference/Submission17202/Reviewer_dfPc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17202/Reviewer_dfPc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17202/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645603174, "cdate": 1761645603174, "tmdate": 1762927173311, "mdate": 1762927173311, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Null-Model-Guided Graph Diffusion, a framework that uses a null-model distribution as the terminal distribution of the forward diffusion process. This terminal distribution is designed to preserve critical network statistics (e.g., degree sequences, clustering coefficients), which in turn guides the reverse process to generate more realistic and structurally valid graphs. The authors provide formal derivations for the forward process, the reverse (denoising) process, and the corresponding training objective. The proposed method is evaluated on three graph generation benchmarks (Community-small, Ego-small, and Enzymes), reportedly achieving significant improvements on several graph quality metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Theoretical Soundness: The authors provide formal derivations for the forward process, the reverse process, and the training objective, establishing a sound theoretical foundation for the proposed framework.\n\n- Clarity of Exposition: The paper is well-written and logically structured. It begins with a clear and strong motivation, followed by systematic derivations of the diffusion process for using a null-model distribution as the prior, network architecture. This logical progression makes the paper easy to follow."}, "weaknesses": {"value": "- Ambiguity and Lack of Ablation for the Null-Model Prior: \n\nThe manuscript provides an insufficient treatment of the null-model prior. The precise mechanism by which it preserves structural statistics remains underspecified, and its **computational cost** is not analyzed. Crucially, the paper lacks an **ablation study** to justify the choice of preserved characteristics, leaving the question of which statistics are most impactful unanswered.\n\n- Unaddressed Dependency on Ground Truth in Reverse Process: \n\nThe reverse process, as formulated in equation 9, seems to depend on the ground-truth graph $A$ via the function $f$. This creates a **circular dependency**, as A is not available at inference time. The paper does not explain how this issue is handled, representing a significant gap in the methodology.\n\n- Limited Experimental Scope and Inadequate Baselines: \n\nThe paper's empirical evaluation is insufficient. It fails to compare against several key state-of-the-art graph generation models, such as DiGress[1] and GraphBFN[2]. Additionally, the experiments are confined to a limited set of datasets, omitting crucial and widely-used benchmarks like QM9 and ZINC250k. This lack of comparison against strong baselines on standard datasets makes it difficult to properly assess the method's performance and scalability. \n\nAdditionally, the proposed method **underperforms SOTA on Enzymes dataset** in all classical metrics, which may suggest the method could not scale to large graphs.\n\n[1]Vignac, C., Krawczuk, I., Siraudin, A., Wang, B., Cevher,V., and Frossard, P. Digress: Discrete denoising diffusion for graph generation\n[2] Yuxuan Song et al. Smooth Interpolation for Improved Discrete Graph Generative Models"}, "questions": {"value": "What is the definition of $q_{null}$? Does it depend on the ground truth graph $A$?\n\nHow dose the null-graph distribution handles node features?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EGid5ZZlgs", "forum": "WcUgnYwnjG", "replyto": "WcUgnYwnjG", "signatures": ["ICLR.cc/2026/Conference/Submission17202/Reviewer_V2QX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17202/Reviewer_V2QX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17202/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761664065246, "cdate": 1761664065246, "tmdate": 1762927173042, "mdate": 1762927173042, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Null-Model-Guided Graph Diffusion, aiming to address a key limitation of existing graph diffusion models, structural degradation when the forward process terminates in pure Gaussian noise. The authors propose using a null model as the terminal distribution, preserving global graph statistics such as degree and clustering. They derive a null-model-guided SDE and design a Position-Enhanced Graph Score Network to capture both continuous and discrete structural cues."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Innovative use of the Null Model as the terminal state of the diffusion model\nThe paper replaces the conventional Gaussian endpoint in diffusion with a null-model distribution, preserving key topological properties such as degree sequence, clustering, and preventing complete structural collapse during the forward process.\n2. Enhanced score network design\nThe proposed Position-Enhanced Graph Score Network integrates continuous adjacency signals with discrete structural encodings, achieving permutation equivariance and improved structural recovery."}, "weaknesses": {"value": "1. Lack of analysis on computational efficiency:\nAlthough the authors claim improved sampling efficiency, the paper does not provide detailed runtime or memory comparisons against prior diffusion models (such as GraphGDP, Pard). The added null-model computation and SDE formulation may introduce nontrivial overhead.\n2.No ablation on the score network architecture:\nThe proposed PGSN combines several structural encodings, but the paper does not isolate the contribution of each (e.g., RWSE vs. SPD). Without such analysis, it is unclear which component primarily drives the performance gain.\n3. Insufficient exploration of parameter sensitivity:\nThe null-model weight η significantly influences generation quality, yet the sensitivity study is limited to a single dataset. The paper lacks a broader discussion on how different graph domains or diffusion schedules affect stability and convergence.\n4. Missing qualitative or visual interpretability analysis:\nWhile quantitative metrics are strong, the paper provides minimal visualization or structural interpretation of generated graphs. More examples or analysis (such as motif frequency, connectivity distribution) would help clarify what specific aspects of topology the null-model guidance preserves."}, "questions": {"value": "1. Clarification on the null model formulation:\nThe authors are encouraged to provide a more detailed explanation of the term q_null. Specifically, what is its explicit mathematical form, and what does ​A-q_null represent in practice? Moreover, further justification is needed for why the term (A-q_null) effectively encourages the generated graphs to preserve key statistical properties (e.g., degree distribution, clustering). A clearer theoretical or intuitive interpretation would strengthen the readers’ understanding of this mechanism.\n\n2. Potential overfitting and generalization concern:\nSince the null-model constraint enforces structural similarity to the training graphs, it raises the question of whether the model might tend to memorize specific graph statistics rather than learning more generalizable topological patterns. If this is an important factor, it would be valuable for the authors to include additional evaluation metrics—such as diversity, novelty, or generalization scores—to quantitatively assess whether the generated graphs go beyond simply reproducing training-set statistics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HwlFW9imSk", "forum": "WcUgnYwnjG", "replyto": "WcUgnYwnjG", "signatures": ["ICLR.cc/2026/Conference/Submission17202/Reviewer_HQfe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17202/Reviewer_HQfe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17202/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952673137, "cdate": 1761952673137, "tmdate": 1762927172188, "mdate": 1762927172188, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}