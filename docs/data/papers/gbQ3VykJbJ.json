{"id": "gbQ3VykJbJ", "number": 21648, "cdate": 1758320086753, "mdate": 1759896910722, "content": {"title": "Flexible Transfer Learning in Deep Cox Models", "abstract": "Prognosis prediction is an important topic in survival analysis. Historically, research aimed at predicting survival outcomes has largely been confined to individual datasets. These datasets often have limitations, such as rare event rates, small sample sizes, high dimensionality, and low signal-to-noise ratios.  To overcome these limitations, integrated survival analysis and transfer learning has been proposed to improve prediction accuracy by incorporating external prediction models into the analysis of newly collected data. However, traditional integrated approaches, such as the integrated Cox proportional hazards model, often face limitations in prognostic prediction capabilities due to their dependence on the linearity and proportional hazards assumptions. In reality, the relationship between event times and risk factors can be intricate, often involving non-linear effects, influences that vary over time, and interactions. To effectively capture the complexities of integrated time-to-event data, it is essential to employ computationally efficient deep learning techniques.", "tldr": "We propose a flexible transfer learning framework for analyzing time-to-event data using Cox model.", "keywords": ["Transfer learning; Survival analysis; Deep Learning; Cox model"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/111ab786c849c003d7e73dd1e45d325515f28973.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a deep learning framework that integrates external risk models with limited internal time-to-event data for improved prognostic prediction through Kullback-Leibler (KL) based transfer learning. The target internal cohort satisfies a flexible  proportional hazards model, and some external risk scores are available from an external model that may not be the same as the internal model. The disparity between the internal and external ranking metric is measured by the Kullback-Leibler (K-L) divergence. Simulation studies and a real-world application on a prostate cancer dataset demonstrate improved prediction accuracy and robustness compared to baseline Cox and deep survival models. \n\nOverall, this is an interesting work with practical relevance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The proposed method addresses a real challenge in biomedical research when the target dataset is too small for a deep neural network approach.\n\n2. The introduction of a generalized KL divergence penalty within a deep neural network survival model represents a significant advancement. \n\n3.  The empirical success of the approach underscores its significance.  \n\n4. The paper is clearly structured and includes proofs and implementation details."}, "weaknesses": {"value": "1. The success of the framework hinges on the relevance and fidelity of external information; poor or misaligned sources may limit improvement.\n\n2. The exploration of domain shift is limited. While some heterogeneity scenarios are tested, more systematic evaluation of extreme domain discrepancies would strengthen claims of robustness.\n\n3. The inclusion of deep learning components may obscure the interpretability advantages typically associated with Cox models."}, "questions": {"value": "1. The proposed internal model may be unidentifiable if the form of the risk function r and the parameter beta are both unknown. \n\n2. How sensitive is the performance  of NNCoxKL to the scaling or monotonic transformation of external risk scores?\n\n3. The choice of the penalty Œ∑ requires careful cross-validation, which may be computationally intensive and unstable in small datasets. Could Œ∑-selection be guided by an information criterion rather than cross-validation to improve efficiency?\n\n4. How does the model handle multiple external sources simultaneously?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SM5vqswVVP", "forum": "gbQ3VykJbJ", "replyto": "gbQ3VykJbJ", "signatures": ["ICLR.cc/2026/Conference/Submission21648/Reviewer_gpjL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21648/Reviewer_gpjL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761462754690, "cdate": 1761462754690, "tmdate": 1762941870458, "mdate": 1762941870458, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NNCoxKL, a deep transfer learning framework designed to integrate external risk models with internal time-to-event data for survival analysis. The approach extends the Cox proportional hazards model by introducing a generalized Kullback‚ÄìLeibler (KL) divergence penalty, which aligns internal and external risk scores and facilitates knowledge transfer from external risk assessment tools. The framework employs neural networks to capture non-linear relationships among covariates and is evaluated on both synthetic simulations and one real-world dataset, demonstrating performance gains through the incorporation of external risk information."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Leveraging external tools to enhance risk prediction or improve generalization is indeed an important problem, especially in survival analysis where sample sizes are often limited and external models typically encode knowledge from larger, more diverse populations."}, "weaknesses": {"value": "-\tThe applicability of the proposed approach appears quite narrow. The method assumes that the internal dataset is relatively small and that the external tool provides informative signals about the same samples based on a subset of the internal covariates. Such a setting may not commonly occur in practice, which likely explains why the authors were only able to demonstrate results on a single real-world dataset that meets these criteria.\n-\tThe paper also lacks a solid theoretical foundation or generalization analysis that could clarify when or why the generalized KL regularization improves transfer performance. In addition, the study does not examine the method‚Äôs potential failure modes under substantial domain shift between internal and external data.\n-\tThe exposition around the use of KL divergence is unnecessarily lengthy. Since KL divergence is a well-established concept in machine learning, its detailed reintroduction offers limited value. The core contribution‚Äîinterpreting ranking as a probabilistic measure and applying KL regularization to align internal and external risk predictions‚Äîis relatively straightforward and could be presented more concisely.\n-\tFinally, the implementation of the ranking-based loss (i.e., the Cox partial likelihood) raises practical concerns. This quantity should ideally be computed over the entire risk set, yet the paper does not sufficiently discuss the implications of using mini-batch training for the deep model $ùëü(ùëç_ùëñ, \\beta)$. Moreover, the computational cost is likely to be substantial, as the ranking must be evaluated across all event times, making the proposed approach potentially inefficient for large-scale applications."}, "questions": {"value": "-\tThe baseline should include a variant that uses the external tool‚Äôs risk scores as an additional input covariate, since this alone may already capture much of the information derived from the broader external population.\n-\tFollowing Weakness 4, what is the impact of mini-batch training on the accumulated generalized KL divergence term $D(\\tilde{r} || r)$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kkn3FLo8it", "forum": "gbQ3VykJbJ", "replyto": "gbQ3VykJbJ", "signatures": ["ICLR.cc/2026/Conference/Submission21648/Reviewer_x6Dh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21648/Reviewer_x6Dh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838580309, "cdate": 1761838580309, "tmdate": 1762941870188, "mdate": 1762941870188, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "NNCoxKL, a generalized KL-based transfer learning framework, flexibly integrates external risk info with internal time-to-event data. It outperforms traditional Cox models and non-transfer deep models in small/moderate datasets. Real-world prostate cancer data and simulations confirm it boosts C-index and reduces loss, validating its value for prognostic prediction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "‚Ä¢ Works for probabilistic/non-probabilistic external data (e.g., risk groups) and homogeneous/heterogeneous settings.\n‚Ä¢ Non-linear modeling: Uses DNN to avoid linearity constraints of classic Cox models.\n‚Ä¢ Overfitting mitigation: Transfer learning stabilizes performance vs. data-limited NNCox."}, "weaknesses": {"value": "The method assumes that clients share overlapping or similar feature spaces, which may not hold in highly heterogeneous cross-domain settings.\nPerformance depends heavily on hyperparameters in the meta-graph (e.g., similarity thresholds, edge weights), but their tuning process is not clearly described."}, "questions": {"value": "Tuning parameter Œ∑ needs cross-validation, is there any better way to optimize the tuning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lcDOyXR4Uj", "forum": "gbQ3VykJbJ", "replyto": "gbQ3VykJbJ", "signatures": ["ICLR.cc/2026/Conference/Submission21648/Reviewer_nurd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21648/Reviewer_nurd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992277919, "cdate": 1761992277919, "tmdate": 1762941869803, "mdate": 1762941869803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents NNCoxKL, a transfer learning framework that augments a flexible neural Cox model with external prognostic information using a generalized Kullback Leiber divergence constructed over risk set rankings. The core idea is to align internal risk scores produced by a neural network with external scores or even coarse risk groupings by minimizing a divergence between Plackett Luce style distributions at each event time, while retaining a partial likelihood structure so standard deep learning optimization remains applicable. A tuning parameter controls how strongly the external signal enters the penalized objective, and a proof shows the objective reduces to a familiar form that weights event indicators by an externally induced pseudo event rate. The paper supports the method with simulations that vary nonlinearity, censoring, data size, and domain shift, and with an application that integrates STAR CAP risk groups into a MUSIC prostate cancer cohort, reporting gains in C index and loss on held out data. The authors also discuss implementation choices such as network architecture, regularization, AdamW, early stopping, and cross validation for selecting the integration weight, and provide additional experiments on public survival datasets.\n\n\nOverall this is a promising and practically relevant contribution that bridges a real gap between clinical risk tools and modern survival learning. With stronger analysis of invariance and negative transfer, broader calibration focused evaluation, and more comprehensive baselines and ablations, the paper would be significantly stronger and more actionable for practitioners."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work is well motivated by the small sample challenge in survival prediction and by practical constraints that often limit external information to model scores or clinical groupings rather than individual level data. Framing integration as a divergence between ranking distributions is elegant and versatile, letting the method use heterogeneous external sources without requiring probability calibrated survival outputs. The derivation that preserves a Cox style training objective is a strong practical contribution because it allows the method to drop into existing neural survival toolchains with minor changes. The empirical study is thoughtful, covering both linear and nonlinear data generating processes, different external model qualities, and explicit domain shift, and it shows consistent discrimination gains and improved optimization behavior with reduced overfitting sensitivity. The real data example with prostate cancer is compelling because it demonstrates how to convert a points based staging system into usable external signal for a modern survival learner. The paper is clearly written, situates itself in the literature on KL based integration and neural survival models, and attends to reproducibility details."}, "weaknesses": {"value": "There are also weaknesses that limit the paper‚Äôs current impact and clarity. Despite the flexible network for covariate effects, the method still inherits a proportional hazards assumption for the baseline, which can be restrictive in settings with strong time varying effects. The approach is sensitive to the scale and even monotone transformation of the external score, and the proposed one step rescaling via a univariate Cox fit is ad hoc and may not be robust across cohorts with heavy shift; a principled invariance or calibration procedure would strengthen the method. The reliance on cross validated selection of the integration weight introduces variance in small internal samples, and no guidance is given for safe defaults or information criteria based selection. The theory focuses on the objective rewrite but offers no guarantees about consistency, oracle properties under correct ranking, or bounds on negative transfer when the external model is poor or misaligned; even a simple analysis under misspecification would be helpful. The evaluation emphasizes discrimination and partial likelihood loss but gives little attention to calibration, which is critical for clinical adoption, and does not report competing risks, time dependent AUC, or D calibration. Comparisons omit recent neural survival baselines that integrate external knowledge through stacking or representation learning, and ablations on architecture depth, dropout, and the role of the external score as an explicit input versus only via the penalty would clarify where the gains come from. Finally, practical aspects such as computational cost, convergence stability, and handling of ties are only briefly mentioned, and the combination of multiple external sources is deferred to future work despite being a natural and common scenario.\n\n---\n\nWeaknesses itemized (for rebuttal and discussion)\n\n1. Inherits a proportional hazards structure from the Cox framework, which can be restrictive when effects vary strongly over time. \n2. The divergence is not invariant to rescaling of external scores and the proposed remedy is an ad hoc rescaling via a univariate Cox fit, with unclear robustness across domains. \n3. Relies on cross-validated selection of the integration weight, which may introduce variance in small samples and lacks clear default guidance. \n4. Provides limited theoretical guarantees beyond the objective rewrite, with no explicit bounds on negative transfer under misaligned external signals.\n5. Evaluation emphasis appears to be on discrimination and loss, with less attention to absolute risk calibration and competing-risk settings that matter for clinical adoption.\n6. Practical guidance on combining multiple external sources, convergence stability, and tie handling is brief relative to likely practitioner needs."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Bte8VJ2KFK", "forum": "gbQ3VykJbJ", "replyto": "gbQ3VykJbJ", "signatures": ["ICLR.cc/2026/Conference/Submission21648/Reviewer_VB7f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21648/Reviewer_VB7f"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993165822, "cdate": 1761993165822, "tmdate": 1762941869509, "mdate": 1762941869509, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}