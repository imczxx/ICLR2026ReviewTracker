{"id": "8pQsiFyTQi", "number": 9832, "cdate": 1758142763328, "mdate": 1759897692987, "content": {"title": "Provably Accelerated Imaging with Restarted Inertia and Score-based Image Priors", "abstract": "Fast convergence and high-quality image recovery are two essential features of algorithms for solving ill-posed imaging inverse problems.\nExisting methods, such as regularization by denoising (RED), often focus on designing sophisticated image priors to improve reconstruction quality, while leaving convergence acceleration to heuristics. \nTo bridge the gap, we propose Restarted Inertia with Score-based Priors (RISP) as a principled extension of RED.\nRISP incorporates a restarting inertia for fast convergence, while still allowing score-based image priors for high-quality reconstruction.\nWe prove that RISP attains a faster stationary-point convergence rate than RED, without requiring the convexity of the image prior.\nWe further derive and analyze the associated continuous-time dynamical system, offering insight into the connection between RISP and the heavy-ball ordinary differential equation (ODE).\nExperiments across a range of imaging inverse problems demonstrate that RISP enables fast convergence while achieving high-quality reconstructions.", "tldr": "", "keywords": ["Image reconstruction", "accelerated iterative algorithms", "regularization by denoising", "score-based image prior", "restarted inertia"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/625657a3776b7d9bef32bea015b0f615d22a7891.pdf", "supplementary_material": "/attachment/4243b592d3b243b57769b572ebc38231f7ffd805.zip"}, "replies": [{"content": {"summary": {"value": "This paper develops an acceleration strategy, namely RISP (Restarted Inertia with Score-based Priors), for the Regularization-by-Denoising (RED) framework in imaging inverse problems. Two variants are proposed: RISP-GM (gradient-style) and RISP-Prox (proximal-style), which incorporate an inertial/momentum step and a restart criterion into RED-like updates, and utilize a pretrained score network as the prior. Under assumptions (score is a gradient field, Lipschitz gradient, and Lipschitz Hessian of data fidelity and score), the authors prove accelerated stationary-point convergence rates of $O(1/n^{\\frac{4}{7}})$ for both variants. They connect the discrete methods to a restarted heavy-ball ODE and validate empirically on linear and nonlinear inverse problems, demonstrating substantial iteration and runtime speedups while improving reconstruction quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper identifies restarting inertia as a theoretically justifiable mechanism to accelerate RED-style algorithms while controlling instability, and presents concrete algorithmic variants.\n- The derivation of $O(1/n^{\\frac{4}{7}})$ convergence under nonconvex score priors is a meaningful advancement in the analysis of accelerated RED/PnP-style methods.\n- The connection to a restarted heavy-ball ODE gives additional intuition and helps explain algorithmic behavior.\n- The empirical section shows applications to linear and nonlinear inverse problems, showing both acceleration benefits and image quality improvement in reconstruction.\n- The algorithms are simple to implement on top of existing RED/PnP solvers: the inertia and restart rules are lightweight and practical."}, "weaknesses": {"value": "- The accelerated rates require Lipschitz continuity of Hessians (Assumption 3) and that the score be an exact gradient field (Assumption 1). While the paper discusses how these can be approximated in practice (e.g., gradient-step denoisers, Lipschitz activations), a more explicit discussion and empirical diagnostics showing how violation of these assumptions affects performance would strengthen the contribution.\n- RISP introduces several new hyperparameters (e.g., the inertia parameter and restart threshold). The paper reports robustness in experiments, but lacks a systematic ablation or guidance for selecting these values in practice. An appendix table or a small experiment showing sensitivity would help practitioners.\n- The restart trigger is based on accumulated relative change; it would be useful to compare this choice against other restart heuristics (e.g., function value increase, gradient norm increase, or adaptive restart strategies). A short ablation would clarify whether the theoretical restart choice is critical.\n- The manuscript cites inertia/acceleration prior works, but could provide a more direct empirical and conceptual comparison to stronger recent baselines that incorporate momentum or acceleration (e.g., PnP-FISTA, PnP Quasi-Newton, and extrapolated three-operator splitting) beyond baseline RED-GM/RED-Prox.\n1. PnP-FISTA: Kamilov et al., “Plug-and-Play FISTA for Solving Nonlinear Imaging Inverse Problems”. \n2. PnP-QN: Tan et al., “Provably Convergent Plug-and-Play Quasi-Newton Methods”. \n3. Wu et al., “Extrapolated Plug-and-Play Three-Operator Splitting Methods for Nonconvex Optimization with Applications to Image Restoration”. \n-Some of the dramatic runtime gains in the large-scale experiment are attributed to the high per-iteration cost of RED variants; however, the per-iteration complexity and GPU/CPU implementation details (e.g., whether prox evaluation or score computation dominates) are not clearly reported."}, "questions": {"value": "- Can you quantify how violations of Assumptions 1–3 affect the convergence rate empirically? For example, how does RISP perform when the score is not exactly a gradient field?\n- Did you compare the chosen restart rule (accumulated relative change) to other restart schemes (e.g., O’Donoghue–Candes adaptive restart or gradient-based restart)? Can you add a discussion, if not a full-blown comparison with other known heuristics for restart?\n- For large-scale inverse scattering, you use DRUNet and patch processing. How sensitive are results to the patching strategy, and does patch-based score evaluation affect theoretical assumptions (e.g., smoothness)?\n- The paper states code will be released upon acceptance. Please ensure the repo includes (i) exact pretrained models used, (ii) scripts for reproducing key plots (gradient-norm decay, PSNR vs runtime), and (iii) detailed hyperparameter selection modules."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GSRojYKVBi", "forum": "8pQsiFyTQi", "replyto": "8pQsiFyTQi", "signatures": ["ICLR.cc/2026/Conference/Submission9832/Reviewer_pe5V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9832/Reviewer_pe5V"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9832/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802521629, "cdate": 1761802521629, "tmdate": 1762921313744, "mdate": 1762921313744, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to accelerate the convergence of the regularization by denoising (RED) framework with score-based priors by incorporating momentum and restart strategies. The authors provide theoretical convergence rate guarantees and extend the analysis to a continuous-time dynamical system formulation. Both the theoretical convergence analysis and empirical experiments demonstrate faster convergence compared to the original RED framework, despite the nonlinearity of score-based priors."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical justification for accelerated convergence is rigorous and carefully presented. In particular, it is valuable that the analysis is conducted under non-convex score-based prior conditions, which are more realistic in modern generative models.\n2. The method builds upon the well-studied RED framework and introduces modifications that are principled and consistent with its formulation.\n3. The proposed changes require only a few additional lines of code, making the method highly practical. This simplicity also suggests that the proposed acceleration could potentially be applied to inverse problem solvers that use diffusion model sampling as a denoiser, not only traditional RED implementations."}, "weaknesses": {"value": "1. The novelty of the proposed method feels somewhat modest. Momentum and restart strategies are widely used in optimization, so the main contribution here seems to lie in establishing acceleration guarantees under non-convex score-based priors. While the theoretical development is sound, the overall structure of the convergence analysis appears similar to existing frameworks for accelerated non-convex optimization. It is not entirely clear how substantially new the analytical perspective is.\n2. While momentum can accelerate the early stages of optimization, it may also introduce oscillations or instability, particularly in nonlinear or ill-conditioned settings. In the experiments presented, there are cases where the final reconstruction quality is actually worse than the baseline without momentum. This suggests that careful hyperparameter tuning may be necessary, and that the practical benefits of acceleration may not always be realized at convergence.\n3. Given that the original RED framework is rarely used in contemporary practice—having largely been superseded by more general PnP and score-based inverse problem formulations—the practical impact of the contribution may be somewhat limited, even if the analysis itself is well executed."}, "questions": {"value": "Please refer to the Weaknesses section for the main points of clarification and concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "zJvtBypw8S", "forum": "8pQsiFyTQi", "replyto": "8pQsiFyTQi", "signatures": ["ICLR.cc/2026/Conference/Submission9832/Reviewer_UnZv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9832/Reviewer_UnZv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9832/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814444365, "cdate": 1761814444365, "tmdate": 1762921313379, "mdate": 1762921313379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method called Restarted Inertia with Score-based Priors (RISP), which extends the popular RED framework by incorporating momentum and a restart mechanism to accelerate convergence in imaging inverse problems. The authors provide non-convex convergence guarantees for two variants—RISP-GM and RISP-Prox—and connect the discrete algorithms to a continuous-time heavy-ball ODE. Experiments on both linear and nonlinear inverse problems demonstrate improved convergence speed and competitive reconstruction quality compared to RED baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides a rigorous non-convex convergence analysis for RISP, establishing an improved rate under Lipschitz-continuous Hessian assumptions. This is a meaningful theoretical advance in the analysis of accelerated methods for imaging inverse problems.\n- The combination of inertia and restarting is well-motivated and effectively addresses overshooting and instability in non-convex settings. The connection to the heavy-ball ODE offers valuable continuous-time intuition.\n- The authors thoroughly evaluate RISP on a range of imaging tasks, including linear and nonlinear inverse problems. The results consistently show faster convergence without sacrificing reconstruction quality, and the method scales well to large images"}, "weaknesses": {"value": "- The paper does not adequately discuss the recent surge of PnP-like methods that use pre-trained diffusion models as score-based priors, such as [1]–[7]. In particular, [7] (A Variational Perspective on Solving Inverse Problems with Diffusion Models) also combines diffusion models with a RED-like framework. A comparison or discussion of how RISP could integrate such powerful priors is missing.\n\n- Another related work in PnP literature is missing [8], which also shows the extension to the RED framework. \n\n- While the experiments are comprehensive, they are limited to traditional denoisers (DRUNet). It would be valuable to see how RISP performs when combined with state-of-the-art diffusion-based score functions, especially since such models have shown superior performance in many inverse problems.\n\n- The method introduces new hyperparameters (theta and B), and while the authors claim robustness, no systematic ablation study is provided to support this claim across different tasks.\n\n### References\n[1] DIFFUSION POSTERIOR SAMPLING FOR GENERAL NOISY INVERSE PROBLEMS, ICLR 2023  \n[2] Improving Diffusion Models for Inverse Problems using Manifold Constraints, Neurips 2022   \n[3] Denoising diffusion models for plug-and-play image restoration, CVPRW 2023  \n[4] zero-shot image restoration using denoising diffusion null-space model, ICLR 2023  \n[5] Diffusion Posterior Sampling for Linear Inverse Problem Solving: A Filtering Perspective, ICLR 2024  \n[6] Pseudoinverse-Guided Diffusion Models for Inverse Problems, ICLR 2023  \n[7] A Variational Perspective on Solving Inverse Problems with Diffusion Models, ICLR 2024  \n[8] TFPnP: Tuning-free Plug-and-Play Proximal Algorithms with Applications to Inverse Imaging Problems, JMLR 2022"}, "questions": {"value": "See [Weaknesses]"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SMQoDQwIlk", "forum": "8pQsiFyTQi", "replyto": "8pQsiFyTQi", "signatures": ["ICLR.cc/2026/Conference/Submission9832/Reviewer_2V7N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9832/Reviewer_2V7N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9832/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915007036, "cdate": 1761915007036, "tmdate": 1762921313041, "mdate": 1762921313041, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Restarted Inertia with Score-based Priors (RISP), an acceleration framework built upon the RED (Regularization by Denoising) methodology for solving imaging inverse problems. The key contribution  is the integration of a restarted heavy-ball-type inertia mechanism with score-based priors derived from deep denoisers, enabling provably faster convergence to stationary points compared to  RED. The authors provide both discrete algorithmic instantiations (RISP-GM and RISP-Prox) and a continuous-time dynamical systems interpretation linked to the heavy-ball ODE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Rigorous convergence analyses for both gradient-based (RISP-GM) and proximal (RISP-Prox) variants under realistic assumptions (e.g., Lipschitz Hessian).\n* Demonstation of significant empirical speedups compared to RED on large scale inverse problems (debluring, super-resolution, inpainting and MRI) \n* A continuous-time dynamical systems interpretation linked to the heavy-ball ODE is offered, enriching theoretical understanding.\n* The performance of the proposed acceleration strategy is validated across diverse tasks, including linear and nonlinear inverse problems \n  showing consistent acceleration and reconstruction quality"}, "weaknesses": {"value": "* The restart condition used in both algorithms (line 5 in both cases) uses a cumulative sum over all past iterations since last restart. This needs to be clarified as a running window accumulator to avoid confusion about global vs. local accumulation.\n* The core idea, ombining restart + inertia + nonconvex smooth optimization is not new. The novelty mainly lies in the application domain (imaging with learned priors) and the compatibility with RED’s score interpretation.\n* An ablation study on the sensitivity to hyperparameters is missing.  \n* Comparison to other acceleration strategies in PnP/RED is limited. For example Anderson acceleration (Hong et al., 2019) has been applied to RED and shows empirical speedups. Also,  FISTA-style momentum with adaptive restart (Alamo et al., 2019; Fercoq & Qu, 2019) could be a relevant baseline.\n\n--\n\n* References\nOlivier Fercoq and Zheng Qu. \"Adaptive restart of accelerated gradient methods under local quadratic growth condition\". IMA Journal of Numerical Analysis, 39(4):2069–2095, 2019."}, "questions": {"value": "While restart improves stability, the method introduces tunable hyperparameters (e.g., restart threshold B , inertia weight ε ). Although the authors claim robustness and provide some analysis in the appendix , more guidance or adaptive tuning strategies would make this work more practical."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zVR2Aje7av", "forum": "8pQsiFyTQi", "replyto": "8pQsiFyTQi", "signatures": ["ICLR.cc/2026/Conference/Submission9832/Reviewer_wKJo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9832/Reviewer_wKJo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9832/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918022078, "cdate": 1761918022078, "tmdate": 1762921312731, "mdate": 1762921312731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}