{"id": "YrX77XRgku", "number": 11868, "cdate": 1758204364788, "mdate": 1763738626225, "content": {"title": "Diffusion and Flow-based Copulas: Forgetting and Remembering Dependencies", "abstract": "Copulas are a fundamental tool for modelling multivariate dependencies in data, forming the method of choice in diverse fields and applications. However, the adoption of existing models for multimodal and high-dimensional dependencies is hindered by restrictive assumptions and poor scaling. In this work, we present methods for modelling copulas based on the principles of diffusions and flows. We design two processes that progressively forget inter-variable dependencies while leaving dimension-wise distributions unaffected, provably defining valid copulas at all times. We show how to obtain copula models by learning to remember the forgotten dependencies from each process, theoretically recovering the true copula at optimality. The first instantiation of our framework focuses on direct density estimation, while the second specialises in expedient sampling. Empirically, we demonstrate the superior performance of our proposed methods over state-of-the-art copula approaches in modelling complex and high-dimensional dependencies from scientific datasets and images. Our work enhances the representational power of copula models, empowering applications and paving the way for their adoption on larger scales and more challenging domains.", "tldr": "We model copulas based on the principles of diffusions and flows with marginal preserving processes.", "keywords": ["Copula estimation", "dependence modelling", "diffusion", "non-parametric copula"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2b7221c1c3325f7052bc327a5ce08e03bf80c092.pdf", "supplementary_material": "/attachment/dbf4d481535c9ddc8113b94aeff6bd900b5d1f45.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel framework for copula modeling using diffusion and flow-based methods, focusing on the processes of \"forgetting\" and \"remembering\" dependencies within data. The authors propose two new models: the classification-diffusion copula and the reflection copula. The CDC is designed as an effective density estimator by framing the problem as a classification task to estimate the ratio of copula densities at different stages of a diffusion process. The Reflection Copula is a generative model built on a flow architecture that enables efficient sampling. Theoretically, both models are shown to recover the true underlying copula at optimality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**S1**. The core idea of explicitly modeling the \"forgetting\" (diffusion to independence) and \"remembering\" (density estimation/generation) of dependencies provides a fresh and theoretically grounded perspective on copula modeling.\n\n**S2**. The introduction of the classification-diffusion copula (leveraging classification for density estimation) and the reflection copula (a dedicated flow for generation) are sound and well-motivated solutions.\n\n**S3**. The most significant strength is the demonstrated ability to achieve SOTA results on complex, high-dimensional data, including image datasets. The models clearly outperform classical (e.g., Vine) and other deep copulas, which struggle with scalability and complexity. The paper also provides thorough empirical validation across diverse datasets, using multiple metrics and visualizations to support its claims."}, "weaknesses": {"value": "**W1**. While the reflection copula samples quickly, the training times for both models, especially the CDC, are reported to be very long (e.g., up to 4 hours for CDC on CIFAR). This high computational cost could hinder practical application.\n\n**W2**. For image generation, the CDC samples are noted to be \"slightly noisier and grainier\" compared to the smoother samples from the reflection copula, indicating a potential trade-off between accurate density estimation and sample fidelity.\n\n**W3**. The paper could benefit from more detailed ablation studies to isolate the contribution of specific architectural choices or loss components to the overall performance."}, "questions": {"value": "No other issues; please refer to the Weaknesses section for specific points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CoojtwIrk8", "forum": "YrX77XRgku", "replyto": "YrX77XRgku", "signatures": ["ICLR.cc/2026/Conference/Submission11868/Reviewer_5pKF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11868/Reviewer_5pKF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761390513884, "cdate": 1761390513884, "tmdate": 1762922887134, "mdate": 1762922887134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Answer - Part 1"}, "comment": {"value": "Dear reviewers, \n\nWe are sincerely thankful for your time and effort in reviewing our paper. We are encouraged by your comments denoting our work as:\n\n-\t**A Significant contribution**:  \n“clearly outperform classical (e.g., Vine) and other deep copulas, which struggle with scalability and complexity” (5pKF),  \n“This was previously considered infeasible […] and represents a major leap forward for the field.” (if98),  \n“clarifies a long-standing issue of marginal inconsistency” (JPHs),  \n“scales reliably […] which has been somewhat of an elusive property of copulas.” (dHoi),\n-\t**Clear**  \n“Exposition and notation are clean” (JPHs),  \n“sound and well-motivated”(5pKF),  \n“clear, well-structured, and easy to read, which is commendable given the technical depth” (if98),\n\n-\t**Rigorous**  \n“fresh and theoretically grounded perspective on copula modeling” (5pKF),  \n“novel and technical” (JPHs),  \n“solid theoretical ground […]. This rigor adds significant credibility” (if98).  \n\nWe address each individual point under your comments and additionally summarize the main improvements thanks to your reviews below this message. We give a comprehensive evaluation of different components of our model, including **ablations on the loss mixture** in Apdx. B4, an **improved computational analysis** in Apdx. B1, an **ablation on schedulers** in Apdx. B under “Time discretization”, and **additional uniformity diagnostics** in Apdx. B5. Relevant parts of our replies have also been added to the main text in the updated pdf.\n\n---\n\n## Ablations on the loss mixture:\n\nIn Appendix B4 of the revised pdf, we provide an ablation to investigate the sensitivity of the $c_{dc}$ to the choice of $\\alpha$. We point to this ablation when introducing the loss in Section 3 as well as at the start of Section 6 of the main text.  \n\nWe perform a sweep over values $\\alpha=(0.0,0.01,0.25,0.5,0.75,1.0,5.0,20.0,500.0)$ for the experiments on all scientific datasets. We report the resulting LL values on a held-out validation set ($10\\%$ of the train set) in Fig. 9. **Our model is shown to be robust to all values of $\\alpha>0.01$, resulting in a stable performance**.  \n\nThis clarifies that incorporating the CE term is important to achieve optimal copulas, which echoes our theoretical analysis in Thm. 5 where $\\alpha>0$ is a necessary condition for optimality.\n\n---\n\n## Improved computational analysis:\nWe report computational times for all models across all experiments in Apdx. C1 Tab. 4, **showing that our sampling times are competitive with vine copulas while being much faster than the Ratio copula**.  \n\nWe now additionally present a dedicated computational time study in Apdx. C1 Fig. 6. From our computational study, we conclude that the network model is the most influential, followed by the number of timesteps used to simulate the SDE/ODE when sampling. We point to this in Section 6 of the main text.  \n\nIn more detail, for $d$ the data dimension , $w$ the network width and $h$ the number of hidden layers, $c_{dc}$ training has a complexity of $\\mathcal{O}(d\\cdot w + h\\cdot w^{2})$. This is because the model performs one forward pass (for class probabilities) and one backward pass (for scores) before taking gradients with respect to the loss during training. During inference, to sample the $c_{dc}$, we perform a forward and backward pass for each of the $k$ classes, following a SDE discretization scheme, resulting in a complexity of $\\mathcal{O}(k\\cdot(d\\cdot w + h\\cdot w^{2}))$. For the reflection copula, one training epoch consists of a single forward pass followed by a weight update, with complexity $\\mathcal{O}(d\\cdot w + h\\cdot w^{2})$. Generating samples requires $m$ network evaluations where $m$ is the number of steps to simulate the ODE for, which scales as $\\mathcal{O}(m\\cdot(d\\cdot w + h\\cdot w^{2}))$.\n\n---\n\n\n## Ablation on schedulers: \nTo justify our choice of scheduler, we now provide an ablation on this in Apdx. B under “Time discretization”. We mention it in the main text in Sec. 3.2. \n\nFor the Robocup experiment, we train our $c_{dc}$ model on $90$% of the train set and use the last $10$% for validation/testing. We report the LL for three different choices of schedulers, namely a linear optimal transport scheduler, a power-law scheduler and a KL scheduler. While the scheduler choice does not affect the LL of the train set, we show that **the KL scheduler is more stable and generalises better from the train to the test set**. This empirically demonstrates our result in Prop. 2 as the KL scheduler is informed by the convergence rate of our forward process."}}, "id": "l2PYx1YFCL", "forum": "YrX77XRgku", "replyto": "YrX77XRgku", "signatures": ["ICLR.cc/2026/Conference/Submission11868/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11868/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11868/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763730880112, "cdate": 1763730880112, "tmdate": 1763730880112, "mdate": 1763730880112, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a type of flow mapping that maps a copula to the independence copula, i.e. the authors define a mapping that forgets dependencies. The model borrows techniques inspired by diffusion models to define a mapping that forgets dependencies such that an appropriate independent copula can be reversed and transformed to new samples that map to the observed data. The authors propose two variants: one that provides likelihoods and another that only provides samples. The authors illustrate the method on a number of high dimensional datasets to showcase the extent to which the method can be applied."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The authors propose an interesting direction to enable high dimensional sapling from copulas, a difficult task that extends the applicability of copulas.\n\nThe method scales reliably to high dimensions which has been somewhat of an elusive property of copulas up to now."}, "weaknesses": {"value": "The architectures prescribed do not preserve the necessary components to ensure a valid copula is being recovered, which can make some of these tools a bit difficult to employ in practice (e.g. if one needs specific families of marginals to be used).\n\nThe authors also miss some relevant works on deep learning and scaling copulas which should be taken into account, especially since these consider high dimensional questions using the stochastic representations [1,2,3].\n\n[1] Inference and Sampling for Archimax Copulas, NeurIPS 2022\n\n[2] Generative Archimedean Copulas, UAI 2022\n\n[3] Copula Flows for Synthetic Data Generation, arxiv:2101.00598"}, "questions": {"value": "While the experiments on image data are quite interesting to showcase the capabilities of the copula, can the authors describe some additional sets of data that would more amenable to this method? Most image data would be well suited for diffusion models etc, but the interesting components of the copula are specifying possibly different parametric families for the marginals and it would be nice to describe that within the paper. \n\nWhat is the computational cost of this method? \n\nHow often are the conditions of the copula empirically violated in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9sTm0Hw4ml", "forum": "YrX77XRgku", "replyto": "YrX77XRgku", "signatures": ["ICLR.cc/2026/Conference/Submission11868/Reviewer_dHoi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11868/Reviewer_dHoi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884855132, "cdate": 1761884855132, "tmdate": 1762922886573, "mdate": 1762922886573, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework for modeling multivariate dependencies using copulas, leveraging principles from diffusion and flow-based models. The core idea is to design forward processes that progressively \"forget\" inter-variable dependencies while provably preserving the marginal distributions. The authors propose two such processes: one based on an Ornstein-Uhlenbeck process on a Gaussian-transformed space, and another based on a reflection process on the copula hypercube.\n\nBased on these forward processes, the paper develops two distinct copula models. The first, the \"classification-diffusion copula\" (cdc), is designed for accurate density estimation. It learns the copula density by framing the problem as classifying the \"time\" or level of dependence in the forward process. The second, the \"reflection copula,\" is a generative model optimized for efficient sampling by learning to reverse the reflection process. A key achievement of this work is demonstrating that these models can effectively capture complex, multi-modal dependencies and scale to very high dimensions (d > 1000), a significant advancement over existing copula methods. Empirical results on scientific datasets and images show good performance."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of modeling dependence by learning to reverse a dependence-forgetting process is both elegant and powerful. It provides a new perspective on generative modeling that explicitly disentangles marginal behavior from joint dependence.\n2. The paper is built on solid theoretical ground. The authors provide proofs for the validity of their forward processes and demonstrate that their proposed models can recover the true copula at optimality. This rigor adds significant credibility to the methods.\n3. The models achieve impressive results, outperforming existing copula methods on complex scientific datasets.\n4. The most significant strength is the demonstrated ability to scale copula models to thousands of dimensions, as shown with the image datasets. This was previously considered infeasible for flexible copula models and represents a major leap forward for the field.\n3. The paper is clear, well-structured, and easy to read, which is commendable given the technical depth of the topic."}, "weaknesses": {"value": "1. The loss function for the cdc model (Theorem 5) involves a hyperparameter α that balances the cross-entropy and score-matching terms. The paper states this is chosen to balance the magnitude of the terms, which is a common but heuristic approach. The paper would be stronger with a more detailed analysis of the sensitivity to this parameter or a more principled selection method.\n2. The paper correctly notes that the models are only guaranteed to be valid copulas (i.e., have uniform marginals) at optimality. While the appendix includes rank histograms as a diagnostic, a more quantitative analysis (e.g., using statistical tests for uniformity) of how close the generated samples are to being marginally uniform in practice would be beneficial.\n3. The FID score for the cdc model on the digits dataset is notably worse than other methods, including the simpler reflection copula. While the authors suggest the samples are \"noisier,\" a deeper explanation for this specific performance drop would be helpful. It raises questions about the robustness of the cdc approach on certain data types."}, "questions": {"value": "The reflection copula initializes velocities from an isotropic Gaussian distribution. Have you considered alternative or learnable initial velocity distributions? Could this provide a better inductive bias for certain types of dependencies and improve performance or training efficiency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jLo7z0b88X", "forum": "YrX77XRgku", "replyto": "YrX77XRgku", "signatures": ["ICLR.cc/2026/Conference/Submission11868/Reviewer_if98"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11868/Reviewer_if98"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986304308, "cdate": 1761986304308, "tmdate": 1762922886052, "mdate": 1762922886052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a principled framework that unifies copula theory with continuous-time generative modeling. It defines marginal-preserving forward processes (diffusions or flows) that progressively remove dependence while keeping all marginals uniform, so every intermediate distribution remains a valid copula. The core mechanism uses an Ornstein–Uhlenbeck diffusion in Gaussian space followed by the Gaussian CDF, which preserves uniform marginals and converges to the independence copula. Reverse dynamics are learned either as a score-based diffusion (likelihood) or a deterministic flow (fast sampling). Experiments report strong performance on high-dimensional data versus vine and neural-flow baselines. Conceptually, the work reframes dependence modeling as a diffusion/flow on the copula manifold, yielding a mathematically grounded and scalable approach to complex dependencies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: Defining stochastic/deterministic dynamics directly on the copula manifold (uniform marginals at all times) is novel and technically \n\nQuality: The marginal-preserving construction (OU + CDF map) is well-motivated and, as stated, supported by a formal proposition; the dual reverse instantiations (score vs. flow) are complementary and well engineered. Empirically, results indicate improved likelihoods and scalability where vines or generic neural copulas struggle.\n\nClarity: Exposition and notation are clean.\n\nSignificance: Establishes a geometric generative foundation for high-dimensional copulas and clarifies a long-standing issue of marginal inconsistency in prior deep copula models."}, "weaknesses": {"value": "In practice, sampling or training in copula space requires numerical integration on $[0,1]^d$ or its Gaussian transform.  The paper does not describe how boundaries $u_j \\in \\{0,1\\}$ are handled under discretization, nor how marginal uniformity is maintained when the OU process is approximated with finite steps.  Since the theoretical result assumes continuous time and ideal mapping, discretization could introduce marginal leakage.\n\nThe paper benchmarks primarily against classical vine and neural-flow baselines but omits newer methos such as [1].\nAlthough the paper claims linear scaling in dimension, no runtime, or memory/parameter analysis are presented compared to other methods and as the dimension increases (in addition to Table 4).\n\nThe weighting function governs how quickly dependence is forgotten. This choice may strongly influences the likelihood–sample-quality trade-off.  The paper fixes a single schedule without ablation, leaving unclear how robust the results are to this design.\n\n \nRefs:\n[1] Kamthe, Sanket, Samuel Assefa, and Marc Deisenroth. \"Copula flows for synthetic data generation.\" arXiv preprint arXiv:2101.00598 (2021)."}, "questions": {"value": "Your Proposition 2 shows marginal preservation for the OU + CDF forward process. Does this extend to other forward processes (e.g., non-OU or state-dependent drifts/β-schedules)? If not, is OU intended as the recommended path?\n\nYour results report overall log-likelihoods and FID-type metrics, but these conflate marginal and dependence contributions. Since the defining advantage of a copula-based model lies in capturing joint dependence given fixed marginals, how do you disentangle and assess the quality of dependence fit separately from the quality of marginal fit?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ckrcfonRlK", "forum": "YrX77XRgku", "replyto": "YrX77XRgku", "signatures": ["ICLR.cc/2026/Conference/Submission11868/Reviewer_JPHs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11868/Reviewer_JPHs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11868/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994244629, "cdate": 1761994244629, "tmdate": 1762922885570, "mdate": 1762922885570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}