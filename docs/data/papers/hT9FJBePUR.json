{"id": "hT9FJBePUR", "number": 14706, "cdate": 1758242145297, "mdate": 1759897353860, "content": {"title": "Bayesian Deep Equilibrium Models with Sequential Inference", "abstract": "Deep Equilibrium Models (DEQs) have drawn considerable attention due to their unique advantages. However, their uncertainty estimation, crucial for prediction-sensitive applications, remains unexplored. In this paper, we propose Bayesian Deep Equilibrium Models to address this gap for the first time. Our study highlights the substantial computational cost associated with uncertainty estimation in Bayesian DEQs. To mitigate this challenge, we introduce a novel sequential inference approach that captures the similarities in the parameters and reduces computational redundancy in the inference, offering a promising method to accelerate uncertainty quantification in DEQs. We also provide theoretical justification for the motivation behind our approach. Comprehensive experiments on MNIST, CIFAR-10, and ImageNet demonstrate that our method can speed up uncertainty estimation with Bayesian DEQs by up to 3 times without any sacrifice in performance.", "tldr": "", "keywords": ["Uncertainty; Bayesian Neural Network; Deep Equilibrium Models"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7aa4d050409a0aed898ed0186aa819a48f5e3052.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper extends **Deep Equilibrium Models (DEQs)** by incorporating Bayesian inference to estimate predictive uncertainty. DEQs solve a fixed‐point equation instead of using a finite sequence of layers, leading to memory efficiency and implicit depth. The authors argue that uncertainty estimation for DEQs is unexplored. They therefore construct Bayesian DEQs using Monte Carlo Markov Chain methods (Stochastic Gradient Langevin Dynamics, SGLD), SWAG and MC‐dropout. To tackle the high computational cost of repeated fixed‐point solves during ensembling, they introduce sequential inference, which has two components:\n\n1.\tSequential sampling: a scheme to draw parameter samples from the posterior in a sequence such that consecutive samples have small $\\ell_2$ distance. \n\n2.\tSequential computation: uses the previous sample’s fixed-point solution as the initialization for the next inference. They provide a theorem (Theorem 4.1) showing that if the DEQ mapping is smooth and consecutive parameter samples are sufficiently close, the resulting fixed points are also close. This motivates reusing the previous fixed point to accelerate convergence.\n\nThe paper evaluates the proposed scheme on multiple datasets and reports that sequential inference achieves comparable accuracy and uncertainty calibration with as few as one fixed‐point iteration, yielding up to a threefold reduction in inference time. The paper further includes ablation studies investigating distance between parameter samples and fixed‐point initialization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper tackles an important question of uncertainty estimation in DEQs. Given the increasing use of implicit models, exploring Bayesian approaches is timely.\n\n2.\tThe idea of reusing fixed‑point solutions across parameter samples is intuitively appealing and easy to implement. The theorem provides some insight into when this reuse may be valid.\n\n3.\tThe authors conduct experiments on multiple datasets and provide ablations showing that sequential inference improves error, negative log‐likelihood and calibration metrics as the number of fixed‐point evaluations increases."}, "weaknesses": {"value": "1.\t**Incremental novelty:** The core ideas are largely straightforward. Warm-starting iterative solvers using previous solution is a well-known technique, and applying MCMC/SWAG to a new model class (DEQs) is incremental. The “sequential sampling” is essentially treating SWAG sample generation as a Markov chain, which has been done in other contexts (and indeed SGLD already produces correlated samples by nature). The paper does not clearly distinguish its novelty from these known practices.\n\n2.\t**Theoretical analysis is shallow:** The theorem relies on strong smoothness and proximity assumptions that may not hold, and there is no analysis of the effect on the posterior or predictive distribution. Theorem 4.1 provides a bound but under strong conditions. The assumption that all samples lie in a small smooth region is not justified for a complex model. Moreover, the paper claims sequential sampling “preserves” the posterior, but this is only briefly mentioned with a W2 distance result in App. G. There is no analysis of the bias or variance introduced by correlating samples (i.e. we lose independent samples). It is unclear how sequential sampling affects the effective sample size.\n\n3.\t**Experimental scope is limited:** Only small‐scale DEQs are considered; evaluation on ImageNet uses a small MDEQ‐SMALL model. More challenging tasks such as language modeling or video understanding are absent. There is no comparison to strong calibration baselines (e.g., temperature scaling, deep ensembles, last‐layer Laplace).\n\n4.\t**Experimental rigor:** Results are presented without error bars or multiple runs, so we cannot assess statistical significance. It is unclear if the reported speedups and performance gains are consistent across random seeds. The single-example curves suggest big differences, but more rigorous evaluation (e.g. repeated trials) would strengthen the claims. \n\n5.\t**Clarity issues:** The description of sequential sampling and its relation to posterior sampling is vague. The algorithm pseudocode mixes indices and omits loop variables. Figures lack sufficient detail and sometimes repeat content from the text."}, "questions": {"value": "1.\t**Posterior representativeness:** How does sequential sampling (especially the correlated Langevin walk for SWAG) affect the true posterior approximation? Did you measure effective sample size or posterior uncertainty calibration relative to independent samples? Under what settings (e.g. step size τ) does sequential sampling remain valid?\n\n2.\t**Baselines:** Why were MC Dropout and deep ensembles not shown in the main results? For example, how does a standard DEQ ensemble (trained with different seeds) compare in accuracy and ECE to Bayesian DEQ? Similarly, how does sequential inference apply to a DEQ ensemble?\n3.\t**Laplacian methods:** In Related Work you state that Laplacian approximations are not suitable for DEQs (citing Section 5.3), but I could not find the explanation in the paper. Can you clarify why LA/LLA/LLLA would not work or would be inefficient for DEQs?\n4.\t**Solver details:** Which fixed-point solver (e.g. Broyden’s method or simple iteration) was used in each experiment? How does the choice of solver interact with your sequential inference? For example, does Broyden’s method benefit as much from warm-start as first-order solvers?\n5.\t**Statistical significance:** Were the plots (e.g. Figures 5–7) averaged over multiple runs? If not, can you provide error bars or standard deviations to show the consistency of the speedup?\n6.\t**Sequential sampling validity:** Can you provide a theoretical guarantee that the proposed Langevin‐based sequential sampling preserves the correct posterior distribution? How sensitive are the results to the Langevin step size τ (for SWAG sampling) and the number of burn-in/skip steps (for SGLD)? Table 9 hints at τ-dependence, but more discussion is needed on how one should choose these parameters.\n7.\t**Scalability:** Can you demonstrate the method on larger DEQ architectures (e.g., multi‐scale or vision transformer–based DEQs) and more challenging datasets? What is the overhead when the base DEQ is large?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "I did not identify explicit violations of the ICLR code of ethics."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vPKz3AnjOB", "forum": "hT9FJBePUR", "replyto": "hT9FJBePUR", "signatures": ["ICLR.cc/2026/Conference/Submission14706/Reviewer_fuzm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14706/Reviewer_fuzm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761778690575, "cdate": 1761778690575, "tmdate": 1762925070448, "mdate": 1762925070448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Bayesian Deep Equilibrium Models (Bayesian DEQs) that integrate Bayesian uncertainty estimation into implicit equilibrium networks. To address the high computational cost of Bayesian inference in DEQs, a Sequential Inference mechanism is also proposed to reuse information across posterior samples through sequential sampling and computation. Experiments on MNIST, CIFAR-10, and ImageNet show that this approach achieves up to 3× faster inference without sacrificing predictive accuracy or uncertainty quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem formulation is novel. The paper addresses an unexplored but important challenge of uncertainty estimation for DEQs, which has good practical values.\n\n2. The proposed Sequential Inference framework achieves notable computational acceleration for Bayesian DEQs without sacrificing performance.\n\n3. The paper provides theoretical justification through bounded equilibrium analysis and extensive empirical evaluations on multiple benchmarks, demonstrating its robustness and generalisation."}, "weaknesses": {"value": "1. There is a lack of quantitative evaluation on how sequential dependence affects the posterior fidelity, i.e., whether the sampled sequence still faithfully represents the true Bayesian posterior. Metrics such as effective sample size, autocorrelation, or divergence from standard MCMC samples are not reported, leaving it unclear whether the sequential samples still faithfully capture the underlying posterior distribution.\n\n2. The sequential computation step reuses previous fixed points for initialization. Although Theorem 4.1 offers a local boundedness guarantee under smoothness assumptions, there is no global or empirical analysis of whether this reuse affects convergence stability or the uniqueness of equilibrium solutions, particularly under large parameter perturbations."}, "questions": {"value": "In scenarios where the DEQ mapping admits multiple equilibria, how does reusing a previous fixed point influence which equilibrium the solver converges to?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f5zaD1qb01", "forum": "hT9FJBePUR", "replyto": "hT9FJBePUR", "signatures": ["ICLR.cc/2026/Conference/Submission14706/Reviewer_NEKE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14706/Reviewer_NEKE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826207043, "cdate": 1761826207043, "tmdate": 1762925069914, "mdate": 1762925069914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the high computational cost of performing Bayesian inference in Deep Equilibrium Models (DEQs), where each posterior sample requires solving an implicit fixed point. Authors propose Sequential Inference, which exploits the smooth evolution of parameters in methods like SGLD and SWAG to reuse the previous fixed point as initialization for the next DEQ solve. A short theoretical result shows that fixed points vary smoothly with small parameter changes, justifying the warm-start strategy. Experiments on MNIST, CIFAR-10, and ImageNet show up to 3× faster inference with similar calibration and accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed sequential inference idea is simple, effective, and can be integrated into existing SGLD or SWAG pipelines with minimal changes.\n\n- The theoretical result (Theorem 4.1) correctly formalizes the intuition that small parameter perturbations induce small changes in the DEQ fixed point. Although interesting, it's not too surprising.\n\n- Experimental evidence across a few datasets shows consistent speedups without degrading predictive uncertainty calibration."}, "weaknesses": {"value": "- The narrative is difficult to follow: definitions of DEQs and standard Bayesian methods are scattered through the methodology section rather than being grouped as background, making it hard to discern what is new. The paper would benefit from a dedicated background section clearly distinguishing DEQs from implicit layers and neural differential equations, as well as summarizing existing UQ methods.\n\n- The method essentially combines (i) correlated posterior sampling (which SGLD and SWAG already produce) with (ii) warm-starting the DEQ solver. This is more of a practical engineering optimization than a fundamentally new Bayesian principle.\n\n- Theorem 4.1 only provides a qualitative bound on the proximity of fixed points; it does not predict the actual reduction in the number of solver iterations. Although not necessarily a problem, it is worth noting.\n\n- The paper modifies the sampling process to make samples more correlated, but does not analyze how this affects posterior diversity or effective sample size. Authors could look into metrics like ESS or variance decomposition.\n\n- The method is demonstrated only for SGLD and SWAG on vision DEQs. No results are shown for other types of DEQs such as implicit GNNs or PDE solvers, despite the generality claims."}, "questions": {"value": "1. Could the authors clarify how much of the speedup arises from sample correlation versus solver warm-starting?\n2. How does the method behave when posterior samples are farther apart, or when the DEQ map has multiple fixed points?\n3. Are there failure cases where reusing a previous fixed point leads to convergence issues?\n4. Could sequential inference be applied to other implicit models such as Neural ODEs and what would be the limitations? I am still not 100% of the difference.\n5. What is the impact on posterior mixing and effective sample size when explicitly correlating SWAG samples using the Langevin noise update?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ySZ8PPnoq4", "forum": "hT9FJBePUR", "replyto": "hT9FJBePUR", "signatures": ["ICLR.cc/2026/Conference/Submission14706/Reviewer_Dajx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14706/Reviewer_Dajx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959996778, "cdate": 1761959996778, "tmdate": 1762925069199, "mdate": 1762925069199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Bayesian version of Deep Equilibrium Models (DEQs) based on the Stochastic Weight Averaging-Gaussian (SWAG) using two techniques: sequential sampling and sequential computation. Benchmark tests show 3 times speed up compared with standard SWAG algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "It is the first attempt to address the inference of DEQ. The proposed sequential procedure can capture the similarity of parameters and use it to reduce redundant computation."}, "weaknesses": {"value": "The presentation is not clear. It only clarifies that the similarity is NOT correlation in the Monte Carlo but does not define what it is. The notations are confusing and the implication of the main theorem is unclear. What is the advantage in terms of error rate if that is the same as SGD?"}, "questions": {"value": "1. What is the similarity of parameters? Do you refer to their distance being small? Please clarify.\n\n2. What is the difference between $z^*_i$ and $z^*$ in the statement of Theorem 4.1? What does the inequality imply? Can $\\delta$ here be arbitrarily small? If not, how does it demonstrate the closeness to the fixed-point solution?\n\n3. Figure 3 is so confusing. Please consider improve the explanation in the main text.\n\n4. The error rate of the proposed method is the same as SGD across different figures. Is it expected? What is the advantage in terms of this?\n\nMinor things:\n\nLine 061: spell out MDEQ when mentioning for the first time.\nLine 286: typo 'compatation'."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GT3SQBvpue", "forum": "hT9FJBePUR", "replyto": "hT9FJBePUR", "signatures": ["ICLR.cc/2026/Conference/Submission14706/Reviewer_CGof"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14706/Reviewer_CGof"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985386450, "cdate": 1761985386450, "tmdate": 1762925068638, "mdate": 1762925068638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}