{"id": "xBW2FIfswU", "number": 13128, "cdate": 1758213867869, "mdate": 1759897462449, "content": {"title": "CauKer: Classification Time Series Foundation Models Can Be Pretrained on Synthetic Data", "abstract": "Time series foundation models (TSFMs) have recently gained significant attention due to their strong zero-shot capabilities and widespread real-world applications. Such models typically require a computationally costly pretraining on large-scale, carefully curated collections of real-world sequences. To allow for a sample-efficient pretraining of TSFMs, we propose CauKer, a novel algorithm designed to generate diverse, causally coherent synthetic time series with realistic trends, seasonality, and nonlinear interactions. CauKer combines Gaussian Process (GP) kernel composition with Structural Causal Models (SCM) to produce data for sample-efficient pretraining of state-of-the-art classification TSFMs having different architectures and following different pretraining approaches. Additionally, our experiments reveal that CauKer-generated datasets exhibit clear scaling laws for both dataset size (10K to 10M samples) and model capacity (1M to 783M parameters), unlike real-world datasets, which display irregular scaling behavior.", "tldr": "", "keywords": ["Time Series Foundation Model", "Time Series Classification"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dc26d785f9a54f568b74502c39980cfb7f4cfaa0.pdf", "supplementary_material": "/attachment/ab24ebf4ff55f33bbb7de5dfaa73620d6c9e90e8.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose CAUKER, a synthetic data generation algorithm that leverages Gaussian Process kernel composition and Structural Causal Models to produce diverse time series for augmenting training data in time series classification tasks. The paper evaluates the proposed approach against other synthetic data generation techniques for several time series foundation models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces a novel synthetic data generation technique leveraging structural causal models (SCMs) for time series.\n- The work is a focused study on synthetic data augmentation for time series classification, an understudied area in time series literature.\n- Two time series foundation models (TSFMs) are evaluated with supervised and contrastive learning pre-training schemes\n- Several synthetic data augmentation approaches are systematically compared in Table 1, highlighting relative effectiveness.\n- Figure 3 effectively illustrates scaling laws and the relationship between model size and performance.\n- Figure 4 provides an interesting analysis showing the diversity of principal components in synthetic data relative to non-synthetic datasets.\n- The study demonstrates that fewer synthetic samples can achieve comparable performance to real-world pre-training datasets, highlighting practical efficiency benefits."}, "weaknesses": {"value": "I would be happy to increase my score if the following concerns/points are addressed.\n\n- Zero-shot evaluation methodology: The study claims to evaluate TSFMs in a zero-shot setting, but the models are allowed to be pre-trained on the training set of the same dataset used for evaluation. This means the evaluation is not strictly zero-shot, as the train and test sets are likely in-distribution (Lines 122–124): “In practice, if we evaluate a given TSFM on a test set from a UCR (Dau et al., 2019) dataset, we ensure that the TSFM was not pre-trained on it, but we allow for the train set of this same dataset to be used for pre-training.” \n\n- Missing baseline comparisons: Results without synthetic data augmentation are not reported in Table 1. Including these and quantifying the lift from augmentation would be helpful.\n\n- No text-based or experimental comparison with the synthetic data generation process used by TabPFN, which also leverages structural causal models.\n\n- No comparison with non-foundation model baselines (e.g., random forecasts, XGBoost, logistic regression).\n\n- Clarification on model pre-training: It is unclear whether the models are pre-trained from scratch on synthetic data or fine-tuned with synthetic data (using pre-trained models on real-world data). For example, the text states: “In practice, if we evaluate a given TSFM on a test set from a UCR (Dau et al., 2019) dataset, we ensure that the TSFM was not pre-trained on it, but we allow for the train set of this same dataset to be used for pre-training.”"}, "questions": {"value": "1. Are the TSFMs pre-trained from scratch on synthetic data, or are they fine-tuned on synthetic data (using models already pre-training on real data)?\n2. How do the models perform without any synthetic data augmentation?\n\nSuggestion: It would be interesting to include the combined scaling laws for the UEA and Cauker datasets on the same plot in Figure 3 to show cross-dataset scaling laws."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nBGyATldPJ", "forum": "xBW2FIfswU", "replyto": "xBW2FIfswU", "signatures": ["ICLR.cc/2026/Conference/Submission13128/Reviewer_zLKs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13128/Reviewer_zLKs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13128/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760753114569, "cdate": 1760753114569, "tmdate": 1762923851143, "mdate": 1762923851143, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CAUKER, a novel and sophisticated pipeline for generating synthetic time series data specifically tailored for the pre-training of classification-oriented Time Series Foundation Models (TSFMs). The core idea is to combine two methodologies: Gaussian Process (GP) kernel composition, which generates realistic temporal patterns (trends, seasonality), and Structural Causal Models (SCMs), which impose a causal graph structure to create complex, non-linear interactions and meaningful clusters. The authors conduct extensive experiments showing that TSFMs pre-trained on CAUKER data not only outperform models trained on other synthetic datasets but also nearly match the performance of models pre-trained on real-world corpora that are over an order of magnitude larger. A key finding is that CAUKER-generated data enables smooth and predictable scaling laws with respect to both dataset and model size, a property the authors show is absent when pre-training on standard real-world benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "*   **Novelty and Formulation:** The primary strength of this work is its well-motivated. Rather than creating a monolithic generator, the authors identify two key requirements for classification data—realistic temporal dynamics and discriminative clustering structure—and solve them by combining the strengths of two distinct fields. Using GP kernel composition (common in forecasting) for temporal patterns and SCMs (from the causality and tabular learning literature) for creating underlying class structures is a novel and highly effective synthesis. The design choices are clearly justified (Section 3.2), and the ablation-style comparison in Table 1 convincingly demonstrates that both components are necessary for optimal performance.\n\n*   **Empirical Evidence of Scaling Laws:** The paper's most impactful result is the clear demonstration of scaling laws (Figure 3). The experiments showing that accuracy on downstream tasks increases smoothly and monotonically with more synthetic data and larger models are a significant contribution. By contrasting this with the erratic and non-scaling behavior of models trained on the real-world UEA benchmark, the authors make a powerful case for using high-quality synthetic data as a controlled \"wind tunnel\" to study and develop scalable TSFMs. This provides a valuable methodology for the community, independent of the CAUKER pipeline itself.\n\n*   **Sample Efficiency and SoTA Performance:** The paper provides strong evidence that \"quality over quantity\" is important for pre-training data. The results in Figure 7 are particularly striking, showing that pre-training a model like Mantis on just 100K synthetic samples can achieve performance nearly identical to pre-training on its original 1.89M real-world sample corpus. This has significant practical implications, as it dramatically reduces the need for expensive and difficult data collection and curation. The fact that this performance is state-of-the-art for synthetic-data pre-training validates the effectiveness of the proposed approach.\n\n*   **Experimemntal Validation:** The paper is written with outstanding clarity. The experimental validation is extensive and robust, covering comparisons to multiple baselines, scaling laws, qualitative analyses (PCA, CKA, non-linearity in Figures 4 and 5), and transferability to different benchmarks (UCR, WOODS) and even a different task (forecasting). The appendices are helpful, providing, detailed descriptions of the function banks, hyperparameter sensitivity analysis."}, "weaknesses": {"value": "I have concerns about the evaluation process and specially related to the complexity of the proposed generator, the framing of its comparison to real-world data, and the scope of the architectural evaluation.\n\n1.  **High Generator Complexity and Opaque Design Choices:** The CAUKER pipeline is a complex amalgamation of multiple components: three distinct function banks (kernel, mean, activation), random kernel composition, and random DAG generation. This introduces a large number of \"meta-hyperparameters\" (e.g., the specific contents and size of the banks, the distribution of DAG parameters). While the appendix provides a sensitivity analysis for a few of these, the process for designing the function banks themselves is not fully justified. It is unclear if the chosen set of 36 kernels or the specific activation functions are uniquely effective, or if a much simpler subset could achieve comparable results. This complexity could pose a significant barrier to adoption and reproducibility for researchers who do not have the authors' expertise in this specific setup.\n\n2.  **Potential for a \"Straw Man\" Argument Against Real Data:** The paper's narrative strongly contrasts the clean scaling of CAUKER with the poor scaling of the UEA benchmark. While this is a powerful rhetorical device, it risks overgeneralizing the conclusion. The UEA archive, while a standard benchmark, is a heterogeneous collection of many small, domain-specific academic datasets; it was not designed as a large-scale, cohesive pre-training corpus in the vein of ImageNet or The Pile. The observed lack of scaling could be an indictment of the UEA dataset's specific properties (lack of diversity, domain mismatch) rather than a fundamental flaw of pre-training on real-world data in general. The paper lacks a discussion of this nuance.\n\n3.  **Limited Diversity of Tested Model Architectures:** The experiments are exclusively focused on two Transformer-based models (Mantis, which is ViT-based, and MOMENT, which is T5-based). While these represent different pre-training objectives (contrastive vs. masked reconstruction), they share a core architectural paradigm. It is an open question whether the benefits of CAUKER's data structure are universally applicable or if they are particularly well-suited to the inductive biases of attention-based models. The rich, causally-linked structures might be more effectively captured by attention than by models with different biases, such as CNNs or State Space Models."}, "questions": {"value": "Based on these weaknesses, here my questions to the authors:\n\n*   **Question 1:** The CAUKER pipeline is composed of several stochastic modules and expertly curated function banks. How were the specific contents of these banks (e.g., the 36 kernels, the set of mean/activation functions) selected and validated? Is the performance highly sensitive to these specific choices, or is the framework robust to using a simpler, more generic set of components?\n\n*   **Question 2:** The hyperparameter sensitivity analysis in Appendix C.3 is helpful. However, to better understand the generator's failure modes, have you investigated scenarios where deliberately poor choices (e.g., using only linear activations, forcing very shallow DAGs, or using only a single kernel type) cause the method to fail or degrade to the level of the simpler baselines in Table 1?\n\n*   **Question 3:** To what extent do you believe the poor scaling on the UEA benchmark is a fundamental property of real-world time series data, versus a specific artifact of the UEA collection's composition and scale? How might CAUKER compare against a hypothetical, massive, and diverse real-world corpus curated specifically for pre-training (e.g., a \"TimeNet\")?\n\n*   **Question 4:** The study convincingly demonstrates CAUKER's benefits for Transformer-based TSFMs. How do you hypothesize the generated data would interact with models possessing fundamentally different inductive biases, such as those based on CNNs (e.g., InceptionTime) or State Space Models (e.g., Mamba), which process information more locally or linearly?\n\n*   **Question 5:** The causal graph propagation step seems central to creating discriminative structure. Does this structural property particularly favor the global receptive field of attention mechanisms? A deeper analysis of which components of CAUKER (GP vs. SCM) are most beneficial for which type of model architecture would be a valuable contribution.\n\n*   **Question 6:** The paper successfully extends CAUKER to forecasting. Does this suggest that good classification data is a superset of good forecasting data, or were any modifications to the CAUKER pipeline necessary to achieve strong forecasting performance? Specifically, are the SCM-induced non-linearities as important for forecasting as they are for classification?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "E5fG5RczLS", "forum": "xBW2FIfswU", "replyto": "xBW2FIfswU", "signatures": ["ICLR.cc/2026/Conference/Submission13128/Reviewer_Mojr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13128/Reviewer_Mojr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13128/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761388473532, "cdate": 1761388473532, "tmdate": 1762923850684, "mdate": 1762923850684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript presents CAUKER, a synthetic data generation pipeline for pretraining classification time-series foundation models. CAUKER composes Gaussian-process kernels and mean functions within a structural causal model (SCM) graph, producing causally coherent sequences for self-supervised pretraining of contrastive (Mantis) and masked-reconstruction (MOMENT) encoders. Empirically, models pretrained solely on CAUKER data achieve competitive zero-shot accuracy on UCR and exhibit monotonic scaling with both dataset size and model capacity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Integrating kernel composition with SCM-based propagation yields diverse dynamics and inter-series dependencies aligned with classification objectives.\n2. Evaluation across contrastive and masked-reconstruction pretraining objectives increases the generality and external validity of the findings.\n3. Experiments demonstrate data/model scaling laws and strong zero-shot transfer, offering a compelling empirical performance."}, "weaknesses": {"value": "1. Pretraining on pure synthetic data and obtaining strong results is not particularly surprising, as prior work (e.g., TabPFN-TS) has already demonstrated the potential of synthetic data. This manuscript would benefit from sharper positioning of what is substantively novel in methodology part. \n2. This paper does not clearly articulate the challenges in transferring synthetic data generation methods designed for forecasting tasks to classification tasks—what the specific difficulties are and how they are addressed. The introduction reads largely as an integration of existing generators applied to classification, with empirical observations such as scaling laws, but as a research contribution this positioning feels insufficient.\n3. The evaluation scope remains narrow (largely UCR-style, often univariate and fixed-length), with limited robustness analysis on generator hyperparameters and little evidence for multivariate, irregularly sampled settings."}, "questions": {"value": "1. What are the concrete, theoretically grounded challenges when porting forecasting-oriented synthetic pipelines to classification (label generation, class balance, inter-class separability, invariance desiderata), and how does each CAUKER design choice mitigate them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pN6JZqUcFn", "forum": "xBW2FIfswU", "replyto": "xBW2FIfswU", "signatures": ["ICLR.cc/2026/Conference/Submission13128/Reviewer_uHPf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13128/Reviewer_uHPf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13128/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761708721056, "cdate": 1761708721056, "tmdate": 1762923850407, "mdate": 1762923850407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CAUKER, a synthetic data generation framework combining Gaussian Process kernel composition and SCM for time series foundation models for classification tasks. Unlike most prior work focusing on forecasting, CAUKER targets classification and demonstrates that synthetic pretraining can yield competitive or superior performance to real world datasets. It also reveals scaling laws for synthetic pretraining in terms of dataset and model size."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* Addresses a clear gap, synthetic pretraining for classification TSFMs.\n* The causal kernel composition is conceptually elegant and well motivated.\n* Benchmarks across multiple models and datasets .\n* Includes scaling law analyses for data, model, and compute.\n* Outperforms real-data pretraining in several zero-shot setups.\n* The method is explained clearly, with schematic diagrams and pseudocode."}, "weaknesses": {"value": "* Both GP based and SCM based data generation already exist, the novelty lies mostly in combining them.\n* Evaluation confined to zero-shot classification. would benefit from downstream fine-tuning or transfer learning results.\n* The contribution of causal graph depth/branching remains unclear.\n* While interesting, the scaling analysis is somewhat descriptive without deeper theoretical grounding"}, "questions": {"value": "* How does CAUKER handle multivariate dependencies beyond univariate channel concatenation?\n\n* Can CAUKER generalize to forecasting or imputation pretraining tasks?\n\n* How computationally expensive is CAUKER compared to kernel only methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Vwi5qXQTFe", "forum": "xBW2FIfswU", "replyto": "xBW2FIfswU", "signatures": ["ICLR.cc/2026/Conference/Submission13128/Reviewer_Ztoq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13128/Reviewer_Ztoq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13128/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945355970, "cdate": 1761945355970, "tmdate": 1762923850050, "mdate": 1762923850050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}