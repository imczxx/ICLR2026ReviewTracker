{"id": "sNk22RlNmy", "number": 4044, "cdate": 1757591232362, "mdate": 1763672952877, "content": {"title": "DoubleGen: Debiased Generative Modeling of Counterfactuals", "abstract": "Generative models for counterfactual outcomes face two key sources of bias. Confounding bias arises when approaches fail to account for systematic differences between those who receive the intervention and those who do not. Misspecification bias arises when methods attempt to address confounding through estimation of an auxiliary model, but specify it incorrectly. We introduce DoubleGen, a doubly robust framework that modifies generative modeling training objectives to mitigate these biases. The new objectives rely on two auxiliaries---a propensity and outcome model---and successfully address confounding bias even if only one of them is correct. We provide finite-sample guarantees for this robustness property. We further establish conditions under which DoubleGen achieves oracle optimality---matching the convergence rates standard approaches would enjoy if interventional data were available---and minimax rate optimality. We illustrate DoubleGen with three examples: diffusion models, flow matching, and autoregressive language models.", "tldr": "DoubleGen is a doubly robust approach that modifies the losses of standard generating modeling frameworks (diffusion models, autoregressive language models, etc.) to produce counterfactual data.", "keywords": ["generative modeling", "counterfactual", "doubly robust", "debiased machine learning"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5ef8b2d6d7cf2b143421cf2b69170a8649766622.pdf", "supplementary_material": "/attachment/e69ae895c9b5dafcffd9abfdf6e63f12ee121b87.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a new counterfactual generation framework that ensures doubly-robustness. Theoretical properties of the robustness and optimality of the estimates were derived. Empirical experiments on the framework were presented and analyzed."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is the first to propose a generative counterfactual framework that is doubly robust. Previous works typically only focus on at most one aspect.\n\nThe framework is completely general-purpose and can be used with any generative models, making it highly flexible to deploy in different practical tasks.\n\nThe theories derived in the paper, including finite-sample PAC bounds and minimax rates, are technically highly nontrivial. The proof techniques are valuable for existing statistical learning and semiparametric theory literature.\n\nThe theories provide a clear interpretation of the role of \"doubly robustness\" in the framework."}, "weaknesses": {"value": "Framework novelty: the proposed framework (Algorithm 1 and Algorithm 2) seems to take the form of a common framework for doubly-robust estimation. The novelty of the framework is unclear.\n\nAssumptions: the theories hinge on a series of assumptions (C3-C8), involving bounded losses, curvature constants, entropy integrals, and Lipschitz properties of transport maps. These assumptions seem to be stylized, and their practical verifiability remains unknown.\n\nBaselines: the baselines used in the experiments are naive (plug-in, IPW), and no state-of-the-art baselines were used for comparison."}, "questions": {"value": "Framework novelty: how is the algorithm novel compared to existing doubly robust frameworks?\n\nAssumptions: could the authors justify the reasonability and verifiability of the assumptions that were used in the paper?\n\nBaselines: I suggest that the authors should do an ablation study by comparing different types of generative models other than the diffusion model used in DoubleGen."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MCOkqT9ICS", "forum": "sNk22RlNmy", "replyto": "sNk22RlNmy", "signatures": ["ICLR.cc/2026/Conference/Submission4044/Reviewer_RQds"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4044/Reviewer_RQds"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760475473810, "cdate": 1760475473810, "tmdate": 1762917149498, "mdate": 1762917149498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a counterfactual generation framework/loss called DoubleGen with doubly robustness properties. That is, the framework can properly estimate the counterfactual risk if either the inverse propensity or the conditional transport map is estimated consistently. The authors then give some examples of adapting DoubleGen to different types of generative models, such as diffusion and autoregressive models. They then provide a theoretical analysis that shows that the resulting generalization error between the estimated and true risk is small with high probability. Finally, the authors conduct numerical experiments on two datasets, demonstrating that DoubleGen has more robust performance under misspecification settings."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "•\tThe proposed framework can be generalized to a number of generative models with different architectures, highlighting its flexibility and potential applicability across diverse domains.\n\n•\tThe authors provide rigorous proofs to validate the generalization and minimax lower bounds for the counterfactual generation problem.\n\n•\tThe conditions/assumptions used in Section 5.2 mostly make sense and allow for nonparametric nuisance estimation while still providing finite-sample guarantees.\n\n•\tThe celebA example serves as an intuitive and straightforward illustration for confounding bias."}, "weaknesses": {"value": "•\tThe notation/symbols in the introduction section needs more clarification to improve readability. For instance, if $P$ represents the factual distribution, then it would be better to use $P^*$ rather than $\\mathbb{P}$ to represent the counterfactual distribution.\n\n•\tSimilarly, the symbols should be better clarified in Sections 4 and 5. For example, it should be noted that $Law(Y)$ means “the distribution of $Y$”. Also, it is recommended to use consistent fonts for variables (e.g., $X$, $Y$, $A$), distributions (e.g., $\\mathbb{P}$), and spaces (e.g., $\\mathcal{Y}$, $\\mathcal{U}$)."}, "questions": {"value": "Is it possible to extend the framework to situations where there exist unmeasured confounding and/or interference (i.e., the treatment on one unit can affect the outcome of another)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ocDJhlr8UG", "forum": "sNk22RlNmy", "replyto": "sNk22RlNmy", "signatures": ["ICLR.cc/2026/Conference/Submission4044/Reviewer_AaJB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4044/Reviewer_AaJB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761442353339, "cdate": 1761442353339, "tmdate": 1762917149314, "mdate": 1762917149314, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revised paper uploaded"}, "comment": {"value": "We thank the reviewers for their helpful comments and suggestions on our paper. We have uploaded a revised version of our paper. Edits are indicated by a grey bar in the right column (e.g., lines 144-146). Of course, we would remove these in the camera-ready version.\n\nWe will reply to each reviewer individually below."}}, "id": "rS1IFPAZlT", "forum": "sNk22RlNmy", "replyto": "sNk22RlNmy", "signatures": ["ICLR.cc/2026/Conference/Submission4044/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4044/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4044/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763651177482, "cdate": 1763651177482, "tmdate": 1763651177482, "mdate": 1763651177482, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper address the problem of training generative models of counterfactuals using observational data, in which the intervention is not assigned randomly, but rather depends on some underlying attributes of the population. The authors define a general class of generative models (OracleGen) and then propose how the loss function for these models can be adjusted to allow for doubly robust generation using samples from a confounded distribution. The authors provide some results about the theoretical guarantees of their proposed approach, although verifying whether these are correct is beyond my expertise. The authors then showcase some empirical results showing that their approach works better than naive approaches and IPW.\n\nThe theoretical results presented in this paper falls outside of my area of expertise, hence in what follows I will focus my comments only on the proposed setup and experimental evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The most important contributions of this paper seem to lie in the theoretical guarantees it derives for the consider counterfactual generation setting. However, I do not feel qualified to evaluate whether these results are correct and/or novel."}, "weaknesses": {"value": "- The experimental results in Table 3 are presented for a single dataset in each modality only. Further, the results seem to be run over a single seed only, making it difficult to establish any notion of statistical significance of the presented results.\n- For section 6.1, from the description of the performance metrics in the appendix (l. 2089) it seems to me that the test set was obtained from the confounded dataset in a way very analogous to the way that the outcome model was constructed (using doubly robust generation, under the same models). If this is the case, one could expect some notion of \"congeniality bias\" in the results (there results are good because the model was fitted using the same principles and assumptions used to construct the test set). Have the authors considered other methods for constructing the test set?\n- For the experiments in section 6.2, I am not sure to what extent PPL is a good evaluation metric in this context, as it seems to measure how \"confident\" the LLM was in its own prediction (unless an external LLM was used to evaluate the quality of the generations, which is not stated in the paper). That does not seem to account for whether the generated samples match the counterfactual distribution or not.\n- It would be great if the descriptions of the evaluation metrics used in the paper were a bit more self-contained."}, "questions": {"value": "Some things which were not clear to me when reading the paper include:\n- What is the space of the interventions $A$? Are the authors only considering binary interventions $A \\in \\{0, 1\\}$? In line 144, why do we consider $A=1$?\n- In Algorithm 2, why is the empirical risk computed over two disjoint sets $\\mathcal{Z}_n^1$ and $\\mathcal{Z}_n^2$? In a standard doubly-robust estimators we usually want to estimate the propensity score function and the outcome model using disjoint subsets of the data, however it does not seem to me from the formulation of $R_n(\\theta)$ which of $\\mathcal{Z}_n^j$ is used for estimating the propensity and which is used for estimating the outcome model. Also, why do we need two outcome models $\\psi_n^1$ and $\\psi_n^2$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "fmmaMJ3zbm", "forum": "sNk22RlNmy", "replyto": "sNk22RlNmy", "signatures": ["ICLR.cc/2026/Conference/Submission4044/Reviewer_bHio"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4044/Reviewer_bHio"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937266169, "cdate": 1761937266169, "tmdate": 1762917149069, "mdate": 1762917149069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies confounding and misspecification in generative models that aim to sample from counterfactual distributions. The authors propose DoubleGen, a doubly robust training framework that learns to generate counterfactual outcomes from observational data with confounding. The paper provides theoretical support and demonstrates the method on diffusion models and language models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1.The paper proposes a doubly robust training framework for counterfactual generation called DoubleGen and claims that the generator remains consistent as long as either the propensity model or the outcome model is correct, without requiring both to be correct.\n\n2.The paper provides theoretical support, including a finite sample generalization bound for the DoubleGen risk, a guarantee that links excess risk to closeness to the target interventional distribution, and a result that in the diffusion setting the method achieves a near minimax optimal rate.\n\n3.The paper motivates the task using clear counterfactual scenarios such as what would each person look like if everyone smiled and frames this as causal counterfactual generation rather than ordinary attribute editing or style transfer."}, "weaknesses": {"value": "1. In the CelebA experiment, the paper highlights specific confounding attributes such as lipstick, female, and no beard, and argues that naive generation entangles these attributes with smiling. However, the quantitative evaluation later focuses on global realism and diversity metrics such as FAD, KID, precision, and recall. The paper does not report whether the attribute distributions themselves were corrected toward the intended counterfactual target, so it is unclear if the method actually removes the identified confounding.\n\n\n2. The theoretical results rely on a large set of conditions (C1-C20), which are distributed across the main paper and the appendix. The paper does not sufficiently discuss the practical meaning of these assumptions or how a practitioner could verify them. For example, the localized bound depends on condition C15, which assumes that at least one of the nuisance models is not estimated poorly."}, "questions": {"value": "Q1. The theory shows bounds in terms of the error of the estimated propensity model and the distance between the estimated outcome model and the oracle outcome model, but in experiments you only present two regimes described as well specified and misspecified. Could the authors quantify nuisance quality more explicitly, for example by reporting calibration error, KL divergence, mean squared error, conditional log-likelihood, FID, or perplexity for each nuisance model?\n\nQ2. The method assumes positivity, namely that every covariate profile has some non-zero chance to receive the intervention of interest. CelebA is relatively balanced for many attributes and the text experiment is semi-controlled, so violations of this assumption may be limited in the reported settings. Could the authors investigate what happens when the treatment probability is near zero for some subpopulation? \n\nQ3. Algorithm 2 involves first fitting the nuisance models, then performing a cross-fit style data split, and then sampling minibatches together with latent noise in order to obtain unbiased gradient estimates of the proposed objective. This appears more expensive than training a single diffusion model or a single language model with a standard loss. Could the authors quantify the additional wall-clock time and GPU memory required by DoubleGen compared to naive finetuning and compared to an IPW-only baseline? Could the authors clarify whether the dominant cost comes from training the nuisance models or from optimizing the DoubleGen objective itself? For the language modeling setup with LoRA finetuning, could the authors report the approximate GPU-hours? \n\nQ4. Table 1 highlights explicit confounding attributes such as lipstick, makeup, and female. However, Table 3 reports global distribution-quality metrics such as FAD and KID rather than directly measuring whether those specific confounding attributes were corrected in the generated counterfactual samples. Could the authors provide a more direct evaluation by reporting, for Naive, IPW, Plug-in, and DoubleGen, the marginal frequencies of the attributes listed in Table 1 within the generated samples, and comparing those frequencies to the target counterfactual distribution estimated via reweighting on the test set?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bTi2LaTNZH", "forum": "sNk22RlNmy", "replyto": "sNk22RlNmy", "signatures": ["ICLR.cc/2026/Conference/Submission4044/Reviewer_YFqG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4044/Reviewer_YFqG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762035327085, "cdate": 1762035327085, "tmdate": 1762917148246, "mdate": 1762917148246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}