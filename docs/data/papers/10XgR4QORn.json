{"id": "10XgR4QORn", "number": 4171, "cdate": 1757621058488, "mdate": 1759898049202, "content": {"title": "Analyzing and Internalizing Complex Policy Documents for LLM Agents", "abstract": "Large Language Model (LLM) based agentic systems rely heavily on in-context policy documents that encode diverse business rules. As business requirements expand, these documents grow substantially, creating significant computational overhead. This motivates the need for internalization methods that embed policy documents into model priors while preserving performance. While prior prompt compression research primarily targets generic prompts, we find that agentic policy documents span multiple levels of complexity and demand more intensive reasoning, presenting greater internalization challenges. We first introduce CC-Gen, an agentic benchmark generator with Controllable Complexity defined across four levels,  enabling systematic benchmarking of how well agents handle complexities and provides a framework for comprehensive evaluation of policy internalization algorithms. Our initial analysis reveals that complex policy specifications governing agent workflows may pose the most significant reasoning challenges. When supporting internalization with gold user–agent interaction trajectories containing chain-of-thought (CoT) annotations through supervised fine-tuning (SFT), we find that this baseline is highly data-intensive and its effectiveness deteriorates markedly as policy document complexity increases. To mitigate data burden and reasoning challenges, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline analyzes policy documents to extract key specifications, grouping them into factual, behavioral, and conditional types. We further isolate complex conditions, which introduce high workflow complexity and drive core reasoning difficulty. This categorization guides a targeted therapy, synthesizing specialized training data for each specification type and enabling agents to internalize policy information more effectively through an autoregressive pretraining loss. Our extensive experiments demonstrate the effectiveness of the curated data and training objective. Combined with SFT, our approach improves baseline across all data scenarios. It is especially effective in data-sparse settings and under high policy complexity, yielding gains of up to 41\\% and 22\\% on Qwen-3-32B. Overall, we achieve up to 97.3\\% prompt length reduction in our benchmark. Applied to $\\tau$-Bench, our approach further improves performance and reduces input length with very limited SFT data.", "tldr": "Internalize Complex Policy Documents for LLM Agents", "keywords": ["Policy Interalization", "LLM Agents"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/147422278410794efd0714143a9e504a212c1898.pdf", "supplementary_material": "/attachment/b92a40542a47634d0ca685d75c1e297d27261840.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies the problem of internalizing long, complex policy documents into the priors of LLM-based agent systems so that agents can operate without having to include the full policy text in-context. The authors (1) introduce CC-Gen, a synthetic benchmark generator that produces policy documents, databases, tools, and user queries with controllable complexity along four axes (environment, task, workflow, query); (2) analyze which complexity dimensions most harm agent performance and identify workflow (nested conditional) complexity as the most damaging; (3) propose Category-Aware Policy Continued Pretraining (CAP-CPT): an automated pipeline that (via an LLM) parses policies into factual, behavioral, simple-conditional and complex-conditional specs, then synthesizes targeted CPT data (paraphrases, QAs, scenario simulations, behavior demos) and performs autoregressive continued pretraining with policy identifiers; and (4) combine CAP-CPT with SFT on gold (or self-generated) CoT trajectories. Experiments on Qwen variants and τ-Bench (and many ablations) show CAP-CPT yields consistent gains over SFT-only internalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Internalizing policy documents for deployed agents is a timely, high-impact problem: reducing prompt length, inference cost, and reliance on long in-context policies matters for real-world systems and safety/regulatory compliance.\n2. CC-Gen with controllable dimensions (especially workflow depth) enables systematic, reproducible study of what makes policy internalization hard. The diagnosis that workflow/nested conditional logic is the primary driver of failure is a useful insight for the community."}, "weaknesses": {"value": "1. CC-Gen is synthetic and the policy-analysis step is performed by the same (or similar) LLMs used downstream; this raises concerns about circularity and generalization to messy, real-world policy texts that may be longer, less templated, or ambiguous. Results on τ-Bench are encouraging but limited.\n2. The paper compares mainly to Gold-CoT SFT baselines. It would strengthen the claims to compare against strong alternatives that are natural for this problem"}, "questions": {"value": "1. Can you compare CAP-CPT to retrieval-based baselines (keeping policies external but retrieved at inference) and to parameter-efficient finetuning (LoRA/adapters) that may reduce forgetting?\n2. How does CAP-CPT scale when many distinct policies must be internalized simultaneously or when policies frequently change? Can you report experiments (or an analysis) showing performance/memory/computation trade-offs when internalizing tens or hundreds of policies? Do you observe interference or catastrophic forgetting across policies, and what mitigation (e.g., adapters, regularization, replay) do you recommend?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iJe8i7MCWa", "forum": "10XgR4QORn", "replyto": "10XgR4QORn", "signatures": ["ICLR.cc/2026/Conference/Submission4171/Reviewer_Gubc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4171/Reviewer_Gubc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807379169, "cdate": 1761807379169, "tmdate": 1762917213675, "mdate": 1762917213675, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents CC-Gen: an unlimited, complexity controllable policy document and task generator, supporting multi-dimensional complexity (environment, task, workflow). The author further proposes CAP-CPT : It automatically decomposes policy documents into four rule categories (facts, behaviors, simple conditions, and complex conditions); and generates specialized training data for each rule category."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The author provides a benchmark with manageable difficulty, focusing primarily on the task-level and workflow-level challenges, and offers a comprehensive analysis of different models and internalization methods.\n\n2.The CAP-CPT pipeline delivers stable improvements in in-domain scenarios, with particularly significant benefits in scenarios involving data sparsity and high complexity."}, "weaknesses": {"value": "1.While policy identifiers significantly improve inference efficiency, they can lead to weak generalization with unseen policy documents, as evidenced by performance in Table 4 Substitute and Override tasks. Furthermore, introducing incremental pre-training pipelines can result in high costs when updating new policy documents, compared to RAG. The authors may need to consider a more lightweight knowledge update strategy to handle this practical issue.\n\n2.The paper assumes that the model can implicitly learn the mapping of \"<#Policy-1356X>\" to the realative policy content through CPT+SFT, but does not provide any probe experiments or visualization analysis to verify this. The limited experimental results of Referral task in Table 4 show that the internalization approach has not successfully established this mapping relationship.\n\n\n\nPresentation Issues & Typos\n\n1.appraoches -> approaches\n2.Redundant appendix reference in K.2"}, "questions": {"value": "1.During the training phase, how can you ensure that the model establishes a mapping relationship between policy identifiers and actual policy files? Have you evaluated how many additional CAP-CPT training samples are needed to learn each new identifier?\n\n2.The article mentions that SFT may lead to catastrophic forgetting problems. Have you evaluated the performance changes of the model before SFT after CAP-CPT compared to the original model without CAP-CPT?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "d8EoQ7xE1g", "forum": "10XgR4QORn", "replyto": "10XgR4QORn", "signatures": ["ICLR.cc/2026/Conference/Submission4171/Reviewer_reek"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4171/Reviewer_reek"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808647155, "cdate": 1761808647155, "tmdate": 1762917213406, "mdate": 1762917213406, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on a specific challenge in LLM agents:  long, complex policy documents that encode business rules or operating procedures (e.g., airline refund policies, compliance workflows) can lead to computational overheads and performance decline. As these policies expand, they increasingly dominate the input context, making in-context prompting inefficient. To address this, the paper introduces two key contributions:\n1. CC-Gen, a benchmark generator that systematically controls and varies policy complexity across four dimensions: task-level, workflow-level, environmental, and query-level. This enables fine-grained evaluation of agent reasoning under increasing policy complexity.\n2. CAP-CPT (Category-Aware Policy Continued Pretraining), a  training approach that analyzes policy documents into factual, behavioral, and conditional specifications, synthesizes targeted training data for each category, and conducts continued pretraining to embed these policies into the model.\n\nExperiments on Qwen models and $\\tau$-Bench demonstrate that CAP-CPT improves internalization robustness and   downstream task success rates."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Motivation: The problem considered is practical, since real-world LLM agents  can indeed be bottlenecked by massive policy prompts. This work directly addresses that bottleneck by proposing scalable internalization techniques.\n2. Novelty in benchmarking approach: CC-Gen fills a gap in evaluation by decomposing policy complexity into controllable fine-grained dimensions and quantifying their effects on reasoning and performance.\n3. Interesting methodological design: The idea of categorizing policy specifications (factual, behavioral, conditional) and applying category-specific data generation  for continued pretraining is interesting and empirically effective, as shown by some experiment results"}, "weaknesses": {"value": "Major\n\n1. Limited base model: While the paper evaluates Qwen models in detail, it would strengthen claims to include  non-Qwen architectures like Gemma or Llama to validate generality across model families.\n2. Generalization: How does CAP-CPT applies to other policies not discussed in the paper? Does introducing new policies always require re-training?\n3. Scalability and compute cost: CAP-CPT requires substantial data synthesis and training compute. Discussion of compute cost  would be valuable for practitioners.\n\nMinor\n1. Consistency: sometimes the paper uses tau-bench, sometimes $\\tau$-bench"}, "questions": {"value": "1. What policy knowledge is truly internalized? Qualitative examples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4zmbLQHyBi", "forum": "10XgR4QORn", "replyto": "10XgR4QORn", "signatures": ["ICLR.cc/2026/Conference/Submission4171/Reviewer_8Fjn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4171/Reviewer_8Fjn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991150189, "cdate": 1761991150189, "tmdate": 1762917212638, "mdate": 1762917212638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the problem of efficiently internalizing long and complex policy documents into LLM agents to reduce prompt length and computational overhead while maintaining reasoning and policy adherence. It introduces CC-Gen, a controllable-complexity benchmark generator that systematically evaluates how agents handle different dimensions of policy complexity, and proposes Category-Aware Policy Continued Pretraining (CAP-CPT), which is an automated pipeline that analyzes and categorizes policy specifications into factual, behavioral, and conditional types to guide targeted pretraining. The paper provides extensive experiments on Qwen-series models, showing significant gains under high-complexity and data-sparse conditions, achieving up to 97.3% input token compression and up to 44% improvement in task success rate."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **S1.** This paper presents a well-motivated and practically relevant problem. It enables LLM-based agents to internalize long, complex policy documents to reduce inference cost and context dependence.\n\n- **S2.** The CC-Gen benchmark is thoughtfully designed, enabling systematic control of task-level, workflow-level, and environmental complexities, which provides valuable tooling for future research.\n\n- **S3.** The proposed CAP-CPT pipeline offers a clear mechanism to address reasoning and memorization challenges by categorizing policy types and generating tailored data.\n\n- **S4.** The empirical results are extensive, covering both in-domain (policy task completion) and out-of-domain (policy substitution, override, referral, instruction following) evaluations.\n\n- **S5.** The approach demonstrates strong gains under data-scarce and high-complexity conditions, which reflects robustness and practical value."}, "weaknesses": {"value": "- **W1.** The methodological novelty of CAP-CPT could be more clearly positioned relative to existing knowledge injection or continued pretraining frameworks. Many components (e.g., policy paraphrase, QA generation, and continued pretraining) build upon known ideas, and the novelty largely resides in their integration and categorization logic.\n\n- **W2.** While the benchmark introduces four complexity dimensions, the quantification criteria for workflow or task complexity are not formally justified beyond heuristic depth/branch counts.\n\n- **W3.** The baseline selection is limited to Qwen and Claude models; broader comparisons (e.g., Llama, GPT-4-style models) could contextualize generality."}, "questions": {"value": "- **Q1.** How sensitive are the CAP-CPT results to errors in the LLM-based policy categorization step? Can we quantify how categorization accuracy affects downstream internalization?\n\n- **Q2.** Does CAP-CPT generalize to real, human-written policies that are less templated than those generated by CC-Gen? \n\n- **Q3.** How does CAP-CPT perform when using smaller models (< 10 B parameters)?\n\n- **Q4.** Would multi-policy internalization scale to hundreds of distinct policy sets, or are there capacity trade-offs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bfu98P6ojg", "forum": "10XgR4QORn", "replyto": "10XgR4QORn", "signatures": ["ICLR.cc/2026/Conference/Submission4171/Reviewer_L8eC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4171/Reviewer_L8eC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993160495, "cdate": 1761993160495, "tmdate": 1762917212383, "mdate": 1762917212383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}