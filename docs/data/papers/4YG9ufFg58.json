{"id": "4YG9ufFg58", "number": 9202, "cdate": 1758115008846, "mdate": 1763378989914, "content": {"title": "Identity-Free Deferral For Unseen Experts", "abstract": "Learning to Defer (L2D) improves AI reliability in decision-critical environments, such as healthcare, by training a model to either make its own prediction or delerejector the decision to a human expert. A key challenge is adapting to unseen experts: those who were not involved during the system's training process. Current methods for this task, however, can falter when unseen experts are out-of-distribution (OOD) relative to the training population. We identify a core architectural flaw as the cause: they learn identity-conditioned policies by processing class-indexed signals in fixed coordinates, creating shortcuts that violate the problem's inherent permutation symmetry. We introduce Identity-Free Deferral (IFD), an architecture that enforces this symmetry by construction. From a few-shot context, IFD builds a query-independent Bayesian competence profile for each expert. It then supplies the deferral rejector with a low-dimensional, role-indexed state containing only structural information, such as the model's confidence in its top-ranked class and the expert's estimated skill for that same role, which obscures absolute class identities. We train IFD using an uncertainty-aware, context-only objective that removes the need for expensive query-time expert labels. We formally prove the permutation invariance of our approach, contrasting it with the generic non-invariance of standard population encoders. Experiments on medical imaging benchmarks and ImageNet-16H with real human annotators show that IFD consistently improves generalization to unseen experts, with significant gains in OOD settings, all while using fewer annotations than competing methods.", "tldr": "", "keywords": ["learning to defer", "healthcare", "medical"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/277cca2bec8c2427f61d54ab35ced581ead93285.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Identity-Free Deferral (IFD), a new architecture for L2D systems that improves generalization to unseen human experts, especially those that are OOD to the training population. In standard L2D frameworks, a model learns when to predict and when to defer to an expert. Recent population-adaptive extensions condition this decision on learned expert embeddings, yet these architectures often rely on class-indexed signals that leak label identities and thus violate the permutation symmetry inherent in the problem. As a result, they tend to overfit to specific expert–class alignments and fail to transfer to unseen or re-indexed experts.\n\nIFD addresses this issue by enforcing permutation invariance architecturally. Instead of embedding expert identities directly, it constructs a Bayesian, query-independent competence profile for each expert using a few-shot context of past predictions. The deferral rejector then operates on a compact, role-indexed state (containing structural information such as the model’s confidence in its top-ranked class and the expert’s estimated competence for that same role), thus eliminating all absolute class-identity channels. The model is trained with a novel uncertainty-aware, context-only loss that removes the need for query-time expert labels, weighting supervision by a lower confidence bound on expert reliability.\n\nThe authors provide formal proofs of permutation invariance, contrasting IFD with the non-invariance of standard population encoders, and show theoretically that the resulting policy focuses on structural relations between model and expert rather than identity-conditioned shortcuts. Empirical results across multiple medical imaging datasets and ImageNet-16H (with real human annotators) demonstrate that IFD consistently outperforms L2D-Pop and other baselines, especially for OOD experts and under input distribution shift. Moreover, IFD achieves these gains with substantially fewer expert annotations."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper tackles a highly relevant and practically important problem in L2D: ensuring reliable deferral to unseen or OOD experts. This setting reflects real-world scenarios such as hospital staff turnover, making the problem both timely and significant for AI deployment.\n\nIn terms of originality, the work offers a clear conceptual advance by identifying identity-conditioned shortcuts as a core limitation of existing L2D approaches and proposing an architectural solution (IFD) that enforces permutation symmetry by design. This symmetry-based perspective introduces a novel and principled inductive bias for expert adaptation.\n\nThe quality of the work is strong. The theoretical analysis is sound and well-motivated, including formal proofs of invariance and clear links to the Bayes-optimal rule. The accompanying uncertainty-aware, context-only training objective is practical, removing the need for costly query-time expert labels.\n\nThe experimental evaluation is thorough, spanning multiple datasets, both simulated and real experts, and a wide range of conditions such as in-distribution and OOD settings, input shifts, and ablations."}, "weaknesses": {"value": "1) Although the theoretical analysis convincingly demonstrates that standard population-adaptive L2D architectures suffer from identity-conditioned shortcuts and that IFD enforces permutation invariance by design, the paper would benefit from a direct empirical illustration of these shortcuts. A simple toy experiment (e.g. showing how a conventional L2D-Pop model fails under systematic class reindexing while IFD remains stable) would make the argument more concrete and visually intuitive.\n\n2) While the theoretical results appear sound, their scope could be clarified more explicitly. The proven invariance strictly holds under coherent relabelings (when both the model and expert are permuted consistently), whereas in practice the paper’s OOD setup often involves expert-only permutations where this assumption may not fully apply. Stating this distinction in the main text and briefly discussing potential extensions to partial or incoherent relabelings would improve conceptual precision.\n\n3) The class-level abstraction of expert competence, though central to the method’s efficiency and invariance, inherently limits sensitivity to within-class, instance-specific expertise differences. While the authors acknowledge this in their discussion, a small-scale experiment or ablation (e.g., comparing performance when experts vary mainly within a class) would clarify how much this simplification affects performance.\n\n4) There are minor presentation issues that should be addressed to improve polish and readability: the word “delerejector” in the abstract appears to be a typo, and Section 4.2 repeats the parenthetical phrase “(why this blocks identity leakage)\"."}, "questions": {"value": "1) Could the authors include or describe a simple empirical toy example demonstrating this failure mode and how IFD avoids it?\n2) The invariance proof assumes coherent relabelings (joint permutations of model, labels, and expert), while real OOD scenarios often involve expert-only shifts. Could the authors clarify how IFD behaves in such cases and whether approximate invariance can still be expected?\n3) IFD models expert competence at the class level, ignoring within-class instance variation. How sensitive is performance to this assumption, and do the authors plan to explore instance-aware but still identity-free extensions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6MrYjIhsUC", "forum": "4YG9ufFg58", "replyto": "4YG9ufFg58", "signatures": ["ICLR.cc/2026/Conference/Submission9202/Reviewer_z5Ji"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9202/Reviewer_z5Ji"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9202/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761408389478, "cdate": 1761408389478, "tmdate": 1762920868909, "mdate": 1762920868909, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Identity-Free Deferral (IFD) for Learning-to-Defer with population experts. The authors argue that common “population” encoders leak class/expert identity and are not invariant to coherent relabelings of classes, which can hurt transfer to new experts. Their approach build a small, permutation-invariant, role-indexed state from a query-independent competence profile estimated from a few context examples. The rejector compares the model’s confidence to an expert’s peak-class accuracy. Several experiments are made on different medical dataset, results are compared with the exist population L2D approach as well as a standard one."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The work is sound and I understand the motivation on the symmetry. \n- Reducing the number of predictions required by the expert is good. \n- The method is quite practical and scalable."}, "weaknesses": {"value": "-  I had a lot of trouble following the paper. The presentation could be substantially clarified: the structure feels dense, and it is often unclear how the different components are connected. A significant rewrite or reorganization might be needed to make the flow easier to follow.\n\n- Some background and notation are imprecise or undefined. For example, $r(x)$ later becomes $r(x, E)$ without a clear definition, $\\Delta$ is introduced but never defined, and LCB appears before Lower Confidence Bound is spelled out.\n\n- Several small presentation issues and typos remain:\n    - The 'QI' column is labeled [1].\n    - Typo at line 10: 'delerejector',  line 1698: 'aggrerejector', parentheses line 229.  \n\n- The base surrogate loss employed in the paper has previously been shown to yield miscalibrated probability estimates [2] and to be non-realizable [3, 4].\n\n- Only for a single expert."}, "questions": {"value": "I have a couple of questions: \n\n1. Your current surrogate loss appears largely inspired by [5]. Is there a specific reason why you compare primarily with the formulation from [1] rather than directly with that of [5]?\n\n2. The base surrogate loss employed in the paper has previously been shown to produce *miscalibrated* probability estimates [2] and to be *non-realizable* under standard assumptions [3, 4]. Is there a particular reason you chose this formulation instead of those from [2] or [3], which are known to yield calibrated or realizable solutions?\n\n3. In Table 3, you argue that **Full** consistently matches or exceeds other variants, but the difference between **Full** and **Mean** appears very small overall. Do you have an explanation for this? Is there a specific trade-off between $\\mu_y^E$ and $\\sigma_y^E$?\n\n4. Out of curiosity, how does your approach perform in the standard Learning-to-Defer setting (with fixed experts), compared for instance to [1]?\n\n5. Is there a reason why the current formulation is restricted to single expert?\n\n\n------\n\n[1] Rajeev Verma, Daniel Barrejon, and Eric Nalisnick. Learning to defer to multiple experts: Consistent surrogate losses, confidence calibration, and conformal ensembles. \n\n[2] Yuzhou Cao, Hussein Mozannar, Lei Feng, Hongxin Wei, and Bo An. In defense of softmax parametrization for calibrated and consistent learning to defer.\n\n[3] Anqi Mao, Mehryar Mohri, and Yutao Zhong. Realizable h-consistent and bayes-consistent loss\nfunctions for learning to defer.\n\n[4] Hussein Mozannar, Hunter Lang, Dennis Wei, Prasanna Sattigeri, Subhro Das, and David A. Sontag. Who should predict? exact algorithms for learning to defer to humans.\n\n[5] Hussein Mozannar and David Sontag. Consistent estimators for learning to defer to an expert"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tyBCvvwG1H", "forum": "4YG9ufFg58", "replyto": "4YG9ufFg58", "signatures": ["ICLR.cc/2026/Conference/Submission9202/Reviewer_R4fz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9202/Reviewer_R4fz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9202/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761730805505, "cdate": 1761730805505, "tmdate": 1762920868484, "mdate": 1762920868484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}