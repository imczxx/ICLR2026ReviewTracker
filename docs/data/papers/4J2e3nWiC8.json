{"id": "4J2e3nWiC8", "number": 21354, "cdate": 1758316552370, "mdate": 1759896926659, "content": {"title": "Priors in time: Missing inductive biases for language model interpretability", "abstract": "A central aim of interpretability tools applied to language models is to recover meaningful concepts from model activations. Existing feature extraction methods focus on single activations regardless of the context, implicitly assuming independence (and therefore stationarity). This leaves open whether they can capture the rich temporal and context-sensitive structure in the activations of language models (LMs). Adopting a Bayesian view, we demonstrate that standard Sparse Autoencoders (SAEs) impose priors that assume independence of concepts across time. We then show that LM representations exhibit rich temporal dynamics, including systematic growth in conceptual dimensionality, context-dependent correlations, and pronounced non-stationarity, in direct conflict with the priors of SAEs. This mismatch casts doubt on existing SAEs' ability to reflect temporal structures of interest in the data. We introduce a novel SAE architecture---Temporal SAE---with a temporal inductive bias that decomposes representations at a given time into two parts: a predictable component, which can be inferred from the context, and a residual component, which captures novel information that cannot be captured by the context. Experiments on LLM activations with Temporal SAE demonstrate its ability to correctly parse garden path sentences, identify event boundaries, and more broadly delineate abstract, slow-moving information from novel, fast-moving information, while existing SAEs show significant pitfalls in all the above tasks. Our results underscore the need for inductive biases that match the data in designing robust interpretability tools.", "tldr": "We show that language model representations exhibit rich, non-stationary temporal dynamics, and demonstrate how mismatched priors in standard Sparse Autoencoders lead to characteristic failures—addressed by a new temporally biased SAE.", "keywords": ["Top-Down Interpretability", "Sparse Autoencoders", "Temporal Structure", "Stationarity"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/735437e0a2aeddf137e80bd5e69c3c2cb789ffa7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper examines the implicit temporal assumptions underlying Sparse Autoencoders (SAEs) widely used in mechanistic interpretability. It reveals that the conventional SAE training objective imposes an implicit independence condition on the prior it assigns to the distribution of feature activations across different token positions—an assumption inconsistent with the highly correlated and nonstationary nature of language sequences. Through empirical analyses of Llama-3.1-8B and Gemma-2-2B, the authors show that the dimensionality and autocorrelation of token representations evolve systematically with position. To address this, they introduce the Temporal Sparse Autoencoder, which decomposes each activation into a predictable component derived from past context and a novel component for the current token capturing new information, akin to the innovation concept in signal processing. The Temporal SAE uncovers temporally structured linguistic features—such as event boundaries in narratives and reanalysis in garden-path sentences—that standard SAEs fail to reveal, underscoring the need for temporal inductive biases in interpretability methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The primary advantage of this paper lies in its thoughtful incorporation of linguistic insights into the analysis, design, and evaluation of SAE methods and LLM representations. The empirical experiments in Section 4, presented in Figure 2, clearly show that LLM representations of token sequences conform to the non-stationarity of natural language, featuring continuous increments of new information regulated by underlying dependency structures. The evaluation of the proposed Temporal SAE on garden-path sentences is both novel and insightful, as the dependency parsing of such sentences is a classic topic in linguistics. The superior performance of the Temporal SAE on these examples effectively demonstrates the benefits of explicitly incorporating temporal and linguistic inductive biases into the interpretability framework.\n\n2. The spectral analysis of SAE and LLM representations at the end of Section 6 is particularly insightful and adds an important dimension to the depth of the work. It convincingly shows that the decomposition of LLM representations by the Temporal SAE into predictable and novel components successfully captures the bipartite structure of representations—comprising a relatively slow-varying component and a more dynamic component with respect to the introduction of new tokens. This analysis reinforces the interpretability and mechanistic validity of the proposed temporal modeling approach."}, "weaknesses": {"value": "1. One of the primary motivations (and functions) of the original SAE is to decompose the polysemous LLM representations into distinct monosemantic features that are more interpretable and less ambiguous, which can further be utilized in steering experiments. This paper, however, makes no attempt to semantically interpret the learned features in this regard—likely because the architectural design of the Temporal SAE, where the feature activations of the predictable part are obtained via an attention mechanism, complicates the interpretation of both activations and activation features.\n\n2. The paper suffers from a lack of clarity with respect to concepts and notations in certain parts, which I list below.\n\n- **Equation 2**: The normalization factor should be $\\frac{1}{T}$.\n- **Section G.2, Equation 40**: $M$ is not defined, which seems to refer to the number of tokens. For the U-statistic to correctly estimate the effective rank, it appears that the model representations must be normalized; however, this is not stated.\n- **Line 291**: The authors claim $x_{n,t} \\perp x_{p,t}$, but this is not structurally guaranteed by the Temporal SAE (e.g., via a projection-based approach). The authors themselves acknowledge in Line 338 that the orthogonality is only approximate. They might consider rephrasing the argument in Line 291 for precision.\n- **Predictable component definition**: The authors state that they use a self-attention layer on top of a single ReLU layer to model $f$ for obtaining the predictable component. However, Figure 3 suggests that the attention layer depends on the SAE activations $v_1, ..., v_t$, and the paper does not specify how these activations are obtained.\n- **Baselines in Figure 2(d) and (h)**: The authors provide a baseline for their variance preservation experiments using representations of a certain number of nearest token representations. However, the method for computing this baseline is never stated (presumably using an equal number of random directions). I also recommend adding another baseline using projections based on the first $k$ tokens’ representations in the context, which could further substantiate the authors’ claims."}, "questions": {"value": "1. What are $W$ and $L_0$ in Table 1?  \n\n2. What is the off-the-shelf algorithm used to extract hierarchical structures from the correlation plot, and how does it work?  \n\n3. Do the “predictive codes (and novel codes, respectively)” frequently mentioned in Section 6 refer to the SAE activations $z_{p,t}$ or to $x_{p,t}$?  \n\n4. Could you provide an (at least intuitive) explanation for why the slow-moving part of the representations (and the predictive codes) exhibits a faster spectral decay?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V3CRfmBQXl", "forum": "4J2e3nWiC8", "replyto": "4J2e3nWiC8", "signatures": ["ICLR.cc/2026/Conference/Submission21354/Reviewer_mbJz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21354/Reviewer_mbJz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794155050, "cdate": 1761794155050, "tmdate": 1762941716655, "mdate": 1762941716655, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper points out current SAE are built on a flawed assumption. They adopt a Bayesian view and show that standard SAEs implicitly impose a \"prior\" that the concepts they extract are independent and identically distributed across time. However, language is full of temporal structure and correlations. Authors introduce a new architecture, the Temporal SAE, which decomposes the activation into two parts: A predictable component and A novel component."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The topic of decomposes the activation into two parts is interesting.\n2. The core problem and flawed assumption that standard SAE has is well introduced.\n3. The proposed method is interesting.\n4. The temporal SAE can successfully identify concept that standard SAE can't"}, "weaknesses": {"value": "1. The author claims their temporal SAE is better than standard SAE. However, sometimes it is really difficult to evaluate an SAE, since there is no \"ground truth\". Therefore, the author should evaluate their SAE on some downstream tasks such as model steering. \n2. What about the interpretable concepts in the predictable component? Why are we not finding interpretable features in predictable component as well?\n3. The paper never evaluates its new features on any of downstream tasks. The evaluations are purely analytical. The paper only shows that its features correlate with these temporal structures, but it never proves that these features are more useful. The big \"so what?\" question is unanswered.\n4. This paper is built on the assumption that the novel component is orthogonal to the predictable component. However, sometimes new information doesn't just add a new, independent concept; it often refines or modifies existing, predictable concepts. Plus, I didn't see any citation prove this assumption in the paper.\n5. The paper miss some important related work.\n\n[1]: A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models"}, "questions": {"value": "1. What is the difference between your method: \n\"input a sentence -> find the novel component at each token -> convert this novel component into human understandable concept\",\nand method where you just input tokens one by one, and convert them into human understandable concept?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pjA3PvAr6t", "forum": "4J2e3nWiC8", "replyto": "4J2e3nWiC8", "signatures": ["ICLR.cc/2026/Conference/Submission21354/Reviewer_r8pv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21354/Reviewer_r8pv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058926850, "cdate": 1762058926850, "tmdate": 1762941716308, "mdate": 1762941716308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors first provide a formal characterization of standard SAEs, arguing SAEs impose an implicit prior that assumes concepts are independent and identically distributed (i.i.d.) across time. They contrast this with an empirical analysis of LM activations, which reveals rich temporal dynamics, including non-stationarity and strong context-dependent correlations. To address this mismatch, the authors introduce the Temporal SAE, a novel architecture with a temporal inductive bias. This model decomposes activations at each timestep into two components: a predictable component ($x_p$), inferred from the context, and a novel component ($x_n$), which captures the residual information. The authors demonstrate that this decomposition allows the model to separate slow-moving, abstract information (in $x_p$) from fast-moving, novel information (in $x_n$). They provide evidence that this model is better at identifying temporal structures, such as event boundaries and correct garden-path sentence parses, which standard SAEs fail to capture."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. *Formal Characterization of SAE Priors:* The paper provides a clear and valuable formalization of the implicit assumptions in standard SAEs. Characterizing the priors as i.i.d. across time (Proposition 3.1) 6cleanly articulates the central problem.\n2. *Strong Empirical Analysis:* The claims about the data's temporal structure are well-supported by a robust empirical analysis. The use of multiple metrics, including intrinsic dimensionality (U-statistic) and autocorrelation, demonstrates the non-stationarity and context-dependence of LM activations (Figure 2) that hold back traditional SAE-based approaches.\n3. *Clarity and Intuition:* The paper is very well-written and intuitive. The core problem and the proposed solution are explained clearly, making the work easy to follow."}, "weaknesses": {"value": "1. *Evaluation Relies on Correlational Evidence:* The primary evidence for the Temporal SAE's improved interpretability is qualitative (dendrograms in Fig. 5, 7) or correlational (CKA with slow/fast Fourier signals in Table 3, Fig. 6). While standard metrics like reconstruction (Table 1) are included as sanity checks, the paper never demonstrates that the disentangled $z_p$and $z_n$ features are _causally_ more useful than standard SAE features at steering model behavior.\n    - The qualitative claims about event boundaries (Fig. 5) are subjective and would be much stronger if validated quantitatively against human-annotated datasets, such as those the authors already cite (e.g., Zacks et al., 2007; Baldassano et al., 2018).\n    - A stronger claim would require causal validation. For instance, are $z_p$ features more effective for patching high-level topics between texts? The paper claims $z_n$ captures \"novel\" information; does this imply $z_n$ features might be better targets targets for model editing? A demonstration that interventions on $z_n$ are more localized and effective than on standard (entangled) $z$ features would provide stronger causal evidence.\n2. *Novelty =/= Un-predictability*: The paper's decomposition rests on an assumption that \"novel\" information is orthogonal to \"predictable\" information. This is questionable, as linguistically or cognitively \"novel\" information (e.g., the start of a new topic) is not always unpredictable. In fact, research on human event memory (which the authors cite) suggests that event boundaries are registered at predictable changes in context, not just at moments of high prediction error. This creates a potential mismatch: the model's \"novel\" component may only be capturing an unpredictable residual, rather than the more structured, and sometimes predictable, \"novelty\" that defines temporal structures."}, "questions": {"value": "1. *Shared vs. Separate Dictionaries:* The model shares a single dictionary $D$ for both the predictable ($z_p$) and novel ($z_n$) components. Given that these codes are purported to capture fundamentally different types of information (slow vs. fast, abstract vs. transient), what is the justification for sharing the dictionary? Were separate dictionaries/encoders explored?\n2. *Causal Utility of Features:* As mentioned in the weaknesses, the \"gold standard\" for interpretability is often causal intervention. Have the authors performed any experiments (e.g., activation patching, model editing) to demonstrate that the $z_p$ and $z_n$ features are more causally effective or localized than features from a standard SAE? Demonstrating this on the garden-path sentence examples would be particularly compelling.\n3. *Quantitative Validation of Event Boundaries:* The hierarchical clustering results in Figure 5 are visually interesting, but can these results be validated more rigorously? For example, by computing a quantitative metric (e.g., F1-score, ARI) for event boundary detection against the human-annotated ground truth in datasets like those cited (Zacks et al., 2007; Baldassano et al., 2018)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "teZt7rCayz", "forum": "4J2e3nWiC8", "replyto": "4J2e3nWiC8", "signatures": ["ICLR.cc/2026/Conference/Submission21354/Reviewer_QXh2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21354/Reviewer_QXh2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150724395, "cdate": 1762150724395, "tmdate": 1762941715932, "mdate": 1762941715932, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}