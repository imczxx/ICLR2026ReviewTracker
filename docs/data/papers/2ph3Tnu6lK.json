{"id": "2ph3Tnu6lK", "number": 19604, "cdate": 1758297596325, "mdate": 1763721326225, "content": {"title": "Discovering interpretable biological concepts in single-cell RNA-seq foundation models", "abstract": "Single-cell RNA-seq foundation models achieve strong performance on downstream tasks but remain black boxes, limiting their utility for biological discovery. Recent work has shown that sparse dictionary learning can extract concepts from deep learning models, with promising applications in biomedical imaging and protein models. However, interpreting biological concepts remains challenging, as biological sequences are not inherently human-interpretable. We introduce a novel concept-based interpretability framework for single-cell RNA-seq models with a focus on concept interpretation and evaluation. We propose an attribution method with counterfactual perturbations that identifies genes that influence concept activation, moving beyond correlational approaches like differential expression analysis. We then provide two complementary interpretation approaches: an expert-driven analysis facilitated by an interactive interface and an ontology-driven method with attribution-based biological pathway enrichment. Applying our framework to two well-known single-cell RNA-seq models from the literature, we interpret concepts extracted by Top-K Sparse Auto-Encoders trained on two immune cell datasets. With a domain expert in immunology, we show that concepts improve interpretability compared to individual neurons while preserving the richness and informativeness of the latent representations. This work provides a principled framework for interpreting what biological knowledge foundation models have encoded, paving the way for their use for hypothesis generation and discovery.", "tldr": "", "keywords": ["interpretability", "computational biology", "concept-based interpretability", "mechanistic interpretability", "single-cell RNAseq"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/01a4bbfcbcccdf791a7cbfa36c9c056367bc9163.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduce an interpretability framework for single-cell RNA-seq models based on concept extraction through a decomposition approach, which relies on sparse auto-encoders. To evaluate these, they propose an attribution-based method with conterfactual perturbations, an attribution-based gene set enrichment analysis (GSEA) and a web-based visualization tool with an expert interpretation. Experiments on Tabula Sapiens Immune and Cross-Tissue Immune Cell Atlas datasets show that these concepts are more interpretable and stable than individual neurons while retaining downstream predictive power."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Paper is well written and structured.\n\n2. Addresses interpretability of large scRNA-seq foundation models, which is still an area of high interest.\n\n3. Combines sparse dictionary learning with counterfactual-based attributions, going beyond correlation-based analyses.\n\n4. Uses large immune cell datasets; includes cross-dataset stability analysis.\n\n5. Incorporates an area expert, which adds credibility and biological realism."}, "weaknesses": {"value": "1. The novelty of the proposed top-k sparse auto-encoder to extract meaningful concepts is limited. \n\n2. Expert evaluation involves only one annotator; inter-expert variability or reproducibility is not assessed.\n\n3. The “interpretability gain” is mostly qualitative, no standardized metric is provided.\n\n4. Both datasets are immune-cell focused; generalization to other tissues or modalities remains untested."}, "questions": {"value": "1. Is the code and visualization platform available at submission? I can't find it in the paper.\n\n2. Could you highlight the main difference between other models that provide an interpretable latent space such as VEGA (https://doi.org/10.1093/bioinformatics/btad387), GSAE (https://doi.org/10.1186/s12918-018-0642-2) or SENA-discrepancy-VAE (https://openreview.net/pdf/f8c0bd3ea256d2af7cfe66c6a46b511cab5ba995.pdf)? Couldn't we forward the single-cell samples through any of these and extract similar features?\n\n2. How does the attribution-based GSEA differ quantitatively from traditional DGEA-based enrichment? Can you provide examples of pathways uniquely discovered?\n\n3. How stable are concepts when changing SAE random seeds or hyperparameters? Could you include std in metrics where multiple seeds have been tested?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "txBJHs73GT", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Reviewer_Tc45"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Reviewer_Tc45"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761479941904, "cdate": 1761479941904, "tmdate": 1762931466789, "mdate": 1762931466789, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework for improving the interpretability of single-cell RNA-seq foundation models. The manuscript is clearly written, the methodology is sound, and the experiments are thorough.\n\nThe core of the contribution is the gene attribution method based on counterfactual perturbations. By identifying genes that distinguish cells activating a concept from similar cells that do not, this approach moves beyond simple correlational analysis (like DGEA) to better pinpoint influential genes.\n\nA couple of weaknesses (context within the broader field of interpretable ML, justification of methodological choices, depth of the counterfactual analysis, limitations of the expert study, hypothesis generation claim) should be addressed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The core contribution (gene attribution method based on counterfactual perturbations) is a well-grounded methodological advancement.\n\nThe empirical validation is sound: The authors provide evidence that concepts extracted via TopK SAEs are more interpretable than individual neurons from the original models scGPT and scVI. Also, the study evaluates the stability of learned concepts across different datasets, a known challenge for SAEs."}, "weaknesses": {"value": "Context within the broader field of interpretable ML: The introduction frames the problem primarily as one of post-hoc explanation for \"black box\" models. However, it would benefit from acknowledging and contrasting its approach with the branch of causal representation learning, e.g., discrepancy-VAE (Zhang et al.), SENA (de la Fuente et al.), and GEARS (Roohani et al.). Discussing why a post-hoc concept extraction approach might be preferable or complementary (e.g., applicable to any pre-trained foundation model without architectural changes) would provide a more complete picture of the landscape.\n\nJustification of methodological choices: The manuscript states that TopK SAEs simplify tuning over vanilla SAEs with L1 regularization. This is a practical reason, but the authors should provide a more thorough justification for choosing this specific dictionary learning architecture over other methods for learning disentangled representations. For instance, why not use a VAE with a structured prior (e.g., beta-VAE) to learn the concepts directly from the embeddings?\n\nDepth of the counterfactual analysis: The counterfactual for a sample is defined as the closest sample in the embedding space that does not activate the concept. This is a reasonable heuristic, but it has limitations. The \"closest\" cell might differ in biologically important ways beyond the concept in question, potentially confounding the attribution scores. The authors should discuss this limitation.\n\nLimitations of the expert study: The study was conducted with a single domain expert. While valuable, this is an N=1 study, and the generalizability could be questioned. The authors should explicitly state this as a limitation and perhaps soften their conclusions slightly. Was there a process to measure intra-expert consistency (e.g., showing the same concept twice)? This should be clarified.\n\nHypothesis generation claim: The examples show that the framework can recover well-established biological concepts. To fully substantiate the claim of enabling hypothesis generation and discovery, it would be powerful to showcase an example of a concept that is either novel, refines existing knowledge, or reveals a non-obvious connection between genes that could lead to a testable biological hypothesis.\n\nTypos:\n- Page 2, line 104: \\sigma(\\cdot)\n- Page 2, line 107: L1 regularization"}, "questions": {"value": "The questions directly relate to the identified weaknesses:\n- How does the post-hoc concept extraction framework complements or offers advantages over methods from causal representation learning which aim to learn disentangled representations directly as part of the model architecture?\n- What are the primary methodological advantages of using TopK SAEs for learning concepts from embeddings compared to alternative approaches for learning disentangled representations?\n- What are the potential limitations of defining a counterfactual as the nearest neighbor that does not activate a concept, particularly the risk that confounding biological differences between the two cells might influence the gene attribution scores?\n- Which measures were taken to assess intra-expert consistency?\n- Can you provide an example where your model identifies a concept that reveals a previously non-obvious connection between genes or refines existing knowledge in a way that leads to a new, testable hypothesis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "434cRYkZA3", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Reviewer_YuVv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Reviewer_YuVv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654092979, "cdate": 1761654092979, "tmdate": 1762931466392, "mdate": 1762931466392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a concept-based interpretability framework for single cell RNA-seq data to uncover genes that activate different (biological) concepts, enabling interpretation of known single-cell emeddings. They also provide an interactive interface to facilitate the concept analysis by experts, as well as an enrichment method based on uncovered attributes.\n\nThe authors show that the purpose model leads to better interpretability compared to individual neurons."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper provide a novel way of interpreting the embeddings provided by well known scRNA-seq models such as scVI and scGPT. They also provide an intuitive framework to analyze the obtained results by experts that may not be able to run the model themselves. I think this work can have important relevance on the biomedical community, as interpretability is a key factor while working with single-cell data."}, "weaknesses": {"value": "I don't think this work provide enough sound advances in representation learning or machine learning for being suitable to ICLR. The method applies known SAE for dictionary learning based on known representation learning models from scRNA-seq data (scVI, scGPT). While the idea of interpreting the concepts inferred by the SAE is very interesting, they are more suitable to more specialized conferences/journals.\n\nIn addition to that, I believe the results are somehow incomplete. While they provide good analyses on the SAE across the two embedding spaces, a more in-depth benchmark is required to fully understand the benefits of the proposed model. For example, there are other integration/embedding models that are widely used that should be compared such as CCA (Seurat), Harmony, the new U-space by MrVI, etc. The inclusion of these models could provide a more \"universal\" view of the proposed interpretability framework.\n\nAdditionally, more there are other works based on SAE for interpretability (eg. https://doi.org/10.1093/nar/gkae197, and reference therein) that should be mentioned (and maybe compared).\n\nFinally, the expert analysis (the soundness of the biology inferred by the model) should be more thoroughly analyzed (see for example, the work mentioned above)."}, "questions": {"value": "How does the model perform when using other integration/embedding models for scRNA-Seq data?\n\nHow does it compare against traditional GSEA analysis on the same comparisons? I understand that through GSEA genes themselves may not have \"interpretability\" but are both models uncovering the same biological processes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dDuiRyeHtA", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Reviewer_GBNb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Reviewer_GBNb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891376109, "cdate": 1761891376109, "tmdate": 1762931465917, "mdate": 1762931465917, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This ms mainly focuses on exploring the cell embeddings given by scGPT and scVI. The idea is to perform a low-rank decomposition of the embedding matrix (cell x emb) using sparse autoencoder (SAE), yielding a loading matrix U and factor matrix D. The factor matrix is called \"concept\" by the authors. Then they try to see which genes are relevant for the concepts. This is done by masking each input gene on chosen cells and check how they change the loading of a given concept. The change is called \"attribution\" by the authors. In two experiments, they show that the concepts are biologically interpretable, which are associated with cell types, GO pathways. This work is a step further than traditional tasks of using cell embeddings for clustering or batch effect correction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of introducing concept seems to make biological sense.\n2. I think the association between the concepts and GO terms (Fig. 3B and Fig. 4C) are very interesting.  It could be further explored in the future.\n3. Although missing some details, the method descriptions are solid."}, "weaknesses": {"value": "Maybe I have missed, but In section 4.2, it is unclear to me\n1. the distribution of the attribution scores, why 0.05 is selected as the cutoff\n2. what are the cells used for calculating the attribution scores\n\nLack of a baseline method for the benchmark. How does it compare with direct low rank decomposition of the cell embedding matrix? In theory, you can treat the factors as the \"concepts\" and loadings as the \"concept activations\"."}, "questions": {"value": "line 179, why not directly mask gene l in x^p ?\nline 288, what is \"expansion factor\" and why it matters here?\nline 300, what is \"neurons\" in scGPT? could you be more specific about the layers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "JhUHrfrzJ8", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Reviewer_mM9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Reviewer_mM9A"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946796885, "cdate": 1761946796885, "tmdate": 1762931465501, "mdate": 1762931465501, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common answer (1/3)"}, "comment": {"value": "Dear reviewers, we sincerely appreciate the time and effort spent reviewing our manuscript and thank you for your detailed feedback. Because some questions or limitations were raised by multiple reviewers, we have prepared a summary of our main answers, additional experiments, and the corresponding revisions made to the paper:\n\n**1. Clarify the positioning and differences with disentangled representation learning / interpretable latent spaces by design (reviewers YuVv, Tc45, and GBNb)**\n\nIn contrast to approaches that enforce interpretability of the latent space at training time (NetActivity, discrepancy-VAE, SENA, GEARS, VEGA, GSAE), our approach is post-hoc and model-agnostic, enabling interpretation of any trained neural network. This distinction offers several advantages: (1) it allows interpretation of black-box models that may achieve superior predictive performance compared to interpretable-by-design architectures, (2) it does not require prior knowledge to be specified at training time, facilitating the incorporation of new biological insights as they emerge, and (3) it could enable the discovery of novel biological patterns. \n\nModifications to the paper: We clarified this positioning in the \"Related work\" section and in the introduction.\n\n\n**2. Limitations of the user study (reviewers YuVv, Tc45, and GBNb)**\n\nThe reviewers pointed out the limitations of the user study, which, although valuable, involves only a single participant. We acknowledge this limitation, which mainly reflects cost and time constraints, as the study requires experts in biology. As suggested, we conducted an additional analysis to assess intra-user variability. We presented 14 concepts to the domain expert, 11 of which had been annotated in the original user study. Among these 11 concepts, 5 received similar interpretations, 4 switched between \"Signal but unclear\" and \"Not interpretable\" (two in each direction), 2 switched between \"Not interpretable\" and \"Interpretable\" (one in each direction). These observations illustrate the sensitivity of the \"Signal but unclear\" annotation. We also observe variability even in annotations we expected stronger, which is more concerning, though difficult to characterize with such a small number of re-annotated concepts. Re-evaluating all concepts a second time would undoubtedly bring deeper insights. While this cannot realistically be done within the limited rebuttal timeframe, it remains an important step that we will address in the next steps of the work.\n\nModifications to the paper: we included a new paragraph in Section 4.3 discussing the limitations of the user study based on the results of the intra-user stability experiment."}}, "id": "V1p2yvfS54", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763717400899, "cdate": 1763717400899, "tmdate": 1763717400899, "mdate": 1763717400899, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common answer 2/3"}, "comment": {"value": "**3. Compare attribution-based GSEA to classic DGEA-based GSEA (reviewers Tc45 and GBNb)**\n\nAttribution-based GSEA is a methodological contribution of our work, the objective is to identify biological processes that best match the signal encoded by the concept. We showed with deletion curves (Figure 8 in Appendix) that genes with high attribution scores have more impact on the concept activation than genes with high fold change obtained from classic differential gene expression analysis (DGEA). As suggested by reviewers, comparing attribution-based GSEA to classic DGEA-based GSEA would further justify the advantages of our method.\n\nAdditional experiment: We computed DGEA-based GSEA and attribution-based GSEA of 100 concepts for the two models. For a given concept, we obtain two sets of biological processes :\n\n- Biological processes from attribution-based GSEA : $P_{att} = {T^{att}_1, ... ,T^{att}_{k_{att}}}$\n- Biological processes from DGEA-based GSEA : $P_{dgea} = {T^{dgea}_1, ..., T^{dgea}_{k_{dgea}}}$\n\nEach biological process $T$ is defined as a set of genes $T={(g_1, l2fc_1, att_1), ..., (g_m, l2fc_m, att_m)}$, with $g$ the gene name, $l2fc$ the log2 fold change from DGEA and $att$ the attribution score. \n\nWe compared the results only if there is at least one biological process in both $P_{att}$ and $P_{dgea}$. The metrics we compute are :\n- The maximal absolute l2fc value in the biological processes: $\\max_{T \\in P_{\\mathrm{att}}}  \\max_{(g, \\mathrm{l2fc}, \\mathrm{att}) \\in T} |\\mathrm{l2fc}|$\n- The maximal attribution score in the biological processes: $\\max_{T \\in P_{\\mathrm{att}}} \\max_{(g, \\mathrm{l2fc}, \\mathrm{att}) \\in T} \\mathrm{att}$\n- IoU of pathways : $\\frac{\\left| P_{\\mathrm{att}} \\cap P_{\\mathrm{dgea}} \\right|}{\\left| P_{\\mathrm{att}} \\cup P_{\\mathrm{dgea}} \\right|}$\n- IoU of genes : $\\frac{\\left| G_{\\mathrm{att}} \\cap G_{\\mathrm{dgea}} \\right|}{\\left| G_{\\mathrm{att}} \\cup G_{\\mathrm{dgea}} \\right|}$ with $G_{\\star} = \\bigcup_{T \\in P_{\\star}} \\{ g \\mid (g, \\mathrm{l2fc}, \\mathrm{att}) \\in T \\}$\n\nResults: First, we observe minimal overlap between the biological processes detected by the two methods (mean IoU of 0.068 for scGPT and 0.025 for scVI) and between the genes within these processes (mean IoU of 0.055 for scGPT, 0.027 for scVI), demonstrating the need to choose one of the methods. As expected, biological processes identified through classic DGEA-based GSEA contain genes with higher absolute log2 fold change (mean 4.0 vs. 2.6 for scGPT, 4.7 vs. 2.4 for scVI), whereas the biological processes identified with the attribution-based method contain genes with higher attribution scores (mean 0.32 vs. 0.17 for scGPT, 0.21 vs. 0.14 for scVI). Deletion curves (shown in the Appendix) further indicate that genes identified via attribution exert a greater impact on concept activation than those identified via DGEA. Together, these results justify the use of attribution-based GSEA for concept interpretation, as the resulting biological processes more accurately reflect the signal associated with the concept.\n\nModifications to the paper: we have added this analysis to Appendix C."}}, "id": "EvjaWEV0L5", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763718765910, "cdate": 1763718765910, "tmdate": 1763718765910, "mdate": 1763718765910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common answer (3/3)"}, "comment": {"value": "**4. Further justify the choice of the decomposition approach (reviewers YuVv and mM9A)**\n\nThe reviewers requested justification for the use of TopK SAE over other decomposition approaches, such as different SAE architectures or low-rank decomposition methods.\nThe objective of this work is not to compare several decomposition approaches, but rather to introduce methods for interpreting and validating the extracted concepts. The methods and framework we propose are not specific to TopK SAEs and other concept extraction methods could be used seamlessly, such as Non-Negative Matrix Factorization (NMF, used in [1] for instance) or other SAE architectures like vanilla SAE [2] or Matryoshka SAE [3]. We chose SAEs over decomposition methods like ICA or NMF following the results of [4], which shows that SAEs have lower reconstruction errors at fixed sparsity. We then decided to use TopK SAE as it simplifies tuning and improves the reconstruction-sparsity frontier compared to vanilla SAE [5].\n\nModifications to the paper: we clarified the choice of TopK SAE in the \"Background on concept extraction\" section.\n\n[1] Fel, Thomas, et al. \"A holistic approach to unifying automatic concept extraction and concept importance estimation.\" Advances in Neural Information Processing Systems 36 (2023): 54805-54818.\n\n[2] Huben, Robert, et al. \"Sparse autoencoders find highly interpretable features in language models.\" The Twelfth International Conference on Learning Representations. 2023.\n\n[3] Bussmann, Bart, et al. \"Learning Multi-Level Features with Matryoshka Sparse Autoencoders.\" Forty-second International Conference on Machine Learning.\n\n[4] Fel, Thomas, et al. \"Archetypal SAE: Adaptive and Stable Dictionary Learning for Concept Extraction in Large Vision Models.\" Forty-second International Conference on Machine Learning.\n\n[5] Gao, Leo, et al. \"Scaling and evaluating sparse autoencoders.\" The Thirteenth International Conference on Learning Representations."}}, "id": "oyp8f9v7bi", "forum": "2ph3Tnu6lK", "replyto": "2ph3Tnu6lK", "signatures": ["ICLR.cc/2026/Conference/Submission19604/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19604/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission19604/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763718826432, "cdate": 1763718826432, "tmdate": 1763718826432, "mdate": 1763718826432, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}