{"id": "ao7VBbvWIK", "number": 18930, "cdate": 1758292079748, "mdate": 1762960448982, "content": {"title": "HASTE: Hybrid AST-guided Selection with Token-bounded Extraction", "abstract": "The rise of Large Language Models (LLMs) has opened new frontiers in software engineering, promising to automate complex tasks from bug fixing to large-scale refactoring. However, this promise is critically hampered by a fundamental constraint: the limited context window of these models. This limitation forces a difficult trade-off in context retrieval. On one hand, structure-aware approaches preserve syntactic integrity but often fail to pinpoint the most semantically relevant code for a given task. On the other, relevance-focused techniques excel at finding pertinent snippets but risk severing critical structural dependencies, leading to incoherent code that causes LLMs to hallucinate.\n\nTo resolve this trade-off, we introduce HASTE (Hybrid AST-guided Selection with Token-bounded Extraction), a novel framework that synergistically integrates robust information retrieval with deep structural analysis. HASTE leverages the Abstract Syntax Tree (AST), combining lexical and semantic search to ensure the extracted code is not only topically relevant but also structurally coherent and executable. Our evaluation, conducted using a robust LLM-as-a-judge framework, demonstrates that HASTE achieves upto 85% code compression while significantly improving the success rate of automated code edits and maintaining high structural fidelity, thereby reducing model-generated hallucinations. HASTE represents a key step towards enabling reliable and scalable AI-assisted software development.", "tldr": "", "keywords": ["Code Comprehension", "Large Language Models", "Context Retrieval", "Abstract Syntax Tree", "Automated Program Repair", "Context Compression"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/81774fe8d1e18c85c90132a6bad0c696114415a8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose using AST information to ensure the correct syntax of code snippets retrieved as additional context for LLMs during code tasks. They also ensure that the syntax remains valid during context compression, thereby further enhancing the usefulness of the retrieved information. They validate the approach, which they name HASTE, on a curated dataset and on SWE-Polybench. They demonstrate the performance in terms of LLM-as-judge and compression ratio."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Proposes syntax-aware data retrieval"}, "weaknesses": {"value": "- The paper seems to confuse what syntax and structure either in the description of the method, or for the method itself (the writing is not clear enough to allow this reviewer to distinguish these cases)\n- It remains unclear why LLMs require valid syntax rather than being resilient to syntax noise\n- The LLM-as-judge scores are not grounded in manual analysis (especially given the small dataset for the curated case)\n- The LLM-as-judge has scores across multiple dimensions; only the aggregate score is reported\n- Paper format issues: Figure 1 is a raster image and of low quality, making reading difficult; the paper does not seem to use the ICLR paper template."}, "questions": {"value": "Q1: How did you select the curated dataset?\nQ2: What licenses do you allow in the data ingestion? How do you ensure compliance with software licenses?\nQ3: How do you assess the hypothesis that LLMs are vulnerable to syntax noise? (There is a naive truncation baseline, but the results seem unreported)"}, "flag_for_ethics_review": {"value": ["Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "It is unclear if the authors perform ethical crawling (is the data ingested permissively licensed, and does the data allow use for AI training).\nIt is unclear if the authors allow a mechanism for opt-out from crawling.\nThe curated dataset has missing details: what projects? Under what license? How were they selected?"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4j7xnE4O4k", "forum": "ao7VBbvWIK", "replyto": "ao7VBbvWIK", "signatures": ["ICLR.cc/2026/Conference/Submission18930/Reviewer_Wkb8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18930/Reviewer_Wkb8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18930/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959382731, "cdate": 1761959382731, "tmdate": 1762930917094, "mdate": 1762930917094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "0Uw0k3QFsa", "forum": "ao7VBbvWIK", "replyto": "ao7VBbvWIK", "signatures": ["ICLR.cc/2026/Conference/Submission18930/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18930/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762960447996, "cdate": 1762960447996, "tmdate": 1762960447996, "mdate": 1762960447996, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes HASTE, a code context retrieval framework that attempts to exploit structural information from Abstract Syntax Trees (AST) and combine it with semantic search from code. This architecture aims to address the context window limitations of LLMs when handling large codebases.\n\nThis work includes a minimal evaluation on 6 undisclosed Python files. Here the context compression is quantified by measuring the quality of “automated edits” listed in Table 2 (there are no details on these tasks). The abstract and introduction are stating that the approach yields up to 85% rate of context compression, yet it is not clear how good this is since there is no quantitative comparison to other state-of-the-art techniques.  \n\nOverall, a lot of technical details are left out (on methods and evaluation) and there is no appendix or supplementary materials to understand them better."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The problem of context compression for code-related tasks is still relevant despite of the very large context window sizes of recent LLMs.\n- The idea of combining semantic relevance and structural coherence has some merit and was already exploited successfully in pre-LLM research, e.g. https://arxiv.org/abs/1910.00577 ."}, "weaknesses": {"value": "- The overall quality of the presentation, evaluation, and related work of this submission is way below the standards of ICLR or even most 2nd tier conferences. Lack of essential information makes it impossible to judge the conceptual contribution adequately. There are too many issues to improve so the following is just a sample of most striking problems.\n- The paper lacks even basic information on the approach (e.g. the key parts like the “Embedding Generator” and “Index Builder” in Sec. 3.2). Also, most other aspects are not sufficiently explained, for example the evaluation metrics (Sec. 4.2), the “automated edits” tasks, test files and other data, parameter settings (e.g. the LLM employed as a Judge), and other aspects crucial for ensuring the reproducibility of the results.\n- Although the paper positions the trade-off between semantic relevance and structural coherence as its central focus, it fails to clarify how HASTE quantifies this trade-off at the methodological level, leaving its main contribution at a conceptual level.\n- The chosen baseline methods (e.g., IR-only, AST-only, naive truncation) are overly simplistic and do not compare against state-of-the-art approaches, failing to convincingly demonstrate the true advantages of the proposed framework. There is no comparison to prior state-of-the-art work.\n- For failure cases in the experiments, the paper simply attributes them to “fundamentally flawed initial suggestions” or “LLM misinterpreting the task,” without critically examining the quality of its retrieved context, resulting in insufficient analytical depth.\n- The benchmark used to address the core research question (RQ2) consists of only six Python files. Conclusions drawn from such a small sample are unreliable.\n- The paper does not follow the formatting guide of ICLR and has partially bad structure (e.g. in Introduction)."}, "questions": {"value": "- How does this approach compare to state-of-the-art baselines?\n- Clarify how HASTE quantifies and manages the trade-off between semantic relevance and structural coherence.\n- Provide the missing details, including the methodology, the Judge-LLM model, evaluation prompts, and key parameter settings, etc."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HQYkAZCuyf", "forum": "ao7VBbvWIK", "replyto": "ao7VBbvWIK", "signatures": ["ICLR.cc/2026/Conference/Submission18930/Reviewer_6h7r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18930/Reviewer_6h7r"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18930/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987434473, "cdate": 1761987434473, "tmdate": 1762930916386, "mdate": 1762930916386, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}