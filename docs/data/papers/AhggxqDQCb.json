{"id": "AhggxqDQCb", "number": 9915, "cdate": 1758148671527, "mdate": 1759897686763, "content": {"title": "Planner and Executor: Collaboration between Discrete Diffusion And Auto-regressive Models in Reasoning", "abstract": "Current reasoning models achieve high accuracy but require long token sequences, making them costly. \nDiscrete diffusion language models (DDLMs) offer parallel, flexible generation within a fixed number of tokens. \nThis motivates a hybrid design where a DDLM serves as the planner and an autoregressive model (ARM) as the executor, combining efficiency with accuracy. \nWe conduct a systematic study of such planner--executor pairings across text- and latent-space collaboration. \nResults show that DDLM$\\to$ARM collaboration is most effective, especially when interaction occurs in latent space. \nA learned projector maps DDLM latents into the ARM’s embedding space, \nbypassing some of diffusion’s limitations and enabling substantial gains on challenging reasoning tasks.\nFor instance, when DDLM$\\to$ARM communication shifts from text space to latent space, accuracy improves from 27.0\\% to 54.0\\% on DART-5 and from 0.0% to 14.0% on AIME24.\nWith only 64 planner tokens and $\\sim$5 executor tokens, the latent-space pipeline surpasses Qwen3.1-7B on DART-5 and AIME while \nonly using 1.9-2.2% tokens, and performs slightly below DeepSeek-R1 while operating with a similarly negligible token budget and only a 3B-sized executor.\nThese findings highlight that diffusion's global revision and autoregression's finalization are complementary, and that latent exchange enables budget-aware reasoning without sacrificing robustness.", "tldr": "Collaboration between Discrete Diffusion And Auto-regressive Models in Reasoning", "keywords": ["Diffusion Language Models (DLLMs)", "Large Language Models (LLMs)", "Hybrid Architectures"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/40cf1311bc046938381643f194911d3f6bbbeab4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates a hybrid \"planner-executor\" framework for reasoning tasks, combining a Discrete Diffusion Language Model (DDLM) as the planner and an Autoregressive Model (ARM) as the executor. The core contribution is the exploration of two collaboration channels: text-space and latent-space, with the latter using a learned projector to map DDLM states into the ARM's embedding space. The central claim is that this hybrid approach, particularly with latent-space communication, achieves competitive reasoning accuracy with a drastically reduced token budget."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The \"DDLM-ARM\" cooperation framework is worth studying.\n- I agree that DDLM has advantages on token budget control, providing a more controlable thinking process.\n- The study provides a systematic comparison of different planner-executor pairings (ARM→ARM, DDLM→DDLM, ARM→DDLM, DDLM→ARM) and collaboration spaces (text vs. latent)."}, "weaknesses": {"value": "- Usually, reasoning algorithms require experiments on MATH / Code generation or common reasoning tasks like GPQA. This paper lacks most of these benchmarks. For AIME, it is doubtful that all these models only achieve near zero on AIME. The metrics are too low.\n- Moreover, Tab. 1 demonstrates a large degradation in all evaluated metrics. Make the effectiveness of the \"planner-executor\" framework doubtful.\n- Actually, I do not think text space cooperation could do harm to the performance as in Tab. 1. By writing a better prompt, it should be at least the same performance without collaboration.\n- As to latent space collaboration, there lacks a comparison between using ARM and DDLM as the planner.\n- Moreover, the authors do not provide any specific examples to see what plan and answer will the models generate.\n- Layout and grammar mistakes (like line changes in L027 & L055)"}, "questions": {"value": "1. If we choose latent space, how many times will the DDLM conduct the forward pass? I suppose it to be only once. If only once, AR model can also be used with fixed token budget and high-level semantics. What is its advantage over AR model.\n2. Have the authors tried to finetune this collaboration framework with RL for reasoning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8Ecgqg7yWA", "forum": "AhggxqDQCb", "replyto": "AhggxqDQCb", "signatures": ["ICLR.cc/2026/Conference/Submission9915/Reviewer_54Fx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9915/Reviewer_54Fx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835345167, "cdate": 1761835345167, "tmdate": 1762921372856, "mdate": 1762921372856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the high computational cost (i.e., token count) of reasoning in high-performing Autoregressive Models (ARMs), which typically rely on long chain-of-thought sequences. It proposes a hybrid planner-executor framework that combines the strengths of ARMs with those of Discrete Diffusion Language Models (DDLMs), which can generate content in parallel with a fixed token budget."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The primary strength is the highly effective proposal of a latent-space DDLM $\\rightarrow$ ARM collaboration. This work moves beyond just using diffusion as another text generator and instead leverages its internal representations for planning, which is a significant conceptual leap. The resulting improvement in token efficiency for complex reasoning is a major finding.\n- The systematic comparison of all four planner-executor pairings and both communication channels (text vs. latent) provides a complete picture. The diagnostic failure analysis (Sec 5.1) is a key strength, providing a data-driven justification for the paper's core hypothesis.\n- The gains are not marginal. The leap from 0.0% to 14.0% on AIME and 27.0% to 54.0% on DART-5 by switching from text to latent space is dramatic. Beating a strong baseline (Qwen3) on these tasks with ~98% fewer tokens is a highly compelling result"}, "weaknesses": {"value": "- The major weakness of the paper is the lack of novelty. Simply plugging the Diffusion Models to the ARMs without further analysis and algorithm design is weak for an academic paper at ICLR.\n- The details of the alignment between the Diffusion Models and the ARM are omitted. For instance, how do you configure the Diffusion Models? How do you determine the time step to extract the latent representation or text output? It introduced lots of confusion here. The text output is obtained from the final hidden representation after an embedding map. Do you use the final hidden representation as the latent space input for ARM or intermediate hidden representation?\n- The experiment settings are insufficient and unorganized. The experiments demonstrated in Table 1 fail to clearly present the comparison between different settings. Please reconsider your choice and determine the critical data which can support your argument."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aab1t4Thnk", "forum": "AhggxqDQCb", "replyto": "AhggxqDQCb", "signatures": ["ICLR.cc/2026/Conference/Submission9915/Reviewer_nR4U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9915/Reviewer_nR4U"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948141166, "cdate": 1761948141166, "tmdate": 1762921372165, "mdate": 1762921372165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work explores developing hybrid frameworks that combine both discrete diffusion language models (DDLM) and autoregressive language models (ARM) for reasoning tasks. Broadly they consider pipelined approaches where one model acts as the “planner” and the other model acts as the “executor”. They present results for multiple choice and math benchmarks across various instantiations of this general framework, integrating both token plans and latent plans (e.g. final layer features) with a trainable projection layer."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This paper presents an interesting approach for combining the strengths of two different generation paradigms: diffusion LMs and AR LLMs. \n\nThe authors present a comprehensive sweep over instantiations of their planner/executor framework. They analyze using diffusion LMs and AR LMs for either role and additionally explore using latent plans instead of raw textual outputs.\n\nThe diagnostic analysis is a smart experimental setup to probe the behavior of different configurations and identify the source of different errors."}, "weaknesses": {"value": "I don’t think the motivation for combining DLMs and AR LMs is very convincing. It is widely accepted that introducing some textual reasoning before answering can be more effective than answering directly (chain-of-thought, R1, etc.). I don’t think the benefit of using a diffusion model to generate the plan then generating the answer with an autoregressive model is very clear.\n\nThe experimental results in Table 2 are generally mixed and are very difficult to parse. It presents 100+ results and the organization makes it challenging to compare the collaboration results with their base models, etc.. Without some kind of aggregation, it is very difficult to observe trends by just inspection. It does not look like the collaboration consistently outperforms both constituent models. Or the simpler setting of using one model to serve as both roles.\n\nWhile the latent plan idea is interesting, it is also SFT-ing directly on the target task while all other results are 0-shot. It can essentially act as a form of prefix-tuning with ground truth labels which would likely lead to downstream performance improvements regardless of the addition of the “plan”. I suspect the gold supervision is a strong contributor to the improvement in that setting.\n\nWhile efficiency is discussed in terms of the number of tokens, the discussion is very incomplete. Discrete diffusion models are generally significantly slower than corresponding autoregressive models of the same scale due to the lack of kv-caching, so the token budget paints an incomplete picture. Furthermore, just focusing on tokens for the executor is incomplete. Generating the plan also has overhead."}, "questions": {"value": "What is the inference overhead of various configurations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rhY0kprUCY", "forum": "AhggxqDQCb", "replyto": "AhggxqDQCb", "signatures": ["ICLR.cc/2026/Conference/Submission9915/Reviewer_gaaM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9915/Reviewer_gaaM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959265119, "cdate": 1761959265119, "tmdate": 1762921371758, "mdate": 1762921371758, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores a hybrid reasoning framework that combines Discrete Diffusion Language Models (DDLMs) and Autoregressive Models (ARMs). The authors systematically study four planner–executor configurations (DDLM and ARM, text vs. latent collaboration) and find that DDLM to ARM collaboration in latent space achieves the best performance. Experiments show large gains on reasoning benchmarks like DART-5 and AIME24, demonstrating that latent-space communication can provide both efficiency and accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Provides a systematic exploration of planner–executor combinations between DDLMs and ARMs, covering both text-space and latent-space collaboration.\n\n2. Demonstrates that latent-space communication enables more efficient and accurate reasoning, offering a practical way to combine diffusion’s global planning with autoregression’s step-by-step precision."}, "weaknesses": {"value": "1. The comparison may not be fully fair: while DDLM-generated planning is performed zero-shot, the latent-space variant involves additional training. Although the authors claim no overlap with benchmark datasets (e.g., MMLU, DART), the training data are all math-related, making it unclear whether the observed AIME improvements stem from training effects rather than the latent vs. discrete planning difference. Hence, the conclusion in Figure 3 is not fully supported.\n\n2. Section 4.3 concludes that using AR as planner and DDLM as executor yields better results, but Section 5 shifts focus to DDLM as planner without explaining the motivation or rationale for this change—this weakens the conceptual coherence of the study."}, "questions": {"value": "1. Some line breaks in the paper are inconsistent (e.g., line 026 and line 054).\n2. The paper lacks training details (e.g., GPU type, batch size, learning rate, training duration), which makes it difficult for others to reproduce the results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2i5TOkxq0X", "forum": "AhggxqDQCb", "replyto": "AhggxqDQCb", "signatures": ["ICLR.cc/2026/Conference/Submission9915/Reviewer_ChMx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9915/Reviewer_ChMx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762056236573, "cdate": 1762056236573, "tmdate": 1762921371378, "mdate": 1762921371378, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}