{"id": "rb7rnOSa2g", "number": 25446, "cdate": 1758368146627, "mdate": 1759896720881, "content": {"title": "Latents-Inv:Robust Semantic Watermark with Key-Assisted Recovery for diffusion models", "abstract": "Semantic watermarking provides imperceptible identity traceability for diffusion-generated images, enabling model copyright protection and image source verification. However, existing semantic watermarking methods based on initial latent noise render the protected image vulnerable to adversarial latent-space manipulations, such as black-box forgery via proxy models and watermark-pattern-removal attacks that exploit statistical regularities. In this paper, we propose a robust watermarking framework resilient diverse adversarial manipulation attack. Specifically, we design a fully reversible, flow-based codec with dual encoding paths, allowing plug-and-play integration into the diffusion generation process across architectures (UNet and MMDiT). The dual-output network encodes watermark information into both the carrier image and the owner’s secret key, enabling recovery of removal attacked watermark via key-assisted reconstruction. To guarantee verification reliability without excessive reliance on the key while retaining the ability to detect forged watermarked images, we propose a joint-training strategy that leverages negative-sample pairs under both accuracy and fidelity constraints. Furthermore, we introduce an Euler-based enhanced solver for the effective inversion in rectified flow models, which improves the accuracy of watermark information recovered. Experimental results show that our method achieves superior robustness under various attacks while maintaining high visual quality across diverse models.", "tldr": "", "keywords": ["watermark", "AI Security", "diffusion model"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/953f565cb7f04df0535f50c851a11c19dacee315.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work proposes a new watermarking method for diffusion models. The key idea is to train a codec/decoder to transform the input \"sampled latents + watermark\" into output \"new latents + key\", and then diffusion on the new latents to generate images. The authors show that their method is robust to various common image distortions compared to Tree-Ring and Gaussian-Shading."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "+ The new method addresses the robustness issues mainly by retaining a key that goes through the codec together with the latents. So this key essentially captures watermark information together with the transformed latents. If an image is distorted, leading to watermark damage, then the above key retained by the owner could help to restore watermark information, hence improving robustness.\n\n+ Compared to the recent training-free works Tree-Ring and Gaussian-Shading, this work Latents-Inv indeed improves robustness on various image transformations."}, "weaknesses": {"value": "- The paper is written and presented in a poor way, making it challenging for readers to follow and appreciated their contribution (see my questions and suggestions below).\n\n- The design of the codec/decoder network architecture lacks explanation.\n\n- The usage of retained key seems to be a double-edged sword. It leaves a complicate question of how to store and manage such keys, and how to match a retained key with a query image during detection.\n\n- The experimental comparison is not sufficient.\n\n- The fidelity of generated images should be evaluated in more formal and quantifiable metrics."}, "questions": {"value": "- The codec architecture is unclear. In equation (1) and (2), what's update network? What's diffusion sub-networks? Could you provide intuition and explanation on the block design? How do you finally achieve such formulas?\n\n- In equation (3) and (4), these symbols do not align with Figure 2.\n\n- How do you manage the output private keys? Given a query image, how to you match it with a key? Do you enumerate all keys in a database?\n\n- Give more intuition on Equation (5).\n\n- Explain equation (7). It is hard to connect this with the text about negative sample pairs.\n\n- Expand the computation of the magic number \"0.6930\" in equation 8.\n\n- This work, as a training-based watermark, should also compare with Stable Signature, which is also a training-based watermark. It cannot just compare with training-free methods Tree-Ring and Gaussian-Shading.\n\n- The experiment in Figure 6 is good but informal.  You should give a quantifiable metric across a dataset for fidelity evaluation (such as FID), instead of just showing results for several examples."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Gm7xCzdfSx", "forum": "rb7rnOSa2g", "replyto": "rb7rnOSa2g", "signatures": ["ICLR.cc/2026/Conference/Submission25446/Reviewer_d9er"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25446/Reviewer_d9er"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761014993559, "cdate": 1761014993559, "tmdate": 1762943433762, "mdate": 1762943433762, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Latents-Inv, a semantic watermarking framework for diffusion models. It uses a fully reversible, flow-based codec with dual outputs to embed watermark information jointly into (i) the carrier’s latents and (ii) an owner’s private key, enabling key-assisted recovery when a watermark is damaged. To support newer rectified-flow models (e.g., SD3/FLUX), the paper adopts an Euler-style “Uni-Inv” inversion procedure for watermark extraction."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Timely problem & cross-architecture aspiration. The paper targets robustness to modern removal/forgery attacks and explicitly aims to work across UNet and MMDiT/rectified-flow architectures, a relevant and important goal for the community."}, "weaknesses": {"value": "1. Incomplete submission (Appendices missing). The manuscript cites appendices for essential proofs/analyses, but no appendix is present in the provided materials/supplement, making key claims unverifiable. \n\n2. No objective visual quality metrics. Evaluation focuses on watermark bit-accuracy without standard image visual quality metrics (e.g., CLIP-Score, FID), so the trade-off between robustness and perceptual quality is unclear. \n\n3. Ablation studies are absent. There is no ablation isolating contributions (e.g., dual-output codec vs. single-channel, key-assisted recovery, coarse- vs. fine-grained decoder), leaving the source of gains ambiguous. (No “ablation” section appears in the provided manuscript.)"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WI2DjT6Tz2", "forum": "rb7rnOSa2g", "replyto": "rb7rnOSa2g", "signatures": ["ICLR.cc/2026/Conference/Submission25446/Reviewer_TCpC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25446/Reviewer_TCpC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761032551677, "cdate": 1761032551677, "tmdate": 1762943433589, "mdate": 1762943433589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Latents-Inv, a semantic watermarking framework for diffusion models that embeds the watermark in the initial latent space via a reversible flow-based codec with a dual-output design: one branch goes into the carrier latents that generate the image, and the other is stored as a private key. When the carrier watermark is degraded by attacks, the key enables key-assisted recovery to improve robustness. Training uses a joint objective with negative sample pairs to limit over-reliance on the key while enabling forgery rejection under accuracy and fidelity constraints. The paper also adopts Uni-Inv (Euler) for Rectified-Flow models to improve inversion accuracy, enabling extraction across UNet and MMDiT backbones. Experiments on SD1.5/2.1/3 and FLUX under multiple attacks suggest improved robustness over existing methods with small visual differences from the originals."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of a reversible flow codec, dual channels (carrier/key), and coarse/fine decoders supports recovery while suppressing overfitting to the key; the overall design is coherent.\n\n2. The paper discusses inversion differences between UNet/DDIM and MMDiT/Rectified-Flow and uses Uni-Inv (Euler) to stabilize RF inversion, aiding generality.\n\n3. Reported results outperform prior methods, with minor visual differences between watermarked and original images."}, "weaknesses": {"value": "1. Writing is difficult to follow. The logical flow is unclear, transitions are abrupt, and key concepts (e.g., invertible block, update network, diffusion sub-networks, flow-based codec) are insufficiently defined. Several statements are vague (e.g., “Pre-processing primarily employs mathematical techniques for channel expansion”) without a concrete explanation.\n\n2. Figures 1 and 2 are not self-explanatory and lack clear guidance, making it hard to understand the method.\n\n3. The dual-output design implies better decoding with the key. Although a coarse key-free decoder is provided, the paper does not report its performance under attacks. This raises the concern that without the key and under attack, detection may fail. The paper should quantify key dependence across scenarios.\n\n4. Insufficient analysis of compute/latency: extra memory and compute for the flow codec, the impact of inversion steps on throughput, and compatibility with production samplers/schedulers are not adequately evaluated. The work focuses on accuracy without a cost–benefit profile.\n\n5. Image quality is shown only via visuals; quantitative metrics (e.g. FID) are missing."}, "questions": {"value": "1. What are the degradation curves of the fine decoder when the key is partially corrupted, fully missing, or tampered with? How robust is the coarse-grained decoder (no-key) against various attacks?\n\n2. What are the additional memory and compute overheads for encoding/decoding and for training?\n\n3. What are the FID (and related) comparisons between original and watermarked images?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ySSaGi9I25", "forum": "rb7rnOSa2g", "replyto": "rb7rnOSa2g", "signatures": ["ICLR.cc/2026/Conference/Submission25446/Reviewer_4QJ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25446/Reviewer_4QJ1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761788489066, "cdate": 1761788489066, "tmdate": 1762943433321, "mdate": 1762943433321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a robust and invertible watermarking framework that acts directly on the diffusion process. The authors introduce a flow-based model which achieves consistency between the latent and key that ultimately helps to protect against forgery attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Integrates into a wide class of models (Uiet and MMDiT)\n\n- Empirical results seem kind of promising\n\n- I think flow-based models do make sense for this task and the entangling of the key + latent creates mutual consistency that allows for forgery and damaged watermark detection"}, "weaknesses": {"value": "- Baselines are very limited although Gaussian-Shading  & Tree-Ring are good to include. I would be interested in performance against Seal, Aqualora, and etc.\n\n- Dataset is kind of limited (more kinds of images would be better)\n\n- Formatting and typo issues make it difficult to read. Please be precise about how you cite work in your paper. Difference between \\citet and \\citep (feels rushed).\n\n- Attacks are way to simple. Please include regeneration, rotation, and etc (as well as more difficult combination attacks). WAVES provides a good benchmark for this (not all are needed)\n\n- Although the method is new, besides the meshing of the key + latent with a flow network it doesn't feel all the novel. And that too has been done in the past in a different way.\n\n- No image quality metrics presented"}, "questions": {"value": "- I don't think that the architectural backbone is very relevant as many modern watermarking methods don't care about the architecture bur rather the distribution of the latent space and DDIM sampling. Maybe I am misunderstanding this claim.\n\n- I wonder if training is very expensive in practice because of the need for feedback from the diffusion models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ebS2KR0icR", "forum": "rb7rnOSa2g", "replyto": "rb7rnOSa2g", "signatures": ["ICLR.cc/2026/Conference/Submission25446/Reviewer_ASUC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25446/Reviewer_ASUC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986487667, "cdate": 1761986487667, "tmdate": 1762943433035, "mdate": 1762943433035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}