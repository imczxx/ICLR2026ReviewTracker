{"id": "px6NxcBhBV", "number": 11397, "cdate": 1758198116350, "mdate": 1763052304239, "content": {"title": "Adversarially Injected Diagnosis for Coherent Visual Autoregressive Generation", "abstract": "Visual Autoregressive (VAR) models, despite their formidable generative capa-\nbilities, accumulate local prediction errors across scales, leading to detail loss and\nlocal distortions. To address this, we introduce AID-VAR, a plug-and-play method\nthat improves pretrained VARs via Adversarially Injected Diagnosis. Inspired by\nGANs, we train a discriminator to detect visual errors in generated samples and\nuse an adversarial objective to pull generations toward the manifold of real im-\nages. To avoid the computational and stability issues of directly updating the\nVAR, we attach a lightweight guidance injector that conditions on previously gen-\nerated scales of a pre-trained and frozen VAR and injects adversarial features to\nguide the next scale. To quantify reductions in cross-scale errors, we introduce\nthe Inter-Scale Consistency Score (ISCS), which measures the fidelity of transi-\ntions between consecutive scales. Across standard VAR backbones, AID-VAR\ndelivers sharper details, fewer local distortions, and stronger global coherence at\nremarkably low computational cost, adding negligible parameters and minimal\ncomputational overhead. Our results establish AID-VAR as a practical pathway\nfor upgrading large VAR generators with adversarial feedback, without modifying\ntraining data, base architecture, or sampling schedules. For instance, our AID-\nVAR-d20 improves FID by 16%, with only 3% parameters increase.", "tldr": "This paper introduces a lightweight, plug-and-play module that uses adversarial guidance to improve the global coherence of large, frozen generative models.", "keywords": ["Visual Autoregressive Models (VARs); Image Generation; Adversarial Learning; Generative Models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/6feae5d2eed136bd1f018558eee79f74ecf33b14.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes AID-VAR, a method to mitigate error accumulation in pre-trained Visual Autoregressive (VAR) models. The core idea is to attach a lightweight, trainable \"guidance injector\" to a frozen VAR. This injector is trained adversarially using a discriminator that operates in the RGB space. The injector conditions on features from previously generated scales and produces a spatial guidance map that is added to the VAR's internal state to steer the next-scale prediction. A \"soft-label decoding\" is designed to ensure differentiability from RGB back to the injector. The paper also introduces a new metric, the Inter-Scale Consistency Score (ISCS), to quantify the coherence between consecutive generation scales. Experiments on ImageNet demonstrate improvements in FID, IS, and the proposed ISCS over the base VAR models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The idea of using a small, adversarially-trained add-on module to correct a large, frozen VAR model is novel and practical.\n\nThe paper provides a thorough quantitative evaluation against strong baselines.\n\nThe introduced ISCS metric may be useful in evaluating the multi-scale refinement process of VAR-like models."}, "weaknesses": {"value": "The writing, while generally understandable, suffers from verbosity and a lack of precision in several critical sections. This reduces the paper's impact and makes it difficult to grasp the finer details of the method. Inconsistent and sometimes unclear notation further exacerbates this issue.\n\nThe central claim—that AID-VAR mitigates \"local prediction errors accumulate across scales\"—is not sufficiently analyzed or visualized. The qualitative results (Fig. 4) show final image improvements but do not clearly demonstrate the process of error correction across scales. Figure 5, intended for this purpose, is confusing and seems to show that AID-VAR also suffers from significant structural issues, which contradicts the narrative of preventing error accumulation from the start.\n\nSeveral important implementation details are either missing from the method description or are confusingly presented. This lack of rigor undermines the reader's confidence and hampers reproducibility."}, "questions": {"value": "The paper would be significantly strengthened by a more detailed analysis of the VAR's failure mode. How exactly do \"local errors\" manifest and propagate? Please provide clearer visualizations to demonstrate that AID-VAR specifically reduces error accumulation, rather than just improving the final output.\n\nIn Figure 5, the AID-VAR generation (middle row) at scale 9 appears to suffer from severe structural degradation around the tail. Please clarify this result. \n\nThe notation needs careful revision. There is no distinction between scalars, vectors and matrices. Important definitions, such as that of $f_{VAR}$, are missing. Please review all equations for consistency and clarity.\n\nThe guidance weight parameter w mentioned in Sec. 5.1 is not defined in the methodological sections. Please introduce it formally when the guided inference process is described.\n\nIn Figure 2, the terms \"real samples\" and \"fake samples\" are used to denote multiple variables, which is confusing. Furthermore, the real/fake samples of $S_1$, $S_2$, $S_3$ and $S_4$ may be confused with the discrete code after vector quantization. This is a critical detail that should be made explicit in the main text and in Figure 2.\n\nWhat is the impact of using soft-label decoding on the real images fed to the discriminator? Does this introduce blur or artifacts that might weaken the adversarial signal? A brief discussion or analysis is needed.\n\nWhat are the differences between the training loop in Sec. 3.3 and that of the standard GANs? The claim that it is a \"key strategy\" for \"on-the-fly refresh\" should be rephrased to clarify its novelty.\n\nWhy should we use the inverse Fréchet Distance in Equation (9), instead of the FD itself mimicking the FID?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JOEnPCjMfa", "forum": "px6NxcBhBV", "replyto": "px6NxcBhBV", "signatures": ["ICLR.cc/2026/Conference/Submission11397/Reviewer_zatQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11397/Reviewer_zatQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636744559, "cdate": 1761636744559, "tmdate": 1762922517375, "mdate": 1762922517375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "WcgneH9JC8", "forum": "px6NxcBhBV", "replyto": "px6NxcBhBV", "signatures": ["ICLR.cc/2026/Conference/Submission11397/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11397/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763052303593, "cdate": 1763052303593, "tmdate": 1763052303593, "mdate": 1763052303593, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work targets improving autoregressive image generation quality.\nTo do this, they employ adversarial training with a GAN inspired objective with a DINO-pretrained discrimnator.\n\nTheir architecture consists of:\n- Base visual autoregressive model (VAR), which they keep frozen\n- Lightweight guidance injector to refine intermediate features\n- Discriminator head using frozen DINO ViT-S/16 backbone\n\nFor training, they use soft-label decoding (straight through estimator) to enable gradients to flow from the discriminator loss to their guidance injector.\n\nThey evaluate on ImageNet 256×256 using FID, IS, and their proposed ISCS (Inter-Scale Consistency Score) metric.\nResults show FID improvements over their baseline VAR-d16/d20/d24 with negligible parameter increase."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-written with clear presentation throughout.\nThe technical sections are detailed and easy to follow.\n\nThe results show good improvements in FID and IS across multiple VAR backbones.\nA key strength is that these gains are achieved while keeping the VAR backbone frozen with minimal architectural changes."}, "weaknesses": {"value": "The paper's experimental section is too concise and does not provide enough insight on some of the architecture/design choices involved in designing their method.\nTable 4 from the appendix provides some analysis on the guidance methods, but this should be included in the main paper, along with more of the analysis.\n\nSince the method relies on the discriminator training signal, ablations comparing the frozen VAR approach against alternatives (e.g., finetuning all weights or selectively unfreezing certain layers) would give insight on the effectiveness of the guidance injector."}, "questions": {"value": "Figure 2 and the inference procedure (Section 3.3) state that \"only the guidance injector is attached to the frozen VAR\" during inference.\nHowever, from the future work section in the appendix, there is a line \"potentially remove the need for the discriminator during inference.\"\nThis statement is a bit puzzling - could the authors clarify whether the discriminator is currently used during inference?\n\nThere appears to be some discrepancy between the baseline performance numbers in Table 1 and those reported in the original VAR Table 1.\nFor example, L-DiT-7B is reported with FID 5.06 and IS 153.3 in Table 1, but VAR's table 1 reports L-DiT-7B with FID 2.28 and IS 316.2.\nCould the authors clarify whether the evaluation protocol differs?\n\nHow important is the DINO discriminator to the method's success?\nIt would be helpful to see ablations comparing DINO against other pretrained visual encoders, or a discriminator trained from scratch."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YhckfGtBPW", "forum": "px6NxcBhBV", "replyto": "px6NxcBhBV", "signatures": ["ICLR.cc/2026/Conference/Submission11397/Reviewer_BkNc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11397/Reviewer_BkNc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762049630915, "cdate": 1762049630915, "tmdate": 1762922516881, "mdate": 1762922516881, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work addresses a key limitation of existing VAR methods: the accumulation of local prediction errors across scales, which leads to a loss of detail and local distortions. To tackle this, the authors introduce a GAN-like discriminator that adversarially guides the generation process toward the real data manifold. They also propose a \"consistency score\" to quantify the fidelity of transitions between consecutive frames. Experimental results demonstrate that this approach achieves improved performance with only a minor increase in parameters."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The manuscript addresses the challenging task of rectifying local imperfections in image generations. The proposed method is novel and demonstrates a marked improvement in generation quality, as evidenced by the experimental results."}, "weaknesses": {"value": "The manuscript's description of the methodology lacks clarity. Furthermore, the experimental design is inadequate, failing to validate the method's effectiveness from multiple perspectives."}, "questions": {"value": "1. There is an apparent contradiction in the interpretation of the ISCS metric. An effective rectification of local errors by AID-VAR should logically lead to a lower ISCS, indicating more substantial corrective changes. This makes the reported higher ISCS values counter-intuitive and requires clarification.\n\n2. The design choice of a single, shared discriminator for all scales warrants justification. The motivation is unclear, and the potential benefits of scale-specific discriminators should be discussed.\n\n3. The description of \"on-the-fly discriminator refresh\" in Section 3.3 is confusing and frames a standard GAN training procedure as a novel component. It is standard practice to update the discriminator concurrently with the generator.\n\n4. The validity of ISCS as a measure of inter-scale consistency is questionable. The calculation in Eq. (9) operates within individual scales and does not directly compare features between scale k-1 and k.\n\n5. To fully showcase the model's capabilities, I suggest expanding the evaluation to include reconstruction quality, latent space controllability, and interpolation smoothness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4AjWNeK7it", "forum": "px6NxcBhBV", "replyto": "px6NxcBhBV", "signatures": ["ICLR.cc/2026/Conference/Submission11397/Reviewer_dvdy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11397/Reviewer_dvdy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762094359220, "cdate": 1762094359220, "tmdate": 1762922516051, "mdate": 1762922516051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors present AID-VAR which is a small auxiliary network trained to inject corrections to the VAR model's visual tokens at a given scale to improve the generation quality. The authors claim that this improvement in the generation quality is due to artifacts formed in the VAR model in earlier scales that propagates with prominence to higher scales . The paper presents results that show an improvement of FID of 16% relative for a 3% param increase without training/fine-tuning the VAR model itself. Finally, the authors also introduce a score for measuring cross-scale consistency."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors introduced AID that is a lightweight module for improving the generative performance of VAR models without training/fine-tuning the VAR model itself\n- Paper is well written and it was easy to grasp the central idea\n- The architectural diagrams were well made and clear\n- Performance improvement of 16% in FID for a 3% increase was achieved by the authors."}, "weaknesses": {"value": "Minor:\n1. Line 74-74: \"Training a disc in contin latent spaces collapses quickly...\" - Please provide citation or evidence for this.\n2. Please mention if Figure 4 images were cherrypicked or randomly picked in the caption.\n\nMajor:\n1. A major issue with the paper is that there is no Evidence presented for the central premise of the paper that \"once a local mistake enters the chain, subsequent decoders amplify rather than correct it\" (Line 39-40) and again on Line 122-124.\n-- Is there a citation to support this claim?\n-- Is this due to some theoretical deductions? (Unlikely because multilayer nets are universal approximators, and in theory, I don't think there is any reason for why a subsequent decoder cannot correct a mistake in the earlier layers. For instance, LLMs share similar autoregressive nature and seem to be fine).\n-- Or is this an empirical claim? Do the authors have evidence to support it by toy experiments or such?\nThe authors provide one (potentially cherry-picked) qualitative figure in Figure 1 to show how an artifact in the lower layer amplifies to an artifact in the higher scale. But there is no systematic empirical / quantitative experiment to back their claims.\n-- What is the Evidence that AID is specifically correcting for such artifacts in lower scales and not affecting non-artifact tokens in the lower scales? \n\nAs far as the reader is concerned, the paper presents a small trainable architecture that improves the overall FID performance by some amount. But the central claim is unfounded in the current form of the paper.\n\n2. Second major problem of the paper is the requirement for Cross-Scale Consistency. It is not clear why this is important for a good-quality high res image generation. \nAny mistakes in a smaller scale *can* be corrected by layers in the future at a larger scale because these are general universal approximator layers. In such a case, cross-scale consistency actually hinders quality by restricting the amount of correction the layer next can do on the previous scale's noisy tokens.\nInfact, with each higher depth in VAR, the model adds more image details that are novel and non-existent in the prev scale. That would reduce the cross-consistency but is not a bad thing.\n\nMoreover, Cross-Scale Consistency must come at the Tradeoff of Diversity/Coverage of Sample Generation, however, no such discussion is presented. If a model has high cross-scale consistency, that should affect the diversity of output samples by reducing it, intuitively.\n\nCross-Scale consistency may be crucial for applications such as Super Resolution where consistency across scales is necessary but such an application is not presented. I do not see why Cross-Scale consistency is needed for a good quality final high-res generation at the highest scale k, and hence the requirement for the new ISCS score designed by the authors.\n\n3. Section 5.3 - Line 418-422: Figure 4 just has the final high res generations. This is insufficient in my view to make any conclusions on the hypothesis presented in the paper about artifacts in lower scales and AID module fixing that problem. Instead please add a figure that includes image reconstructions at each scale for a given image (picked at random) and compare that with your method. If indeed there exists artifacts in the lower scales for the original VAR method with a worser final high-res output compared to the presented AID method, that would be more convincing. \nE.g. the authors talk about a \"ghost wing\" and yet they don't trace it back to lower scales to show what could have caused it and why the network was unable to correct its mistakes.\n\n4. No Qualitative figures presented in the main paper that show the failure modes of AID module. \n\n5. Section 6: Conclusion - \"To address the detail loss and struct distortions in VAR models caused by error accumulation\" -- As discussed before, this is an unfounded claim without experimental / theoretical support.\n\n6. If AID-VAR is seen simply as an lightweight trainable module to increase FID of generations without the unfounded claims of cross-consistency being the root of errors, then it must be also compared with similar architectural baselines such as the style injection architecture of StyleGANs using the BatchNorms, among others."}, "questions": {"value": "In addition to the issues raised in Weaknesses, \n\n1. Fake samples are \"refreshed\" in a GAN training as well, so can the authors please clarify why their on-the-fly disc refresh (Sec 3.3) is novel?\n2. In Eq. 8: for a given real image, how are its low-res images computed? What kernel is used to compute low-res? E.g. bicubic kernel or some other anti-aliasing kernel? And, why?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T1UzsekDVz", "forum": "px6NxcBhBV", "replyto": "px6NxcBhBV", "signatures": ["ICLR.cc/2026/Conference/Submission11397/Reviewer_B48p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11397/Reviewer_B48p"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762270065608, "cdate": 1762270065608, "tmdate": 1762922515120, "mdate": 1762922515120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}