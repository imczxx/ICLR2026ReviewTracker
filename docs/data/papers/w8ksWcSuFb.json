{"id": "w8ksWcSuFb", "number": 8437, "cdate": 1758083509737, "mdate": 1759897783846, "content": {"title": "Relational Feature Caching for Accelerating Diffusion Transformers", "abstract": "Feature caching approaches accelerate diffusion transformers (DiTs) by storing the output features of computationally expensive modules at certain timesteps, and exploiting them for subsequent steps to reduce redundant computations. Recent forecasting-based caching approaches employ temporal extrapolation techniques to approximate the output features with cached ones. Although effective, relying exclusively on temporal extrapolation still suffers from significant prediction errors, leading to performance degradation. Through a detailed analysis, we find that 1) these errors stem from the irregular magnitude of changes in the output features, and 2) an input feature of a module is strongly correlated with the corresponding output. Based on this, we propose relational feature caching (RFC), a novel framework that leverages the input-output relationship to enhance the accuracy of the feature prediction. Specifically, we introduce relational feature estimation (RFE) to estimate the magnitude of changes in the output features from the inputs, enabling more accurate feature predictions. We also present relational cache scheduling (RCS), which estimates the prediction errors using the input features and performs full computations only when the errors are expected to be substantial. Extensive experiments across various DiT models demonstrate that RFC consistently outperforms prior approaches significantly. We will release our code publicly upon acceptance.", "tldr": "", "keywords": ["Diffusion transformer", "Feature Caching"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bd85f59f28e4b4e518ed6c83d05fdb6ae207ef77.pdf", "supplementary_material": "/attachment/bbd3257e7551f065394f893ec61f2b290bf5e9eb.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes an improvement of TayloSeer, motivated by the highly correlated magnitudes of change of input and output features. It uses the change of input features to estimate the change of output, therefore reducing the computation to a large extent. On both text-to-image and text-to-video tasks, RFC manages to achieve better or comparable performances against baselines. Visual results from the paper also support the effectiveness of this method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation of this paper is clear. The empirical results in Figures 1 and 2 serve as strong evidence for the proposed method.\n2. The discussion of related work is thorough, further enhancing the novelty of this paper.\n3. The experimental analysis is comprehensive. The authors validate their method not just on one model or task, but across three distinct, large-scale generative tasks (class-conditional, T2I, T2V) using modern, powerful models."}, "weaknesses": {"value": "Please see the weakness of the method and experiments in the questions.\n\nHere are some weaknesses in the presentation:\n1. The related work section is a bit hard to read with the long paragraph. I suggest the author reorganize this section to improve the readability.\n2. I suggest using the full name of RFE and RCS as the paragraph header."}, "questions": {"value": "1. How does RFC perform on distilled models?\n2. What is the recomputation rate under different parameter settings? In other words, is $\\tau$ hard to tune for different DiT models? It seems this value differs across the DiT models tested.\n3. The empirical results (Figures 1 and 2) are obtained on ImageNet and DiT, which are relatively simple. Are the findings the same in a different case? For example, it might be more convincing to also show empirical results on FLUX.1 dev or HunyuanVideo.\n4. RFC seems to be slower than the baseline. Where does the main overhead come from, and did the author think about how to reduce it?\n5. Did the author study whether shallow layers / early timesteps should be skipped or not to achieve better results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Z9CNxxLaLz", "forum": "w8ksWcSuFb", "replyto": "w8ksWcSuFb", "signatures": ["ICLR.cc/2026/Conference/Submission8437/Reviewer_xGHL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8437/Reviewer_xGHL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761596104581, "cdate": 1761596104581, "tmdate": 1762920328735, "mdate": 1762920328735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Relational Feature Caching (RFC) to accelerate Diffusion Transformers by exploiting correlations between input and output features, rather than relying solely on temporal extrapolation as in prior methods like TaylorSeer. The approach introduces Relational Feature Estimation (RFE) to predict output changes from input variations and Relational Cache Scheduling (RCS) to adaptively trigger full computations based on estimated errors. Experiments on image, text-to-image, and video generation tasks show consistent improvements over existing caching methods in both quality and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear motivation with strong empirical evidence showing the limitation of purely temporal forecasting.\n- Simple yet effective design—RFE and RCS are well-justified and complementary.\n- Comprehensive experiments across multiple diffusion models and tasks."}, "weaknesses": {"value": "- In Table 2, TaylorSeer achieves the highest CLIP scores; the paper should discuss why RFC does not consistently outperform it on semantic alignment metrics.\n- The paper could analyze RFC’s applicability to U-Net–based diffusion models to better demonstrate generality and architectural adaptability."}, "questions": {"value": "- While RFC significantly accelerates DiTs, what happens at higher acceleration ratios (larger N)? A discussion on generation quality degradation at extreme speedups would help readers assess its robustness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "n5Mb3aUEQL", "forum": "w8ksWcSuFb", "replyto": "w8ksWcSuFb", "signatures": ["ICLR.cc/2026/Conference/Submission8437/Reviewer_h2W6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8437/Reviewer_h2W6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761644042564, "cdate": 1761644042564, "tmdate": 1762920328304, "mdate": 1762920328304, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Objective: Accelerate Diffusion Transformers by improving feature caching accuracy. The paper identifies that forecast-based caches suffer from large errors due to irregular output changes and strong input–output correlations in modules. It proposes Relational Feature Caching (RFC) with two components: Relational Feature Estimation (RFE) to predict output-change magnitudes from inputs, and Relational Cache Scheduling (RCS) to estimate prediction error from inputs and trigger full computation only when errors are likely high. Experiments across multiple DiT models show consistent, significant improvements over temporal extrapolation baselines, with planned code release upon acceptance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper studies an important topic of feature caching, which is critical for optimizing the efficiency of diffusion transformers.\n\nThe identification of input–output correlation as a predictor of output changes is insightful and well supported by the empirical analysis.\n\nThe proposed RFC showcase on multiple metrics and settings, demonstrating a comparable to superior performance. The authors also present qualitative results, which are promising."}, "weaknesses": {"value": "The organization of the manuscript needs improvement. There is overlapping and duplicate content across the first three sections. It may be better to defer the detailed discussion of related work to a later section and to reorganize Section 2 and Section 3.1.\n\nWhile the empirical correlation between inputs and outputs is demonstrated, the paper offers little formal analysis explaining why this correlation should hold across arbitrary architectures or datasets."}, "questions": {"value": "line 302-304, \"For a fair comparison, we reproduce the results of state-of-the-art methods using the official source codes, and adjust the threshold τ in Eq. (13) to ensure that the average number of full computations (NFC) matches that of other methods.\" can you elaborate more on how to adjust the threshold tau?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "79msHDirrB", "forum": "w8ksWcSuFb", "replyto": "w8ksWcSuFb", "signatures": ["ICLR.cc/2026/Conference/Submission8437/Reviewer_6daa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8437/Reviewer_6daa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943924123, "cdate": 1761943924123, "tmdate": 1762920327890, "mdate": 1762920327890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses inefficiencies in diffusion transformers (DiTs) by advancing feature caching techniques used to accelerate inference. Prior approaches speed up computation by temporally extrapolating and reusing output features of expensive modules, but these methods can incur significant prediction errors. Through detailed analysis, the authors find that such errors arise from irregular feature magnitude changes and that there is a strong correlation between a module’s input and its output features. Building on these insights, they introduce Relational Feature Caching (RFC), a novel framework that leverages the relationship between inputs and outputs to improve feature prediction accuracy. RFC includes two key components: Relational Feature Estimation (RFE), which uses input features to predict output changes more reliably, and Relational Cache Scheduling (RCS), which estimates likely prediction errors from inputs and recomputes outputs only when large errors are expected. Experiments on various DiT models show that RFC consistently outperforms earlier techniques, significantly improving efficiency and accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This work introduces novel components—Relational Feature Estimation (RFE) and Relational Cache Scheduling (RCS)—that have not been explored in prior work. It utilizes input–output relationships, enabling a more accurate prediction of output features. The paper clearly articulates the motivation, challenges, and contributions, and provides a general framework that could inspire further research for DiTs."}, "weaknesses": {"value": "Clarity of Mathematical Formulation (RELATIONAL FEATURE CACHING section):\n\nThe presentation of equations in the RELATIONAL FEATURE CACHING section lacks clarity, making it difficult for readers to follow the mathematical foundations of the approach. For instance, the connection between the two components, RFE and RCS, is not clear at the beginning, and the logical flow from one equation to the next is not always well-motivated.\n\nActionable suggestion: Including intuitive descriptions or intermediary steps (potentially with illustrative diagrams or simplified toy examples) would help clarify the input-output relationship modeling and the estimation process.\n\nExperimental Evaluation Coverage:\n\nWhile the experiments show consistent gains across several DiT models, the paper primarily focuses on performance improvements and does not fully explore scenarios where the method may fail or be less effective (e.g., with particularly noisy or weak input-output correlations).\nActionable suggestion: Include ablation studies or failure case analysis to identify situations where the relational estimation approach may struggle or need further modification. Examining a broader range of conditions, such as varying degrees of input-output correlation, would provide a more comprehensive understanding of the method's robustness. For Table 4, provide a brief written summary in the main text to guide the reader through the table and highlight the most important results."}, "questions": {"value": "How does the model perform in terms of efficiency when the RCS component has a different scheduling policy?\n\nIs there a clear trade-off pattern for the method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "PuqRvz84Tk", "forum": "w8ksWcSuFb", "replyto": "w8ksWcSuFb", "signatures": ["ICLR.cc/2026/Conference/Submission8437/Reviewer_gkp8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8437/Reviewer_gkp8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762033591621, "cdate": 1762033591621, "tmdate": 1762920327611, "mdate": 1762920327611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}