{"id": "p8sBNCqQUY", "number": 9921, "cdate": 1758149118844, "mdate": 1763747242794, "content": {"title": "MedMMV: A Controllable Multimodal Multi-Agent Framework for Reliable and Verifiable Clinical Reasoning", "abstract": "Recent progress in multimodal large language models (MLLMs) has demonstrated promising performance on medical benchmarks and in preliminary trials as clinical assistants. Yet, our pilot audit of diagnostic cases uncovers a critical failure mode: instability in early evidence interpretation precedes hallucination, creating branching reasoning trajectories that cascade into globally inconsistent conclusions. This highlights the need for clinical reasoning agents that constrain stochasticity and hallucination while producing auditable decision flows. We introduce MedMMV, a controllable multimodal multi-agent framework for reliable and verifiable clinical reasoning. MedMMV stabilizes reasoning through diversified short rollouts, grounds intermediate steps in a structured evidence graph under the supervision of a Hallucination Detector, and aggregates candidate paths with a Combined Uncertainty scorer. On six medical benchmarks, MedMMV improves accuracy by up to 12.7% and, more critically, demonstrates superior reliability. Blind physician evaluations confirm that MedMMV substantially increases reasoning truthfulness without sacrificing informational content. By controlling instability through a verifiable, multi-agent process, our framework provides a robust path toward deploying trustworthy AI systems in high-stakes domains like clinical decision support.", "tldr": "A multi-agent framework controls instability for reliable AI clinical reasoning.", "keywords": ["large language model agent", "clinical reasoning", "medical diagnose", "hallucination"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9aa661a33297b05e3c8f69c4c3d7d68bdd71c95a.pdf", "supplementary_material": "/attachment/e4026c06e077d7f1f825ccdd5e54fa7b00264b63.zip"}, "replies": [{"content": {"summary": {"value": "The authors present a controllable multimodal multi-agent framework for reliable and verifiable clinical reasoning called MedMMV. Their approach is based on empirical evidence from experiments, which they perform to demonstrate limitations of direct prompting chain-of-thought methods. Empirical results from their pilot studies demonstrate that high variability in direct prompting chain-of-thought approaches for various tasks, and hallucination from misinterpretation of facts at the beginning of trajectories, lead to unstable paths and unreliable results with majority voting approaches.\n\nFollowing this analysis, their proposed approach consists of three main steps:\n\n- Short initial rollouts, which are subsequently self-refined based on evidence graphs and hallucination detectors.\n- Use of MLLM and web search to build evidence graphs using prior text and images, if available from the initial input.\n- An uncertainty scorer which scores each final trajectory using a weighted sum of various metrics.\n\nTheir results demonstrate that MedMMV outperforms chain-of-thought and other medical agent approaches on 6 medical reasoning datasets benchmarks. Furthermore, various ablation studies demonstrate the importance of the various components of their design choices."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes an interesting approach, notably the use of evidence graphs to self-refine reasoning paths and hallucination detectors to prevent hallucinations. The use of an uncertainty scorer is also interesting, as it can be applied in downstream approaches to validate the agent’s diagnosis only if the uncertainty is below a certain threshold."}, "weaknesses": {"value": "- The presentation of the results in the preliminary analysis on the limitations of direct chain-of-thought approaches could be simplified or improved to make the message easier to understand (Figure 2). Furthermore, the description of the various metrics used there, notably RGM and CMHR, could be clarified to facilitate understanding.\n\n- On most datasets, the improvement in accuracy compared to CoT is less than 5%, while the token usage of MedMMV and other agent-based methods is approximately nine times higher than that of CoT methods. This suggests that the proposed approach might be too computationally expensive for the modest performance gains achieved."}, "questions": {"value": "- What motivated the choice of datasets? Among the baselines used, one of the most *reliable* approaches is **MDAgents** — I say reliable because it was published at NeurIPS. Why not use similar datasets to make comparisons simpler? Furthermore, I noticed that the accuracy for **MedQA**, which overlaps with the datasets used in the MDAgents paper, is lower than what was reported there. Is this due to the use of a smaller sample size?\n- Were any measures taken to verify that the datasets used are not part of the training data for **GPT-5**, which serves as the base model for all the agents?\n- Why do you only use a single rollout for the chain-of-thought methods as a comparison? Wouldn't a fairer comparison be to use the same number of trajectories as in **MedMMV**, with majority voting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jAiWktfLVd", "forum": "p8sBNCqQUY", "replyto": "p8sBNCqQUY", "signatures": ["ICLR.cc/2026/Conference/Submission9921/Reviewer_HjDw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9921/Reviewer_HjDw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761651707142, "cdate": 1761651707142, "tmdate": 1762921378084, "mdate": 1762921378084, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents MedMMV, a framework designed to produce more truthful and stable responses from large language models in high-stakes domains such as healthcare prediction. Motivated by the challenge of hallucinations found in current LLMs, the authors propose a three-step approach: (i) generating multiple candidate solutions, (ii) iteratively refining and verifying them for truthfulness using web-based evidence while constructing an evidence graph, and (iii) evaluating all candidate solutions across several LLMs using multiple metrics, selecting the one with the highest aggregated score. Extensive experiments on multiple datasets demonstrate that MedMMV consistently outperforms several strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written and easy to follow. It addresses an important and timely problem that deserves further investigation. The motivation is well grounded, supported by both quantitative and qualitative analyses of current models in a specific high-stakes setting. The experimental evaluation is extensive and robust, covering multiple datasets and strong baselines. While the multi-step review process itself is not entirely novel, the proposed mechanism for selecting the best answer among candidates is original and well justified."}, "weaknesses": {"value": "- Many figures are overly dense and difficult to interpret, which limits their readability and the clarity of the results.\n- The framework relies heavily on LLMs, both in the evaluation process and in the preliminary study. While the inclusion of expert validation is appreciated, it would strengthen the paper to directly compare the expert assessments with the LLM-based evaluations to assess their alignment.\n- Although the authors acknowledge the higher computational cost introduced by the proposed multi-step process, it would be valuable to include a quantitative analysis of the additional time or number of generated tokens required."}, "questions": {"value": "In addition to the points discussed in the Weaknesses section, I have the following question:\n- What would happen if the CU scoring mechanism were used to filter or rank the base LLM responses directly? Would this alone improve their performance, or is the full multi-step process necessary to achieve the reported gains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vE1nDp2czf", "forum": "p8sBNCqQUY", "replyto": "p8sBNCqQUY", "signatures": ["ICLR.cc/2026/Conference/Submission9921/Reviewer_e3qd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9921/Reviewer_e3qd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928986495, "cdate": 1761928986495, "tmdate": 1762921377439, "mdate": 1762921377439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes MedMMV, a multi-stage framework designed to enhance the reliability and verifiability of multimodal medical reasoning in large language models. By combining uncertainty-aware path generation, evidence-grounded refinement, and structured decision aggregation, MedMMV produces diagnostic outputs that are both logically coherent and empirically auditable. A key innovation lies in its construction of a multimodal evidence graph, synthesized by specialized agents across textual, visual, and external knowledge modalities."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear Motivation and Design: the paper addresses the challenge of hallucination and unverifiable reasoning in medical LLMs, motivating a shift from single-shot inference to multi-path verification.\n\n2. Novel Multi-Stage Framework: MedMMV introduces a structured pipeline combining uncertainty-aware path generation, supervised refinement, and evidence-based scoring. The use of a multimodal evidence graph constructed by specialized agents is a key innovation.\n\n3. Comprehensive Evaluation of Reasoning Faithfulness: the empirical study covers six medical QA benchmarks—three multimodal and three text-only—demonstrating consistent improvements in diagnostic accuracy, factual consistency, and evidence-groundedness over competitive baselines. Beyond accuracy, the evaluation incorporates hallucination rate and evidence coverage metrics, offering a more rigorous assessment of reasoning reliability."}, "weaknesses": {"value": "1. Inference-Time Efficiency: while the multi-path framework improves reasoning robustness, the paper lacks analysis of inference-time efficiency, which may hinder its deployment in time-sensitive or resource-constrained clinical settings.\n\n2. Limited Ablation Coverage: the ablation study should extend to additional multimodal and text-only benchmarks to better substantiate the generality and robustness of the proposed components across task types."}, "questions": {"value": "Please see my weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0uafL0m3vC", "forum": "p8sBNCqQUY", "replyto": "p8sBNCqQUY", "signatures": ["ICLR.cc/2026/Conference/Submission9921/Reviewer_RJ5J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9921/Reviewer_RJ5J"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955672278, "cdate": 1761955672278, "tmdate": 1762921376681, "mdate": 1762921376681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "MedMMV is a controllable multimodal multi-agent framework for clinical reasoning that targets the observed failure mode “instability → hallucination.” It generates diversified short rollouts, grounds and verifies each path against a structured evidence graph via a hallucination/consistency supervisor, and selects the final diagnosis using a Combined Uncertainty scorer. Across six benchmarks and multiple backbones, it improves accuracy (up to +12.7%) and boosts truthfulness without reducing informativeness; a blind physician study corroborates gains."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Clear identification and quantification of instability preceding hallucination in multimodal clinical reasoning.\n- Controllable, auditable pipeline: diversified hypotheses, evidence-graph grounding, iterative repair, and uncertainty-based aggregation.\n- Consistent gains across datasets/backbones; physician study supports higher truthfulness.\n- Solid ablations isolating main contributors (CU scorer, hallucination detector)."}, "weaknesses": {"value": "- Heavy reliance on LLM judges/evaluators for TRUE/INFO and CU sub-scores risks bias and circularity; limited human IRR details.\n- Evidence graph quality is a potential single point of failure; robustness to noisy extraction/provenance underexplored.\n- Higher compute/latency and API costs; scalability guidance limited.\n- Heuristic CU weighting and limited sensitivity analyses.\n- Evaluation on representative subsets; limited fairness analysis (context windows, image preprocessing) and contamination controls."}, "questions": {"value": "- CU scorer: how were weights chosen; sensitivity to weights, rollout counts, and repair iterations?\n- Evaluator independence: do results hold with different supervisor/evaluator backbones; add blinded human TRUE/INFO with inter-rater reliability?\n- Evidence graph: how do you detect/resolve extraction conflicts and control web source quality (domain, recency, dedup)?\n- Scalability/fairness: detailed compute/latency per stage; do gains persist under tighter context and lower image resolution; any contamination audits?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ioaO1NLfxn", "forum": "p8sBNCqQUY", "replyto": "p8sBNCqQUY", "signatures": ["ICLR.cc/2026/Conference/Submission9921/Reviewer_XREK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9921/Reviewer_XREK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762068298030, "cdate": 1762068298030, "tmdate": 1762921376236, "mdate": 1762921376236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}