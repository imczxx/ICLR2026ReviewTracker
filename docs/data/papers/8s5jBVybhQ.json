{"id": "8s5jBVybhQ", "number": 21137, "cdate": 1758314133690, "mdate": 1763682272033, "content": {"title": "Remotely Detectable Robot Policy Watermarking", "abstract": "The success of machine learning for real-world robotic systems has created a new form of intellectual property: the trained policy. This raises a critical need for novel methods that verify ownership and detect unauthorized, possibly unsafe misuse. While watermarking is established in other domains, physical policies present a unique challenge: remote detection. Existing methods assume access to the robot’s internal state, but auditors are often limited to external observations (e.g., video footage). This “Physical Observation Gap” means the watermark must be detected from signals that are noisy, asynchronous, and filtered by unknown system dynamics. We formalize this challenge using the concept of a glimpse sequence, and introduce Colored Noise Coherency (CoNoCo), the first watermarking strategy designed for remote detection. CoNoCo embeds a spectral signal into the robot’s motions by leveraging the policy’s inherent stochasticity. To show it does not degrade performance, we prove CoNoCo preserves the marginal action distribution. Our experiments demonstrate strong, robust detection across various remote modalities—including motion capture and side-way/top-down video footage—in both simulated and real-world robot experiments. This work provides a necessary step toward protecting intellectual property in robotics, offering the first method for validating the provenance of physical policies non invasively, using purely remote observations.", "tldr": "", "keywords": ["watermarking", "robotics", "stochastic policies"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b65a93407d1b5701e738f2607309ffc5b1ec1308.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces CoNoCo (Colored Noise Coherency), the first framework for remotely detectable watermarking of robot control policies. Unlike prior approaches that require white-box or onboard access, CoNoCo embeds a frequency-domain signature into the stochastic exploration noise of a policy, enabling provenance verification from remote, noisy, and asynchronous observations (e.g., video footage). The watermark is injected by shaping the policy’s Gaussian noise into a narrow spectral band and later detected via spectral coherency, which is invariant to unknown system dynamics. The method is evaluated on simulated and real-world robots (e.g., RoboMaster platform) under various sensing modalities, showing high detectability, policy utility preservation, and strong robustness to additive noise attacks. The authors also open-source their full code and trained models."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper addresses a novel and important challenge: remote watermark detection for robotic policies, representing a new research direction beyond digital or model-based watermarking. The concept of bridging the “Physical Observation Gap” through spectral coherency is both elegant and well-motivated.\n\nThe methodology is clearly described and mathematically grounded, with supporting theorems demonstrating action-distribution preservation and LTI-invariant detectability. The experiments cover a diverse set of control environments and modalities, including real-world deployment, demonstrating consistent performance.\n\nThe paper is exceptionally well-written and organized. Figures clearly illustrate the concept and pipeline. The mathematical derivations are detailed yet readable, and limitations are candidly discussed in the appendix.\n\nThe problem addressed is highly relevant to both AI safety and IP protection in robotics. Remote verification of control policies is crucial for future large-scale autonomous deployments. The release of code and trained models enhances the paper’s impact and reproducibility."}, "weaknesses": {"value": "While the paper convincingly demonstrates robustness under several noise conditions, it does not discuss or evaluate how the watermark performs under unseen or novel distortions beyond the tested scenarios. Real-world observation pipelines may involve motion blur, lighting changes, camera compression, occlusions, or domain shifts in dynamic, conditions under which the spectral coherency assumption might weaken. Without empirical evidence or analysis of these unseen distortions, it remains uncertain how broadly the robustness claim generalizes in practice."}, "questions": {"value": "1. How does CoNoCo perform under unseen distortions such as camera compression, lighting variation, partial occlusion, or non-linear distortions that break LTI assumptions?\n\n2. Could frequency-domain regularization or multi-band embedding improve robustness to these distortions?\n\n3. Does the open-source release include pretrained detectors for other robot types or example video-based detection pipelines?\n\n4. Would combining CoNoCo with learned feature-based detectors (e.g., neural coherence estimators) further enhance robustness under non-linear observation mappings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K1njNsR7a8", "forum": "8s5jBVybhQ", "replyto": "8s5jBVybhQ", "signatures": ["ICLR.cc/2026/Conference/Submission21137/Reviewer_RB6n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21137/Reviewer_RB6n"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761521138556, "cdate": 1761521138556, "tmdate": 1762941416738, "mdate": 1762941416738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank the reviewers for their thoughtful comments. We are encouraged that the reviewers found our problem 'well-scoped and original' (Reviewer UYqi), our method 'elegant and well-motivated' (Reviewer RB6n), and our theoretical and experimental contributions 'very theoretically sound' (Reviewer Mmbz), 'mathematically grounded' (Reviewer RB6n), and supported by a 'broad experimental sweep' (Reviewer g3WJ). In response to their feedback, we have made several updates to the revised manuscript to further strengthen our results:\n- **Clarified open questions:** We addressed limitations regarding deterministic policies and real-world sensing constraints (Appendix A).\n- **Additional experiments on robustness to alterations:** We conducted a comprehensive empirical study on glimpse alterations (time offsets, jitter, frame drops, camera shifts) in Appendix G.\n- **Time offset handling:** We show that a minimal transformation (GCC-PHAT) to the glimpse data before it is inputted to CoNoCo enables it to robustly handle large time offsets, retaining perfect AUC (Appendix G). Hence, this is no longer a limitation of our method, and we revised the paper text accordingly.\n- **Expanded analysis of adversarial attacks:** We analyzed two additional adversarial attack scenarios, Band-Stop Filtering and Structured Jamming, demonstrating the trade-off between attack success and policy utility in Appendix H. We also consider distillation in the same appendix. \n- **New environment:** We validated our method on a new environment: VMAS Navigation with obstacles, confirming performance in constrained settings (Appendix I).\n\nWe are grateful to the reviewers for the many constructive insights, which have significantly strengthened our manuscript, and we welcome any further questions or suggestions during the discussion phase."}}, "id": "LpTFlDep74", "forum": "8s5jBVybhQ", "replyto": "8s5jBVybhQ", "signatures": ["ICLR.cc/2026/Conference/Submission21137/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21137/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21137/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763679377071, "cdate": 1763679377071, "tmdate": 1763680342357, "mdate": 1763680342357, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an approach to encode IP protections into robot actions using colored noise coherency approaches. This adds noise to robot actions, preserving the marginal action distribution. The noise used is Colored Gaussian Noise (CGN), which replaces white noise used during exploration phase of the RL system training. Unlike dynamic watermarking methods for sensor inputs, this approach requires detectability and is not a strict defense against attackers - as such, it is also simple enough to be rapidly detectable. The paper proves that the CGN watermark detectability converges to unity as the 'glimpse sequence' of action data observed increases."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is very theoretically sound, proving its claims in theory before moving to experimentation, in one case on real robot hardware. It is also thorough in its discussion on limitations, open questions and questions such as attack resilience of the CoNoCo approach."}, "weaknesses": {"value": "For a reinforcement learning based paper that focuses on IP protections in robotics, it seems too thin on the experimental section to me, but otherwise is excellent."}, "questions": {"value": "1. Could the authors comment on the complexity of robots such as multi-jointed arms that have to also conduct fine manipulation? Would CoNoCo be applicable there, given the smaller margin of error for those manipulations?\n\n2. While the authors address the limitations of glimpse sequence sensor data quality requirements in the appendices, I would like to know if approaches involving signal reconstruction under noise would allow more robust watermarking without the need to fit the glimpse sequence length required to the periodicity of the signal (as mentioned in the periodicity part of open questions)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PSJuwPn7am", "forum": "8s5jBVybhQ", "replyto": "8s5jBVybhQ", "signatures": ["ICLR.cc/2026/Conference/Submission21137/Reviewer_Mmbz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21137/Reviewer_Mmbz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928363647, "cdate": 1761928363647, "tmdate": 1762941414636, "mdate": 1762941414636, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Colored Noise Coherency, or CoNoCo, a watermarking strategy for robotic control policies that can be detected from remote observations. The core idea is to replace standard white exploration noise with band limited colored noise and to detect the resulting spectral signature through coherency in the frequency domain. The authors argue that coherency is invariant to unknown linear time invariant dynamics, which makes the detector robust to the physical observation gap between actions and sensed motion. The study reports strong detection from motion capture and monocular video while preserving the marginal action distribution and task reward."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear problem formulation of remote watermark detection with only glimpse sequences and a careful breakdown of synchronization uncertainty, dynamics, and noise.\n- A principled detector based on spectral coherency that is motivated by standard results in signal processing and that aligns well with the physical setting.\n- Broad experimental sweep across simulated and real platforms with multiple sensing modalities, including top down and side view video, with anonymization tests and ROC based reporting."}, "weaknesses": {"value": "## \n\n- Watermarks are not detected in the presence of obstacles in the navigation task. It remains to see if the CoNoCo policy characteristics would be detectable in a general cluttered environment.\n- Inability to Handle Time Offsets: This is a major operational weakness. The paper states that CoNoCo \"does not handle large time offsets well\" and that detection requires the \"glimpse data recording needs to start near the beginning of the robot's operations\". In any realistic scenario (like pulling CCTV footage), an auditor will be \"tuning in\" at an arbitrary time, not at the precise moment the robot was activated. Ideally the watermarking sequence $W_k$ would be ran in short intervals or a study of the time offset detection capabilities w.r.t. offset and detection length required would be included.\n- The authors test a naive Additive Noise Attack in Appendix G. This attack involves adding White Gaussian Noise (WGN) to the policy's actions before execution but the attacker has no other objectives like maintaining performance.\n    - An adversarial RL agent would not just add *random* noise. It could be trained with a multi-objective reward function:\n        1. Maximize the original task reward (to maintain performance).\n        2. Add random noise or change the policy in a structured way.\n    This RL agent would learn to output a structured jamming signal that would most likely interfere with the spectral signature in the secret frequency band $\\mathcal{B}$.\n    - Another option is policy distillation [1,2] where the adversary learns to copy the behavior of the watermarked policy while maintaining performance. This could effectively change the policy and thus remove the watermark.\n\n### References\n\n[1] Policy Distillation, Andrei A. R. et al., 2015\n\n[2] Refined Policy Distillation: From VLA Generalists to RL Experts, Tobias J. et al., IROS 2026"}, "questions": {"value": "1. In the robustness to adversarial additive noise experiments in Appendix G, is the adversary given any objective to maintain performance, for example a reward preserving constraint or penalty on deviation from nominal actions?\n2. Does the detector ever raise false positives on non watermarked policies that naturally concentrate energy in the secret band due to task dynamics, and what priors or band selection rules mitigate this risk?\n3. How sensitive is detection to modest drift in the policy execution rate during a single deployment, and can the search grid adapt online?\n4. How is policy distillation or behavior cloning as a way to remove the watermarking detection capability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zFdD5RZpUI", "forum": "8s5jBVybhQ", "replyto": "8s5jBVybhQ", "signatures": ["ICLR.cc/2026/Conference/Submission21137/Reviewer_g3WJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21137/Reviewer_g3WJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966528195, "cdate": 1761966528195, "tmdate": 1762941413470, "mdate": 1762941413470, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to design watermark for trained robotic policies in the observation-only setting. That is, to verify the ownership of a robot’s policy using only remote observation such as videos or motion capture. To make this concrete, the authors identifies the “Physical Observation Gap,” which captures the three key challenges. The approach focuses on Gaussian policies.\n\nThe method CoNoCo adds a covert spectral signature into the exploration noise of the policy by concentrating energy in a secret frequency band. This modification preserves the marginal distribution over actions, ensuring task performance is unaffected. The detector uses it to reconstruct and compare the signature via spectral coherency, scanning over possible execution rates.\n\nTheory shows the watermark remains statistically invisible per timestep but can be detected over time. Experiments across real and simulated environments including RoboMaster, VMAS, and MuJoCo tasks demonstrate strong detection performance, reward preservation, and some robustness to noise."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Well-scoped and original problem: The paper clearly frames a new challenge—verifying the ownership of a robot’s policy using only remote sensing (e.g., video), with no white-box access. The proposed “Physical Observation Gap” is realistic and well-formulated, addressing timing mismatches, unknown dynamics, and sensing limitations.\n\n2. Simple but clever method: The idea to use colored Gaussian noise with energy concentrated in a secret frequency band is elegant. It avoids changing the marginal action distribution while enabling detectability through spectral analysis. The implementation is straightforward and practical.\n\n3. Solid theoretical grounding: The paper gives intuitive and mathematically sound analysis. It shows that marginal action distributions are preserved and that the coherence metric used for detection has a direct relationship with SINR.\n\n4. Strong and diverse experiments: The authors validate the method in both simulation and a real robot setting, using various sensing modalities including motion capture and single-camera video. They report strong detection results, reasonable robustness, and include anonymity comparisons with a baseline."}, "weaknesses": {"value": "1. Limited attack robustness: The experiments mainly test additive noise. But real-world attackers might apply frame drops, time shifts; none of which are evaluated here. These could undermine coherency-based detection.\n\n2. Scope is restricted to continuous Gaussian policies: There’s no discussion on how this approach might extend to discrete or deterministic policies, which are common in practice"}, "questions": {"value": "1. Attack resilience: How does your method perform under time distortions, missing frames, or camera shifts? Any strategies to make it more invariant?\n\n2. Beyond Gaussian policies: Do you see a way to adapt this idea to deterministic or discrete-action policies while retaining reward preservation and detectability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xnyIj0Y3aH", "forum": "8s5jBVybhQ", "replyto": "8s5jBVybhQ", "signatures": ["ICLR.cc/2026/Conference/Submission21137/Reviewer_UYqi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21137/Reviewer_UYqi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973227140, "cdate": 1761973227140, "tmdate": 1762941411836, "mdate": 1762941411836, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}