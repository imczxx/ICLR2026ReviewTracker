{"id": "5ekhMkawuT", "number": 7574, "cdate": 1758028159047, "mdate": 1759897845302, "content": {"title": "Quantization-Aware Diffusion Models For Maximum Likelihood Training", "abstract": "Diffusion models are powerful generative models for continuous signals, such as images and videos.\nHowever, real-world digital data are quantized; hence, they take not continuous values but only a finite set of discrete values.\nFor example, pixels in 8‑bit images can take only 256 discrete values.\nIn existing diffusion models, quantization is either ignored by treating data as continuous, or handled by adding small noise to make the data continuous.\nNeither approach guarantees that samples from the model will converge to the finite set of quantized points.\nIn this work, we propose a methodology to explicitly account for quantization within diffusion models.\nSpecifically, by adopting a particular form of parameterization, we guarantee that samples from the reverse diffusion process converge to quantized points.\nIn experiments, we demonstrate that our quantization-aware model can substantially improve the performance of diffusion models for density estimation, and achieve state‑of‑the‑art results on pixel‑level image generation in likelihood evaluation.\nIn particular, for CIFAR‑10 image generation, the negative log‑likelihood improves substantially from 2.42 to 0.27, approaching the theoretical lower bound.", "tldr": "Quantization-aware diffusion (QDPM) makes the reverse SDE provably land on discrete pixel values, enabling maximum-likelihood training and achieving SoTA NLL.", "keywords": ["diffusion model", "dequantization"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5b42bffaaf7f38d4ffc0f9b0f89808652880e8f1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work introduces a new parameterization technique for diffusion models aimed at improving negative log-likelihood performance by ensuring generated outputs lie on quantized values. The approach is broadly applicable to density modeling on discretized data and experimental results show significant NLL gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written with well-motivated methodology. The rationale behind the approach and its implementation is easy to understand, and the experiments effectively highlight its advantages.\n\n2. The method is supported by theoretical analysis regarding both the parameterization and associated solvers, though there may be some concerns with the proposition as noted below.\n\n3. Strong experimental results are demonstrated on discrete-signal density estimation tasks, outperforming prior state-of-the-art methods. Notably, CIFAR-10 results show substantial improvement."}, "weaknesses": {"value": "A recent work [1] proposes an equilibrium formulation for image generation rather than traditional density estimation. Although their approach does not strictly ensure convergence to quantized points, it explicitly defines a fixed point for the generative process. It would be valuable to discuss how this relates to your method and whether their training strategy could potentially benefit or be adapted to your framework. In addition, that work argues that standard diffusion models do not exhibit a valid fixed point at t=0. This observation seems relevant to Proposition 1 in your paper and merits further discussion or clarification.\n\n2. In the proof, the function labeled $f$ should be $\\hat{x}_\\theta$\n\n[1] Wang, Runqian, and Yilun Du. \"Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models.\" arXiv preprint arXiv:2510.02300 (2025)."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5bJ1IZ75S0", "forum": "5ekhMkawuT", "replyto": "5ekhMkawuT", "signatures": ["ICLR.cc/2026/Conference/Submission7574/Reviewer_12ST"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7574/Reviewer_12ST"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960504797, "cdate": 1761960504797, "tmdate": 1762919669666, "mdate": 1762919669666, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new parameterization for diffusion models designed to improve negative log-likelihood (NLL) performance by ensuring that generated samples converge to quantized points. The proposed parameterization can be broadly applied to density estimation tasks involving quantized data. Experimental results demonstrate substantial improvements in NLL across various datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is clearly written and easy to follow. The motivation and methodological design are well articulated, and the experiments convincingly demonstrate the proposed approach’s effectiveness.\n\n* The method is supported by theoretical analysis for both the parameterization and the associated solvers, though there are some issues with the description in Proposition 1 (see Weaknesses).\n\n* The experiments show strong performance on density estimation for discrete signal data, outperforming state-of-the-art methods. For example, the improvement on CIFAR-10 reduces NLL from 2.42 to 0.27."}, "weaknesses": {"value": "* Proposition 1 claims that the SDE defined in Eq. (14) has a fixed point at time step 0; however, this does not appear to hold in the general case. Constructing denoised score matching for diffusion models requires defining the score field over discrete data through noise injection. As discussed in [1], when the model distribution approaches the real data distribution, the gradient becomes steeper due to the small Gaussian variance, making the boundedness assumption not always valid. While the proposed parameterization may alleviate this issue, a more detailed explanation covering broader cases would strengthen the argument. Moreover, the role of the fixed-point requirement in Proposition 1 is unclear. \n\n* Beyond the explanation in Proposition 1, an ablation study validating this proposition, for instance, by reporting the magnitude of the fixed-point error, would significantly improve the paper’s empirical evidence.\n​\n\n[1] Song, Yang, et al. \"Sliced Score Matching: A Scalable Approach to Density and Score Estimation.\" Uncertainty in Artificial Intelligence. PMLR, 2020."}, "questions": {"value": "* In the proof, should $f$ be $\\hat{x}_{\\theta}$?\n\n* Could you provide more details about the role of the fixed-point requirement in Proposition 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "HSTMA1qTKE", "forum": "5ekhMkawuT", "replyto": "5ekhMkawuT", "signatures": ["ICLR.cc/2026/Conference/Submission7574/Reviewer_Zbvq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7574/Reviewer_Zbvq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762649875390, "cdate": 1762649875390, "tmdate": 1762919669294, "mdate": 1762919669294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work introduces a quantization-aware diffusion parameterization that guarantees convergence to discrete codebook points at \n$t \\downarrow 0$. It derives a reverse-SDE solution specific to this parameterization, proposes first/second-order solvers, and trains with a likelihood-motivated objective that avoids explicit dequantization. Results show very low bits-per-dim (BPD) on CIFAR-10 and ImageNet-32.\n\nIn more detail, the paper proposes a parameterization that forces the reverse SDE to converge to quantized points by making $x_\\theta(\\cdot,0)$ equal a (soft) rounding operator; formally, the limit $x_0$ is a fixed point of $x_\\theta(\\cdot,0)$, and they limit the set of fixed points to a finite set, hence the output is quantized. The training objective is presented as an ELBO-style upper bound on $-\\log p_0(x_0)$ with $t_{\\min} \\to 0$, $t_{\\max} \\to\\infty$ (Eq. 19), then reparameterized via $u=e^{-1/t^2}$ to yield a simple Monte-Carlo form (Eq. 22). They evaluate an upper bound on NLL for the reverse SDE and report extremely low BPD on CIFAR-10/ImageNet-32 (0.27 / 0.32), claiming closeness to a “theoretical lower bound”."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear mechanism to force quantized fixed points; the softround + $e^{-1/t^2}\\delta_\\theta$ parameterization is simple and elegant.  \n- Derivation of an SDE solution enables specialized solvers with straightforward implementations.  \n- Ambitious likelihood-centric evaluation; if comparable, the reported BPD would be a genuine leap."}, "weaknesses": {"value": "None listed yet; see **Questions** instead. I prefer to label weaknesses only after the discussion period. Everything is only a question until then."}, "questions": {"value": "### 0. A few typos\n\nThroughout, there are expressions of the form $\\Omega = \\prod_{i=1}^d \\{ x^{(k)}\\}_{k=1}^K$ where $i$ is not used\n\n### 1. Comparability of the “likelihood” metric\n\nPrior continuous-model papers typically report *dequantized* likelihoods (e.g., uniform $[0,1)$ or learned dequantization), or use a categorical $p_\\theta(x_0 \\mid x_{t_{\\min}})$ at a positive $t_{\\min}$. Here the bound integrates to $t_{\\min} \\to 0$ with a quantized fixed-point parameterization.  It isn’t obvious this produces the same quantity other works report.  It would help to clarify whether the contribution is primarily the bound, the trained model, or both.  \n\n**(1a) Type of bound**\n\nPlease state at a high level whether your BPD corresponds to:\n\n(i) discrete likelihood (categorical over 256 bins per channel),  \n(ii) dequantized continuous likelihood, or  \n\n\n**(1b) Logp → BPD conversion**\n\nRight now the text says you “report [the] upper bound calculated with Eq. (19)” but does not specify the unit conversion or definition used to go from log-likelihood to BPD.  Assuming the logp is computed correctly, could you specify the exact computation you used to convert from your logp bound to your BPD bound?  \n\n**(1c) Evaluating other models with your bound, and evaluating your model with other bounds**\n\n- (1c.i) Would your bound, if used to evaluate another model, also report numbers <=1.0? Especially given that rounding is included in the likelihood evaluation. Regardless of how another model checkpoint was trained, does this bound (with rounding) give that model a better BPD too? Could this be evaluated on existing checkpoints from Song, Kingma, etc.?  \n\n- (1c.ii) Conversely, what would the *standard* dequantization bound (Eq. 26) report for your model, without the rounding step?  \n\n### 2. (Important!) Change-of-variables detail in Eq. (22)\n\nQuestion 1 concerned defining the BPD (assuming logp computation is correct).  This question is about the correctness of the logp computation itself. When moving from Eq. (20) to Eq. (22) with the substitution $u=e^{-1/t^2}$, the weighting induced by $du/dt$ must be accounted for; otherwise the Monte-Carlo estimator could be biased and underestimate NLL.   Could you please show the exact steps (including Jacobian factors) to justify the *unweighted* expectation over $u \\sim \\mathrm{Unif}(0,1)$ in Eq. (22)?  \n\n### 3. “Theoretical lower bound” – Q1\n\nThe lower bound $\\log_2(50000)/(3 \\cdot 32^2) \\approx 0.0051$ appears to be the code-length of a uniform categorical over the 50k images divided by dimension.  This is a property of the finite dataset, not the underlying data distribution. Please justify using this as a target for generative modeling and clarify whether your evaluation implicitly allows near-memorization (e.g., concentrating mass on quantized locations). Is it a theoretical lower bound on the 50k images?\n\n### 4. “Theoretical lower bound” – Q2\n\nWhy is the word “test” used here? For CIFAR there are 50k train images and 10k test images; for ImageNet, ~1.2M train and 50k test.  \nWas there a mix-up? The other numbers reported in Table 1 usually refer to the CIFAR *test* set of 10,000 datapoints (even though FID is often reported on the training set). Which sets were your BPD numbers computed on?  Why do we compare CIFAR test BPDs to a lower bound computed on 50k training points?\n\n### 5. Definition of $s_t$\n\nCould you explicitly define $s_t(x_t) = \\nabla_{x_t} \\log q_{0t}(x_t \\mid x_0)$ around Eqs. (2)–(4) for readability? It may be clear to experts, but all mathematical symbols should be defined.  \n\n### 6. Code availability\n\nThe anonymous code link in Appx. B.1 is currently empty.  It would be helpful to share working code so others can confirm the BPD computation protocol.  \n\n### 7. Sensitivity of reported BPD\n\nHow sensitive are the reported BPD values to the time-discretization schedule? In my experience, sampling 1,000 vs. 10,000 uniform points in (0,1) can drastically affect dequantized-diffusion BPDs for standard noise schedules and common checkpoints (e.g., those from Song, Durkan & Song, Kingma, etc.)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "egAfJW50IB", "forum": "5ekhMkawuT", "replyto": "5ekhMkawuT", "signatures": ["ICLR.cc/2026/Conference/Submission7574/Reviewer_Pzwu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7574/Reviewer_Pzwu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762719414958, "cdate": 1762719414958, "tmdate": 1762919668586, "mdate": 1762919668586, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper introduces Quantizing Diffusion Probabilistic Models (QDPM), a diffusion model that explicitly integrates quantization into the  reverse diffusion process. \n - Unlike traditional models that treat data as continuous or rely on dequantization noise, QDPM enforces convergence to quantized points through a carefully designed signal predictor. \n - The authors prove theoretical guarantees, derive a quantization-aware maximum likelihood objective, and develop efficient SDE solvers. \n - Experiments on CIFAR-10 and ImageNet-32 show remarkable improvements in negative log-likelihood (NLL), from prior SoTA of 2.42 bpd to 0.27 bpd, nearing the theoretical lower bound."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a clear theoretical foundation for incorporating quantization into the reverse SDE. The use of softround + decaying correction (Eq. 17) is interpretable.\n2. The analysis of convergence (Propositions 1 and 2) and the closed-form derivation of the SDE solution demonstrate theoretical grounding.\n3. Achieving a 0.27 bpd test NLL on CIFAR-10 is a good improvement and suggests genuine progress in likelihood-based training of diffusion models.\n4. The proposed QDPM framework could influence how quantization is treated in generative modeling, especially for discrete data domains (e.g., images, audio)."}, "weaknesses": {"value": "1. The paper emphasizes log-likelihood but gives limited discussion on sample quality (FID ≈ 5.6 / 8.9). While the authors claim NLL–FID trade-off is expected, a deeper analysis (e.g., perceptual vs likelihood trade-off curve) would strengthen claims.\n2. Although the authors cite dequantization-based diffusion models, there are no direct experimental comparisons using the same architecture but with traditional dequantization. This would isolate the quantization-aware effect.\n3. The paper reports approaching the theoretical lower bound (~0.0051 bpd), but this bound assumes uniform discrete entropy over the test set; a short derivation or clarification would help readers assess the significance.\n4. There are no ablations on components such as the softround function, or solver order. These would be important to understand where the gain originates."}, "questions": {"value": "Please check the weaknesses and answer the questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UnJw2cZxuX", "forum": "5ekhMkawuT", "replyto": "5ekhMkawuT", "signatures": ["ICLR.cc/2026/Conference/Submission7574/Reviewer_poSH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7574/Reviewer_poSH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7574/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762833029748, "cdate": 1762833029748, "tmdate": 1762919668104, "mdate": 1762919668104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}