{"id": "T2Oihh7zN8", "number": 9446, "cdate": 1758122781292, "mdate": 1759897724252, "content": {"title": "VARestorer: One-Step VAR Distillation for Real-World Image Super-Resolution", "abstract": "Recent advancements in visual autoregressive models (VAR) have demonstrated their effectiveness in image generation, highlighting their potential for real-world image super-resolution (Real-ISR). However, adapting VAR for ISR presents critical challenges. The next-scale prediction mechanism, constrained by casual attention, fails to fully exploit global low-quality (LQ) context, resulting in blurry and inconsistent high-quality (HQ) outputs. Additionally, error accumulation in the iterative prediction severely degrades coherence in ISR task. To address these issues, we propose VARestorer, a simple yet effective distillation framework that transforms a pre-trained text-to-image VAR model into a one-step ISR model. By leveraging distribution matching, our method eliminates the need for iterative refinement, significantly reducing error propagation and inference time. Furthermore, we introduce pyramid image conditioning with cross-scale attention, which enables bidirectional scale-wise interactions and fully utilizes the input image information while adapting to the autoregressive mechanism. This prevents later LQ tokens from being overlooked in the transformer. By fine-tuning only 1.2\\% of the model parameters through parameter-efficient adapters, our method maintains the expressive power of the original VAR model while significantly enhancing efficiency. Extensive experiments show that VARestorer achieves state-of-the-art performance with 72.32 MUSIQ and 0.7669 CLIPIQA on DIV2K dataset, while accelerating inference by 10 times compared to conventional VAR inference.", "tldr": "", "keywords": ["visual autoregressive model", "image restoration"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/34fad03cc1dd1f6763d6234ca394caf9e312f311.pdf", "supplementary_material": "/attachment/cd26327ef00f593e99c60cc68a8850813179608d.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes VARestorer, a one-step super-resolution framework that addresses error accumulation in visual autoregressive models through distribution matching distillation. The method incorporates cross-scale pyramid conditioning to enable multi-scale information interaction while maintaining the original model's generative capabilities. Experiments demonstrate superior performance, achieving an optimal balance between efficiency and restoration quality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper adapts VAR models to the real-world image super-resolution (Real-ISR) task. The proposed distillation approach directly tackles the critical issue of error accumulation inherent in autoregressive models for restoration.\n2. The pyramid image conditioning with cross-scale attention enables bidirectional scale-wise interactions and fully utilizes the information of the input image while adapting to the autoregressive mechanism."}, "weaknesses": {"value": "1. The computational cost of the cross-scale pyramid conditioning should be discussed, with quantitative analysis to justify its overhead in relation to performance gains.\n2. The labels and arrows in Figure 3 are unclear. Please define $\\mathcal{D}$ and $\\mathcal{E}$ (possibly Encoder and Decoder) in the caption or figure, and redraw the arrows to unambiguously show the process flow and component interactions.\n3. The paper employs BLIP to generate textual prompts, yet its necessity remains unverified. The claim that text guidance improves restoration quality lacks support from ablation studies.\n4. Although the high efficiency of training only 1.2% of the parameters was emphasized, no performance comparison was made with full parameter fine-tuning. It is suggested to add the baseline experimental results of full parameter fine-tuning to conclusively prove that LoRA can balance efficiency while maintaining performance.\n5. The computational efficiency claims lack comprehensive quantification. While inference time is reported, metrics like FLOPs or MACs are missing, making cross-architecture comparison difficult."}, "questions": {"value": "1. How does the distillation process prevent the student model from learning and reproducing any inherent errors or suboptimal predictions made by the teacher model during distribution matching?\n2. By transforming a sequential decision process into a one-shot mapping, the model might sacrifice some expressive power for computational efficiency. Could you discuss the theoretical limitations this imposes, especially when addressing highly complex or unseen degradations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Na4D5kzlSU", "forum": "T2Oihh7zN8", "replyto": "T2Oihh7zN8", "signatures": ["ICLR.cc/2026/Conference/Submission9446/Reviewer_gJQV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9446/Reviewer_gJQV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761718513093, "cdate": 1761718513093, "tmdate": 1762921043094, "mdate": 1762921043094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a VAR-based distillation framework that distills the generative prior of a pretrained VAR model into a one-step model to achieve more efficient real-world image super-resolution. In addition, the authors propose a full-attention-based cross-scale conditioning mechanism to further improve generation quality. Experiments on multiple datasets demonstrate significant improvements on no-reference metrics."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper’s narrative is coherent, the language is clear and fluent, and it is easy to follow.\n\n2. Beyond super-resolution, the authors also conduct experiments on de-raining and low-light enhancement, demonstrating the effectiveness of the method.\n\n3. Through ablation studies, the paper validates the effectiveness of each component."}, "weaknesses": {"value": "From Table 1, although the method shows clear gains on no-reference metrics, its performance on reference-based metrics is poor. This result may suggest a fidelity–perception trade-off; the authors should explain possible reasons for the weak reference-based performance."}, "questions": {"value": "Why is a restorer used as a preprocessing step? How does the VAR model perform without it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IN0Ri4fufs", "forum": "T2Oihh7zN8", "replyto": "T2Oihh7zN8", "signatures": ["ICLR.cc/2026/Conference/Submission9446/Reviewer_BsAZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9446/Reviewer_BsAZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761747222097, "cdate": 1761747222097, "tmdate": 1762921042812, "mdate": 1762921042812, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes VARestorer, a one-step visual autoregressive (VAR) distillation framework for real-world image super-resolution (Real-ISR). The method addresses two key challenges in applying VAR to ISR: (1) the next-scale prediction mechanism's limited ability to exploit global low-quality context, and (2) error accumulation during iterative prediction. VARestorer distills a pre-trained text-to-image VAR model into a one-step model using distribution matching, and introduces cross-scale pyramid conditioning with full attention to better leverage input information. Experiments on DIV2K-Val, DrealSR, and RealSR show improvements on perceptual metrics (72.32 MUSIQ, 0.7669 CLIPIQA) with 10× faster inference than vanilla VAR."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper has clear problem motivation, Identifies specific limitations of VAR for ISR (error accumulation, limited context)\n2. Solid experimental setup: LODO protocol, multiple datasets, standard metrics\n3. Good visual quality: Figure 1, 4 show appealing results\n4. Ablations validate components: Table 3 shows each component contributes\n5. Practical efficiency: One-step inference is desirable for deployment"}, "weaknesses": {"value": "1. This paper has weak theoretical foundation, including the following points:\n- KL divergence formulation (Eq. 3) with mismatched conditioning lacks justification\n- No analysis of distillation convergence or optimality\n- Cross-scale full attention's compatibility with autoregressive generation unclear\n- Missing theoretical characterization of when method should succeed/fail\n\n2. Insufficient experimental rigor:\n- Training 1 epoch (10K steps) without convergence analysis is concerning\n- Teacher fine-tuning on 512×512 (vs. original 1024×1024) impact not studied\n- Baseline comparison potentially unfair (VARSR-10 vs VARestorer-1)\n- No sensitivity analysis of loss weights (λKL, λperc, λMSE)\n- \"w/o distill\" baseline terrible but not investigated\n\n3. Method limitations underexplored:\n- Caption dependency critical but only qualitatively discussed (Figure G), also failure on severe degradation acknowledged but not analyzed.\n- Fixed resolution (512×512) limits practical utility\n- PSNR/SSIM degradation vs. baselines suggests fidelity issues\n\n\n4. For presentation:\n- Parameter count inconsistencies (1.2% vs 0.09% vs 27.3M)\n- Cross-scale conditioning implementation vague\n- Missing algorithmic details for key components\n- No discussion of why VAR is preferable to diffusion"}, "questions": {"value": "1. In Equation (3), pT and pS have different conditioning. How do you compute DKL(pT(rk | rHQ,<k) || pS(rˆk | rLQ))? Is this importance sampling, or are you assuming some form of equivalence?\n2. How does \"cross-scale full attention\" preserve the autoregressive property of VAR? Don't future scales condition on past scales in VAR? Providing the attention mask explicitly would help.\n3. Teacher fine-tuning: Why fine-tune the 1024×1024 VAR on 512×512? Doesn't this lose the high-resolution knowledge? Have you tried using the original teacher directly?\n4. Training sufficiency: Why only 10K steps (1 epoch)? Have you verified convergence? What happens with more training?\n5. Which is correct: 1.2% (abstract), 0.09% or 1.78M (Appendix A), or 27.3M (Table 2)?\n6. Table 3 shows \"w/o distill\" performs very poorly. Does this mean VAR is inherently unsuitable for ISR without distillation?\n7. Why does VARSR need 10 steps? Have you tried VARSR with 1 step for fair comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IwKNSzGG8x", "forum": "T2Oihh7zN8", "replyto": "T2Oihh7zN8", "signatures": ["ICLR.cc/2026/Conference/Submission9446/Reviewer_YB72"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9446/Reviewer_YB72"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761853139652, "cdate": 1761853139652, "tmdate": 1762921042426, "mdate": 1762921042426, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a distilled VAR framework for real-world image super-resolution. The method distills a single-step student model from a multi-step VAR teacher to achieve faster inference while maintaining visual quality. A multi-step guidance strategy is introduced to reduce accumulated errors during training. Experiments on several benchmarks demonstrate competitive no-reference metrics and visually sharp results compared with existing SR methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written and tackles an important problem in real-world image super-resolution. The idea of distilling a multi-step VAR model into a single-step version is practical and well-motivated for efficiency. Experiments are thorough, covering multiple benchmarks, and the proposed method achieves strong results on several perceptual quality metrics."}, "weaknesses": {"value": "- **Inconsistency in the core motivation and training design.**\n\nThe paper claims that multi-step VAR models suffer from cumulative errors, yet the proposed approach distills knowledge from a multi-step VAR teacher. Since the teacher’s outputs are already affected by the same multi-step bias, the student may inherit those errors rather than eliminating them. This raises a conceptual inconsistency between the stated problem and the actual training setup, making it unclear whether the proposed method truly mitigates error accumulation or simply compresses it into a single step.\n\n- **Mismatch between metrics and visual realism.**\nAlthough the method achieves significantly higher no-reference quality scores on RealSR, the visual results (e.g., the flower example in Fig. 4) exhibit unrealistic, hallucinated textures. The generated details appear sharp but not natural, suggesting that the improvement in perceptual metrics may come from artificial high-frequency patterns rather than faithful detail recovery. This discrepancy questions whether the claimed perceptual gains reflect genuine visual quality improvements.\n\nIf these concerns are properly addressed and clarified, I would be willing to consider raising my score."}, "questions": {"value": "please see the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UucoaCfSv2", "forum": "T2Oihh7zN8", "replyto": "T2Oihh7zN8", "signatures": ["ICLR.cc/2026/Conference/Submission9446/Reviewer_RnKJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9446/Reviewer_RnKJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931128779, "cdate": 1761931128779, "tmdate": 1762921042115, "mdate": 1762921042115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}