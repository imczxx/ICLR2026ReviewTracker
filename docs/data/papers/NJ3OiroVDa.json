{"id": "NJ3OiroVDa", "number": 24491, "cdate": 1758357368635, "mdate": 1763722358319, "content": {"title": "Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse", "abstract": "Self-referential learning---training a model on data it generated itself---promises\n\t\tboundless scalability but chronically suffers from \\emph{model collapse}: language\n\t\tmodels degenerate into repetitive text, GANs drop modes, and reinforcement-learning\n\t\tpolicies over-exploit. Although practitioners employ ad~hoc fixes such as real-data\n\t\tmixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation,\n\t\ta single principle that explains both the failure mode and the success of these\n\t\tfixes has remained elusive.\n\t\t\n\t\tWe present \\textbf{Entropy-Reservoir Bregman Projection} (ERBP), an\n\t\tinformation-geometric framework that unifies these phenomena. We model the closed\n\t\tloop as a stochastic Bregman projection sequence in distribution space. Without\n\t\texternal coupling, finite-sample noise forces the system to project onto an\n\t\tever-shrinking empirical support, causing exponential entropy decay and eventual\n\t\tcollapse. Introducing an \\emph{Entropy Reservoir}---a high-entropy distribution\n\t\tmixed into each projection---injects a controllable entropy flux that provably\n\t\tstabilises the dynamics.\n\t\t\n\t\tOur theory yields (i) a necessary condition for collapse, (ii) a sufficient\n\t\tcondition that guarantees a non-trivial entropy floor, and (iii) closed-form rates\n\t\tthat depend only on sample size and the strong-convexity/Lipschitz constants of\n\t\tthe Bregman generator. Experiments on large-language-model self-training, Soft\n\t\tActor-Critic in reinforcement learning, and GAN optimisation validate our\n\t\tpredictions and show that disparate stabilisation heuristics correspond to\n\t\tspecific reservoir choices and coupling coefficients. ERBP thus transforms a\n\t\tcollection of folk remedies into a single, quantitative design rule: monitor and\n\t\tbudget your entropy flux.", "tldr": "Self-training is a stochastic Bregman-projection loop whose entropy inevitably vanishes unless it is continuously mixed with a high-entropy reservoir—an insight that unifies and explains all existing anti-collapse tricks.", "keywords": ["self-referential learning", "model collapse", "entropy reservoir", "Bregman projection", "information geometry", "generative AI"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e2835f3cf5360b73bf597eb716c4487933b33b34.pdf", "supplementary_material": "/attachment/13e20bbe8c3b74332052c5feda1cb01ce7d9e6c3.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Entropy-Reservoir Bregman Projection (ERBP) that derive the necessary condition for collapse, and a sufficient condition for a non-trivial entropy floor."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- This paper analyze the dynamics of self-referential learning systems with Entropy-Reservoir Bregman Projection framework\n- Rigorous proofs and empirical experiments are provided"}, "weaknesses": {"value": "- Some notations appear before being properly defined, such as $P_{res,t}$ and $\\lambda_t$ in lines 64–65. Providing brief explanations when first introduced would improve readability.\n- The presentation of Sections 4.2 and 4.3 could be strengthened by adding more narrative around the proof logic and the connections between theorems, rather than only listing results. This would help readers follow the reasoning flow more clearly.\n- The experimental section is relatively weak compared to the theoretical part. It would be beneficial to include additional comparisons with related methods mentioned in the related work to better demonstrate the advantages of the proposed approach."}, "questions": {"value": "- The abstract should be presented as a single coherent paragraph rather than being split into multiple short ones. Merging them would improve readability and make the summary flow more naturally."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sQ6Iju9lK9", "forum": "NJ3OiroVDa", "replyto": "NJ3OiroVDa", "signatures": ["ICLR.cc/2026/Conference/Submission24491/Reviewer_qXAV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24491/Reviewer_qXAV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760691766821, "cdate": 1760691766821, "tmdate": 1762943102095, "mdate": 1762943102095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an information-geometric framework, called Entropy-Reservoir Bregman Projection (ERBP), to unify different phenomena of model collapse across LLMs, GANs, and RL agents. The authors model self-referential training loops as stochastic Bregman projection sequences in distribution space, where entropy tends to shrink without external coupling. They introduce the concept of an Entropy Reservoir to counteract entropy decay."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The novelty is ok. Recasting self-training dynamics as Bregman projection processes is novel and potentially unifying for understanding entropy decay across domains.\n\n2. This paper is clearly organized, with some tables summarizing conceptual mappings."}, "weaknesses": {"value": "1. Mathematical inconsistency / over-claim in theoretical findings, e.g., thm 1.\n\n2. Lack of proof detail. For example, in the proof of thm 1,  what does ``martingale convergence plus the support argument of the main text finishes the proof.'' mean?"}, "questions": {"value": "1. In Theorem 1, how can the authors claim that full collapse to a single mode is inevitable when inequality (5) only upper-bounds the expected entropy by $C_F(m) + \\frac{L_F \\kappa}{\\alpha}$ (which is strictly positive, e.g. $\\log m > 0$ for the Shannon case)? What additional assumptions or steps would be required to make this conclusion mathematically valid?\n\n2. In experimental evaluation,  what exact $\\lambda$ value and reservoir sampling process were used? How was the ``entropy proxy'' (unique n-gram count) computed and normalized?\n\n3. Does the framework hold if the model manifold M is highly non-convex and projections are approximate (large $\\epsilon_{\\max}$)? How sensitive are the results to $\\epsilon_{\\max}$ assumptions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dAaW54BvUi", "forum": "NJ3OiroVDa", "replyto": "NJ3OiroVDa", "signatures": ["ICLR.cc/2026/Conference/Submission24491/Reviewer_AZMF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24491/Reviewer_AZMF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902176878, "cdate": 1761902176878, "tmdate": 1762943101710, "mdate": 1762943101710, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Entropy-Reservoir Bregman Projection (ERBP) as a unified information-geometric lens on ``model collapse'' in self-referential learning loops (LLMs trained from synthesized data, GANs, RL). They model each round as a stochastic Bregman projection onto a target formed by mixing the empirical self-samples with a high-entropy reservoir using coefficient $\\lambda$. Without the reservoir ($\\lambda$=0), generalized entropy contracts toward a small-support limit, but any sustained coupling guarantees a non-trivial entropy floor, with rates controlled by sample size and the generator's strong-convexity/Lipschitz constants. A small simulation with a frozen LLM shows entropy decay with $\\lambda$=0 and stability with $\\lambda$>0."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1) The paper provides a unifying perspective that cleanly ties together disparate \"folk remedies\" via the $\\lambda$-coupled reservoir.\n2) The proposed method provides simple, quantitative conditions that are easy to reason about and potentially monitor during training.\n3) The results are demonstrated with a breadth across various divergences beyond just KL."}, "weaknesses": {"value": "1) The use of terminology is a little bit confusing. As a researcher from the generative models community, the term that I'm more familiar with is \"mode collapse\" instead of \"model collapse\". I originally thought the authors wanted to propose a new definition that describes a different class of model failure case, but according to the paper it seems like the authors are just describing \"mode collapse\". Please correct me if I'm wrong.\n\n2) While the proposed framework can be very promising, and in fact the case of RL and GAN validations may be covered too, the authors choose to leave them as planned future work and only focus on single frozen-LLM loop, which is a little bit disappointing. I recommend to at least show some rather simple cases in RL, since this can take less efforts than in GANs and will make the paper more impactful.\n\n3) The projection-as-dynamics viewpoint is interesting, but parts echo standard entropic regularization intuitions; the delta over prior collapse analyses (e.g., recursion-curse) could be sharpened in positioning."}, "questions": {"value": "1) How do you propose estimating $\\epsilon_{max}$ during scaled-up settings?\n\n2) How specifially does algorithms like top-p sampling impact the distribution under your framework? Could you extend your current analysis with a given step probability cap $p$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "laGsaU4uHW", "forum": "NJ3OiroVDa", "replyto": "NJ3OiroVDa", "signatures": ["ICLR.cc/2026/Conference/Submission24491/Reviewer_87SS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24491/Reviewer_87SS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975290374, "cdate": 1761975290374, "tmdate": 1762943101461, "mdate": 1762943101461, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response to All Reviewers"}, "comment": {"value": "We thank all reviewers for their insightful comments. The primary concern raised across reviews was the lack of empirical validation for our theoretical claims regarding GANs and RL. We have significantly revised the paper to address this. Section 6 now includes full experimental validation across three domains:\n\nLLM Self-Training (Exp 2): Differentiating between knowledge collapse and functional degeneracy.\nRecursive GANs (Exp 3): Demonstrating mode collapse and reservoir stabilization on MNIST.\nReinforcement Learning (Exp 4): Showing how reservoirs prevent policy collapse in non-convex landscapes.\nWe believe these additions substantiate the unification claims made in the abstract."}}, "id": "iRh7jE7xA9", "forum": "NJ3OiroVDa", "replyto": "NJ3OiroVDa", "signatures": ["ICLR.cc/2026/Conference/Submission24491/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24491/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24491/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763723119934, "cdate": 1763723119934, "tmdate": 1763723119934, "mdate": 1763723119934, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the \"Entropy-Reservoir Bregman Projection\" (ERBP) framework, a novel information-geometric model to unify the phenomenon of model collapse in self-referential learning. The authors model this process as a stochastic Bregman projection sequence, arguing that entropy-decay and collapse are inevitable unless coupled with a high-entropy \"Entropy Reservoir\". This concept is used to provide a unified explanation for various stabilization techniques, from real-data mixing to Retrieval-Augmented Generation (RAG)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper has a few strengths:\n1. The core idea of modeling self-referential learning as a Bregman projection dynamical system is elegant and provides a powerful new language for analyzing these systems.\n2. The \"Entropy Reservoir\" concept is insightful, successfully connecting disparate, seemingly ad hoc techniques (like data mixing, RLHF, and label smoothing) under a single, coherent mathematical principle.\n3. The paper provides theoretical proofs for its claims, formalizing the conditions for both entropy collapse (Theorem 1) and stability (Theorem 2)."}, "weaknesses": {"value": "The paper's primary, and critical, weakness is a failure to substantiate its broad claims with empirical evidence. The experimental section is critically incomplete:\n\n1. The abstract explicitly claims validation across large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation. However, Section 6 directly contradicts this, stating that the work on \"LLM fine-tuning and reinforcement learning\" is \"planned future work\". The GAN experiment is never mentioned again. This misrepresentation of the work's completion status is a major flaw.\n2. The only experiment provided (Section 6.1) is insufficient as a proof of concept. It uses a frozen distilgpt2 model and shows that feeding its own output back as a prompt (with $\\lambda=0$) leads to repetition. This demonstrates context collapse in an autoregressive loop, but it does not test the paper's core theoretical claim, which is about model collapse resulting from self-referential training (i.e., an optimization and projection step that updates the model's parameters or state).\n\nWhile the theoretical framework presented is promising and insightful, the paper is incomplete. The empirical validation promised in the abstract is essential for supporting the paper's unification claims, but it is explicitly admitted to be \"planned future work\". The single experiment that is present does not adequately test the central theory of collapse during training. Therefore, the paper should be rejected in its current form."}, "questions": {"value": "Please see the Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "R8esOx5Nlv", "forum": "NJ3OiroVDa", "replyto": "NJ3OiroVDa", "signatures": ["ICLR.cc/2026/Conference/Submission24491/Reviewer_nJEy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24491/Reviewer_nJEy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24491/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762294312645, "cdate": 1762294312645, "tmdate": 1762943101232, "mdate": 1762943101232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}