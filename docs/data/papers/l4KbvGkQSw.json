{"id": "l4KbvGkQSw", "number": 7347, "cdate": 1758017200394, "mdate": 1759897858379, "content": {"title": "PhysTTT: Accurate and Lightweight Cross-Domain Heart Rate Measurement with Test-Time Training", "abstract": "Remote photoplethysmography (rPPG), a contactless technology for measuring physiological signals, holds significant promise for smart healthcare and affective computing. However, a key challenge for existing deep learning methods is the paradox between maintaining high measurement accuracy and ensuring low computational cost, especially in cross-domain scenarios. To address this, we propose PhysTTT, a novel and lightweight framework for heart rate measurement that integrates multiple 1D-CNNs with residual structures and a Test-Time Training (TTT) layer. Multi-time frame differences fusion and 1D-CNNs extract spatio-temporal features from facial video sequences by modeling subtle brightness variations, the TTT layer compresses the context information into a learnable vector space, enhancing the temporal modeling capability. Crucially, the TTT mechanism enables the model to adapt to unseen data distributions during inference, significantly boosting cross-domain generalization. Extensive experiments demonstrate that PhysTTT achieves state-of-the-art accuracy in both in-domain and cross-domain evaluations, offering an optimal balance of high performance, strong generalization, and low computational cost. Our code is publicly available at https://anonymous.4open.science/r/PhysTTT-B605/.", "tldr": "Measure heart rate using the test-time training method in cross-domain scenarios.", "keywords": ["rPPG", "Heart rate measurement", "Test-Time Training", "Cross-domain"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5175a6b06504ffb097fbc5305aa14b930d5a1277.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work introduces a lightweight rPPG measurement framework that leverages test-time training to enhance adaptability in cross-domain scenarios. The method focuses on enforcing temporal consistency through multi-objective losses that align waveform trends and spectral components with physiological patterns. The approach shows promise for practical deployment due to its low complexity and ability to update online at inference time (Table 5)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The model achieves competitive performance with a compact architecture, demonstrating a strong balance between computational efficiency and prediction accuracy suitable for real-time or mobile deployment.\n\n2. By updating parameters during inference, the method adapts dynamically to unseen conditions and distributions, improving robustness when deployment environments differ from the training domain."}, "weaknesses": {"value": "1. The frequency and waveform stability is mainly enforced by the definition of the lost function. While the model itself have simple architectures without explicit ability to help on the temporal structure of rPPG. A better design or an explanation of why keeping the model architecture simple is needed.\n\n2. The cross-domain evaluation currently focuses only on UBFC-rPPG and VIPL-HR. These datasets share limited diversity in terms of illumination, subject motion, and demographic variations. As a result, the reported cross-domain gains may largely reflect spectral alignment improvements rather than true robustness to heterogeneous real-world conditions. Including more challenging and diverse datasets such as MMPD or BUAA would provide a more comprehensive assessment of generalization performance, particularly regarding sensitivity to skin tone variation, lighting shifts, and motion artifacts, which are key factors in practical deployment."}, "questions": {"value": "1. What is the reason of separating the optimization process into an inner-outer loop? Does the optimization of W and theta be split to ensure convexity or smoothness? Or it is simply based on empirical observation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bWTFh4AGAQ", "forum": "l4KbvGkQSw", "replyto": "l4KbvGkQSw", "signatures": ["ICLR.cc/2026/Conference/Submission7347/Reviewer_pzPR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7347/Reviewer_pzPR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761700386704, "cdate": 1761700386704, "tmdate": 1762919483159, "mdate": 1762919483159, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel Test-Time Training (TTT) framework for remote physiological signal measurement. The proposed approach employs multi-frame difference fusion techniques and leverages 1D-CNNs to extract spatio-temporal features from facial video sequences. The TTT layer subsequently compresses contextual information from video frame sequences into a self-supervised learning model, enabling adaptation to unseen domain distributions during the testing phase. Experimental results demonstrate that the method outperforms existing state-of-the-art approaches, exhibiting precise and efficient measurement capabilities."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The method systematically introduces Test-Time Training into the Test-Time Adaptation framework for remote photoplethysmography (rPPG), effectively addressing domain shift issues in this field.\n2. The proposed approach achieves a favorable balance between measurement accuracy and computational cost, thereby enhancing the generalizability of remote physiological signal measurement, which is particularly valuable for real-world deployment.\n3. Comprehensive experiments validate the exceptional performance of the method in both in-domain and cross-domain scenarios.\n4. The paper is well-written with a clear narrative structure, adequately covers related work, and distinctly highlights its contributions."}, "weaknesses": {"value": "1. In lines 084–086 of the introduction, the authors state that “While SSMs offer a better balance between linear complexity and long-range modeling, they can face limitations in generalization and parallel processing, particularly in cross-domain scenarios where model robustness is critical.” This claim lacks sufficient justification or empirical evidence.\n2. In line 088 of the introduction, there are several citation errors. Specifically, Dual-GAN is a standard supervised learning method, while Dual-bridging belongs to the domain generalization category, not domain adaptation, as stated by the authors.\n3. Section 2.2 of the related work is unclear and lacks logical structure. It is not evident what the authors intend to convey, nor why “PhysTTT effectively captures spatial information.” This section needs a clearer focus and stronger justification.\n4. The Frame Stem module described in Section 3.2 is nearly identical to those used in RhythmFormer and RhythmMamba. This component should not be claimed as a novel contribution, and the authors must explicitly clarify this overlap in the paper.\n5. All formulas in the paper are missing serial numbering, which violates the standard formatting and submission requirements of academic papers.\n6. Both the intra-dataset and cross-dataset experiments only consider illumination variations, without evaluating robustness under other common noise factors such as head motion. This is a significant limitation in the experimental design.\n7. The paper reports cross-domain experiments only on UBFC-rPPG and VIPL-HR, which are not sufficiently diverse. It is recommended to validate the proposed method on a broader range of datasets (e.g., MMPD, MR-NIRP-Car) to demonstrate robustness and generalization.\n8. Table 5 mentions “Throughput” in its caption, but the corresponding quantitative results are missing. \n9. The paper lacks crucial ablation studies on these core modules and the self-supervised learning strategy, as well as validation on alternative backbones to verify the generality of the proposed approach."}, "questions": {"value": "1. The paper does not clearly explain the conceptual and practical differences between TTT (Test-Time Training) and TTA (Test-Time Adaptation). What are the respective advantages and disadvantages of TTT compared to TTA, and why is TTT considered more suitable for rPPG tasks?\n2. The source of the model’s strong cross-domain performance remains unclear. To what extent does it stem from the carefully designed 1D-ResNet and frame-difference backbone, and to what extent from the TTT adaptation layer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "a6m3fcmk1j", "forum": "l4KbvGkQSw", "replyto": "l4KbvGkQSw", "signatures": ["ICLR.cc/2026/Conference/Submission7347/Reviewer_jTxE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7347/Reviewer_jTxE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898333775, "cdate": 1761898333775, "tmdate": 1762919482587, "mdate": 1762919482587, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose PhysTTT, a Test Time Training framework for remote heart rate estimation. The authors claim this to be a first time experiment with TTT in the domain and this seeks to address cross-domain generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors aim to tackle a known problem of cross-domain generalization in the rPPG domain. This is crucial as rPPG signals are extremely sensitive to environment settings, and also to skin tones."}, "weaknesses": {"value": "- The authors can explore more datasets where the experiments settings are different.\n  - For example, PURE has 6 types of movement in the dataset. COHFACE has natural and artificial lightning and is a challenging dataset.\n- The authors should also compare their work with other approaches on the task to further elucidate their results and contributions."}, "questions": {"value": "- I understand that some of the design choices around using 1D CNNs was around efficiency, however do the authors think too much information is being lost in the pooling layer in the Frame-Stem, and then subsequently utilizing 1D CNNs in the pipeline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z1JXR0UchY", "forum": "l4KbvGkQSw", "replyto": "l4KbvGkQSw", "signatures": ["ICLR.cc/2026/Conference/Submission7347/Reviewer_bqbB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7347/Reviewer_bqbB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937758728, "cdate": 1761937758728, "tmdate": 1762919477002, "mdate": 1762919477002, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the paradox between high accuracy and low computational cost in cross-domain remote photoplethysmography (rPPG)-based heart rate measurement, this paper proposes PhysTTT, a lightweight framework integrating multiple 1D-CNNs with residual structures and a Test-Time Training (TTT) layer. The frame stem amplifies subtle skin color variations through multi-time frame differences fusion, 1D-ResNet layers extract local spatio-temporal features, and the TTT layer dynamically adapts to unseen data distributions during inference by updating model weights, thereby enhancing cross-domain generalization. Equipped with a multi-dimensional loss function (trend pattern alignment, frequency domain alignment, and waveform feature alignment) for fine-grained BVP signal recovery, PhysTTT is evaluated on UBFC-rPPG and VIPL-HR datasets, achieving state-of-the-art performance in both in-domain and cross-domain (including cross-dataset and cross-illumination) scenarios while maintaining low computational cost (42.64M MACs and 7.08M peak GPU memory usage), demonstrating great potential for real-world healthcare applications."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. It is the first work to introduce the Test-Time Training (TTT) paradigm into rPPG research, effectively solving the challenge of adapting to unseen data distributions in cross-domain scenarios that traditional methods struggle with.\n2. The multi-dimensional loss function designed for rPPG tasks (integrating negative Pearson correlation loss, power spectral density loss, and peak alignment loss) enables precise alignment of predicted and ground truth BVP signals, significantly improving the accuracy of heart rate measurement.\n3. The comprehensive experimental validation (covering in-domain, cross-dataset, and cross-illumination evaluations) and ablation study fully demonstrate the effectiveness of each module, while the lightweight design (low parameters, MACs, and GPU memory usage) ensures its applicability on resource-constrained devices."}, "weaknesses": {"value": "1. The paper does not provide detailed analysis on the real-time performance of PhysTTT, especially the additional latency introduced by the TTT layer’s parameter updates during inference, which is critical for practical deployment in real-time health monitoring.\n2. Cross-domain evaluations are limited to two datasets (UBFC-rPPG and VIPL-HR) and three illumination conditions, lacking validation in more diverse scenarios such as different camera devices, extreme motion, or varied skin tones, which may restrict the generalization of the conclusions.\n3. The ablation study only verifies the overall contribution of key modules (frame stem, 1D-ResNet, TTT layer) but fails to explore the impact of critical hyperparameters (e.g., the balance factor α in peak alignment loss) or compare with different TTA variants, leaving room for optimizing the model’s design."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "zvUAAZCO6A", "forum": "l4KbvGkQSw", "replyto": "l4KbvGkQSw", "signatures": ["ICLR.cc/2026/Conference/Submission7347/Reviewer_Ehji"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7347/Reviewer_Ehji"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968061564, "cdate": 1761968061564, "tmdate": 1762919475961, "mdate": 1762919475961, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}