{"id": "FAK3lJSRQQ", "number": 25386, "cdate": 1758367416008, "mdate": 1762611117868, "content": {"title": "ExLLM: Experience-Enhanced LLM Optimization for Molecular Design and Beyond", "abstract": "Molecular design involves an enormous and irregular search space, where traditional optimizers such as Bayesian optimization, genetic algorithms, and generative models struggle to leverage expert knowledge or handle complex feedback. Recently, LLMs have been used as optimizers, achieving promising results on benchmarks such as PMO. However, existing approaches rely only on prompting or extra training, without mechanisms to handle complex feedback or maintain scalable memory. In particular, the common practice of appending or summarizing experiences at every query leads to redundancy, degraded exploration, and ultimately poor final outcomes under large-scale iterative search. We introduce ExLLM, an LLM-as-optimizer framework with three components: (1) a compact, evolving experience snippet tailored to large discrete spaces that distills non-redundant cues and improves convergence at low cost; (2) a simple yet effective k-offspring scheme that widens exploration per call and reduces orchestration cost; and (3) a lightweight feedback adapter that normalizes objectives for selection while formatting constraints and expert hints for iteration. ExLLM sets new state-of-the-art results on PMO and generalizes strongly—in our setup, it sets records on circle packing and stellarator design, and yields consistent gains across additional domains—requiring only a task-description template and evaluation functions to transfer.", "tldr": "ExLLM is an LLM-as-Optimizer with experience, offspring, and feedback mechanisms, achieving SOTA in molecular design and generalizing to diverse discrete optimization tasks with minimal problem templates.", "keywords": ["Large Language Models", "Molecular Design", "Evolutionary Algorithms", "Discrete Optimization"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/565d3e43e701210d23422f488938de88d1fae4e2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose ExLLM, a framework that enables the effective utilization of LLMs for molecular design without re-engineering or additional training. ExLLM employs a k-offspring and an evolving experience mechanism to achieve efficient exploration and maintain a non-redundant population. Moreover, the proposed feedback adapter allows the framework to perform consistent and stable optimization in multi-objective settings"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a compelling framework that leverages pretrained LLMs as optimizer without requiring any additional training. Also, ExLLMs showed improved performance gains in both single-objective and multi-objective optimization tasks\n\n- The k-offspring and evolving experience effectively enhance the exploration capability of pretrained LLMs while reducing the number of API calls and costs. This design choice represents a novel contribution that improves efficiency without sacrificing optimization quality"}, "weaknesses": {"value": "- In the paper, the comparison with other LLM-as-optimizer models is somewhat limited. While approaches such as OPRO, LMEA, and AlphaEvolve are mentioned, the paper does not provide experimental results against them in the molecular design. Moreover, other relevant molecular design-aware LLM frameworks (e.g., ChemCrow, LICO, MolReGPT, Prompt-MolOpt) are discussed but not empirically compared.\n\n- The paper primarily relies on GPT-4o or Gemini, without evaluating open-source LLMs such as Llama[1] or Qwen[2].\n\n- Although the work is positioned as an LLM optimizer for molecular design, the paper provides limited discussion on molecular design.\n\n- Figure 1 could be improved for clarity. Some key components(e.g., k-offspring) are not visually highlighted, making it somewhat difficult for readers. \n\n[1] Dubey, Abhimanyu, et al. \"The llama 3 herd of models.\" arXiv e-prints (2024): arXiv-2407.\n\n[2] Yang, An, et al. \"Qwen3 technical report.\" arXiv preprint arXiv:2505.09388 (2025)."}, "questions": {"value": "- (w1)The authors do not present experimental comparisons with other LLM-as-optimizer models in molecular design. While existing LLM optimizer studies (e.g., OPRO, LMEA, AlphaEvolve) may not be specifically designed for molecular design tasks, ExLLM also operates without explicit in-context learning, prompt engineering, or domain-specific feedback. Therefore, it seems feasible to evaluate these LLM optimizer frameworks on molecular design. In addition, could you clarify why MOLLEO was selected as the only molecular-design baseline(e.g., ChemCrow, LICO, MolReGPT, Prompt-MolOpt)? If there are practical constraints in evaluating agent-based frameworks or using external chemical tools, it would be helpful to mention that explicitly, and include comparisons with any executable models if possible.\n\n-  (w2)The paper only presents results using GPT-4o and Gemini. However, it seems that other open-source LLMs such as Llama[1], Qwen[2] could also be applied to ExLLM. In particular, Qwen[2], which adopts a Mixture-of-Experts (MoE) architecture, is expected to offer advantages in terms of API calls and inference time. It would be helpful to include additional ablation experiments comparing their cost and performance.\n\n-  (w3)Although the paper is positioned as an LLM optimizer for molecular design, there is little discussion related to the generated molecules. In particular, since k-offspring is introduced only in the ablation study, it would be helpful to include a brief analysis of the sampled offspring themselves.  Moreover, a pareto front plot and an oracle call curve (for PMO single-objective optimization) are not presented. \n\n- In Table 2(and Table 10), the reported diversity appears to be somewhat lower, even though uniqueness remains high. Could you elaborate on this observation? Is the lower diversity mainly due to differences in how the metric is defined, or should it be understood as a trade-off between fitness and diversity?\n\n- Could you provide more details on the selection process? It could be viewed as a form of sampling, but it currently appears to be implemented solely as a weighted-sum operation. Are there any experiments comparing this approach with other selection methods? For example, methods such as Chebyshev scalarization sampling[3], Tchebycheff Scalarization[4], or Dirichlet distribution–based sampling[5] could also be considered. Are these approaches incorporated into the pareto front–based selector? Additional explanation of the fitness and pareto selectors would be helpful.\n\n- In the appendix ‘7.9 NUMBER OF OUTPUT MOLECULES’, “Table??” appears to be a LaTeX mapping error. Please correct it.\n\n[3] Chugh, Tinkle. \"Scalarizing functions in Bayesian multiobjective optimization.\" 2020 IEEE Congress on Evolutionary Computation (CEC). IEEE, 2020.\n\n[4] Lin, Xi, et al. \"Smooth tchebycheff scalarization for multi-objective optimization.\" arXiv preprint arXiv:2402.19078 (2024).\n\n[5] Shin, Dong-Hee, et al. \"Offline Model-based Optimization for Real-World Molecular Discovery.\" Forty-second International Conference on Machine Learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p7QJV1MaGm", "forum": "FAK3lJSRQQ", "replyto": "FAK3lJSRQQ", "signatures": ["ICLR.cc/2026/Conference/Submission25386/Reviewer_CwLi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25386/Reviewer_CwLi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25386/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731113819, "cdate": 1761731113819, "tmdate": 1762943420381, "mdate": 1762943420381, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces an LLM-as-optimizer framework with three contributions: an evolving experience snippet, a k-offspring scheme, and a feedback adapter for molecular design and optimization. Under fixed evaluation budgets this approach improves on PMO benchmark, across single- and multi-objective molecular optimization settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The manuscript reads mostly clearly.\nStrong results on PMO benchmark.\nThe experiments included extra in addition to small molecules such as peptides.\nSix-objective experiments with good results are novel."}, "weaknesses": {"value": "The three main contributions seem to focus on “low cost” but discussion on cost perspective significantly lacks. \nThe framework looks close to MOLLEO, as LLMs handle mutation and crossover on the parent molecules and the evaluation and update pools rely on conventional metrics, even if the templates looked carefully crafted in their overview.\n\nFigure 1 and the method section do not provide a clear end-to-end overview. Subsections in Section 3 Method do not fully match the figure. The paper should clarify how the next population is selected in single vs multi objective cases, given that Pareto selection applies only to multi objective settings. \n\nEditorial issues. Please look through the whole manuscript and fix indexing. Below are some wrong referencing I have found.\n-line 141 says Figure 8 for the framework overview, but I assume they refer to Figure 1.\n-Table 2 is missing some boldface for some best results.\n-Around lines 316-317, the text points to Table 10 which appears to mean Table 2.\n\nMore concerns and questions will be placed in Questions section below."}, "questions": {"value": "This lies with Weakness 1 regarding the main contributions. Could you compare cost directly and show how the framework reduces cost, for example with ablations or matched cost vs quality analysis in detail?\n\nReading through the method and the overview figure, I assume the task-specific templates and the prompts seem very important, yet details are limited. Please describe design choices.\n\nThe LLM-as-optimizer idea is emphasized, but the final decision makers are a fitness-based selector and a Pareto front-based selector for next populations and choosing the best molecules. Have you done some ablations that replaces LLM proposals with molecules that are generated in rule-based way and optimizes with the fitness/pareto-based selectors?\n\nIn Figure 2 in Ablation study, GPT-based variants are consistently better in both single and five objective settings regardless of k. The curves over k do not show a stable pattern, especially in multi-objective setting. Clear evidence that k  offspring scheme itself actually add meaningful contribution to the framework should be included. \n\nIn multi objective molecular optimization, some objectives like QED and SA are easier than others. In the five-objective setting, can you provide evidence that the framework balances the objectives rather than leaning on easy objectives? For example, through per-objective improvements and coverage of the Pareto front."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cSdDaNQ99U", "forum": "FAK3lJSRQQ", "replyto": "FAK3lJSRQQ", "signatures": ["ICLR.cc/2026/Conference/Submission25386/Reviewer_ds92"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25386/Reviewer_ds92"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25386/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875846069, "cdate": 1761875846069, "tmdate": 1762943420191, "mdate": 1762943420191, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ExLLM (Experience-Enhanced LLM Optimization), which is a framework that uses LLM as optimizers for molecular design and other large discrete optimization problems. The proposed framework addresses key limitations of existing LLM-based methods for molecular design, which are often heavily prompt-dependent, require additional training, and lack memory mechanisms suited for large-scale iterative search. ExLLM consists of three main components: (1) an evolving experience mechanism that maintains a single, compact memory snippet updated each generation to distill non-redundant insights from good and bad examples, avoiding the memory bloat and exploration collapse seen in retrieval-style memories; (2) a k-offspring sampling scheme that generates k candidate molecules per LLM call by exploiting autoregressive factorization, widening exploration while reducing the number of LLM queries needed; and (3) a feedback adapter that normalizes multiple objectives into comparable vectors for Pareto-based selection and formats constraints/expert feedback into structured text for the next iteration. The framework uses a hybrid selection strategy, choosing half the population by scalar fitness (weighted sum of normalized objectives) and half from the Pareto front. The experience is injected into prompts with probability p_exp to balance exploitation and exploration."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. I appreciate that the authors address multi-objective optimization, which many molecular generation works either omit or treat superficially. I personally believe that multi-objective optimization is critically important for real-world molecular discovery.\n\n2. The training-free approach requires no additional model training, thereby reducing computational costs compared to other existing methods that require retraining for each new task or property.\n\n3. Generating multiple offspring per LLM call reduces the number of required queries and thus improves computational efficiency."}, "weaknesses": {"value": "**1. Limited Technical Novelty**\n- Using LLMs for molecular design is no longer novel and has become a well-established research direction. The prior works mentioned in the introduction (ChemCrow, LICO, MolReGPT, Prompt-MolOpt, MOLLEO) already demonstrate that LLMs can be effectively applied to molecular generation/optimization tasks.\n\n- The core contribution appears to be incremental tweaking of existing components rather than methodological innovation. The evolving experience mechanism is adapted from prior work (ReEvo, ExpeL as acknowledged by authors), the k-offspring strategy is a straightforward application of autoregressive sampling of LLMs, and the feedback adapter is essentially normalization plus text formatting. Each component individually represents a relatively minor modification to existing techniques.\n\n**2. Insufficient Baseline Comparisons for LLM-based Methods**\n- The authors mention multiple LLM-based molecular design methods in the introduction (ChemCrow, LICO, MolReGPT, Prompt-MolOpt) but only include MOLLEO as a competing LLM-based baseline in the experiments. This creates an incomplete picture of how ExLLM compares to the broader landscape of LLM-based molecular optimization approaches.\n\n**3. Poor Paper Organization and Presentation** \n- Section 2.3 contains only the text \"We have put this part to appendix 7.2,\" which is highly unusual and unprofessional. While moving supplementary details to an appendix is acceptable practice, completely omitting a main-text section and relegating all content to the appendix is inappropriate formatting.\n\n- This organizational choice disrupts the flow of the paper and suggests either careless preparation or an attempt to circumvent page limits. If the LLM-as-optimizer and memory mechanism background is important enough to warrant a section number, it deserves at least a brief summary in the main text with details deferred to the appendix.\n\n**4. Insufficient ablation studies and analysis**\n- No ablation on the hybrid selection strategy (50% fitness-based, 50% Pareto-based). Why this specific ratio? How sensitive is performance to this choice?\n\n- I am still confused and not fully convinced about the clear beneficial effects of the hybrid selection strategy.\n\n- The paper claims the experience mechanism is \"lightweight\" and \"low-redundancy,\" but provides no quantitative analysis of memory consumption, prompt token counts over time, or computational overhead compared to the retrieval-style baseline beyond Table 1."}, "questions": {"value": "1. The paper exclusively uses two proprietary LLMs (GPT-4o and Gemini) without justifying this choice or exploring alternatives. Why were only these specific models selected? Would the proposed framework work with open-source general-purpose LLMs such as Llama, Mistral, Qwen, or DeepSeek? \n2. Also, would chemistry-specific LLMs such as ChemLLM or Galactica potentially perform better given their domain-specific pretraining? \n\n3. The paper extensively evaluates three initialization schemes (worst-init, random-init, best-init) in Table 2, but provides no justification for why these specific schemes are relevant to real-world molecular discovery. In practical drug discovery scenarios, what situation would correspond to \"worst-init\" where researchers deliberately start with the 100 worst-performing molecules? The paper should clarify what real-world molecular discovery processes these initialization schemes are meant to simulate, and why demonstrating robustness across all three is important \n\n4. The paper acknowledges in Table 2 that \"ExLLM delivers substantial gains over the initial populations in all three init schemes, while trading some diversity for finer exploitation\" and that \"the diversity of the final top-100 set is somewhat lower.\" However, molecular diversity is a crucial consideration in real-world drug discovery for several reasons: (1) diverse chemical scaffolds provide multiple starting points for lead optimization; (2) diversity helps hedge against failures in later stages (e.g., toxicity, synthesis issues); (3) intellectual property strategies often require exploring diverse chemical matter. ExLLM's diversity scores are substantially lower than several baselines. How do the authors justify sacrificing molecular diversity for higher fitness in the context of real-world applications where diversity is often explicitly required? Would the framework be unsuitable for scaffold-hopping or exploring novel chemical space?\n\n5. The evolving experience mechanism maintains a single, continually updated snippet that is overwritten each generation. This unidirectional update raises concerns about catastrophic forgetting. For example, early in optimization, certain structural patterns might seem unimportant and get discarded, but they could become critical after the search moves to a different region of chemical space. The paper provides no mechanism to prevent or detect such forgetting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wakmu16SRd", "forum": "FAK3lJSRQQ", "replyto": "FAK3lJSRQQ", "signatures": ["ICLR.cc/2026/Conference/Submission25386/Reviewer_Kohi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25386/Reviewer_Kohi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25386/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761888690555, "cdate": 1761888690555, "tmdate": 1762943419833, "mdate": 1762943419833, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper closely follows the overall workflow of MOLLEO for multi-objective molecular optimization. The main contribution lies in introducing several practical techniques for updating the memory pool and reducing the computational cost associated with feedback processing."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The related work section is well-organized and provides a clear overview of prior research. The paper introduces several strategies to reduce the computational cost in LLM-based molecular optimization, particularly within the MOLLEO framework."}, "weaknesses": {"value": "Overall, the paper does not appear to provide a method with substantial novelty. The proposed approach largely follows the MOLLEO process, and the modifications in the memory update and feedback stages seem a little incremental rather than fundamentally new. The contribution is closer to presenting practical tips for reducing LLM API calling costs and prompt engineering strategies, rather than introducing a novel algorithmic framework.\n\nRegarding the presentation of results, the main tables could be improved for clarity. The current main table contains many blank entries, which hurts readability. I recommend condensing the main table by focusing on a subset of objectives (e.g., 3–6 or 4–6 objectives) and reporting full results in the Appendix. Since the paper also includes experiments with 1–6 objectives, it would be more informative to include strong baselines such as MOLLEO, DyMol, and Genetic-GFN for the higher-dimensional objective settings in the main comparison.\n\nAdditionally, the result tables would benefit from further refinement. The “Worst” and “Best initial” columns contain many empty cells, and it is unclear whether they need to be part of the main results. These analyses feel closer to ablation-level studies and may be more suitable for the Appendix rather than presented as primary results."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "txF1gU6xOX", "forum": "FAK3lJSRQQ", "replyto": "FAK3lJSRQQ", "signatures": ["ICLR.cc/2026/Conference/Submission25386/Reviewer_Yxrt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25386/Reviewer_Yxrt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25386/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915977697, "cdate": 1761915977697, "tmdate": 1762943419625, "mdate": 1762943419625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}