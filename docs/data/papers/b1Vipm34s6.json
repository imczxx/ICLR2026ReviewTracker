{"id": "b1Vipm34s6", "number": 12781, "cdate": 1758210278489, "mdate": 1763562049489, "content": {"title": "Solve Smart, Not Often: Policy Learning for Costly MILP Re-solving", "abstract": "A common challenge in real-time operations is deciding whether to re-solve an optimization problem or continue using an existing solution. While modern data platforms may collect information at high frequencies, many real-time operations require repeatedly solving computationally intensive optimization problems formulated as Mixed-Integer Linear Programs (MILPs). Determining when to re-solve is, therefore, an economically important question. This problem poses several challenges: 1) How to characterize solution optimality and solving cost; 2) How to detect environmental changes and select beneficial samples for solving the MILP; 3) Given the large time horizon and non-MDP structure, vanilla reinforcement learning (RL) methods are not directly applicable and tend to suffer from value function explosion. Existing literature largely focuses on heuristics, low-data settings, and smooth objectives, with little focus on common NP-hard MILPs. We propose a framework called Proximal $\\underline{\\text{P}}$olicy $\\underline{\\text{O}}$ptimization with $\\underline{\\text{C}}$hange Point Detection (POC), which systematically offers a solution for balancing performance and cost when deciding appropriate re-solving times. Theoretically, we establish the relationship between the number of re-solves and the re-solving cost.\nTo test our framework, we assemble eight synthetic and real-world datasets, and show that POC consistently outperforms existing baselines by 2\\%-17\\%. As a side benefit, our work fills the gap in the literature by introducing real-time MILP benchmarks and evaluation criteria.", "tldr": "", "keywords": ["Real-time operation", "Policy learning", "Mixed-Integer Linear Programming"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/2a39c188f1d72cbe54ef6658c0e7376984491b30.pdf", "supplementary_material": "/attachment/b527aef77dc388db14b56dbe6e923a2685ebaa08.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the important real-world problem of determining when to re-solve computationally expensive Mixed-Integer Linear Programs (MILPs) in dynamic environments. The authors propose a framework called Proximal Policy Optimization with Change Point Detection (POC) that balances solution quality and solving cost. The paper establishes theoretical relationships between the number of re-solves and re-solving cost, and demonstrates through extensive experiments on eight synthetic and real-world datasets that POC consistently outperforms existing baselines by 2%-17%. The work fills a significant gap in the literature by introducing real-time MILP benchmarks and evaluation criteria."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses a practically important problem with real-world relevance in operations research and optimization.\n2. Provides both theoretical analysis and extensive experimental validation across diverse datasets.\n3. The theoretical results (Theorems 1 and 2) provide meaningful insights into the relationship between re-solving frequency and optimization loss."}, "weaknesses": {"value": "1. The paper doesn't sufficiently discuss the computational overhead of the change point detection component, which might be significant for real-time applications.\n2. The paper claims to address \"large time horizon and non-MDP structure\" challenges, but doesn't clearly explain how POC overcomes these limitations compared to other reinforcement learning approaches.\n3. The experimental section could benefit from more detailed analysis of the trade-offs between solution quality and computational cost.\n4. The presentation of Figure 2 is somewhat oversimplified, while the layout of Figures 3-5 is suboptimal."}, "questions": {"value": "1. The paper fails to mention which solver was used, and it is unclear if tests were run on multiple solvers.\n2. The description of the dataset is lacking; the number of variables and constraints for the MILP problems should be included.\n3. Could you elaborate on how your framework specifically handles the non-MDP structure of MILP re-solving problems, and why vanilla RL methods fail in this context?\n4. The paper mentions \"real-time MILP benchmarks\" - could you provide more details about these benchmarks and how they differ from existing MILP benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "65cg41nFea", "forum": "b1Vipm34s6", "replyto": "b1Vipm34s6", "signatures": ["ICLR.cc/2026/Conference/Submission12781/Reviewer_5JPi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12781/Reviewer_5JPi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12781/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761265720385, "cdate": 1761265720385, "tmdate": 1762923589569, "mdate": 1762923589569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "iABONOVa42", "forum": "b1Vipm34s6", "replyto": "b1Vipm34s6", "signatures": ["ICLR.cc/2026/Conference/Submission12781/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12781/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763562048634, "cdate": 1763562048634, "tmdate": 1763562048634, "mdate": 1763562048634, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the practical challenge of determining when to re-solve MILPs in dynamic environments with high-frequency data streams. The authors propose POC, a framework combining change point detection, feature engineering, and PPO to balance optimization loss and re-solving costs. Theoretical analysis characterizes the relationship between environment changes and discount factors, deriving bounds on re-solving frequency. Experiments show that POC reduces cumulative loss by 2%â€“17% compared to baselines while significantly cutting re-solving events."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper systematically formalizes the understudied problem of cost-aware MILP re-solving in non-stationary environments, highlighting real-world constraints \n2.  Theoretical results are provided that link environment change probability to discount factors in RL and prove structural properties of re-solving intervals."}, "weaknesses": {"value": "1. The dynamic enviroment is tackled via check point dectection, which is not contributed by the authors. The settings of both dynamic environment and unobservable $c_t$ seem mixed together and hinder the insights a little bit.\n2. When constraints are static, **prior solutions may accelerate subsequent re-solving** (e.g., via cutting planes), such accumulative advantage should not be neglected.\n3. **Notations**: $c_t^Tx$ should be $c_t^\\top x$ (\\top), since $T$ is the given timeframe. Moreover, I fail to find the definition of $t_k^*$ in Theorem 2."}, "questions": {"value": "1.  Intuitively the re-solving cost is hard to exactly quantify, but is crucial to $CL(\\pi)$. How should practitioners set the re-solving cost $C$ in real applications?\n2.  An easier setting is that $c_t$ is varying but can be observed at time $t$. Do there exist approaches for such setting? If no, why don't the authors consider the more fundamental case first; if yes, then is POC applicable to such case and what is POC's advantage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EmoV6CEynr", "forum": "b1Vipm34s6", "replyto": "b1Vipm34s6", "signatures": ["ICLR.cc/2026/Conference/Submission12781/Reviewer_cybh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12781/Reviewer_cybh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12781/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761737886879, "cdate": 1761737886879, "tmdate": 1762923589227, "mdate": 1762923589227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of determining when to re-solve a Mixed-Integer Linear Program (MILP) in dynamically changing environments while accounting for the cost that arises from repeated re-solving. To tackle this problem, the authors propose the POC framework, which combines Proximal Policy Optimization (PPO) with Change-Point Detection (CPD). The paper also provides theoretical analysis on structural properties such as an upper bound on the re-solving frequency and increasing intervals between re-solves under stable environments. The authors construct eight MILP-based benchmarks to evaluate their method and empirically demonstrate that the proposed approach reduces cumulative optimization loss more effectively than existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper proposes a method to determine when to re-solve MILP problems while considering re-solving costs. Although this topic has not been extensively explored in prior work, it is practically relevant for certain industrial applications.\n\n- The paper performs theoretical analysis on structural properties, including an upper bound on re-solving frequency and increasing intervals when the environment remains stable.\n\n- To evaluate the proposed approach, the authors construct eight benchmarks, establishing a foundation for future research in the field.\n\n- Based on the provided datasets, the authors empirically demonstrate reductions in cumulative loss compared to existing methods."}, "weaknesses": {"value": "- This work assumes a single constant re-solving cost; however, in real-world scenarios, quantifying such costs can be challenging for various reasons. As a result, applying the proposed approach directly to practical systems may be limited.\n\n- POC requires additional computation for determining re-solving times, yet the paper does not sufficiently discuss how this overhead affects the overall cost structure.\n\n- The proposed POC framework introduces additional complexity compared to existing approaches, requiring further development and maintenance efforts to integrate into operational environments. In industrial settings, re-solving decisions may not always be critical enough to justify adopting a more complex system."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rifGRuBajN", "forum": "b1Vipm34s6", "replyto": "b1Vipm34s6", "signatures": ["ICLR.cc/2026/Conference/Submission12781/Reviewer_YKwD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12781/Reviewer_YKwD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12781/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801164569, "cdate": 1761801164569, "tmdate": 1762923588819, "mdate": 1762923588819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Proximal Policy Optimization with Change Point Detection (POC) that learns when to re-solve a large-scale Mixed-Integer Linear Programming (MILP) problem by using reinforcement learning (RL). POC is design to balance the accuracy and the computation cost in a situation where the volume and distribution of input data is dynamic. This paper evaluates POC on eight benchmark datasets."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- S1. [Motivation] This paper proposes a RL-based change point detection method for solving a large-scale MILP."}, "weaknesses": {"value": "- W1. [Formulation] The problem formulation is rather unclear. It seems like that POC aims to lean when to re-solve a large-scale MILP problem by using RL. However, this paper does not provide a problem formulation based on Markov Decision Process (MDP). If this paper formulates the problem as a constraint RL, this paper needs to provide a proper formulation.  \n\n- W2. [Presentation] The presentation of this paper needs to be revised. The section structure of this paper does not seem effective. For example, Section 2 (i.e., Preliminaries) and 3 (i.e., Theoretical Analysis) are relatively long (about three pages), compared to Section 4 (i.e., Method). On the other hand, the related works section (i.e., Section 1.1) is very short (only one paragraph). \n\n- W3. [Relevance] I am not sure whether the problem addressed in this paper is relevant with topics of interest to the ICLR research community."}, "questions": {"value": "- Q1. What is the state space, the action space, the transition function, the reward function, and discount factor of the policy?\n\n- Q2. Do the authors measure the amount of computational cost induced by POC?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UrtmxVmAWN", "forum": "b1Vipm34s6", "replyto": "b1Vipm34s6", "signatures": ["ICLR.cc/2026/Conference/Submission12781/Reviewer_zToV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12781/Reviewer_zToV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12781/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988252503, "cdate": 1761988252503, "tmdate": 1762923588507, "mdate": 1762923588507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}