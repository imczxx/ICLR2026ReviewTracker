{"id": "20DsUSauCj", "number": 4275, "cdate": 1757652409222, "mdate": 1759898042210, "content": {"title": "Persona Vectors: Monitoring and Controlling Character Traits in Language Models", "abstract": "Large language models interact with users through a simulated 'Assistant' persona. While the Assistant is typically trained to be helpful, harmless, and honest, it sometimes deviates from these ideals. In this paper, we identify directions in the model's activation space-persona vectors-underlying several traits, such as evil, sycophancy, and propensity to hallucinate. We confirm that these vectors can be used to monitor fluctuations in the Assistant's personality at deployment time. We then apply persona vectors to predict and control personality shifts that occur during training. We find that both intended and unintended personality changes after finetuning are strongly correlated with shifts along the relevant persona vectors. These shifts can be mitigated through post-hoc intervention, or avoided in the first place with a new preventative steering method. Moreover, persona vectors can be used to flag training data that will produce undesirable personality changes, both at the dataset level and the individual sample level. Our method for extracting persona vectors is automated and can be applied to any personality trait of interest, given only a natural-language description.", "tldr": "", "keywords": ["Large Language Model", "alignment", "emergent misalignemnt", "mechanism interpretation", "steering"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b3bc5defa341d1ff1dc9190148c0ca98afa808d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces ``persona vectors'', which are directions in a large language model's (LLM) activation space that correspond to specific, high-level character traits. The authors present a novel, automated pipeline that uses a frontier LLM to generate contrastive data from a simple natural-language description of a trait, which is then used to extract the corresponding vector. The paper demonstrates that persona vectors can be used to monitor persona, control persona, prevent persona shift, and screen data, demonstrating effective usage of the derived features from existing LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Sound Engineering Method: The automated pipeline for vector extraction is a good contribution. By requiring only a natural-language description of a trait, it provides a scalable method for representation engineering, moving beyond bespoke, manually-curated datasets for each concept.\n\n2. Comprehensive Experiments: The authors rigorously validate the utility of the extracted vectors across a wide range of applications (monitoring, inference-time control, training-time control, and data screening). This demonstrates that the persona vectors are not just a correlational artifact on the model's behavior."}, "weaknesses": {"value": "1. Limited Scientific Insight: The paper is presented more as an engineering achievement than a scientific one. It demonstrates that persona traits can be mapped to vectors but provides little insight into why this is the case and if other naive methods could do the same. The method feels like advanced prompt engineering applied to activations, rather than some general methodological approaches towards general understanding of related problems.\n\n2. Insufficient Comparison to Naive Baselines: The paper fails to adequately compare its complex steering methods against simpler, \"naive\" baselines in the main text. A full evaluation against standard system prompting or language based methods (instead of using vectors) is critical. Lack of such experiments make it hard to judge if the vectors are truly necessary.\n\n3. Method Clarity: The core methodology is not fully detailed in the main text, making the workflow and its components difficult to understand. Key components, such as the exact prompts used for artifact generation, and workflow are best described in the paper with illustrative display items. This lack of details hinders reproducibility and a clear evaluation of the method's components."}, "questions": {"value": "Based on the weaknesses:\n\n1. Your paper is presented more as an engineering method than a scientific discovery. Do you have a hypothesis for why complex, high-level persona traits are robustly encoded as linear directions? Is this an emergent property of all LLMs, or specific to their chat-finetuning? How about other behavioral properties not defined as persona?\n\n2. The paper's central claim rests on the utility of these vectors, yet the comparisons to \"naive\" baselines (like simple system prompting) are missing. Is there a purely prompting pipeline that can achieve similar effects as your vectors, making your vecotors uncessary?\n\n3.  The workflow for vector extraction is hard to understand from the main paper. How sensitive is the final vector's quality to the components of this pipeline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R0fG4MdNuI", "forum": "20DsUSauCj", "replyto": "20DsUSauCj", "signatures": ["ICLR.cc/2026/Conference/Submission4275/Reviewer_rxfH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4275/Reviewer_rxfH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761550204152, "cdate": 1761550204152, "tmdate": 1762917270339, "mdate": 1762917270339, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces an automated algorithm to extract persona vectors from LLMs, which can be applied to various use cases. Specifically, the authors demonstrate the use of persona vectors to detect and prevent certain personality traits during inference or fine-tuning. The fine-tuning-induced persona shifts can even be predicted before the fine-tuning process begins."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- This work is very comprehensive in the experiments, showcasing diverse use cases for the proposed persona vector. Also, the experiments are delivered very clearly.\n- The writing is simple and direct, and it was easy to follow.\n- The Appendix is impressive, providing helpful details and further experiments that support the authors' claims."}, "weaknesses": {"value": "### 1. Method Novelty \nWhile this work is very comprehensive, my biggest concern is the novelty of the approach. Previously, there have been numerous works that discuss model steering vectors, like RepE [1] or ITI [2]. Also, many works have provided ways to \"steer\" LLMs for personalized use [3], and even to change LLM personality traits in the latent embedding space [4,5]. Given these works that discuss similar approaches, I believe this deserves an in-depth discussion on what differences the Persona Vector has compared to previous literature.\n\n[1] REPRESENTATION ENGINEERING: A TOP-DOWN APPROACH TO AI TRANSPARENCY\n\n[2] Inference-Time Intervention: Eliciting Truthful Answers from a Language Model\n\n[3] Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization\n\n[4] Exploring the Personality Traits of LLMs through Latent Features Steering\n\n[5] Style Vectors for Steering Generative Large Language Models\n\n\n### 2. Precision of What the Persona Vector Represents\n- I am concerned about the authors' finding that \"persona shifts are rather correlated between seemingly different traits. In particular, we notice that negative traits tend to shift together\". This finding is concerning because this shows the weakness of the linear interventions in steering the model's persona. While it is understandable that certain persona sets may be correlated to each other to some extent, extremely high correlations (e.g., over 0.8) are not acceptable, because persona vectors should, by definition, be able to pinpoint vector directions that represent a \"specific persona\", and not be a measure to mitigate \"harmfulness\" as a whole. If we cannot extract a persona vector that steers the specific persona orthogonal to any other persona, I think the definition of \"persona vector\" is over-claiming its capabilities.\n\n- The persona vectors are extracted by generating system prompts that would best elicit the target trait, and using the difference in mean activations between responses. This \"persona vector\" represents the direction that best explains the target persona, which is then applied to many use cases. However, I think this introduces a high risk of confirmation bias; i.e., the persona steering and detection approaches are only confirming the direction that has just been introduced systematically. To refute this point, I suggest you do an experiment that shows that the extracted persona vector is indeed a representation of the target persona, by testing on the inverted direction of the persona vector. For instance, if the \"evil\" vector _v_ indeed represents the direction of \"evil\", the negative vector _- v_ should represent \"benign\". Also, if the \"sycophancy\" vector is _v_, then _- v_ should represent a \"stubborn\" or \"self-biased\" personality trait. Using the persona vectors _v_ extracted for each persona, please provide a systematic evaluation of the effect of _- v_. If _- v_ can elicit the opposite persona, then the experiments provided are not just a confirmation of the direction, and we can say that the persona vector indeed captures the intended personality trait."}, "questions": {"value": "- Depending on the target persona, I think there might be refusal behaviors of models during the 10 rollouts. How are these handled?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7VLQn31ZCx", "forum": "20DsUSauCj", "replyto": "20DsUSauCj", "signatures": ["ICLR.cc/2026/Conference/Submission4275/Reviewer_ftbh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4275/Reviewer_ftbh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761630000866, "cdate": 1761630000866, "tmdate": 1762917270085, "mdate": 1762917270085, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper reports on a study of LLM personas. Using mechanistic interpretability methods, the authors extract persona vectors, i.e., linear paths in the activation space, corresponding to multiple personality traits. The authors show how these vectors can be used to monitor, predict, and control personality traits during training, to mitigate and avoid unwanted personality shifts through steering, and even to flag training data that could lead to unwanted personality changes beforehand."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "The authors present an automated pipeline for monitoring, predicting, and controlling LLM personalities. However, the paper hides a more salient contribution, the paper includes a case study of preventative steering, i.e., ablating persona vectors at training rather than inference time. The authors demonstrate that fine-tuning on new facts while steering away from the hallucination vector, preserves accuracy on the MMLU with only a slight degradation on new facts. Thus, compared to other SOA methods, such as CAFT, i.e., abblating undesirable vectors, preventative steering seems to mitigate hallucinations in addition to undesirable traits."}, "weaknesses": {"value": "The presentation is flawed. The paper is very comprehensive and compares the steering approach against psychometric baselines, SAE, fine-tuning vs. few-shot prompting, etc. but this also works to their detriment as it obfuscates the main empirical findings.\nAccording to the authors, the main contribution appears to be an automated pipeline. In terms of empirical findings, the paper would seem to have less to offer. As the authors outline, the methods are otherwise well-established and extensively studied, i.e., linear probing. \nHowever, the paper includes a case study that shows that preventative steering during fine-tuning can reduce hallucinations without degrading accuracy.\nWhile the comprehensiveness of the report is laudable, it takes away from the overall argument. The paper would benefit from a more concise presentation focused on preventative steering, which is the novel empirical contribution, not the automated pipeline."}, "questions": {"value": "The process of computing the persona vectors needs further elaboration: How many times were the persona vectors computed? Were the prompts/models varied? Could the persona vectors be strengthened by averaging activation across multiple prompts? How do the persona vectors compare across models?\nP26 L1387 The inter-rater agreement setup seems gamed to boost agreement: using high/low split forces a binary choice, it does not validate the texts' trait representations only relative magnitudes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mjusa8HotM", "forum": "20DsUSauCj", "replyto": "20DsUSauCj", "signatures": ["ICLR.cc/2026/Conference/Submission4275/Reviewer_2pzc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4275/Reviewer_2pzc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4275/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935355631, "cdate": 1761935355631, "tmdate": 1762917269854, "mdate": 1762917269854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}