{"id": "EjfzChLkHO", "number": 13651, "cdate": 1758220466544, "mdate": 1759897422282, "content": {"title": "Understanding Generative Recommendation with Semantic IDs from a Model-scaling View", "abstract": "Recent advancements in generative models have allowed the emergence of a promising paradigm for recommender systems (RS), known as Generative Recommendation (GR), which tries to unify rich item multimodal semantics and collaborative filtering signals. \nOne popular modern approach is to use semantic IDs (SIDs), which are discrete codes quantized from the embeddings of modality encoders (e.g. large language or vision models), to represent items in an autoregressive user interaction sequence modeling setup (henceforth, SID-based GR).\nWhile generative models in other domains exhibit well-established scaling laws, our work reveals that SID-based GR shows significant bottlenecks while scaling up the model; in particular, the performance of SID-based GR quickly saturates as we enlarge each component -- the modality encoder, the quantization tokenizer, and the RS itself. \nIn this work, we identify the limited capacity of SIDs to encode item semantic information as one of the fundamental bottlenecks. \nMotivated by this observation, as an initial effort to obtain GR models with better scaling behaviors, we revisit another GR paradigm that directly uses LLMs as recommenders (henceforth, LLM-as-RS).\nOur experiments show that LLM-as-RS paradigm has superior model scaling properties and achieves up to 20\\% improvement than the best achievable performance of SID-based GR through scaling. \nWe also challenge the prevailing belief that LLMs struggle to capture collaborative filtering information, showing that LLMs' ability to model user–item interactions improves as LLMs scale up. \nOur analyses on both SID-based GR and LLMs across model sizes from 44M to 14B parameters underscore the intrinsic scaling limits of SID-based GR and positions LLM-as-RS as a promising path toward foundation models for GR.", "tldr": "Our analyses on both SID-based GR and LLMs across model sizes from 44M to 14B parameters underscore the intrinsic scaling limits of SID-based GR and positions LLM-as-RS as a promising path toward foundation models for GR.", "keywords": ["Generative Recommendation", "Model Scaling Laws"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c0ee4ef9bee40d81d03efc1aaf8dff8c7582e830.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper compares two AI recommendation methods: SID-based GR and LLM-as-RS. SID-based GR hits a performance ceiling quickly when scaling up. LLM-as-RS keeps improving with larger models, achieving 20% better results. The authors also show that LLMs can effectively learn user behavior patterns and improve with scale, making LLM-as-RS more promising for future recommendation systems despite higher computational costs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses one of the most critical questions in the recommender systems field: which paradigm should generative recommendation follow? The research question demonstrates both novelty and necessity, tackling a fundamental challenge in the current landscape of recommendation systems.\n\n2. The authors conduct extensive experiments and derive numerous valuable insights that will benefit future research in this domain. The empirical findings provide meaningful guidance for the community.\n\n3. The paper is well-written and easy to follow, making complex concepts accessible to a broad audience."}, "weaknesses": {"value": "1. The model employs an encoder-decoder architecture (TIGER) for the SID approach. However, encoder-decoder architectures inherently suffer from significant scaling limitations compared to decoder-only LLMs. The authors do not acknowledge this fundamental constraint, which could confound their conclusions about SID's scaling behavior. Note: this refers to the recommender architecture, not the text embedding component.\n2. All experiments are conducted exclusively on Amazon datasets. To strengthen the generalizability of the findings, the study should include at least one dataset from a non-Amazon platform. This would provide more convincing evidence for the claimed conclusions.\n3. The datasets used are relatively small-scale academic benchmarks, yet the authors make broad claims about the entire community's research direction. Given the significance of these claims, industrial-scale datasets and ideally online A/B test results should support such conclusions. The lack of large-scale validation limits the impact of the findings.\n4. The paper discusses performance gaps between SID and LLM-as-RS approaches but lacks a fair comparison at equivalent parameter scales. LLM-as-RS models range from billions to 14 billion parameters, while the largest SID model is only 192M parameters. For an empirical study focused on scaling behavior, comparing models at similar scales is essential. The authors should provide controlled experiments with parameter-matched models."}, "questions": {"value": "1. The paper concludes that SID remains meaningful primarily due to efficiency advantages. Have the authors conducted any experiments to provide insights on how to improve SID's performance? What strategies should be explored to enhance SID models' scaling capabilities from a scaling perspective?\n2. The efficiency section shows that LLM4Rec's inference speed is substantially slower than SID, suggesting it may be impractical for real-world industrial applications. Given that LLM4Rec is positioned as the primary recommended architecture, how do the authors propose addressing these practical deployment challenges?\n3. The paper does not explain how embeddings are extracted in the SID approach. Could the authors clarify this process?\n4. Have the authors tested their findings on other datasets? Do the results generalize beyond the Amazon datasets, or are there domain-specific patterns that affect the conclusions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IX0KVC9gQQ", "forum": "EjfzChLkHO", "replyto": "EjfzChLkHO", "signatures": ["ICLR.cc/2026/Conference/Submission13651/Reviewer_mLTN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13651/Reviewer_mLTN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761682797116, "cdate": 1761682797116, "tmdate": 1762924225219, "mdate": 1762924225219, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper foucuses on the performance of semantic id-based generative recommendation (SID-based GR) and LLMs as recommeders (LLM-as-RS) when LLM backbone is scaling up. The authors conducted extensive experiments on multiple datasets with various experiment settings and further lead to the conclusion that compared to LLM-as-RS, SID-based GR shows earlier performance saturation.\n\nContributions:\n\n**1.** This paper conducted extensive experiments to demonstarte that SID-based GR paradigm shows intrinsic bottleneck when scaling up its components.\n\n**2.** This paper discusses two generative recommendation paradigms from the persprective of the ability of LLMs to capture CF and semantic information."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors clearly define the question discussed and show the experiment results in an organized manner. Also, this paper contains sufficient results figures with elaborate descriptions, showing great writing clarity.\n\n2. This research discusses the two trending generative recommendation paradigms from a novel perspective of model-scaling analysis and further obtain insightful conclusions."}, "weaknesses": {"value": "1. The paper uses models from 336K to 192M parameters conduct scaling experiments of LLM backbone in the SID-based GR. However, one can easily find much larger models, and such small model can hardly deny the scaling law in SID-based GR.\n\n2. When conducting scaling experiments of LLM backbone in the LLM-as-RS, the authors use models from 0.6B to 14B parameters, which is much larger than the model used in experiments of SID-based GR. Existing methods have already applied LLMs of this scale in SID-based GR. There is no reason not using these LLMs.\n\n3. When conducting experiments of LLM encoder and codebook size in SID-based GR, the authors summarized great observations from the results. However, one would more expect insightful analysis from the experiments, not just observations."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9iTXFcOZ3W", "forum": "EjfzChLkHO", "replyto": "EjfzChLkHO", "signatures": ["ICLR.cc/2026/Conference/Submission13651/Reviewer_adPM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13651/Reviewer_adPM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813993349, "cdate": 1761813993349, "tmdate": 1762924224597, "mdate": 1762924224597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a empirical study on the scaling behaviors of modern generative recommendation (GR) paradigms. The authors focus on two representative frameworks:\n- SID-based GR, where items are represented as semantic IDs (SIDs) derived from modality encoders and quantization tokenizers.\n- LLM-as-RS, where large language models (LLMs) are directly used to generate recommendations without intermediate SIDs.\nThe paper found that SID-based GR exhibits early performance saturation while LLM-as-RS continues to improve with model size. The authors argue that LLM-as-RS represents a more scalable and semantically expressive path toward developing foundation models for recommendation systems."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**S1:Scope**: The paper focuses on an important topic of generative recommendation systems: scaling behaviors. Understanding how different GR paradigms scale with model size is crucial for building effective recommendation foundation models.\n\n**S2:Experiment**\"\" Empirical study across model sizes and LoRA configurations provides valuable evidence for analyzing LLM-as-RS scaling trends."}, "weaknesses": {"value": "**W1: Limited analysis on data scaling**: While the paper provides a thorough analysis of model scaling, it lacks a comprehensive examination of data scaling [1]. The training data used in the experiments is small-scale (1M interactions). As far as I know, SASRec with 8e6 parameter are saturated on these datasets. And as shown in Figure 2, Generative recommendation models performance saturate after parameter size reaches 1e7. Without dataset scaling analysis, it is hard to ablate whether the performance saturation is due to model size or data size.\n\n**W2: Semantic and CF information are not clearly disentangled in the scaling analyse on LLM-as-RS**: \"Throughout these experiments, the trainable LoRA weights are maintained at approximately 1% of the total LLM parameters.\" As a result, when scaling up the backbone LLM, both the representational capacity (semantic understanding of items) and the effective amount of trainable parameters grow simultaneously, making it difficult to attribute the observed performance improvements to either factor. To truly disentangle these effects, it would be necessary to compare models of different backbone sizes under varying LoRA capacities (e.g., fixed LoRA rank vs. proportional LoRA rank), and analyze whether scaling gains primarily stem from the frozen LLM’s semantic prior or from the additional trainable parameters. Without such a control, the interpretation of γ and β as independent scaling coefficients for semantic and CF learning remains ambiguous.\n\n**W3: LLM-as-RS’s CF scaling claim appears internally inconsistent.**: The paper presents seemingly conflicting evidence regarding the scaling of LLMs’ ability to capture collaborative filtering (CF) signals.\nIn Section 3, the authors argue that SID-based GR models fail to scale effectively, largely because their CF-driven representations saturate quickly.\nHowever, in Section 4.2, they employ larger SASRec models to provide “stronger” CF embeddings and observe that larger LLM-as-RS models benefit less from these external CF signals.\nIf CF signals themselves are bounded and non-scalable—as implied by the earlier results—it remains unclear how the authors justify that the LLM-as-RS’s improved scaling stems from its enhanced ability to model CF information.\n\n[1] Hoffmann, Jordan, et al. \"Training compute-optimal large language models.\" arXiv preprint arXiv:2203.15556 (2022)."}, "questions": {"value": "Refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X1tuf5vJSb", "forum": "EjfzChLkHO", "replyto": "EjfzChLkHO", "signatures": ["ICLR.cc/2026/Conference/Submission13651/Reviewer_gVU9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13651/Reviewer_gVU9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934800851, "cdate": 1761934800851, "tmdate": 1762924224222, "mdate": 1762924224222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies how generative recommendation (GR) scales along two paradigms: (i) SID-based GR (quantizing item semantics into discrete “semantic IDs” and training a sequential recommender on SID sequences) and (ii) LLM-as-RS (fine-tuning an LLM to directly generate the next item title with constrained decoding). It proposes a scaling-law formulation grounded in a risk decomposition where total error (measured as MR@k = 1−Recall@k) separates into semantic-information (SI) error and collaborative-filtering (CF) error. The resulting expression predicts Recall@k as a sum of two *decreasing power-law* terms in the effective SI/CF parameter budgets.   Experiments use three Amazon subsets—Beauty, Sports & Outdoors, Toys & Games—with fixed splits and preprocessing following prior work; sequence-length statistics are reported."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Unified scaling-law lens for GR.** The paper provides a *single, interpretable* equation for Recall@k that decomposes SI vs. CF contributions, enabling side-by-side comparison of paradigms and modules under a fixed data budget.  \n- **Clear paradigm contrast.** It operationalizes both **SID-based** and **LLM-as-RS** within a comparable evaluation protocol, exposing where and why SID-based methods saturate and how LLM-as-RS keeps improving with scale.  \n- **Concrete, reproducible LLM-as-RS design.** The constrained-decoding setup (trie + beam search) and minimal prompt are precisely described, helping readers *replicate* next-item generation on catalog vocabularies. \n- **Negative results are informative.** The analysis doesn’t just report wins; it **identifies bottlenecks** in SID pipelines (limited SID semantic capacity), which is practically valuable for future GR system design. \n- **Actionable takeaway for practitioners.** If compute is available, **scaling LLM-as-RS** appears a more reliable path to gains than scaling SID encoders/tokenizers/recommenders alone; additionally, the **diminishing returns of external CF embeddings** at larger LLM sizes guide feature-engineering choices. \n- **Dataset transparency.** The paper discloses dataset stats and sequence-length distributions, aligning with the scaling-law narrative and enabling fairer comparisons and efficiency analyses."}, "weaknesses": {"value": "### 1) Metric–task **conflation**: treating “title generation = recall hit”\n\n- The paper reports **Recall@k/NDCG@k**, yet **LLM-as-RS** decodes with **constrained beam search + a trie built from the catalog**, i.e., the **candidate space equals the full catalog** and a “hit” is counted by **exact title string match**.\n- This **collapses text generation** into **character-level constrained search over a dictionary**, which is closer to **vocabulary-based retrieval/relabeling** than open-ended generation. Results are extremely sensitive to **synonyms/aliases**, **normalization/cleaning rules**, and **string equivalence**. The paper does not report **title→item-ID coverage/ambiguity**, **dedup/alias policies**, or **failure cases** (e.g., homonyms).\n\n------\n\n### 2) Insufficient **identifiability** and **fit reliability** for the scaling-law formula\n\n- Recall@k is modeled as the **difference of two power-law terms** (Eqs. (2)/(3)) with **γ, β** as effective weights; the appendix later claims **γ₁, γ₂ ≈ 0** (encoder/tokenizer scale has no effect) and proceeds with **simplified fits** (Eqs. (9)/(10)).\n- **Identifiability is not discussed**: when multiple module sizes co-vary and performance–scale is fit with a **log–power-law**, parameters (**R₀, A, B, a, b, γ, β**) can be **highly collinear**; multiple parameterizations may yield **high R²** yet **different physical interpretations** (e.g., the claim that the LLM contributes no SI). R²>0.9 alone does **not** validate the **semantics** of the parameters.\n  - **Recommendations:**\n    - Report **sensitivity analyses/bootstrapped CIs** and **parameter-correlation heatmaps**.\n    - Use **regularization** or **hierarchical Bayesian** fitting to mitigate over-fitting.\n    - Provide **stability across datasets/seeds** for the fitted parameters.\n- The evidence for **β>0** (lower error on a **20% held-out** when using Eq. (4) vs. a weakened Eq. (6)) is **fragile**: the held-out is drawn from the **same curve** (e.g., Fig. 8) rather than an independent setting, and it compares only **two approximations’** prediction errors—**noise-sensitive** by design. Stronger statistical tests (e.g., **multi-split CV**, **likelihood-ratio tests**) are needed.\n\n------\n\n### 3) **Baselines and ablations** are incomplete\n\n- Prior work such as **GenRec (ECIR 2024)** (directly generating the next item name) and **COBRA/LIGER (2024–2025)** (hybrid sparse SID + dense text) are **mentioned** but **not reproduced under the same data/protocol**, making it hard to align the paper’s scaling observations with existing systems.\n\n------\n\n### 4) **Evaluation statistics** and **reproducibility** details are insufficient\n\n- Missing **confidence intervals** or **mean±std over multiple runs**; figures show **no error bars**. Scaling claims typically require **robustness across random seeds** and **subsampled training sets**.\n\n------\n\n### 5) **Writing and figure quality**\n\n- **Spelling/grammar:**\n  - “**exihibit** scaling behaviors” → *exhibit*\n  - “**argumnet** that β>0” → *argument*\n  - Figure 14 title “**Beuaty**” → *Beauty*\n  - Figure 10 caption “**structuture**” → *structure*\n  - “**There statistics** will affect …” → *These statistics*\n- **Symbols/terminology:**\n  - Typos such as “**traing** stage” near Eq. (3).\n  - Definitions of **γ** and **β** are **scattered**."}, "questions": {"value": "No"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4NqvgZFiY2", "forum": "EjfzChLkHO", "replyto": "EjfzChLkHO", "signatures": ["ICLR.cc/2026/Conference/Submission13651/Reviewer_rLfN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13651/Reviewer_rLfN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971936856, "cdate": 1761971936856, "tmdate": 1762924223956, "mdate": 1762924223956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}