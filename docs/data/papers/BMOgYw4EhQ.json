{"id": "BMOgYw4EhQ", "number": 16267, "cdate": 1758262521186, "mdate": 1759897251174, "content": {"title": "An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems", "abstract": "Complex vehicle routing problems (VRPs) remain a fundamental challenge, demanding substantial expert effort for intent interpretation and algorithm design. While large language models (LLMs) offer a promising path toward automation, current approaches still rely on external intervention, which restrict autonomy and often lead to execution errors and low solution feasibility. To address these challenges, we propose an Agentic Framework with LLMs (AFL) for solving complex vehicle routing problems, achieving full automation from problem instance to solution. AFL directly extracts knowledge from raw inputs and enables self-contained code generation without handcrafted modules or external solvers. To improve trustworthiness, AFL decomposes the overall pipeline into three manageable subtasks and employs four specialized agents whose coordinated interactions enforce cross-functional consistency and logical soundness. Extensive experiments on 20 complex VRPs, ranging from standard benchmarks to practical variants, validate the effectiveness and generality of our framework, showing comparable performance against meticulously designed algorithms. Notably, it substantially outperforms existing LLM-based baselines in both code reliability and solution feasibility, achieving rates close to 100% on the evaluated benchmarks.", "tldr": "We propose a fully automation LLM agent for solving complex vehicle routing problem", "keywords": ["Vehicle Routing Problems", "Agent", "LLM"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a613c2ef00fddf2c49bc944f51bd05864f904e30.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a self-contained, LLM-driven framework for solving complex vehicle routing problems (VRPs). The framework is evaluated on 20 VRP variants, demonstrating its effectiveness and generality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of designing a self-contained framework powered by LLMs to fully automate the process of solving VRPs is promising.\n2. The framework aims to generalize across various VRP formulations, which is an ambitious and potentially impactful direction."}, "weaknesses": {"value": "1. The paper states that its goal is not to surpass state-of-the-art (SOTA) solvers on conventional VRPs, but rather to develop an automated and self-contained framework for handling complex VRPs. However, prior works such as [1, 2] have already demonstrated that LLMs can automatically design heuristics that achieve or even surpass SOTA performance. Compared with those works, the main novelty of this paper appears to lie in increasing automation by accepting natural language task descriptions as input. While this is an interesting step toward fully automated problem solving, it is not entirely clear how significant this improvement is in practice. Given the current framework design, I am not convinced that the heuristics generated by the proposed method would outperform those produced in [1, 2].\n2. In Tables 3 and 4, the paper reports results on eight VRPs. However, it is unclear whether the same generated heuristic is used across all problem instances of a given VRP type, or if a separate heuristic is generated for each instance. This distinction is important for assessing the generalization capability of the approach. The authors report performance under different numbers of iterations but do not provide the computational cost or runtime associated with these iterations. Such information is necessary to properly interpret the trade-off between performance and efficiency.\n3. In Table 6, the paper presents results on different benchmarks with varying numbers of nodes. It is again unclear whether the same heuristic method is reused or newly generated for each benchmark setting. Clarification on this point is needed to understand how the proposed method scales and generalizes.\n\n# References\n[1] ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution\n\n[2] Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization"}, "questions": {"value": "Check Weakness Section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RkzJb7F3DM", "forum": "BMOgYw4EhQ", "replyto": "BMOgYw4EhQ", "signatures": ["ICLR.cc/2026/Conference/Submission16267/Reviewer_KgjX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16267/Reviewer_KgjX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761430028454, "cdate": 1761430028454, "tmdate": 1762926416933, "mdate": 1762926416933, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework named AFL (Agentic Framework with LLMs), which aims to fully automate the solving of complex Vehicle Routing Problems (VRPs) using Large Language Models (LLMs). It decomposes the complex solving pipeline into three subtasks: problem description, code generation, and solution derivation. It also introduces four specialized LLM Agents—Generation, Critique, Revision, and Error Analysis—to collaborate, significantly improving the reliability of the generated code and the feasibility of the final solution."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. AFL achieves full end-to-end automation, from the VRP instance file to the final solution, without requiring human intervention during execution or relying on external solvers or predefined code libraries.\n2. Decomposing the complex task and introducing multiple collaborating LLM Agents with specialized roles (Generation, Critique, Revision, Error Analysis) is an effective strategy for enhancing the reliability of LLMs in complex programming and reasoning tasks. This approach is generalizable and could potentially be applied to other optimization problems.\n3. The experiments not only include standard VRPs but also specifically test complex variants more common in real-world scenarios, such as Electric VRPs (EVRPs) with multiple combined constraints, demonstrating the framework's effectiveness and generality in handling complex constraints."}, "weaknesses": {"value": "1. It is highly dependent on the powerful code generation, comprehension, and reasoning capabilities of the LLM used (GPT-4.1). How the framework performs on less capable, open-source LLMs, and its sensitivity to different LLMs, warrants further investigation.\n2. Excessive time consumption is a potential issue, as shown in Table 3. How do the authors view this trade-off of sacrificing time for accuracy? In scenarios requiring rapid feedback, is this algorithm still viable?\n\nSince I am not an expert in this field,  I don't know if the novelty of this kind of prompt engineering paper is sufficient."}, "questions": {"value": "see in weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iHn4wodo3Q", "forum": "BMOgYw4EhQ", "replyto": "BMOgYw4EhQ", "signatures": ["ICLR.cc/2026/Conference/Submission16267/Reviewer_KZcf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16267/Reviewer_KZcf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761609144215, "cdate": 1761609144215, "tmdate": 1762926416352, "mdate": 1762926416352, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript proposes an Agentic Framework with LLMs (AFL) for solving complex VRPs with full automation and self-containment. AFL decomposes the VRP-solving pipeline into three subtasks and employs four specialized agents to ensure cross-functional consistency and logical soundness. The framework directly extracts domain knowledge from VRPLib-format raw inputs, generates executable code without handcrafted modules, and derives feasible solutions. Extensive experiments on 20 VRP variants demonstrate that the performance of AFL is comparable to state-of-the-art solvers and significant outperformance over existing LLM-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "AFL achieves end-to-end automation from raw VRP instances to solutions by decomposing the pipeline into manageable subtasks and leveraging specialized agents. This eliminates human intervention and external solver dependencies, addressing key limitations of prior LLM-based approaches.\n\nAFL is validated on 20 diverse VRP variants, including standard benchmarks (CVRP, VRPTW), practical electric VRPs (ECVRP, ECVRPTW), and other combinatorial problems (ATSP, ACVRP, SOP). It consistently delivers competitive performance, demonstrating broad applicability to complex real-world routing scenarios."}, "weaknesses": {"value": "While AFL achieves competitive performance, it still lags behind state-of-the-art solvers (e.g., HGS-PyVRP)\n\nThe performance of AFL heavily relies on the LLM's ability to generate accurate problem descriptions and code. Potential biases or inaccuracies in LLM outputs may propagate through the pipeline, affecting the final solution quality."}, "questions": {"value": "Do you plan to integrate more advanced heuristic strategies (e.g., evolutionary search) to narrow the performance gap with specialized SOTA solvers? If so, how to ensure the framework remains automated and generalizable?\n\nCan AFL perform on extremely large VRP instances (e.g., 5000+ customers)? If not, are there any constraints? if so, are there any  optimization strategies to improve computational efficiency?\n\nHave you tested AFL with different LLMs (e.g., GPT-4o, Claude 3)? How do variations in LLM capabilities affect the framework's code reliability and solution quality?\n\nCan AFL be extended to handle dynamic VRPs (e.g., real-time customer additions, traffic condition changes)? If yes, what modifications are needed to the current agentic pipeline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "3Gsv7HmuJR", "forum": "BMOgYw4EhQ", "replyto": "BMOgYw4EhQ", "signatures": ["ICLR.cc/2026/Conference/Submission16267/Reviewer_9utD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16267/Reviewer_9utD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761732764893, "cdate": 1761732764893, "tmdate": 1762926415958, "mdate": 1762926415958, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an LLM-based agent framework (AFL) for end-to-end solving of the Vehicle Routing Problem (VRP). The framework proceeds from the original VRPLIB instance to executable solver code and feasible solutions, without requiring manually written modules or external solvers. The entire workflow is decomposed into three subtasks: problem description, code generation, and solution derivation, executed by four dedicated agents: a Generating Agent (GA), a Judging Agent (JA), a Revising Agent (RA), and an Error Analysis Agent (EAA). These agents iteratively generate, inspect, and repair code under instance-specific constraints. At the core of the system lies a unified destroy (insert improvement heuristic), combined with simulated annealing for solution acceptance and rigorous constraint verification (capacity, time windows, and energy).\n\nExperimental results show that AFL achieves 0% runtime error rate (RER) and 100% success rate (SR) across 17 VRP variants, and produces objective values competitive with traditional solvers and state-of-the-art LLM baselines such as SGE and DRoC."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The paper cleanly explains the three subtasks and the four roles (GA/JA/RA/EAA) and how they interact (including buffer reuse and EAA-driven debugging loops). In addition, the overview figure and tables mapping constraints to VRPLIB fields aid comprehension.\n\n(2) The proposed multi-agent, verification-centric code generation framework substantially reduces execution failures in LLM-based systems. It demonstrates strong reliability and scalability across a wide range of VRP variants, suggesting that the approach could serve as a promising blueprint for extending agentic LLM frameworks to other combinatorial optimization domains."}, "weaknesses": {"value": "(1) Although the paper reports objective gaps (e.g., compared to the best-known or HGS reference algorithms), a more detailed runtime analysis, including per-stage timing breakdowns and hardware/memory configurations, would clarify the computational footprint and reproducibility of AFL.\n\n(2) AFL relies on standardized VRPLIB input and Euclidean coordinates. Its robustness to schema variations (e.g., non-VRPLIB formats), data noise or missing fields, and non-Euclidean or network-based distance metrics remains unclear.\n\n(3) The experimental comparisons primarily focus on SGE and DRoC (and reference classical solvers via gap reports). Given AFL’s agentic architecture, it would be beneficial to include an additional baseline that leverages tool-augmented debugging or unit-test generation within a single-agent setup, in order to isolate the specific impact of the multi-agent design."}, "questions": {"value": "Please See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YCnBUJc2BI", "forum": "BMOgYw4EhQ", "replyto": "BMOgYw4EhQ", "signatures": ["ICLR.cc/2026/Conference/Submission16267/Reviewer_QnWc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16267/Reviewer_QnWc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959855869, "cdate": 1761959855869, "tmdate": 1762926415190, "mdate": 1762926415190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}