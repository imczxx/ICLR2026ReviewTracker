{"id": "3tscL6zGPJ", "number": 7222, "cdate": 1758012093741, "mdate": 1763124186193, "content": {"title": "Semi-supervised Source Detection in Astronomical Images: New Benchmark and Strong Baseline", "abstract": "Source detection in modern observational astronomy is a cornerstone for accurately localizing and identifying stellar sources. It is crucial for studies such as stellar population synthesis and cosmological parameter estimation. \nHowever, the characteristics of astronomical images, including high density, the effect of point spread functions and low signal-to-noise ratios, significantly challenge the latest advanced object detectors. \nBesides, fully-supervised detection methods are hardly practical, due to the significant difficulty in annotating dense, small, and faint sources in astronomical images. \nTo tackle the scarcity of astronomical datasets, we introduce a new comprehensive benchmark (LAMOST-DET), comprising 18,400 astronomical images and 728,898 source instances.\nUpon the dataset, we further devise a novel semi-supervised learning framework coined Nova Teacher, capable of detecting dense sources effectively given sparse annotations. \nIt integrates source light enhancement module, confidence-guided pseudo-supervision, and cross-view complementary mining in a dual-teacher paradigm.\nExtensive experiments on LAMOST-DET show that, Nova Teacher consistently improves previous competitors by 4.04\\% and 5.22\\% mAP under two semi-supervised settings.\nAdditionally, our method competes against other detectors on a natural image dataset, validating its generalization ability to various scenarios.\nSource codes and data samples are available at supple. material.", "tldr": "This paper introduces LAMOST-DET, a benchmark for astronomical source detection, and proposes Nova Teacher, a semi-supervised framework that improves detection accuracy even with sparse annotations, outperforming state-of-the-art methods.", "keywords": ["Semi-supervised Object Detection", "Astronomical Images", "Dense Object Detection"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/4c6dbb62f07727c06542a97a19dc9642c09955ce.pdf", "supplementary_material": "/attachment/a6b3800cf8f0fccb88d7e4fba07a593d27775d81.zip"}, "replies": [{"content": {"summary": {"value": "The paper focuses on semi-supervised source extraction for astronomy, proposing a new benchmark and method. The benchmark consists of cutouts of the LAMOST survey, annotated with SExtractor and further labeled with metadata on the number of sources and their S/N ratios. The method has a student-teacher set-up and comes with three modules, designed to enhance the signal in the complex images, deal with label noise, and enhance recall. The network is trained end-to-end with a combination of five losses and evaluated on the proposed benchmark against baselines from natural image (semi-)supervised object detection."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed setting is well-motivated.\n- The figures enhance the clarity of the paper.\n- The ablation studies show the benefit of the different components."}, "weaknesses": {"value": "My main concerns lie in the experimental protocol. \nFirst, the ground truth used for the evaluation of the methods is based on SExtractor, with an unknown number of spurious detections manually removed. However, SExtractor is known to struggle with fainter sources and achieves a much lower accuracy (albeit faster processing times) than many methods proposed since 1996 [1]. Using these detections as the ground truth thus optimizes for a sub-optimal ground truth. The analysis also does not contain a comparison to SExtractor itself or other unsupervised source extraction tools such as MTObjects or NoiseChisel. Given that SExtractor provides the ground truth, why not use SExtractor?\nAs a result, the results would be far more convincing if a simulated dataset were used for training and validation, where the exact ground truth is known, as also done in previous works [1]. This would allow for a comparison against standard methods and lead to more certainty in results. Additionally, it would allow for generalization experiments on real data, which would strengthen the paper, as currently the methods are only evaluated on a single astronomical dataset.\nLastly, splitting images into quadrants, then randomly dividing them into train and test, does not allow us to draw conclusions about generalization to less similar environments and backgrounds, which will be the reality in deployment.\n\nRegarding the model, from the ablation in Table 3, it looks like the authors built on top of SOOD, as the ablation M1 results are the same as those for SOOD in Table 2. It would be appropriate to include how many additional parameters are added by the proposed modules to exclude the possibility that a bigger model is the reason for the performance increase.\n\n[1] Haigh, Caroline, et al. \"Optimising and comparing source-extraction tools using objective segmentation quality criteria.\" Astronomy & Astrophysics 645 (2021): A107."}, "questions": {"value": "- How many spurious detections were \"removed through manual reviews\"?\n- Why are the images split into quadrants? This way, quadrants from the same image will be present in both training and testing. To test generalization, it would be better to train on distinct cutouts from the test set.\n- It is unclear why \" We can expect the promising performance achieved by Nova Teacher, as general objects in those natural images are not so complex than the sources in astronomical images.\" (L465-467). The contributions in this paper are made specifically to tackle the difficulties present in astronomical images only. Why then should we expect better performance on natural images? \n- How were the hyperparameters for the baselines set? Are they using the standard settings for natural images, or were they tuned for the task, as was done for the proposed model?\n\nOther:\n- Make sure to use \\citep{} instead of \\cite when a reference is not used as a part of the sentence itself.\n- SSOD is defined a second time on L141\n- \"which we set to 2 following prior work\" on L316 should contain a reference.\n- How do you plan to use \"multi-modal large models\" (L486) for pseudo-labels? This is the first mention of multi-modality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xwfvrinjbB", "forum": "3tscL6zGPJ", "replyto": "3tscL6zGPJ", "signatures": ["ICLR.cc/2026/Conference/Submission7222/Reviewer_RBKN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7222/Reviewer_RBKN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7222/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761300967873, "cdate": 1761300967873, "tmdate": 1762919367232, "mdate": 1762919367232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "QwJgoEcLK5", "forum": "3tscL6zGPJ", "replyto": "3tscL6zGPJ", "signatures": ["ICLR.cc/2026/Conference/Submission7222/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7222/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763124185386, "cdate": 1763124185386, "tmdate": 1763124185386, "mdate": 1763124185386, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Nova Teacher, a semi-supervised framework for astronomical source detection under sparse annotations. It introduces a new benchmark, LAMOST-DET, containing over 18,000 images and 700k annotated sources. The framework integrates a source light enhancement module, confidence-guided pseudo-supervision, and cross-view complementary mining to improve recall and robustness. Overall, the writing is clear and well-organized, and the experiments are extensive. The contributions are technically solid, though some aspects, such as annotation quality and baseline novelty, could be further clarified."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe writing is clear and easy to follow.\n2.\tThe LAMOST-DET dataset is large-scale and contributes a valuable new resource.\n3.\tThe proposed method is conceptually simple and achieves strong results.\n4.\tExperiments are thorough and convincingly demonstrate the method’s effectiveness."}, "weaknesses": {"value": "1.\tThe paper lacks a detailed description of the annotation protocol; for example, the ellipses are not perfectly edge-aligned, raising concerns about label consistency.\n2.\tComparisons with recent semi-supervised detection methods from 2025 are missing, which limits the assessment of competitiveness.\n3.\tThe proposed CGPS and CVCM modules are conceptually similar to existing pseudo-labeling and mean teacher strategies; it would help to highlight their specific adaptation to astronomical source detection."}, "questions": {"value": "1.\tCould the authors elaborate on how annotation consistency was ensured given the imperfect alignment of elliptical masks?\n2.\tWill the dataset include detailed labeling guidelines or inter-annotator agreement statistics?\n3.\tHow would Nova Teacher compare against the most recent 2025 semi-supervised detection frameworks?\n4.\tWhat are the distinctive aspects of CGPS and CVCM that make them particularly effective for elliptical source detection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jfhdMHBODb", "forum": "3tscL6zGPJ", "replyto": "3tscL6zGPJ", "signatures": ["ICLR.cc/2026/Conference/Submission7222/Reviewer_U26t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7222/Reviewer_U26t"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7222/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761665592015, "cdate": 1761665592015, "tmdate": 1762919366828, "mdate": 1762919366828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of source detection in astronomical imaging by introducing a novel semi-supervised approach designed to enhance detection performance over existing methods. The proposed architecture consists of three key modules: a source light enhancement module, a confidence-guided pseudo supervision mechanism, and a cross-view complementary mining strategy. In addition to methodological innovations, the authors present a new benchmark dataset specifically for source detection in astronomical images. The effectiveness of the approach is demonstrated through comprehensive evaluations on this benchmark in a semi-supervised setting, where it achieves superior detection performance compared to previous methods. Furthermore, the method is tested on a non-astronomical task (semi-supervised ellipse detection in natural images) and again outperforms baseline approaches."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed benchmark is substantial in scale, encompassing a large number of images and annotated sources, which facilitates evaluation and comparison of models.\n    \n- The method demonstrates superior detection performance in both astronomical and natural image domains, indicating its effectiveness and versatility.\n    \n-  The figures presented in the paper are clear and informative."}, "weaknesses": {"value": "- A key issue that remains insufficiently addressed throughout the paper is a clear justification for the insufficiency of traditional methods.\n    \n    For example, the noise present in the images (as illustrated in Fig. 4) appears to be predominantly thermal noise, a scenario where matched filter techniques are typically effective. In astronomical contexts, considerable effort is devoted to calibrating and characterizing both the noise properties and the point spread function (PSF) of the measurements. This careful calibration often enables traditional methods to perform well. In contrast, the application of deep learning for object detection is generally motivated in domains such as natural image analysis, where object representations are less well-defined and traditional approaches may fall short.\n    \n    Therefore, the paper would benefit from a more thorough discussion of the specific limitations of existing methods in this context, and a clearer justification for the adoption of deep learning techniques.\n    \n- Equation 7 appears to be somewhat counterintuitive. The transformation it defines takes the opposite of certain values within a specific range, which results in a modification of the overall ordering of the confidence scores. Since the c values are constrained to the interval [0,1] the ordering of any values within [0,\\tau_{low}] is effectively reversed by this operation. It is not immediately clear what the intended benefit of this reversal is, as simply setting these values to zero would seem to achieve a similar effect in terms of suppressing low-confidence detections, without altering the relative ordering. Further clarification or justification for this particular transformation would be helpful.\n    \n- It would be helpful for the authors to clarify the criteria used by astronomers to differentiate between actual sources that require annotation and background blurry spots. From Fig. 4, it appears that many spots in the image are not considered stellar sources. This raises several important questions regarding the learning objective: What specific characteristics distinguish a true positive (i.e., a real astronomical source) from a false positive (e.g., noise or background artifacts)? Is the distinction primarily based on the shape of the spot, such as the degree of peakedness, with real stellar sources exhibiting a more pronounced peak? Are there additional features or contextual information that are taken into account during annotation? Furthermore, what are the typical origins of the spots that are not labeled as sources: are they due to instrumental noise, cosmic rays, or other astrophysical phenomena? In this context, how certain are the astronomers of the annotations ? A more detailed discussion of these criteria would provide valuable context for understanding both the annotation process and the challenges faced by automated detection methods.\n    \n- An important practical consideration for astronomers that appears to be missing from the proposed method is the quantification and control of uncertainty.  Does the method provide any mechanism for estimating or controlling the false alarm rate, for example through score calibration or threshold adjustment?"}, "questions": {"value": "- Were all the baselines in Table 1  trained on LAMOST ? Same question for Table 4 with the GED dataset ?\n    \n- L 263: “negative samples may contain important information that distinguishes the astronomical sources” : How so ? Can you elaborate on this ?\n    \n\nMinor:\n\n- L 267: The term \"matrix\" is confusing in this context, maybe \"confidence map\" or \"detection map\" would be more appropriate.\n    \n- L 228:  “Fronzen” -> “Frozen”"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kAhGf9yVYt", "forum": "3tscL6zGPJ", "replyto": "3tscL6zGPJ", "signatures": ["ICLR.cc/2026/Conference/Submission7222/Reviewer_tvnt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7222/Reviewer_tvnt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7222/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920414941, "cdate": 1761920414941, "tmdate": 1762919366450, "mdate": 1762919366450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This article deals with the detection of astronomical sources in a specific body of data coming from a spectroscopic telescope located in China. Sources can be both stars from our own galaxy or distant galaxies, in similar proportions. The authors propose a semi-supervised source detection method comprising several novel modules. The first is a source enhancement module that learns to enhance the contrast of the sources. The second is a pseudo-labelling technique based on confidence weighting. The third is a \"cross-view\" pseudo-label augmentation technique using two teachers.\n\nThe authors compare their source detection technique on other semi-supervised and supervised detectors not specifically tuned to astronomical source detection, and obtain better results. They perform an ablation study showing all three modules contribute to these results, and briefly test their method on a computer-vision benchmark, performing ellipse detection on natural-images, with state-of-the-art results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is reasonably well written and illustrated. The three contributions to semi-supervised learning are interesting although the first one (source-light enhancement module) is specific to astronomical source detection. The confidence-based module and the cross-view module work well together. The paper is sufficiently detailed, and with source code and data availability, should be reproducible. The approach does not require much computation power (a single inexpensive GPU used for training). Testing the approach on an ellipse-detection problem in computer vision show that some of the approaches carry over to different problems.\n\nThe comparison is well conducted on similar, competing methods, achieving state-of-the-art methods. The ablation study show that the proposed enhancement approaches for SSD work well together."}, "weaknesses": {"value": "The paper focuses on solving a specific problem, namely source detection for a specific spectroscopic telescope. This is not uninteresting, and the authors do show that some of their approach can carry over to other problems -- albeit with less impressive success, but the fact remains that the vast majority of the paper focuses on this problem. By itself this is not bad, but it does limit the impact of the paper.\n\nThe paper would have been much more interesting if the authors had not focused on the data coming from the LAMOST telescope, but had tried to propose a more general astronomical source detector. As it stands, this telescope has a unique optical design and purpose and therefore uniquely specific data; whereas source detection in astronomy is a widely studied topic with many aspects (stars, galaxies, faint objects, asteroids etc) and many evolving challenges. The data samples shown in supplementary material seems to show exclusively stellar-like point sources marred by various, very visible, optical artefacts, that are not representative of the variety of astronomical sources found in widespread data releases such as the Sloan Digital Sky Survey found at https://www.sdss.org \n\nIt is to be noted that many astronomical databases have been publicly available for quite some time and some are already well annotated. See for example the popular Galaxy Zoo project (https://data.galaxyzoo.org) which crowdsourced the detection and classification of millions of deep sky objects. Therefore I'm skeptical of the widespread appeal of the author's data contribution.\n\nAnother point I find problematic is the authors' claim that only relatively recent object detectors based on deep learning have any merit. The author's comparison section only lists such methods. In astronomy, the standard source detector is the tool sextractor, which the authors do cite, which was introduced in 1996, but of course has been regularly updated. The latest version dates from 2017. The python version the author used dates from 2024. This is one of the most widely used software tool in all of astronomy. It works very well across a wide variety of astronomical imaging modalities. In fact the authors of this paper used this tool to make their annotations! It is unthinkable that they did not compare their performance to this tool. Note that various enhancements have been proposed to sextractor, see [1,2] among others. Also, due to its versatile but simple approach, sextractor results are highly interpretable, which is not the case for most deep-learning based detectors.\n\nThe authors claim \"traditional\" tools like sextractor based on statistical detection and classical hand-crafted features are no longer relevant since deep-learning based detection are both faster and better performing. In fact sextractor is very fast and runs on modest hardware, and the authors did not show in any way that they did get better results than sextractor.\n\nConcerning the contributions, the first (source enhancement) is interesting but very specific. The second has larger appeal, although confidence-based pseudo annotations have been proposed before and have been shown to be biased. The third module is not very well described, in a single paragraph.\n\n\n[1] Thanh Xuan Nguyen et al. CGO: Multiband astronomical source detection with component-graphs. In 2020 IEEE International Conference on Image Processing (ICIP), pages 16–20. IEEE, 2020.\n[2] Mohammad Hashem Faezi, Reynier Peletier, and Michael HF Wilkinson. Multi-spectral source-segmentation using semantically-informed max-trees. IEEE Access, 12:72288–72302, 2024."}, "questions": {"value": "- Why not compare with sextractor ?\n- Why ignore more recent advances in astronomical source detection using traditional tools?\n- The bibliography on source detection with deep learning is incomplete. See for example [3] for a list of recent methods.\n- How much retraining would be necessary for the proposed method to work on say, SDSS data?\n- How were the annotations produced exactly? How much interaction with astronomers was necessary? how long was the process?\n\n\n\n[3] Ma Long, Xin Jiarong, Du Jiangbin, Zhao Jiayao, Wang Xiaotian, and Zhang Yu. Astronomical pointlike\nsource detection via deep feature matching. The Astrophysical Journal Supplement Series, 276(1):4, 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "MX7gfcGXlM", "forum": "3tscL6zGPJ", "replyto": "3tscL6zGPJ", "signatures": ["ICLR.cc/2026/Conference/Submission7222/Reviewer_ZfNx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7222/Reviewer_ZfNx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7222/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762305665029, "cdate": 1762305665029, "tmdate": 1762919365494, "mdate": 1762919365494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}