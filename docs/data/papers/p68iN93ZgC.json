{"id": "p68iN93ZgC", "number": 10273, "cdate": 1758165660949, "mdate": 1763694230168, "content": {"title": "Adaptive Neuronal Dynamics Drive Accurate and Efficient Spiking Neural Networks", "abstract": "Neuronal dynamics are fundamental to the temporal processing capabilities of spiking neural networks (SNNs), directly influencing their responsiveness and integration of dynamic input features. While most existing advances in SNNs focus on architectural optimizations or learning algorithms, the potential of adaptive neuronal dynamics remains underexplored. In this work, we pioneer a new direction by proposing a novel neuron model that achieves adaptive neuronal dynamics through a combined mechanism of learnable and dynamically modulated membrane time constant. This design enables each neuron to regulate its integration behavior in response to stimulus intensity and firing history, achieving short-term adaptive responses while maintaining long-term stability. Importantly, our approach maintains computational simplicity throughout the implementation. Experiments on multiple benchmarks, including physiological signals (DEAP) and neuromorphic vision datasets (DVS-Gesture, CIFAR10-DVS), demonstrate superior performance in both classification accuracy and robustness. In particular, our model achieves state-of-the-art accuracy of 90.11\\% and 92.57\\% on the DEAP valence and arousal classification tasks, representing improvements of +9.08\\% and +9.97\\% over the baseline. Furthermore, the proposed neuron demonstrates strong generalization across various network architectures, confirming its generality as a fundamental component for SNN-based systems. Additional energy consumption analysis confirms the high efficiency of our method. These results establish adaptive neuronal dynamics as a new pathway for developing effective and efficient  neuromorphic systems.", "tldr": "This work enhances the capability and efficiency of spiking neural networks through the implementation of adaptive neuronal dynamics.", "keywords": ["spiking neural networks", "adaptive neuronal dynamics"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/7ff71f8b52805a960bd834d9f56af56107d97977.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The parameterization of spiking neurons has a large impact on SNN performance and has been intensively studied. This paper proposes the AND-LIF model, whose membrane time constant τ is decomposed into three terms: a fixed base value, an input-dependent term, and an output-dependent term. The base value is trained by gradient descent, while the input- and output-related terms are updated as moving averages of the input current and output spikes, respectively; the coefficients in these recursions are also learned by back-propagation. The model is evaluated on one EEG classification task and two neuromorphic vision classification tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation is sound: AND-LIF adapts τ on-the-fly to both input and output, which in practice usually enlarges the neuron's memory horizon.  \n- Compared with the standard LIF neuron, AND-LIF introduces only negligible extra computation."}, "weaknesses": {"value": "The benchmark suite is not sufficiently representative. DEAP has rarely been used in previous SNN works, so well-established baselines are lacking; DVS-Gesture is small, and at >97 % accuracy the difference between methods amounts to only a few correctly classified samples; CIFAR10-DVS is the only large and challenging dataset with extensive baselines. The current results do not conclusively demonstrate the effectiveness of the proposed method."}, "questions": {"value": "How much slower is AND-LIF than LIF in actual training and inference time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rmEHyjcIAt", "forum": "p68iN93ZgC", "replyto": "p68iN93ZgC", "signatures": ["ICLR.cc/2026/Conference/Submission10273/Reviewer_77oK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10273/Reviewer_77oK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761013351119, "cdate": 1761013351119, "tmdate": 1762921626972, "mdate": 1762921626972, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "9BEbVhyDCS", "forum": "p68iN93ZgC", "replyto": "p68iN93ZgC", "signatures": ["ICLR.cc/2026/Conference/Submission10273/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10273/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763694229552, "cdate": 1763694229552, "tmdate": 1763694229552, "mdate": 1763694229552, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors use spiking neural networks for image and neuromorphic dataset classification. They propose a new spiking neuron model (the AND-LIF): essentially a leaky integrate-and-fire (LIF) neuron whose time constant is dynamic, because it is input and output-dependent."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "As far as I know, this neuron model is new."}, "weaknesses": {"value": "* The ablation study (Table 4) is not convincing, because the accuracy of the LIF on DVS-Gesture (I'm not familiar with DEAP, the other dataset they use) is very poor. The AND-LIF does much better, but of course, it's much easier to improve the accuracy on a poor architecture. So I suggest the authors use an architecture that reaches, or approaches, the SOTA with LIF neurons. If the  AND-LIF does even better, then it would improve the SOTA, making the paper much more interesting (more on this below).\n\n* Contrary to what the authors say and the tables suggest, the authors do not reach the SOTA on CIFAR10-DVS and do not improve it on DVS-Gesture (again, I'm not familiar with DEAP, the other dataset they use):\n1) On CIFAR10-DVS, several papers (not cited) reached 83%+ (see http://arxiv.org/abs/2304.12760 and refs therein), which is much better than this paper  \n2) On DVS-Gesture, several papers (not cited) reached 98%+ (see http://arxiv.org/abs/2502.10422 and refs therein), which is similar to this paper\n\nSo again, I suggest the authors start from an architecture that reaches the SOTA with LIF, and then replace LIF with AND-LIF, and see if this allows improving the SOTA.\n\nMINOR POINTS\n\n* Fig 1: I think S_j^{l+1} belongs to layer l. Thus, it should be in the upper box, and called S_j^l\n\n* Eq. 3: the authors may want to say that they used a so-called \"soft reset\"."}, "questions": {"value": "Eq 10 and 11: the authors use two parameters lambda and eta, but I think one would do. I think they could use a convex combination with lambda and (1-lambda), right?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "K4GIkZfjI8", "forum": "p68iN93ZgC", "replyto": "p68iN93ZgC", "signatures": ["ICLR.cc/2026/Conference/Submission10273/Reviewer_rjCE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10273/Reviewer_rjCE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761733680849, "cdate": 1761733680849, "tmdate": 1762921626478, "mdate": 1762921626478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes AND-LIF, a novel spiking neuron model that combines learnable and dynamically modulated membrane time constants. The neuron adaptively regulates its temporal integration behavior based on both input strength and spike history, achieving short-term adaptability while maintaining long-term stability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper grounds its design in well-known neurophysiological phenomena (e.g., Hodgkin–Huxley conductance adaptation, short-term plasticity), bridging biological neuron dynamics and computational models. \nThe proposed design integrates a trainable base time constant (long-term plasticity) with input- and spike-driven dynamic modulation (short-term adaptability)."}, "weaknesses": {"value": "1. The proposed adaptive time constant mechanism builds on well-established ideas from LTC networks and BA-LIF. The paper’s novelty lies more in combining learnable and dynamic components rather than introducing a fundamentally new formulation of temporal adaptation.\n2. The contributions of learnable vs. dynamic modulation are not thoroughly separated. It remains unclear how much each component contributes to the final efficiency gains.\n3. Although DVS-Gesture and DEAP are appropriate dynamic datasets, the paper does not test on frame-based temporal tasks (e.g., video or event-to-frame hybrid benchmarks). This limits the understanding of how AND-LIF scales to complex spatio-temporal modeling.\n4. This work focuses at the neuron level, but does not explore how adaptive dynamics could interact with higher-level architectural components.\n5. Without hardware-level validation, the energy benefit remains somewhat speculative."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eNok1TnjII", "forum": "p68iN93ZgC", "replyto": "p68iN93ZgC", "signatures": ["ICLR.cc/2026/Conference/Submission10273/Reviewer_RK65"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10273/Reviewer_RK65"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790668538, "cdate": 1761790668538, "tmdate": 1762921625920, "mdate": 1762921625920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}