{"id": "ryC6pXobCw", "number": 17269, "cdate": 1758274060849, "mdate": 1763734255999, "content": {"title": "KV Cache Steering for Controlling Frozen LLMs", "abstract": "We propose cache steering, a lightweight method for implicit steering of language models via a one-shot intervention applied directly to the key-value cache. To validate its effectiveness, we apply cache steering to induce chain-of-thought reasoning in small language models. Our approach constructs steering vectors from reasoning traces, obtained either from teacher models (e.g., GPT-4o) or existing human annotations, that shift model behavior toward more explicit, multi-step reasoning without fine-tuning or prompt modifications. Experimental evaluations on diverse reasoning benchmarks demonstrate that cache steering improves both the qualitative structure of model reasoning and quantitative task performance. Additional experiments show that the method also scales to larger models and yields further gains on challenging datasets such as GPQA and MATH. Compared to prior activation steering techniques that require continuous interventions, our one-shot cache steering offers substantial advantages in terms of inference latency, hyperparameter stability, and ease of integration with existing inference APIs. Beyond mere reasoning induction, we show that cache steering enables controllable transfer of reasoning styles (e.g., stepwise, causal, analogical), making it a practical tool for behavior-level guidance of language models.", "tldr": "", "keywords": ["large language models", "cache steering", "key-value cache", "chain-of-thought reasoning", "activation steering", "representation engineering", "style control"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f72b37c5c98d1e8b5db30474cf78e5c497e4d6a5.pdf", "supplementary_material": "/attachment/76f2855a300f307e3f23dc21c7e3abeaf7ed5dc0.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes cache steering, which, unlike previous Activation Steering, applies (patches) steering to the KV cache instead of each hidden activations (last position). According to the authors, this reduces computational overhead and sensitivity to hyperparameters. The core idea is to apply a one-shot modification to the prefilled key–value cache using steering vectors extracted from reasoning traces generated by a teacher model or human annotations. Experimental results show that cache steering improves both the reasoning structure and task accuracy across multiple small and medium-sized models, outperforming activation steering while incurring virtually no additional latency."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed cache steering is computationally more efficient than activation steering by removing the need for continuous activation editing.\n- The paper provides comprehensive evaluations across multiple models and datasets, with well-designed ablations on contrastive pair size, steering strength, and reasoning style.\n- The writing is clear, and the figures and tables are well-organised, improving readability and accessibility."}, "weaknesses": {"value": "If I have misunderstood any of the following points or if additional evidence can be provided, I would happily reconsider my evaluation.\n\n- The central idea of this work is to apply steering to the KV cache rather than to the hidden activations. However, as noted by the authors themselves in the related work section (Liu et al., 2025b), prior studies have already explored KV-cache-based interventions for enhancing reasoning ability. It would therefore be helpful if the authors could clarify what novel research insight or conceptual contribution distinguishes this paper from those earlier approaches. While the proposed idea does not necessarily need to be complex, it should clearly articulate its unique conceptual advance beyond existing work.\n- The paper discusses the over-steering problem, but this issue has already been addressed in prior work through Dynamic Steering (e.g., Scalena et al., 2024 [1]; Do et al., 2025 [2]). A comparison with these approaches is needed in my opinion.\n- The claim that KV-cache-based steering is less sensitive to hyperparameter choices requires stronger evidence. The authors only vary the number of contrastive pairs, few-shot examples, and steering strengths. In the experiments, cache steering is applied to all layers and specifically to a neutral offset token. It remains unclear whether the method would remain robust if applied to different layers or different token positions (see questions below).\n\n[1] Multi-property Steering of Large Language Models with Dynamic Activation Composition, Scalena et al., 2024, Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP\n\n[2] Dynamic Steering With Episodic Memory For Large Language Models, Do et al., 2025, Findings of the Association for Computational Linguistics: ACL 2025"}, "questions": {"value": "- Is KV-cache-based steering truly less sensitive to steering location as a hyperparameter? If applying it to only specific layers or to arbitrary token positions instead of the neutral offset token produces better results, then the method would still require grid search, similar to activation steering.\n- When steering is applied at each layer, doesn’t this still risk over-steering, since it modifies the representation at multiple points, analogous to injecting steering vectors into each residual stream? (although I agree that the over-steering would be less than the original activation steering)\n- In Table 1, cache steering underperforms activation steering on GSM8K for three models. Can the authors explain this behaviour? Also, have they tested a combination of activation steering + CoT prompting for a fair comparison?\n- As the generation length increases, the influence of the cache intervention may decay. Did the authors analyse this effect? If it does weaken over long generations, have they considered combining their method with continuous patching (as in standard activation steering)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "L3siDghmk0", "forum": "ryC6pXobCw", "replyto": "ryC6pXobCw", "signatures": ["ICLR.cc/2026/Conference/Submission17269/Reviewer_qbMb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17269/Reviewer_qbMb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17269/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937522613, "cdate": 1761937522613, "tmdate": 1762927218122, "mdate": 1762927218122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a KV cache steering method to induce reasoning capability to LLMs by modifying its internal hidden states. In specific, the KV steering is applied as a one time modification of the prefill KV and the steering is computed by following the reasoning traces of a capable teacher model like GPT-4o. The authors claim that compared to activation steering, which applies interventions at every decoding step, cache steering avoids cascading effects, is robust to hyperparameter choices, introduces virtually no runtime cost, and seamlessly integrates with standard inference pipelines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Beyond simple reasoning induction, KV cache steering enables controllable transfer of reasoning styles, without requiring any computation heavy re-training of the model.\n\n2. The KV cache steering is an one time effort compared to that with activation steering that is a repetitive effort (applies during each decode state) and requires fewer hyperparameter tuning overhead."}, "weaknesses": {"value": "1. While this work of leveraging steering vector to induce reasoning thoughts in a model is different, there exists other steering method that are applied to reduce the reasoning thoughts (example: [1, 2]).  Thus it is important to highlight these works and clearly state steering identification difference for the community to understand the usefulness and differences of such steering. Please add discussion to compare your work with these steerable calibration methods, particularly highlight the differences and/or similarities in calculating the steering vectors.\n\n2. The previously methods of reasoning trace steering are also one shot intervention, hence, the authors are requested to tone down on that part of the claim.\n\n3. Need of a teacher model to extract reasoning traces is a weakness, as it requires additional distillation memory of a bigger model loading, as well as dependence on the choice of teacher model.\n\n4. The extraction policy is very similar to activation steering as also noted by the authors, affecting the novelty of their key contribution.\n\n5. Advance requirement to know the desired and non desired behavior is a weakness, as it is not clear on the guideline of knowing this. Also, identification of such things asks for human intervention that can be compared with that of the labeling in SFT, thus downgrading one of the benefits of cache steering.\n\n[1] SEAL: Steerable Reasoning Calibration of Large Language Models for Free, COLM 2025.\n\n[2] Activation Steering for Chain-of-Thought Compression, Arxiv 2025."}, "questions": {"value": "1. Please add comparison of steering vector computation w.r.t [1, 2] and discuss differences in the steering process.\n\n2. Please demonstrate the reasoning capability on other reasoning datasets as well.\n\n3. Please compare the reasoning performance of an instruction tuned LLM with that of a rasoning training reasoning model.\n\n[1] SEAL: Steerable Reasoning Calibration of Large Language Models for Free, COLM 2025.\n\n[2] Activation Steering for Chain-of-Thought Compression, Arxiv 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8ZbyD5Gy5L", "forum": "ryC6pXobCw", "replyto": "ryC6pXobCw", "signatures": ["ICLR.cc/2026/Conference/Submission17269/Reviewer_Pttn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17269/Reviewer_Pttn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17269/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966788226, "cdate": 1761966788226, "tmdate": 1762927217480, "mdate": 1762927217480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed Cache Steering, which is a lightweight and easy-to-implement approach to steer language models for reasoning tasks. The approach focus on modification of the KV cache during inference with pre-computed steering vectors that calculated from contrastive set of prompt pairs. The shows advantages compared with activation steering in term of both accuracy and latency. The approach is also able to distill certain reasoning styles from teacher models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed Cache Steering is simple and easy-to-implement compared with other steering approaches. With little impact on latency, it shows better potential for real applications. \n2. The experiments are comprehensive, covering a wide range of LLMs and various reasoning datasets."}, "weaknesses": {"value": "1. Limited Performance: The proposed approach only achieved average accuracy improvement of less than 1% in Table 1, compared with CoT Prompt. Considering its performance vibration larger than 1% with different hyperparameters in figure 2, I'm not convinced that the proposed approach can further improve reasoning based on the commonly used Zero-shot CoT Prompt. \n2. Lack of interpretability analysis: No theoretical or empirical analysis for explaining why and how the proposed approach works, leaving limited insights for further investigation. \n3. Long CoT Models: Considering the promising reasoning performance of long CoT models like OpenAI o1 and DeepSeek-R1. I believe the value of the paper can be further improved if the proposed approach tested and discussed on long CoT models.\n4. Typo issues: Equation in section 3.2 is not clear from my view. I suppose f_l(p^+) and f_l(p^-) are the key or value vectors obtained within the attention block of Transformer layer l. But the notations do not show this, and even the same notations are used for key and value vectors. The \"which\" is misspelled as \"whcih\" in line 358 and 694."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eByoJy0Js6", "forum": "ryC6pXobCw", "replyto": "ryC6pXobCw", "signatures": ["ICLR.cc/2026/Conference/Submission17269/Reviewer_XM7K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17269/Reviewer_XM7K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17269/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969367443, "cdate": 1761969367443, "tmdate": 1762927216928, "mdate": 1762927216928, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}