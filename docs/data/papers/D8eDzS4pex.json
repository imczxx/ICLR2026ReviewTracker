{"id": "D8eDzS4pex", "number": 18649, "cdate": 1758289719562, "mdate": 1759897089706, "content": {"title": "LEARNING DISCRETE REPRESENTATIONS TO UNDER- STAND AND PREDICT TISSUE BIOLOGY", "abstract": "Learning tissue-level representations that capture the organization of entire tissues while preserving cellular and microenvironmental detail is a central challenge in spatial biology. While graph autoencoders have been employed to learn spatially aware continuous representations, they have limited utility for tissue-level generation, lack inherent interpretability for biological analysis, and are not readily reusable across contexts and modeling architectures. To address this challenge, we present SQUINT, a discrete representation learning framework for spatially-resolved transcriptomics that encodes tissues into a finite vocabulary of interpretable discrete codes. SQUINT achieves this by combining graph neural networks with vector quantization, conditioning on relative spatial distances, and employing a masking strategy during training. Cells are then represented by assignments to this shared vocabulary, allowing whole tissues to be modeled as sequences of discrete tokens. At inference, SQUINT codes enable gene expression imputation at arbitrary spatial locations outperforming state-of-the-art generative methods across diverse datasets. Further, we demonstrate the interpretability of these discrete tokens in capturing meaningful tissue structures beyond individual cells and reflecting recurrent mi-\ncroenvironmental organization patterns through downstream applications including 3D imputation, tumour stratification, and perturbation analysis.", "tldr": "Tokenization Scheme for Tissues using Spatially-Resolved Transcriptomics", "keywords": ["Spatial Transcriptomics", "Graph Machine Learning", "AI for Science", "Computational Biology"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9f735f6f44a555c68f544b78f49826771ab33cb4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SQUINT, a discrete representation learning framework for spatially resolved transcriptomics (SRT). The method combines a GNN encoder, vector quantization, and conditional masking to tokenize cells into discrete codes. The learned tokens are used for tissue-level generative modeling, tumor stratification, and perturbation analysis."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is easy to follow.\n- The idea of learning discrete spatially-aware cell tokens for SRT is conceptually interesting."}, "weaknesses": {"value": "- The evaluation of SQUINT is weak, which can be summarized in several aspects: \n  - For Task A (2D imputation), the author includes the Wasserstein Flow Matching (WFM) as a baseline for comparison. However,  it is apparent that WFM is not a suitable baseline as there are too many \"NA\" in the table. I suggest that the authors try simpler baselines such as Gaussian-process-based spatial interpolation methods, which have been demonstrated to perform effectively for spatial imputation in [2–4].\n  - For Task B-D, quantitative comparison with baseline methods seems to be completely missing.\n  - The ablation studies for the critical component in SQUINT are too simple.SQUINTw/o C model doesn't have much information for algorithmic insight.\n- The literature review on relevant work is notably incomplete. Discrete representation learning on transcriptomic data is not new [1] and the comparison with many existing works is missing. A method [2] for spatial imputation and perturbation is also ignored, which makes the claim \"To the best of our knowledge, SQUINT is the first model to address this task on SRT data.\" overstated.\n- Claims about batch effect correction are made but not supported by any experimental results.\n\n[1] Li, Y. MetaQ: fast, scalable and accurate metacell inference via single-cell quantization.\n\n[2] Hao, M. *et al.* GeST: Towards Building A Generative Pretrained Transformer for Learning Cellular Spatial Context.\n\n[3] Shang, L. & Zhou, X. Spatially aware dimension reduction for spatial transcriptomics. *Nat Commun* **13**, 7203 (2022).\n\n[4] Tian, T., Zhang, J., Lin, X., Wei, Z. & Hakonarson, H. Dependency-aware deep generative models for multitasking analysis of spatial omics data. *Nat Methods* **21**, 1501–1513 (2024)."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Au1iwxezhh", "forum": "D8eDzS4pex", "replyto": "D8eDzS4pex", "signatures": ["ICLR.cc/2026/Conference/Submission18649/Reviewer_yXRW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18649/Reviewer_yXRW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760790297587, "cdate": 1760790297587, "tmdate": 1762928357728, "mdate": 1762928357728, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents SQUINT, a spatially-aware discrete representation learning framework for spatial transcriptomics (SRT).\n Unlike continuous embedding approaches such as graph autoencoders or transformers, SQUINT encodes tissues into a finite vocabulary of interpretable discrete codes using a graph neural network encoder combined with vector quantization conditioned on relative spatial distances.\n Each cell is assigned to a shared codebook entry, allowing tissues to be represented as sequences of discrete tokens.\n The learned codes enable gene expression imputation at arbitrary spatial locations and capture recurrent microenvironmental motifs across samples.\n Empirical results on multiple datasets, including 3D skin sections and kidney tumor tissues, show that SQUINT achieves competitive reconstruction accuracy while providing interpretable symbolic representations applicable to downstream tasks such as tumor stratification and perturbation analysis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Discretization resolution and codebook stability not analyzed:**\n The impact of codebook size, token granularity, and quantization error on tissue representation quality is not systematically evaluated.\n\n\n**Clear architecture and presentation:**\n The model design—encoder, vector quantization bottleneck, decoder—is well illustrated and easy to follow. Figures and explanations are well aligned with the mathematical description.\n\n**Biological insight:**\n The discrete tokens reveal spatially recurrent structures and microenvironmental organization patterns that correspond to known biological phenomena (e.g., immune infiltration, tumor aggressiveness)."}, "weaknesses": {"value": "**Limited novelty relative to existing VQ approaches:**\n\n The overall framework follows the standard vector quantization autoencoder pipeline (VQ-VAE), with the main innovation being its application to SRT. The methodological contribution may be incremental compared to recent graph-based SRT embedding models.\n\n **Limited robustness and spatial consistency:**\n\nWhile SQUINT performs well in 2D spatial imputation, its robustness across 3D tissue sections is limited.\n As acknowledged by the authors, imputation quality drops in the middle of the Z-stack, likely due to misalignment and uneven section spacing.\n This indicates that the current formulation lacks explicit mechanisms to enforce spatial continuity or cross-section alignment, effectively treating 3D data as independent 2D slices.\n Consequently, the model’s generalization and robustness to spatial distortions or imperfect registration remain limited.\n Future work should consider alignment-aware architectures or continuous spatial encoders to achieve true volumetric reconstruction.\n\n**Scalability and computational cost not discussed:**\n\n Given the large number of cells in modern SRT datasets, it is unclear whether the model scales efficiently to millions of spatial spots or whole-organ datasets.\n\n**Limited cross-platform validation:**\n\nAlthough SQUINT claims general applicability to spatial transcriptomics data, the experiments are restricted to a small set of platforms (Visium, Xenium, CosMx).\n No evaluation is provided on high-resolution single-cell or subcellular assays such as MERFISH, seqFISH, or Stereo-seq, which differ substantially in spatial density, noise structure, and coordinate geometry.\n Without such validation, it remains unclear whether SQUINT can generalize across measurement technologies or maintain consistent token semantics under varying data modalities.\n This limitation raises questions about the model’s robustness and practical usability for diverse spatial omics datasets."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OBdlGGG54b", "forum": "D8eDzS4pex", "replyto": "D8eDzS4pex", "signatures": ["ICLR.cc/2026/Conference/Submission18649/Reviewer_DTxe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18649/Reviewer_DTxe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825859743, "cdate": 1761825859743, "tmdate": 1762928357155, "mdate": 1762928357155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a discrete representation learning framework for ST data that combines GNNs with vector quantization to encode cells as discrete tokens from a learned codebook. The authors claim these tokens enable gene expression imputation at arbitrary spatial locations and demonstrate applications in imputation, tumor stratification, and perturbation analysis. The manuscript in its current state has important conceptual, experimental, and presentation deficiencies that prevent me from recommending acceptance. The core concerns are: weak baseline comparisons, insufficient ablations and controls for important design choices, potential data/experimental leakage, over-claiming interpretability/clinical relevance from tiny cohorts, and missing reproducibility details."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper demonstrates the utility of learned discrete tokens across multiple biologically relevant applications (2D/3D imputation, tumor stratification, perturbation analysis), showing that the representations capture meaningful information beyond simple reconstruction. \n- Table 1 shows SQUINT achieves substantially better reconstruction metrics than the baseline across multiple datasets and species."}, "weaknesses": {"value": "- Authors claim the method enable generation of expression profiles. However the evaluation is limited to reconstruction metrics (MSE, SSIM, Pearson correlation). The authors should present examples of samples from the generative model, assessments of sample diversity, evaluations of biological validity beyond held-out reconstruction and comparisons to baseline generative models.\n- The authors fail to cite or compare against the relevant prior work. The paper claims to be \"the first spatially-aware discrete tokenizer tailored to SRT\". These claims are demonstrably false e.g., Yarlagadda et. al. [1] which presents a similar approach using VQ-VAE for ST data. This is oversight undermines claims of novelty. \n- The only generative baseline is WFM, which requires cell-type annotations & cannot perform location-specific imputation. The authors exclude other GNN-based ST methods like SpaGCN, STAGATE, GraphST, recent transformer approaches like CellPLM and scGPT-spatial, NMF-/ topic-modeling based approaches, or scVI-like VAEs adapted for spatial data.\n- How important are the different components like masking and FiLM conditioning? An ablation study assessing their impact is lacking. The \"custom masking strategy\" (Eq. 4) is just replacing masked cells with a learnable vector plus noise.\n- The generative model formulation (Section 4.1) is unnecessarily complex for what amounts to a conditional VQ-VAE\n- Why is GraphSAGE with mean pooling used here? The single-layer GNN seems simplistic. Fig. 8 shows GIN performs comparably—was this actually optimized or just chosen arbitrarily?\n- The MSSIM + NB loss combination (Eq. 5) lacks justification. Why MSSIM for sparse gene expression data? The λ weights appear hand-tuned without principled selection.\n- The imputation experiments define patches within one section as imputation sites while training on other cells from that section as well as remaining sections. That phrasing suggests the training set may include spatially adjacent cells to the held-out patches, risking trivial interpolation rather than true out-of-region generalization. The authors must precisely define the train/test partitioning (are held-out patches contiguous? how far from training cells?), and ideally evaluate far-away masking splits (e.g., hold out entire anatomical regions or whole sections) to test true generalization. Without this, the strong numerical gains could reflect spatial proximity rather than real generative power.\n\n[1]. Yarlagadda, D. V. K., Massagué, J., & Leslie, C. (2023). Discrete representation learning for modeling imaging-based spatial transcriptomics data. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 3846-3855)."}, "questions": {"value": "- How is the codebook initialized? The authors state using a codebook size of 5000 with multiple heads in some experiments (and claim it “avoids collapse”), but in the 3D skin experiment they use a codebook size of 50 (and 200 latent dims) — no explanation for the dramatic difference or guidance on choosing K. There is no systematic ablation of codebook size, head count, code utilization statistics, or metrics of codebook collapse.\n- What is the masking schedule (0.2 to 0.6 annealing)?\n- How stable is training with the straight-through estimator? What is the variance across random seeds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "n0iKDQhr3T", "forum": "D8eDzS4pex", "replyto": "D8eDzS4pex", "signatures": ["ICLR.cc/2026/Conference/Submission18649/Reviewer_Fxmk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18649/Reviewer_Fxmk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963333837, "cdate": 1761963333837, "tmdate": 1762928356518, "mdate": 1762928356518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SQUINT, a novel framework designed to learn discrete representations from spatially-resolved transcriptomics (SRT) data. The primary goal is to capture tissue-level organization and microenvironmental details within a finite, interpretable vocabulary of discrete codes. The method combines a Graph Neural Network (GNN) encoder with vector quantization (VQ), conditioned on relative spatial distances and trained using a masking strategy. Cells are thus represented by token assignments, enabling whole tissues to be modeled as sequences. The authors validate their approach on several downstream tasks, including 2D and 3D gene expression imputation, tumour stratification, and in silico perturbation analysis, claiming SQUINT provides interpretable codes and outperforms existing generative methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles the important and challenging problem of learning compact, interpretable, and reusable representations for complex SRT data, which is a significant bottleneck in the field.\n- The proposed method of combining a GNN with vector quantization to create a \"tissue tokenizer\" is a novel and interesting approach.\n- The authors demonstrate the utility of the learned discrete codes across a diverse range of downstream applications (imputation, stratification, perturbation), showing the potential versatility of the framework."}, "weaknesses": {"value": "1. **Overstated Novelty and Missing Baselines:** The authors claim that SQUINT is \"the first model to address\" the task of imputing gene expression at specific spatial locations. This is factually incorrect. For example, scGPT-spatial already supports this task and explicitly includes it as a pre-training objective. A direct performance comparison with this highly relevant baseline is missing, which makes it difficult to assess the actual performance and contribution of SQUINT for spatial imputation.\n2. **Unaddressed Scalability Concerns:** The paper does not sufficiently address the scalability of the GNN-based approach. The largest dataset mentioned (Sec 5.2) contains 280K cells, which is modest by modern SRT standards. It is unclear how SQUINT would perform in terms of memory and runtime on datasets with millions of cells. The authors do not report detailed computational overhead nor do they discuss potential GNN-specific issues like over-smoothing, which can be a significant problem in large, densely-connected graphs.\n3. **Insufficient Justification for Architectural Choices:** The justification for key architectural choices is lacking. The paper asserts that a two-layer MLP is sufficient to handle data sparsity, but this claim is not substantiated with ablation studies or other evidence. It is unclear how this conclusion was reached or why this specific design is optimal.\n4. **Lack of Detailed Dataset Information:** The paper omits a clear, consolidated summary of the datasets. For reproducibility, it is essential to provide specific details for *each* dataset, including the precise cell counts, the sequencing technology used (e.g., Xenium, Visium), and the number of genes measured."}, "questions": {"value": "1. Could the authors please clarify the claim of novelty regarding spatial imputation, given that models like scGPT-spatial already perform this task? More importantly, could you provide a direct performance comparison against scGPT-spatial for the 2D expression imputation task?\n2. Regarding scalability:\n   - What are the specific runtime and peak memory usage for training SQUINT on the 280K-cell dataset (Task B)? How do you anticipate these resources scaling to datasets with >1 million cells?\n   - Have you investigated the potential for GNN over-smoothing in your framework, particularly as the graph size and neighborhood depth increase?\n3. Could the authors provide an ablation study or further justification for the claim that a two-layer MLP is sufficient for handling data sparsity?\n4. Could you please add a table summarizing the key statistics for *each* dataset used in the experiments (e.g., specific cell count, sequencing method, gene count, data source)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ls4Yz2uJJc", "forum": "D8eDzS4pex", "replyto": "D8eDzS4pex", "signatures": ["ICLR.cc/2026/Conference/Submission18649/Reviewer_AdAr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18649/Reviewer_AdAr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18649/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004145306, "cdate": 1762004145306, "tmdate": 1762928355498, "mdate": 1762928355498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}