{"id": "S3YAqJk653", "number": 12336, "cdate": 1758207142697, "mdate": 1763707826231, "content": {"title": "GenEval: A framework to evaluate feasibility of domain generalization", "abstract": "This paper proposes a novel methodology for evaluating whether a learned hypothesis is generalizable to a new domain. EvalGen extracts underlying models that represent effects of causal factors on domain data and labels and uses a novel model divergence detection mechanism based on conformal inference to evaluate significant shift in causal factors in the new domain. As such, EvalGen can predict the performance of a learned hypothesis in the new domain without the need for execution in the new domain. We evaluate EvalGen on single, multi-dimensional time series applications as well as challenging medical imaging case studies on diabetic retinopathy in both single and multi-domain generalization experiments.", "tldr": "Given a set of source domains, a method for detection of feasibility of generalization to a target domain is proposed.", "keywords": ["domain generalization", "necessary sufficient condition", "violation detection"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f6586f1d5759abb591096d4617ac84269e81bf3d.pdf", "supplementary_material": "/attachment/aea68f3475395ed1289b54e438be66e2ab27b9fb.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces GenEval, a framework that predicts—without accessing target data—whether a domain-generalization (DG) hypothesis will succeed on a new domain. GenEval first recovers an implicit causal model from source domains via a Koopman–Mori–Zwanzig-based neural architecture, then detects distribution shift in causal factors through conformal inference. Extensive experiments on 14 time-series regression tasks and two medical-imaging benchmarks (diabetic-retinopathy classification) show that GenEval’s “domain-conformal boundary” (DCB) correlates strongly with downstream DG accuracy, enabling feasibility screening and source-domain selection."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Theoretical novelty: First work to explicitly test causal support and invariance preservation—two recently proven necessary conditions for DG—before deploying a model.  \n2. Methodological contribution: Non-steady-state extension of Mori–Zwanzig combined with conformal inference yields a calibration-free, unsupervised shift detector that works across modalities.  \n3. Empirical coverage: Evaluated on single-source and multi-source DG, regression and classification, synthetic and real clinical data; strong correlation (ρ ≈ 0.9) between DCB and SOTA accuracy.  \n4. Practical impact: Provides clinicians with a go/no-go indicator for deploying DG models on unseen hospitals/imaging devices without collecting new labels."}, "weaknesses": {"value": "1. Clarity and readability: The manuscript is extremely dense (≈ 21 pages, 6 algorithms, 4 theorems, 20+ metrics); key ideas are buried in notation.  \n2. Missing baselines: No comparison with recent DG diagnostics such as H-score (Arjovsky et al.), IRM’s ψ-score, or dataset-distance proxies (e.g., CMD, MMD).  \n3. Theoretical gaps:  \n   - Universality proof (Theorem 3) assumes control-affine dynamics; extension to non-smooth or partial-observable POMDPs is not discussed.  \n   - Conformal guarantees (Theorems 1–2) rely on exchangeability which may be violated under strong domain shift.  \n4. Reproducibility: Code is promised but not submitted; only pseudo-code is given. Hyper-parameters (τ, dropout threshold, library degree) are not ablated."}, "questions": {"value": "1. How does GenEval handle discrete/categorical domains (e.g., different DR grading protocols)?  \n2. What is the wall-clock time to compute DCB for a 100 k-image dataset?  \n3. Does the framework break when source domains themselves violate causal support (i.e., none cover Z_c)?  \n4. Can DCB be adversarially manipulated by augmenting source data with target-style noise?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DcjHaCNGKW", "forum": "S3YAqJk653", "replyto": "S3YAqJk653", "signatures": ["ICLR.cc/2026/Conference/Submission12336/Reviewer_1scL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12336/Reviewer_1scL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761800714353, "cdate": 1761800714353, "tmdate": 1762923258437, "mdate": 1762923258437, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the feasibility of domain generalization (DG) from one or multiple source domains to a target domain. It proposes a novel method called GenEval as a solution. GenEval addresses two key questions in evaluating DG feasibility—causal support and invariance preservation—by establishing domain conformal boundaries and hypothesis conformal boundaries. The method is evaluated on both time-domain and medical imaging tasks, demonstrating its effectiveness in various aspects of DG, including detecting violations of causal support and invariant-preserving representations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The presentation of this paper is good. Each methodological design is well justified with relevant prior works, and experimental details are fully provided. In particular, the analysis of the DG problem and related research is insightful—it identifies the core challenges of this topic and leads naturally to the proposed method.\n\n- The proposed method, GenEval, is both novel and versatile in the context of DG. It builds on solid theoretical foundations and effectively addresses the two key questions regarding the feasibility of DG. Moreover, it extends the DG problem setting by enabling target-domain performance prediction without model deployment and improving source domain selection to enhance generalization performance.\n\n- The empirical evaluation is extensive, covering diverse settings—including both single- and multi-source DG—and multiple task types, such as time-series regression and medical imaging classification."}, "weaknesses": {"value": "- The title and the claim that GenEval can evaluate the feasibility of domain generalization are somewhat misleading and may be considered an overstatement, given that GenEval assumes the data generation process is continuous and differentiable.\n\n- Although the current experiments demonstrate the effectiveness of GenEval in evaluating the two key properties of DG on time-series and medical imaging tasks, it remains unclear whether GenEval can assist in model selection or source domain selection when applied to various state-of-the-art DG methods reviewed in Section 2.2, especially on mainstream DG benchmarks such as DomainBed."}, "questions": {"value": "Since the paper addresses the DG problem, the justification would be clearer if state-of-the-art DG methods and mainstream DG benchmarks were included in the empirical evaluation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gvCDFmsG4C", "forum": "S3YAqJk653", "replyto": "S3YAqJk653", "signatures": ["ICLR.cc/2026/Conference/Submission12336/Reviewer_B4BX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12336/Reviewer_B4BX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993285091, "cdate": 1761993285091, "tmdate": 1762923258104, "mdate": 1762923258104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel framework \"GenEval\" to evaluate whether domain generalization (DG) is feasible for a given target domain without needing to execute models on that domain. The framework addresses two critical questions: \n\n1. Does the target domain satisfy the causal support assumption? (Are all causal factors in the target domain present in source domains?). \n\n2. Does a learned hypothesis preserve invariance? (Does the representation function accurately capture causal relationships across domains?). \n\nTo address both these questions, the framework has two main components: \n\n1. Unmeasured Causal Factor Extraction: Uses a novel combination of Mori-Zwanzig (MZ) formulation and Koopman operator theory with Liquid Time-Constant Neural Networks (LTC-NN) to recover hidden causal factors from data, even under forcing inputs (non-steady-state conditions). \n\n2. Model-Free Change Detection: Applies conformal inference to establish \"domain conformal boundaries\" (DCB) that detect significant shifts in causal structures between source and target domains.\n\nEmpirically, the paper shows the strong performance of GenEval for both time series benchmarks and medical imaging tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Following are the strenghts of the paper:\n\n1. This paper addresses an important problem of determining whether domain generalization (DG) is feasible for a given target domain. Further, it can assess DG feasibility before deploying models on target domains, also providing a practical tool for domain selection.\n\n2. Extends MZ-Koopman formalism to handle forcing inputs and non-steady-state dynamics, overcoming limitations of existing equation discovery methods.\n\n3. Uses conformal inference instead of extreme value theory, avoiding restrictive distributional assumptions.\n\n4. Empirically it works for both time-series (1D) and image (2D) data, demonstrated on 14 time-series benchmarks and challenging medical imaging tasks, and shows high correlation (0.83-0.91) between DCB% and actual model accuracy, validating the approach as a surrogate metric."}, "weaknesses": {"value": "Following are the main weakenesses of the paper:\n\n1. Paper is not well written and difficult to follow. Specifically,\n    \n    a. The related work is spread out across the paper (as drawbacks of existing literature), reducing the readability and flow of the paper. It would be beneficial if it is brought under a single section and then clearly mention the limitations of existing literature.\n    \n    b. In Section 2, the notation for both the time series and images are introduced together, which makes it difficult to understand.\n    \n    c. In introduction, while it is clear that Q2 relates to NC2, but it is not clear how Q1 relates to NC1. It would be helpful to give some reasoning for it in the introduction?\n\n    d. Overall, Sections 2 and 3 needs better reorganization.\n\n2. Assumption of differentiability :  The paper assumes data generation processes can be represented as continuous, differentiable dynamics, which somewhat limits the applicability of the framework. While the authors argue non-differentiable systems can be approximated as piecewise hybrid models, it seems it complicates the overall modeling of the system.\n\n3. Reading Table 3 and 4 together - it seems DCB% only provides guidance for relative accuracy and not absolute accuracy. Is it true? - how to use it practically, what should be the threshold under which it should be considered DG feasible v/s infeasible.\n\n4. The radial sampling strategy for images and trajectory-based SINDy analysis may not scale well to very large datasets or high-resolution images."}, "questions": {"value": "1. What is the compute and runtime required for the experiments (especially when LTC-NN architecture is being used)?\n\n2. Can you delve upon when this framework works or when it might not work?\n\n3. How can we distinguish between spurious correlations and genuine causal relationships?\n\n4.  While GenEval shows good correlation with existing methods, the absolute performance on diabetic retinopathy remains modest (best ~73-79%), does this reflect the general difficulty of the problem?\n\n5. Empirically, what DCB% threshold should considered for DG feasible vs. infeasible."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "eijdGBrhJJ", "forum": "S3YAqJk653", "replyto": "S3YAqJk653", "signatures": ["ICLR.cc/2026/Conference/Submission12336/Reviewer_4FP9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12336/Reviewer_4FP9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762364537140, "cdate": 1762364537140, "tmdate": 1762923257851, "mdate": 1762923257851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}