{"id": "94FUEijXfg", "number": 3752, "cdate": 1757512502945, "mdate": 1762957623254, "content": {"title": "Hierarchical Representation Matching for CLIP-based Class-Incremental Learning", "abstract": "Class-Incremental Learning (CIL) aims to endow models with the ability to continuously adapt to evolving data streams. Recent advances in pre-trained vision-language models (e.g., CLIP) provide a powerful foundation for this task. However, existing approaches often rely on simplistic templates, such as “a photo of a [CLASS]”, which overlook the hierarchical nature of visual concepts. For example, recognizing \"cat\" versus \"car\" depends on coarse-grained cues, while distinguishing \"cat\" from \"lion\" requires fine-grained details. Similarly, the current feature mapping in CLIP relies solely on the representation from the last layer, neglecting the hierarchical information contained in earlier layers. In this work, we introduce HiErarchical Representation MAtchiNg (HERMAN) for CLIP-based CIL. Our approach leverages LLMs to recursively generate discriminative textual descriptors, thereby augmenting the semantic space with explicit hierarchical cues. These descriptors are matched to different levels of the semantic hierarchy and adaptively routed based on task-specific requirements, enabling precise discrimination while alleviating catastrophic forgetting in incremental tasks. Extensive experiments on multiple benchmarks demonstrate that our method consistently achieves state-of-the-art performance.", "tldr": "", "keywords": ["Continual Learning; CLIP; Catastrophic Forgetting"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/06e20f381283ed2dae668f659411acf30a258b6f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes HERMAN (HiErarchical Representation MAtchiNg) for CLIP-based class-incremental learning (CIL). It (i) uses an LLM to generate hierarchical textual descriptors per class, (ii) aligns these with intermediate CLIP layer features via Top-K matching, (iii) introduces an adaptive router to weight layers. Across nine benchmarks, HERMAN reports consistent gains over prior CIL methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is easy to follow.\n- Across nine benchmarks, HERMAN reports consistent gains over prior CIL methods.\n- Reproducibility details are clear."}, "weaknesses": {"value": "- The paper’s central motivation is to leverage CLIP’s multi-layer representations and LLM-generated, multi-granularity textual descriptors. However, these design choices are largely orthogonal to the core challenges of class-incremental learning (CIL), so the method does not appear to be specifically tailored for CIL. While the authors do address forgetting via the routing update, this seems more like a localized fix than a CIL-driven design principle.\n- The novelty of this paper is limited. (i) The utilization of fine-grained description to enhance the representation has been studied, such as [a][b]. (ii) CLIP's multi-layer representations are also studied, such as [c]. The proposed adaptive hierarchy routing is similar to the Trainable Importance Estimator in [c].\n- More recent works should be compared, such as [d] [e].\n- For the ablation study, (i) more datasets should be applied, and (ii) results for all pairwise component combinations in addition to the full method should be reported.\n\n\n[a] DEMOCRATIZING FINE-GRAINED VISUAL RECOGNITION WITH LARGE LANGUAGE MODELS, ICLR 2024.\n[b] Does VLM Classification Benefit from LLM Description Semantics? AAAI 2025.\n[c] LEVERAGING REPRESENTATIONS FROM INTERMEDIATE ENCODER-BLOCKS FOR SYNTHETIC IMAGE DETECTION, ECCV 2024.\n[d] Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation, CVPR 2025.\n[e] Mind the Gap: Preserving and Compensating for the Modality Gap in CLIP-Based Continual Learning, ICCV 2025."}, "questions": {"value": "See the detailed comments in weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "TQL9LbiJPl", "forum": "94FUEijXfg", "replyto": "94FUEijXfg", "signatures": ["ICLR.cc/2026/Conference/Submission3752/Reviewer_2m6n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3752/Reviewer_2m6n"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760563383471, "cdate": 1760563383471, "tmdate": 1762916966205, "mdate": 1762916966205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "STRzHfxjFY", "forum": "94FUEijXfg", "replyto": "94FUEijXfg", "signatures": ["ICLR.cc/2026/Conference/Submission3752/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3752/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762957622168, "cdate": 1762957622168, "tmdate": 1762957622168, "mdate": 1762957622168, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HERMAN (HiErarchical Representation MAtchiNg), a method for class-incremental learning (CIL) built upon CLIP. The approach leverages hierarchical visual-textual representations by aligning CLIP’s intermediate visual features with LLM-generated textual descriptors of varying granularity (from coarse to fine). To combine these multi-level representations, the authors propose an adaptive routing mechanism with a projection-based update to preserve stability across incremental tasks. Experiments on nine CIL benchmarks show consistent improvements over prior CLIP-based methods such as RAPF and PROOF."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and easy to follow, with clear motivation and problem formulation.\n\n- The hierarchical descriptor idea is intuitively appealing and effectively illustrated.\n\n- The framework is modular (descriptor generation $\\rightarrow$ alignment $\\rightarrow$ routing), making it conceptually straightforward to implement.\n\n- The experiments are comprehensive, covering nine benchmarks with reasonable ablations and sensitivity analyses.\n\n- The comparison baselines are mostly fair, as all methods use the same pre-trained CLIP backbone."}, "weaknesses": {"value": "- The core technical contribution lacks novelty. Aligning CLIP’s intermediate layers with hierarchical or multi-level textual cues is similar to prior work that already explored hierarchical or layer-wise multimodal alignment [1, 2]. \n\n- The hierarchical textual descriptors depend heavily on LLMs (GPT-5, Qwen-Plus), yet the paper offers no analysis of descriptor quality, variability, or noise sensitivity. The LLM essentially produces descriptive phrases, which may not always be semantically consistent or discriminative.\n\n- The adaptive router with a projection constraint is conceptually close to prior projection/subspace stabilization in continual learning, where updates are projected to preserve subspaces important for past tasks [3, 4].\n\n- There is no discussion of computational overhead or the cost of descriptor generation and multi-layer matching, which are relevant for practical deployment.\n\n\n[1] Visual Query Tuning: Towards Effective Usage of Intermediate Representations for Parameter and Memory Efficient Transfer Learning. In CVPR 2023.\n\n[2] Multi-Layer Visual Feature Fusion in Multimodal LLMs. In CVPR 2025.\n\n[3] Gradient Projection Memory for Continual Learning. In ICLR 2021.\n\n[4] Efficient Lifelong Learning with A-GEM. In ICLR 2019."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GaJ6tjpzwZ", "forum": "94FUEijXfg", "replyto": "94FUEijXfg", "signatures": ["ICLR.cc/2026/Conference/Submission3752/Reviewer_uUw4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3752/Reviewer_uUw4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761628262670, "cdate": 1761628262670, "tmdate": 1762916966003, "mdate": 1762916966003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes Hierarchical Representation Matching for CLIP-based CIL in order to dynamically exploit hierarchical representations. Furthermore, to select the most suitable semantic hierarchy, it introduces an adaptive routing mechanism. Plus, additional techniques are introduced to stabilize the routing process."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It utilizes LLM to generate multiple text descriptors ( from coarse to fine-grained).\n2. Adaptive routing mechanisms are beneficial for adjusting the expression and mutual trade-offs of features at different levels."}, "weaknesses": {"value": "1. Regarding the route update issue, intuitively, using projection constraints can indeed reduce subspace overlap during optimization. However, it seems the ablation experiments don't cover this part of the update. Could the authors demonstrate this ablation experiment? I see Figure 3(c) is about similarity, mentioning this ablation, but it only shows similarity, not accuracy (neither the accuracy of old knowledge nor the overall accuracy).\n\n2. The router could be considered for direct freezing. If this reveals a performance difference, it proves that router optimization is necessary to some extent; otherwise, it doesn't demonstrate this. I hope the authors can provide experiments in this area."}, "questions": {"value": "1. Regarding $\\beta$, I'd like to ask if there's a corresponding distribution for beta that can be shown? After all, the distribution of $\\beta $ determines whether this is a true multi-layered problem, or whether only one or two layers are activated."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3NsT0gFq1w", "forum": "94FUEijXfg", "replyto": "94FUEijXfg", "signatures": ["ICLR.cc/2026/Conference/Submission3752/Reviewer_jiuj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3752/Reviewer_jiuj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761823803115, "cdate": 1761823803115, "tmdate": 1762916965806, "mdate": 1762916965806, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "HERMAN enhances CLIP for class-incremental learning via hierarchical textual descriptors from LLMs, aligned with multi-layer visual features, and an adaptive router updated with projections to reduce forgetting. It outperforms SOTA on benchmarks such as CIFAR-100 and ImageNet-R."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.Integrates LLMs naturally for enriching semantics in CIL.\n2.The adaptive routing mechanism helps balance coarse- and fine-grained cues.\n3.The projection-based router update is a nice touch for stability in CIL."}, "weaknesses": {"value": "1.The novelty is limited, as hierarchical matching builds on existing ideas such as multi-layer features in CLIP (e.g., Enhancing CLIP with GPT-4) and prompt hierarchies, which don't introduce fundamentally new concepts. \n\n2.Similar hierarchical prompting appears in works such as Menon & Vondrick (2023) and Khattak et al. (2023), and the routing is reminiscent of a mixture-of-experts without strong differentiation.\n\n3.The projection for the router feels like a minor tweak on subspace preservation techniques.\n\n4.Experiments lack comparisons to more recent CIL methods beyond PROOF, such as those using advanced replay or distillation in vision-language settings.\n\n5.The method's complexity (LLM generation, routing, projection) may not justify the modest gains over simpler baselines like SimpleCIL.\n\n6.How sensitive is performance to the choice of LLM (e.g., GPT-5 vs. others)? The paper shows robustness, but what about smaller models?\n\n7.Could you clarify the computational overhead of recursive descriptor generation and routing?\n\n8.Why not compare to non-CLIP CIL methods like iCaRL or DER for a broader context?\n\n9.How does HERMAN handle domains far from CLIP's pre-training, beyond the reported benchmarks?\n\n10.What is the runtime cost of LLM descriptor generation per class? Is it feasible for large-scale CIL?\n\n11.Could you provide t-SNE visualizations for additional datasets to demonstrate the alignment benefits?\n\n12.How does HERMAN perform with frozen text encoders or minor CLIP variants?"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JkUyQEPwuE", "forum": "94FUEijXfg", "replyto": "94FUEijXfg", "signatures": ["ICLR.cc/2026/Conference/Submission3752/Reviewer_dGS6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3752/Reviewer_dGS6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762106145903, "cdate": 1762106145903, "tmdate": 1762916965550, "mdate": 1762916965550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}