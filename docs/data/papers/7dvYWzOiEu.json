{"id": "7dvYWzOiEu", "number": 3766, "cdate": 1757515916861, "mdate": 1759898070962, "content": {"title": "Meta-Learning Theory-Informed Inductive Biases using Deep Kernel Gaussian Processes", "abstract": "Normative and task-driven theories offer powerful top-down explanations for biological systems, yet the goals of quantitatively arbitrating between competing theories, and utilizing them as inductive biases to improve data-driven fits of real biological datasets are prohibitively laborious, and often impossible. To this end, we introduce a Bayesian meta-learning framework designed to automatically convert raw functional predictions from normative theories into tractable probabilistic models.\nWe employ adaptive deep kernel Gaussian processes, meta-learning a kernel on synthetic data generated from a normative theory. This Theory-Informed Kernel specifies a probabilistic model representing the theory predictions -- usable for both fitting data and rigorously validating the theory. As a demonstration, we apply our framework to the early visual system, using efficient coding as our normative theory. \nWe show improved response prediction accuracy in ex vivo recordings of mouse retinal ganglion cells stimulated by natural scenes compared to conventional data-driven baselines, while providing well-calibrated uncertainty estimates and interpretable representations. Using exact Bayesian model selection, we also show that our informed kernel can accurately infer the degree of theory-match from data, confirming faithful encapsulation of theory structure. This work provides a more general, scalable, and automated approach for integrating theoretical knowledge into data-driven scientific inquiry in neuroscience and beyond.", "tldr": "", "keywords": ["Computational Neuroscience", "Gaussian Processes", "Efficient Coding", "Deep Kernel Learning", "Meta-Learning", "Inductive Biases", "Bayesian Deep Learning"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/73908cf7df8d994c935f7e145c16434b196554f9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "I'm very sorry, but even after three readings I did not understand this paper; it is simply _way_ out of my area of expertise. I'm going to give it a neutral review: goods all around, with the lowest possible confidence. But this review should be totally discarded."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "n/a; see above."}, "weaknesses": {"value": "n/a; see above."}, "questions": {"value": "If the paper were totally rewritten in such a way that I could understand it, the would help. But it's hardly an appropriate task for the authors. However, if they want to have impact on neuroscientists (at least neuroscientists such as myself), they're going to have to publish a massively dumbed-down version."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "x3ejEvyWam", "forum": "7dvYWzOiEu", "replyto": "7dvYWzOiEu", "signatures": ["ICLR.cc/2026/Conference/Submission3766/Reviewer_JnnY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3766/Reviewer_JnnY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556626945, "cdate": 1761556626945, "tmdate": 1762916979795, "mdate": 1762916979795, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This research presents a new Bayesian machine learning framework to bridge the gap between theoretical neuroscience and data analysis. The method automatically translates complex “normative” theories (like efficient coding) into practical, probabilistic models that can be directly used to analyze biological data. By using a “theory-informed kernel” within a deep Gaussian process, the framework improves prediction accuracy, provides reliable uncertainty estimates, and allows for rigorous testing of the underlying theory – all without requiring manual tuning or specific parameterizations of the theory itself.\n\nThe work delivers a scalable and automated way to integrate theoretical knowledge into data-driven neuroscience, demonstrating improved performance on retinal ganglion cell data. Beyond neuroscience, it also advances Bayesian machine learning by providing a novel application of deep kernels for domain-informed model design, addressing common challenges like “feature collapse” to ensure well-calibrated uncertainty. This framework ultimately allows researchers to not only use theories to understand data, but also test and refine those theories with data in a statistically rigorous manner."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This work demonstrates considerable merit through a novel and conceptually strong approach to integrating theoretical frameworks with data-driven analysis. The authors’ strategy of embedding inductive bias via the Theory-Informed Kernel, learned from simulations generated by normative theory, is particularly intriguing and offers a compelling pathway toward more biologically plausible modeling.\n\nThe methodological foundation built upon Bayesian machine learning is a significant strength, with the provision of calibrated uncertainty estimates representing a valuable addition to the standard machine learning toolkit. Furthermore, the proposed Bayesian model comparison framework appears to be a promising and well-motivated concept, facilitating rigorous hypothesis testing and quantitative evaluation of theoretical predictions.\n\nFinally, the inclusion of detailed technical considerations regarding Deep Kernel Learning (DKL) training, as outlined in Supplementary Figure S.F.4, constitutes a valuable contribution to the field, offering practical insights and potentially mitigating common pitfalls such as feature collapse as previously reported in the literature. This level of technical detail enhances the reproducibility and broader applicability of the presented methodology."}, "weaknesses": {"value": "The paper appears to be written mainly by neuroscience domain experts,\nmaking it difficult for readers primarily interested in the ML methodology\nto follow due to the use of domain-specific terminology. For instance, the\nmanuscript frequently employs neuroscience-specific terms without introduction\n-- for example, the use of “bottleneck” in expressions such as “minimizing\nbottleneck activity” (line 215) and “single optimized bottleneck neuron” (line\n237) -- which may not be immediately clear to readers from the ML community.\nSection 4.1 and the corresponding supplementary material are challenging to\ninterpret for non-experts; translating the neuroscience terminology into\nmachine learning concepts requires some effort before the underlying regression\nsetup becomes apparent. The interchangeable use of the terms “task” and “neuron”\nis confusing and should be avoided."}, "questions": {"value": "Content:\n\n* The authors should elaborate on why it is necessary to have \"task-specific\"\n  linear layers feeding into task-specific GP models. The text introduces the\n  fact but doesn't actually seem to motivate it.\n* Line 266: The authors could elaborate on how the \"base RBF GP\" works when the\n  feature extractor is not used, i.e. how are the input images processed and\n  fed to the linear head and GP in this case?\n* Fig. 3b, Sec. 4.4.: the authors should elaborate on the principal components:\n  how many PCs are needed to faithfully explain the data / why is it adequate\n  to show the GP prediction as function of just PC1?\n* Fig. 3b, Sec. 4.4.: from the plots it seems that the DKL with RBF base kernel\n  has similar behavior to the \"bare\" RBF GP baseline - in both cases the RBF's\n  stiffness / smoothness / low curvature seems to dominate and the model\n  doesn't actually seem to model the data particularly well (esp. in the 1400\n  points case) -- the \"informed\" kernel's effect seems minor.\n* Fig. 5a: The authors should explain the tight cluster of points parallel to\n  the x-axis, they don't seem to be part of the linear trend point cloud.\n* The manuscript introduces \"support\" and \"query\" data (line 140) and equate\n  those to more familiar \"train\" and \"validation\" data, which would make the\n  former two terms unnecessary. Please explain why this new terminology is\n  needed.\n* In several places the authors mention \"well-calibrated (epistemic)\n  uncertainty\". Around lines 1446 and 1589 it is mentioned that the\n  likelihood's noise level is set close to zero. Typically in regression\n  settings, GPs are calibrated when the total uncertainty, in the simplest case\n  of a scalar homoscedastic $\\sigma_n$, $\\Sigma + \\sigma_n^2\\,I$, is\n  considered. If the likelihood noise is (assumed to be) zero, then the authors\n  seem to suggest that the variance in the data is explained by model\n  uncertainty alone. In this case, calibration plots or calibration error\n  metrics (see e.g. http://arxiv.org/abs/2109.10254) should be reported to back\n  the claim that uncertainties are indeed \"well-calibrated\".\n\n- line 265: “the improved performance over the bare RBF GP indicates that the learned embedding is meaningful” such indirect assessments suggest to be glossing over details as the performance of the whole system is taken as an indicator for the performance of a subsystem. Please be more precise.\n\n- line 271: “this subverts the conventional idea about kernel methods, such as GPs, being specialized for extremely low data regimes.” This reads like an overly general statement without references. I relate this statement to the approach documented in the paper, which cannot give rise for a general statement about GPs.\n\n- line 288: “with both models fit on the full dataset” I hope that the models have only been fitted on the training set and a hold-out set or cross-validation was performed. Please reconsider this formulation.\n\n- line 296: “this suggests … our representation usefully structures the input space” no evidence is given for this assessment, please consider removing it.\n\n- line 299: the introduction of the main metric NLPD is very brief. The text does hardly detail where the probability distribution in question is obtained from. Please add details on how NLPD is computed in your use case. This provides a better angle for people in the ML community unfamiliar with this metric to judge your results.\n\n- line 323: 'As N grows, the GP layers ... letting the data \"speak for themselves\".' Please remove this heuristic description of an effect for which the paper does not present evidence.\n\n- page 7, fig 4.a. Please add a color scale, so that the different tones of red/blue can be interpreted\n\nNotation:\n\n* Table S1: please use scientific notation $A \\times 10^{-B}$ vs. ``Ae-B``\n* The manuscript shows inconsistent notation (or typos) in several places:\n  * task $T$ (line 216) vs. $\\mathcal T$ (line 161)\n  * likelihood noise $\\sigma_n$ (lines 1547, 1575) vs. $\\sigma_\\eta$ (line 127 and others)\n  * $\\theta_\\text{gp}$ (line 124) vs. $\\theta_{gp}$ (1375)\n  * $exp$ (line 1375) vs. $\\exp$\n  * text in subscripts such as $\\mathcal D_{train}$ (line 126) vs. $x_\\text{train}$ (line 300)\n  * $P(...)$ (line 404) vs. P$(...)$ (line 416)\n* There is code-specific notation lacking corresponding typesetting, e.g.\n  ZeroMean() instead of $\\texttt{ZeroMean()}$ or better just \"zero mean\" in\n  this case maybe (line 1375), Scikit-Learn’s NearestNeighbors instead of\n  $\\texttt{NearestNeighbors}$, same with n_clusters=None (Sec. S.D.3)\n* line 404 and 416: although the formula in the letter line for $\\beta^*$ is targetting the grid search, please check if the use of $\\beta$ and $K_\\beta$ is correct. If so, please comment why $K_\\beta$ is used in the latter formula on line 416."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VyNsVumKzl", "forum": "7dvYWzOiEu", "replyto": "7dvYWzOiEu", "signatures": ["ICLR.cc/2026/Conference/Submission3766/Reviewer_SKqL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3766/Reviewer_SKqL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835335580, "cdate": 1761835335580, "tmdate": 1762916979057, "mdate": 1762916979057, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work the authors present a novel framework to capture normative theoreies as deep kernels for a Gaussian Process by framing the extraction process as meta-learning framework. Based on simulation results generated from a theoretical model, the inductive-bias of the theory is sought to be captured by learning a feature extractor that works across distinct instances of tasks, thereby serving as basis of GP kernel that in turn can be used to model and assess real experimental data. The Bayesian model nature of this approach (via the GP) allows for assessment typically difficult in theoretically-motivated models such as the degree of epistemic uncertainty and fidelity of the theory in capturing the experimental data."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Clarity: The work is clearly written with easy to follow structure. All necessary background materials were described suffiicently allowing for readers who may not be deeply familiar with the topic to follow and appreciate the contribution.\n\nQuality: All derivations and mathematical motivations are clearly presented and accurate. \n\n\nOriginality & Significance\nThe paper addresses a critical challenge in computational neuroscience — quantitative and comparable assessment of alternative normative theories. As the authors highlight in introduction, the field has been in great need of a method to combine the inductive bias provided by normative theories while providing data-rooted assessment of the merits (or lack thereof) of theory-based inductive bias in improving model predictions.\nThe theory-informed Gaussian process introduced by the authors provide a straightforward approach  to possibly frame theoretical predictions into a meta learning task, capturing the effective inductive-bias into the meta-learned feature extractor. Unlike traditional theoretically-motivated approaches, this method provides for a concrete approach to turn theoretical-model with plausible simulation into ultimately a Gaussian process model that can be fit and evaluated on experimental data. The work is quite original with a theoretically well-motivated application of deep GP kernels in capturing the inductive bias through the formulation of meta-learning framework."}, "weaknesses": {"value": "Although the bridge from the inductive-bias into meta-learning framework is elegant, the presented case of efficient coding appears quite limited, and leaves applications to a broader theoretical inductive-bias deserved to fully assess the generalizability of this approach. In particular, for the efficient coding example, it appears that meta learning tasks were all derived from a specific instance of auto-encoder model trained on natural images in accordance to efficient-coding objective. Given this, it appears to be an overstatment to me to say that the meta-learning framework can be said to have captured the inductive-bias of the full notion/theory of efficient coding. Rather, it appears that the Gaussian process feature extractor only effectively captured the very specific instance of an autoencoder, and thus not necessary can be deemed to be representative of the underlying theoretical framework.\nIt is also not clear"}, "questions": {"value": "Questions:\n* Can this framework be applied to other categories of normative theories such as neural sampling code/theory?\n* Would it be viable to meta-learn the feature extractor on multiple instances of theoretical models (e.g. such as models trained and optimized on a distinct set of natural images, but all still trained using EC objective)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BeNqZGMSVd", "forum": "7dvYWzOiEu", "replyto": "7dvYWzOiEu", "signatures": ["ICLR.cc/2026/Conference/Submission3766/Reviewer_Xmij"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3766/Reviewer_Xmij"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976603684, "cdate": 1761976603684, "tmdate": 1762916977175, "mdate": 1762916977175, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a Bayesian meta-learning framework that automatically converts predictions from normative theories (such as efficient coding in vision) into tractable probabilistic models using adaptive deep kernel Gaussian processes. The approach has three stages: (1) generating synthetic data from a normative theory, (2) meta-learning a theory-informed kernel (TIK) on this synthetic data, and (3) adapting this kernel to real biological data. The authors demonstrate their framework on mouse retinal ganglion cell (RGC) responses to natural images, showing improved prediction accuracy over baselines while providing well-calibrated uncertainty estimates and interpretable representations. A key contribution is enabling rigorous Bayesian model comparison to quantify the degree of theory-match in biological data.\n\nThe main contributions are: (1) a general framework for automatically constructing probabilistic models from \"black-box\" normative theories, (2) demonstration that theory-informed priors improve predictive accuracy and uncertainty quantification on real neural data, (3) interpretable representations via prototype images that reveal what task-specific heads learn, and (4) a principled method for validating competing scientific hypotheses using exact marginal likelihoods."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: the paper makes several original contributions. First, it bridges normative modeling and data-driven approaches in a principled Bayesian framework, addressing a longstanding challenge in computational neuroscience. While meta-learning and deep kernel GPs exist independently, their combination for learning theory-informed priors over functions is novel. The adaptive nature of the prior, where the Bayesian Occam effect automatically relaxes theoretical structure as data becomes abundant (Fig. 4b), is a novel finding in line with theory.\n- Quality: The experimental validation is thorough and rigorous. The authors provide extensive ablation studies (Fig. S1, Table S1) demonstrating that performance gains specifically arise from meta-learned theory-informed features, not from generic meta-learning or random features. The framework also successfully avoids feature collapse (a known pathology in deep kernel GPs) through careful design choices that are well-documented (S.F.4). The validation on synthetic data with controlled optimality levels (Fig. 5a, showing Pearson correlation of 0.88 with ground truth) nicely demonstrates that the method can accurately infer the degree by which the data matches the theory. I am also pleased that the paper also includes negative results and limitations (the \"worst NLPD\" neurons in Fig. 4c), which increases credibility.\n- Clarity: The paper is generally well-written with clear motivation and strong visual presentation. Figure 1 effectively communicates the three-stage framework, and Figure 2 provides a detailed architectural overview. The mathematical notation is consistent, with the theory-informed kernel clearly specified. The supplementary material is exceptionally comprehensive, providing implementation details, hyperparameters, and additional results that would help reproducibility. I appreciate that the main text is accessible, but maintains technical rigor (with additional information in the supplementals where necessary). \n- Significance: this work provides a principled method for validating and comparing normative theories against biological data, a critical need in computational neuroscience. The framework's generality to any normative model where data is available suggests broad impact. Moreover, the ability to perform exact Bayesian model comparison without manual model specification is a useful methodological advancement. The finding that “theory-informed” models excel across all data regimes, and not just low-data settings, challenges conventional wisdom about kernel methods and supports modern perspectives on inductive biases in deep learning. For the machine learning community, this provides a compelling real-world application of deep kernel GPs."}, "weaknesses": {"value": "1. Validation of this method is restricted to a single biological system (86 mouse RGCs from one retina), testing one normative model of the efficient coding principle. It remains unclear how well this method can generalize to other principles or normative models, and how reliant it is on the specific architectural choices (e.g. CNN feature extractor). To that end, I would have liked to see the method applied to other recent models such as Cadena et al. (2019), Bashivan et al. (2019), or even vision transformers, which would help demonstrate the generality of this method. Moreover, the claim that the framework is “broadly applicable” would be substantially strengthened by demonstrating successful application to at least one additional domain from Table S2 (e.g. V1 simple cells, where sparse coding predictions could be tested, or auditory cortex). \n2. There is insufficient analysis of when and why the method fails. The paper shows that performance varies substantially across neurons (Fig. 4c, 5b), but provides limited insight into what distinguishes neurons where the method succeeds from those where it fails. The observation that poorly-fit neurons have less interpretable and less consistent prototype images (Fig. 4c-d) is descriptive rather than explanatory. Failures might be explained by (a) neurons that genuinely don't follow efficient coding, (b) limitations in the specific efficient coding model used (Ocko et al. 2018), (c) the meta-train set not covering the relevant part of theory space, or (d) fundamental limitations of the RBF kernel in the learned embedding space. The paper would benefit from a more systematic analysis to explain the failure modes. \n3. I have some concerns with the prototype image analysis (Section 4.5, S.H). First, the normalizing procedure for computing $\\Delta_{jk}^{(i)}$ (which normalizes by maximum values) is problematic. For instance, a single distant pair of data points can dominate the normalization, which may induce spurious values in the other data pairs. I suggest seeing how the analysis changes if normalization is calculated through relative distance changes, i.e. $\\Delta_{jk}^{(i)} = (D_{jk}^{\\phi}-D_{jk}^{(i)}) / D_{jk}^{\\phi}$, or through Procrustes alignment. Second, the pixel-wise comparison assumes features exist at the same spatial locations across images, which is a strong assumption given that the feature extractor includes convolutional layers that should be translation-invariant. The visualization method cannot capture features that the head is sensitive to at different spatial locations. I suggest a SVD-based analysis of the head transformation, where $W_i = U \\Sigma V^{T}$. The right singular vectors indicate the most transformed direction in $\\phi$ space, and for each $v_l$ one can compute the gradient $\\partial v_{l}^{\\top}\\phi_{j} / \\partial x_{j}$ to show which features in the image most influence that direction.\n4. In the section on Bayesian model comparison, high $\\beta^{\\*}$ could mean either (a) the neuron follows efficient coding principles, or (b) the neuron’s function is well-described by features useful for natural images generally, or (c) both. To distinguish between these, one could test the model on non-natural stimuli such as white noise, gratings, or synthetic stimuli, where natural image statistics do not apply but where efficient coding principles might still hold. Second, it is not clear what $\\beta^{*}=0$ means. Is it that the neuron is best described by the RBF null model, or that neither the TIK nor RBF kernel captures it well. \n5. The method extracts linearized receptive fields from the EC autoencoder’s bottleneck via LN model fits. Why is the linear readout the right quantity to meta-learn? Moreover, all 490 meta-train tasks come from a single instantiation of the Ocko et al. model with fixed hyperparameters. The paper acknowledges that “varying these parameters would likely yield different efficient coding solutions” (S.E.1). Would meta-training on a family of EC models with varied hyperparameters improve generalization? \n6. From section S.G.3, I see that meta-training tasks around 4 hours, and adapting this to all 86 neurons at all data sizes takes 6-12 hours on a single GPU. For researchers wanting to apply this to hundreds or thousands of neurons, or to test variations of their normative theory, these costs could be prohibitive. I think this paper would benefit from an analysis of how runtime scales with meta-train set size, number of neurons, and data dimensions, and a discussion of possible optimizations such as amortized inference or GP approximations. \n7. What other ways could you have partitioned the meta-learning process other than a CNN feature extractor and linear readout? Could you consider alternatives, such as task-specific kernels beyond RBF in the head space, meta-learning the kernel type itself, or task-specific transformations? Some discussion of why you made these specific architectural choices would help."}, "questions": {"value": "1. Can you provide a systematic analysis of what distinguishes neurons where the model performs well versus poorly? Specifically, are failure cases correlated with any known biological properties (cell type, receptive field location/size, response reliability)? For the neurons with low $\\beta^*$ values (Fig. 5b), is this because they do not follow efficient coding, or is it to do with model limitations? Can you analyze whether failures occur for neurons whose true receptive fields fall outside the range covered by your augmented meta-train set?\n2. How would the SVD approach (mentioned above) compare against the current prototype images? Can you validate that the prototype images capture causally-relevant features, for instance by showing that synthetic images emphasizing these prototypes produce predictable changes in model outputs? Finally, for neurons where prototype images look interpretable (Fig. 4c, left), do they match the receptive fields estimated by traditional methods (e.g., spike-triggered average)?\n3. Can you test the model comparison approach on non-natural stimuli (white noise, gratings, synthetic images) that do not possess natural image statistics? If $\\beta^{\\*}$ remains high for neurons with high $\\beta^{\\*}$ on natural images, this would provide stronger evidence that the theory informed kernel​ captures specific EC principles rather than natural image features. Have you considered alternative null models? For instance, what happens if you compare against the \"Task Ablation\" kernel (meta-learned on PCA prediction tasks) instead of the RBF? Would this better isolate theory-specific structure? Finally, for biological neurons with $\\beta^{\\*}$ near 0, can you determine whether this means the RBF null is actually a good fit, or whether both models fail?\n4. You meta-trained on one instantiation of the Ocko et al. model with fixed hyperparameters. Have you explored meta-training on a family of EC models with varied hyperparameters? Would this improve generalization and/or allow the framework to discover which EC hyperparameters best match biology?\n5. You use fixed task-specific linear heads of a specific dimensionality. How sensitive are results to this dimensionality? How would using non-linear task-specific transformations affect the results? Also, the narrow lengthscale on the kernel seems important. Is there a principled way to set this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w7vsdh9tsB", "forum": "7dvYWzOiEu", "replyto": "7dvYWzOiEu", "signatures": ["ICLR.cc/2026/Conference/Submission3766/Reviewer_YV9C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3766/Reviewer_YV9C"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762207154843, "cdate": 1762207154843, "tmdate": 1762916975873, "mdate": 1762916975873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for Bayesian meta-learning that turns predictions from a normative theory into a deep-kernel Gaussian Process. The shared feature extractor is meta-trained on synthetic data from an efficient-coding model of the retina, which is then adapted per task to fit real neural activity. The theory-informed kernel enables Bayesian model comparison via a mixture kernel that estimates each neuron’s degree of alignment with the theory. On retinal ganglion cells, the model has higher predictive accuracy and better uncertainty calibration compared to baselines (RBF-GP, CNN, and LN), and in addition, yields interpretable features."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The novelty of this study resides in the development of a Bayesian meta-learing framework that links normative theories to empirical observations.\n\n- The study is technically sound, although I have a few points I would appreciate the authors to address (see weaknesses).\n\n- In general, the manuscript is clearly written.\n\n- The results in this study suggest that the developed approach is a valuable contribution towards integrating normative theories and data-driven modelling."}, "weaknesses": {"value": "- The experiments are limited to a single dataset. It would be desirable to study how the approach generalises to other problems.\n\n- It is unclear how the approach will scale to the very common scenario in neuroscience of the study of neural circuits."}, "questions": {"value": "- Could the authors discuss how the proposed framework might extend to other neural systems beyond the retina, especially in cases where normative theories differ from efficient coding or are less well defined?\n\n- How does the method scale with increasing dataset size or when modelling populations of neurons?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "k9eXR17YVa", "forum": "7dvYWzOiEu", "replyto": "7dvYWzOiEu", "signatures": ["ICLR.cc/2026/Conference/Submission3766/Reviewer_raz1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3766/Reviewer_raz1"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission3766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762364522695, "cdate": 1762364522695, "tmdate": 1762916975145, "mdate": 1762916975145, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}