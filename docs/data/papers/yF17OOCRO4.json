{"id": "yF17OOCRO4", "number": 20554, "cdate": 1758307349242, "mdate": 1763084509109, "content": {"title": "SliceFine: The Universal Winning-Slice Hypothesis for Pretrained Networks", "abstract": "This paper presents a theoretical framework that explains why fine-tuning small, randomly selected subnetworks (slices) within pre-trained models is sufficient for downstream adaptation. We prove that pretrained networks exhibit a universal winning slice property, arising from two phenomena: (1) spectral balance— the eigenspectra of different weight matrix slices are remarkably similar—and (2) high task energy—their backbone representations (pretrained weights) retain rich, task-relevant features. This leads to the Universal Winning Slice Hypothesis, which provides a theoretical foundation for parameter-efficient fine-tuning (PEFT) in large-scale models. Inspired by this, we propose SliceFine, a PEFT method that uses this inherent redundancy by updating only selected slices of the origi- nal weights—introducing zero new parameters, unlike adapter-based approaches. Empirically, SliceFine matches the performance of SOTA PEFT methods across various language and vision tasks, while significantly improving training speed, memory efficiency, and model compactness. Our work bridges theory and prac- tice, offering a theoretically grounded alternative to existing PEFT techniques.", "tldr": "Pretrained models contain “universal winning slices”; tuning tiny random weight slices with SliceFine—adding no new parameters—matches SOTA across language and vision.", "keywords": ["PEFT", "subnetwork/slice selection", "spectral balance", "universal winning slice", "lottery-ticket", "fine-tuning", "transfer learning", "LLMs", "vision transformers."], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0a8a0ebdf33505effaaae5ad281b161348a017dc.pdf", "supplementary_material": "/attachment/5142a146018bdd55e713b205533ed56390bc0696.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes SliceFine, a novel PEFT method that adapts a pretrained model to a downstream task by updating only a selected subset of rows and columns, called slices, of the original weights. The method is motivated by a universal winning slice property, grounded in spectral theory, which demonstrates that optimizing a single slice of a weight matrix can be sufficient to reduce downstream task loss. This property arises from two phenomena: (1) spectral balance, where each slice of a weight matrix contains roughly the same spectral energy, and (2) high task energy, where each slice retains nontrivial overlap with the task-relevant subspace. SliceFine is shown to match the performance of state-of-the-art PEFT methods across extensive vision and language experiments, while significantly reducing the number of fine-tuned parameters, improving training speed and memory efficiency. These results suggest that SliceFine is a strong and efficient alternative to existing PEFT techniques."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "Simplicity and Transparency: The proposed SliceFine method is conceptually and practically simple. Its implementation requires no architectural modification or added parameters, making it easy to integrate with existing frameworks.\n\nTheoretical Grounding: The method is well motivated by the Universal Winning Slice Hypothesis, supported by spectral balance and high task energy analyses.\n\nCompetitive Performance and Efficiency: Through extensive experiments across vision, language, and multimodal domains, SliceFine achieves performance on par with or slightly better than SOTA PEFT methods such as LoRA and AdaLoRA, while being faster, memory-efficient, and parameter-free.\n\nComprehensive Validation: The paper provides theoretical insights, ablation studies, and empirical benchmarks. It examines slice rank, switching interval, orientation, and randomization effects, which strengthen and support the proposed method."}, "weaknesses": {"value": "Comparison with random mask: Although the proposed method is theoretically well-grounded, the ablation study \"K\" using a random mask, where a random subset of weights is selected instead of a predefined slice, shows performance comparable to the main approach. This suggests that, for a model that has been extensively pretrained, nearly any random subset of weights can be fine-tuned with similar effectiveness. It would therefore be valuable to demonstrate additional benefits of using structured slices (such as rows or columns) beyond potential hardware efficiency. In particular, could you quantify the performance difference in terms of wall-clock time or similar metrics? Without such justification, the advantage of using structured slices over random masking appears limited. I recommend including this ablation and its analysis in the main paper.\n\nRelationship between slice rank and number of slices: It is not clear how the relative importance between the slice rank r and the total number of fine-tuned slices manifests in the dynamic slice setting. In other words, would it be more beneficial to increase r while using a static slice policy, or to adopt a dynamic policy with a lower r? Clarifying this trade-off would help better understand the factors that most influence performance.\n\nSlice selection strategy (row vs. column): The results suggest that the choice between row- and column-based slicing has little impact on performance. This observation reinforces the idea that a specific slice selection heuristic may not be necessary, and that one could arbitrarily choose a subset of weights from each layer for fine-tuning with comparable results. Does alternating row–column updates meaningfully improve representational diversity or convergence stability?"}, "questions": {"value": "How many training steps or epochs are typically required for SliceFine to converge compared to existing PEFT methods? \nDoes the dynamic slice movement introduce additional instability or slower early convergence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ttui02RhpW", "forum": "yF17OOCRO4", "replyto": "yF17OOCRO4", "signatures": ["ICLR.cc/2026/Conference/Submission20554/Reviewer_nmDw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20554/Reviewer_nmDw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20554/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760708856275, "cdate": 1760708856275, "tmdate": 1762933971124, "mdate": 1762933971124, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript under review proposes the Universal Winning–Slice Hypothesis (UWSH): in dense pretrained networks, any sufficiently wide row/column “slice” is a local winner, and a small set of such slices across layers can match full fine-tuning (global winner). It motivates SliceFine, a PEFT method that updates only moving slices of existing weights (no new parameters), and reports competitive accuracy and efficiency gains across language, image, and video tasks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Forumulation of UWSH is new and it connects PEFT success to structure already present in pretrained weights, \n\n2. SliceFine updates only in-place slices (no adapters/rank factors) and can sweep positions; the method is straightforward to implement. \n\n3. Results cover LLMs (LLaMA-3B reasoning), ViT on VTAB-1k, and VideoMAE, with clear tables.\n\n4. Wall-clock comparisons under matched budgets (same epochs/batch/precision) are provided."}, "weaknesses": {"value": "1. The paper's core theoretical contribution rests on an unproven \"Spectral Balance Across Slices\" statement, which is presented as a lemma but lacks a mathematical proof. Without a mathematical proof, this is an assumption, not an established lemma. Furthermore, even if this assumption is granted, the proof for Theorem 2.4 (regarding the global winning ticket) appears incomplete. The derivation likely requires additional strong assumptions about the relationship between the model's Jacobian, the task subspace, and the perturbation introduced by fine-tuning, which are not explicitly stated or justified.\n\n2. While the training setup is matched, the comparisons may not be fully equitable. Parameter-Efficient Fine-Tuning (PEFT) methods are highly sensitive to hyperparameters like rank, adapter placement, and warm-start strategies. The current ablations are insufficient to rule out performance variations stemming from suboptimal baseline configurations. A more comprehensive sweep over ranks and placements for baseline methods, coupled with reporting multi-seed variance (beyond 3 seeds), is necessary to robustly validate the claimed improvements.\n\n3. The efficiency analysis in Table 3 is incomplete, as it omits key comparisons. Most notably, the VeRA method is missing from this table, making it impossible to assess its efficiency relative to the proposed method. Additionally, for the results in Table 2, the specific rank used for the VeRA baseline is not stated, preventing a fair comparison of performance versus parameter count. Also, VeRA for Roberta-base seems to have higher scores than reported in Table 7 (appendix) with smaller number of parameters.\n\n4. The paper observes that a rank-1 adaptation is often sufficient, but also notes that tasks with flatter loss landscapes require larger ranks. This nuance tempers the \"tiny slice\" narrative. While the authors suggest using PCA on a calibration set for automatic rank selection, this guidance remains a high-level sketch and is not operationalized into a practical, validated algorithm for practitioners.\n\n5. The introduction and related work fail to situate the method within the growing body of research on spectral fine-tuning. Spectral Adapter (Zhang & Pilanci, NeurIPS 2024) directly fine-tunes in the spectral domain. This is highly relevant. Other works on the connection of LTH, spectrum and finetuning such as XoRA (Ev et al., NeurIPS 2024 Workshop), A Study on the Ramanujan Graph Property of Winning Lottery Tickets (Pal et al., ICML 2022) etc are also pertinent."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Y7eLNzhS7n", "forum": "yF17OOCRO4", "replyto": "yF17OOCRO4", "signatures": ["ICLR.cc/2026/Conference/Submission20554/Reviewer_NnfP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20554/Reviewer_NnfP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20554/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924896607, "cdate": 1761924896607, "tmdate": 1762933970807, "mdate": 1762933970807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "I enjoyed reading this paper. The idea behind SliceFine is surprisingly simple—just update a small slice of the pretrained weights instead of adding any adapters—but the authors show that this works consistently well across many models and tasks. I also found the efficiency angle compelling: keeping everything dense and contiguous makes the method very practical.\nOne thing I’m curious about is whether this approach could also apply to audio models like Whisper or wav2vec-style encoders, since the technique mainly relies on the structure of pretrained weight matrices.\nThanks to the authors for this beautiful and informative work."}}, "id": "SBOX02jpDK", "forum": "yF17OOCRO4", "replyto": "yF17OOCRO4", "signatures": ["~Haris_Mansoor1"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "~Haris_Mansoor1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20554/-/Public_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763095325523, "cdate": 1763095325523, "tmdate": 1763095325523, "mdate": 1763095325523, "parentInvitations": "ICLR.cc/2026/Conference/-/Public_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel theoretical framework for understanding and enabling parameter-efficient fine-tuning (PEFT) of large pre-trained models. The authors introduce the Universal Winning-Slice Hypothesis (UWSH), which states that any sufficiently wide, randomly selected slice (a contiguous set of rows or columns) of a pre-trained weight matrix can act as a \"local winning ticket.\" Fine-tuning only this slice, while freezing the rest of the network, reliably improves downstream performance. This phenomenon arises from two key properties of pre-trained networks: spectral balance, where different slices of a weight matrix have similar eigenspectra, ensuring no slice is inherently weak; and high task energy, where the frozen backbone representations already concentrate features relevant to the downstream task. Theoretically, the work formalizes how a slice's overlap with the task subspace guarantees a non-zero gradient and loss decrease.\n\nInspired by this theory, the authors develop SliceFine, a PEFT method that fine-tunes only a small, moving set of slices across the network's layers. Crucially, SliceFine introduces zero new parameters, unlike adapter- or low-rank-based methods, by updating only selected portions of the original weights. The active slice is periodically moved to a new position during training, allowing the model to gradually cover the task-relevant subspace.\n\nComprehensive experiments across language, vision, and video tasks demonstrate that SliceFine matches or exceeds the accuracy of state-of-the-art PEFT methods while significantly improving training speed, reducing memory usage, and yielding more compact models. Empirical ablations robustly confirm the UWSH, showing that performance is largely insensitive to the specific position or importance-based selection of the slice. This work successfully bridges theory and practice, offering a compelling, theoretically-grounded alternative for efficient model adaptation."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "This paper demonstrates substantial strengths in originality, quality, clarity, and significance. Its core originality lies in proposing the novel Universal Winning Slice Hypothesis, which fundamentally challenges the conventional Lottery Ticket Hypothesis by revealing that any sufficiently large weight slice in pre-trained networks can serve as an effective adaptation unit. The derived SliceFine method represents exceptional ingenuity, introducing a parameter-efficient fine-tuning approach that dynamically updates original weight slices without adding any new parameters.\n\nThe paper exhibits outstanding quality through rigorous theoretical analysis grounded in spectral balance and high task energy, providing solid mathematical foundations for its claims. Comprehensive experimental validation across diverse modalities—including language, vision, and video tasks—robustly demonstrates competitive performance against state-of-the-art baselines while achieving superior efficiency. The empirical design is particularly thorough, incorporating extensive ablation studies that systematically verify critical components like slice rank and switching frequency.\n\nExceptional clarity is maintained throughout the presentation, with logical organization from theoretical foundation to practical implementation. Complex concepts are clearly explained through well-designed illustrations and coherent narrative flow. The work's significance is profound, offering both theoretical insights into pre-trained networks' intrinsic properties and practical advances for efficient adaptation. By demonstrating the untapped potential within original model parameters, it opens new research directions in minimalist fine-tuning strategies and substantially advances our understanding of model adaptation mechanisms."}, "weaknesses": {"value": "While the paper is strong, some limitations exist. The theoretical analysis relies heavily on the linearized NTK regime, whose validity for deep nonlinear fine-tuning remains unclear. Experimentally, the method's evaluation on extremely large-scale models (e.g., >50B parameters) is absent, leaving its scalability to the largest contemporary models unverified. Additionally, the comparison to recent sparse fine-tuning methods like SparseFine and DSP is missing, creating an incomplete competitive landscape."}, "questions": {"value": "Could you discuss how SliceFine scales to extremely large models beyond 50B parameters, particularly regarding training stability and slice rank requirements? How does your method compare with recent sparse fine-tuning approaches like SparseGPT that also avoid adding parameters? The theoretical analysis relies on the linearized NTK regime - could you address how the approach remains effective when fine-tuning induces significant nonlinear behavior in deeper layers? Have you explored adaptive slice selection strategies based on gradient information rather than cyclic scheduling, and if so, what were the outcomes? These clarifications would help better understand the method's scalability, competitive positioning, and theoretical robustness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MNgt8CfwKR", "forum": "yF17OOCRO4", "replyto": "yF17OOCRO4", "signatures": ["ICLR.cc/2026/Conference/Submission20554/Reviewer_j1cG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20554/Reviewer_j1cG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20554/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762071026229, "cdate": 1762071026229, "tmdate": 1762933970506, "mdate": 1762933970506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "I really enjoyed going through this paper. SliceFine feels like one of those ideas that’s almost “too simple” in the best way—just train a small slice of the existing weights—yet the results show it competing with or outperforming much more complicated PEFT methods.\n\nI also appreciated the theoretical motivation, especially the “universal winning slice” hypothesis. It gives a nice perspective on why fine-tuning works and why so many different subsets of weights can still be effective. That part really helped deepen the intuition behind the method.\n\nI do have one question about inference: in LoRA we typically merge the low-rank factors back into the base weight and then run inference normally. How does this work for SliceFine? Since the method updates a slice of the weight matrix directly, is inference identical to using the base model with the updated slice, or is there any additional step needed?\n\nOverall, great work—thanks to the authors for presenting such a clean and well-investigated approach."}}, "id": "EtUFRkZvlA", "forum": "yF17OOCRO4", "replyto": "yF17OOCRO4", "signatures": ["~Upama_Roy_Chowdhury1"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "~Upama_Roy_Chowdhury1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20554/-/Public_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763531584753, "cdate": 1763531584753, "tmdate": 1763531584753, "mdate": 1763531584753, "parentInvitations": "ICLR.cc/2026/Conference/-/Public_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}