{"id": "avnKEvJk3O", "number": 18993, "cdate": 1758292602063, "mdate": 1759897068612, "content": {"title": "Transformers self-organize like newborn visual systems when trained in prenatal worlds", "abstract": "Do transformers learn like brains? A key challenge in addressing this question is that transformers and brains are trained on fundamentally different data. Brains are initially ”trained” on prenatal sensory experiences (e.g., retinal waves), whereas transformers are typically trained on large datasets that are not biologically plausible. We reasoned that if transformers learn like brains, then they should develop the same structure as newborn brains when exposed to the same prenatal data. To test this prediction, we simulated prenatal visual input using a retinal wave generator. Then, using self-supervised temporal learning, we trained transformers to adapt to those retinal waves. During training, the transformers spontaneously developed the same structure as newborn visual systems: (1) early layers became sensitive to edges, (2) later layers became sensitive to shapes, and (3) the models developed larger receptive fields across layers. The organization of newborn visual systems emerges spontaneously when transformers adapt to a prenatal visual world. This developmental convergence suggests that brains and transformers learn in common ways and follow the same general fitting principles.", "tldr": "Transformers trained on simulated prenatal retinal wave develop brain-like visual structures, suggesting that both systems may learn through shared, general principles of space-time fitting.", "keywords": ["transformers", "prenatal", "retinal waves", "newborn visual system", "orientation", "shape perception"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cf4aa64f00f1091470eb12d6f3269aa70169a5b2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper examines a specific class of flexible space-time fitters, i.e., transformers, by training them on retinal wave-like visual stimuli to recapitulate edge specificity in early model layers, shape specificity in later model layers, and a local-to-global effective receptive field hierarchy across the model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Understanding the functio-structural relevance of retinal waves is an important question as a lot of prior research has theorized their involvement in shaping the functional organization of the cortex in-utero. If one were to build a biophysically-plausible model of the visual system to analyze developmental similarities, then an investigation into some form of pre-eye opening activity-dependent organization of the model units seems necessary. The paper does a good job of presenting the motivation, and the paper is generally easy to follow. The methods used also seem reasonable."}, "weaknesses": {"value": "I am a bit confused about the term \"self-organization\" as used throughout the paper. When I think about self-organization or functional organization or organization more simply, I dissociate it from representational similarity. The methods used in the paper, such as for edge and shape selectivity, either simply compare representational similarities between the model layers and that hardcoded for orientation tuning, or discriminate between color- and shape-based preference. How do the RSMs from different model layers compare to those from humans? Prior works have already compared RSMs between models and adult brains, so using some of that data here might be helpful towards the claim. But thinking outside of just representational similarity, a leading theory behind why brains functionally organize is due to wiring economy constraints, such as that explored by Margalit et al. (2024). If the claim being made in the paper is that transformers \"mimick the proto-organization of newborn visual systems\" (ll. 392-393), then the methods as they have been used in the paper do not fully support that. How should I think about organization without considering the model as topographic at some level?\n\nAdditionally, I think the paper is missing a control. What happens if you train transformers on other kinds of stimuli, such as drifting sine gratings or natural videos, to tease out the unique contributions of the specific prenatal visual worlds (retinal waves) that infants are exposed to. Does pre-training, in any form irrespective of the visual world, yield the same forms of preferences in the model? If so, what roles do retinal waves play?\n\nFinally, some of the figures such as 4(d) bar plots are really low-resolution and I cannot interpret them carefully even after significantly zooming in."}, "questions": {"value": "Please see the weaknesses section above!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "L7IoDhX0yh", "forum": "avnKEvJk3O", "replyto": "avnKEvJk3O", "signatures": ["ICLR.cc/2026/Conference/Submission18993/Reviewer_czJx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18993/Reviewer_czJx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18993/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761762562081, "cdate": 1761762562081, "tmdate": 1762931046808, "mdate": 1762931046808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose to train a Transformer on synthetically generated retinal wave data to simulate visual learning in prenatal phase. The resulting model is used as a model of the biological visual systems to probe various characteristics of proto-organization of visual systems like edge sensitivity, shape sensitivity, and increased receptive field size. The authors find that network trained on retinal wave data does in fact develop edge sensitivity in earlier layers, shape sensitivity to later layers, and increased receptive field size. The authors also train on temporal shuffled retinal wave data, and the network fails to learn lots of important structure of visual systems in prenatal phase. This indicate the necessity of the temporal statistics of retinal wave in facilitating basic visual system development."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and easy to follow.\n- The neuroscientific motivation is strong. In the absence of better non-invasive device of recording the brain activities of prenatal babies, probing a computational model of the brain is the obvious way to go."}, "weaknesses": {"value": "- Line 098: “did not use spatiotemporal retinal waves”. This is not quite true. Ligeralde et al. (2024) used spatiotemporal retinal waves data and also retinal waves data collected from neurophysical experiments.\n- I have some concerns about the experiment over temporally shuffled retinal wave data. Essentially, if you destroy the temporally smoothly varying structure, then there is no hope of learning the conventional image-to-image similarity metric using any temporally contrastive methods. In fact, you are learning a distribution that’s already different from the natural video distribution. By pulling together representations in a small window of temporally shuffled data, you fail to isolate the effect of spatial statistics in facilitating the formations of various characteristics of prenatal visual systems. So it seems like to me that if you want to carefully isolate out the effect of spatial statistics in the absence of temporal statistics, you should use a reconstruction-based objective (either in pixel-space or latent space) over the retinal wave data. Otherwise, it’s hard to entangle whether the failure of learning structured receptive fields is due to absence of both spatial and temporal structure or just the temporal statistics."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KTpMTDjY8d", "forum": "avnKEvJk3O", "replyto": "avnKEvJk3O", "signatures": ["ICLR.cc/2026/Conference/Submission18993/Reviewer_VdaR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18993/Reviewer_VdaR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18993/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845741184, "cdate": 1761845741184, "tmdate": 1762931046431, "mdate": 1762931046431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examines whether transformers can self-organize like newborn visual systems when trained on biologically inspired “prenatal” data. Specifically, the authors train Vision Transformers (ViT-CoT) on simulated retinal wave inputs using a temporally contrastive learning objective. They report that the trained models spontaneously develop three hallmarks of early visual organization: (1) edge sensitivity in early layers (2) shape sensitivity in later layers and (3) progressively larger receptive fields across depth. Control experiments using temporally scrambled inputs fail to produce these properties, leading the authors to conclude that temporal continuity in prenatal sensory experience is sufficient for the emergence of newborn-like visual structure.\n\nWhile the framing is interesting, the main claims of the study seem overstated. It remains unclear what unique scientific or methodological insights arise specifically from using transformers instead of CNNs, beyond substituting architectures and adopting an existing temporal contrastive objective. The lack of downstream or out-of-domain evaluations makes it difficult to assess whether pretraining on retinal waves produces useful or generalizable representations. Training for 100 epochs (!) on a small, repetitive dataset diverges sharply from real prenatal conditions, and the model’s spatial resolution and foveal focus limit biological plausibility. The study seems to be an illustrative demonstration than quantitative progress toward understanding how brains self-organize."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. he paper is well structured, and easy to follow from motivation through methods and results. The narrative is coherent, and the figures are well integrated with the text.\n2. The plots and visualizations are clean, intuitive, and easy to interpret, which makes the main findings immediately accessible even to readers outside the specific subfield.\n3. The idea itself is conceptually compelling and has the potential to inspire new directions at the intersection of neuroscience and machine learning."}, "weaknesses": {"value": "1. The work closely mirrors the approach of [Ligeralde et al. (2024)], differing mainly in the substitution of CNNs with ViTs and the adoption of the ViT-CoT contrastive temporal loss from [Pandey et al.]. Several prior studies have already trained models on simulated retinal wave data, demonstrating the emergence of V1-like receptive fields. As a result, the scientific contribution here feels incremental (architecture substitution than fundamentally new idea or learning principle, or even a strong test)\n\n2. The paper does not meaningfully compare the current results against other (prior) models trained on retinal activity (like Ligeralde et al., or ReWaRD). Is the claim that those models don't learn V1-like receptive fields? Not including the existing body of work within the evaluations of the current paper makes it unclear what conceptual advance is being claimed. \n\n3. The authors claim that “if transformers really do learn like brains, they should develop the same structure as newborn brains when trained on the same prenatal data.” But they end up training , training for *100 epochs* (!) seems biologically implausible. This seems contradictory to the core premise of the paper. A model of development should consider the developmental training trajectories as well!\n\n5. The experiments use very low-resolution inputs, which raises concerns about whether the reported findings would hold at more realistic scales (e.g., 224×224 images). Alternative architectures such as [LightViT](https://arxiv.org/pdf/2207.05557) could be used because a) they don’t have convolutional layers and b) they support large image resolutions.\n\n6. The receptive field experiments are restricted to the foveal region. However, receptive field size is known to vary with eccentricity (see [Freeman & Simoncelli, 2011](https://www.nature.com/articles/nn.2889), Fig. 1). Extending this analysis across eccentricities would provide a more comprehensive and biologically grounded evaluation.\n\n7. By default, the ViT-CoT architecture (as implemented in the [`vit_pytorch`](https://github.com/buildingamind/ViT-CoT/blob/097f83ed70814793f7b32a1beddeb3a4cbbc4625/requirements.txt#L19C1-L19C12) library used by [used by Pandey et al.](https://github.com/buildingamind/ViT-CoT/blob/097f83ed70814793f7b32a1beddeb3a4cbbc4625/models/vit_contrastive.py#L82), which the authors follow) takes the `[CLS]` token as the model’s output embedding by default (as seen [here](https://github.com/lucidrains/vit-pytorch/blob/cbf6723063df2aa89526f9482b1c9a64feef9cb0/vit_pytorch/vit.py#L83)). If this token is excluded when computing receptive fields, the analysis may no longer reflect the representations actually used for downstream processing. This discrepancy (using one token for functional output and another set for representational analysis) raises concerns about the validity and interpretability of the receptive field results."}, "questions": {"value": "1. What does using ViTs and the ViT-CoT loss reveal beyond Ligeralde et al. (2024)? Is there any new scientific insight here, or just an architectural substitution? Do the authors think Transformers are more biologically realistic than CNNs? Please clarify the core claims better. \n\n2. Why are prior models trained on retinal activity (Ligeralde et al., ReWaRD) not compared during evaluation? Do those models fail to show the same effects claimed in the study?\n\n3. How is training for 100 epochs on a small, repeating dataset biologically plausible? Would a single-pass or variable-input setup yield the same outcomes?\n\n4. Do the reported trends (edge → shape → hierarchy) hold at higher image resolutions (e.g., 224×224)? Why not test this with transformer variants like LightViT that can handle larger inputs?\n\n5. Since receptive field size varies with eccentricity, have the authors tested whether similar scaling trends emerge beyond the foveal region?\n\n6. Why does the receptive field analysis use patch tokens instead of the [CLS] token that defines the model’s output? Does this mismatch affect the validity of the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fdXzMEetmC", "forum": "avnKEvJk3O", "replyto": "avnKEvJk3O", "signatures": ["ICLR.cc/2026/Conference/Submission18993/Reviewer_1rmk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18993/Reviewer_1rmk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18993/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933817477, "cdate": 1761933817477, "tmdate": 1762931045945, "mdate": 1762931045945, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "They train a transformer on simulated retinal waves. After training, the transformers develop common organizational patterns with the visual system, namely (1) edge detectors in early layers; (2) shape sensitivity (vs color) in later layers; (3) receptive field size increasing with layer depth."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Original study.\n- Carefully done analyses which support the claims of the study.\n- Clear writing.\n- Results with some significance to the field of neuroscience.\n- Very good literature review."}, "weaknesses": {"value": "- The model is trained with backprop, which limits the biological plausibility of the model. Alternatives have been proposed elsewhere, see e.g., https://openreview.net/forum?id=lQBsLfAWhj\n- In the methods, I have not seen the description of the unsupervised temporal learning method. Please add."}, "questions": {"value": "- Why was the study not including ConvNets as well?\n- Consider citing https://arxiv.org/abs/2103.13023, with analyses and results which bear some resemblance to your work.\n- fig2a: text too small"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Di2l1MjD7p", "forum": "avnKEvJk3O", "replyto": "avnKEvJk3O", "signatures": ["ICLR.cc/2026/Conference/Submission18993/Reviewer_Z8zP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18993/Reviewer_Z8zP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18993/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962050109, "cdate": 1761962050109, "tmdate": 1762931045555, "mdate": 1762931045555, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}