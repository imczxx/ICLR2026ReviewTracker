{"id": "7wbrFQvfdH", "number": 13501, "cdate": 1758218685918, "mdate": 1759897432616, "content": {"title": "Inference-Time Scaling of Discrete Diffusion Models via Importance Weighting and Optimal Proposal Design", "abstract": "Discrete diffusion models have become highly effective across various domains. However, real-world applications often require the generative process to adhere to certain constraints.\nTo this end, we propose a Sequential Monte Carlo (SMC) framework that enables scalable inference-time control of discrete diffusion models through principled importance weighting and optimal proposal construction.\nSpecifically, our approach derives tractable importance weights for a range of intermediate targets and characterises the optimal proposal, for which we develop two practical approximations: a first-order gradient-based approximation and an amortised proposal trained to minimise the log-variance of the importance weights.\nEmpirical results across synthetic tasks, language modelling, biology design, and text-to-image generation demonstrate that our framework enhances controllability and sample quality, highlighting the effectiveness of SMC as a versatile recipe for scaling discrete diffusion models at inference time.", "tldr": "", "keywords": ["discrete diffusion", "test-time scaling", "reward aligntment"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/92d2d3ceff77871b7ec0664316bef3885ca3cdc5.pdf", "supplementary_material": "/attachment/4980f7236eaa7300a3613f7cf57ddd785a0febc8.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a method to fine-tune discrete diffusion models to downstream tasks. More precisely, it aims to sample either from the product of target distributions or reward-tilted distributions. To this end, the authors define an annealing schedule of proposal distributions and run a sequential Monte Carlo algorithm on this annealing schedule. The technical part contains the computation of the importance weights, and the definition and computation (via a certain loss) of the annealing distributions. Finally, the authors apply there methods to examples accross several domains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper is proposes a new fine-tuning method for discrete diffusion models and demonstrate its performance by numerical examples.\n\nBy training the proposal distributions instead of the full sampling kernel the authors circumvent a typical problem of SMC-like methods: They only learn the proposal distributions which avoids sampling an ensemble of particles at training time."}, "weaknesses": {"value": "- Due to the imbalance of modes, SMC is sometimes prone to collapsing modes. Also the figures look a bit like that (in Fig 3 the digits have all a similar rotation, in Fig 13 the fence with the bike has always the same orientation, in Fig 15 the Van Gogh cat always looks towards the viewer (which is not the case for the base model)). A simple way to check this can be to consider the effective sample size before the resampling steps in SMC. I would be curious how it behaves over the iterations.\n\n- The optimization uses the full sampling trajectory of the diffusion model at once resulting in a comparably high computational cost.\n\n- The writing is a bit fuzzy and not very intuitive and not self-contained. The paper is only well readable for people familiar with the SMC literature. Additionally it contains notations like $p(x_{t-1}|x_t, \\mu_\\theta(x_t))$ (line 80). Formally, this does not make sense ($\\mu_\\theta(x_t)$ is $x_t$-measurable for any $\\theta$ such that $p(x_{t-1}|x_t, \\mu_\\theta(x_t))=p(x_{t-1}|x_t)$ independent of $\\theta$). I know what the authors try to say, but this is not what is written there. Also the Algorithms 1/2 are never referenced in the text.\n\n- In the technical part, there is a overlap with the paper https://arxiv.org/abs/2502.04468 (Lemma 4 and Appendix A.1) regarding the computation of importance weights for diffusion models. Also, the overall idea of importance fine-tuning is related. The authors should discuss the connection. Additionally, model-based learning of the transition kernels in SMC were considered in https://arxiv.org/abs/2201.13117\n\n- Typo: line 125/125: is --> its"}, "questions": {"value": "- In order to be effective, SMC requires a comparably large number of samples considered at inference-time. The paper does not mention anything about that. How does the number of samples considered in Alg 2 influence the results?\n\n- In the text-to-image example from the appendix: You train with a batch size of 256? This requires incredible much GPU power. Why is this large batch size required? Compared to the size of the model, the training with 1000 optimization step seems to be pretty small at the same time. What happens if we train longer? Does the model get better or worse?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wjULyUZcTV", "forum": "7wbrFQvfdH", "replyto": "7wbrFQvfdH", "signatures": ["ICLR.cc/2026/Conference/Submission13501/Reviewer_jzG5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13501/Reviewer_jzG5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760954918106, "cdate": 1760954918106, "tmdate": 1762924116870, "mdate": 1762924116870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes:\n\n1. The use of reward-gradient guided proposals and fine-tuned models for sequential Monte Carlo with discrete diffusion models. The authors show that sampling from the reward tilted proposal models for discrete transition kernels can be done via a first order Taylor approximation, as proposed in Grathwohl et al. (2021); Zhang et al. (2022). \n2. An objective to learn locally optimal proposals. Local optimality is defined as the proposal that minimizes the variance of the importance weights. \n\nThe authors show the benefits of their proposed gradient-based kernels and the learned proposal on image, text and DNA sequence design datasets, showing the efficacy of their approach over best of N and SMC without gradients or learned proposals."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper develops two different proposals for SMC for discrete diffusion models. Both proposals are rigorously motivated and are practical to implement, with the empirical results showing the efficacy of both approaches."}, "weaknesses": {"value": "While the underlying results have been known (and cited) in the context of designing proposals for MCMC and discrete generative (Grathwohl et al. (2021); Zhang et al. (2022)). Their use in discrete diffusion is well motivated and shown to produce significant improvements."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BqmUisXjr8", "forum": "7wbrFQvfdH", "replyto": "7wbrFQvfdH", "signatures": ["ICLR.cc/2026/Conference/Submission13501/Reviewer_vdGL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13501/Reviewer_vdGL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761758423161, "cdate": 1761758423161, "tmdate": 1762924116515, "mdate": 1762924116515, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how to perform inference-time control of a pretrained masked diffusion model (MDM), such as sampling from a reward-tilted distribution or sampling from \"product of experts\" (a more general notion of classifier-free guidance). The paper proposed an SMC framework, and discussed several design choices including how to choose the intermediate distributions, the proposal distributions, and light-weighted learning objectives compared to full fine-tuning."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper is well-written and clearly organized, with rigorous mathematical derivations, although some of the notations can be further improved for better clarity. The SMC framework for MDMs is novel and well-motivated. The experiments are also comprehensive, covering various tasks from synthetic toy examples to large scale language, DNA and image generation tasks, and the results demonstrate the effectiveness of the proposed methods. I appreciate the extensive ablation studies and analyses provide, and feel that the paper makes a solid contribution to the field of inference-time scaling of masked diffusion models."}, "weaknesses": {"value": "I don't see any significant weakness, but one way this paper can be further improved is through including inference-time scaling baselines to compare with, which are not presented in the main text. I checked the appendix and found some comparisons with other fine-tuning methods such as DRAKES for the DNA task, but there is no comparison with purely inference-time control methods (e.g., SVDD, arxiv:2408.08252). The authors are encouraged to include such comparisons and report the results, but I understand that it may require significant additional effort and the current results are already quite strong and convincing."}, "questions": {"value": "1. In section 3.3, the authors proposed to approximate $r(x _ t)$ by $\\hat r(x _ t):=\\mathbb{E} _ {p _ \\theta(x _ 0|x _ t)}r(x _ 0)$, as the original $r(x _ t)$ may not be well-defined (e.g., $x _ t$ contains mask states, while $r$ is evaluated on clean sequences). Could the authors explain in more detail how to apply the Gumbel softmax trick in order to compute $\\nabla _ {x _ t}\\hat r(x _ t)$? It's supposed to be discussed in appendix C.2 but I couldn't find the details there. Also, here $p _ \\theta(x _ 0|x _ t)$ is actually one-step denoising, assuming each masked position is sampled independently from the model output, right?\n\n2. In proposition 2, the authors proposed to use the locally optimal proposal for variance reduction of the weights, and train an amortized proposal distribution $q _ \\phi$ through the log-variance loss. Is it possible to visualize the effective sample size of the SMC with and without the learned proposal to demonstrate the performance gain?\n\n\nMinor comments:\n\n1. In line 101-107: it's better to add the superscript $\\star^{(i)}$ to all $x _ t$ and $x _ {t-1}$'s to make it more clear and consistent.\n\n2. In line 112-123: at first glance, I though that the aim is only to sample from the final target distributions $\\pi(x _ 0)\\propto p _ {\\theta _ 1}^\\alpha(x _ 0)p _ {\\theta _ 2}^\\beta(x _ 0)$ and $\\pi(x _ 0)\\propto p _ {\\theta}(x _ 0)\\exp(r(x _ 0))$, and the intermediate distributions are obtained by propagating these final targets through the same forward noising process as in the original MDM. But later I realized that these equations also specify *all* intermediate distributions $\\pi(x _ t)$ along the way that you want your generated trajectories to follow. It would be helpful to clarify this point in the main text to avoid confusion.\n\n3. In equation (7): $\\exp(r(x _ 0))$ should be $\\exp(r(x _ {t-1}))$?\n\n4. In equation (9), the variance and summation should swap their positions? Actually we can directly write in the expectation over $t$ from uniform distribution on $1$ to $T$ so that there will be no $T^2$ term in proposition 3.\n\n5. In proposition 1, the weight does not depend on the backward rate matrix $\\hat R _ t$. I checked the proof and realized that this is because of the assumption on lines 1008-1009, which should be stated in the proposition."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zMyOLOERRL", "forum": "7wbrFQvfdH", "replyto": "7wbrFQvfdH", "signatures": ["ICLR.cc/2026/Conference/Submission13501/Reviewer_rEgU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13501/Reviewer_rEgU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761761811737, "cdate": 1761761811737, "tmdate": 1762924116209, "mdate": 1762924116209, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Based on the motivation from existing work on the inference-time scaling framework of continuous diffusion models, this paper also used the Sequential Monte Carlo (SMC) method to develop an inference-time scaling/control framework of pretrained discrete diffusion models, with a particular focus on reward-tilted sampling (posterior sampling) and classifier-free guidance (CFG). Specifically, tractable importance weights are used throughout the inference process to sample from either reward-tilted or product-of-experts targets with pretrained discrete diffusion models. To avoid possible problems incurred by particle degeneracy, the authors also proposed a way to approximate that the locally optimal proposal that minimizes the variance of the particles' weights. Numerical experiments on synthetic examples, language modeling, biology design and text-to-image generation are provided to justify the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The reviewer finds that the paper is clearly written and explained."}, "weaknesses": {"value": "The reviewer thinks that this paper does have quite a few weaknesses, which are listed below:\n\n(1) Firstly, it seems that the novelty of the SMC-based inference-time scaling framework seems to be quite limited. Specifically, the distribution path (with respect to time time variable $t$) is the same as that of [1], even though the authors did provide a way to justify how the discrete-time formulation proposed in this paper converges to [1] under the continuum limit. Moreover, the idea of variance reduction seems to be the same as that of [2]. In addition, to the best of the reviewer's knowledge, the inference-time scaling of continuous and discrete diffusion models have emerged as a quite hot topic these days, but the current version of the manuscript's literature review section is missing a bunch of related work [3,4,5,6,7,8,9,10,11,12,13,14,20,21] (including works studying the problem of fine-tuning continuous/discrete diffusion models), especially the ones [3,4,6,7,20,21] that developed SMC-based methods for sampling the reward-tilted or product-of-experts targets. Specifically for the setting of discrete diffusion models, the reviewer also note that there exists a few concurrent work [15,16] studying the same topic as this paper. Overall, the quality and positioning of this paper can be possibly improved by citing all work (related and concurrent) above and discussing them appropriately. \n\n(2) Secondly, the reviewer is a bit concerned that there are not enough baselines included in the current version of this paper. In particular, the authors only included 3 methods that are not SMC-based as baselines for large-scale experiments like language modeling, biology design and text-to-image generation. To the best of the reviewer's knowledge, these methods are not state-of-the-art (SOTA) within the class of methods that use only a single particle. For instance, one other more effective methods that the authors might consider including as baselines is the one [8,17] based on Gibbs sampling. \n\n(3) Thirdly, the reviewer finds the theory part presented in the paper to be a bit weak. Just as what has been done in the theoretical part of previous work [18,19] that develops SMC-based methods for diffusion-based sampling, the authors should consider studying what is the final error between the targe distribution (reward-tilted or product-of-experts targets) and the distribution returned by the SMC algorithm by adopting appropriate assumptions (for instance, score matching error)."}, "questions": {"value": "Following (3) discussed in the weaknesses section above, would it be possible for the authors to provide some intuition on how a theoretical analysis for the discrete-time formulation proposed in this paper? Specifically, what might be the analogies of the assumptions and theoretical results in previous work [18,19] for the SMC-based inference-time scaling of discrete diffusion models?\n\nFurthermore, it seems to the reviewer that the approach proposed in subsection 3.2.1 needs to have access to the gradient of the reward function $r$, but sometimes $r$ might not be differentiable. Would it be possible for the authors to come up with a modified version of equation (8) to approximate the optimal proposal in this case?\n\nConclusively speaking, the reviewer thinks that this paper is probably not ready for a top ML venue like ICLR and needs further revision. \n\nReferences:\n\n[1] Lee, Cheuk Kit, Paul Jeha, Jes Frellsen, Pietro Lio, Michael Samuel Albergo, and Francisco Vargas. \"Debiasing guidance for discrete diffusion with sequential monte carlo.\" arXiv preprint arXiv:2502.06079 (2025).\n\n[2] Holderrieth, Peter, Michael S. Albergo, and Tommi Jaakkola. \"LEAPS: A discrete neural sampler via locally equivariant networks.\" arXiv preprint arXiv:2502.10843 (2025). \n\n[3] Trippe, B. L., Yim, J., Tischer, D., Baker, D., Broderick, T., Barzilay, R., & Jaakkola, T. (2022). Diffusion probabilistic modeling of protein backbones in 3d for the motif-scaffolding problem. In The Eleventh International Conference on Learning Representations (ICLR), 2023.\n\n[4] Dou, Z., & Song, Y. (2024). Diffusion posterior sampling for linear inverse problem solving: A filtering perspective. In The Twelfth International Conference on Learning Representations (ICLR), 2024.\n\n[5] Ma, Nanye, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang et al. \"Scaling Inference Time Compute for Diffusion Models.\" In Proceedings of the Computer Vision and Pattern Recognition Conference, pp. 2523-2534. 2025.\n\n[6] Chen, Haoxuan, Yinuo Ren, Martin Renqiang Min, Lexing Ying, and Zachary Izzo. \"Solving inverse problems via diffusion-based priors: An approximation-free ensemble sampling approach.\" arXiv preprint arXiv:2506.03979 (2025).\n\n[7] Yoon, Taehoon, Yunhong Min, Kyeongmin Yeo, and Minhyuk Sung. \"$\\Psi $-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models.\" arXiv preprint arXiv:2506.01320 (2025).\n\n[8] Dang, Meihua, Jiaqi Han, Minkai Xu, Kai Xu, Akash Srivastava, and Stefano Ermon. \"Inference-time scaling of diffusion language models with particle gibbs sampling.\" arXiv preprint arXiv:2507.08390 (2025).\n\n[9] Chen, Tianlang, Minkai Xu, Jure Leskovec, and Stefano Ermon. \"RFG: Test-Time Scaling for Diffusion Large Language Model Reasoning with Reward-Free Guidance.\" arXiv preprint arXiv:2509.25604 (2025).\n\n[10] Ren, Yinuo, Wenhao Gao, Lexing Ying, Grant M. Rotskoff, and Jiequn Han. \"Driftlite: Lightweight drift control for inference-time scaling of diffusion models.\" arXiv preprint arXiv:2509.21655 (2025).\n\n[11] Zhang, Xiangcheng, Haowei Lin, Haotian Ye, James Zou, Jianzhu Ma, Yitao Liang, and Yilun Du. \"Inference-time scaling of diffusion models through classical search.\" arXiv preprint arXiv:2505.23614 (2025).\n\n[12] Jain, Vineet, Kusha Sareen, Mohammad Pedramfar, and Siamak Ravanbakhsh. \"Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models.\" arXiv preprint arXiv:2506.20701 (2025).\n\n[13] Ramesh, Vignav, and Morteza Mardani. \"Test-Time Scaling of Diffusion Models via Noise Trajectory Search.\" arXiv preprint arXiv:2506.03164 (2025).\n\n[14] Tang, Sophia, Yuchen Zhu, Molei Tao, and Pranam Chatterjee. \"TR2-D2: Tree Search Guided Trajectory-Aware Fine-Tuning for Discrete Diffusion.\" arXiv preprint arXiv:2509.25171 (2025).\n\n[15] Hasan, Mohsin, Marta Skreta, Alan Aspuru-Guzik, Yoshua Bengio, and Kirill Neklyudov. \"Discrete feynman-kac correctors.\" In 2nd AI for Math Workshop@ ICML 2025. 2025.\n\n[16] Rout, Litu, Andreas Lugmayr, Yasamin Jafarian, Srivatsan Varadharajan, Constantine Caramanis, Sanjay Shakkottai, and Ira Kemelmacher-Shlizerman. \"Test-Time Anchoring for Discrete Diffusion Posterior Sampling.\" arXiv preprint arXiv:2510.02291 (2025).\n\n[17] Chu, Wenda, Zihui Wu, Yifan Chen, Yang Song, and Yisong Yue. \"Split gibbs discrete diffusion posterior sampling.\" arXiv preprint arXiv:2503.01161 (2025).\n\n[18] Wu, Luhuan, Brian Trippe, Christian Naesseth, David Blei, and John P. Cunningham. \"Practical and asymptotically exact conditional sampling in diffusion models.\" Advances in Neural Information Processing Systems 36 (2023): 31372-31403.\n\n[19] Cardoso, Gabriel, Yazid Janati El Idrissi, Sylvain Le Corff, and Eric Moulines. \"Monte Carlo guided diffusion for Bayesian linear inverse problems.\" arXiv preprint arXiv:2308.07983 (2023).\n\n[20] He, Jiajun, José Miguel Hernández-Lobato, Yuanqi Du, and Francisco Vargas. \"RNE: a plug-and-play framework for diffusion density estimation and inference-time control.\" arXiv preprint arXiv:2506.05668 (2025).\n\n[21] He, Jiajun, Paul Jeha, Peter Potaptchik, Leo Zhang, José Miguel Hernández-Lobato, Yuanqi Du, Saifuddin Syed, and Francisco Vargas. \"CREPE: Controlling Diffusion with Replica Exchange.\" arXiv preprint arXiv:2509.23265 (2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "keSpYvdMOx", "forum": "7wbrFQvfdH", "replyto": "7wbrFQvfdH", "signatures": ["ICLR.cc/2026/Conference/Submission13501/Reviewer_MEfE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13501/Reviewer_MEfE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762155691376, "cdate": 1762155691376, "tmdate": 1762924115930, "mdate": 1762924115930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}