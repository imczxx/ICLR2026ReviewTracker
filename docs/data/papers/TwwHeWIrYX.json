{"id": "TwwHeWIrYX", "number": 4598, "cdate": 1757722110731, "mdate": 1759898024030, "content": {"title": "When Machines Write: A method for detecting AI-edited text", "abstract": "Existing AI-text detectors have reported a great success in detecting AI-generated content created by text completion and question answering. We consider a more challenging problem---distinguishing between human-written content and human-written, AI-edited content (hwAI-generated text), in which the signals are weaker and existing methods are less satisfying. We propose {\\it word-list-assisted prompting} as a new method. It is based on two empirical observations: (i) Word-count features, despite being sparse, are powerful in detecting hwAI-generated text. (ii) The direct prompting approach, though conventionally not recommended, becomes effective after being supplied a selected word list in the prompt. To this end, we develop two feature selection methods, leveraging the advancement in large-scale multiple testing and topic modeling. Our prompting approach, powered by these feature selection methods, achieves appealing performance in detecting hwAI-generated text in several data sets containing academic abstracts, movie reviews, and news.", "tldr": "We introduce a new method for detecting AI-edited text. It combines sparse feature selection with prompting.", "keywords": ["Higher Criticism; prompt; Topic-SCORE; authorship attribution"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e12873652b2a8a8163fdc6dde923388d51249faa.pdf", "supplementary_material": "/attachment/5ea1cd6c2bdb2d8b08def5a5d2e9dc9a94bee0cd.pdf"}, "replies": [{"content": {"summary": {"value": "This paper introduces a prompt-based method for detecting AI-edited texts. It first selects word list critical to detection from the training set and prompt the LLM with this additional information for detection."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The task of detecting AI-edited texts is challenging.\n\n2. The proposed method is relatively efficient compared with methods that require extensive training."}, "weaknesses": {"value": "1. My concern about this paper is its assumption that most editing by AI is word replacement. I believe how AI edits texts depends on the instructions instead of its inner mechanism. I find the prompt for editing used in this work is \"Given the following abstract, make some revisions. Make sure not to change the length too much.\" (line 348-349). I think \"make some revisions\" is not a normal instruction for editing in real life. Therefore, I question if the proposed method would generalize to different editing instructions that are practical in real-world applications. \n\n2. The definition of \"AI-edited text\" is not clear. For example, if the text contains three paragraphs and you only ask the AI to edit one of them, would you call the whole text \"AI-edited\"? I suppose the core problem in such a question is to conduct fine-grained detection instead of giving an overall judgement about the whole text.\n\n3. As a safety-related work, more analysis about the robustness of the proposed method should be condecuted."}, "questions": {"value": "See the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Nrp72j7Mpa", "forum": "TwwHeWIrYX", "replyto": "TwwHeWIrYX", "signatures": ["ICLR.cc/2026/Conference/Submission4598/Reviewer_o5dF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4598/Reviewer_o5dF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761313291514, "cdate": 1761313291514, "tmdate": 1762917462932, "mdate": 1762917462932, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a more challenging detection problem, distinguishing between purely human-written text and human-written but AI-edited text (called as hwAI text), where conventional AI detectors often fail due to weaker signals. The authors propose a word-list-assisted prompting approach that enhances prompt-based detection using carefully selected discriminative words. They first observe that simple word-count features remain surprisingly effective for identifying hwAI text, and that prompting can achieve strong results when augmented with such word lists. To construct these lists, they introduce two feature selection methods grounded in large-scale multiple testing and topic modeling. Experiments across diverse domains demonstrate that the proposed method achieves strong and consistent performance in detecting AI-edited texts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Propose a new detection approach via a simple prompting with an optimized word list to discern human-written and human-edited-by-AI texts\n- Thorough evaluations across multiple detectors and recent generators"}, "weaknesses": {"value": "- **Lack of justification for prompting approach:** The paper claims that prompt-based methods consistently outperform simple linear classifiers with the curated word list (L131), yet no numerical comparison is provided in the main results (Table 1). Without such evidence, the necessity of using prompts over linear classifiers remains unclear.\n- **Missing evaluation on core detection task:** While distinguishing human vs. human-edited-by-AI texts is valuable, it is not shown whether the method can still detect human vs. machine-generated texts, which is the original and simpler task. The absence of this verification raises concerns about effectiveness of the proposed method.\n- **Limited robustness analysis:** Despite claiming that discrete word lists prevent overfitting (L084), the work does not evaluate robustness against paraphrasing or adversarial perturbations, where such discrete cues are likely fragile.\n- **Limited cross-(domain | model) detection evaluation:** Cross-domain results are presented but with only one baseline (Binoculars, zero-shot detector), making its robustness questionable. Likewise, there is no cross-model evaluation (e.g., testing on GPT-4o-mini edits with word lists from Gemini-1.5-Flash edits), which is essential given that the editing model is the key factor in this task.\n- **Too simple edit prompt setting:** The paper observes that AI edits are mostly word replacements (L085), but this may depend heavily on the edit instruction. Indeed, the prompt in L348 (“Given the following abstract, make some revisions. Make sure not to change the length too much.”) is overly simple and does not reflect real-world editing intents such as improving readability or persuasiveness. This raises the questionable effectiveness of the proposed method in real-world scenarios, where people use more diverse prompting for AI edits.\n- **Missing reference to relevant prior work:** The study does not refer to a prior work [1] first demonstrating that prompting LLMs can be an effective detection via in-context learning with retrieved similar texts, which should be discussed for a fair contextualization of the proposed approach.\n\n---\n\nReferences:\n\n[1] Koike et al. OUTFOX: LLM-Generated Essay Detection Through In-Context Learning with Adversarially Generated Examples. AAAI 2024."}, "questions": {"value": "See the weaknesses part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bTZQf5rKjA", "forum": "TwwHeWIrYX", "replyto": "TwwHeWIrYX", "signatures": ["ICLR.cc/2026/Conference/Submission4598/Reviewer_8EF1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4598/Reviewer_8EF1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761570903009, "cdate": 1761570903009, "tmdate": 1762917462685, "mdate": 1762917462685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles detecting human-written, AI-edited text (hwAI) -- a harder setting than pure AI generation because signals are weaker. It proposes word-list-assisted prompting: select a sparse, signed vocabulary via multiple-testing (Higher Criticism) and topic-modeling, then include that list in the LLM prompt for hwAI detection."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "**Mathematically principled feature selection:** They model per-word counts as Poisson, compute z-scores and p-values, then pick a tuning-free threshold via Higher Criticism -- with a p-value justification -- and sign words by the z-score, yielding an interpretable lexicon for rare/weak signals."}, "weaknesses": {"value": "1. Weak Contribution: The authors evaluate detection only for HW-text vs. hwAI-text, not AI-text vs. AIhw-text. Moreover, prior work has already highlighted this problem.\n\n2. Relevant Works Missing: There are existing studies on detecting AI-rewritten/AI-polished texts (e.g., [1, 2, 3]). The authors should clarify their positioning relative to these and evaluate on benchmarks like APT-Eval [1] and MixSet [2], and include RoBERTa-HPPT [3] as a baseline.\n\n3. Strong Assumption: Authors assume edits are largely word replacements and count “natural words” without stemming/lemmatization, which can bias toward topical/style cues.\n\n4. Baselines Missing: Stronger methods like RADAR [4], and commercial methods should be included to make the experiment rigorous. \n\n5. Presentation Issues: The presentation could be better, e.g., there are repetitive texts all over the paper, missing any discussion or conclusion, etc.\n\n\n\nReferences:\n\n[1] Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing\n\n[2] LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase\n\n[3] IS CHATGPT INVOLVED IN TEXTS? MEASURE THE POLISH RATIO TO DETECT CHATGPT-GENERATED TEXT\n\n[4] RADAR: Robust AI-Text Detection via Adversarial Learning"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U3drmZDytY", "forum": "TwwHeWIrYX", "replyto": "TwwHeWIrYX", "signatures": ["ICLR.cc/2026/Conference/Submission4598/Reviewer_pbLK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4598/Reviewer_pbLK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965502169, "cdate": 1761965502169, "tmdate": 1762917462459, "mdate": 1762917462459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for AI generated text detection, for a novel problem setting which is to distinguish human-written content and human-written, AI-edited content (hwAI-generated text)."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a novel setting in the context of AI-generated text detection. Departing from existing frameworks that focus on distinguishing AI-generated text from human-written text, this new setup is refreshing and has potential for further exploration. The paper is overall well-written and easy to follow."}, "weaknesses": {"value": "My first concern is about the justification of the new problem, namely distinguishing between AI-generated, human-rewritten, and AI-modified text. While I find the deviation from the traditional setup interesting, I am not sure what the potential use cases for this problem would be. Ideally, we would want to identify AI-generated text that has been modified by humans. I would appreciate it if the authors could provide concrete use cases to better justify this novel problem formulation.\n\nMoreover, the proposed framework in the paper is based on prompt engineering, making it not robust and heavily dependent on prompt design. In addition, as part of the proposed method, the paper empirically curates a list of discriminative words; however, it remains unclear how accurate or comprehensive this list is without further justification or supporting evidence."}, "questions": {"value": "Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KY2q6E3dHk", "forum": "TwwHeWIrYX", "replyto": "TwwHeWIrYX", "signatures": ["ICLR.cc/2026/Conference/Submission4598/Reviewer_wVVJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4598/Reviewer_wVVJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762024590581, "cdate": 1762024590581, "tmdate": 1762917462071, "mdate": 1762917462071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}