{"id": "DmhbGdwIkr", "number": 10206, "cdate": 1758163879872, "mdate": 1759897666838, "content": {"title": "Strengthen Out-of-Distribution Detection with Uncertainty-Driven Adaptively Rectified Backpropagation", "abstract": "Out-of-distribution (OOD) detection aims to ensure AI system reliability by detecting inputs outside the training distribution. Recent work shows that overfitting during later stages of training can hurt OOD detection. To overcome overfitting, several methods attempt to distill the model after training or prune the model during training from a model-centric perspective. In contrast, this paper proposes a data-centric end-to-end solution called Uncertainty-driven Adaptively Rectified Backpropagation (UARB), which follows the principle that once the model has mastered an instance, training on it should stop to prevent overfitting. UARB considers an instance mastered if the zero-order and second-order differences of its uncertainty value remain within a small range around zero, offering a more consistent measure of an instance’s learning status. Additionally, since different classes exhibit varying optimization progress, using a fixed threshold to determine when to exclude an instance from backpropagation is theoretically unsound. UARB develops an adaptive threshold by incorporating class-informed statistics to determine when to exclude an instance. Extensive experiments demonstrate that UARB can enhance OOD detection performance.", "tldr": "We propose Adaptively Rectified Backpropagation (ARB), is a data-centric approach that prevents overfitting for OOD detection.", "keywords": ["Out-of-distribution detection", "Uncertainty"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/63ba9d74aa96597e23cd8b6c64584929c3aff44f.pdf", "supplementary_material": "/attachment/09306d9b7201ef300e76478c4a7e96bf439d1eac.zip"}, "replies": [{"content": {"summary": {"value": "This study aims to mitigate overfitting and the consequent decline in OOD detection performance by dynamically excluding samples that the model has already mastered during training. To this end, the authors propose a novel uncertainty-based adaptive data selection strategy UARB, which leverages both zeroth- and second-order uncertainty measures and introduces class-level thresholds as data selection criteria. Comprehensive experiments conducted on both small- and large-scale datasets include evaluations in both far-OOD and near-OOD scenarios, as well as compatibility tests with a wide range of existing methods, consistently demonstrating promising performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**Originality:**\nUnlike prior methods such as UM, which mitigate overfitting to improve OOD detection performance by performing gradient ascent on the loss over an entire batch of samples, UARB addresses overfitting at a finer, more granular level. Additionally, UARB overcomes the limitation of UM’s reliance on pretrained models, enabling direct end-to-end training.\n\n**Quality:**\nThe paper is generally a good paper with a clear central idea.\n\n**Clarity:**\nThe organization of the paper is good and it is easy to follow the topic and the proposed algorithms.\n\n**Performance:** \nExtensive and comprehensive experiments validate the effectiveness of UARB, demonstrating promising improvements in OOD detection performance from a data-centric perspective."}, "weaknesses": {"value": "1. In the introduction, it would be helpful to clarify why overfitting to the training data leads to a decline in OOD detection performance. The current manuscript may be somewhat difficult to follow for readers who are not familiar with the related work.\n\n2. Although the overall presentation is clear, several minor issues need to be addressed. For example, the purpose of the green dashed line in Figure 1 is somewhat unclear; an extra parenthesis appears in line 354; since OOD detection has already been abbreviated earlier, it may not be necessary to repeat the full term to avoid redundancy; and the captions of Tables 7 and 8 could be revised to more accurately reflect the experimental content.\n\n3. It has not been analyzed whether the decline in OOD detection performance in the later stages of training is fully mitigated after applying the UARB training strategy."}, "questions": {"value": "Could you further analyze whether the hyperparameter settings are sensitive to the dataset, or if they are related to the learning difficulty of the dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7HFxtApRkF", "forum": "DmhbGdwIkr", "replyto": "DmhbGdwIkr", "signatures": ["ICLR.cc/2026/Conference/Submission10206/Reviewer_EbRE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10206/Reviewer_EbRE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760870449874, "cdate": 1760870449874, "tmdate": 1762921567612, "mdate": 1762921567612, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the performance degradation in the late training stage due to overfitting on mastered in-distribution samples. The authors propose a data-centric end-to-end framework UARB that identifies mastered samples and then implements instance-level early stopping by excluding mastered samples from backpropagation. Experiments on CIFAR-10/100 and ImageNet show UARB improves OOD detection when combined with baselines like MSP, Energy, and KNN."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Unlike model-centric methods that treat symptoms of overfitting, UARB dynamically filters training data, which aligning with the growing focus on data quality in OOD detection.  \n- By integrating class-wise uncertainty variance, UARB balances training of easy and hard classes."}, "weaknesses": {"value": "- Most experimental improvements are margin, as can be observed in the tables, especially on ImageNet dataset. Such gains are insufficient to justify the added complexity over simpler baselines.  \n- The paper claims UARB mitigates overfitting but there is no direct visualization of overfitting, which is critical to validate its core mechanism.  \n- Experiments only use ResNet-18, a lightweight but outdated architecture. Modern OOD detection increasingly relies on transformers (e.g., ViT, Swin Transformer) or pre-trained models. UARB’s effectiveness on these architectures is unproven, limiting its practical relevance.  \n- UARB adds non-trivial computations, e.g., second-order difference across epochs, class-wise variance calculation, but provides no analysis of computational cost compared to baselines. For resource-constrained edge devices, this omission makes it impossible to assess practicality.  \n- The paper relies entirely on experimental results. There is no theoretical guarantees for the proposed method."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7y4G4hnnL4", "forum": "DmhbGdwIkr", "replyto": "DmhbGdwIkr", "signatures": ["ICLR.cc/2026/Conference/Submission10206/Reviewer_LZKj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10206/Reviewer_LZKj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913605138, "cdate": 1761913605138, "tmdate": 1762921567183, "mdate": 1762921567183, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Overfitting during the training phase can significantly degrade OOD detection performance. This paper addresses this issue by proposing Uncertainty-driven Adaptively Rectified Backpropagation (UARB), which mitigates overfitting by blocking the backpropagation of mastered instances. The authors first demonstrate that OOD detection performance declines in the later stages of training due to overfitting. To alleviate this, they propose UARB, which leverages uncertainty to estimate the degree of learning for each instance and selectively stops training for sufficiently learned samples. Furthermore, they highlight the issue of class imbalance during training and introduce an adaptive threshold mechanism, which employs both the uncertainty and its second-order difference to dynamically balance per-class thresholds when identifying mastered instances. Extensive experiments across various datasets and OOD detection scenarios demonstrate the effectiveness and generality of their method compared with UM."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. UARB is a plug-and-play method with strong applicability to various existing OOD detection approaches.\n2. The problem of overfitting is clearly demonstrated through experimental evidence (as shown in Figure 1).\n3. The motivation behind using uncertainty, the second-order difference, and the adaptive threshold mechanism is clearly explained.\n4. UARB clearly outperforms UM, the most relevant prior approach, across multiple benchmarks."}, "weaknesses": {"value": "1. In Section 2.2, the authors mention that they empirically verify the increase in instances that meet the mastered criteria. However, no corresponding experimental results are presented in the paper.\n2. The authors argue that using a fixed threshold to determine when to exclude an instance from backpropagation is theoretically unsound, yet no further explanation or theoretical analysis is provided. I encourage the authors to elaborate on this point with more detailed justification.\n3. UARB requires tracking the uncertainty across three consecutive epochs for the entire training dataset, which introduces substantial computational and memory overhead — especially as the dataset size and model complexity increase.\n4. Although this paper mainly focuses on OOD detection during the training phase, it omits discussion of more recent and powerful OOD detection methods, such as DICE [1] and LINe [2].\n5. While variance normalization can provide certain benefits, it assumes that all classes are generally imbalanced. In early training stages or fine-grained datasets where class-wise variation is minimal, this assumption may instead lead to adverse effects.\n6. I recommend that the authors revise the full manuscript to improve readability and completeness.\n- In the Introduction, some expressions (e.g., mastered instance, data-level issue) are difficult to understand immediately.\n- Minor typos:\n Line 269: scenatios → scenarios\n Line 411: Table → Equation\n- In the main manuscript, Table 7 is not referenced or used.\n\n[1] \"Dice: Leveraging sparsification for out-of-distribution detection.\" ECCV 2022.\\\n[2] \"LINe: Out-of-distribution detection by leveraging important neurons.\" CVPR 2023."}, "questions": {"value": "1. Extending from the concern about computational cost, I am curious about the applicability of the proposed method to larger backbones, such as ResNet-50 or ViT.\n2. UARB utilizes both uncertainty and the second-order difference. Could the authors clarify why the first-order difference was not considered in their formulation? (or provide some experimental results).\n3. Since UARB uses uncertainty from three consecutive epochs to compute the second-order difference, I recommend conducting an ablation study on this hyperparameter to analyze its sensitivity and impact."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HWUA2k3SgK", "forum": "DmhbGdwIkr", "replyto": "DmhbGdwIkr", "signatures": ["ICLR.cc/2026/Conference/Submission10206/Reviewer_PAyv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10206/Reviewer_PAyv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960605598, "cdate": 1761960605598, "tmdate": 1762921566851, "mdate": 1762921566851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose Uncertainty‑driven Adaptively Rectified Backpropagation (UARB) to improve OOD detection performance of classification models. The motivation is that there is an issue that during training the model may over-fit to ID instances in later epochs, thereby degrading its ability to distinguish OOD. The authors monitor the uncertainty score (zero-order) and the second-order difference of uncertainty (roughly the change in change) over epochs. If both fall below thresholds, they declare the instance mastered. Once an instance is marked mastered, they exclude it from further back-propagation so as to prevent over-training on that sample and reduce over-fitting. They use class-informed statistics to derive adaptive thresholds for mastering each class. They report experiments showing improved OOD detection across benchmarks when using UARB compared with baseline training."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The observation that OOD detection performance can decline during later training epochs is important and less emphasized in many OOD works.\n- Intervening in the training loop is a novel angle for OOD detection.\n- By recognizing that different classes converge at different rates, the authors design class-specific thresholds."}, "weaknesses": {"value": "- The methodology relies heavily on an uncertainty score per instance and its second-order difference across epochs. But the paper is somewhat light on which uncertainty metric is used. How sensitive results are to this choice, and how robustly it correlates with mastery.\n- Is the second order difference stable and sufficiently noise-free to reliably identify mastered instances? How does noise in uncertainty estimates affect the criteria?\n- The details of how the class-specific thresholds are computed are relatively brief. How sensitive are results to the thresholds\n- By excluding mastered samples from further training, the method effectively reduces the effective training set size and focuses training on harder instances. While this may reduce over-fitting, it could potentially under-fit some classes or lead to class imbalance issues. Is there analysis of whether ID classification accuracy or calibration suffers?\n- It would be great to add the following ablation studies. \n1. the effect of using only zero-order vs. also second-order difference\n2. fixed threshold vs adaptive threshold;\n3. baseline training without UARB but with same number of epochs/training budget."}, "questions": {"value": "- It would be great to add discussion on uncertainty metrics (entropy, MSP, and loss) and show how the criteria for mastery behaves under each.\n- It would be great to include sensitivity analyses on δ₁, δ₂ and show robustness of performance\n- It would be great to add experiments on more diverse datasets and OOD types including near-OOD/far-OOD\n- It should report the impact on primary classification task metrics (ID accuracy, calibration, robustness)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UFjPxklyw9", "forum": "DmhbGdwIkr", "replyto": "DmhbGdwIkr", "signatures": ["ICLR.cc/2026/Conference/Submission10206/Reviewer_LSjt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10206/Reviewer_LSjt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973650428, "cdate": 1761973650428, "tmdate": 1762921566449, "mdate": 1762921566449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}