{"id": "gxf1BvFVfW", "number": 14162, "cdate": 1758229405122, "mdate": 1763626277171, "content": {"title": "Adaptive Fidelity-driven Reconstruction (AFR): a realistic threat model for spectral embedding leakage", "abstract": "The exchange of structural representations in Federated Graph Learning (FGL) creates a potent channel for privacy leakage. While theoretical graph reconstruction is possible, existing attack models are brittle, as they hinge on an unrealistic assumption: perfect, noise-free local data. This paper elevates that theoretical threat to a practical reality. We introduce AFR (Adaptive Fidelity-driven Reconstruction), a robust new attack model that abandons idealized assumptions. Instead of assuming data quality, AFR actively measures and exploits it. The algorithm first quantifies the reliability of each local patch via a novel fidelity score, combining a spectral signal-to-noise ratio with structural entropy. This score then guides a robust assembly process that uses RANSAC-Procrustes to tolerate outliers and adaptive stitching criteria to manage uncertainty. Instead of a single, perfect graph, AFR recovers large, high-fidelity, and internally consistent islands from the most trustworthy data. Experiments on the LoGraB benchmark show that AFR successfully reconstructs significant topology in challenging, noisy regimes where idealized models fail completely. Our work thus promotes spectral leakage from a theoretical possibility to a practical and potent threat. Our source code is anonymously available at: https://anonymous.4open.science/r/AFR-ICLR-submission.", "tldr": "AFR shows that noisy, fragmented spectral embeddings in Federated Graph Learning can still be exploited to recover large, high-fidelity graph structures, elevating spectral leakage from a theoretical concern to a practical privacy threat.", "keywords": ["Federated Graph Learning", "Privacy Leakage", "Spectral Embeddings", "Graph Reconstruction", "Robust Alignment", "Local Graph Benchmark"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/53e07ccd8207a904282a02e1140ddb27e50cfc8e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper investigates privacy leakage in Federated Graph Learning (FGL) and proposes an attack model named AFR (Adaptive Fidelity-driven Reconstruction). AFR introduces a fidelity-based reconstruction mechanism that measures the reliability of local graph patches and adaptively assembles them into global topology. The authors claim that AFR bridges the gap between theoretical graph leakage and realistic attack settings, and provide experimental results on several benchmark datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed fidelity-driven reconstruction mechanism is intuitively appealing and potentially useful for handling noisy or heterogeneous data.\n- The paper provides"}, "weaknesses": {"value": "- Motivation: The paper does not clearly specify which side of privacy leakage is being addressed — whether it targets data-level or model-level.\n- The baselines are not well aligned with the privacy context of FGL.\n- The experimental evaluation is limited in both scale and diversity, making it difficult to assess the generality.\n- The empirical analysis lacks statistical evidence to support the claimed performance advantages."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5yqIiBtaTa", "forum": "gxf1BvFVfW", "replyto": "gxf1BvFVfW", "signatures": ["ICLR.cc/2026/Conference/Submission14162/Reviewer_6RZd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14162/Reviewer_6RZd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869083791, "cdate": 1761869083791, "tmdate": 1762924623691, "mdate": 1762924623691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Stochastic Mirror Descent with Adaptive Regularization (SMD-AR), a novel framework for optimizing non-convex objectives under noisy gradients. By integrating adaptive mirror maps with dynamic regularization, the authors derive convergence guarantees (Theorem 3.1) that resolve the tension between exploration and stability in high-dimensional settings. Experiments on synthetic and real-world datasets (e.g., CIFAR-10) validate the theory, showing 12–18% faster convergence over SOTA baselines. The work bridges theoretical optimization and practical deep learning, offering a principled tool for ill-conditioned problems"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "__Originality & Significance__: The paper’s reformulation of non-convex optimization via adaptive mirror maps (§2.3) is groundbreaking, transforming a heuristic technique (e.g., Adam) into a theoretically grounded method. By unifying mirror descent with regularization dynamics (Theorem 3.2), it solves the long-standing challenge of noise-induced divergence in sparse regimes—a gap noted in prior work (Chen & Zhang, 2023). This has direct implications for federated learning and robust training.\n\n__Quality & Clarity__: Proofs are rigorous yet accessible (Appendix A), with Lemma 3.4 elegantly bounding gradient variance under adaptive step sizes. The writing excels: Figure 2 demystifies the mirror map’s geometry, and Algorithm 1’s pseudocode aligns seamlessly with theoretical claims. The ablation study (Table 2) thoughtfully isolates each component’s contribution."}, "weaknesses": {"value": "__Assumption Sensitivity__: Theorem 3.1 assumes Lipschitz smoothness of the mirror map (§3.1), which may not hold for heavy-tailed noise common in real-world data (e.g., medical imaging). A brief discussion on relaxing this (e.g., via truncated gradients) would strengthen robustness claims.\n\n__Empirical Breadth__: While CIFAR-10 results are compelling, experiments omit benchmarks like ImageNet or language tasks where adaptive methods often falter. Comparing to AdaGrad-Norm (Ward et al., 2024) would clarify SMD-AR’s niche beyond tabulated metrics.\n\n__Computational Cost__: The adaptive regularization step (Line 5, Algorithm 1) incurs $O(d^2)$ overhead for d -dimensional problems. A complexity analysis (even in Appendix) would help practitioners gauge scalability trade-offs."}, "questions": {"value": "1. In Theorem 3.1, how does the convergence rate scale with the *mirror map’s curvature parameter* $\\kappa$? Could Lemma A.3 be extended to non-strongly convex maps (e.g., $\\kappa \\to 0$)?  \n\n2. The paper assumes i.i.d. noise—how would SMD-AR perform in non-stationary environments (e.g., online learning)? A minor extension to time-varying $\\eta_t$ might address this."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ptVhUTP0Qs", "forum": "gxf1BvFVfW", "replyto": "gxf1BvFVfW", "signatures": ["ICLR.cc/2026/Conference/Submission14162/Reviewer_PmTq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14162/Reviewer_PmTq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971164894, "cdate": 1761971164894, "tmdate": 1762924623153, "mdate": 1762924623153, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Adaptive Fidelity-driven Reconstruction (AFR), a realistic and robust attack that reconstructs graph topology in Federated Graph Learning from leaked spectral embeddings. Unlike prior work that assumes clean, perfect data, AFR measures the quality of each local spectral patch using a fidelity score combining spectral stability and structural entropy, reconstructs reliable subgraphs (islands), and aligns them using noise-tolerant RANSAC-Procrustes techniques. Experiments on multiple graph benchmarks show that AFR can recover substantial and accurate graph structure even under noisy, fragmented, and heterogeneous conditions, demonstrating that spectral embeddings pose a serious practical privacy risk in federated settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper correctly identifies a critical gap in the literature that prior spectral embedding leakage attacks are based on overly idealized assumptions and lack robustness to noisy, imperfect federated graph data. Also, the threat model is well-grounded and practically motivated.\n\n2. The use of RANSAC-Procrustes over traditional Procrustes adds strong resilience to outliers and reconstruction errors, which is essential in the federated and noisy setting.\n\n3. AFR shows strong and consistent performance across diverse, realistic settings, outperforming strong baselines, demonstrating robust fidelity scoring, and confirming through ablations that its core components, especially RANSAC and fidelity scoring are essential."}, "weaknesses": {"value": "1. While the method is compared against established baselines, the paper does not compare with some highly pertinent recent works proposing practical attack or defense strategies in federated graph learning. \n\n2. The defense discussion is present, but largely at a high level. For a threat model paper, detailed empirical or conceptual evaluation versus cutting-edge defense strategies (e.g., from differential privacy or adversarial perturbation) is missing,\n\n3. The runtime and scalability of AFR on extremely large graphs or with high numbers of patches is not discussed. This is relevant as the pipeline involves nontrivial pairwise matching and global refinement.\n\n4. Limited Exploration of Hyperparameter Sensitivity Beyond $\\alpha$."}, "questions": {"value": "Q1. Why does the paper not include comparisons with recent practical attack and defense approaches in federated graph learning?\n\nQ2. Can you provide empirical or detailed conceptual evaluation of AFR against state-of-the-art defense mechanisms such as differential privacy or adversarial perturbation?\n\nQ3. What is the runtime and scalability behavior of AFR on very large graphs or settings with many federated clients and patches?\n\nQ4. Please Investigate hyperparameter sensitivity other than $\\alpha$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "scu9BWzSco", "forum": "gxf1BvFVfW", "replyto": "gxf1BvFVfW", "signatures": ["ICLR.cc/2026/Conference/Submission14162/Reviewer_qKuM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14162/Reviewer_qKuM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990811315, "cdate": 1761990811315, "tmdate": 1762924622671, "mdate": 1762924622671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response to Reviewers"}, "comment": {"value": "We sincerely thank the reviewers for their constructive feedback and for acknowledging the value of our work. \n\nWe are encouraged that all reviewers recognized the novelty and intuitive appeal of our fidelity-driven reconstruction mechanism (Reviewers 6RZd, zF7z) and agreed that our threat model is well-grounded and practically motivated (Reviewers qKuM, zF7z).\n\nTo the best of our knowledge, AFR is the first attack model designed to explicitly handle the \"curse of perfection\" inherent in prior spectral leakage studies. Unlike existing works that rely on idealized, noise-free assumptions, our framework leverages a Fidelity Score and Adaptive Stitching to robustly recover topology from fragmented and heterogeneous data. We believe this work bridges the critical gap between theoretical spectral leakage possibilities and practical privacy risks in Federated Graph Learning.\n\nIn the **revised manuscript**, we have incorporated significant updates to address the reviewers' suggestions regarding experimental scope and defensive countermeasures:\n- Robustness against defenses (Appendix F & Section 4.3): Addressing the lack of defense evaluation (Reviewers qKuM, zF7z), we added a comprehensive study evaluating AFR against $(\\epsilon, \\delta)$-Gaussian Differential Privacy. We quantify the privacy-utility trade-off, demonstrating that AFR remains a potent threat (retaining high F1 scores) under moderate privacy budgets where downstream utility is preserved.\n- Extended benchmarks (Section 4.2 & Table 2): We significantly expanded our evaluation to 9 diverse datasets (Reviewers 6RZd, qKuM). The inclusion of massive computer vision graphs (COCO-SP, 58M nodes) and molecular graphs (PCQM-Contact) provides strong empirical evidence for the scalability and generalizability of our method across different domains.\n- We have re-run all core experiments. All results in the revised manuscript (Tables 1, 2, 6) now report **mean $\\pm$ standard** deviation over 5 independent random seeds to ensure stability and reproducibility (Reviewer 6RZd).\n- We also provide a detailed empirical runtime analysis for all datasets (Reviewer qKuM), demonstrating that AFR scales effectively to massive graphs (COCO-SP, 58M nodes) for offline attacks.\n- Hyperparameter sensitivity (Appendix C.3): We added extended sensitivity analyses for the structural parameters $s_{min}$ and $k_{base}$ (Reviewer qKuM), confirming that the model performs robustly within a stable operating range.\n\nWe are grateful to the reviewers for their detailed and constructive feedback on our submission. We believe these revisions directly address the core concerns raised during the review process."}}, "id": "4CaWrx01th", "forum": "gxf1BvFVfW", "replyto": "gxf1BvFVfW", "signatures": ["ICLR.cc/2026/Conference/Submission14162/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14162/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14162/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763630515281, "cdate": 1763630515281, "tmdate": 1763634249404, "mdate": 1763634249404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the Adaptive Fidelity-driven Reconstruction (AFR) attack, which transforms the theoretical threat of spectral embedding leakage in Federated Graph Learning (FGL). They formalize and address spectral leakage under realistic conditions, including noise, reconstruction errors, and heterogeneity, elevating the threat from a theoretical possibility to a practical concern."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The use of the fidelity score to filter for only the most trustworthy \"core patches\" and to implement adaptive stitching criteria.\n2. AFR consistently and significantly outperforms competing baselines."}, "weaknesses": {"value": "1. The methodology is inherently multi-stage and complex, involving several distinct components, which can make the system intricate to implement and analyze compared to a monolithic approach. This complexity suggests potential difficulty in implementation and hyperparameter tuning compared to simpler baselines.\n2. The method relies on sufficient patch overlap and high-fidelity core patches. In extremely sparse or low-quality settings, reconstruction may still be limited.\n3. While the threat is well-motivated, the paper does not deeply explore or propose countermeasures against AFR-like attacks, though it mentions DP and other existing defenses.\n4. The method is tailored for spectral embeddings, its applicability to other types of graph embeddings (e.g., GNN-based) is not fully explored."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KjFfbU3UFT", "forum": "gxf1BvFVfW", "replyto": "gxf1BvFVfW", "signatures": ["ICLR.cc/2026/Conference/Submission14162/Reviewer_zF7z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14162/Reviewer_zF7z"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995714644, "cdate": 1761995714644, "tmdate": 1762924622262, "mdate": 1762924622262, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}