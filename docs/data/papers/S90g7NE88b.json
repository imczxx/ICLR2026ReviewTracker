{"id": "S90g7NE88b", "number": 8230, "cdate": 1758075265142, "mdate": 1759897797670, "content": {"title": "Flatness Guided Test-Time Adaptation for Vision-Language Models", "abstract": "Test-time adaptation (TTA) of Vision-Language Models (VLMs) has emerged as a technique for tackling distribution shifts during the test time.  Recent research indicates that the test-time adaptation is intrinsically linked to the model's training history. However, existing TTA methods, such as Test-time Prompt Tuning, often design adaptation strategies in isolation from the models' training characteristics, which degrade their performance. This paper argues that the flatness acquired via sharpness-aware training is an efficient clue for the test-time adaptation of VLMs. Built on this insight, this paper proposes a novel Flatness-Guided Adaptation framework (FGA) for VLMs to cohesively unify training and test-time procedures. Its core idea is to leverage the alignment between the training minimum and test loss flat regions to guide the adaptation process. Specifically, our FGA consists of a prompt-tuning stage and a test-time adaptation stage. In the tuning stage, a Sharpness-Aware Prompt Tuning method is utilized to identify the training flat minimum, offering a geometric clue of flatness for subsequent adaptation. In the test stage, a Sharpness-based Test Sample Selection approach is proposed to ensure the alignment of flat minima between the training and each augmented test sample's loss landscape.  In comparison to existing TTA methods, our FGA avoids the expensive prompt parameter updates during test time, and substantially reduces the computation overhead. Extensive experiments on both domain generalization and cross-dataset benchmarks demonstrate that our FGA achieves superior performance over prevalent TTA methods. Notably, FGA even surpasses SOTA performance by 4.55\\% on ImageNet-A, when using a ViT-B/16 image encoder. Our code will be available soon.", "tldr": "", "keywords": ["Vision-Language Models", "Generalization", "Loss landscape"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/45f914fcb57eb4cefbe717bddded1654b0caced7.pdf", "supplementary_material": "/attachment/0865e9bbf07045cd9740a0a987df432a77c4cec5.pdf"}, "replies": [{"content": {"summary": {"value": "Most of existing test-time adaption methods isolate the test phase adaption from the training phase, leading to sub-optimal generalization performance. To mitigate this gap, this paper leverages the alignment between the training minimum and test loss flat regions to guide the test-time adaptation process, and proposes a flatness-guided adaptation framework (FGA). The effectiveness of FGA is verified both by theoretical analyses and extensive experiments."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* This paper is well-written and easy to follow.\n\n* The proposed framework FGA is novelty and well-motivated. The experimental results also demonstrate its effectiveness.\n\n* The experimental results are sufficient."}, "weaknesses": {"value": "There are some concerns on the theoretical analyses.\n\n* The generalization error bound in Theorem 1 is not tight and its effectiveness can be very restricted.\n\nIn Theorem 1, there is a term $M\\sqrt{\\frac{1}{2}\\cdot\\ln\\frac{2}{\\delta}}$ on the upper bound. It seems that this generalization error bound is efficient only for $\\delta>\\frac{2}{\\mathrm{e}^2}$. Otherwise, this upper bound is larger than $M$, a trivial result. \n\n* In Theorem 4, there is a lack of an upper bound on $\\xi$. If $\\xi$ is very large, then it is hard to distinct two test distributions by (12)."}, "questions": {"value": "* In Theorem 1, what are the definitions of $d_{F\\Delta F}$ and $\\hat{\\ell}^{\\rho}$ ? Does the loss function in the theorem i.e., $\\ell^p()$, equal to $\\ell_{STSS}$ ?\n\n\n* In (5), why are the perturbations sampled from the standard normal distribution? Is it used to approximate the direction of gradient (similar to (4))? If so, why is such an approximation strategy reasonable?\n\n* In Theorem 4, what is the relation between $\\xi$ and $\\beta$ ? In Theorem 1, if $\\delta>\\frac{2}{\\mathrm{e}^2}$, then there is a trivial upper bound on the generalization, i.e., $M$. By Definition 2, we can conclude $\\beta=0$. In this case, is $\\xi=M$ ?\n\n* FGA is independent of the methods that augment test samples. In the experiment, how does FGA augment test samples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SkY67c2HyP", "forum": "S90g7NE88b", "replyto": "S90g7NE88b", "signatures": ["ICLR.cc/2026/Conference/Submission8230/Reviewer_BBAK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8230/Reviewer_BBAK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760513959319, "cdate": 1760513959319, "tmdate": 1762920177541, "mdate": 1762920177541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses test-time adaptation (TTA) for vision-language models (VLMs) such as CLIP. Test-time prompt tuning (TPT), which optimizes text prompts corresponding to classes, is the mainstream approach in this field. TPT optimizes prompts for test samples using surrogate losses like entropy minimization. Since this optimization relies on backpropagation, it incurs significant overhead and substantially increases inference time. To this end, this paper proposes a novel test-time adaptation paradigm called flatness-guided adaptation (FGA). The core idea of FGA consists of two parts: adding regularization during the prompt-tuning phase to flatten the loss landscape, and selecting data augmentation samples during inference based on sharpness scores from the surrogate loss. This enables adapting the model to the test distribution without backpropagation during testing. Theoretically, the paper demonstrates that selecting similar samples via sharpness scores can bring the test distribution closer to the training distribution, potentially improving generalization performance. Experimentally, across standard benchmarks, the paper shows that FGA significantly improves performance compared to existing TPT baselines while substantially reducing inference time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **S1.** The paper proposes a novel TTA paradigm that eliminates the need for backpropagation during testing. This is innovative.\n- **S2.** The paper theoretically discusses the relationship between sharpness and generalization performance on the loss landscape, justifying the effectiveness of the proposed method. If this analysis is novel, it is expected to have a significant impact on the field.\n- **S3.** The paper evaluates the performance and inference speed improvements achieved by the proposed method through experiments using standard benchmarks. In particular, the comparison with the baseline combining CoOp and TPT is carefully designed and fair."}, "weaknesses": {"value": "- **W1.** Section 4's theoretical analysis discusses generalization performance using the loss $l^\\rho$ (e.g., cross-entropy for classification), but the proposed method shown in Section 3 actually evaluates sharpness using the surrogate loss $l_\\text{SRG}$, causing a discrepancy with reality and theory. The paper should add theoretical supplements describing the effects by this gap. Furthermore, practical insights such as the correlation between sharpness computed via cross-entropy using ground-truth labels and sharpness computed via entropy would also be desirable.\n- **W2.** FGA can indeed avoid backpropagation during inference, but the additional training cost due to flatness regularization is significant. While the paper introduces a reasonable approximation calculation via Taylor expansion in Eq. (4), a quantitative discussion is needed on how much training time increases compared to existing prompt-tuning, such as CoOp.\n- **W3.** FGA relies on a training phase with teacher labels. This is a significant practical constraint. The paper primarily trains using 16-shot ImageNet, implying a requirement for 16,000 training samples. Collecting datasets of this scale is a major burden in contexts like medical image processing. In this sense, demonstrating experimental results with fewer shots would significantly strengthen the paper's claims and enhance its value for practitioners, though it already shows \"zero-shot\" performance as \"FGA wo/ SAPT\" in Table 1."}, "questions": {"value": "Please respond to the concerns raised in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ro6bhc0VG2", "forum": "S90g7NE88b", "replyto": "S90g7NE88b", "signatures": ["ICLR.cc/2026/Conference/Submission8230/Reviewer_P1eB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8230/Reviewer_P1eB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761471696061, "cdate": 1761471696061, "tmdate": 1762920177055, "mdate": 1762920177055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Flatness-Guided Adaptation (FGA) for test-time adaptation of CLIP, leveraging sharpness-aware training to align training and test loss landscapes without updating parameters at test time.It introduces SAPT and STSS to guide adaptation using flatness as a geometric clue, enhancing generalization."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a FGA method that cohesively links training and test-time adaptation through the concept of loss landscape flatness, improving robustness to distribution shifts without updating model parameters during inference.\n2. FGA avoids backpropagation and prompt updates at test time, resulting in lower computational overhead while still improving performance."}, "weaknesses": {"value": "1. The scope of the paper is mismatched: While the title refers to test-time adaptation (TTA) for ``vision-language models\" broadly, all experiments are limited to CLIP variants (ViT-B/16 and ResNet50). This narrow scope excludes newer or structurally different VLMs such as  LLAVA or CLIP variants such as SigLIP, SigLIP-v2, or other similar models, undermining the generality claim. \n2. The phrase ``training data on downstream task\" is vague. From the experimental section, it seems the prompt tuning is conducted on ImageNet, while evaluation is on ImageNet variants. If ImageNet is treated as the training data, this may conflict with standard TTA setups, where benchmark dataset ImageNet should be unseen during training to preserve test-time integrity.\n3. The method combines sharpness-aware prompt tuning (SAPT) and test-time selection based on sharpness. While effective, this formulation closely relates to ideas explored in prior work like DPO [1], which also applies perturbation-based optimization for TTA, albeit in 3D object detection. A discussion of its differences/similarities would strengthen the positioning of this work.\n4. The experimental comparisons are inconsistent. While Table 1 includes TDA, Table 2 omits it despite being a relevant baseline for cross-dataset generalization. \n5. Recent methods like TCA [2] report higher performance than FGA without requiring augmentations or training overhead. The absence of direct comparison with such state-of-the-art approaches weakens the empirical claims. \n\n[1] DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection \n\n[2] Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation"}, "questions": {"value": "See the Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "RVA12a266m", "forum": "S90g7NE88b", "replyto": "S90g7NE88b", "signatures": ["ICLR.cc/2026/Conference/Submission8230/Reviewer_j4NZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8230/Reviewer_j4NZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761708536845, "cdate": 1761708536845, "tmdate": 1762920176624, "mdate": 1762920176624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The article proposes an approach for test-time adaptation of vision language models based on flat minima. Specifically, the approach (FGA) is composed of two elements: (i) sharpness-aware prompt tuning (SAPT), which adds a regularizer toward flat minima when tuning prompts in the style of CoOp (Zhou et al. 2022b), (ii) sharpness-based test-time sample selection (STSS), which augments test samples and selects the top augmented views according to the flatness of their loss landscape. Experiments on three benchmarks show the efficacy of the approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. To my knowledge, this is the first work tackling TTA (and prompt tuning) for vision-language models from the point of view of flat minima. This perspective on the problem is sound, supported by both findings of previous works (e.g., Niu et al. 2023, Gong et al. 2023) as well as the theoretical analysis of Sec. 4, and the achieved experimental results. The paper confirms the potential of this strategy, proposing variants suitable for the increased representation capabilities of VLMs.\n\n2. The strategy for selecting samples based on their sharpness in the loss landscape (STSS), is an interesting contribution, providing an alternative way to the commonly employed entropy (e.g., Shu et al. 2023) and being the element with the highest impact on the performance (Fig. 3). These showcases that flatness priors can guide the model at multiple levels, both during training for prompt tuning and during inference for data filtering."}, "weaknesses": {"value": "**1.** While FGA is an interesting approach, its two components could be techniques applied independently for prompt-tuning (SAPT) and for sample selection (STSS). Specifically, these two approaches might be treated independently from each other, as SAPT is a strategy for prompt tuning while STSS is a strategy for TTA with sample selection. Thus:\\\n&nbsp;&nbsp;&nbsp;**1.1**  SAPT could be, in principle, compared with CoOp and related variants on prompt-tuning benchmarks (e.g., base vs novel categories, as in Zhou et al. 2022a). This would show the benefit of flatness-aware prompt tuning with strong empirical evidence against prompt tuning alternatives. Similarly, as the method builds on CoOp, adding the flatness-aware regularizer of SAPT on top of other prompt-tuning approaches based on simple contrastive objectives (e.g., Zhou et al. 2022a, Khattak et al. 2023) would showcase that the advantages of flatness-aware prompt tuning are not restricted to CoOp-based tuning.\\\n&nbsp;&nbsp;&nbsp;**1.2** On the other hand, STSS could bring benefits to various approaches performing sample selection for TTA (without considering prompt tuning). In fact, selecting augmentations and aggregating their scores might be a variant for a lot of TTA approaches performing sample selection based on alternative criteria (e.g., entropy-based, as in TPT, Shu et al. 2023, DPE, Zhang et al. 2024a, and ZERO, Farina et al. 2024). This would demonstrate that flatness-aware selection can improve a wide range of methods, strengthening the case for its wider applicability.\n\n**2.** Given that the method is based on both offline prompt tuning and TTA, baselines should comprise three categories of methods: (i) TTA-only strategies, (ii) prompt-tuning only strategies, and (iii) the two merged. While this is the case, the selection of methods for the third category is limited, as, beyond PromptAlign (Abdul Samadh et al. 2024), only TPT and DiffTPT are considered as potential TTA strategies applied to prompt tuning approaches, and not in a consistent manner (e.g., Tab. 1 reports both applied to CoOp, Tab. 2 only TPT on top of CoOp and MaPLe). To fully demonstrate the strength of the approach, more competitive baselines should be built using more recent TTA approaches (e.g., C-TPT, ZERO, [b]) coupled with more recent prompt tuning strategies (e.g., [c,d]), reported in all tables. Moreover, following on the previous point, tables could report the results for SAPT and STSS alone (i.e., coupled with CoOp or alternatives), as prompt-tuning and TTA methods, respectively, ensuring a fair comparison beyond merging solutions for the two problems. \n\n**3.** Another set of strong baselines missing are those related to previous methods proposing flatness-aware optimization for online TTA, i.e.,  SAR (Niu et al. 2023) and SoTTA (Gong et al. 2023). It is worth noting that while the problem they address is different (i.e., online TTA with continuous updates), tables already include comparisons with methods employed in this setup (e.g., TDA, Karmanov et al. 2024, and DPE, Zhang et al. 2024a). Moreover, while it is true that they were not designed for VLMs, an adaptation of these approaches (as done in [a] for SAR) would suffice and strengthen the claim that FGA is the TTA strategy using flatness principles that is most suited for VLMs.\n\n**Minors:**\n\n4. Tables 1 and 2 appear far from the pages where they are described (e.g., Tab. 1 is on page 6 but discussed only on page 8). Reporting the table closer would avoid back and forth between pages when reading the manuscript.\n\n5. In the appendix, the name of the method changes to TLLA.\n\n**References:**\\\n[a] Wang, Zixin, et al. \"Is less more? exploring token condensation as training-free test-time adaptation.\" ICCV 2025.\\\n[b] Zanella, Maxime, and Ismail Ben Ayed. \"On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?\" CVPR 2024.\\\n[c] Yao, Hantao, Rui Zhang, and Changsheng Xu. \"Visual-language prompt tuning with knowledge-guided context optimization.\" CVPR 2023.\\\n[d] Roy, Shuvendu, and Ali Etemad. \"Consistency-guided Prompt Learning for Vision-Language Models.\" ICLR 2024."}, "questions": {"value": "1. Is SAPT an effective strategy for improving prompt-tuning with few shots?\n2. Is STSS an effective strategy for improving samples selection for TTA?\n3. How would the method compare with more recent baselines (even those merging recent TTA and prompt-tuning strategies)?\n4. How would the method (and its individual components) compare with adaptations of SAR and SoTTA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yjDLfPCnEv", "forum": "S90g7NE88b", "replyto": "S90g7NE88b", "signatures": ["ICLR.cc/2026/Conference/Submission8230/Reviewer_RFcj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8230/Reviewer_RFcj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8230/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819002768, "cdate": 1761819002768, "tmdate": 1762920176239, "mdate": 1762920176239, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}