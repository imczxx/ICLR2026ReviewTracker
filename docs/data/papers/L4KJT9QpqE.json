{"id": "L4KJT9QpqE", "number": 24135, "cdate": 1758353189443, "mdate": 1759896780195, "content": {"title": "Beyond Edge Deletion: A Comprehensive Approach to Counterfactual Explanation in Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are increasingly adopted in domains like molecular biology and social network analysis, yet their black-box nature hinders interpretability and trust. This is especially problematic in high-stakes applications, such as predicting molecule toxicity, drug discovery, or guiding financial fraud detections, where transparent explanations are essential. Counterfactual explanations - minimal changes that flip a model's prediction - offer a transparent lens into GNNs behavior. In this work, we introduce XPlore, a novel technique that significantly broadens the counterfactual search space. It consists of gradient-guided perturbations to adjacency and node feature matrices. Unlike most prior methods, which focus solely on edge deletions, our approach belongs to the growing class of techniques that optimize edge insertions and node-feature perturbations, here jointly performed under a unified gradient-based framework, enabling a richer and more nuanced exploration of counterfactuals. To quantify both structural and semantic fidelity, we introduce a cosine similarity metric on learned graph embeddings, addressing a key limitation of traditional distance-based metrics, demonstrating that XPlore produces more coherent and minimal counterfactuals. Empirical results on nine real-world and five synthetic benchmarks show up to +56.3% improvement in validity and +52.8% in fidelity over state-of-the-art baselines, while retaining competitive runtime.", "tldr": "", "keywords": ["Counterfactual Explainability", "Trustworthiness", "Graph Learning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ea7420aa622bca6d4d3878f12c30964949095f79.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors present Xplore, a counterfactual (CF) explanation method for graph neural networks. The method is derived from CF-GNNexplainer (Lucic et al.), but with a diffusion twist that allows for edge addition. Experiments are performed on different datasets and baselines for the problem of finding counterfactual."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The overall idea (of gradient guided optimization) is interesting.\n- The experiments consider a good amount of datasets.\n- The mathematical proof of convergence is sound, although very standard and too slow."}, "weaknesses": {"value": "- Presentation: Some parts of the paper are hard to read. The literature citations completely stop the flow of the text, Appendix section are poorly referenced. The paper does not seem to have been proofread with the applied ICLR format.\n\n- In the contribution stated claim 2) seem incorrect, claim 1) should be reformulated.\n\n- The literature review is outdated, and omits works published after early 2024. The paper only uses work from 2023 and before, and ignores relevant baselines from 2023, 2024, and 2025.\n\n- The claim of novelty of adding edges or perturbing features is false, as seen in works such as: (1) Empowering Counterfactual Reasoning over Graph Neural Networks through Inductivity, Verma et al, 2023; (2) Global Counterfactual Explainer for Graph Neural Networks, Kosan et al, 2022; (3) COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks via Node Feature and Structural Perturbations, Giogi et al, 2025\n\n- Following these gaps in the literature review, important recent baselines are missing.\n\n- The analysis of the experimental results is extremely lacking: in CF explanation, there is a trade-off between validity of the counterfactual and its distance to the original graphs. See Lucic et al. (2022), CF-GNNExplainer, or Ma et al. (2022), CLEAR. This trade-off is nowhere mentioned, and absent from the analysis. The good validity results of the method may be entirely explained by the algorithm not stopping until it finds any valid counterfactual."}, "questions": {"value": "- Part 1: claim 1 seems to express that you are the first to consider edge and node deletion, but this is not true, as for instance the cited Ma et al.’s CLEAR already does this.\n\n- Part 1: claim 2 appears incorrect as well, ”the closest counterfactual through directed modifications” is not mentioned in the rest of the paper, and in fact, as seen in Table 3 for GED, seems widely incorrect.\n\n- Part 2: Since D4Explainer also uses diffusion to find CF through denoising diffusion, how does your method differ? Please add a deeper comparison with this paper.\n\n- Part 3.1: Equation 2 is awkwardly introduced, and does not serve any purpose; the loss used is given in Equation 7. You should introduce the metrics for your objective here, not the loss.\n\n- Part 3.1: the Node Counterfactual Explanation is unclear, and should go after your method or be more general. It fails to explain what Node Counterfactual Explanation is. Please state the objective.\n\n- Part 3.2: As mentioned, equation (3) is a subcase of Lucic et al.’s work where the subgraph considered is the whole graph.\n\n- Part 3.2: The idea of noisy perturbation then denoising is interesting, and very similar to diffusion. I would reframe the work this way.\n\n- Part 4: Table 3 is misleading, and does not relate to the objective stated: you should compare fidelity/validity and GED/CS at the same time for each method. Fidelity aims at finding counterfactuals, GED looks for good, i.e close counterfactual. Hence both should be analyzed together, as there is a trade-off.\n\n- Part 4: Table 3 and validity. Getting 100 % validity is not surprising since the algorithm stops when it finds a counterfactual. The comparison with baselines seems unfair. This is also NOT discussed anywhere in the paper, which is a major issue.\n\n- Part 4: unsurprisingly, the GED/CS of the proposed method is much higher than that of other methods, since the algorithm.\n\n- Part 4.3: I am not sure what is the purpose of this part, this is not introduced or mentioned in the paper, and poorly structured.\n\n- Appendix A.1: I am puzzled as to why you rewrote the proof of an already proven theorem. It is sufficient to just cite a theorem and use its result."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zput6Jua90", "forum": "L4KJT9QpqE", "replyto": "L4KJT9QpqE", "signatures": ["ICLR.cc/2026/Conference/Submission24135/Reviewer_mmHe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24135/Reviewer_mmHe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761625376206, "cdate": 1761625376206, "tmdate": 1762942952081, "mdate": 1762942952081, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a gradient-based framework for graph counterfactual explanations that expands the search space beyond edge deletions to allow edge insertions and node feature perturbations. It optimizes a soft objective balancing prediction flip and distance to the original graph, and naturally extends to node-level counterfactuals."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe proposed method XPlore achieves impressive improvements on both validity and fidelity metrics.\n2.\tThe method’s performance was validated on 14 datasets, spanning multiple graph types.\n3.\tThis paper explicitly acknowledged that the residual OOD effects remain open and links them to robustness of oracles."}, "weaknesses": {"value": "1.\tTo my current knowledge, there exists prior work (e.g., C2Explainer) that has already enabled edge insertion and node feature perturbations; this might weaken Xplore’s claimed novelty unless positioned more precisely.\n2.\tWhile the evaluation was performed on 14 datasets, it is skewed towards molecular/biology category, with only one social network dataset (i.e., COLLAB). As social network analysis might be a key application area for GNN interpretability, adding more datasets in this area would benefit generality. \n3.\tA few typos: (i) in Figure 2 (d), the caption reads “edge inserion” and should be “edge insertion”; (ii) in Section 4.2, “sparisity” should be “sparsity”."}, "questions": {"value": "1.\tCould you please situate the proposed work’s novelty against recent counterfactual explainers that support edge insertions and/or node feature perturbations, such as C2Explainer?\n2.\tWould you consider including recent baselines (2024-2025) that permit node perturbations or edge insertions?\n3.\tWould you consider adding more social-network datasets beyond COLLAB? This would help assess generality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "s5ezPxfHLf", "forum": "L4KJT9QpqE", "replyto": "L4KJT9QpqE", "signatures": ["ICLR.cc/2026/Conference/Submission24135/Reviewer_awWW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24135/Reviewer_awWW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680059139, "cdate": 1761680059139, "tmdate": 1762942951799, "mdate": 1762942951799, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies counterfactual generation on graphs by allowing not only edge deletions but also edge additions and feature perturbations. The proposed gradient-based framework optimizes these operations in a unified manner. It replaces distance-based objectives with a cosine-similarity metric, yielding more coherent explanations. Experiments report substantially higher validity and fidelity than state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear algorithmic description with well-structured steps; the method is easy to follow.\n- Extensive experiments with comparisons against multiple competing approaches.\n- Thoughtful discussion of future directions that can guide subsequent research."}, "weaknesses": {"value": "- The contributions are repetitive and could be more concise. For example, contribution points 1 and 4 appear overlapping and could be merged.\n- Positioning the work as an “extension” of a prior paper weakens the novelty message.\n- Novelty is limited in parts; for instance, edge addition in counterfactual explanations has prior art.\n- The motivation for feature perturbations is underdeveloped, and the ablation on this component is limited.\n- The search space and resulting computational complexity are not sufficiently justified.\n- It remains unclear why the method should yield better out-of-distribution robustness or influence."}, "questions": {"value": "- Edge additions for counterfactual explanations have been studied. What is the specific new insight or advantage your approach provides over prior formulations?\n- Complexity: With edge operations, a naive search could appear O(n^2). Please clarify why your algorithm remains O(|E| + n f)?\n- Motivation for feature perturbation: Could you add concrete examples where edge edits alone fail but small feature changes produce plausible, faithful counterfactuals (e.g., molecular graphs where atom attributes change properties, or social/product graphs where node attributes shift recommendations)?\n- Experimental protocol: How many runs were executed for the explanation module? You report standard deviations—does the table show mean ± std over k runs? Please state k and any fixed random seeds.\n\nEditorial/Presentation Notes:\n- Figure 2 colors are hard to distinguish; maybe increase line/marker thickness for clarity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ggH1CMseVs", "forum": "L4KJT9QpqE", "replyto": "L4KJT9QpqE", "signatures": ["ICLR.cc/2026/Conference/Submission24135/Reviewer_CW7Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24135/Reviewer_CW7Q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958667568, "cdate": 1761958667568, "tmdate": 1762942951496, "mdate": 1762942951496, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes XPlore, a counterfactual explainer for GNNs that can delete and insert edges and also perturb node features. The authors formulate counterfactual search as minimizing a prediction-change loss plus a distance loss. The method targets both graph-level and node-level counterfactuals and introduces a cosine-similarity-on-embeddings metric to capture semantic fidelity. Across 14 datasets, their method outperforms nearly all baselines, and OOD performance is discussed."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- XPlore covers graph modifications that most GCE methods don't. Insertions + feature shifts matter.\n- Performance on benchmarks against baselines is very strong.\n- The authors are honest about their OOD performance and highlight key challenges for all methods."}, "weaknesses": {"value": "- The method still relies on an oracle model, which adds another degree of freedom for practitioners to consider and means XPlore also likely inherits the oracle's faults.\n- The OOD discussion seems to suggest that XPlore focuses on model-flipping counterfactuals rather than plausible counterfactuals, which is a significant weakness."}, "questions": {"value": "- Are there any ablations for examining deletions only, deletions+ insertions, and deletions+insertions+features performance?\n- Have the authors examined examples for the molecular datasets to ensure that the generated counterfactuals are also chemically valid (e.g. does not violate valence rules)?\n- Table 4 only considers CF-GNNExpl on one dataset. How about other baselines/datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oG53xhpzC7", "forum": "L4KJT9QpqE", "replyto": "L4KJT9QpqE", "signatures": ["ICLR.cc/2026/Conference/Submission24135/Reviewer_Pu3X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24135/Reviewer_Pu3X"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24135/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012259271, "cdate": 1762012259271, "tmdate": 1762942951031, "mdate": 1762942951031, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}