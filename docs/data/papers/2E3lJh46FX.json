{"id": "2E3lJh46FX", "number": 5512, "cdate": 1757917209851, "mdate": 1759897970220, "content": {"title": "Robust Time Series Forecasting via Basis-Aligned Sampling in Decycled Residual Space", "abstract": "Time series forecasting is crucial in domains such as finance, energy, and traffic, yet real-world data are often contaminated by anomalies and noise.\nIn this work, we first identify a fundamental limitation of existing approaches—their excessive reliance on specific input points, particularly the most recent observation—which makes them highly susceptible to point-wise perturbations and undermines prediction reliability.\nTo further address this challenge, we propose RESAM, a novel approach for robust time series forecasting that effectively mitigates the impact of point-wise perturbations while maintaining high overall forecasting accuracy. \nRESAM utilizes a basis-aligned randomized sampling strategy to comprehensively exploit the global context and achieve a unified representation for irregularly sampled sequences.\nMoreover, RESAM employs a learnable periodicity extraction module with a two-stage training protocol to enhance the accuracy and robustness of both periodicity and residual learning.\nComprehensive evaluations on eight benchmark datasets show that RESAM achieves competitive forecasting accuracy and significantly surpasses state-of-the-art models in robustness to point-wise perturbations.", "tldr": "A robust time series forecasting method that reduces reliance on individual data points, improving resilience to point-wise perturbations while maintaining high accuracy through global context utilization and periodicity learning.", "keywords": ["Robust Time Series Forecasting", "Deep Learning"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2b27aafe6035fa6439d711a8694854a37c62bd8d.pdf", "supplementary_material": "/attachment/2e85ce62f8f3da155372e19869e69496545911cd.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses the issue that recent observations in time series have a significant impact on forecasting performance. To mitigate this, the paper proposes a new robust time series forecasting method, RESAM, aimed at improving prediction reliability. Specifically, RESAM uses a basis-aligned random sampling strategy to explore global context information while achieving a unified representation for irregularly sampled sequences. Additionally, RESAM incorporates a learnable periodicity extraction module to capture periodic patterns. Evaluations on multiple datasets show that it outperforms baseline models in terms of performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies the issue of the last points.\n2. The architecture design is simple and efficient."}, "weaknesses": {"value": "1. The experimental baseline models are not cutting-edge enough. It is recommended to include more recent, high-performing baseline methods. Additionally, the effectiveness of the method is not sufficiently demonstrated in the main experiments.\n2. The paper seems more like an engineering-driven modular approach for performance improvement rather than an in-depth exploration of the issue, which significantly weakens its contribution.\n3. The motivation behind the paper seems illogical. It is reasonable that the last points in a time series are important and that learning such biases is valid. It is also intuitive that perturbing these points would lead to a significant drop in performance.\n4. The related work section is too broad and lacks adequate discussion of relevant research. In my knowledge, the importance of more recent observations is a widely accepted phenomenon, especially in fields like finance where \"market efficiency\" often dictates that recent data hold higher significance."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NAN"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bR2VCgnEFS", "forum": "2E3lJh46FX", "replyto": "2E3lJh46FX", "signatures": ["ICLR.cc/2026/Conference/Submission5512/Reviewer_YX6M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5512/Reviewer_YX6M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808086364, "cdate": 1761808086364, "tmdate": 1762918103457, "mdate": 1762918103457, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method that leverages a basis-aligned randomized sampling strategy and a learnable periodicity extraction module with a two-stage training protocol to forecast time series robustly."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Easy to follow and understand.\n2. Well-motivated"}, "weaknesses": {"value": "1. There is a lack of a sufficient literature review. In the introduction part, the authors should discuss on the existing works and the reason why they cannot solve the challenges.\n2. The baselines are not comprehensive enough to claim a SOTA performance. More baselines, such as iTransformer, Time-LLM, and GPT4TS, should be compared.\n3. There is no experiment on short-term forecasting, limiting the application scope.\n4. The overall performance increase is not significant and robust. It seems that only on ETTm1 and ETTm2, the proposed method shows clear advantages. Besides, on robustness evaluation, RESAM is worse than Crossformer and TimesNet according to the MSE increase."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "plEzkA0HK5", "forum": "2E3lJh46FX", "replyto": "2E3lJh46FX", "signatures": ["ICLR.cc/2026/Conference/Submission5512/Reviewer_3Xag"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5512/Reviewer_3Xag"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869843610, "cdate": 1761869843610, "tmdate": 1762918103138, "mdate": 1762918103138, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a randomized sampling strategy to exploit global context to mitigate the impact of point-wise perturbations for time series forecasting. Experiments on 8 datasets show the robustness to point-wise perturbations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This motivation is easy to follow.\n2. Visualization and showcases.\n3. Code are provided for reproducibility.\n4. Randomized sampling strategy to exploit global context to mitigate the impact of point-wise perturbations is very interesting."}, "weaknesses": {"value": "1. The claimed contributions and novelty are exaggerated. There are existing works on anomalies or perturbations on time series forecasting, such as [1-2]. There are also many works on basis / decycle or decomposition, such as [3-4]. And the proposed Learnable Periodicity Extraction module seems to be from [3], or I cannot find how to learn periodic cycle $W$ from the presentation in Section 3.2.\n\n[1] RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies. ICLR 2024.\n\n[2] Weakly Guided Adaptation for Robust Time Series Forecasting. Proc. VLDB Endow. 17(4): 766-779 (2023).\n\n[3] Revitalizing multivariate time series forecasting: Learnable decomposition with inter-series dependencies and intra-series variations modeling. ICML 2024.\n\n[4] CycleNet Enhancing time series forecasting through modeling periodic patterns, Lin et al., NIPS 2024.\n\n2. Key experimental comparison for baselines [1-2] is missing. The author should also compare state-of-the-art baselines such as [3].\n\n3. How to evaluate the improvements by identifying the real perturbations in original datasets? Or the improvements are just gained by randomized sampling strategy which enhance generalization ability?"}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OX4D1B1l1Q", "forum": "2E3lJh46FX", "replyto": "2E3lJh46FX", "signatures": ["ICLR.cc/2026/Conference/Submission5512/Reviewer_FyDr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5512/Reviewer_FyDr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941072928, "cdate": 1761941072928, "tmdate": 1762918102890, "mdate": 1762918102890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents RESAM, a method for robust time series forecasting designed to mitigate vulnerability to point-wise perturbations, particularly on the most recent input points. The approach combines Basis-Aligned Randomized Sampling (BARS) to represent sampled time points via trigonometric basis functions and a Learnable Periodicity Extraction (LPE) module that learns the periodic component independently before sampling. A two-stage training procedure further stabilizes dual-space learning. Extensive experiments across eight benchmarks demonstrate improved perturbation robustness and competitive forecasting accuracy relative to prominent baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper convincingly identifies and empirically demonstrates a core vulnerability in modern time series forecasting architectures: an over-reliance on recent input points, as shown in Figure 1 and Figure 3. This motivates the necessity for robustness-oriented model design.\n2. A comprehensive set of ablation studies (Figure 8) shows that both LPE and the BARS sampling improve robustness and accuracy, offering deeper insight into the contribution of each component.\n3. The paper is clearly and lucidly written, making the methodology easy to follow. The authors' provision of source code further enhances the credibility and reproducibility of their work."}, "weaknesses": {"value": "1. On Novelty and Contribution: The Learnable Periodicity Extraction (LPE) module, a key component of the proposed framework, appears to be heavily inspired by or substantially similar to prior work, particularly CycleNet. This significant overlap raises concerns about the novelty and the incremental contribution of this paper. While integrating existing ideas is valid, the reliance on this established architecture may limit the perceived originality of the overall work.\n2. In Stage 1 of training, the authors replace the basis-aligned sampling module and MLP backbone with a simple linear layer. However, the ablation study does not include a baseline that only uses this Stage 1 architecture for final prediction (i.e., without proceeding to Stage 2). \n3. On Overall Performance: From a practical standpoint, the empirical results suggest that RESAM does not consistently achieve state-of-the-art performance across all benchmarks. Even on the datasets where RESAM performs favorably, the margin of improvement over existing baselines is often limited. This raises questions about the practical significance of the proposed method in standard, noise-free forecasting scenarios and whether the added complexity is justified by the marginal gains.\n4. On the Perturbation Model and Scope of Conclusions: The paper's core motivation hinges on the finding that existing models are more sensitive to a last-point perturbation than a random-point one. However, the realism of this specific perturbation model is a significant concern; it is difficult to identify practical, real-world scenarios where noise or corruption would systematically affect only the single most recent data point. Furthermore, the proposed methodology, especially the basis-aligned sampling, seems inherently capable of addressing other non-point-wise disturbances, such as block-wise corruption or multi-point noise. The authors' failure to discuss or evaluate their model against these more general and arguably more realistic perturbation types restricts the applicability and scope of their conclusions. This leaves the model's robustness in a broader range of practical scenarios underexplored.\n5. My concerns about the limited generalizability of the conclusions are further amplified by the appendix, where the sensitivity analysis for the perturbation ratio α is conducted exclusively on the ETT series of datasets. To strengthen the paper's claims, I recommend that the authors extend this important ablation study to a more diverse range of datasets."}, "questions": {"value": "1. **On the Necessity of Stage 2 Training**: Fundamentally, fitting basis coefficients is a linear task. It is therefore plausible that replacing the basis-fitting module with a linear layer, as done in Stage 1, could theoretically achieve comparable results. My primary concern is whether the Stage 2 training genuinely provides a significant performance improvement over the foundation established in Stage 1. To address this, could the authors supplement the ablation study by reporting the performance of the Stage 1 model (trained and evaluated on its own) across the various datasets? This would clarify the true value added by Stage 2.\n2. **On the Complexity of the Two-Stage Protocol**: The introduction of a linear or MLP layer in Stage 1, which is later replaced by the full RESAM architecture in Stage 2, appears to significantly increase the model's overall parameter count and training complexity. Is this added complexity truly necessary? Could the authors consider a simpler approach for Stage 1, where only a periodic pattern matrix is trained, and the forecast is generated by simply extrapolating this learned cycle? Such a method would likely be more computationally efficient and would help isolate the benefits of the periodicity learning itself.\n3. **On the Realism of the Last-Point Perturbation Model**: The paper demonstrates that RESAM is effective at mitigating last-point perturbations, but its efficacy against other point-wise disturbances seems limited by design. Could the authors comment on the practical relevance of this specific last-point perturbation model? In which real-world scenarios does this type of isolated, terminal-point corruption actually occur? Justifying the focus on this particular failure mode is crucial for the paper's practical impact.\n4. **On the Generalizability to Other Perturbation Types**: Could RESAM be extrapolated to handle other common disturbance patterns, such as block-wise corruption, random multi-point noise, or missing value imputation? The current analysis is narrowly focused on a single type of perturbation. An evaluation of RESAM's performance against these more varied and arguably more common types of data corruption would provide a much more comprehensive assessment of its robustness and practical utility.\n\nI believe this paper has potential, but the concerns raised above are significant. Should the authors provide a convincing response that effectively addresses these weaknesses and clarifies the open questions, I would be happy to reconsider my evaluation and increase my score accordingly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oZg7007vPX", "forum": "2E3lJh46FX", "replyto": "2E3lJh46FX", "signatures": ["ICLR.cc/2026/Conference/Submission5512/Reviewer_kTBq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5512/Reviewer_kTBq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762430303221, "cdate": 1762430303221, "tmdate": 1762918102638, "mdate": 1762918102638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}