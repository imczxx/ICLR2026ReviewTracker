{"id": "UESTP6dR1K", "number": 24986, "cdate": 1758362790933, "mdate": 1759896739090, "content": {"title": "Automated Stateful Specialization for Adaptive Agent Systems", "abstract": "Current automated agent design frameworks produce either static workflows that lack adaptability or per-query optimizers that prevent the accumulation of deep, agent-level task expertise. We propose a new direction that reconciles these paradigms: creating stateful teams of specialist agents that accumulate knowledge over time and can be reconfigured for novel tasks entirely without human intervention. To this end, we introduce \\textsc{ASpec}, a framework that manages this full agent lifecycle by first autonomously $\\textbf{discovering}$ specialist archetypes via evolutionary search and then $\\textbf{cultivating}$ their expertise through experience, mirroring how human experts learn through practice and reflection. We further introduce a lightweight hierarchical control policy, \"retain-then-escalate,\" which governs when to leverage the established agent system versus when to adapt its structure. Through comprehensive experiments, we demonstrate that this approach leads to significant performance gains on expert-level scientific benchmarks like GPQA while matching the state-of-the-art on broader domain tasks, demonstrating a promising path toward agent systems that are simultaneously expert, adaptive, and efficient.", "tldr": "We introduce a framework that creates persistent, specialist agent teams through an offline lifecycle of discovery and cultivation, and deploys them with an online policy that efficiently adapts the team's structure for novel tasks.", "keywords": ["LLMs", "Autonomous Agents", "Agent Specialization"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e80582ce468d83036273dd5b4ebdc6bd3decc715.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work introduces ASpec, a framework that manages the full lifecycle of expert specialist agents by first autonomously discovering specialist archetypes via evolutionary search and then cultivating their expertise through experience. It also introduces \"retain-then-escalate\", a control policy that, instead of being either fully static or fully dynamic, defaults to retaining a stateful agent team across related queries to leverage expertise and minimize cost, only escalating to architectural resampling when needed. Results show that the proposed approach can lead to substantial performance improvements without sacrificing efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed method is novel and well-motivated. It effectively addresses the limitation of prior work, where architectures lack long-term state because they are regenerated or resampled for every query.\n\n- The results in Table 1 show substantial performance improvements, which validate the effectiveness of the proposed method."}, "weaknesses": {"value": "- I am confused about the transferability results presented in Figure 5 (right). I can't understand this figure and there is no accompanying explanation or analysis. I would like to understand how well the proposed method transfers to different tasks, and a more detailed discussion would be helpful."}, "questions": {"value": "- I am not very familiar with the related work in this area, so I am unsure whether the selected baselines are the most appropriate for comparison."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Jwl4MngyLP", "forum": "UESTP6dR1K", "replyto": "UESTP6dR1K", "signatures": ["ICLR.cc/2026/Conference/Submission24986/Reviewer_vhtg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24986/Reviewer_vhtg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680727247, "cdate": 1761680727247, "tmdate": 1762943273299, "mdate": 1762943273299, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ASPEC framework builds evolving teams of specialized agents that can keep improving with experience. It designs specialized agent types through evolutionary search and enables them to improve through practice. Experiments show that this method leads to performance gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "ASPEC effectively bridges the gap between static task-level designs and per-query adaptive systems.\nAchieves top performance on multiple benchmarks—including GPQA and SciCode, surpassing prior frameworks such as AFlow, ADAS, and EvoAgent.\nEvaluated across five diverse benchmarks covering reasoning, scientific QA, and coding tasks, demonstrating robust generalization across domains.\nThe paper explicitly reports that ASPEC achieves higher accuracy than baselines at a fraction of the computational cost. This “Pareto-efficient” behavior is one of its key strengths.\n\nIncludes detailed ablation studies quantifying the contribution of each system component—such as specialist operators, the meta-controller, and the architect—to overall performance and efficiency."}, "weaknesses": {"value": "The meta-agent evaluation process introduces multiple sources of randomness (including LLM output variance, error propagation across chained agents, sampling variability within the meta-agent, and stochastic evaluation outcomes). This leads to higher variability than typical single-LLM evaluations. In addition to averaging results over three runs, reporting variances would help assess and demonstrate the stability of the system’s performance.\n\nThe framework’s separation into two discrete stages (specialist discovery and specialist cultivation) appears conceptually convenient but somewhat artificial."}, "questions": {"value": "How can other long-term memory methods be incorporated into your framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cuGn00BP9G", "forum": "UESTP6dR1K", "replyto": "UESTP6dR1K", "signatures": ["ICLR.cc/2026/Conference/Submission24986/Reviewer_1R45"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24986/Reviewer_1R45"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997474377, "cdate": 1761997474377, "tmdate": 1762943272924, "mdate": 1762943272924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an automated method for generating stateful specifications to improve AI agent performance on complex tasks. By combining formal methods with machine learning, the system automatically extracts state transition rules and constraints from task execution traces. Experiments on various state management tasks show the approach effectively improves task success rates and code quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **High degree of automation**: Automatically extracts specifications from execution traces with minimal human intervention, enhancing practicality\n2. **Methodological innovation**: Combines symbolic reasoning with statistical learning, leveraging advantages of both for complex state spaces\n3. **Comprehensive experiments**: Validation across different task types including file system operations, database management, and workflow orchestration\n4. **Good interpretability**: Generated state specifications are human-readable, facilitating debugging and understanding of agent behavior\n5. **Clear effectiveness**: Experiments show significant improvements in task success rates and code robustness"}, "weaknesses": {"value": "1. **Insufficient formal guarantees**: Despite using formal methods, lacks theoretical guarantees for correctness and completeness of generated specifications. Critical states or constraints may be missed\n2. **Questionable scalability**: How does computational complexity scale with state space size? The paper lacks analysis of large-scale scenarios\n3. **Data dependency**: Requires sufficiently diverse execution traces to learn complete specifications. Cold start and rare state handling is inadequate\n4. **Shallow comparisons**: Limited comparison with pure learning-based or pure formal methods, making it hard to assess true advantages of the hybrid approach\n5. **Practical deployment challenges**: How are state specifications continuously updated in dynamic environments? Maintenance issues aren't discussed"}, "questions": {"value": "1. When task definitions change, how efficiently can learned state specifications be updated? Does this require recollecting large amounts of data?\n2. For scenarios with concurrent operations, how do you model partial ordering of state transitions?\n3. How do you address state explosion? In very complex systems, possible state combinations grow exponentially\n4. Compared to manually designed specifications, where are automatically generated ones superior? Have you conducted such comparisons?\n5. How transferable is the method across domains? How much domain-specific tuning is required?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e7hDe9HCEg", "forum": "UESTP6dR1K", "replyto": "UESTP6dR1K", "signatures": ["ICLR.cc/2026/Conference/Submission24986/Reviewer_HnVD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24986/Reviewer_HnVD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998289478, "cdate": 1761998289478, "tmdate": 1762943272611, "mdate": 1762943272611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "I apologize for any confusion in the earlier review. I have now carefully re-examined the paper and updated the comments, and based on the revised assessment, I think the original score does not need to be changed.\nThis paper introduces ASPEC, an automated framework designed to bridge the gap between static agent workflows, which lack adaptability, and per-query optimizers that are flexible but computationally expensive and stateless. The core idea is to manage the full lifecycle of agents by mimicking human learning through two offline stages: \"Discovery,\" where evolutionary search creates specialist archetypes with specific identities and directives, and \"Cultivation,\" where these agents build long-term memory through practice and reflection. During deployment, the system employs a lightweight \"Retain-then-Escalate\" policy managed by a Meta-Controller. This controller intelligently decides whether to reuse the current team of specialists to save costs or invoke the \"Architect\" to redesign the structure for novel tasks. Empirical results show ASPEC outperforms existing baselines on benchmarks like GPQA, MATH, and HumanEval, achieving a notable 6.5% gain over Gemini 2.0 Flash on GPQA while maintaining lower inference costs than comparable automated methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A key strength of this work is its shift in focus from merely optimizing the connection topology between agents to evolving the \"identity\" of the agents themselves. By using crossover and mutation operations, the framework allows agents to inherit prompt characteristics in a way that effectively mimics biological evolution.\n2. The integration of a non-parametric memory module significantly improves upon existing dynamic agent systems. This allows the system to record successful experiences and past failures, effectively addressing the common inability of dynamic agents to accumulate deep, domain-specific knowledge over time."}, "weaknesses": {"value": "1. I found the distinction made in the Related Work section somewhat unconvincing. Specifically, the claim that linking discovery to cultivation ensures expertise accumulation does not clearly explain how this fundamentally differs from or improves upon existing self-evolving agent frameworks. This requires more explanations.\n2. The sensitivity analysis suggests that performance is highly dependent on specific hyperparameter settings, particularly the number of specialists (k) and the window size (m). The fact that performance drops if these are too high or too low implies that the system might be brittle and require precise tuning to work well.\n3. While the paper highlights efficiency during inference, it lacks a detailed analysis of the computational costs during the offline \"Discovery\" and \"Cultivation\" phases. Given that evolutionary search is typically resource-intensive, omitting the cost of training and searching makes it difficult to assess the true overall efficiency of the proposed method.\n4. The experiments rely heavily on large models such as Gemini 2.0 Flash, GPT-4o-mini and Llama 3.3 70B Instruct. This raises a concern that the framework's success might be overly dependent on the strong capabilities of large models. This makes me wonder if it works for smaller LLMs such as Qwen 3 8B?"}, "questions": {"value": "Regarding the sensitivity to the number of specialists (k), could the drop in performance with a larger k be due to retrieval dilution, or is there another explanation? Conversely, does a small k simply result in insufficient domain coverage? I would appreciate more insight into this trade-off. Furthermore, if we were to apply this framework to a completely different domain like law or medicine, would these hyperparameters need to be re-optimized from scratch?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e7hDe9HCEg", "forum": "UESTP6dR1K", "replyto": "UESTP6dR1K", "signatures": ["ICLR.cc/2026/Conference/Submission24986/Reviewer_HnVD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24986/Reviewer_HnVD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998289478, "cdate": 1761998289478, "tmdate": 1763653226180, "mdate": 1763653226180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ASPEC, a framework designed to bridge the functional gap in contemporary agent system design between static, task-specific workflows and dynamic, per-query optimizers. It proposes a system of specialized agents capable of accumulating persistent, role-specific expertise over time. The methodology involves an automated lifecycle consisting of evolutionary discovery and experiential cultivation, governed by a cost-aware \"retain-then-escalate\" control policy. The authors demonstrate measurable performance improvements, notably achieving an accuracy of 62.8% on the GPQA benchmark, and establish competitive cost efficiency relative to approaches that rely on constant architectural resampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposal to develop adaptive, stateful specialist agents represents a highly appealing and novel direction compared to other current multi-agent system approaches. Furthermore, the empirical results presented are compelling, and the supporting analysis of the system's components and efficiency is sound."}, "weaknesses": {"value": "The system is inherently complex due to its hierarchical, two-tiered structure. It requires maintaining both a low-level Architect (a large generative LLM used for evolutionary search) and a high-level, trained Meta-Controller (a neural policy). The entire process involves managing an offline two-stage training loop (Discovery and Cultivation), which is more involved than implementing fixed-architecture or simple prompt-optimization methods."}, "questions": {"value": "Could you elaborate on how the framework determines when a newly discovered specialist's niche is too narrow to be retained, thus avoiding excessive fragmentation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AZZLIznOGU", "forum": "UESTP6dR1K", "replyto": "UESTP6dR1K", "signatures": ["ICLR.cc/2026/Conference/Submission24986/Reviewer_Yi79"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24986/Reviewer_Yi79"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762325294136, "cdate": 1762325294136, "tmdate": 1762943272369, "mdate": 1762943272369, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}