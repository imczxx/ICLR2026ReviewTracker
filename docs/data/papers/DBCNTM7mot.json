{"id": "DBCNTM7mot", "number": 8054, "cdate": 1758055515598, "mdate": 1763718892516, "content": {"title": "Continual Low-Rank Adapters for LLM-based Generative Recommender Systems", "abstract": "While large language models (LLMs) achieve strong performance in recommendation, they face challenges in continual learning as users, items, and user preferences evolve over time. Existing LoRA-based continual methods primarily focus on preserving performance on previous tasks, but this overlooks the unique nature of recommendation: the goal is not to predict past preferences, and outdated preferences can even harm performance when current interests shift significantly. To address this, we propose PESO (Proximally rEgularized Single evolving lOra, a continual adaptation method for LoRA in recommendation. PESO introduces a proximal regularizer that anchors the current adapter to its most recent frozen state, enabling the model to flexibly balance adaptation and preservation, and to better capture recent user behaviors. Theoretically, we show that this proximal design provides data-aware, direction-wise guidance in the LoRA subspace. Empirically, PESO consistently outperforms existing LoRA-based continual learning methods.", "tldr": "", "keywords": ["LLM-based generative recommender; continual learning; low-rank adapters"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/39a0ddf436a2813d5e639eac1f554585a26e5518.pdf", "supplementary_material": "/attachment/5ead9d4fdfbf02f3d45615e834c8e69e68ebdd0e.zip"}, "replies": [{"content": {"summary": {"value": "This paper has focused on the continual learning in LLM-based recommender systems. The authors found that existing cumulative-LoRA-based methods cannot capture the preferences well contained in frozen past adapters. Besides, they face the challenges of growing storage costs. To address these issues, this paper facilitates the continual learning methods specified for LLM-based RS, including a proximal regularizer. The extensive experiments have validated the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ S1. This paper is well-organized and -written, making it easy to follow.\n+ S2. Extensive experiments have been conducted.\n+ S3. The code is released, making it easy to reproduce."}, "weaknesses": {"value": "- W1. More illustration of the importance of continual learning in recommender systems is needed. In general, the models used in industry are retrained periodically.\n- W2. The authors have claimed that existing cumulative LoRA methods face the challenge of adapter entanglement for the recommendation tasks. However, it seems that not all PEFT methods in continual learning belong to cumulative LoRA, such as O-LoRA [1] and AM-LoRA [2]. Do they face the same challenges as the cumulative LoRA methods?\n- W3. The performance of the model training on the full dataset should be revealed to show the merit of continual learning.\n- W4. Only one basic LLM-based recommendation model is experimented with in this paper. I suggest that the authors add more up-to-date LLM-based RS models, such as LLaRA and BIGRec, to further validate the robustness of the proposed method.\n\n\n\n[1]. Wang, Xiao, et al. \"Orthogonal Subspace Learning for Language Model Continual Learning.\" *The 2023 Conference on Empirical Methods in Natural Language Processing*.\n\n\n\n[2]. Liu, Jialin, et al. \"Learning attentional mixture of loras for language model continual learning.\" *arXiv preprint [arXiv:2409.19611](https://arxiv.org/abs/2409.19611)* (2024).\n\n\n\n[3]. Liao, Jiayi, et al. \"Llara: Large language-recommendation assistant.\" *Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval*. 2024.\n\n\n\n[4]. Bao, Keqin, et al. \"A bi-step grounding paradigm for large language models in recommendation systems.\" *ACM Transactions on Recommender Systems* 3.4 (2025): 1-27."}, "questions": {"value": "All my questions have been included in the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TwlpJfWy7l", "forum": "DBCNTM7mot", "replyto": "DBCNTM7mot", "signatures": ["ICLR.cc/2026/Conference/Submission8054/Reviewer_qc7d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8054/Reviewer_qc7d"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727696715, "cdate": 1761727696715, "tmdate": 1762920046199, "mdate": 1762920046199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CLoRA (Continual Low-Rank Adaptation), a novel method designed to enable continual learning for large pre-trained models without retraining or catastrophic forgetting. Traditional fine-tuning methods require storing large model checkpoints for each new task, leading to significant storage and computation overhead. CLoRA builds upon LoRA (Low-Rank Adaptation) by introducing a continual learning mechanism that efficiently integrates knowledge from new tasks while retaining performance on previously learned ones.\n\nThe key idea is to dynamically allocate and merge low-rank adapters for each new task through orthogonal subspace projection, which minimizes interference between tasks. Additionally, CLoRA introduces a knowledge preservation constraint that stabilizes updates and ensures consistent performance across tasks. Extensive experiments on NLP benchmarks (e.g., GLUE, SuperGLUE, and continual text classification datasets) show that CLoRA achieves competitive or superior performance compared to existing continual learning and parameter-efficient fine-tuning methods, all while maintaining low storage costs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel problem framing:** The paper clearly articulates how continual recommendation differs from general continual learning, emphasizing the role of evolving user preferences instead of task retention. This perspective grounds the LLM-based recommendersa in realistic recommender settings.\n\n2. **Simple but Effective:** PESO avoids multiple adapters (reducing storage and interference) and introduces a lightweight proximal term that yields theoretically grounded, data-aware stability—achieving simplicity without sacrificing effectiveness.\n\n3. **theoretical foundation:** The paper provides formal analysis linking proximal regularization to direction-wise interpolation in the LoRA subspace, offering mathematical clarity about why PESO balances stability and plasticity."}, "weaknesses": {"value": "1. **Limited modeling of long-term preference dynamics：** PESO is evaluated on short-term chronological splits (four-stage Amazon data). How would it behave under nonlinear or cyclical preference drifts over long horizons? Would the single-step proximal constraint still be sufficient, or would multi-timescale or memory-based mechanisms be required?\n\n2. **Unanalyzed efficiency trade-offs.** PESO maintains previous adapter states for proximal computation. What is the actual storage and computational overhead compared with single or cumulative LoRA?\n\n3. **No explicit measurement of catastrophic forgetting:** The study reports only global Hit@K and NDCG metrics. Without tracking performance decay on past data (e.g., forgetting ratio), it is hard to disentangle whether PESO’s gains come from genuine stability or from overfitting recent tasks."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UWP7bh1H1F", "forum": "DBCNTM7mot", "replyto": "DBCNTM7mot", "signatures": ["ICLR.cc/2026/Conference/Submission8054/Reviewer_VejX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8054/Reviewer_VejX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968478141, "cdate": 1761968478141, "tmdate": 1762920045831, "mdate": 1762920045831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PESO, a new method for continually adapting LLM-based recommender systems to evolving user preferences. Traditional methods struggle by either forgetting past preferences or rigidly holding on to outdated ones. PESO addresses this by maintaining a single evolving LoRA adapter and using a proximal regularizer to anchor it to its most recent state. This design allows the model to flexibly balance adapting to new interests (plasticity) with preserving long-term preferences (stability), enabling it to better capture the dynamic nature of user behavior."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written and easy to follow, with a solid theoretical analysis for the proposed PESO.\n2. The choice of a modern, semantic ID-based generative recommendation as the experimental backbone is highly relevant and makes the results more convincing."}, "weaknesses": {"value": "1. A key weakness is the practical relevance of the problem formulation. The paper partitions data into discrete, chronological blocks to simulate a continual learning scenario. However, in real-world RS that are updated frequently (often in near real-time), the data distribution shift between consecutive updates is typically small and gradual. The paper fails to quantify the distribution shift in its experimental data splits, making it unclear if the problem it solves reflects realistic deployment conditions.\n2. In Equations 6 and 12, could you provide more details on how the parameters of LoRA are partitioned into groups, and how the number of groups G impacts the performance of PESO?\n3. The experimental results in Table 2 are missing a comparison to a standard full fine-tuning baseline."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vJhfYgeaGw", "forum": "DBCNTM7mot", "replyto": "DBCNTM7mot", "signatures": ["ICLR.cc/2026/Conference/Submission8054/Reviewer_4gyJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8054/Reviewer_4gyJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995675725, "cdate": 1761995675725, "tmdate": 1762920045119, "mdate": 1762920045119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies continual learning in LLM-based generative recommender systems. The authors argue that existing LoRA-based continual learning methods emphasize preserving past performance but overlook that recommendation requires modeling evolving user preferences rather than retaining outdated ones. To address this, they propose PESO, which maintains a single evolving LoRA adapter regularized toward its previous state. Theoretically, the authors show that the proximal term provides data-aware, direction-wise guidance in the LoRA subspace. Empirical results on Amazon datasets demonstrate consistent improvement over existing LoRA-based continual learning methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles continual learning in recommendation, a fundamental and practical problem.\n\n2. The motivation is clear, with comprehensive analysis of single vs. cumulative LoRA and their limitations in the recommendation setting.\n\n3. The theoretical justification for the proximal regularization providing data-aware, direction-wise guidance in the LoRA subspace is well presented.\n\n4. Experiments are systematic and demonstrate consistent gains over baselines."}, "weaknesses": {"value": "1. The motivation for using LoRA as the primary PEFT technique is not fully convincing. Comparison or discussion with alternatives such as prompt tuning or layer pruning is missing.\n\n2. The paper lacks discussion and comparison with recent works on continual or incremental learning for LLM-based generative recommendation [1].\n\n3. The experimental datasets lack diversity, all drawn from the Amazon Review corpus in the e-commerce domain, limiting the generalization of conclusions.\n\n4. While the theoretical formulation is elegant, the intuitive explanation of how direction-wise guidance relates to long-term versus short-term preference adaptation could be elaborated.\n\n[1] Shi et al., Preliminary Study on Incremental Learning for Large Language Model-based Recommender Systems. CIKM'24."}, "questions": {"value": "1. What are the advantages of using LoRA compared to other parameter-efficient fine-tuning methods, such as prompt tuning?\n\n2. Can the authors elaborate on the intuition of how data-aware, direction-wise guidance in the LoRA subspace helps balance long-term and evolving user preferences?\n\n3. How would the method perform in non-e-commerce or multi-domain continual recommendation scenarios?\n\n4. Is there any case studies on how the proposed method balances the long-term interests and current evolved user preferences?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cdZMYB9yqi", "forum": "DBCNTM7mot", "replyto": "DBCNTM7mot", "signatures": ["ICLR.cc/2026/Conference/Submission8054/Reviewer_PErP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8054/Reviewer_PErP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8054/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058628067, "cdate": 1762058628067, "tmdate": 1762920044495, "mdate": 1762920044495, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}