{"id": "AxhWmQBRRg", "number": 12256, "cdate": 1758206638170, "mdate": 1759897522271, "content": {"title": "Similarity and Separation of Last-Iterate Convergence between Optimism and Reflected Algorithms in Time-Varying Games", "abstract": "In this paper, we investigate the behaviours of reflected gradient (RG), accelerated reflected gradient (ARG), and optimistic gradient (OG) algorithms in multi-player games modelled as variational inequalities with $L$-smooth continuous monotone limits in convergent time-varying cases and with $L$-smooth continuous and monotone games at each time in periodic cases, both in convex action sets. The RG, ARG, and OG algorithms require fewer complex calculations, i.e., on the gradients and projections per iteration. We prove that a convergence rate of $O(1/\\sqrt{T})$ and $O(1/T)$ can be reached by the RG and ARG algorithms with bounded action sets for convergent perturbed monotone games, respectively, if the sequence of time-varying games converges to the limit fast enough, without additional assumptions like strong monotonicity, and such a result matches and improves the existing results on similar algorithms requiring calculations on two gradients with different actions. Besides, a surprising result is also shown that the standard OG algorithm in time-varying games behaves dramatically differently from its variant and other similar algorithms: the standard OG algorithm converges in any sequences of time-varying monotone $L$-smooth games with a common Nash equilibrium, including some periodic games, while at the same time, its variant with a slight difference diverges exponentially even in periodic games. We also show that the RG and ARG algorithms diverge exponentially in some periodic games.", "tldr": "", "keywords": ["time-varying games", "Nash equilibrium", "reflected gradient algorithm", "optimistic gradient algorithm"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/29c579a09b704a5435a80f9dd5f9419cc305198e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies time-varying games, where the utility function evolves over time. In particular, it considers two cases:\n- Fast-convergent perturbed games, in which the total deviation from a fixed game remains bounded, and\n- Periodic games, where multiple fixed games repeat in a periodic pattern.\nThe authors present both positive and negative results for the algorithms RG, ARG, OG, and VOG, as summarized in Table 1."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper examines a series of algorithms in this area and presents comprehensive results. \n- The presentation is clear, well-organized, and easy to follow."}, "weaknesses": {"value": "My main concern lies in the technical contribution of the results. The paper relies on the BAP assumption to address the convergent perturbed game, but the BAP assumption appear overly strong. In particular, the BAP assumption requires the accumulated deviation to remain constant, which seems unrealistically fast and renders the resulting analysis somewhat trivial.\n\nSince the accumulated deviation is bounded, the result follows directly from the classical analysis of these algorithms in fixed games, with an additional bounded error at each iteration due to the BAP assumption."}, "questions": {"value": "I believe that, to make the results complete, a lower bound on the convergence rate for the perturbed game should be considered. Specifically, let $W_T$ denote the total deviation from the fixed game over $T$ iterations (see [1]). What is the corresponding lower bound on the convergence rate? Furthermore, do the algorithms considered in the paper achieve this lower bound?\n\nI would be inclined to raise my score to accept if the authors could address these questions.\n\n[1] Anagnostides, Ioannis, et al. \"On the convergence of no-regret learning dynamics in time-varying games.\" Advances in Neural Information Processing Systems 36 (2023): 16367-16405."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xPiSJXZec7", "forum": "AxhWmQBRRg", "replyto": "AxhWmQBRRg", "signatures": ["ICLR.cc/2026/Conference/Submission12256/Reviewer_TPem"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12256/Reviewer_TPem"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761008729584, "cdate": 1761008729584, "tmdate": 1762923196246, "mdate": 1762923196246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the convergence properties of reflected gradient (RG), accelerated reflected gradient (ARG), and optimistic gradient (OG) in time-varying games including periodic games, and those that convergence fast enough according to a bounded accumulated perturbations assumption (BAP). The paper claims a convergence rate for RG and ARG in games that satisfy a BAP assumption and under bounded action sets but show that they both fail to converge in periodic games. In contrast, the OG method is shown to converge without the BAP assumption and in periodic games so long as the Lipschitz constant is bounded. Empirical simulations are also provided to verify some of the results."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper provides a somewhat unifying perspective to several algorithms of interest in the context of time-varying games. Including both negative results for RG and ARG as well as strong positive results for the OG method."}, "weaknesses": {"value": "A main weakness of the paper is its technical clarity and rigour as well lack of discussion on some technical details. The proofs are quite difficult to follow even with the proof sketches in the main body. Below I list some concerns, additional issues are listed in the questions section. \n\n**BAP** assumption\nThe paper uses the BAP assumption to quantify sufficient convergence in perturbed games. However, I've noticed that the assumption includes $\\mathcal{Z}$ is bounded meanwhile this is not used in other works such as Feng et al 2023. Furthermore, it is unclear what is meant by $\\max \\|G_t\\|$ is this supposed to mean $\\max_{z \\in \\mathcal{z}}\\|G_t(z)\\|$? I also cannot see this max in Feng et al 2023 nore in the cited works for the BAP condition. Finally, at several points in the paper the following claim is made:\n\n> Assumption 1 (BAP) implies $\\max\\|G_t\\| = O(\\frac{1}{t})$\n\nThis is used in line 1206 in Theorem 2 and line 1604 in Theorem 4. I do not see how the BAP summability assumption ($\\sum_{t}\\max\\|G_t\\| < \\infty$) implies a rate on the last term in the series, in general I think we need more information on the convergence rate.\n\n**BAP** assumption in Section 4.2\nOn top of the BAP assumption Theorem 4 assume the stronger condition $\\sum_{t=0}^\\infty t^2\\|G_t\\|< +\\infty$ but there is no discussion why we need this stronger assumption in the ARG case. Intuition or identifying technical challenges on why this case merits a stronger assumption would be helpful to understand the result in the broader context of the paper and existing work.\n\n**Bounded action sets**\nAll the convergence results (except maybe OG) require bounded action sets yet the divergence negative periodic game results are in the unbounded setting. Discussion on why bounded sets are necessary would be helpful especially when existing works such as Feng et al 2023 do not assume a bounded domain. How would the periodic results change if we were to assume a bounded domain? Additionally, the convergence proofs seem to heavily depend on the bounded domain whereas existing works do not need it, a discussion on this difference and potential limitations of the analysis could be helpful.\n\n**Missing steps and typos** There are quite a few missing steps and typos in the proofs. Please see the question section for more details"}, "questions": {"value": "- line 1199 to line 1201 can be expanded with an extra step\n- it is unclear where Lemma 6 is invoked in Theorem 2 is it used for line 1209? adding pointers to when lemmas would be helpful\n- The transition from equation (51) to equation (52) is not clear\n- Where does the inequality in equation (120) come from?\n- Weak monotonicity i.e. $\\rho$ in Theorems 4-6 are introduced without being discussed in the paper. This assumption/relaxation and its significance  should be included in the background/discussion.\n- Where does the VOG algorithm come from (variant of OG)? Is there a reference? In the description of VOG in Theorem 5 seems to suggest that VOG is a proximal like algorithm since $z_{t+1}$ depends on $F_{t+1}$, is this the case?\n- Feng et al 2023 shows convergence for EG in the periodic case yet Table 1 seems to suggest that this result is still open. My understanding is that the paper studies both EG and PEG. \n- on line 136 it is mentioned that bilinear games are not strictly monotone but in general I  do not think it is true that $\\langle F(z_1)-F(z_2), z_1-z_2 \\rangle =0$?\n- BAP assumption is mentioned on line 141 but only introduced later\n- $\\mathcal{Z}^{(i)}$ never defined before used in section 2.3\n- there seems to be a typo for equations 28 and 27, both are the same?\n- In the proof of Lemma 2 why do we have $G_t(z^\\star) =0$? A common Nash equilibrium doesn't imply $F_t(z^\\star) = F_{\\infty}(z^\\star)$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tMYpDA5oL8", "forum": "AxhWmQBRRg", "replyto": "AxhWmQBRRg", "signatures": ["ICLR.cc/2026/Conference/Submission12256/Reviewer_7azo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12256/Reviewer_7azo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761148018242, "cdate": 1761148018242, "tmdate": 1762923195665, "mdate": 1762923195665, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the convergence properties of several first-order algorithms, specifically Reflected Gradient (RG), Accelerated Reflected Gradient (ARG), and Optimistic Gradient (OG), in the context of multi-player, time-varying monotone games. The authors analyze two distinct time-varying settings: (1) periodic games, where the game's cost functions repeat with a fixed period, and (2) fast convergent perturbed games, where the game converges to a limit $F_{\\infty}$ and the perturbation satisfies a Bounded Accumulated Perturbations (BAP) assumption.\n\nThe paper's core contribution is a \"separation\" of behaviors between these algorithms:\n\n- Convergent Perturbed (BAP) Case: The RG and ARG algorithms are shown to be robust to this type of perturbation. The paper proves last-iterate convergence rates of $O(1/\\sqrt{T})$ for RG (Theorem 2) and an optimal $O(1/T)$ for ARG (Theorem 4), assuming the perturbation converges sufficiently fast.\n- Periodic Case: In sharp contrast, the paper provides counterexamples showing that both RG (Theorem 1) and ARG (Theorem 3) can diverge exponentially in periodic games.\n- In addition, the standard OG algorithm is proven to be robust in both settings, achieving a best-iterate convergence rate of $O(1/\\sqrt{T})$ in time-varying games with a common Nash equilibrium, which includes the periodic case (Theorem 6). However, a slight variant of OG (VOG) is shown to fail."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- One strength of this paper is the separation it identifies, which is the exponential divergence of RG and ARG in periodic games (Theorems 1 and 3).\n- The paper also shows several positive results for the convergent perturbed (BAP) case, including a $O(1/\\sqrt{T})$ last-iterate rate for RG (Theorem 2) and an optimal $O(1/T)$ last-iterate rate for ARG (Theorem 4) in this time-varying setting.\n- In addition, the authors also show that the robustness of the standard OG algorithm to periodic games (Theorem 6). This contrasts sharply with the failure of PEG/OGDA in periodic games (as cited from Feng et al. (2023)) and the failure of the VOG variant shown in this paper (Theorem 5)."}, "weaknesses": {"value": "- The positive results for the OG algorithm in periodic games (Theorem 6) and the analysis for the BAP case (Lemma 2) rely on the assumption of a common Nash equilibrium $z^*$ for all games $F_t$. This assumption seems to be strong and counter-intuitive for a time-varying game. The paper motivates periodic games by citing ``seasonal changes or market competitions'', but in such scenarios, one would expect the equilibrium itself to be periodic, not static. This assumption severely limits the practical implications and generality of the paper's key positive result (Theorem 6).\n- In addition, the optimal $O(1/T)$ rate for ARG (Theorem 4) requires the perturbation $G_t$ to converge very rapidly, specifically $\\sum_{t=0}^{\\infty}t^{2}||G_{t}||<\\infty$. This is even stronger than the standard BAP assumption (Assumption 1, which is $\\sum_{t=0}^{\\infty} \\max ||G_t|| < \\infty$). While the paper shows the rate degrades to $O(1/\\sqrt{T})$ under the weaker Assumption 1, the $O(1/T)$ optimal rate relies on this impractical, convergence condition.\n- The \"variant of OG\" (VOG) is introduced as a foil to the standard OG algorithm. However, its definition and motivation are confusing. Theorem 5 states it is created by modifying Line 5 of Algorithm 3 to use $F_{t+1}$ instead of $F_t$. Algorithm 3 (OG) uses $F_t$ to compute both $z_{t+1/2}$ (Line 4) and $z_{t+1}$ (Line 5). The modification $z_{t+1} = z_{t+1/2} + \\eta F_{t+1}(z_{t-1/2}) - \\eta F_{t+1}(z_{t+1/2})$ (based on and Algorithm 3) appears to require oracle access to the gradient function $F_{t+1}$ at time $t$. It is not clear to me why this is a \"natural variant\" to study, as it seems to break the assumptions of online learning.\n- While the paper is technically dense, the reliance on proof sketches and deferrals to the appendix for all details makes the core technical arguments difficult to fully assess. It would be better to include explanations/intuitions on the proofs of Theorem 4/5/6 in the main text."}, "questions": {"value": "Besides the question in the Weakness section:\n- Could the authors please clarify the definition and motivation for the VOG algorithm (Theorem 5)? The use of $F_{t+1}$ in the update rule seems to require an oracle for the next time step's gradient function.\n- The $O(1/T)$ rate for ARG requires $\\sum t^2 ||G_t|| < \\infty$. Is this assumption necessary, or is it an artifact of the proof technique (e.g., the potential function $V_t$ in Eq. 70)? Is there any evidence to suggest that the $O(1/T)$ rate is impossible under the standard BAP assumption (Assumption 1)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CqhzKV6NTz", "forum": "AxhWmQBRRg", "replyto": "AxhWmQBRRg", "signatures": ["ICLR.cc/2026/Conference/Submission12256/Reviewer_8ohC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12256/Reviewer_8ohC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974229670, "cdate": 1761974229670, "tmdate": 1762923195192, "mdate": 1762923195192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the Reflected Gradient, Accelerated Reflected Gradient, and Optimistic Gradient algorithms in L-smooth time-varying monotone games. It establishes a surprising separation: while RG and ARG achieve strong convergence rates in fast-converging perturbed games, they both diverge exponentially in periodic games. In sharp contrast, the standard OG algorithm is robust and converges (O (1/\\sqrt{T})) in periodic games, while a minor variant of it diverges."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Theoretical: The core finding of the paper is the \"surprising\" separation in convergence behaviors. It demonstrates that while standard OG converges in periodic time-varying games, the closely related RG, ARG, and even a slight variant of OG (VOG) all diverge exponentially. This is a novel and important insight into the specific properties that enable convergence in non-stationary environments.\n 2. Empirical: The theoretical claims are illustrated and verified by Section I, that directly test the divergence and convergence predictions of all six theorems.\n 3. Clarity: The paper is exceptionally well-written. It clearly motivates the problem â€” less computational cost, defines the gap it aims to fill, and summarizes its findings effectively in the introduction and in Table 1."}, "weaknesses": {"value": "I have the following main concerns: \n 1. Weak Motivation for the VOG Variant: The paper introduces VOG algorithm primarily to show it diverges, highlighting the specificity of the standard OG's success. However, the paper provides little motivation for why this specific variant is a \"natural\" one to consider. The finding is further diluted by the proof's demonstration that this VOG is equivalent to the RG algorithm in bilinear games, which was already shown to diverge (Theorem 1).\n 2. Strong Assumption for OG Robustness: The celebrated robustness of the standard OG algorithm (Theorem 6) is proven only under the assumption that the sequence of time-varying games shares a common Nash equilibrium. This is a significant limitation, as many realistic periodic or time-varying games would likely feature an equilibrium that also varies with time.\n\nI might miss some key points, please correct me if anything has been misunderstood."}, "questions": {"value": "1. Could you elaborate on the choice of the VOG algorithm (Theorem 5)? \n\n2. It is proved a best-iterate rate for OG (Theorem 6) and list last-iterate convergence as future work. Do you have any intuition as to whether standard OG achieves last-iterate convergence in the periodic setting?\n\n3. The robustness of the standard OG algorithm (Theorem 6) is shown under the strong assumption of a common Nash equilibrium across all time-varying games. This seems quite restrictive for general periodic or time-varying scenarios. Could the convergence guarantee of OG be extended to the more general setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a2ivRpXOfr", "forum": "AxhWmQBRRg", "replyto": "AxhWmQBRRg", "signatures": ["ICLR.cc/2026/Conference/Submission12256/Reviewer_i3wz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12256/Reviewer_i3wz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996915497, "cdate": 1761996915497, "tmdate": 1762923194423, "mdate": 1762923194423, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}