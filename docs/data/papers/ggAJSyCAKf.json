{"id": "ggAJSyCAKf", "number": 8947, "cdate": 1758103554145, "mdate": 1759897752352, "content": {"title": "ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?", "abstract": "We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios,  curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22\\% for GPT-5, 3.92\\% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.", "tldr": "", "keywords": ["deep research", "agent", "web search", "benchmark", "LLM real-world utility", "s ecurity", "report evaluation", "rubric"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/65166cc3ca6b71f2ae2b26e5c177d79a4e38ab50.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Overall, I think the paper is good for writing and I have been enjoyed reading it. My judgement is that the paper might not meet the high standard of the papers at ICLR level."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "A very good written paper"}, "weaknesses": {"value": "Actually the topic of this paper is in my research area. I have kind of feeling that the paper did not meet the quality as a ICLR paper."}, "questions": {"value": "Would suggest authors do more in-depth analysis. Current one is too short and too shallow."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fi0aFWUuGH", "forum": "ggAJSyCAKf", "replyto": "ggAJSyCAKf", "signatures": ["ICLR.cc/2026/Conference/Submission8947/Reviewer_JBSD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8947/Reviewer_JBSD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8947/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964449524, "cdate": 1761964449524, "tmdate": 1762920687033, "mdate": 1762920687033, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a benchmark for evaluating the performance of LLM-driven shopping agents in real scenarios. It specifically evaluates the LLM's product retrieval ability, expert-level report generation ability, and the reliability of making safe decisions. In terms of evaluation dimensions, it expands on existing work's precise product retrieval and report generation quality by adding a new evaluation dimension for product safety assessment. Experiments on numerous tasks and scenarios reveal the performance limitations of various LLMs in real application scenarios and their discrepancies with human results. This research is interesting and valuable, providing a realistic and verifiable benchmark for evaluating e-commerce LLM agents."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This research is interesting and valuable. The authors propose a benchmark for evaluating LLM-driven shopping agents in real tasks and scenarios, which is no longer limited to academic benchmarks but focuses more on users' actual needs and shopping experience. This provides a real application direction and reference for related research fields.\n2. Besides evaluating the LLM agent's product retrieval ability and report generation quality, the authors have also expanded with a safety decision reliability evaluation. It evaluates whether the products recommended by the LLM agent have safety hazards and false information, and assesses whether the LLM can accurately filter these non-safe products. This is also a key concern for users. The introduction of this evaluation metric also enhances the benchmark's evaluation completeness.\n3. A new report evaluation metric has been proposed, enhancing the reliability of assessments in real-world scenarios.\n4. Experiments reveal the performance differences of LLM-driven shopping agents between academic benchmarks and real scenarios, as well as the persistent lag behind human performance. This also provides valuable insights and considerations for the practical deployment of LLM agents.\n5. The article's presentation is good and smooth. The introduction of the problem, analysis of related works, data collection, and experimental design are relatively clear."}, "weaknesses": {"value": "1. There is a lack of introduction about the proposed benchmark containing 120 tasks and 1026 real scenarios, how this benchmark is composed, and how it is organized in subsequent testing. This point is not clearly explained.\n2. The description of the data collection process in Section 3.2 is insufficient. Readers cannot understand the specific format and presentation of the data. Examples should be provided, for instance in the form of figures or tables. These can be provided in supplementary materials.\n3. The same problem appears in Section 3.3. This section introduces two LLM verifiers used to check whether products meet specific scenarios. How exactly the checking is done, and what the fulfillment criteria are, lack detailed introduction. It is recommended to provide a detailed introduction to facilitate reader understanding."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bUyZz7RfSv", "forum": "ggAJSyCAKf", "replyto": "ggAJSyCAKf", "signatures": ["ICLR.cc/2026/Conference/Submission8947/Reviewer_dMUb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8947/Reviewer_dMUb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8947/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966386303, "cdate": 1761966386303, "tmdate": 1762920686665, "mdate": 1762920686665, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ShoppingComp, a new benchmark for evaluating LLM-powered shopping agents. Its core contribution lies in the comprehensive evaluation of three key capabilities within a unified, open-web framework: 1) accurate product retrieval grounded in complex, real-world user requirements; 2) the quality of verifiable report generation, assessed against a detailed rubric; and 3) safety-critical decision-making in scenarios involving potential risks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a well-designed and highly challenging benchmark. Its preliminary findings provide valuable insights into the real-world limitations of current Large Language Models (LLMs), making a timely contribution to the field of agent evaluation."}, "weaknesses": {"value": "1.The primary contribution leans more towards empirical findings rather than methodological innovation. \n2.The Y-axis in Figure 4 lacks a clear label, which hinders the interpretation of the chart.\n3.There is an inconsistency in the reported performance for GPT-5. The \"Conclusion and Future Work\" section states it \"reaches only 19.6%\", which appears to conflict with the data presented in Table 2. Please clarify or correct this discrepancy."}, "questions": {"value": "1.Regarding the model's failures in safety-critical decision-making, could these be attributed to specific knowledge gaps in its pre-training data? \n2. The paper commendably reports that the Report Verifier has only a 75.6% agreement rate with human annotators. This implies that nearly a quarter of the judgments in the report quality evaluation could be inaccurate. Could this level of uncertainty significantly affect the final ranking of the models and the validity of the conclusions drawn about their report generation capabilities?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "A4tFVGPPMC", "forum": "ggAJSyCAKf", "replyto": "ggAJSyCAKf", "signatures": ["ICLR.cc/2026/Conference/Submission8947/Reviewer_RBMc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8947/Reviewer_RBMc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8947/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762178312788, "cdate": 1762178312788, "tmdate": 1762920686210, "mdate": 1762920686210, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ShoppingComp, a practical benchmark for evaluating LLM-based shopping agents along three axes: (i) Browse Products, (ii) Expert-level Report Generation, and (iii) Safety-Critical Decision Making. The benchmark contains 120 tasks and 1,026 scenarios.\nThe evaluation of this benchmark uses LLM-as-a-Judge (e.g., Gemini-2.5-Pro), and the results show that LLM-based agents have large gaps to humans (e.g., GPT-5 AnswerMatch-F1 11.22% vs expert 25.73%).\nThis paper focuses on a practical application scenario of LLM-based agents, but it misses many details of data collection and categorization. This makes the paper less suitable for the dataset/benchmark area and more like a study that reveals problems and gaps."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Interesting and practical topic. This paper focuses on a valuable and interesting application scenario, namely, LLM-based shopping agents.\n2. Empirical takeaways from the experiments. The paper conducts large-scale experiments to highlight the bottlenecks of LLM-based agents in real-world deployment.\n3. Well-defined scoring dimensions. The scoring includes three parts of evaluation metrics, which provide a comprehensive foundation for future research."}, "weaknesses": {"value": "1. Dataset accessibility and details. The paper promises future open-sourcing but provides no current release, subset, or several appendix samples; this undermines claims of reproducibility for a benchmark/dataset paper.\n2. Potential evaluation bias risk. Gemini-2.5-Pro is used as both the LLM evaluator and the evaluation target, raising potential bias concerns (existing research has revealed that LLM evaluators would prefer the results generated by themselves)\n3. Poor organization. As a dataset/benchmark paper, this paper spends less than 1.5 pages on the dataset construction and omits many details directly related to the fairness and reliability of the dataset.\n4. Missing References, e.g., [1].\n5. Potential copyright issue. The authors directly use real-world product images and even links. One of the concerns is the author's data sources, the licenses obtained, and whether there are any copyright risks."}, "questions": {"value": "1. Missing Dataset Details:\n   1. The authors claim they spent at least 4,000 person-hours building the dataset, but the dataset is neither open-source nor included in supplementary materials, and even a portion of their dataset is not shown in the appendix. Worse still, one of the highlights, safety questions/safety traps (e.g., in Table 1), lacks details. What types of safety traps are included? Are they designed based on existing work or just from ad-hoc ideas? Do safety traps include common dark patterns in shopping (e.g., concealing key parameters in product descriptions, using keywords easily confused with other popular products, etc.)?\n   2. Where are the `real e-commerce queries` analyzed in the user questions from (Line 230)? How are `diverse, purpose-driven user prompts` synthesized? Could this process introduce bias? \n   3. Line 239: What is the criterion of an `overly easy question`?\n   4. Line 269 mentions `high-value categories such as home appliances, electronics...`. After searching with these keywords, I realize that the authors have not mentioned how many categories this paper includes, nor the meaning and scope of the categories, like `home appliances`. Furthermore, which categories are high-value? Which are low-value?\n   5. Too many details about the dataset remain unknown. These details are crucial for understanding potential copyright, bias, and other issues related to the benchmark. Even if the main text cannot accommodate them, this content should at least be included in supplementary materials or an appendix.\n2. In real-world shopping, there may be multiple products that meet the users' requirements. Does the dataset include this situation? How to determine the ground truth in this situation?\n3. Evaluation Risks: Section 4.1.2 mentions that this paper uses LLM-as-a-judge to evaluate the quality of product recommendation reports. Is the Gemini-2.5-Pro ​model ​used here? Does this model also appear as an evaluation object in Table 2? Existing research has shown that LLM-as-a-judge is more likely to give its own generated content a high score [1]. One concern is that such an evaluation setting may introduce bias and reduce the reliability of the observation results.\n4. Missing Reference: What are the differences compared to the Product Comparison Dataset for Online Shopping dataset [2] in the same field? Does this paper use the data samples from this dataset?\n5. Potential Copyright Risks: The authors directly used real-world product images and even links (as shown in Fig. 2). One concern is the authors' data sources. Did the authors obtain permission from the data sources (and what kind of permission), and are copyright risks involved in this paper?\n\n\n[1] Llm evaluators recognize and favor their own generations. Advances in Neural Information Processing Systems. 2024.\n\n[2] Generating explainable product comparisons for online shopping. Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. 2023."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YQyMZN3weD", "forum": "ggAJSyCAKf", "replyto": "ggAJSyCAKf", "signatures": ["ICLR.cc/2026/Conference/Submission8947/Reviewer_QH8m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8947/Reviewer_QH8m"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8947/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762181184598, "cdate": 1762181184598, "tmdate": 1762920685657, "mdate": 1762920685657, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a large data set they compiled to evaluate LLMs for several online shopping tasks, such as product retrieval, safety-related recommendation, scenario coverage, etc. They describe some of the tasks and how the data was collected and curated, and provide initial evaluation of several strong LLM baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Very relevant and timely problem being considered.\n- Large data set curated and to be publicly release.\n- Interesting new tasks considered, especially around safety.\n- Promising results shown, and some interesting patterns uncovered."}, "weaknesses": {"value": "- Very poorly written at times, too high level.\n- Handwavy explanations, reads like a quick summary without actual deep explanations.\n- Evaluation is also high-level and handwavy, without examples to help understand the data the tasks in a deeper manner."}, "questions": {"value": "- Figures 1 and 5 are never referenced in the text.\n- Many of the explanations are very high-level, without clarifying examples and case studies. E.g., line 88, \"typically express needs in ...\", some examples would help immensely. This lack of clear and reasonable examples repeats throughout the work.\n- Are there any X's in Table 1? When such tables with checkmarks are provided, it is always important to see what are the downsides.\n- The authors provide some examples of the data, but at an insufficient level. More discussion around the data and how it looks like should be added.\n- In addition, data statistics are insufficiently discussed.\n- Line 124, what do these number mean, on what data, on what task? Very unclear.\n- Similarly, examples or deeper discussion missing in lines 234, and in 239.\n- Also in line 250.\n- The results in this paragraph are just given, without deeper discussion, making it very difficult to appreciate the results.\n- Line 254, \"the verifier evaluates report quality against ...\", how exactly? Very vague.\n- Line 442, \"three patterns emerge\", some examples?\n\nOverall, the work is written at just a too high a level, without an attempt to actually help the readers understand what is the data actually being used. It reads as a brief and a high-level summary, that might be sufficient for a webpage for example, but far from sufficient for a venue such as ICLR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xUc8k89LVW", "forum": "ggAJSyCAKf", "replyto": "ggAJSyCAKf", "signatures": ["ICLR.cc/2026/Conference/Submission8947/Reviewer_u67A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8947/Reviewer_u67A"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8947/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762225492877, "cdate": 1762225492877, "tmdate": 1762920685238, "mdate": 1762920685238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}