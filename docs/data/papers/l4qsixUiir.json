{"id": "l4qsixUiir", "number": 22181, "cdate": 1758327290154, "mdate": 1759896881943, "content": {"title": "Online Continual Learning for Time Series: a Natural Score-driven Approach", "abstract": "Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student’s t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.", "tldr": "", "keywords": ["Online Time Series Forecasting", "Online Continual Learning", "Score-driven Models"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d70c088a86698db3360b9c81f49525f5ed017c83.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper builds the connection between natural gradient descent and the score-driven model, or the generalized autoregressive score (GAS) model. It shows that natural gradient descent is a score-driven model and proves its information-theoretica optimality. To improve robustness to outliers, it introduces the student’s likelihood and shows the bounded update. It is further combined with a replay buffer and a dynamic scale heuristic called natural score-driven replay (NatSR). Overall, limited experiments are performed to test the proposed algorithm."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThis paper is a theoretical paper. The biggest contribution of this paper is that it reveals the connection between natural gradient descent and the score-driven model, or the generalized autoregressive score (GAS) model. From this connection, the student’s likelihood and a replay buffer are introduced, leading to a a dynamic scale heuristic called natural score-driven replay (NatSR). From theoretical perspective, this paper is a good addition to the time series community."}, "weaknesses": {"value": "1.\tExcept the theoretical results, the paper looks weak, especially its practical value in real-world applications. For example, the experiments are quite limited, with limited data, limited baselines and only one metric. Only MASE is reported. It is suggested to report RMSE and MAPE as well. In particular, on some datasets (ECL and Traffic), the performance of the proposed method is much worse than other baselines. I am not sure if the current experiments can justify the publication of this paper."}, "questions": {"value": "1. Can you expand the experiments, including more SOTA baselines, more evaluation metrics, and more datasets. Given the current experimental results, it is fairly hard to me to justify the publication of this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IEnt6RS2by", "forum": "l4qsixUiir", "replyto": "l4qsixUiir", "signatures": ["ICLR.cc/2026/Conference/Submission22181/Reviewer_Nj1d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22181/Reviewer_Nj1d"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954377754, "cdate": 1761954377754, "tmdate": 1762942105268, "mdate": 1762942105268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Natural Score-driven Replay (NatSR), a novel method for Online Continual Learning (OCL) applied to Time Series Forecasting (OTSF). The core idea is to bridge concepts from econometrics (score-driven models) and optimization (natural gradient descent) to create a more robust and theoretically grounded online learner. It also integrates this with an experience replay buffer, resulting in a practical OCL algorithm that achieves competitive performance on several real-world time series datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**Originality:** The conceptual link between natural gradient descent and score-driven models is a significant and novel insight. It provides a fresh, unifying perspective on online optimization.\n\n**Clarity:** Despite the technical density in some sections, the core ideas are effectively communicated. The abstract and introduction succinctly outline the contributions, and the experiments are clearly described.\n\n**Significance:** The paper tackles a fundamental problem (online learning in non-stationary environments) with a method that is both principled and practical. Its strong performance on real-world data, without requiring specialized architectures, makes it a valuable contribution for the broader ICLR community interested in robust and adaptive machine learning."}, "weaknesses": {"value": "**Presentation:** Some parts, particularly in Sections 4.2 and 4.3, are quite dense and could be challenging for a reader not deeply familiar with both information geometry and score-driven models. A little more high-level intuition before diving into the equations would improve accessibility. The pseudocode in Appendix D is helpful but could be more clearly annotated.\n\n**Performance on High-Dynamics Datasets:** The method underperforms on the ECL and Traffic datasets, which the authors attribute to a need for more plasticity. While this is a fair observation, it highlights a limitation: the conservatism induced by the robustness guarantee can be a drawback in certain environments. The paper would be strengthened by a deeper analysis or a more adaptive mechanism for this trade-off, perhaps beyond the NatSR_fast variant mentioned in the appendix.\n\n**Theoretical Assumptions:** The theoretical optimality results (Propositions 4.1 and 4.2) rely on assumptions like the Bi-Lipschitz condition (A4). A discussion on how realistic these assumptions are for deep neural networks in practice would add nuance to the theoretical contributions."}, "questions": {"value": "- The heuristic for updating the FIM (only on the worst 1% of losses) is pragmatic but somewhat divorced from the core theory. How sensitive are the results to this heuristic (e.g., the 1% threshold)? Was there any exploration of more theoretically motivated triggers, such as those based on the norm of the score or detected regime shifts?\n\n- The bounded update property is reminiscent of proximal methods or gradient clipping. Could the authors provide more discussion or a small experiment comparing the type of robustness achieved by NatSR versus a carefully tuned proximal method or a simple combination of AdamW with gradient clipping and a Student's t-loss?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Jzi5w3ygvz", "forum": "l4qsixUiir", "replyto": "l4qsixUiir", "signatures": ["ICLR.cc/2026/Conference/Submission22181/Reviewer_xQJz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22181/Reviewer_xQJz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969207772, "cdate": 1761969207772, "tmdate": 1762942104079, "mdate": 1762942104079, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies online continual learning (OCL) for time-series prediction. First, it analyzes neural network optimization from a score-driven parameter filtering perspective. Next, it uses a Student-t likelihood to bound update norms for robustness. Finally, it proposes NatSR, which combines natural gradient descent, a replay buffer, and a dynamic scale heuristic."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an important and practical OCL setting in time-series prediction—requiring high plasticity to adapt while maintaining high stability to avoid forgetting.\n2. The analysis of natural gradient descent from a score-driven filtering perspective is reasonable and original.\n3.  The proposed method is simple and useful, combining natural gradients, replay, and a dynamic scale heuristic in a coherent recipe."}, "weaknesses": {"value": "1. Baselines are limited to rehearsal-style OCL. There are additional families relevant to OCL in time series: Error-feedback methods (e.g., online model adaptation, Extended Kalman Filter) and feedforward adaptation approaches that pair memory buffers with sample selection and tailored optimization [1]. Regularization-based continual learning methods to mitigate catastrophic forgetting [2]. Including these baselines (or carefully justifying their omission) would strengthen the empirical\n2. The neural backbone is no longer state-of-the-art or standard in current time-series forecasting. Since the backbone strongly affects performance, results on stronger models would be more convincing (e.g.,  [3,4]).\n3. The proposed second-order updates can add overhead. It would be useful to report time/space costs for NatSR and baselines.\n4. The rationale for key hyperparameters is unclear. Please provide ablation/sensitivity for $k, \\tau, \\nu$, and buffer size.\n5. Minor. Recent work studies unified/foundation time series prediction models [5]. Please discuss when OCL is preferable compared to training a large time-series foundation model and deploying it frozen. What benefits does OCL offer in deployment?\n\n[1] Abuduweili, Abulikemu, and Changliu Liu. \"Online model adaptation with feedforward compensation.\" Conference on Robot Learning. PMLR, 2023.  \n[2] Zhao, Xuyang, et al. \"A statistical theory of regularization-based continual learning.\" arXiv preprint arXiv:2406.06213 (2024).  \n[3] Zeng, Ailing, et al. \"Are transformers effective for time series forecasting?.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 9. 2023.  \n[4] Lin, Shengsheng, et al. \"Cyclenet: Enhancing time series forecasting through modeling periodic patterns.\" Advances in Neural Information Processing Systems 37 (2024): 106315-106345.  \n[5] Woo, Gerald, et al. \"Unified training of universal time series forecasting transformers.\" (2024): 53140."}, "questions": {"value": "1. Could you add feedback/feedforward and regularization-based baselines, or provide a clear rationale if not feasible?\n2. Could you evaluate on a stronger backbone (e.g., Patch/Transformer-style, periodic models) to test NatSR’s generality?\n3. What is the time and memory cost of NatSR vs. baselines during the online phase?\n4. Please report hyperparameter sensitivity for  $k, \\tau, \\nu$, and buffer size.\n5. How do you justify OCL relative to unified/foundation time-series models? When is OCL the better choice"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nRflCpfyJF", "forum": "l4qsixUiir", "replyto": "l4qsixUiir", "signatures": ["ICLR.cc/2026/Conference/Submission22181/Reviewer_ALYR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22181/Reviewer_ALYR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145653052, "cdate": 1762145653052, "tmdate": 1762942103656, "mdate": 1762942103656, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Natural Score-Driven Replay (NatSR), a new method for online continual learning (OCL) applied to time series forecasting (OTSF). The key insight is to reinterpret natural gradient descent as a score-driven filtering process, linking it theoretically to Generalized Autoregressive Score (GAS) models from econometrics. The authors then discuss the proposed method with theoretical justifications.  The authors also use empirical experiments to show the performance improvement over the existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The connection between natural gradient descent and score-driven models is interesting and seems new in time series forecasting literature. \n\n2. Consistent gains over strong baselines on several datasets; the ablation study supports the claims.\n\n3. Sample code is provided to help the reviewer verify the results independently."}, "weaknesses": {"value": "1. The writing could be improved. For example, the main algorithm, which, from my perspective, is one of the most important parts of this work, is deferred to the appendix. Moreover, it would be better to clearly include a separate section or use bullet points to state the major contributions.\n\n2. The numerical experiments are limited to end-to-end trained models. The current experimental settings largely follow Pham et al. (2023)\nand Wen et al. (2023). The small models are end-to-end trained on each single dataset. Recently, various pretrained time-series foundation models (e.g., models in GIFT-EVAL benchmark) provided even stronger baselines than those end-to-end models. It would be better extend the current algorithm into fine-tuning pretrained time-series foundation models."}, "questions": {"value": "Please see the weakness part.\n\nAt the current stage, I consider this paper borderline, though I lean toward recommending acceptance. I remain open to re-evaluating my assessment after further discussions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "mBVtmOmZOt", "forum": "l4qsixUiir", "replyto": "l4qsixUiir", "signatures": ["ICLR.cc/2026/Conference/Submission22181/Reviewer_Pftj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22181/Reviewer_Pftj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762762254038, "cdate": 1762762254038, "tmdate": 1762942103422, "mdate": 1762942103422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}