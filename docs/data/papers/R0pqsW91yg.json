{"id": "R0pqsW91yg", "number": 20427, "cdate": 1758305988526, "mdate": 1759896978080, "content": {"title": "No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models", "abstract": "Efficient training strategies for large-scale diffusion models have recently emphasized the importance of improving discriminative feature representations in these models. A central line of work in this direction is representation alignment with features obtained from powerful external encoders, which improves the representation quality as assessed through *linear probing*. Alignment-based approaches show promise but depend on large pretrained encoders, which are computationally expensive to obtain. In this work, we propose an alternative regularization for training, based on promoting the **L**inear **SEP**arability (LSEP) of intermediate layer representations. LSEP eliminates the need for an auxiliary encoder and representation alignment, while incorporating linear probing directly into the network’s learning dynamics rather than treating it as a simple post-hoc evaluation tool. Our results demonstrate substantial improvements in both training efficiency and generation quality on flow-based transformer architectures such as SiTs, achieving an FID of 1.46 on $256 \\times 256$ ImageNet dataset.", "tldr": "", "keywords": ["Diffusion models", "Representation Learning", "Linear Separability"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a188622c27a4546875357f14989e38eb57bac1d2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents Linear Separability (LSEP), a regularization strategy for diffusion transformers which explicitly encourages linearly separable representations without external alignment. The high-level idea is to jointly train a linear probe with the denoising objective thereby enhancing feature separability in the early layer. The authors introduce three design components (1) classification specific conditioning, (2) random cropping for patch-level separability, and (3) time-dependent loss weighting. Experiments on SiT models show that LSEP improves both training speed and generation quality achieving comparable results to alignment-based methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed training framework is simple yet efficient, achieving both faster convergence and improved generation quality without relying on external modules.\n\n- The paper is well-written and easy to follow. The motivation and ideas are clearly articulated, figures and visualizations make the concepts easy to understand.\n\n- The ablation studies on each design components are well-designed and detailed which effectively validates each design choice."}, "weaknesses": {"value": "- The study mainly focus on linear probing as the main indicator of representational quality. It is unclear whether this approach generalizes beyond class-labeled settings (e.g., text-to-image or video generation). It would be helpful to discuss how linear separability could be defined or leveraged in such contexts.\n\n- Although linear separability is a useful cue, good linear separation does not necessarily imply better representation. The setup therefore feels somewhat constrained and overly tied to the classification context. When combined with REPA (Table 2 and Figure 7), it achieves much higher performance and clearer separability, showing that linear probing alone does not fully explain the improvements in generation quality.\n\n- The rationale for selecting the weighting parameter $\\omega_{\\text{class}}$ is not well explained. Its value (e.g., 0.03) appears empirically chosen; an ablation study or sensitivity analysis would strengthen this aspect.  \n\n- Higher resolution (e.g., 512x512) experiments would help demonstrate scalability."}, "questions": {"value": "- The linear probe module is already conditioned on timestep embeddings. Could the authors elaborate on why additional time-dependent weight is still necessary? While Table 1 shows empirical improvements, a deeper explanation of its role would be helpful.  \n\n- The authors mention that LSEP continues to improve and approaches REPA. Does this trend persist with longer training (e.g., beyond 4M steps)?\n\n-  All experiments are conducted only on SiTs. Is this also applicable to DiTs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yCVlGkISrG", "forum": "R0pqsW91yg", "replyto": "R0pqsW91yg", "signatures": ["ICLR.cc/2026/Conference/Submission20427/Reviewer_bpbB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20427/Reviewer_bpbB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809180879, "cdate": 1761809180879, "tmdate": 1762933868964, "mdate": 1762933868964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a regularization method, Linear SEParability (LSEP), to improve the training efficiency and generation quality of diffusion models, without relying on external pre-trained encoders.\n\nThe idea is to incorporate a linear classifier, inspired by linear probing in post-hoc evaluation, directly into diffusion training as an auxiliary objective, encouraging the model to learn more linearly separable intermediate representations. The approach is straightforward but also includes several specific training strategies and hyper-parameter choices.\n\nExperiments on the ImageNet 256x256 dataset show that LSEP accelerates convergence and improves final performance across various model sizes of SiT using the original SD-VAE. It also demonstrates a synergistic effect when combined with existing alignment-based methods like REPA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper's primary strength lies in its novel and straightforward idea: a linear classifier can directly be an effective training regularizer. This provides a new, simple alternative to the dominant paradigm of external representation alignment.\n- Although the idea of supervised training is simple, several tricks like patch-level random cropping are clever and effective.\n- The empirical results are convincing. The method demonstrates consistent improvements over baselines. The finding that LSEP and REPA are complementary is also valuable."}, "weaknesses": {"value": "- Training cost: The paper claims improvements in training efficiency, demonstrated by training iterations vs. FID scores.\n  - However, the proposed method appears to require two separate forward passes through the first few layers, as the two branches require different class-conditioning (Figure 1, Section 3.2).\n  - This could introduce significant computational overhead, potentially doubling the cost for a portion of the model, and this overhead is not discussed. A wall-clock time (or compute) vs. FID plot would be helpful.\n- On linear separability: The paper is motivated by a claim that enhancing linear separability is the mechanism driving the improvements in generation. However, evidence for this link is sparse.\n  - The main results in Table 1 do not report the linear probing accuracy for each configuration, making it impossible to directly correlate the degree of separability with the final FID. If we plot the (acc, FID) points for all 21 configurations in Table 1, will it demonstrate a clear, strong correlation?\n  - In Table 2, it is also unclear how REPA and LSEP independently (and jointly) improve linear separability.\n  - While Figure 4(a) shows an increase in accuracy, the absolute value remains relatively low (below 60%, much weaker than supervised learning), which warrants further discussion.\n- Generalizability to other settings: The method, in its current form, explicitly relies on class labels for the auxiliary loss. This dependency limits its applicability to other tasks such as text-to-image or unconditional generation.\n  - It would strengthen the paper to demonstrate how LSEP could be adapted for such scenarios, for instance, by training on class or attribute labels as a regularizer while still performing text-conditional or unconditional generation for the primary task.\n  - Can the input conditions and labels for auxiliary classification be decoupled?\n- Loss weighting design: Eq. (7) appears somewhat hand-crafted and might be sensitive to changes in the training-time timestep sampling (e.g., LogNorm distribution in SD3 and VA-VAE).\n  - The ablation study in Table 1 shows that this parameter is carefully tailored to a very narrow range of values ([0.0275, 0.0325]).\n  - The paper also does not show how the general magnitude of this value (around 0.03) is determined, as the cross entropy loss itself is already low enough (<0.1, according to Figure 6)."}, "questions": {"value": "Please refer to the weaknesses regarding the correlation between linear separability and performance, and the generalizability to other conditioning signals.\n\nThe current manuscript also reads like a strong empirical study with good performance but leaves many questions unanswered. For example, will other well-known techniques in supervised learning (e.g., label smoothing) be helpful? Will other discriminative tasks (other than a simple classification) also be beneficial? Why does a classifier trained on diffusion backbone lag behind supervised ViTs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7DFHLDXdhL", "forum": "R0pqsW91yg", "replyto": "R0pqsW91yg", "signatures": ["ICLR.cc/2026/Conference/Submission20427/Reviewer_xeMs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20427/Reviewer_xeMs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916876869, "cdate": 1761916876869, "tmdate": 1762933868206, "mdate": 1762933868206, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to accelerate the training of diffusion transformers without additional computational costs by using a linear classifier. Specifically, instead of aligning the intermediate features of the diffusion transformers with a pretrained vision encoder, it uses intermediate features to be linearly separable to classify the category of the given image. The authors demonstrate that the proposed method (LSEP) shows competitive results with REPA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The idea is simple yet effective: It can even be used with REPA to further accelerate the training of the diffusion transformer.\n\n2. Extensive analysis of the design choices facilitates the practitioners to use this approach."}, "weaknesses": {"value": "1. LEAP is limited only to the dataset that has human annotations (i.e., labels). How can we use this method to accelerate training diffusion models that do not have ground-truth labels, e.g., T2I generation (MS-COCO)?\n\n2. Even though REPA uses an external encoder as conditioning, the reported REPA results do not use any external labels (i.e., unsupervised), but LSEP needs labels (i.e., supervised). In some sense, LSEP uses more information to generate images, but shows worse performance and slower training than REPA (in terms of training time)."}, "questions": {"value": "1. Please answer the Weaknesses.\n\n2. Table 2 shows SiT + REPA + LSEP. However, in Table 3, the authors report only SiT + LSEP. Can SiT + REPA + LSEP achieve SOTA performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "81c6CKbXOe", "forum": "R0pqsW91yg", "replyto": "R0pqsW91yg", "signatures": ["ICLR.cc/2026/Conference/Submission20427/Reviewer_BysX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20427/Reviewer_BysX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979951283, "cdate": 1761979951283, "tmdate": 1762933867609, "mdate": 1762933867609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The paper proposes LSEP, a simple regularization that inserts a trainable linear probe at an intermediate layer of a diffusion transformer and co-optimizes it with the standard denoising loss, with the goal of directly promoting linear separability of intermediate features during training rather than measuring it post-hoc. \n- On ImageNet 256×256 with SiT backbones, LSEP reduces FID versus the SiT baseline, improves linear-probe accuracy at early layers, and shows complementarity with alignment methods like REPA\n- The paper positions LSEP as a no-alignment alternative that can also be combined with alignment (e.g., REPA) to further speed training and improve generation quality, and it discusses limitations such as the lack of experiments on text-to-image, video, or higher resolutions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles a concrete and important problem of improving the quality of features learnt by generative models. \n- The intervention is architecturally minimal and easy to adopt, since it adds a single linear head and combines it with the standard denoising loss via a simple weight.\n- The experiments show consistent FID gains over baseline SiT and demonstrate complementarity with REPA, with clear tables and figures that place the numbers in context and avoid relying solely on a single configuration. \n- The writing is generally clear about the two-branch setup and provides a useful hyperparameter grid for reproduction."}, "weaknesses": {"value": "- The goal of pretraining is to learn general-purpose, task-agnostic features that transfer across datasets, label spaces, and objectives (e.g., detection, segmentation, retrieval, open-set recognition), but this method explicitly supervises a linear probe on ImageNet class labels during pretraining and pressures intermediate features to be separable with respect to that specific taxonomy. As a result, the learned geometry is optimized for class-conditional ImageNet generation and linearly decoding those same labels, which does not guarantee that the features capture fine-grained structure needed by unrelated downstream tasks and may bias representations toward dataset-specific shortcuts.\n- The probe and denoiser use different class-conditioning schedules, which creates gradient-level tension; the paper notes that $ρ_L=1$ causes a mismatch but does not analyze interference between the two schedules or test mitigations such as stop-gradient into shared embeddings or separate class embeddings.\n- The paper trains its linear probe on pooled features (and sometimes pooled crops), which can make the average representation linearly separable while leaving individual patch tokens messy. Without token-level evaluations, the claim that LSEP improves patch-space geometry remains unclear and could reflect pooling shortcuts \n\n- The paper sets the probe’s unconditioning probability very high but below one, yet it does not test whether the method remains stable under label noise or whether those occasional non-null conditioning steps make the probe exploit conditioning artifacts rather than visual content. It will be interesting to see if the reported gains survive mislabeled classes and still hold when the class-conditioning pathway is perturbed or ablated."}, "questions": {"value": "See weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6qpImYPCq6", "forum": "R0pqsW91yg", "replyto": "R0pqsW91yg", "signatures": ["ICLR.cc/2026/Conference/Submission20427/Reviewer_iiBB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20427/Reviewer_iiBB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762124764437, "cdate": 1762124764437, "tmdate": 1762933866941, "mdate": 1762933866941, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}