{"id": "6vnIId8vj4", "number": 20933, "cdate": 1758311790350, "mdate": 1759896950916, "content": {"title": "Theoretical foundations of curriculum learning in linear RNNs", "abstract": "Pretraining models with a curriculum of simpler tasks is a common approach to speed up training. However, it is unclear what aspects of task structure drive learning speed, and how to practically choose the curriculum based on theoretical principles. Using recent advances in the analysis of learning trajectories in linear RNNs (Proca et al., 2025), we study a simple but informative example of performing two integration tasks in sequence, and ask what aspects of their task structure lead to faster overall learning of the second ``target'' task. We show both analytically and through simulations that even for tasks that are similar in their geometry, sequencing them based on the strength and scale of the input-to-target correlations can provably enhance learning speed. A surprising result from our theory that goes against conventional wisdom is that training intermediate tasks to suboptimal accuracies can be more beneficial to learning speed, rather than training them to convergence. These results provide foundational insight into how task similarity forms both a theoretical and practical basis for curriculum learning.", "tldr": "", "keywords": ["curriculum learning", "learning speed", "pretraining", "theory", "linear RNNs"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/22cac5745c42a592bc1b3ff9dfb7437c79a947a1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies the training time of linear RNNs in two scenarios: (i) learning a single \"target\" task; (ii) first learning an \"easier\" task and then learning the \"target\" task when initialized from the first task. By simplifying the problem via an alignment assumption between tasks, the authors derive closed-form solutions for the time required for both scenarios. These times depend on the task via the covariances of the data. They analyze when (ii) is faster than (i) by considering training the first task to an $\\epsilon$ error. They validate their analysis in linear RNNs and provide further evidence from nonlinear RNNs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper has a refreshing style based on training dynamics analysis for curriculum learning. It provides sharp and testable predictions. As far as I'm aware, this is novel. The theory is also presented clearly."}, "weaknesses": {"value": "1. The main issue with the paper is the assumption that the training time of a gradient flow dynamics quantifies the hardness of the task. The speed of learning is sensitive to the learning rate. Based on the authors' definition, one can adjust the learning rate to change the hardness of the problem, which does not make sense. This is very much reflected in the results of the paper. Using stronger singular values in the first task is a way of increasing the learning rate.\n\n2. Related to the point above, the hardness of a task should incorporate something about the statistical hardness of the task. It is not at all clear that the notion the authors proposed aligns with the statistical difficulties of problems. For example, consider a regression problem where the data is scaled by some constant. This is the same problem and the difficulty should be the same. Therefore, the results need to take into account some form of normalization, which is beyond the learning rate discussion. Ideal results with training dynamics would look like this: the first task allows an efficient recovery of the domain of the target task and then the second task is learned much more efficiently."}, "questions": {"value": "1. Can you comment on the example I have given regarding scaled regression? Is it true that your model considers this as a simpler task? Can't you derive the benefits of curriculum with simple learning rate scheduling then? \n\n2. What is the difference between linear networks and linear RNNs when we just focus on prediction at the last token? I see that we get more complicated covariances but aren't they the same up to some transformations in the data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iJxfrK2hAH", "forum": "6vnIId8vj4", "replyto": "6vnIId8vj4", "signatures": ["ICLR.cc/2026/Conference/Submission20933/Reviewer_wg5z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20933/Reviewer_wg5z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761562682873, "cdate": 1761562682873, "tmdate": 1762939033847, "mdate": 1762939033847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the effect of curriculum in a linear RNN setting with fixed recurrent weights and trainable input-to-hidden and hidden-to-output weights. It identifies task statistics that yield faster learning from a curriculum as opposed to direct training. The results are verified in simulation and qualitatively hold in ReLU RNNs."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents new exact solutions to the learning dynamics of a linear RNN with fixed recurrent weights.\n\nThe results identify the key dataset properties in this setting which enable curriculum learning to outpace direct training.\n\nThe paper is clear and the figures are to a high standard."}, "weaknesses": {"value": "The studied model is a particularly simple form of RNN in which the recurrent weights are not trainable. The paper could be strengthened by investigating whether qualitatively similar results hold when recurrent weights are trained as well.\n\nThe tasks studied are versions of learning to integrate an input. While this is an interesting task, it would be useful to understand the limits of the theory for other types of tasks.\n\nThe paper could benefit from discussing other theoretical work on curriculum, for instance the work of Stefano Sarao Mannelli."}, "questions": {"value": "Does a qualitatively similar picture hold when recurrent weights are trained?\n\nDoes a feedforward network yield similar optimal curricula or does recurrence make a different set of curricula beneficial?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pz1wuKFQdm", "forum": "6vnIId8vj4", "replyto": "6vnIId8vj4", "signatures": ["ICLR.cc/2026/Conference/Submission20933/Reviewer_c6Wu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20933/Reviewer_c6Wu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941918124, "cdate": 1761941918124, "tmdate": 1762939033238, "mdate": 1762939033238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a theoretical account of curriculum learning (CL) in linear RNNs and validates key predictions in simulations (with a small nonlinear check). Using recent analyses of learning trajectories in linear RNNs (Proca et al., 2025), the authors study training two related tasks in sequence and ask when pretraining on task T1 accelerates learning of target task T2. The main results are: (i) sequencing by task covariance matters—pretraining that increases input–target covariance strength and scale can provably reduce training time for T2; (ii) counterintuitively, stopping T1 early (sub-optimal accuracy) can yield faster T2 learning; and (iii) the theory gives explicit time-to-convergence formulas and phase-plane predictions, corroborated numerically."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The abstract and discussion cleanly articulate what structural aspects of the two tasks (covariance strength/temporal structure) drive speedups, with the “stop T1 early” prediction highlighted as surprising.\n\n2. The appendix lays out the model and derivation path (extending recent work), including the linear RNN equations and loss setup.\n\n3. The paper motivates CL/pretraining’s mixed empirical record and positions the analysis within that context.\n\n4. Simulations, including a nonlinear-RNN sanity check (Fig. 4), exhibit the same qualitative dependencies predicted by the theory across different task-covariance regimes."}, "weaknesses": {"value": "1. Results are derived for pairs of “similar” tasks with shared geometry, and training focuses on input/output weights with predefined recurrence—limiting generality.\n\n2. The main emphasis is learning speed; robustness/generalization/noise sensitivity are left to future work.\n\n3. The nonlinear experiments are positioned as qualitative trend checks rather than tight quantitative tests of the theory.\n\n4. The paper does not cite some relevant work, eg papers that analyzed curriculum sequencing, representational transfer, and gradient-alignment mechanisms in RNNs, like Kepple, Engelken, Rajan, ICLR, among others. Those works anticipated aspects of the current analysis—particularly the role of inter-task geometry in shaping convergence—so their absence weakens contextualization. The related-work section should explicitly discuss how this study’s theoretical framework extends or differs from that earlier line of curriculum-learning theory."}, "questions": {"value": "1. Can you add quantitative error bars comparing predicted vs. observed time-to-convergence in nonlinear RNNs across the covariance sweeps in Fig. 4?\n\n2. What breaks first if T1 and T2 do not share task geometry (e.g., rotations/compositional changes)? Any preliminary results on the “rotation to factorized regime” you outline?\n\n3. How would updating Wh alter the phase-plane and convergence-time analysis? You note it as feasible for long-timescale computations—any tractable subcase?\n\n4. Given the “stop early” result, could you propose a curriculum-selection heuristic (e.g., proxy measures of input–target covariance strength/scale) and a stopping rule for T1? (Pointers exist but a recipe would help.)\n\n5. Any insight on whether the same covariance principles predict robustness/generalization improvements, not just speed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VRqJPGWaUa", "forum": "6vnIId8vj4", "replyto": "6vnIId8vj4", "signatures": ["ICLR.cc/2026/Conference/Submission20933/Reviewer_UJEY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20933/Reviewer_UJEY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096652428, "cdate": 1762096652428, "tmdate": 1762939032700, "mdate": 1762939032700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}