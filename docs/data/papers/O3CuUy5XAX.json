{"id": "O3CuUy5XAX", "number": 10529, "cdate": 1758174744521, "mdate": 1759897645564, "content": {"title": "One-Timestep is Enough: Achieving High-performance ANN-to-SNN Conversion via Scale-and-Fire Neurons", "abstract": "Spiking Neural Networks (SNNs) are gaining attention as energy-efficient alternatives to Artificial Neural Networks (ANNs), especially in resource-constrained settings. While ANN-to-SNN conversion (ANN2SNN) achieves high accuracy without end-to-end SNN training, existing methods rely on large time steps, leading to high inference latency and computational cost. In this paper, we propose a theoretical and practical framework for single-timestep ANN2SNN. We establish the Temporal-to-Spatial Equivalence Theory, proving that multi-timestep integrate-and-fire (IF) neurons can be equivalently replaced by single-timestep multi-threshold neurons (MTN).\nBased on this theory, we introduce the Scale-and-Fire Neuron (SFN), which enables effective single-timestep ($T=1$) spiking through adaptive scaling and firing. Furthermore, we develop the SFN-based Spiking Transformer (SFormer), a specialized instantiation of SFN within Transformer architectures, where spike patterns are aligned with attention distributions to mitigate the computational, energy, and hardware overhead of the multi-threshold design.\nExtensive experiments on image classification, object detection, and instance segmentation demonstrate that our method achieves state-of-the-art performance under single-timestep inference. Notably, we achieve 88.8\\% top-1 accuracy on ImageNet-1K at $T=1$, surpassing existing conversion methods.", "tldr": "", "keywords": ["Spiking Neural Network", "ANN-SNN Conversion", "One-Timestep Conversion", "Multi-Threshold Neurons", "Scale-and-Fire Neurons"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5835a0661e6b2f203a758bf28926e921929f0388.pdf", "supplementary_material": "/attachment/83f35cd1051b72396dc3c27842bd3576ccb7cd23.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a new ANN-to-SNN conversion framework called **Scale-and-Fire Neuron (SFN)**, which enables **single-timestep (T=1)** inference while maintaining high accuracy. The authors introduce the **Temporal-to-Spatial Equivalence Theory**, which proves that multi-timestep integrate-and-fire (IF) neurons can be equivalently replaced by single-timestep **multi-threshold neurons (MTN)**.  \n\nBuilding upon this theory, the SFN integrates:\n1. A **membrane potential scaling mechanism**, where the **scaling factor (λ)** is optimized via **Bayesian optimization** to balance spike sparsity and accuracy.\n2. An **adaptive fire function**, whose discrete thresholds $ \\theta_i $ are *determined* based on the activation distribution and are proportional to the optimized scaling factor ($ \\theta_i = \\lambda \\theta y_i $).\n\nThe authors extend this design to Transformer architectures, forming the **SFN-based Spiking Transformer (SFormer)**, which aligns spike distributions with attention patterns. Experiments show strong performance across multiple vision benchmarks:\n- **ImageNet-1K:** 88.8% Top-1 accuracy at $T = 1$.  \n- **COCO-2017 Detection:** 78.2% mAP@0.5.  \n- **Energy efficiency:** up to 81% reduction in energy consumption relative to the ANN baseline.\n\nOverall, the paper provides both a theoretical and practical framework for **high-performance single-timestep ANN-to-SNN conversion**, bridging temporal spiking integration and spatial multi-threshold encoding."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces the **Scale-and-Fire Neuron (SFN)** and the **Temporal-to-Spatial Equivalence Theory**, enabling single-timestep ($T=1$) ANN-to-SNN conversion with high accuracy. Experiments on ImageNet and COCO demonstrate good empirical performance and energy savings. The integration of a Bayesian-optimized scaling factor ($\\lambda$) and adaptive multi-threshold firing is both elegant and effective.\n\nThe work is clearly written. It shows that high-performance ANN-to-SNN conversion can be achieved without multi-timestep accumulation. The framework’s applicability to Transformer architectures (SFormer) further enhances its relevance to large-scale vision models and energy-efficient AI research."}, "weaknesses": {"value": "1) Originality: the Temporal-to-Spatial Equivalence is new, but the practical recipe (multi-threshold neurons at single step $T=1$ with scaling $\\lambda$ and density-aware thresholds) overlaps with prior multi-threshold or dynamic-threshold conversion (Huang et al., 2024; Li et al., 2025; MT-SNN). The paper does not show a clear win at matched $N$, nor operator-aware bounds beyond the theory’s non-negative/linear assumptions.\n\n2)  SoftMax is explicitly handled via a max-driven cap $\\theta_{\\text{softmax}}$; GELU is only implicitly covered (no operator-level rule/ablation); LayerNorm handling is missing (no pre/post-LN placement, no treatment of signed activations). This is a material reproducibility and validity gap for ViT-style models.\n\n3) Practical efficiency evidence is incomplete  \nThe method trades time for spatial threshold multiplicity. Per-neuron updates scale with $N$, and spike/event traffic can grow with $N$. No $N$-sweep or absolute energy (mJ/inference), and no accuracy-matched multi-timestep IF ($T>1$) baseline with end-to-end latency/energy and per-layer spike histograms.\n\n4) Cost/justification of $\\lambda$  \n$\\lambda$ is selected by Bayesian optimization; the search budget/range/compute cost are undisclosed, and there is no comparison to simple analytical or percentile estimators, weakening the “training-free” claim.\n\n5) Sensitivity and robustness  \nA max-driven $\\theta_{\\text{softmax}}$ is outlier-sensitive; there is no percentile-based alternative or drift analysis. Stability of density-aware thresholds under activation shifts is also unreported.\n\n6) Large $N$ can be counterproductive  \nEnergy and event counts tend to rise with $N$; neuron-side work grows $O(N)$ and can erode the latency gain; hardware burden (threshold storage/lookup, event queues) increases; fine binning can overfit activation noise and hurt generalization; returns diminish once $N$ already covers the bulk of the activation mass (often around a moderate value like 32). The chosen $N$ should be justified via an $N$-sweep (latency/energy/event counts/bandwidth/accuracy) and a fair $T>1$ baseline.\n\nReferences\n\nHuang, X. et al., 2024. “Towards High-Performance Spiking Transformers from ANN to SNN Conversion.” https://arxiv.org/pdf/2502.21193  \nLi, Y. et al., 2025. “Multi-Threshold Neuron Models for Single-Step ANN-to-SNN Conversion.” https://arxiv.org/pdf/2503.00301  \nWang, Z. and Zhang, T., 2023/2024. “MT-SNN: Enhance Spiking Neural Network with Multiple Thresholds.” https://arxiv.org/pdf/2303.11127  \nFan, Y. et al., 2025. “A multisynaptic spiking neuron for simultaneously encoding spatiotemporal dynamics.” Nature Communications. https://www.nature.com/articles/s41467-025-62251-6"}, "questions": {"value": "Q1. Originality and theoretical contribution\nThe Temporal-to-Spatial Equivalence theory is interesting, but its practical form (multi-threshold + λ-scaling + adaptive thresholds) resembles prior MT-SNN or dynamic-threshold methods (Huang 2024; Li 2025). Could the authors clarify what is fundamentally novel in Scale-and-Fire Neuron?\n\nQ2. Theorems 1–2 assume non-negative inputs and linear operations, which may not hold with GELU, LayerNorm, or signed activations.\nCan the authors quantify the impact of these violations and explain how such nonlinearities are handled or approximated in practice?\n\nQ3. Scalability and applicability\nTable 1 shows O(N) neuron cost, but experiments fix N = 32.\nCan the authors include an N-sweep (e.g., 8–64) showing accuracy, latency, and energy trade-offs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HT7odKpGqN", "forum": "O3CuUy5XAX", "replyto": "O3CuUy5XAX", "signatures": ["ICLR.cc/2026/Conference/Submission10529/Reviewer_Q445"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10529/Reviewer_Q445"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10529/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760796848429, "cdate": 1760796848429, "tmdate": 1762921809823, "mdate": 1762921809823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SFN, which enables converted SNNs to achieve good performance within 1 time step."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The proposed SFN enables converted SNNs to achieve good performance with only 1 timestep."}, "weaknesses": {"value": "1. The proposed Scale-and-Fire Neuron (SFN) largely mirrors the non-uniform activation quantization with calibration used in quanted ANNs.  The so-called \"Temporal-to-Spatial Equivalence Theory\" is quite obvious and superficial. The resulting SFN actually transmits floating-point values and relies heavily on intricate searches for an appropriate scaling factor, which is unlikely to be a fixed constant that is completely task-independent and model-independent (as also acknowledged by the authors in Section 3.2.2), undermining the purported motivation and simplicity of spiking/neural dynamics.\n\n2. This work proposed to replace \"multi-step membrane potential integration\" with \"single-step multi-threshold\", aiming to transform temporal integration into spatial multi-level thresholds. However, this eliminates neural dynamics (membrane potential evolution and temporal correlation of residual membrane potential) with spatial quantized intervals. The resulting SFN is more of an engineering parameterization of step interval and threshold assignment, and is unrelated to neural dynamics.\n\n3. To achieve better performance, the authors stacked multiple heuristics: positive and negative branches, specialized upper threshold bounds for the SoftMax layer, Bayesian optimization of λ, quantile p, and varying threshold densities at each level. These are all a combination of a posteriori calibration properties, resulting in increased implementation complexity and parameter sensitivity, undermining the simple temporal processing mechanism that SNNs are supposed to possess. In contrast, a clean IF/BPTT or reliable ANN quantization scheme is more maintainable and verifiable.\n\n4. The purpose of ANN-to-SNN conversion is to convert the pretrained ANN into an SNN to take advantage of the high performance of ANNs and the high energy efficiency of SNNs.  However, the proposed SFN cannot actually be converted into a single/simple IF/LIF model during inference, and even complicates the membrane potential accumulation process of the spiking neuron. In fact, during this converted SNN inference, the computational complexity of each operation is not just O(1). Therefore, it is unreasonable to estimate the energy consumption of 0.9pJ per synaptic operation as in previous literature.\n\n5. SFN is not a standard neuron. Multiple threshold comparisons, non-uniform threshold mapping, positive and negative branching, and dedicated SoftMax upper bounds all introduce control flow and table lookup overhead; implementing this type of piecewise non-uniform thresholding is not \"free.\" The energy consumption metrics used in this paper are still approximated by an operator energy model (treating multiplication as multiple additions), without actual end-to-end chip or FPGA-level simulations/measurements or timing analysis. More importantly, while single-step execution with N thresholds reduces the repetition of non-neuronal operators, it significantly increases the number of firing spikes and additional operations, e.g., comparisons per layer when N is large, potentially offsetting the energy/latency gains. Overall, SFN is not a standard neuron, while the paper does not provide the corresponding hardware deployment strategy and energy consumption/delay analysis. Therefore, the provided analysis results at the operation-level using normal IF/LIF models are obviously not rigorous."}, "questions": {"value": "1. SFN requires a lot of hyperparameters. Can they have a certain degree of generalization across different tasks/models?\n\n2. SFN actually transmits a floating-point value. What's the actual difference between SFN and quantized ANN activation? Running a quantized ANN only requires one timestep, while it does not need that many complicated hyperparameters or additional runtime computations(e.g., comparisons of positive/negative values). \nIf the author cannot provide the hardware implementation strategy or analysis, what are the actual benefits of SFN compared to mature quantized ANNs that can run on dozens of well-commercialized hardware?\n\n3. It seems that SFN aims to force the firing rate of the SNN to align with the activation value of each layer of the ANN. If T is not 1, can it run step-by-step(asynchronously) rather than layer-by-layer(synchronously)?\n\n4. For SNNs, a single time step is almost a degenerate case. This means no stateful units, no time integration, and no dynamics. I am curious whether the proposed SFN can work well on neuromorphic datasets or why does the author consider SFN to be classified as a spiking neuron? Clearly, the values ​​transmitted by SFN are not binary spikes, cannot convert MAC to AC, are not energy-efficient, and layer-by-layer calibration would prevent the network from operating asynchronously."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1B189mL3qE", "forum": "O3CuUy5XAX", "replyto": "O3CuUy5XAX", "signatures": ["ICLR.cc/2026/Conference/Submission10529/Reviewer_aVto"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10529/Reviewer_aVto"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10529/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761655604741, "cdate": 1761655604741, "tmdate": 1762921809226, "mdate": 1762921809226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel framework for high-performance, single-timestep (T=1) Artificial Neural Network (ANN) to Spiking Neural Network (SNN) conversion. The authors introduce a \"Temporal-to-Spatial Equivalence Theory\" to formally connect multi-timestep Integrate-and-Fire (IF) neurons with single-timestep Multi-Threshold Neurons (MTN). Based on this theory, they propose the Scale-and-Fire Neuron (SFN) and an SFN-based Spiking Transformer (SFormer). In the end, the authors show a new SOTA on ImageNet-1K with 88.8% top-1 accuracy at T=1."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors attempt to provide a rigorous theoretical underpinning for their single-time step approach through the \"Temporal-to-Spatial Equivalence Theory\". Grounding the methodology in a formal equivalence (even under ideal conditions) is a commendable effort that adds depth and clarity to the proposed conversion framework. \n\n2. The proposed Scale-and-Fire Neuron (SFN) is a well-motivated design. It moves beyond a naive multi-threshold implementation by incorporating a scaling factor (λ) and an adaptive firing function. This design directly addresses the practical challenges of converting large models where activation distributions can be highly skewed and varied. The use of Bayesian optimization to tune λ is a principled approach to finding a good balance between accuracy and spike sparsity."}, "weaknesses": {"value": "1. In Table 2, the performance comparison between different architectures is obviously unfair, the author should compare with other ANN2SNN methods using the same model architecture \n2. Since the model uses multi thresholds and the time step is 1 only, the model is more similar to an activation quantized only model. Therefore, the comparison with some typical quantization methods like [1], is also necessary. \n3. The citations of all existing other methods on all performance comparison tables are missing.\n\n[1] Elias Frantar, et al. GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers."}, "questions": {"value": "None."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1RT6c66lt5", "forum": "O3CuUy5XAX", "replyto": "O3CuUy5XAX", "signatures": ["ICLR.cc/2026/Conference/Submission10529/Reviewer_37fc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10529/Reviewer_37fc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10529/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966330944, "cdate": 1761966330944, "tmdate": 1762921808674, "mdate": 1762921808674, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to reduce the inference time step of ANN-to-SNN conversion to 1 time step, while maintaining high conversion accuracy. Specifically, it proves that under certain conditions, multi-time-step Integrate-and-Fire (IF) neurons are equivalent to one-time-step Multi-Threshold Neurons (MTN). Then, it proposes the Scaleand-Fire Neuron (SFN) model for use in the Transformer architecture to convert ANNs into SNNs with one-time-step."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The writing of this paper is fluent, with a well-structured organization. All the theories claimed in the paper have been properly illustrated and elaborated."}, "weaknesses": {"value": "1. **Question on the correctness of Theorem 1**: Theorem 1 requires that \"the input is bounded by θ\", which constitutes a rather strong constraint. How to ensure this constraint can be satisfied? This is because the input is correlated with both input activations and weights.  \n\n\n2. **Clarification on the definition of variables and equivalence of outputs**: What is the meaning of \\( o_M \\) in Equation (27)? Is it consistent with the definition of \\( o(t) \\) in Equation (6)? It is noted that \\( o_M \\) has no temporal dimension, while \\( o(t) \\), although containing a temporal dimension, only represents the output at a single time step. In summary, please provide a detailed explanation of the following:  \n   - What exactly are the equivalent outputs of the MTN and the IF  model?  Is their equivalent output given by Equation (32)?  \n   - Additionally, since the entire paper focuses on **one time step**, the temporal dimension becomes meaningless. In this case, the work degrades to a simple activation quantization task. Consequently, the MTN—i.e., the model described in Equation (6), merely serves as an activation quantizer for artificial neural networks (ANNs).  \n\n3. **Question on the necessity of this work**: Theorem 2 is self-evident and does not require a separate proof, which raises doubts about the necessity of this study. For ANN-to-SNN conversion works, the core goal is to transform ANNs into SNNs. However, the essence of this work is an ANN-to-ANN conversion (the MTN  functions only as an activation quantization function and does not introduce temporal dimension).  \n\n4. **Further question on the necessity of this work**: Considering that this paper discusses one timestep, are the t in h(t) and o(t) in formulas (6), (8), and (10) all 1? If so, then SFN is just quantifying the activation after observing the output of the ANN. \n\n5. **Question on the scope of application of the proposed theory and the relationship between MTN and SFN**: Are the MTN and SFN the same concept? Specifically:  \n   - Theorems 1, 2, and 3 are all proofs for the MTN, yet no proof is provided to verify the relationship between the MTN and the SFN.  \n   - Why can Theorems 1, 2, and 3 be applied to the SFN and still hold true?  \n\n6. **Comment on experimental results**: The experimental results on COCO-2017 object detection may lack persuasiveness, as the backbone networks used (in this work and comparative studies) are not consistent."}, "questions": {"value": "The problem is detailed in the above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "neF2YUuehM", "forum": "O3CuUy5XAX", "replyto": "O3CuUy5XAX", "signatures": ["ICLR.cc/2026/Conference/Submission10529/Reviewer_pZCi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10529/Reviewer_pZCi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10529/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154556931, "cdate": 1762154556931, "tmdate": 1762921808219, "mdate": 1762921808219, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}