{"id": "ChRwhtCmwT", "number": 23436, "cdate": 1758343727441, "mdate": 1759896814768, "content": {"title": "SAGE: Sufficiency-Aware Implicit Graph Exploration for Long Context Reasoning", "abstract": "Large Language Models (LLMs) have achieved impressive progress in natural language processing, but their limited ability to retain long-term context constrains performance on document-level or multi-turn tasks. Retrieval-Augmented Generation (RAG) mitigates this by retrieving relevant information from an external corpus. Recently, graph-based RAG systems have shown promise for long-context reasoning. However, these methods face some challenges: high preprocessing computational costs, static graph architectures with fixed node and edge semantics, and complex parameter finetuning requirements that could limit their practical adoption. Recognizing that modern LLMs possess substantially improved reasoning capabilities, we propose SAGE, a dynamic implicit graph exploration framework that eliminates the need for explicit graph construction while preserving multi-hop reasoning benefits. Experiments are conducted on challenging long-context QA benchmarks, including NovelQA and Marathon. Our approach consistently outperforms strong baselines across these datasets. Additionally, it reduces storage and runtime requirements by over an order of magnitude. These results show that high-quality retrieval can be achieved through LLM-driven text exploration without relying on static preprocessing or vector representations.", "tldr": "", "keywords": ["Language Models", "Knowledge Graph", "Retrieval Augmented Generation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ddc439db2bc4a8c2ca088d4c8a0cdf8c1097ca56.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SAGE (Sufficiency-Aware implicit Graph Exploration), a retrieval-augmented framework for long-context reasoning that avoids explicit graph construction and dense vector indexing. Instead, SAGE treats documents as an implicit graph of chunks and lets an LLM iteratively (i) generate query-conditioned keywords, (ii) retrieve candidate chunks lexically, (iii) assess sufficiency using an objective importance score that measures each chunk’s causal impact on the answer distribution via noise perturbations, and (iv) expand along spatial (context neighbors) and semantic (topic neighbors) edges only when evidence is insufficient. On NovelQA and Marathon, SAGE reports higher accuracy than MiniRAG/RAPTOR across multiple LLaMA scales while cutting storage and preparation time by orders of magnitude, since it stores only the original text and skips any pre-built graphs/embeddings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Pre-built graphs are costly and rigid, and embedding-based methods add storage overhead and reduce interpretability in long-context settings.\n2. The method’s combination of implicit graph exploration, keyword-based retrieval, and sufficiency-aware stopping forms a clear and interpretable pipeline.\n3. The importance score, based on light perturbation and KL evaluation, helps prevent premature stopping and reduces hallucination.\n4. It is highly efficient: almost zero preprocessing, only original text stored (≈1×), yet it matches or outperforms MiniRAG/RAPTOR, especially with 8B/70B models.\n5. Ablation studies show the benefit of each component (voters, expansion, importance signal), and performance is robust across context lengths."}, "weaknesses": {"value": "1. Lexical retrieval ceiling: While interpretability is a plus, relying on keyword overlap risks recall issues for paraphrased, non-lexically aligned evidence; a hybrid (lexical + light semantic) comparison would strengthen claims of “embedding-free superiority.”  \n2. Benchmark scope: Only multiple-choice QA (NovelQA/Marathon). It would be valuable to add free-form QA and multi-document synthesis (e.g., GovReports, Qasper, LongFact) to test robustness beyond MCQ cueing effects.  \n3. Importance metric assumptions: The KL→cosine approximation assumes near-constant variance/softmax temperature; an empirical sensitivity study (temperature, noise distributions, #samples) would bolster soundness.  \n4. Counting branch: Counting is handled via a special pipeline. This is practical, but it highlights that SAGE still needs task-specific forks; a unified controller that chooses among skills/tools could generalize better.  \n5. Comparisons vs. stronger agentic baselines: Given the “LLM-as-retriever/agent” lineage, adding ReAct- or Toolformer-style agentic retrieval baselines (without embeddings) would clarify where SAGE’s sufficiency gating provides the most benefit. The set of compared methods in the paper is currently too limited."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YWfL7ni6lm", "forum": "ChRwhtCmwT", "replyto": "ChRwhtCmwT", "signatures": ["ICLR.cc/2026/Conference/Submission23436/Reviewer_pfgd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23436/Reviewer_pfgd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760556903959, "cdate": 1760556903959, "tmdate": 1762942660898, "mdate": 1762942660898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SAGE, a framework for dynamic implicit graph exploration. SAGE aims to preserve multi-hop reasoning capabilities in RAG by treating documents as implicit knowledge graphs where relationships are discovered on-demand, thereby eliminating the need for explicit graph construction."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "1. The ad-hoc handling of \"counting\" problems, as described in Section 4.1, seems superfluous and undermines the method's generality. The technique employed for this specific task is highly intuitive and appears to offer minimal technical contribution.\n\n2. The paper's overall presentation is poor, suffering from unclear writing and numerous formatting errors, which makes the methodology difficult to follow. For instance:\n\n    a. A \"DisSim\" function is mentioned on line 329, with a reference to Appendix B.1 for implementation details. However, Appendix B.1 describes an \"Imp()\" function, and \"DisSim\" is never mentioned again.\n\n    b. Algorithm 3 is included in the paper but is never referenced or explained in the main text.\n\n    c. There are multiple distracting formatting errors, such as missing parentheses for citations (e.g., lines 112, 194) and improper spacing around parentheses (e.g., line 412).\n\n4. The related work section is insufficient and misses several critical citations. The paper fails to discuss or position itself against highly relevant recent work, such as:\n```\n@inproceedings{wang2024knowledge,\ntitle={Knowledge graph prompting for multi-document question answering},\nauthor={Wang, Yu and Lipka, Nedim and Rossi, Ryan A and Siu, Alexa and Zhang, Ruiyi and Derr, Tyler},\nbooktitle={Proceedings of the AAAI conference on artificial intelligence},\nvolume={38},\nnumber={17},\npages={19206--19214},\nyear={2024}\n}\n@article{li2024graphreader,\ntitle={Graphreader: Building graph-based agent to enhance long-context abilities of large language models},\nauthor={Li, Shilong and He, Yancheng and Guo, Hangyu and Bu, Xingyuan and Bai, Ge and Liu, Jie and Liu, Jiaheng and Qu, Xingwei and Li, Yangguang and Ouyang, Wanli and others},\njournal={EMNLP},\nyear={2024}\n}\n```"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Ubnjq4nRj3", "forum": "ChRwhtCmwT", "replyto": "ChRwhtCmwT", "signatures": ["ICLR.cc/2026/Conference/Submission23436/Reviewer_i7LV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23436/Reviewer_i7LV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551228246, "cdate": 1761551228246, "tmdate": 1762942660455, "mdate": 1762942660455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SAGE, a sufficiency-aware implicit graph exploration framework designed to enhance long-context reasoning for Large Language Models (LLMs). \n\nInstead of relying on explicit graph construction or vector embeddings, SAGE enables dynamic implicit graph traversal over text chunks using LLM reasoning capabilities. The framework introduces a sufficiency evaluation mechanism to decide when enough information has been retrieved, guided by an objective importance score that measures how much a text chunk influences the model’s reasoning. \n\nExperiments on NovelQA and Marathon benchmarks show that SAGE achieves SOTA accuracy and efficiency, outperforming graph-based methods like MiniRAG and Raptor, while reducing preprocessing time and storage by orders of magnitude. The authors argue that this embedding-free, reflective retrieval paradigm marks a paradigm shift toward more interpretable and adaptive long-context retrieval systems."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- SAGE eliminates the need for embedding and graph construction, significantly enhancing retrieval efficiency for long-context QA.\n- SAGE introduces an objective, effective, and novel method for evaluating the importance of evidence in RAG."}, "weaknesses": {"value": "- The paper's description of the methodology lacks clarity, making it difficult to correlate the main text, the algorithm, and the pipeline in Figure 1.\n- The experiments are insufficient. The paper compares too few baselines and does not include a comparison with the GraphRAG paradigm mentioned at the beginning.\n- The ablation study design has problems: firstly, it lacks experiments on the impact of iteration rounds $T$ on results; secondly, it fails to provide comparisons between with and without importance scores under non-default values of voter_num and recall_index.\n- Experiments are limited to LLaMA family models. The generalization to other LLMs is not verified."}, "questions": {"value": "Refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xhGEjPH6BB", "forum": "ChRwhtCmwT", "replyto": "ChRwhtCmwT", "signatures": ["ICLR.cc/2026/Conference/Submission23436/Reviewer_sFCj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23436/Reviewer_sFCj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832514321, "cdate": 1761832514321, "tmdate": 1762942660162, "mdate": 1762942660162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an LLM-based RAG approach that iteratively retrieve sentences. The major motivation is to treat sentence as retrieval units and perform graph-like search trajectory without the need of pre-building a graph. Specifically, it identifies keywords in each turn, retrieve sentences by keyword-based matching, and evaluate evidence importance by measuring the effects of it on the LLM's output. Experiments are mainly comparing with some graph-based baselines that show the reduced offline cost and higher performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper is inspired by graph-based approaches while proposes a method that mimic a similar behavior without graph construction. This work is thus well motivated\n- The proposed objective importance metric is interesting and seems to be effective. It worth further studying and could be applied in different cases as well"}, "weaknesses": {"value": "- The methodology is essentially two unrelated parts, one on counting queries and another one on the retrieval algorithm. This makes the paper lose a focused contribution, and more essentially, the experiments also do not show how the two parts contribute to the performance\n- The selection of baselines is insufficient. For example, there are quite a number of graph RAG approaches and also some prompt-based iterative RAG methods without graph.\n- Because the method does not involve training, it would be expected to evaluate on more than just open-source models like Llama."}, "questions": {"value": "Please see weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JCyjK1BHA7", "forum": "ChRwhtCmwT", "replyto": "ChRwhtCmwT", "signatures": ["ICLR.cc/2026/Conference/Submission23436/Reviewer_CQkY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23436/Reviewer_CQkY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762031060765, "cdate": 1762031060765, "tmdate": 1762942659848, "mdate": 1762942659848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}