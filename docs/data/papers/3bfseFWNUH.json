{"id": "3bfseFWNUH", "number": 10231, "cdate": 1758164699393, "mdate": 1759897664739, "content": {"title": "ICLR: Iterative Optimization for Information Extraction on In-Context Learning via Rule Filtering", "abstract": "Existing information extraction (IE) tasks, such as named entity recognition (NER) and relation extraction (RE), typically rely on fine-tuning or few-shot learning methods. In few-shot learning, large language models (LLMs) demonstrate excellent performance through in-context learning (ICL), which involves guiding the model by providing a few examples or rules in the prompt. However, a major challenge with this approach is the selection and optimization of contextual information for diverse IE tasks. In this work, we introduce ICLR (Iterative Context Learning Rule), a control-theoretic framework that models rule optimization as an adaptive filtering problem for comprehensive information extraction. We treat rules as controllable state variables and design an observer system to monitor and control LLM behavior indirectly, without modifying model parameters. Our method iteratively estimates and updates the optimal rule combinations using performance feedback, thereby reformulating the traditionally complex problem of LLM control into a well-defined state-space optimization that generalizes across multiple IE tasks. We evaluate ICLR on both NER datasets (CoNLL03, ACE05, GENIA) and RE datasets (NYT, CoNLL04), demonstrating rapid convergence and superior performance with minimal training data requirements. Our approach achieves up to 10\\% performance improvement over state-of-the-art ICL methods while requiring no additional model training and ICLR provides the first control-theoretic foundation for understanding and optimizing in-context learning behavior in information extraction.", "tldr": "We propose ICLR, a control-theoretic framework that optimizes in-context learning rules for information extraction, achieving up to 10% gains without training.", "keywords": ["In-Context Learning", "Named Entity Recognition", "Rule Optimization", "Iterative Filtering", "Large Language Models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/938a50a12fb21700c4a0b83b8238a3c7047f2ab9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces **ICLR (Iterative Context Learning Rule)**, a control-theoretic framework that optimizes rule selection for information extraction (IE) tasks via in-context learning. The key idea is to treat annotation rules as controllable state variables and model rule optimization as an adaptive particle filtering problem. Without modifying model parameters, ICLR iteratively refines rule combinations using performance feedback, forming a closed-loop system that efficiently converges to high-performing rule sets. The method is evaluated on both Named Entity Recognition (CoNLL03, ACE05, GENIA) and Relation Extraction (NYT, CoNLL04) datasets, demonstrating improved performance over existing ICL baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Theoretical Innovation**: Pioneers the integration of control theory and particle filtering into in-context learning optimization, establishing a novel theoretical foundation for understanding and steering LLM behavior.\n- **Principled Optimization**: Introduces a systematic methodology for rule selection through iterative filtering and mutation, effectively overcoming the limitations of heuristic-based approaches.\n- **Computational Efficiency**: Achieves significant performance gains solely through external rule optimization without updating model parameters, demonstrating superior token efficiency and lower data requirements compared to methods like CodeIE."}, "weaknesses": {"value": "**1 Citation Issues:**\n\n(1) The concepts of \"particle\" and \"particle filtering\" are fundamental to the core idea of this paper, yet relevant seminal works are missing.  \n(2) The references in the related work section appear somewhat outdated, with only one citation each from 2024 and 2025. While I understand the authors focus on backbone training-free research, numerous relevant studies exist:\n-  Demonstration-based methods\n\t[1] A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction (2024)\n\t[2] C-ICL: Contrastive In-context Learning for Information Extraction (2024)\n\t[3] Recall, Retrieve and Reason: Towards Better In-Context Relation Extraction (2024)\n\t[4] GPT-RE: In-context Learning for Relation Extraction using Large Language Models (2023)\n- QA-based methods\n\t[5] ChatIE: Zero-Shot Information Extraction via Chatting with ChatGPT (2024) \n\t[6] Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors (2023)\n\t[7] Revisiting Large Language Models as Zero-shot Relation Extractors (2023)\n- Guideline/Rule-based methods (most related)**\n\t**[8] Guideline Learning for In-Context Information Extraction (2023)**\n\n**2 Techniccal Details**\n\n(1) In Eq. 4, what does $h(\\cdot)$ refer to? Is its output $y_t$ the F1 score or the sequence generated by the backbone LLM?  \n(2) In the rule extraction stage, the number of particles summarized by the LLM is not specified. Is there a limit?  \n(3) In Eq. 7, what does $\\theta$ represent?  \n(4) Eqs. 7, 8, and 11 are applied to individual particles. Why is the softmax function used? If I understand correctly, the input is a single scalar, not multiple values.  \n(5) How is the hyper-parameter $\\beta$ in Eq. 8 set? Is it tuned for different tasks or datasets?  \n(6) What does \"context\" refer to in Eq. 8 and Sec. 4.5.1?  \n(7) Regarding Eq. 9: What is the theoretical or practical justification for modeling the likelihood term $p(⋅)$ as an exponential function $exp⁡(\\beta⋅y_i^{(t)})$? Does this formulation have a rigorous foundation?\n(8) In the resampling stage, the authors state that particles with weights below a threshold will be removed, but in Fig. 3, the discarded particles are not the lowest-weighted ones. How is the filtering threshold determined? Is it tuned for different tasks or datasets?  \n(9) The evaluation of generative IE differs from sequence tagging models. Sec. 4 states that the authors \"follow previous work and adopt F1-score,\" but no citation is provided, and the specific F1 scoring method is not detailed.\n\n**3 Experimental Sufficiency**\n\n(1) Is ICLR applicable to common but more complex IE tasks such as Event Extraction, or subtasks of NER, RE, and EE, such as Entity Typing, Relation Classification, Event Detection, and Event Argument Extraction?  Given that the paper's title positions the work as a general solution for \"Information Extraction\" rather than being specifically limited to NER and RE, it is important to demonstrate the framework's applicability and performance on these broader and more complex IE tasks. \n\n(2) The experimental datasets for NER and RE tasks are insufficient.  \n(3) Do smaller context lengths and less training data imply more iterative optimization steps? Please provide the relationship between the number of iterative optimization steps and F1 score under different settings.  \n(4) The authors mention that tightly coupled components are unsuitable for traditional ablation studies, but this weakens the understanding of each component's contribution, especially the independent roles of rule extraction, weight update, and resampling modules.\n\n**4 Model Efficiency**\n\n(1) Although ICLR does not involve parameter training, particle generation, evaluation, and resampling are performed on individual particles, suggesting complex optimization steps and potentially long runtime. Please provide data on optimization time.  \n(2) The introduction emphasizes that ICLR can achieve better rules with less data compared to GuideNER, but the method section states that the entire training data is used. The main results do not report the size of the training set used, despite the analysis in Sec. 4.5.2 on the impact of training data quantity.\n\n**5 Writing Issues**\n\n(1) In LaTeX, English double quotes should be written as` `` + \"` instead of`\"+\"`.  \n(2) The first paragraph of Sec. 3 redundantly describes the content of Fig. 3."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JnuvvX8FOY", "forum": "3bfseFWNUH", "replyto": "3bfseFWNUH", "signatures": ["ICLR.cc/2026/Conference/Submission10231/Reviewer_3vBY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10231/Reviewer_3vBY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761493587738, "cdate": 1761493587738, "tmdate": 1762921591735, "mdate": 1762921591735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ICLR (Iterative Context Learning Rule) — a control-theoretic framework that models rule optimization for information extraction (IE) as an adaptive filtering process. The authors treat rules as controllable state variables and design a closed-loop system that iteratively updates rule combinations based on model performance feedback. Experiments on five benchmarks (CoNLL03, ACE05, GENIA, NYT, CoNLL04) and multiple LLMs (Qwen2.5, Llama3.1, Pixtral) demonstrate consistent improvements (up to 10% F1) over GuideNER and CodeIE."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel conceptual framing: The idea of viewing in-context rules as control variables introduces a new theoretical lens to study ICL optimization.\n2. Algorithmic innovation: The particle filtering approach for adaptive rule selection is original and well-motivated.\n3. Comprehensive experiments: Covers both NER and RE tasks, across diverse datasets and model scales (3B–12B).\n4. Interpretability: Rules provide a semantically meaningful and observable interface for controlling LLM behavior."}, "weaknesses": {"value": "1. Theoretical rigor is weak. The so-called “control-theoretic” framework lacks formal derivation or stability/convergence analysis. The control formulation (Eq. 3–4) is largely conceptual rather than mathematically grounded.\n2. Algorithmic complexity not analyzed. The particle filtering and multi-level mutation mechanism could be computationally heavy. No analysis or empirical evidence is provided regarding scalability with model size or dataset complexity.\n3. Experimental comparisons limited. The baselines are all ICL-based. Missing comparison with prompt-tuning, fine-tuning, or retrieval-augmented baselines weakens the generality claim.\n4. Reproducibility concerns. Many implementation details (e.g., β parameter, mutation rate, prompt templates) are omitted. The algorithm description is visual but not formally specified or released as pseudocode."}, "questions": {"value": "1. What is the computational overhead compared to GuideNER? Any quantitative analysis beyond token counts?\n2. Further questions please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VuQQMJ8lWB", "forum": "3bfseFWNUH", "replyto": "3bfseFWNUH", "signatures": ["ICLR.cc/2026/Conference/Submission10231/Reviewer_ssnn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10231/Reviewer_ssnn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761597795352, "cdate": 1761597795352, "tmdate": 1762921591020, "mdate": 1762921591020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ICLR, a novel control-theoretic framework that optimizes in-context learning for Information Extraction tasks like Named Entity Recognition and Relation Extraction. It treats annotation rules as controllable state variables and uses an iterative, particle-based filtering algorithm to evolve and select the most effective rules based on performance feedback, without modifying the underlying LLM’s parameters. Evaluations show ICLR outperforms state-of-the-art methods, achieving up to a 10% performance improvement with greater data efficiency and shorter prompts."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea is novel, introducing a control-theoretic framework (ICLR) to optimize in-context learning rules as state variables, which is underexplored in LLM literature.\n2. The method demonstrates strong empirical performance, achieving up to 10% improvement over SOTA ICL methods across multiple IE tasks with minimal training data."}, "weaknesses": {"value": "1. The presentation requires significant improvement. The method section lacks clarity, and several key terms (e.g., “particle-based state representation”) are insufficiently explained, making the paper difficult to follow. The manuscript would benefit greatly from clearer organization and more precise writing.\n2. The experimental scope is limited. The evaluation only covers models below 13B parameters (e.g., Qwen-7B, Llama-8B), overlooking larger or proprietary models where optimal performance is typically observed. This limitation undermines the paper’s claim of “parameter-free optimization.”\n3. The particle optimization process incurs substantial inference costs due to repeated LLM calls. Although this issue is acknowledged, the manuscript does not provide an adequate discussion or mitigation strategy."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ttdPKJSt2o", "forum": "3bfseFWNUH", "replyto": "3bfseFWNUH", "signatures": ["ICLR.cc/2026/Conference/Submission10231/Reviewer_RvNj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10231/Reviewer_RvNj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897121710, "cdate": 1761897121710, "tmdate": 1762921590394, "mdate": 1762921590394, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ICLR (Iterative Context Learning Rule), which is a control-theoretic framework for optimizing in-context rules for information extraction (IE) and argues it is the first control-theoretic formalization of ICL rule optimization for IE. \n\nThe core idea of this paper is to treat rules (LLM-generated subcategory patterns paired with labels) as controllable state variables and to run an iterative, particle-filter style loop. The loop is like this: initializing rules from LLM/GuideNER-like prompts, evaluating them via ICL on a small validation slice, updating weights with a Bayesian/posterior step, then resampling rules to preserve high-performing and diverse ones. This turns the original problem formulation in into a structured state-space optimization process. ICLR outperforms IO, CodeIE, and GuideNER on five IE benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper has a good problem formulation. Instead of sticking to the original heuristic top-k selection problems, this paper jumps out of the scope and gives out a new problem framework that is treat rules as states and optimize them with an observer plus control loop. Alse this paper explicitly models rule evolution and observation:\n\n    - Rule evolution: R_(t+1)=f(R_t,u_t)\n\n    - Performance observation: y_t=h(R_t)\nThis gives the proposed method a solid and formulated backbone.\n\t\n2. Without identifying NER and RE tasks, this proposed method can be used for both NER and RE, and is competitive or clearly best across both task benchmarks. It provides a more unified framework for IE work.\n\n3. The results on both NER and RE tasks are consistent and competitive.These results support the claim that iterative rule search helps beyond static rules. Also token cost is reported.\n\n4. This paper did further analysis on impact of context length and training-set size on ICLR performance. It shows the method actually converges with quite small data slices. That’s well aligned with the motivation of controlling LLM behavior without fine-tuning.\n\n5. This paper has a clear, reader-friendly pipeline figure and has three case studies in the appendix appendix make the algorithm understandable. It helps understand how the probabilistic updates steps interweaved with LLM prompting."}, "weaknesses": {"value": "1.\tThis paper replaces ablation studies with parameter sensitivitiy. The paper says “ICLR is a unified sequential framework…preclude conventional ablation studies,” so it reports context-length / data-size sensitivities instead. That’s understandable, but still a gap. We don’t have a clear idea about how different parts in this algorithm really contribute to the performance improvement. Variants like no Tier-2 mutation, no Bayesian weight update, no LLM-confidence-based prior, no diversity, or noisy influence, etc. can be involved in this discussion to show the robustness of the method. \n\n2.\tThis paper can choose more up-to-date baselines. For IE-with-LLMs, there are now retrieval-augmented and “ICL-as-program/code” approaches that plug in more structure, and there are prompt-search / auto-prompt frameworks. Also, GuideNER is only for NER tasks, which reduce the strength of comparisons on RE tasks. So it would be better to involve more baselines in the main experiments.\n\n3.\tThis method proposed by this paper has a heavy on LLM quality. Many steps in the algorithms like initialization, posterior estimation, mutation are with help of LLM. This paper is based on an assumption that the chosen LLM can perform well on both IE and judging/mutating rules. But somehow, if the LLM is weaker on one domain, like Pixtral-12B underperforms despite size, the method may degrade.\n\n4.\tThis paper only methions token cost but should clarify more details to make the total cost of the algorithm reliable and clear. Like whether token cost is per example, per dataset pass, or per rule update loop, and whether LLM calls for mutation are counted. \n\n5.\tSome part of writing in this paper can be polished more. Like several parts of Sec. 3 restate the same 4-step loop with slightly different words; some equations could be tightened, and the method could be expressed in one clean algorithm box."}, "questions": {"value": "1. In Eq. (9) you use w_i^((t))∝w_i^((t-1))⋅exp⁡(β⋅y_i^((t))). How was this form chosen? Did you try alternatives? A short ablation here would make the choice more convincing. \n\n2. How many LLM calls per iteration and per dataset? Your pipeline has (i) LLM extract, (ii) LLM confidence, (iii) ICL evaluation, (iv) LLM mutate. Are all the tokens used counted in token size mentioned in the paper? If not, please report total LLM calls / tokens for the full optimization.\n\n3. Why not compare to prompt-/rule-search baselines like genetic prompt search or gradient-free prompt tuning?\n\n4. When the dataset is tiny, how do you prevent overfitting?\n\n5. Can you give a more detailed on your novelty to clarify your claim of “first control-theoretic foundation”?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HOIMIV5u4z", "forum": "3bfseFWNUH", "replyto": "3bfseFWNUH", "signatures": ["ICLR.cc/2026/Conference/Submission10231/Reviewer_8vNz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10231/Reviewer_8vNz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977166852, "cdate": 1761977166852, "tmdate": 1762921589552, "mdate": 1762921589552, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}