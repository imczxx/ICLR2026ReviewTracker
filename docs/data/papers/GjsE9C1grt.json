{"id": "GjsE9C1grt", "number": 36, "cdate": 1756728195963, "mdate": 1759898277983, "content": {"title": "Nonlinear Steering for Token-Efficient Reasoning in LLMs via Flow Matching", "abstract": "Large Reasoning Models (LRMs) excel at complex reasoning tasks, but their efficiency is often hampered by overly verbose outputs. Prior steering methods attempt to address this issue by applying a single, global vector to hidden representations—a rigid approach grounded in the restrictive *linear representation hypothesis*. In this work, we introduce *FlowSteer*, a nonlinear steering method that goes beyond uniform linear shifts by learning a complete *transformation between the distributions* associated with verbose and concise reasoning. This transformation is learned via *Flow Matching* as a velocity field, enabling precise, input-dependent control over the model's reasoning process. Across diverse reasoning benchmarks, *FlowSteer* simultaneously achieves superior accuracy and token efficiency over leading inference-time baselines. Our work demonstrates that modeling the full distributional transport with powerful generative techniques offers a more effective and principled foundation for controlling LRMs.", "tldr": "This paper introduces a nonlinear steering method using Flow Matching to transform verbose reasoning paths into concise ones, achieving superior accuracy and token efficiency in LLMs.", "keywords": ["representation steering; large reasoning models; LRMs; large language models; LLMs; efficient reasoning; flow matching"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3421f23aa0576a1a0ef1db91cfc97936c8c749b3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes using Flow Matching for LRM steering. The authors explored distribution alignment with flow matching, as well as methods for robust training. They followed the SEAL methodology of using verbose and concise CoTs to train their model. The results show improvements in both model quality and reduced length of CoTs."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is generally well written, with sufficient details provided (e.g., examples of reasoning, training details, etc.).\n- The idea is novel and interesting for further research."}, "weaknesses": {"value": "- My main concern with this paper is the stated dichotomy between the SEAL intervention protocol and training with RL (L451). More concretely, the method ultimately learns steering vectors based on two sets of representations (verbose and concise). From my point of view, this does not differ much from an RL setup, as we still rely on sampling from a non-trained model and training interventions.  From this perspective, I find it premature to state that the linear representation hypothesis ignores complexities in a model (L043). This also reduces the depth of the work, as it remains unclear whether one should bother with sophisticated methods or simply use linear interventions (without relying on a pre-defined set of verbose and concise representations)."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hIPLScOsI1", "forum": "GjsE9C1grt", "replyto": "GjsE9C1grt", "signatures": ["ICLR.cc/2026/Conference/Submission36/Reviewer_3ynx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission36/Reviewer_3ynx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission36/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761546068135, "cdate": 1761546068135, "tmdate": 1762915440848, "mdate": 1762915440848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a method for steering large language models toward concise, accurate reasoning by learning a nonlinear transformation of hidden states via flow matching. The method models a velocity field that transports internal representations from verbose to concise reasoning styles. It incorporates robust training techniques and a novel guidance mechanism based on Gaussian score matching to improve reliability and coverage. Tested on math and coding tasks, it outperforms existing inference-time baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The method is well-theoretically grounded, and the motivation to learn nonlinear transformation of hidden representations sounds clear and logical\n* The method has a low overhead in computing resources and time"}, "weaknesses": {"value": "* The paper's probabilistic guidance relies on approximating hidden state distributions as diagonal Gaussians—a simplification that may not fully capture the true geometry of LLM representations. The authors justify this assumption by citing prior work showing Gaussian-like behavior in the final-layer activations of RNNs and vision models [1, 2]. However, it remains unclear whether this finding reliably extends to Transformer-based language models pretrained on diverse textual data. Is this assumption too strong, given the potential multimodality or anisotropy of hidden states in large-scale LLMs?\n* The method’s effectiveness depends on access to a training dataset containing paired verbose and concise reasoning traces, from which the flow model learns to steer representations. In this work, the authors use the MATH dataset to construct these training pairs, and then apply the learned steering across multiple domains including code generation without further adaptation. While the method generalizes reasonably well in their experiments, it’s unclear how well the method would perform on other domains.\n* The obvious way to solve the problem of moving from verbose to concise reasoning is RL. For the honesty of the experiment, it is also possible to train only steering vector using RL, as it is done in the article [3]. Although this method is not inference-time, it requires very little resources and time.\n* The results presented in the paper do not include standard deviations or any assessment of statistical significance.\n\n[1] Hashemi et al, Gaussian-based runtime detection of out-of-distribution inputs for neural networks.\n\n[2] Zhang et al, Finegrained neural network explanation by identifying input features with predictive information. \n\n[3] Sinii et al, Steering LLM Reasoning Through Bias-Only Adaptation"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zHO8xsT4Z8", "forum": "GjsE9C1grt", "replyto": "GjsE9C1grt", "signatures": ["ICLR.cc/2026/Conference/Submission36/Reviewer_3uSn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission36/Reviewer_3uSn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission36/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761651502782, "cdate": 1761651502782, "tmdate": 1762915440713, "mdate": 1762915440713, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a method for steering reasoning models using flow matching. The setup resembles SEAL, but rather than steering in a single direction, Flow Steer learns to match the distribution between long and short answers by partitioning reasoning traces into three phases: execution, reflection, and transition."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The core idea is interesting and produces better results than baselines in most settings.\n\n- The evaluation appears sound, with a comprehensive set of baselines."}, "weaknesses": {"value": "- Section 3 introduces several modifications to simple flow matching—median–IQR normalization, Huber loss in place of MSE, and probabilistic guidance—yet the ablation studies cover only the last. For example, what happens if standard z‑score normalization $ \\tilde{x} = (x - \\mu)/ \\sigma $ is used?\n- The method relies on many heuristics/tricks but shows only marginal gains on many tasks/models; without clearer benefits. I can’t see it being widely adopted in modern pipelines.\n- Data efficiency is unclear. How many training samples are required to train the flow-matching component, and from what scale does it outperform linear steering?"}, "questions": {"value": "- Replacing MSE with Huber loss appears to drop Gaussian-based optimality guarantees. Probabilistic guidance, however, assumes a Gaussian approximation and seems to enhance steering performance. Can the authors reconcile this tension and justify the loss choice empirically and/or theoretically?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FDzb4aT1zS", "forum": "GjsE9C1grt", "replyto": "GjsE9C1grt", "signatures": ["ICLR.cc/2026/Conference/Submission36/Reviewer_PoZa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission36/Reviewer_PoZa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission36/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761733516952, "cdate": 1761733516952, "tmdate": 1762915440572, "mdate": 1762915440572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors note that linear steering vectors transform representations in a way that discards higher-order distribution statistics, creating a mismatch. To address this, they propose Flow Matching, which is less restrictive. They highlight two challenges: massive activations and low-velocity zones, and tackle the former with normalization, a Huber loss, and optimal-transport coupling between source and target, and the latter with probabilistic guidance. Their strategy yields higher performance on several benchmarks than prior methods and achieves better distributional alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is well written and easy to follow.\n* It tackles the distribution-mismatch problem in a novel and interesting way."}, "weaknesses": {"value": "### Methodological Problems\n\n* **Small gains**\n\n  In my experience, the gains reported in Table 1 for math benchmarks are often not statistically significant. Please add standard deviations to the table.\n\n* **Narrow evaluation**\n\n  The evaluation uses only Qwen-based models, which are known to yield observations that do not generalize broadly in math reasoning [1,2]. Please include evaluations on LLaMA models.\n\n* **Incomplete efficiency evaluation**\n\n  Section 4.5 compares only to the vanilla model, reporting reduced time per answer. What is the reduction relative to SEAL, which, per Table 1, often reduces token counts comparably to FlowSteer?\n  Also, how much time/resources are required to train FlowSteer?\n\n### Motivational Problems\n\nI am concerned about the complexity of the proposed approach given the marginal gains -- training, substantial code, and an ODE solver are required. Could similar results be achieved by training, for example, an affine map, a LoRA, or a single full layer? Moreover, while I see the benefit of reducing distribution mismatch, I’m not convinced it is the primary obstacle preventing steering methods from achieving high performance. [3] show that when steering vectors are trained directly on the objective of interest, they can match full-weight training. The paper would benefit from a deeper discussion of its motivation and limitations in light of these two concerns.\n\n## References\n\n[1] Shao, Rulin, et al. “Spurious rewards: Rethinking training signals in RLvR.” arXiv:2506.10947 (2025).\n\n[2] Liu, Zichen, et al. “Understanding R1-zero-like training: A critical perspective.” arXiv:2503.20783 (2025).\n\n[3] Sinii, Viacheslav, et al. \"Steering LLM Reasoning Through Bias-Only Adaptation.\" arXiv preprint arXiv:2505.18706 (2025)."}, "questions": {"value": "* Please clarify what a single source–target pair comprises and how each component is computed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4yBgeE4U38", "forum": "GjsE9C1grt", "replyto": "GjsE9C1grt", "signatures": ["ICLR.cc/2026/Conference/Submission36/Reviewer_wQxn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission36/Reviewer_wQxn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission36/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849964407, "cdate": 1761849964407, "tmdate": 1762915440419, "mdate": 1762915440419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}