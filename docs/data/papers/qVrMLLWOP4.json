{"id": "qVrMLLWOP4", "number": 12019, "cdate": 1758205219578, "mdate": 1759897538819, "content": {"title": "Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication", "abstract": "Homonyms are words with identical spelling but distinct meanings, which pose challenges for many generative models. When a homonym appears in a prompt, diffusion models may generate multiple senses of the word simultaneously, which is known as homonym duplication. This issue is further complicated by an Anglocentric bias, which includes an additional translation step before the text-to-image model pipeline. As a result, even words that are not homonymous in the original language may become homonyms and lose their original meaning after translation into English. In this paper, we introduce a method for measuring duplication rates and conduct evaluations of different diffusion models using both automatic evaluation utilizing Vision-Language Models (VLM) and human evaluation. Additionally, we investigate methods to mitigate the homonym duplication problem through prompt expansion, demonstrating that this approach also effectively reduces duplication related to Anglocentric bias. The code for the automatic evaluation pipeline is publicly available.", "tldr": "", "keywords": ["Homonym Duplication", "Diffusion Models", "Prompt Expansion"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ea172336f05fc6e1fc7c83e1572f2194c9279516.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the rate at which VLMs generate multiple senses of homonyms--identically spelled words with multiple distinct meanings--when prompted with just the single word. They curate a list of 171 frequently used homonyms in English to create a benchmark quantifying the duplication rate using both human crowdsourced evaluation as well as VLM as a Judge methods. The human evaluation showed 5% of images containing duplicates. Next, the authors investigate the Anglocentric bias in VLMs through this lens, since models tend to translate non-English prompts into English before generation, potentially resulting in images depicting the wrong meaning of the original word. By curating the list of 171 homonyms into distinct translations in Russian, they find that up to 50% of images generated depicted the wrong sense of the word. Using prompt expansion techniques in the original language proved to be an effective mitigation, dropping the rate to 22%."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper is very well written and easy to follow. I especially appreciate the thorough related works and clear examples in Fig 1.\n- The problem of the anglocentric bias of the homonym duplication problem is novel and important. The results show pretty definitively that this problem is widespread and a simple mitigation (prompt expansion) is fairly effective.\n- The homonym list curation is very thorough and sound, including linguistic experts as well as experienced translators. \n- Eight diffusion VLMs were evaluated across various sizes and families\n- I found the proper name bias analysis interesting"}, "weaknesses": {"value": "1. The automatic evaluation seemed to have pretty low agreement with humans, so I'm not really sure how reliable it is. The human evaluations also have only 90% instances with a consensus, it would strengthen the paper to address this. For example, the authors/additional annotators/expert annotators could make a determination on these cases. \n2. The single-word prompt into the models, while specially designed to be ambiguous for the sake of evaluation, are not realistic. It could be interesting to see if this phenomenon occurs in slightly more realistic prompt templates (e.g. \"Generate an image of [word]\" or variations thereof). This would also be closer to the expanded prompt scenarios.\n    - On a related note, the prompt expansion mitigation didn't fully solve the problem (decreased by only half a percent on human eval). It would strengthen the paper to include an error analysis here. For example, did the cases in which duplicates were found for expanded prompts due to the expanded prompt also being ambiguous as to the meaning of the word? \n3. In the human evaluation, only about 5% of instances were judged as duplicates. How does this compare to prior works investigating this phenomenon? Even if it's not the same exact models, it would be good to have a sense of whether the frequency is in the same ballpark or not. \n    - In general, the paper lacks a discussion on how the findings fit into the related literature. Including this would greatly strengthen the paper.\n4. All figures are low resolution and the text is extremely small (esp Figs 2-5), making them very hard to read. I'd suggest uploading them as PDFs in the LaTeX so they maintain resolution, as well as increase the text size to match the actual font of your paper."}, "questions": {"value": "Please address the questions in the weaknesses section first. Below are more things I'm curious about.\n- It would be cool to see if the Anglocentric bias issue occurs in any VLMs that are stronger multilingual models (ie don't rely on a translation). \n\n- Why do you use \"VLM\" in most of the paper, but in line 339 \"VLLM\"? Is this intentional?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PJJgY1dsNr", "forum": "qVrMLLWOP4", "replyto": "qVrMLLWOP4", "signatures": ["ICLR.cc/2026/Conference/Submission12019/Reviewer_FQia"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12019/Reviewer_FQia"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761581640450, "cdate": 1761581640450, "tmdate": 1762923005594, "mdate": 1762923005594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the systematic failure mode of the diffusion-based text graph model when dealing with homonyms (for example, \"palm\" can refer to both the palm of the hand and the palm tree): the model tends to \"play it safe\" and draw all possible meanings in the same diagram, rather than picking the most appropriate semantics. The authors call this phenomenon \"homonym duplication\" . The authors point out that this phenomenon not only affects English prompts, but is also related to \"Anglocentric bias\": many generative systems translate non-English prompts into English before inference. As a result, words that were originally unambiguous in the source language are translated into English homographs, thereby introducing non-existent ambiguity and leading to incorrect or repeated generation (for example, the Russian word that clearly means \"date/meeting\" becomes \"date\" after translation into English, which may trigger two images of \"date fruit + date on the calendar\")."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Systematic Benchmark + Large-Scale Empirical Research:\n• 171 homographs (across English and Russian), 94,000+ generated samples, 430,000+ manual annotations, and coverage across 11 major open-source diffusion models. The scale and coverage are both high, sufficient to support the conclusions.\n2. Pragmatic Metric Design:\n• HDR directly addresses the user-perceivable problem of \"multiple meanings appearing in a single image,\" rather than an abstract embedding score.\n• PFFR explicitly distinguishes between \"the model doesn't actually draw the image\" and \"the model draws the image correctly but without ambiguity,\" preventing the misjudgment of \"low HDR = good.\""}, "weaknesses": {"value": "1. The HDR metric itself relies on subjective judgment: Whether it's human annotators or the VLM, each is subject to personal interpretation or inherent model bias, resulting in non-objective and reproducible conclusions about whether an image exhibits polysemy.\n2. The consistency between automated and human evaluation remains low: Although the authors report a moderate AUROC*, the overall correlation remains unstable, making it difficult to consider automated evaluation as a reliable alternative.\n3. The proposed LLM expansion method did not significantly reduce HDR under human evaluation, only down by 0.5 points: The reduction in HDR using human annotators' metrics was limited, suggesting that the actual user benefits of this mitigation may be overestimated."}, "questions": {"value": "In your results, (1) HDR determination is inherently highly subjective/model-biased, (2) the correlation between automated and human evaluations is low, and (3) LLM expansion does not significantly reduce HDR under human evaluation. Given these three points, how do you support the conclusion that \"our approach is effective and can serve as a general mitigation solution/evaluation pipeline\"? Specifically, can you provide: the significant reduction in HDR under human evaluation, and why we can trust automated evaluation when there is a discrepancy between automated and human evaluations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O9nG6Il6Zd", "forum": "qVrMLLWOP4", "replyto": "qVrMLLWOP4", "signatures": ["ICLR.cc/2026/Conference/Submission12019/Reviewer_Dzi9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12019/Reviewer_Dzi9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761582801218, "cdate": 1761582801218, "tmdate": 1762923005207, "mdate": 1762923005207, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the homonym duplication problem in text-to-image (T2I) generative models, where a single ambiguous word is rendered with multiple meanings within the same generated image. To examine this issue, the paper constructs a list of homonyms and uses it to evaluate 11 T2I models. To alleviate the problem, it proposes a simple prompt expansion technique that uses a large language model (LLM) to rewrite single-word prompts into longer, disambiguated descriptions before passing them to the T2I models."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper tries to address the homonym duplication problem in T2I generative models, which is an under-explored topic in the current literature."}, "weaknesses": {"value": "1. Problem formulation. \n   - The paper addresses the homonym duplication problem only for single-word prompts. This is an unrealistic setting for modern T2I applications, as real-world prompts are typically longer and more descriptive. The study should extend its scope to include general prompts rather than limiting itself to single-word cases.  \n   - The negative impact of homonyms (or polysemous words) in T2I generation is not limited to duplication; it also includes the generation of undesired or incorrect concepts [1]. The paper does not clearly justify why it focuses exclusively on the duplication.\n\n2. Limited novelty. \n   - The proposed evaluation metric is just a simple majority-voting, which limits its novelty.  \n   - The proposed prompt expansion technique merely rewrites a single word prompt through textual expansion using an LLM. This approach lacks novelty and may unintentionally distort the meaning of the original prompt.  \n\n3. Filtering criteria of the homonym list. \n   - To serve as a meaningful benchmark, the filtering criteria used to construct the homonym list should ensure that the selected homonyms are representative and unbiased. However, some criteria described in Section 3.2 appear to prioritize annotation convenience over representativeness or importance of homonyms.\n\n[1] \"Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models.\" (ICLR 2025)"}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "DkvgA8PXoC", "forum": "qVrMLLWOP4", "replyto": "qVrMLLWOP4", "signatures": ["ICLR.cc/2026/Conference/Submission12019/Reviewer_Ci4d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12019/Reviewer_Ci4d"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761637461093, "cdate": 1761637461093, "tmdate": 1762923004810, "mdate": 1762923004810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}