{"id": "72TN9UAtNI", "number": 14451, "cdate": 1758235741238, "mdate": 1759897369341, "content": {"title": "Emotions Where Art Thou: Understanding and Characterizing the Emotional Latent Space of Large Language Models", "abstract": "This work investigates how large language models (LLMs) internally represent emotion by analyzing the geometry of their hidden-state space. Using a synthetic dataset of emotionally rewritten sentences, we identify a low-dimensional emotional manifold via singular value decomposition and show that emotional representations are directionally encoded, distributed across layers, and aligned with interpretable dimensions. These structures are stable across depth and generalize to eight real-world emotion datasets spanning five languages. Cross-domain alignment yields low error and strong linear probe performance, indicating a universal emotional subspace. Within this space, internal emotion perception can be steered while preserving semantics using a learned intervention module, with especially strong control for basic emotions across languages. These findings reveal a consistent and manipulable affective geometry in LLMs and offer insight into how they internalize and process emotion.", "tldr": "", "keywords": ["emotions", "latent space"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5f8499966acebb8a21367ea9d946fc2d4e903227.pdf", "supplementary_material": "/attachment/1133144bcedd62c1281e4628007ac9079b283f2e.zip"}, "replies": [{"content": {"summary": {"value": "The authors analyze consistency of the underlying geometry of emotions in LLMs. They present several studies to support their claims: similarity metrics of synthetic to real samples, dimensionality reduction of the space to discover lower-dimensional structure in a principled manner, and steering representation to study whether the space behaves predictably."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The authors present many metrics and models, as well as some useful baselines in the appendix to contextualize the numbers\n- Many studies are presented to corroborate the claims of the paper instead of building a case from only a single case.\n- The authors use existing theoretical work in emotion to ground their findings."}, "weaknesses": {"value": "- Manuscript is very difficult to read, with methodology blended with experiments, making it very difficult to follow what is currently being presented. For example, what is Table 2 showing (L210)? Same with L230, and all of the subsequent sections (5 and 6). I found myself jumping back and forth constantly, trying to understand what is being compared to what and how. Moreover, some numbers seem to be presented in the text only. I would appreciate clearer methodology in the rebuttal, as some concepts are also not explained at all.\n- Tables 1 and 3 contain so much information that it becomes very difficult to figure out what the takeaway from each should be. A better mode of presentation would be preferable, and the full tables can be in the appendix for the interested reader.\n- Figure 2 could be improved, perhaps by showing the projection to the Dominance-Valence plane. As it is now, sad and happy seem to have the same embedding (meaning the same valance value, among the other dimensions). As a result, the study this corresponds to I believe would benefit from some quantification to substantiate the claim.\n- The fact that from layer 0 to layer 31, the % of neurons remains the same might indicate that the clustering is happening because of word embeddings themselves rather than emotion content per se. This is because we would expect higher-level emotional content to emerge after processing in later layers, except if it based on individual words.\n\nTo reiterate, the main weakness of the paper is its lack of clarity, not necessarily a lack of substance or novelty."}, "questions": {"value": "- Formatting errors: the authors have used the wrong citation format (every citation is used outside of parenthesis, probably showing some lack of care when switching between templates)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MOSMbouBb7", "forum": "72TN9UAtNI", "replyto": "72TN9UAtNI", "signatures": ["ICLR.cc/2026/Conference/Submission14451/Reviewer_3kjH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14451/Reviewer_3kjH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761527078660, "cdate": 1761527078660, "tmdate": 1762924854880, "mdate": 1762924854880, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an investigation on how LLMs represent emotions in their latent spaces. It finds generalizable evidence that emotion is confined to a few critical dimensions that can be interpreted and manipulated. The authors then present a new method for steering controls to improve emotion classification. The authors robustly back up these central claims through several methods and across multiple languages and datasets. I particularly appreciate the multi-lingual analysis to demonstrate that these findings are generalizable. While paper itself provides some interesting and novel findings, but the presentation is somewhat unclear and messy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper presents the first investigation on emotional latent space representations in LLMs, and I believe the techniques used are novel and interesting.\nThe authors provide analysis on many different perspectives, styles, and languages, which adds to the robustness of their findings.\nThe new steering method introduced presents a new way to consider how to change emotions: by focusing on changing the underlying emotional subspace rather than focusing on downstream output."}, "weaknesses": {"value": "It is unclear exactly what Table 2 is measuring, specifically in regards to cosine similarity and MSE. The paper states high cosine similarity between emotions in real datasets and their synthetic counterparts: what synthetic counterpart are we referring to? Does this reference the Reichman et al. synthetic dataset? Table 2 does not mention which method it utilized as well. What does it mean to measure the cosine similarity of an emotion between two datasets, what datum from each dataset is actually being passed in? Same to MSE and the other metrics. I would recommend rewriting this section to be clearer, as in its current state I was unable to understand exactly what is going on.\n\nOn that note, it is not clear exactly what the experimental setup in 4.2 is. I would appreciate some more clarity on the exact methods used, number of experiments, etc. In particular, I feel like the distortion metrics should be clarified on what they actually represent, as this information is not present in the paper and should not assumed to be common knowledge.\n\nThe presentation of the paper is not very clear; the sections seem rather disjoint and clarifying figures are somewhat lacking throughout. While I believe the content is novel and unique, a rewrite for clarity would improve this paper significantly."}, "questions": {"value": "Does the Space Alignment method rely on the same Reichman et al. dataset that Centered-SVD does? If so, please state that explicitly.\n Additionally, it would seem to me that the performance of Centered-SVD and/or Space Alignment would highly depend on the quality of this underlying training dataset. I would appreciate some clarity quantifying the quality of this Reichman dataset (or justifying why it was chosen) as this choice seems to be integral to both of these methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kMz5YvLYtV", "forum": "72TN9UAtNI", "replyto": "72TN9UAtNI", "signatures": ["ICLR.cc/2026/Conference/Submission14451/Reviewer_bf2Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14451/Reviewer_bf2Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955615983, "cdate": 1761955615983, "tmdate": 1762924854198, "mdate": 1762924854198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how large language models (LLMs) internally represent emotion by analyzing the geometry of their hidden states. Using models like LLaMA 3.1, Olmo-v2, and Ministral across eight multilingual datasets, the authors find a low-dimensional emotional manifold that aligns with psychological dimensions such as valence, dominance, and arousal. These representations are directional, distributed, and consistent across layers and languages. Through SVD and neuron-level analysis (ML-AURA), the paper shows that emotional axes are stable and interpretable. A learned steering module further demonstrates that these internal states can be manipulated predictably without altering semantics, revealing a coherent and controllable affective geometry in LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a comprehensive, cross-lingual study covering eight datasets in five languages, offering strong evidence for the universality of LLM emotion representations.\n- The use of ML-AURA and SVD-based analyses provides a rigorous and interpretable framework for linking internal neuron activity to affective semantics.\n- The learned steering module demonstrates practical control of emotion representations while preserving meaning, which is an innovative advance beyond descriptive analyses."}, "weaknesses": {"value": "- While broad in scope, the work is methodologically complex, and the abundance of metrics (stress, distortion, spectral flatness, etc.) may obscure key takeaways.\n- The evaluation relies heavily on synthetic emotion text for subspace construction, which may bias the identified directions.\n- Although the paper claims semantic preservation under steering, this is mostly supported by cosine similarity metrics rather than human evaluations."}, "questions": {"value": "- How does the emotional manifold evolve across training or fine-tuning stages? Does it emerge early or gradually with language exposure?\n- Could the authors validate the psychological interpretability of latent axes quantitatively (e.g., correlations with human valence/arousal ratings)?\n- Does the steering module modify only internal representations, or can it predictably change generated emotional tone in open-ended text?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nnskAa4iLD", "forum": "72TN9UAtNI", "replyto": "72TN9UAtNI", "signatures": ["ICLR.cc/2026/Conference/Submission14451/Reviewer_UVfz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14451/Reviewer_UVfz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968922556, "cdate": 1761968922556, "tmdate": 1762924853733, "mdate": 1762924853733, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes how large language models (LLMs) internally represent emotions. Through geometric and probing analyses, the authors identify a low-dimensional “emotional subspace” embedded across model layers, in which affective states are encoded directionally and often linearly decodable. They show this structure generalizes across multiple emotion datasets and five languages, producing a broadly consistent emotional manifold. The authors further develop a learned steering module that can intervene on hidden states to shift the model’s internal emotional perception toward target emotions while largely preserving semantic content; evaluations report strong post-steering classification accuracy for many basic emotions across models and languages. The study combines alignment metrics (cosine similarity, regression error), distortion/stress diagnostics, linear probes, and qualitative rewriting examples to characterize representation geometry, cross-domain robustness, and steerability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Identification of a low-dimensional, directionally encoded emotional manifold: The paper demonstrates that emotions in LLMs occupy a low-dimensional subspace that is interpretable and directionally organized across layers, with principal axes (PC1–PC3) showing high rank correlations in many models/layers.\n- Cross-dataset and multilingual generalization of emotional structure: Using eight emotion datasets spanning five languages and diverse textual styles, the authors show that the extracted emotional subspace generalizes (low alignment distortion, above-chance linear probe accuracy), supporting the existence of a near-universal affective subspace in multiple LLM families.\n- A learned intervention/steering module that controls internal emotional representations: They introduce and evaluate a module that shifts hidden states toward target emotions. Post-steering emotion prediction rates typically rise substantially (often >85% for many emotions), while semantic-similarity loss remains low, indicating control without wholesale semantic degradation. The method is evaluated across model families and languages, with ablations in the appendix."}, "weaknesses": {"value": "- Geometry vs. local distortion — inconsistent relational preservation: Although global alignment measures (cosine, regression) are often strong, stress and distortion analyses reveal notable local warping of relative geometry in many layers and datasets. Thus the emotional manifold is not uniformly faithful to human emotion-space relations, which complicates interpretation and downstream use.\n- Uneven multilingual and dataset robustness: Performance and steerability degrade in lower-resource settings (e.g., some emotions in Hindi/Bhaav), and certain datasets (e.g., Go-Emotions) show high layer-wise distortion. This suggests lexical sparsity, annotation imbalance, or domain mismatch limit universality claims and practical applicability across all languages/styles.\n- Potential semantic and safety/ethical concerns with steering: Although semantic-similarity loss is reported low, steering produces surface rewrites that can alter tone, register, or pragmatics (examples show forceful rewrites for anger). The paper does not deeply address possible misuse (manipulating perceived emotion), downstream impacts on user trust, or safeguards for safe deployment. Additionally, steering effectiveness varies across emotions and models; some target emotions remain difficult to induce reliably."}, "questions": {"value": "SEE WEAKNESS"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NO"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "f6TMSFpDmr", "forum": "72TN9UAtNI", "replyto": "72TN9UAtNI", "signatures": ["ICLR.cc/2026/Conference/Submission14451/Reviewer_hPou"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14451/Reviewer_hPou"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973127938, "cdate": 1761973127938, "tmdate": 1762924853326, "mdate": 1762924853326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}