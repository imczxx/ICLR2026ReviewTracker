{"id": "fvCHkWbdgX", "number": 4922, "cdate": 1757807538546, "mdate": 1759898004863, "content": {"title": "PROTDYN: A FOUNDATION PROTEIN LANGUAGE MODEL FOR THERMODYNAMICS AND DYNAMICS GENERATION", "abstract": "Molecular dynamics (MD) simulation has long been the principal computational tool for exploring protein conformational landscapes, but its application is limited by high computational cost. We present ProTDyn, a foundation protein language model that unifies conformational ensemble generation and multi-timescale dynamics modeling within a single framework. Unlike prior approaches that treat these tasks separately, ProTDyn allows flexible i.i.d ensemble sampling and dynamic trajectory simulation. Across diverse protein systems, ProTDyn yields thermodynamically consistent ensembles, faithfully reproduces dynamical properties over multiple timescales, and generalizes to proteins beyond its training data—offering a scalable and efficient alternative to conventional MD simulations.", "tldr": "A unified generative model for simultaneously generating protein conformation ensemble and dynamic trajectories", "keywords": ["Transformer", "Protein Language Model", "Protein ensemble generation", "Protein dynamics", "generative model"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7d67140b62bd08a40ae08bb937158bfd274af7ae.pdf", "supplementary_material": "/attachment/a2b73c600a1cee9a68c8a2c6c57f4ab3589a825a.zip"}, "replies": [{"content": {"summary": {"value": "The work proposes ProTDyn, a model that is able to do conformation ensemble generation and multi-timescale dynamics modeling within a single model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-written and easy to follow. The fact that the authors present a model that is able to perform simultaneously equilibrium conformation ensemble generation and multi-timescale dynamic trajectory generation is interesting and as far as I am aware novel."}, "weaknesses": {"value": "As the paper is not near my main area of research, it is hard for me to make questions or comment on the weaknesses although I found the paper easy to follow and appreciated especially the explanation on page 4. \n\nThe paper is a rather standard application of ML modelling techniques but unfortunately I cannot comment on the strength of the results. For this reason I will leave a weaker confidence score."}, "questions": {"value": "I'm slightly confused by Figure 1 as the authors mention it is a language model, but there does not seem to be language/text as input in the diagram. Could the authors please clarify? Are the authors using \"language model\" to highlight the fact that it is an autoregressive (causal/decoder) Transformer architecture and not that the input is language."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ggOklTNLme", "forum": "fvCHkWbdgX", "replyto": "fvCHkWbdgX", "signatures": ["ICLR.cc/2026/Conference/Submission4922/Reviewer_x8Ec"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4922/Reviewer_x8Ec"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753355929, "cdate": 1761753355929, "tmdate": 1762917769338, "mdate": 1762917769338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors present ProTDyn which is a transformer operating on ESM3 structure tokens trained for conformation and dynamics sampling. The model is trained on a mixture of the alphafold synthetic database of structures and molecular dynamic datasets. It is trained for both equilibrium distribution sampling as well as jumping ahead in MD simulations or inpainting in between coarse time steps in MD simulations. The model improves over BioEmu, a recent deep learning model for conformer generation, in terms of distributional match to MD."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The training of the model is simple in that all 3 tasks of thermodynamics, dynamics and dynamics inpainting are trained jointly and simultaneously in a single model. This avoids the need for any task specific fine-tuning which is a downside of prior approaches. All tasks are unified in terms of autoregressive modelling with different factorizations.\n\nThe experimental results look strong in terms of improvement over the BioEmu baseline model. Distibutional fit on MD test data looks quite convincingly better in Table 1 and in Figure 2.\n\nThe authors make some interesting observations in terms of the time resolution with which to sample their dynamics model. They find that sampling with a finer grid can lead to worse overall performance potentially due to error accumulation. This finding will be useful for further research into deep learning based dynamics models."}, "weaknesses": {"value": "A main weakness of the paper is the lack of ablations with respect to the stated contribution of ProTDyn being a unified model for Thermodynamics and Dynamics generation. On L56-L58 in the introduction the authors describe how joint training can be mutually beneficial for both tasks. I would therefore expect experiments and ablations showing that this is indeed the case. You could train a version of your model on the tasks individually and compare performance with the multi-task trained model. I don't think comparing to BioEmu is enough to make this claim since BioEmu is pretrained on Thermodynamics style tasks and fine-tuned on dynamics tasks which can be seen as a form of multitask training.\n\nWith regards to Table 2, where these proteins are in your test set but BioEmu's training set, I am unsure how ProTDyn ended up with a different test set to BioEmu that made this comparison difficult. If you are using the same datasets as BioEmu, why not also use the same splits? In the end, it makes it very hard to draw any conclusions from Table 2 since the models are not comparable.\n\nThe paper is quite unclear with the usage of the term 'module'. The authors state that they have a 'thermodynamics module' and a 'dynamics module'. This would imply separate parts of the network that are being trained for these two tasks which would be in contradiction with the introduction describing a single unified model which is a key stated contribution of the work. I am unsure what the authors are referring to with regards to these modules and this should be made clearer. \n\nFurther, in terms of clarity, on L149 the authors describe their model as a 'multimodal protein language model'. In what way is this a multimodal model because as far as I am aware the model just generates structural tokens (and no other modalities).\n\n\nI am tending to accept this paper due to the strong experimental results with regards to BioEmu and simple training scheme. This model seems to make a significant improvement on the state of the art for conformational modelling."}, "questions": {"value": "Why did you decide to use a causal autoregressive distribution for the generation of structural tokens? In ESM3, an any-order autoregressive model was used to generate tokens in parallel which seems to make sense for protein data. Did you try any other parameterizations?\n\nHow were the proteins in Figure 2 selected? If these were cherry-picked as to best show the benefits of your method this should be stated clearly. Or if these are exhaustive of the CATH2 dataset, this should also be made clear because this is important for judging the significance of your findings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Dex90fdW3x", "forum": "fvCHkWbdgX", "replyto": "fvCHkWbdgX", "signatures": ["ICLR.cc/2026/Conference/Submission4922/Reviewer_7aKu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4922/Reviewer_7aKu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864556235, "cdate": 1761864556235, "tmdate": 1762917768863, "mdate": 1762917768863, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ProTDyn, a foundation PLM to unify equilibrium distribution sampling, time-dependent dynamics sampling as well as inpainting for fine-grained timesteps based on coarse grained timesteps. It has been trained on a large scale molecular dynamics dataset, and demonstrated promising performance in the generated sample distribution in comparison with baseline models. I find this methodology very interesting and novel, and has shown scaling up in the model and data."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Novel methodology**\n- The method is novel to incorporate three tasks in one model:\n  1. i.i.d. equilibrium distribution sampling\n  2. time lagged predictions with multiple time scales\n  3. inpainting: given two coarse grained time steps, predict fine grained steps in between\n- This methodology overcomes the lack of capability in the description of dynamics/kinetics in the equilibrium sampling models\n\n**Transferability**\n- The model is trained on multiple time scales, showing transferability in the time dependence\n- The model is trained on a large scale of MD data, showing transferability in the chemical space\n\n**Performance**\n- The performance has been compared on MD sample distributions with proper baselines and benchmarks, and has demonstrated the advantage of this model"}, "weaknesses": {"value": "- **Generalization**: For the dynamics tasks, the test proteins were seen by the model during thermodynamics training, which may not represent true generalization. A stronger evaluation would involve holding out proteins based on sequence similarity\n- **Baseline**: This model is only compared against BioEmu as the only baseline. It can consider adding more baseline models, such as Alphaflow which is also trained on mdCATH, as well as a few other works that baked in the time dependence for dynamics generation of protein models.\n- **Inpainting task**: Dynamics inpainting is highlighted as a key capability, but its performance is only measured indirectly through the quality of the final, end-to-end generated trajectories. There are no specific benchmarks that isolate and quantify the accuracy of the inpainting process itself"}, "questions": {"value": "- Could you clarify the train/test splitting procedure? Was any filtering based on sequence identity or structural similarity\n- Have the authors considered other architectures such as those AF-based models? What was the specific rationale for choosing the ESM3 architecture?\n- BioEmu has been finetuned on experimental data after training on MD, so the comparison on MD distribution might not be the most direct comparison, which can be noted.\n- The method aims to generate coarse-grained dynamics. It'll be helpful to demonstrate the computational cost in comparison with MD simulation\n- Have the authors considered the asymptotic behavior of the time dependence? e.g. when the $\\delta t \\to \\inf$, it should approach an i.i.d. distribution"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1R6MNIXOW8", "forum": "fvCHkWbdgX", "replyto": "fvCHkWbdgX", "signatures": ["ICLR.cc/2026/Conference/Submission4922/Reviewer_NTbS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4922/Reviewer_NTbS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902723040, "cdate": 1761902723040, "tmdate": 1762917768505, "mdate": 1762917768505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a protein foundation model based on ESM3 that unifies equilibrium distribution modelling and dynamics generation for protein structures. Training of the model optimizes the loss for distribution modeling, dynamic trajectory prediction, and dynamic trajectory inpainting at the same time. To enable the modeling of dynamics, ProTDyn proposes two-layer rotary embedding scheme to combine time rotary embedding. Experiment results show that ProTDyn performs than baselines in metrics including distributional similarity. ProTDyn also shows reasonable performance in capturing state transitions consistent with molecular dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper proposes an interesting view of enabling one model for both equilibrium distribution sampling and temporal molecular dynamic modeling.\n\n2.The experiment results prove the effectiveness of the method in distribution modeling compared with strong baselines.\n\n3.The paper is clearly written with the mothod being simple yet elegant."}, "weaknesses": {"value": "1.The benefit of unifying thermodynamics and dynamics generation is not explicitly discussed in this paper. It would be interesting to see how the two tasks interfered with each other in terms of performance. This would also provide stronger support for the motivation of the unification.\n\n2.Some important details of the method are missing. For example, how the “two-layer rotary embedding scheme” is designed to combine temporal and residue positions. Given the model architecture leverages the ESM3 backbone, such details are important for the readers to understand the key adaptation to enabling the dynamics generation.\n\n3.The evaluation metric for the distributional similarity are along low dimensional collective variables. Specifically, distribution along the Rg and RMSD (which are single values not reflecting details of the protein structures) w.r.t. the native structure seems to be less significant in reflecting the true distribution in 3D Euclidean space with all the residues."}, "questions": {"value": "1.Before ProTDyn, the paper “Two for One: Diffusion Models and Force Fields for Coarse-Grained Molecular Dynamics” also discusses how the connections between score-based generative models and force fields can be leverage to train a diffusion model on MD simulations, and the trained score function can be used to simulate MD trajectories. It would be valuable to clarify the difference and advantage of ProTDyn when compared with these methods.\n\n2.It would be interesting to see how ProTDyn works on larger proteins. Particularly, it would both enhance the presentation of the paper and provide more evidence of the generalizability of ProTDyn if the predicted structure/distribution can be demonstrated with figures."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8vdzoupe0L", "forum": "fvCHkWbdgX", "replyto": "fvCHkWbdgX", "signatures": ["ICLR.cc/2026/Conference/Submission4922/Reviewer_87Fq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4922/Reviewer_87Fq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917982788, "cdate": 1761917982788, "tmdate": 1762917768119, "mdate": 1762917768119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}