{"id": "GEtOzC4MIi", "number": 8986, "cdate": 1758106055230, "mdate": 1759897749913, "content": {"title": "Fisher-Rao Sensitivity for Out-of-Distribution Detection in Deep Neural Networks", "abstract": "Deep neural networks often remain overconfident on Out-of-Distribution (OoD) inputs. We revisit this problem through Riemannian information geometry. We model the network's predictions as a statistical manifold and find that OoD inputs exhibit higher local Fisher-Rao sensitivity. By quantifying this sensitivity with the trace of the Fisher Information Matrix (FIM), we derive a unifying geometric connection between two common OoD signals: feature magnitude and output uncertainty. Analyzing the limitations of this multiplicative form, we extend our analysis using a product manifold construction. This provides a theoretical framework for the robust additive scores used in state-of-the-art (SOTA) detectors and motivates our final, competitive method.", "tldr": "", "keywords": ["Deep Learning", "Out-Of Distribution Detection", "Information Geometry"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fc3760da4df82c49b335538d186777f0063212e5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper approaches the OOD detection problem from the perspective of information geometry, using the Fisher–Rao metric. It posits that the *per-sample* trace of the Fisher Information Matrix (FIM) tends to be larger for OOD samples than for in-distribution (ID) ones, meaning that small parameter perturbations cause greater output changes on OOD points. The FIM trace is also interpreted as the product of a \"softmax uncertainty\" term and the magnitude of the penultimate-layer features. Building on this view, the authors propose three OOD detection methods: (1) Standard FIM Trace, using the full last-layer parameter space; (2) Tensor FIM Trace, which projects the two multiplicative components onto subspaces learned from ID data; and (3) Additive FIM Trace, which replaces the product with a weighted sum of these terms and adds a third component capturing the penumltimate features magnitude orthogonal to the learned ID subspace."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**(S1) Presentation and writing:** The paper is clearly written and well-structured. The Fisher Information framework for OOD detection is effectively introduced and its connection to the first two proposed metrics is well motivated (though the link to the third metric remains less clear; see W1).\n\n**(S2) Analysis of FIM trace metric:** The work offers an interesting perspective on the FIM trace with respect to the penultimate layer parameters, interpreting it as the product of a softmax uncertainty term and the norm of the penultimate layer features. This provides a way to understand the factors influencing OOD detection performance in this and prior works."}, "weaknesses": {"value": "**(W1) Motivation for the additive FIM trace score:** My main concern is that the motivation and \"derivation\" of the additive FIM trace score do not align with the Fisher–Rao framework developed earlier in the paper. The additive score is introduced by defining a metric on a product of three manifolds, but this construction is no longer Fisher–Rao, lacks a clear statistical interpretation, and is not derived from information-geometric principles. As a result, the proposed formulation appears to be a post hoc way to connect the additive score to the genuinely FIM-based quantities presented in earlier sections.\n\n**(W2) Dependence on a \"calibration set\":** Although the methods are described as \"post-hoc,\" both the Tensor FIM Trace and Additive FIM Trace require access to a calibration set of ID data to fit the projection matrices $Q$ and $R$ (via PCA and/or LDA). This constitutes an additional training phase and requires at least partial access to ID data. Moreover, the performance of these methods is likely sensitive to the specific dataset, model, and selection of the calibration set. The paper, including Appendix A.2 (\"Sensitivity to calibration set size\"), does not clearly specify how this set is chosen or how its composition (not just its size) affects the results. If the selection is random, no error bars are provided to quantify the corresponding variability.\n\n**(W3) Hyperparameters range and clarity:** The two subspace-based methods depend on several hyperparameters: the dimensions of $Q$ and $R$, the weights $\\lambda_M$ and $\\lambda_y$, and the algorithms used to construct $Q$ and $R$ (PCA or LDA). In the experiments, these choices are made via brute-force search, leaving unclear how they should be selected in practice or how robust the results are across different models and datasets. Overall, the discussion of hyperparameters seems to lack transparency. In addition to the ambiguity around the choice of the calibration set (see W2), Appendix A.3 (\"Sensitivity to $\\lambda$ parameters\") is difficult to understand. It refers to the “top-left” and “bottom-right” of Figure 3 as regions of best performance, which does not correspond to the AUC scores actually displayed in the figure.\n\n\n**(W4, minor) Novelty and related work:** I think the paper's claim that it introduces \"a novel perspective on OOD detection through the lens of Riemannian information geometry\" could be at least partially overstated. Previous works did use Fisher Information for OOD detection, one relatively well-cited example is Kwon et al. (2020) [1]. It would help if the authors clarified the difference from [1] and offer a general discussion of information-geometric methods for OOD detection.\n\nOverall, my main concern is that the paper’s main proposed method does not fit coherently within the information-geometric framework developed earlier (see W1). This raises doubts about the usefulness of the framework itself. If the proposed methods demonstrated substantial empirical improvements over SOTA, this could be less concerning. However, since the paper’s primary goal appears to deepen understanding of the mechanisms behind OOD detection, this is a critical weakness.\n\n\n\n## References\n\n[1] Kwon, Gukyeong, et al. \"Backpropagated gradient representations for anomaly detection.\" European conference on computer vision. Cham: Springer International Publishing, 2020."}, "questions": {"value": "- Does the metric defined on the product manifold to justify the Additive FIM score retain any important properties of metrics defined above? What motivates calling it a “metric” rather than a heuristic combination of components?  \n- How is the calibration set selected (e.g., randomly sampled, curated subset)? \n- Could the authors discuss the relationship to [1]?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "muohJMY4Ao", "forum": "GEtOzC4MIi", "replyto": "GEtOzC4MIi", "signatures": ["ICLR.cc/2026/Conference/Submission8986/Reviewer_LmQv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8986/Reviewer_LmQv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761309907753, "cdate": 1761309907753, "tmdate": 1762920716472, "mdate": 1762920716472, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper reframes Out-of-Distribution (OoD) detection using Riemannian information geometry, hypothesizing that OoD inputs exhibit higher \"local Fisher-Rao sensitivity\" than in-distribution data. The authors first provide a novel theoretical proof (Theorem 5.1) that this geometric sensitivity, quantified by the trace of the Fisher Information Matrix (FIM), mathematically decomposes into the product of two common OoD signals: feature magnitude and output uncertainty. Finally, after analyzing this product's limitations, the paper proposes a \"product manifold\" construction to provide a formal geometric justification for robust additive scores, which motivates their final, competitive \"Additive FIM Trace\" method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper's primary strength is providing a new, unifying geometric language for OoD detection and offers what appears to be the first formal geometric justification for the empirical success of robust additive OoD detectors (like the SOTA method ViM)\n\n* The paper introduces a critical refinement of existing feature-space methods. This is a novel and significant finding that validates a key design choice in its final, competitive \"Additive FIM Trace\" score\n\n* The experimental validation is comprehensive and thorough"}, "weaknesses": {"value": "* The clarity of section 5.3.1 could be improved (I found it difficult to follow and verify). In particular the introduction of the product manifold $M = U \\times U \\times U$ seems unmotivated. Can you add a high-level description of this section? \n\n* The role of the last layer, while clear from a practical standpoint, seems theoretically somewhat arbitrary. Can the authors briefly comment on the role of the remaining parameters (even if the formula become now intractable)? Could they theoretically be added to the statistical manifold? What additional information would this provide? \n\n* The hyper-parameters $\\lambda_M$ and $\\lambda_y$ need to be tuned. Can the authors comment on the range of these parameters for different settings? Are there \"good default\" or the tuning results in widely different values for different settings?"}, "questions": {"value": "See weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wcll4sdr00", "forum": "GEtOzC4MIi", "replyto": "GEtOzC4MIi", "signatures": ["ICLR.cc/2026/Conference/Submission8986/Reviewer_BE7f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8986/Reviewer_BE7f"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761448978060, "cdate": 1761448978060, "tmdate": 1762920716045, "mdate": 1762920716045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes an OOD detection strategy that makes use of information geometric guidance on the last layer of deep neural network model for classification tasks. The strategy implements itself into three different proxies, all based on using trace of Fisher Information Matrix (FIM) as their foundations. The three proxies differ by how the last layer parameter space is decomposed, such that different hyperparameter weights for the traces from each decomposed portions can be applied. The weights, in addition to a couple of projection matrices to decompose the FIM are significant hyperparameters of the proposed OOD detection method. Empirical validations are comprised of ImageNet-based and CIFAR-based scenarios, in which the proposed method is compared to nine other OOD detection methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work in this manuscript proposes a mathematically grounded strategy to approach OOD detection problem for classification tasks. Albeit limited to last layers only, the actual implementation comes in three flavors, making use of trace(FIM) directly, and then decomposing FIM into two pieces, then into three pieces. The last decompostion, which explicitly takes residual orthogonal subspaces seems to make the strategy wholesome and beautifully closed. This gradual improvement makes this work contain educational value as well as researchwise novelty. \n\nThe mathematical complications under the hood of the proposed algorithm are nicely placed in the appendices, in addition to easy-to-read comparison to IGEOOD which also makes use of local geometry of models wrt their parameters. I also appreciate significant portion of work on sensitivity analyses in the appendix.\n\nEmpirical validation section is much richer than a typical theory-oriented manuscript. This is a desirable stance, as the less-mathematically-equipped audience and those who values practical impact much more will find the work more acceptable."}, "weaknesses": {"value": "The key idea would be much more intuitively understood if theorem 5.1 would accompany the contextualized connection to the strategy found in Eq. 8. I found relevant portions in Appendix D, which was a delight, but at the same time, a dismay that this has to be placed in the appendix rather than places like lines 264-266. Also, the opening of the paragraph on lines 328-332 is personally enjoyed but may throw some readers away due to its mathematical brevity. There are some assumptions simply given in that paragraph without any contextual explanation (e.g. assuming nonzero fraction in line 332), whose meaning may be justified intuitively and concisely.\n\nIt seems that this method relies heavily on a good choice of D_val dataset to calibrate the key parameters \\lambda's, R, and Q. The sensitivity to the size of the D_val is in the appendix, but as the method claims to be an OOD detection method that does not require OOD dataset, I think more thorough analysis (either theoretical or empirical) would provide readers much more insight to this method and OOD detection in general.\n\nPlease correct. Two minor typos I found: \n1) on lines 302-303. \"in Eq. equation 9\". \n2) in the equation for F''' in lines 334-335. L2norm-squared looks weird after the first f_{\\hat{\\theta}}(x) (don't you want it embrace the entire f(x) - RR^T f(x), which is already there?)"}, "questions": {"value": "The robustness of the additive decomposition of geometric space from last layer may depend on a well-chosen set of relative weights \\lambda's. The sensitivity analysis results in Figure 3 seems to agree on this, and at the same time suggesting some narrow goldilocks zone, which unfortunately seems to be per-dataset, per-model, a posteriori information which requires grid search. Would there be any alternatives that make this hyperparameter search more theory-guided (more post-hoc, if I were to hijack the term)?\n\nThis is mentioned in the limitation. But let me raise it once more. OOD behavior may be also due to factors hidden in the learnable feature (i.e. the non-last-layer of the NN models). How would this information geometric idea extend to the deeper layers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zcah3lpkth", "forum": "GEtOzC4MIi", "replyto": "GEtOzC4MIi", "signatures": ["ICLR.cc/2026/Conference/Submission8986/Reviewer_ba3P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8986/Reviewer_ba3P"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997541852, "cdate": 1761997541852, "tmdate": 1762920715701, "mdate": 1762920715701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is presenting a new Out-of-Distribution (OoD) detection method (post-hoc method) grounded in information geometry (Riemannian manifold). The authors model a network's predictive distribution as a statistical manifold and hypothesize that OoD inputs exhibit higher \"local Fisher-Rao sensitivity\" than in-distribution (ID) inputs. The paper's first main contribution is Theorem 5.1, which provides a closed-form expression for this sensitivity obtained from the last layer's statistics. Later authors criticize the multiplicative nature of the score and moving into additive version. Competitive with SOTA methods is shown."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Theorem 5.1 provides an analytical, and geometrically-grounded reason why feature magnitude and output uncertainty are such effective signals for OoD detection. It successfully bridges the gap between abstract geometric theory and common empirical practice.\n- The paper clearly explains why a simple product of (magnitude * uncertainty) is a flawed score: ID inputs are (High * Low) while OoD inputs are (Low * High), and these products can be indistinguishable . \n- ablation studies are rich."}, "weaknesses": {"value": "- true motivation is empirical rather than quantitative/theoretical.\n- does U(x) provide any benefit?\n- Wang et al 2022 paper has extremely similar formulation on additive score that authors are presenting. Clarification needed. Conceptual overlap is very strong. Isolate contribution from this paper.\n- why PCA is chosen for class subspace Q? how about other methods like unsupervised methods ?"}, "questions": {"value": "weaknesses section have self-contained questions for each item."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P2mx8Aws2v", "forum": "GEtOzC4MIi", "replyto": "GEtOzC4MIi", "signatures": ["ICLR.cc/2026/Conference/Submission8986/Reviewer_6tV2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8986/Reviewer_6tV2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762212433545, "cdate": 1762212433545, "tmdate": 1762920715242, "mdate": 1762920715242, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a post-hoc OoD detection method based on the per-input trace of the Fisher Information Matrix (FIM) restricted to the final-layer network weights. This acts as a proxy for model sensitivity, which the authors claim is greater for OoD versus ID signals. For a linear softmax head, the authors show that this “standard FIM trace” factorizes into the product of the L2-norm of the final layer features, and a predictive uncertainty term, unifying two well-known OoD signals. They further introduce a more performant “tensor-factorized” variant of this score that involves projecting the final-layer FIM onto a learned subspace, which is constructed from feature and prediction statistics. Finally, they present a more robust additive version of the tensor-factorized score, which they demonstrate is competitive with current SOTA post-hoc OoD detection methods on CIFAR and ImageNet-style benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper gives an interesting information-geometric justification for the use of two popular OoD signals (feature magnitude, prediction uncertainty). The tensor-factorized subspace approach appears novel and meaningful, and the underlying \"orthogonality hypothesis\" (if further supported) could provide a useful principle for designing new OoD detection methods. The empirical evaluation is thorough, and demonstrates that the final additive version of their OoD score consistently attains performance which is competitive with similar state of the art methods. The ablation studies are also reasonably extensive, although some of the details could benefit from additional clarification (see questions)."}, "weaknesses": {"value": "1. The geometric interpretation of the additive score (section 5.3) reads somewhat like a post-hoc justification. That is, the product manifold and metric seem to be engineered so that the trace reproduces the score, rather than the design of the score being informed by some underlying geometric principle. It would be helpful to clarify whether this product manifold is in some sense “canonical”, and whether it offers any insights/uses beyond re-expressing the additive score in geometric notation.\n\n2. The orthogonality hypothesis (Appendix B) proposes that the tangent subspace corresponding to the final-layer weights can be decomposed into two approximately orthogonal subspaces: one determined by the layer inputs (features) and one by the outputs (class predictions). This is an intriguing and potentially quite insightful claim; however, it does not appear to be supported by much empirical or theoretical evidence. Some further investigation in this direction could strengthen the paper.\n\n3. The paper would benefit from a careful editing pass. There are multiple small typos, some notation issues, and also some potential errors in the ablation studies. Several of these have been highlighted in the questions section."}, "questions": {"value": "Ablation Studies:\n\n1. Impact of subspace construction (A.1): it is mentioned that a partial least squares approach is examined for computing the feature subspace. However, this is not included in the results (Table 3). Furthermore, the baseline (no projection) yields slightly different AUROC contributions for the residual and projected norms, which does not make sense. Have these two been mixed up?\n\n2. Sensitivity to score weights (A.3): it is mentioned that the best AUROC performance is attained when the projected norm is high and residual is low (or vice versa), however the graph shows that this occurs along the diagonal (i.e., when both residual and projected norm are high).\n\nMiscellaneous:\n\n1. The use of notation of the form $X_{\\text{Long Text}}$ is a little awkward. For example, something like $S_{x_{OoD}}$ and $S_{x_{ID}}$ could be replaced by $S_x^O$ and $S_x^I$, while $G_{probability}$ and $G_{feature}$ could be $G_p$ and $G_f$.\n\n2. In lines 912-914, the terms $p_{k,\\hat{\\theta}}(x)(x)$ seem like they should be $p_{k,\\hat{\\theta}}(x)$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ZKBtuuTIDG", "forum": "GEtOzC4MIi", "replyto": "GEtOzC4MIi", "signatures": ["ICLR.cc/2026/Conference/Submission8986/Reviewer_1qwa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8986/Reviewer_1qwa"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8986/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762688156044, "cdate": 1762688156044, "tmdate": 1762920714764, "mdate": 1762920714764, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}