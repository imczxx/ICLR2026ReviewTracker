{"id": "AQEnNqRuUU", "number": 9772, "cdate": 1758139357763, "mdate": 1759897699225, "content": {"title": "Neural Decoding through Multi-subject Class-conditional Hyperalignment", "abstract": "Understanding brain dynamics in multi-subject studies is challenging, as each individual exhibits unique neural patterns. Such variability complicates the identification of shared task-related dynamics without carefully accounting for meaningful individual differences. Typical analyses involve fitting subject-specific models separately and aggregating results post hoc. This approach, however, precludes the possibility of information sharing across the models. Hyperalignment methods resolve this by mapping subject-specific responses into a shared latent representational space, but typically require a secondary dataset to learn these mappings by exposing all subjects to an identical, rich and evocative stimulus, such as watching an exciting movie. These datasets are costly to collect and understandably infeasible in nonhuman studies. An alignment method for multi-subject studies that can be applied directly to the primary dataset would be of immense value. To this end, we introduce the Multi-Subject Class-Conditional Hyperalignment ($\\mathbf{MuSCH}$) model which learns aligned latent embeddings of multi-subject data by leveraging class labels available from the experimental protocol of the primary dataset itself. $\\mathbf{MuSCH}$ trains subject-specific encoder networks using a novel Supervised Contrastive Learning framework which simultaneously makes same-class embeddings similar and different-class embeddings dissimilar across subjects. Using both simulation studies and a real memory experiment, we demonstrate how principled information sharing improves the performance of a downstream neural decoding task. Furthermore, by modulating signal strength in the simulated dataset, we show that classification improvements are especially pronounced in regimes with weak signals, a situation commonly encountered in neuroscience investigations. $\\mathbf{MuSCH}$ obviates traditional hyperalignment's onerous prerequisite of a secondary alignment dataset, extending the promise of a single robust and generalizable model to any labeled, multi-subject dataset where subject-specific distortions prevent a joint analysis.", "tldr": "We greatly expand the scope of multi-subject neural datasets available for latent representational alignment by introducing a class-conditional hyperalignment method which can be applied directly to experimental data.", "keywords": ["latent representation learning", "supervised contrastive learning", "hyperalignment"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cadd0bda40bf63191ae574d10cd412e082a2f9be.pdf", "supplementary_material": "/attachment/0f534716b33788f0ec4e3ca34747cf30cf25a4cb.zip"}, "replies": [{"content": {"summary": {"value": "The authors sued supervised contrastive learning and by formulating positive pairs from data across different subjects that share classes. Through this loss objective, a separate encoder was trained for each subject to hyperalign the latent space of neural data across subjects. The proposed method is tested in simulated data and rats' hippocampal spike data performing odor memory task."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "* The problem is well defined and the limitation of the previous methods are well described.\n\n* The work demonstrates successful implementation and training of supervised contrastive learning that uses across-subject pairs to encourage hyperalingment."}, "weaknesses": {"value": "* The definition of equation 1 is not used or proven. It is unclear that the mathematical ground or any empirical evidence that the loss in equation 2 will guarantee (or likely converge to) that the solution will converge to the right hand side of equation 1. As an arbitrary neural network can express an arbitrary function, grounding evidence is crucial that demonstrates the hyperalignment definition in eq 1 can be achieved. \n\n* Mixed results in ablation experiment: putting aside the groundness of the proposed method, the decoding results denoted in Table 1 show that including the proposed training method yields degraded performance from the w/o proposed method (“Aligned-Single”), for many cases. This may imply the proposed loss is not very well compatible or suboptimal in hyperalignment purpose.\n\n* The model evaluation is significantly limited in terms of recruiting baseline models. Only MMVM-VAE is tested. There are other hyperalignment methods listed in the related works. (Some of them need timely aligned stimuli but the dataset can be easily processed to provide such by chunking time span of each category, and dynamic time warping can be used.) Moreover, how the authors trained the model using the dataset they are testing is not elaborated. If they used a pretrained model, it should be made sure that the training/testing distribution exactly matches to provide a fair comparison. \n\n* The proposed methods still require class information and cannot be applied to complex stimuli or behaviors which are hard to define discrete categories.This significantly limits the utility of the method.\n\n* The approach lack novelty that it simply reorganize positive/negative pairs to be recruited across subjects. Due to the above caveats in lack of ground and limited evaluation, this lack of technical novelty is yet to be resolved."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "t2ZAfCmPMB", "forum": "AQEnNqRuUU", "replyto": "AQEnNqRuUU", "signatures": ["ICLR.cc/2026/Conference/Submission9772/Reviewer_GJQJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9772/Reviewer_GJQJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9772/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760972151743, "cdate": 1760972151743, "tmdate": 1762921261607, "mdate": 1762921261607, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The study introduces a supervised contrastive learning framework for class-conditional functional alignment across subjects that does not have the secondary dataset requirement in hyperalignment method. The suggested method jointly class-conditionally-clusters and encodes samples in a lower-dimensional space with supervised contrastive learning, prior to classification."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a novel supervised contrastive method for hyperalignment problem. \n- The application domain is novel, introducing new challenges for the field."}, "weaknesses": {"value": "- Regarding the optimization of the subject-specific encoders, the stopping criterion is not explained in the study. The optimization of encoders and their utility is data dependent, hence a metric is needed to quantify convergence for reproducibility.\n- Since the evaluation is dependent on the chosen decoder architecture, an ablation of network parameters in Section 5 is missing and required for isolating alignment performance from decoder capacity. \n- The decoder that is used to assess how well the suggested method works, is a nonlinear neural network, while the encoders are linear networks. Since a nonlinear neural network gradient is input-dependent, due to saturation mode of the sigmoidal function, its performance is not a reliable identifier of how well the data is separable. In an ablation study, adding the results of a linear decoder is required to more directly measure the improvement in linear separability. \n- The positioning of the study could be strengthened by discussing closely related studies on supervised functional alignment implementations in Canonical Correlation Analysis (CCA) studies, specifically Maxvar-Generalized-CCA and variational-CCA implementations.  \n- An overall method figure for Section 3 is missing, making it harder to grasp the core contribution of the paper. \n- T is introduced without a definition (Line 134-135) that stands for the number of frames in movie-watching task."}, "questions": {"value": "Q: Could you please specify the convergence criteria used for optimizing the subject-specific encoders? For example, was it based on early stopping using a validation loss, a fixed number of epochs, or a performance threshold? Was the target subject held-out data used in the assessment of convergence? Clarifying this is essential for assessing the robustness of the training procedure and for ensuring the results are reproducible."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sgRu78JjFL", "forum": "AQEnNqRuUU", "replyto": "AQEnNqRuUU", "signatures": ["ICLR.cc/2026/Conference/Submission9772/Reviewer_ETex"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9772/Reviewer_ETex"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9772/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761535917660, "cdate": 1761535917660, "tmdate": 1762921260548, "mdate": 1762921260548, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MuSCH (Multi-Subject Class-conditional Hyperalignment), a method for aligning neural data across multiple subjects using contrastive learning. This eliminates the need for secondary alignment datasets required by traditional hyperalignment methods by leveraging class labels (supervised) from the primary experimental dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles a limitation of existing hyperalignment methods—the requirement for expensive, time-consuming secondary datasets with time-locked stimuli. This is especially problematic for animal studies where data collection is hard\n\n- Reproducibility: The author used public dataset and shared with code."}, "weaknesses": {"value": "1. Supervised contrastive learning is a good way to train the model, however, recent works in self-supervised learning (foundation model) in neural data also show extremely well performance for cross-subject/animal/session results. Compare with one of state-of-the-art decoding methods in this field, e.g. POYO+ (ICLR2025), NEDS (ICML2025).\n\n2. Scalability Concerns. What about scale up the method training with 10, 50 animals? Does the N different encoder network still works well?  Computation might be costly?\n\n3. Only one real dataset result. I'm not sure about model's generalization ability."}, "questions": {"value": "- What's the representation of neural data looks like? Are there any clustering effects for subjects or similar tasks?\n\n- Can you show some further analysis on the representations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "f1BMKlc2fY", "forum": "AQEnNqRuUU", "replyto": "AQEnNqRuUU", "signatures": ["ICLR.cc/2026/Conference/Submission9772/Reviewer_pXka"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9772/Reviewer_pXka"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9772/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877462316, "cdate": 1761877462316, "tmdate": 1762921259885, "mdate": 1762921259885, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MuSCH (Multi-Subject Class-Conditional Hyperalignment), a method for aligning neural data across subjects using Supervised Contrastive Learning based on class labels instead of time-synchronized stimuli. This approach eliminates the need for secondary alignment datasets and enables cross-subject neural decoding in nonhuman studies. The method is evaluated on both simulated datasets and real hippocampal spike data from rats performing an odor sequence-memory task. Results show that MuSCH improves downstream decoding accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n1. The use of Supervised Contrastive Learning (SupCon) for multi-subject alignment is new in neuroscience applications.\n2. The method is clearly formulated and mathematically consistent."}, "weaknesses": {"value": "Weaknesses:\n1. The problem of aligning neural representations across subjects is not new, as several existing methods, such as [1][2][3], already address or could feasibly address multi-subject representation learning under different assumptions. However, the authors do not sufficiently discuss these related approaches or clearly delineate how their method conceptually differs from them.\n2. The authors do not compare MuSCH with closely related multi-subject or multi-session decoding models.\n\n\n  \nReferences:  \n[1] Azabou, Mehdi, et al. \"A unified, scalable framework for neural population decoding.\" Advances in Neural Information Processing Systems 36 (2023): 44937-44956.   \n[2] Zhang, Yizi, et al. \"Towards a\" universal translator\" for neural dynamics at single-cell, single-spike resolution.\" Advances in Neural Information Processing Systems 37 (2024): 80495-80521.  \n[3] Zhang, Yizi, et al. \"Neural encoding and decoding at scale.\" arXiv preprint arXiv:2504.08201 (2025)."}, "questions": {"value": "Questions:\n1. How are positive pairs and negative pairs exactly sampled within a batch?  \n2. Why the encoders are frozen before training the decoder, rather than training the whole model end to end? It’s unclear how this design choice affects the adaptability of the learned representations and overall decoding performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yNjfLcW0ig", "forum": "AQEnNqRuUU", "replyto": "AQEnNqRuUU", "signatures": ["ICLR.cc/2026/Conference/Submission9772/Reviewer_GQnF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9772/Reviewer_GQnF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9772/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945203654, "cdate": 1761945203654, "tmdate": 1762921259332, "mdate": 1762921259332, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}