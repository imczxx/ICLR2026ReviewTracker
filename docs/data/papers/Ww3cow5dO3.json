{"id": "Ww3cow5dO3", "number": 14457, "cdate": 1758236073081, "mdate": 1759897368905, "content": {"title": "Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees", "abstract": "The rapid proliferation of high-quality synthetic data---generated by advanced AI models or collected as auxiliary data from related tasks---presents both opportunities and challenges for statistical inference. This paper introduces a GEneral Synthetic-Powered Inference (GESPI) framework that wraps around any statistical inference procedure to safely enhance sample efficiency by combining synthetic and real data. Our framework leverages high-quality synthetic data to boost statistical power, yet adaptively defaults to the standard inference method using only real data when synthetic data is of low quality. \nThe error of our method remains below a user-specified bound without any distributional assumptions on the synthetic data, and decreases as the quality of the synthetic data improves.\nThis flexibility enables seamless integration with conformal prediction, risk control, hypothesis testing, and multiple testing procedures, all without modifying the base inference method.\nWe demonstrate the benefits of our method on challenging tasks with limited labeled data, including AlphaFold protein structure prediction, and comparing large reasoning models on complex math problems.", "tldr": "", "keywords": ["Hypothesis Testing", "Multiple Hypothesis Testing", "Conformal Prediction", "Uncertainty Quantification", "Auxiliary Data"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b5cf30a2565db935a92c995597bb1a6c462eb7c6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes to combine synthetic and real data for statistical inference problems while controlling the risk to a given level. Potential applications include conformal prediction, one-sided hypothesis testing, outlier detection and multiple hypothesis testing. The method, called GESPI, targets a confidence level $\\alpha$, and includes an error term $\\epsilon$. GESPI uses the underlying statistical inference method on the real data with confidence levels $\\alpha$ and $\\alpha + \\epsilon$, and on the combination of real and synthetic data with confidence level $\\alpha$. These results from the three runs are combined in such a way that the result is valid for confidence level $\\alpha + \\epsilon$ regardless of the distribution of the synthetic data, and has higher power than the test only using real data with confidence level $\\alpha$ if the synthetic data is similar enough to the real data. The paper compares GESPI against two baselines: only using real data, and only using synthetic data, both with confidence level $\\alpha$. Across many applications, the results show that GESPI has higher power than either baseline."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper tackles an important problem: data are scarce in many important applications, which limits the effectiveness of reliable statistical procedures. Two of the applications presented in the paper, protein folding prediction and LLM performance comparison, are very good examples of these types of problems. The writing of the paper is generally clear, and the proposed method is original."}, "weaknesses": {"value": "The critical weakness of GESPI is the error term $\\epsilon$: GESPI only has the distribution-free guarantee advertised in the abstract and introduction for a confidence level $\\alpha + \\epsilon$. This means that GESPI should be compared to using only the real data at confidence level $\\alpha + \\epsilon$. However, the formulation of GESPI shows that it would lose this comparison. This can be seen by looking at the result of GESPI in each of Sections 3.1-3.3: in each case, GESPI cannot return a better result than the underlying inference method with confidence level $\\alpha + \\epsilon$. For example, for conformal prediction in Section 3.1, GESPI cannot return a smaller confidence set than the underlying procedure only using real data at $\\alpha + \\epsilon$, which is pointed out in footnote 2. The paper even proves this more generally in Proposition E.1. It is true that the actual type 1 error rate of GESPI may be lower than $\\alpha + \\epsilon$, but this cannot be known without making assumptions on the synthetic data and giving up the distribution-free guarantee.\n\nThis baselines chosen for the experiments conceal this weakness. The baseline using only real data is calibrated to $\\alpha$, not $\\alpha + \\epsilon$, so it is not surprising that it has less power. The proper baseline to compare with would be calibrated to $\\alpha + \\epsilon$. In addition, the baseline using only synthetic data doesn't make sense. It should use the real data in addition to the synthetic data.\n\nMinor points:\n- Figure 2: it is not clear what is the difference between panels (1) through (4) before page 8. This should be in the caption.\n- Line 413: shouldn't the null be $p \\leq 0.5$?"}, "questions": {"value": "No additional questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "n6Kb8j6dCY", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_yUKm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_yUKm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761491254123, "cdate": 1761491254123, "tmdate": 1762924859016, "mdate": 1762924859016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Comment (Part 2)"}, "comment": {"value": "> ### **Comment 3** (Reviewer yUKm, FjoW): authors try to conceal the ``weakness'' of increasing the error by $\\varepsilon$.\n\n**Response**: To clarify, **there is nothing to conceal compared to the worst-case guardrail** (using the real data at level $\\alpha + \\varepsilon$); and there is no ``win or lose'' situation. GESPI is **not competing with the worst-case guardrail---which is instead an integral part of our method**. In fact, Theorem 3.3 formally shows that the GESPI procedure is deterministically sandwiched between the base and the worst-case guardrail. Deterministically, GESPI’s power is always capped by the worst-case guardrail, which is further discussed in the example presented after the theorem.\n \n We can certainly compare GESPI with the method that uses real data at error level $\\alpha + \\varepsilon$, and we include all experiments with this guardrail method in the supporting document in this [link](https://tinyurl.com/rebuttal-exp). However, that method **does not leverage the synthetic data, and therefore still suffers from the low real sample size, even if it is run at a higher level**. Our experiments show that for this reason, this method leads to a large variability (even though the average risk is controlled at $\\alpha + \\varepsilon$, the variance can be much higher than that of our GESPI method). This shows that this method is not uniformly preferable to our method. \n\nTo further illustrate this point, we added a new experiment on class-conditional coverage in image classification. As shown in Figure S1 in this [link](https://tinyurl.com/rebuttal-exp), for the *Magpie* class, the variance of the guardrail method is extremely large due to the small sample size, leading to realized coverage as low as 60\\% even though the target level is 95\\%. In contrast, GESPI achieves coverage close to 95\\% with far lower variability, making it clearly preferable to the guardrail approach in this case.\n\n**Clarification**: We regret not stating earlier in the manuscript that the power of GESPI is capped by the worst-case guardrail. We will ensure it is incorporated in the abstract, introduction, and contributions. As in the standard literature on statistical inference (e.g., hypothesis testing and confidence intervals), we viewed the validity of GESPI as its core underlying theoretical property. Thus, we emphasized that the worst-case guardrail ensures validity, and the base method ensures that the power of GESPI is never worse than the base method.\n\n> ### **Comment 4** (Reviewers FjoW, MhsE, yUKm): lack of baselines.\n\n**Response**: To the best of our knowledge, **there is no other method in the literature that controls risk under arbitrary synthetic data**. The natural ``baselines'' are `OnlyReal` and ` OnlySynth`, where the latter lacks any risk control guarantees and is included solely to illustrate how the unknown quality of the synthetic data can affect the performance (either controlling or not controlling the risk depending on the situation).\n\nWe did not include the worst-case guardrail in the initial manuscript because, as stated in Theorem 3.3, GESPI’s performance is deterministically sandwiched between the base method and the worst-case guardrail, and is in turn capped by the guardrail. Similarly, the pooled real and synthetic baseline was not included initially; like `OnlySynth`, this approach lacks risk control guarantees. These are not really baselines in the classic sense that they are competing with our method, but rather components of our method (our method uses both of them!), and one can think of this comparison more as an ablation study.\n\n**Clarification**: To fully address the reviewers' requests, we include in the supporting document in this [link](https://tinyurl.com/rebuttal-exp) all possible baselines: `OnlyReal`---the base inference method applied to the real data at level $\\alpha$; `Guardrail`---the same as OnlyReal but applied at level $\\alpha+\\varepsilon$; `OnlySynth`---the same inference method applied to the synthetic data at level $\\alpha$; this method does not have error rate control guarantees; and `Synth+Real`---similar to OnlySynth but using the pooled real and synthetic data, which likewise lacks error-rate control guarantees."}}, "id": "wO1645yNOJ", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763650950400, "cdate": 1763650950400, "tmdate": 1763650950400, "mdate": 1763650950400, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose GESPI, a general procedure for combining real and synthetic data to perform statistical inference (e.g., predictive inference, hypothesis testing) while controlling risk at a specified level. The procedure relies upon two “guardrails” to ensure validity: a risk level-$\\alpha$ algorithm, which ensures the algorithm resulting from pooling the real and synthetic data is at least as useful as when using the real data only; and a risk level-($\\alpha + \\epsilon$) algorithm, which ensures that the risk of the pooled algorithm is controlled at level $\\alpha + \\epsilon$. \n\nThe authors effectively demonstrated that GESPI can be applied to many inference problems, including conformal inference and risk control, one-sided hypothesis testing, multiple hypothesis testing, and outlier detection (Sections 3.1-3.3). They subsequently generalize their framework to general statistical inference problems (Section 3.4).\n\nIn Section 3.4.1, the authors prove that the GESPI procedure controls the risk at level $\\alpha + \\epsilon$, and they give an upper bound on the risk of the algorithm that depends on the (unknown) closeness of the real data distribution to the synthetic data distribution. Moreover, they prove that when the risk level-$\\alpha$ algorithm is used as a lower guardrail, the GESPI algorithm will always be at least as useful as this algorithm.\n\nFinally, in Section 4 (and Appendix Section C), the authors demonstrate the varying degrees to which GESPI improves upon the real-only and the synthetic-only algorithms.  Their applications include conformal risk control for protein structure prediction (with AlphaFold2), hypothesis testing for the win-rate of two LLMs on the AIME25 dataset, conformal outlier detection on benchmark datasets, and hypothesis testing for mechanistic interpretability in a vision transformer."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The problem of leveraging synthetic data to perform better statistical inference is well-motivated and timely.\n- The paper is well organized and could be understood by a reader unfamiliar with the related literature e.g., synthetic-power predictive inference, conformal prediction.\n- Unlike recent works [1] that leverage unlabeled data, GESPI does not assume that the distribution of covariates is the same for the labeled and unlabeled data. \n- The general formulation of the GESPI framework (Section 3.4) is elegant, and the main results of the paper (Theorems 3.2 and 3.3) are well-explained.\n- The experimental results for conformal risk control in protein structure prediction and outlier detection are compelling. For the outlier detection example, I would be interested in seeing how the performance of GESPI changes as a function of the size and contamination rate of the reference set.\n- The manuscript includes detailed appendices explaining experimental setup and providing proofs of theoretical results.\n\n[1] Angelopoulos et al., “Prediction-powered inference”. Science, 2023."}, "weaknesses": {"value": "- The authors claim (p. 2)  that when synthetic and real data are well-aligned, GESPI “mimics the effect of applying the base method to a larger real dataset.” I disagree with this claim.\n\nIn particular, suppose one would like to test $H_0: \\mu = 0$ against $H_1: \\mu > 1$ in the normal family $P_{\\mu} = N(\\mu, 1)$. Then according to eq. (3), the power of GESPI under any alternative is at most $P_{\\mu}(Z > z_{1-\\alpha - \\epsilon} - \\sqrt{n} \\mu)$. However, if the synthetic data is also _i.i.d._ from $P_{\\mu}$, then the uniformly most powerful level-$\\alpha$ test achieves power $P_{\\mu}(Z > z_{1-\\alpha} - \\sqrt{n + N} \\mu)$. As $N \\to \\infty$ (the number of synthetic data points increases to infinity), the UMP test has power $\\to 1$, whereas that of GESPI remains constant. More succinctly, the power of GESPI is limited by the real data sample size.\n\nI understand that this is a consequence of the fact that GESPI is a distribution-free method–as pointed out in Appendix C.1–but the authors should be more upfront about this limitation in the main text.\n\n- In the testing experiments (Section 4.2), it’d be helpful to see a comparison to the power of the level-$(\\alpha + \\epsilon)$ OnlyReal test. It is clear that the GESPI test controls Type I error approximately at level $\\alpha$ (and at worst $\\alpha + \\epsilon$), but does it obtain power close to that of the level-$(\\alpha + \\epsilon)$ test?\n\n- The paper could benefit from more specifics about how the general GESPI procedure relates to Synthetic-Powered Predictive Inference procedure from Bashari et al., 2025 [2], either in the main text or in Appendix A.\n\n[2] Bashari et al., “Synthetic-powered predictive inference”. arXiv preprint arXiv:2505.13432, 2025."}, "questions": {"value": "- If a practitioner would like to apply GESPI, how would you advise that they choose $\\epsilon$? Can $\\epsilon$ potentially be chosen as a function of the data (e.g., make $\\epsilon$ large if the empirical distributions of the real and synthetic data look similar)?\n- Related to the normal testing example above, I’d imagine one could quantify the suboptimality of GESPI compared to the pooled (UMP) test against local alternatives when $n, N \\to \\infty$ and $N / n \\to \\gamma$ while $\\epsilon$ remains fixed. Can you give a formal result of this flavor?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HYiQXvfIdN", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_3sMY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_3sMY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761605328645, "cdate": 1761605328645, "tmdate": 1762924858596, "mdate": 1762924858596, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Comment (Part 1)"}, "comment": {"value": "We thank the reviewers for their feedback and for taking the time to review our work. We address all comments separately in a point-by-point manner. But unfortunately, there are some critical misunderstandings that are at the core of our method, as well as factually incorrect comments that we would first like to clarify generally below.\n\n> ### **Comment 1** (Reviewers FjoW, MhsE): minor novelty compared to previous SPI work [1].\n\n[1] Bashari et al. (2025) ``Synthetic-Powered Predictive Inference.''\n\n**Response**: Our work introduces two key contributions that go well beyond a reformulation of SPI as a wrapper. First, **we propose a formulation that is universally applicable to any loss function**, and thus allows us to tackle a broad variety of statistical problems in a unified way. This perspective is in line with one of the most commonly studied perspectives in statistical work, statistical decision theory, a field that formulates statistical problems in terms of loss functions, and which has been widely studied in the literature. Our method does enable using synthetic data with rigorous statistical guarantees in a wide variety of settings, which has not been previously possible. \n \nSecond, **we introduce the new GESPI procedure, which enables using synthetic data with risk-based safety guarantees, and which was not possible before our work**.  This method is not an extension of SPI, but rather a brand new perspective on how statistical inference can safely leverage synthetic data. GESPI is accompanied by new theoretical results, including theoretical results on the power of the method---results that do not exist for SPI. While we clearly give credit to SPI as an inspiration, the scope of GESPI is considerably broader (and the method is different!).\n\nImportantly, SPI is tailored to conformal prediction, and after reading that paper, it was not clear at all how/if that method could be adapted to the broader setting we consider. The SPI method is based on opening windows in the space of scores of synthetic data and mapping the real scores to the synthetic scores. Clearly, the SPI window-based mapping approach is not applicable to the broader setting of loss control that we study here. Even in the conformal prediction setting, our method and theoretical guarantees differ from those in SPI (see Theorem H.1 compared with Theorems 3.3 and 3.5 in SPI).\n\nFinally, **GESPI allows greater methodological flexibility than SPI**. In particular, we can utilize the synthetic data $\\tilde{\\mathcal{D}}_N$ pooled with the real data $\\mathcal{D}_n$, and we can apply any algorithm that takes $(\\tilde{\\mathcal{D}}_N, \\mathcal{D}_n)$ as inputs, while the guardrail bounds still hold; which was not previously possible. This flexibility allows the practitioners to filter, modify, or adapt the synthetic data using data-dependent choices without compromising validity. In contrast, SPI is restricted to applying only the split conformal prediction algorithm solely on the synthetic data.\n\n\n> ### **Comment 2** (Reviewer FjoW): small-scale experiments with modest improvement compared to OnlyReal.\n\n**Response**: **We included six different experimental settings covering a broad range of domains**: conformal risk control for protein structure prediction, hypothesis testing for large reasoning model comparisons, outlier detection with type I error and FWER control across three different benchmarks, hypothesis testing for mechanistic interpretability of vision transformers, and comprehensive simulated data experiments for hypothesis testing.\n\nThus, we believe that **the scale and diversity of our experiments match or exceed those in papers accepted to ICLR or related venues in past years**. In response to the reviewers’ comments (which were not related to experimental scale), we added two further experimental settings (see all experiments are in the supporting document in this [link](https://tinyurl.com/rebuttal-exp)): class-conditional coverage for image classification on ImageNet with FLUX-generated images, and hypothesis testing for hyper-parameter selection for the K-majority vote of a large reasoning model.\n\nFurther, **our experiments strongly support the claim that the improvements can be significant**, especially when synthetic data is moderate to high quality. For this reason, we disagree with the claim that the improvements are modest. In particular, the gains in the outlier-detection experiments and the protein-folding experiments are substantial (see Figures 5 and 3). Specifically, for the outlier detection, we have the same power as the oracle procedure! To summarize, we believe that our experiments convincingly demonstrate the benefits of using our method, which allows practitioners to leverage synthetic data in a safe way."}}, "id": "sb09gSuC5W", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763651032830, "cdate": 1763651032830, "tmdate": 1763651032830, "mdate": 1763651032830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GESPI, a general framework for leveraging synthetic data in statistical inference with guaranteed error-rate control. The method wraps around a base inference algorithm. It runs the base method three times: (1) standard, (2) a more relaxed guardrail version using only real data, and (3) pooled real+synthetic. It then aggregates the outputs to ensure the final decision does not exceed an error-rate bound, even if the synthetic data is misaligned. Experiments span risk-controlled protein structure prediction, model comparison, out-of-distribution detection, and interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It addresses an important and timely problem: using synthetic data safely.\n2. The proposed framework is general, applies to various inference tasks, with finite-sample guarantees providing rigor and confidence in decision-making."}, "weaknesses": {"value": "1. The core idea resembles Synthetic-Powered Predictive Inference (SPI) (Bashari et al. 2025) with a wrapper reformulation. The conceptual advance over existing selective-use-of-synthetic-data methods is modest.\n2. The applications largely show numerical improvements but do not demonstrate meaningful decision changes attributable to GESPI. For example, in AlphaFold experiments, why should abstaining on slightly fewer residues matter biologically?\n3. Lack of baseline: each application should have more baselines. For example, the hypothesis testing should have PPI and PPI++ as baseline. Similar for other applications.\n4. The synthetic data in the experiments is unusually high-quality (e.g., AlphaFold MSAs), biasing results toward success scenarios. In practice, the synthetic data may not be of such high quality"}, "questions": {"value": "1. Can you provide one clear decision-making example where the guardrail version changes the outcome in a scientifically significant way?\n2. How will the other baseline perform in those tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2rUWwaR5mV", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_MhsE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_MhsE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942032905, "cdate": 1761942032905, "tmdate": 1762924858281, "mdate": 1762924858281, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GEPSI, a general framework for incorporating synthetic data into statistical inference while maintaining distribution-free, finite-sample guarantees. \nThe method applies to any inference procedure three times and aggregates the outputs to ensure that the overall error rate never exceeds \\alpha+\\epsilon.\nWhile the framework is conceptually interesting, the contribution is somewhat incremental relative to prior work on synthetic-powered inference (e.g., SPI) and conformal prediction. \nMore importantly, theoretically, should the proposed method maintain the error rate at \\alpha instead of \\alpha+\\epsilon?\nThe intuition is that, if one method has a relaxed error rate control, it should of course have a greater power.\nIn addition, the empirical studies are illustrative but limited in scope and depth, and the practical impact of the proposed method remains unclear."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The method is general and easy to implement, acting as a wrapper for existing inference procedures.\n\nFinite-sample, distribution-free guarantees are theoretically appealing and well-articulated."}, "weaknesses": {"value": "Incremental contribution: The proposed framework closely parallels earlier work such as Synthetic-Powered Predictive Inference (SPI). GESPI mainly reformulates SPI in a more general setting but adds limited new theoretical or methodological insight.\n\nWeak experimental evidence: The experiments are small-scale and largely illustrative. The improvements over the baseline (using real data only) are modest, and the synthetic data setups (e.g., AlphaFold MSA sequences or Olympiad math questions) feel somewhat ad hoc.\n\nLimited novelty in theory: The theoretical guarantees mostly extend standard monotonicity and total variation arguments; there is little fundamentally new mathematical insight.\n\nParameter sensitivity: The \\epsilon parameter plays a critical role in balancing power and validity, yet there is no principled or data-driven way to choose it.\n\nLack of strong baselines: The comparisons omit relevant existing methods for combining heterogeneous datasets, such as transfer learning, domain adaptation, or causal data fusion approaches.\n\nUnclear practical relevance: It is not evident that practitioners would find GESPI advantageous, given the need to rerun inference procedures multiple times and the modest empirical gains."}, "questions": {"value": "How does GESPI differ fundamentally from SPI beyond the reformulation to a more general inference framework?\n\nCould you provide theoretical or empirical comparisons with domain adaptation or semi-supervised learning approaches that also combine datasets from different distributions?\n\nHow sensitive is performance to \\epsilon, and could it be tuned automatically rather than chosen heuristically?\n\nCan the method be applied meaningfully at large scale, where repeated runs of the base inference algorithm may be infeasible?\n\nHow can one assess when synthetic data are sufficiently aligned to expect benefits from GESPI?\n\nShould the proposed method maintain the error rate at \\alpha instead of \\alpha+\\epsilon? Otherwise, it is not a fair comparison with the baseline which controls the error rate at \\alpha.\n\nIn all the numerical studies, should you compare with the method Real+Synth? Why OnlySynth?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Fgr8Nsctba", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_FjoW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_FjoW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960687394, "cdate": 1761960687394, "tmdate": 1762924857912, "mdate": 1762924857912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes General Synthetic-Powered Predictive Inference (GESPI) that can leverage synthetic data samples for statistical inference, while maintaining \"guardrails\" against synthetic data that differs (in quality, but probably also distribution) from the limited real data."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The proposed work is interesting and timely. Its approach is general and not tailored to any particular statistical inference model like prior works. The paper is well-written with a neat exposition that makes it easy to understand for even a general ML audience."}, "weaknesses": {"value": "I do not have any concerns about this work. Some questions I had about the theory are below. Comments related to writing are under \"questions.\"\n\n**Q1. Effect of $n$** and $N$: How does the number of real samples $n$ and the number of synthetic samples $N$ (or their ratio) affect the guarantees in Theorems 3.2 and 3.3?\n\n**Q2. Presence of low quality samples in real data**: If there were a few low quality samples in the real dataset and the synthetic data matched the distribution of good quality real samples, wouldn't GESPI essentially throw out some of the benefits from good quality synthetic data? I understand that this is not the exact scenario for which GESPI was designed, but I would like to know what its behavior would be.\n\n**Q3. Comparison with SPI**: Is it possible to compare GESPI with SPI in conformal prediction experiments on the datasets in this work or the SPI paper?"}, "questions": {"value": "Comments related to writing:\n\n**C1.** Line 284 says \"the synthetic-leveraging procedure...improves upon the standard procedure...\" Can the authors clarify what \"improve\" means here in formal terms?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iCdI3FuoKn", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_SedH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_SedH"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971744662, "cdate": 1761971744662, "tmdate": 1762924857447, "mdate": 1762924857447, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}