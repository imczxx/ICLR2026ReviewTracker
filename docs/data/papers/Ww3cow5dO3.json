{"id": "Ww3cow5dO3", "number": 14457, "cdate": 1758236073081, "mdate": 1759897368905, "content": {"title": "Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees", "abstract": "The rapid proliferation of high-quality synthetic data---generated by advanced AI models or collected as auxiliary data from related tasks---presents both opportunities and challenges for statistical inference. This paper introduces a GEneral Synthetic-Powered Inference (GESPI) framework that wraps around any statistical inference procedure to safely enhance sample efficiency by combining synthetic and real data. Our framework leverages high-quality synthetic data to boost statistical power, yet adaptively defaults to the standard inference method using only real data when synthetic data is of low quality. \nThe error of our method remains below a user-specified bound without any distributional assumptions on the synthetic data, and decreases as the quality of the synthetic data improves.\nThis flexibility enables seamless integration with conformal prediction, risk control, hypothesis testing, and multiple testing procedures, all without modifying the base inference method.\nWe demonstrate the benefits of our method on challenging tasks with limited labeled data, including AlphaFold protein structure prediction, and comparing large reasoning models on complex math problems.", "tldr": "", "keywords": ["Hypothesis Testing", "Multiple Hypothesis Testing", "Conformal Prediction", "Uncertainty Quantification", "Auxiliary Data"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b5cf30a2565db935a92c995597bb1a6c462eb7c6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes to combine synthetic and real data for statistical inference problems while controlling the risk to a given level. Potential applications include conformal prediction, one-sided hypothesis testing, outlier detection and multiple hypothesis testing. The method, called GESPI, targets a confidence level $\\alpha$, and includes an error term $\\epsilon$. GESPI uses the underlying statistical inference method on the real data with confidence levels $\\alpha$ and $\\alpha + \\epsilon$, and on the combination of real and synthetic data with confidence level $\\alpha$. These results from the three runs are combined in such a way that the result is valid for confidence level $\\alpha + \\epsilon$ regardless of the distribution of the synthetic data, and has higher power than the test only using real data with confidence level $\\alpha$ if the synthetic data is similar enough to the real data. The paper compares GESPI against two baselines: only using real data, and only using synthetic data, both with confidence level $\\alpha$. Across many applications, the results show that GESPI has higher power than either baseline."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper tackles an important problem: data are scarce in many important applications, which limits the effectiveness of reliable statistical procedures. Two of the applications presented in the paper, protein folding prediction and LLM performance comparison, are very good examples of these types of problems. The writing of the paper is generally clear, and the proposed method is original."}, "weaknesses": {"value": "The critical weakness of GESPI is the error term $\\epsilon$: GESPI only has the distribution-free guarantee advertised in the abstract and introduction for a confidence level $\\alpha + \\epsilon$. This means that GESPI should be compared to using only the real data at confidence level $\\alpha + \\epsilon$. However, the formulation of GESPI shows that it would lose this comparison. This can be seen by looking at the result of GESPI in each of Sections 3.1-3.3: in each case, GESPI cannot return a better result than the underlying inference method with confidence level $\\alpha + \\epsilon$. For example, for conformal prediction in Section 3.1, GESPI cannot return a smaller confidence set than the underlying procedure only using real data at $\\alpha + \\epsilon$, which is pointed out in footnote 2. The paper even proves this more generally in Proposition E.1. It is true that the actual type 1 error rate of GESPI may be lower than $\\alpha + \\epsilon$, but this cannot be known without making assumptions on the synthetic data and giving up the distribution-free guarantee.\n\nThis baselines chosen for the experiments conceal this weakness. The baseline using only real data is calibrated to $\\alpha$, not $\\alpha + \\epsilon$, so it is not surprising that it has less power. The proper baseline to compare with would be calibrated to $\\alpha + \\epsilon$. In addition, the baseline using only synthetic data doesn't make sense. It should use the real data in addition to the synthetic data.\n\nMinor points:\n- Figure 2: it is not clear what is the difference between panels (1) through (4) before page 8. This should be in the caption.\n- Line 413: shouldn't the null be $p \\leq 0.5$?"}, "questions": {"value": "No additional questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "n6Kb8j6dCY", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_yUKm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_yUKm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761491254123, "cdate": 1761491254123, "tmdate": 1762924859016, "mdate": 1762924859016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose GESPI, a general procedure for combining real and synthetic data to perform statistical inference (e.g., predictive inference, hypothesis testing) while controlling risk at a specified level. The procedure relies upon two “guardrails” to ensure validity: a risk level-$\\alpha$ algorithm, which ensures the algorithm resulting from pooling the real and synthetic data is at least as useful as when using the real data only; and a risk level-($\\alpha + \\epsilon$) algorithm, which ensures that the risk of the pooled algorithm is controlled at level $\\alpha + \\epsilon$. \n\nThe authors effectively demonstrated that GESPI can be applied to many inference problems, including conformal inference and risk control, one-sided hypothesis testing, multiple hypothesis testing, and outlier detection (Sections 3.1-3.3). They subsequently generalize their framework to general statistical inference problems (Section 3.4).\n\nIn Section 3.4.1, the authors prove that the GESPI procedure controls the risk at level $\\alpha + \\epsilon$, and they give an upper bound on the risk of the algorithm that depends on the (unknown) closeness of the real data distribution to the synthetic data distribution. Moreover, they prove that when the risk level-$\\alpha$ algorithm is used as a lower guardrail, the GESPI algorithm will always be at least as useful as this algorithm.\n\nFinally, in Section 4 (and Appendix Section C), the authors demonstrate the varying degrees to which GESPI improves upon the real-only and the synthetic-only algorithms.  Their applications include conformal risk control for protein structure prediction (with AlphaFold2), hypothesis testing for the win-rate of two LLMs on the AIME25 dataset, conformal outlier detection on benchmark datasets, and hypothesis testing for mechanistic interpretability in a vision transformer."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The problem of leveraging synthetic data to perform better statistical inference is well-motivated and timely.\n- The paper is well organized and could be understood by a reader unfamiliar with the related literature e.g., synthetic-power predictive inference, conformal prediction.\n- Unlike recent works [1] that leverage unlabeled data, GESPI does not assume that the distribution of covariates is the same for the labeled and unlabeled data. \n- The general formulation of the GESPI framework (Section 3.4) is elegant, and the main results of the paper (Theorems 3.2 and 3.3) are well-explained.\n- The experimental results for conformal risk control in protein structure prediction and outlier detection are compelling. For the outlier detection example, I would be interested in seeing how the performance of GESPI changes as a function of the size and contamination rate of the reference set.\n- The manuscript includes detailed appendices explaining experimental setup and providing proofs of theoretical results.\n\n[1] Angelopoulos et al., “Prediction-powered inference”. Science, 2023."}, "weaknesses": {"value": "- The authors claim (p. 2)  that when synthetic and real data are well-aligned, GESPI “mimics the effect of applying the base method to a larger real dataset.” I disagree with this claim.\n\nIn particular, suppose one would like to test $H_0: \\mu = 0$ against $H_1: \\mu > 1$ in the normal family $P_{\\mu} = N(\\mu, 1)$. Then according to eq. (3), the power of GESPI under any alternative is at most $P_{\\mu}(Z > z_{1-\\alpha - \\epsilon} - \\sqrt{n} \\mu)$. However, if the synthetic data is also _i.i.d._ from $P_{\\mu}$, then the uniformly most powerful level-$\\alpha$ test achieves power $P_{\\mu}(Z > z_{1-\\alpha} - \\sqrt{n + N} \\mu)$. As $N \\to \\infty$ (the number of synthetic data points increases to infinity), the UMP test has power $\\to 1$, whereas that of GESPI remains constant. More succinctly, the power of GESPI is limited by the real data sample size.\n\nI understand that this is a consequence of the fact that GESPI is a distribution-free method–as pointed out in Appendix C.1–but the authors should be more upfront about this limitation in the main text.\n\n- In the testing experiments (Section 4.2), it’d be helpful to see a comparison to the power of the level-$(\\alpha + \\epsilon)$ OnlyReal test. It is clear that the GESPI test controls Type I error approximately at level $\\alpha$ (and at worst $\\alpha + \\epsilon$), but does it obtain power close to that of the level-$(\\alpha + \\epsilon)$ test?\n\n- The paper could benefit from more specifics about how the general GESPI procedure relates to Synthetic-Powered Predictive Inference procedure from Bashari et al., 2025 [2], either in the main text or in Appendix A.\n\n[2] Bashari et al., “Synthetic-powered predictive inference”. arXiv preprint arXiv:2505.13432, 2025."}, "questions": {"value": "- If a practitioner would like to apply GESPI, how would you advise that they choose $\\epsilon$? Can $\\epsilon$ potentially be chosen as a function of the data (e.g., make $\\epsilon$ large if the empirical distributions of the real and synthetic data look similar)?\n- Related to the normal testing example above, I’d imagine one could quantify the suboptimality of GESPI compared to the pooled (UMP) test against local alternatives when $n, N \\to \\infty$ and $N / n \\to \\gamma$ while $\\epsilon$ remains fixed. Can you give a formal result of this flavor?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HYiQXvfIdN", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_3sMY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_3sMY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761605328645, "cdate": 1761605328645, "tmdate": 1762924858596, "mdate": 1762924858596, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GESPI, a general framework for leveraging synthetic data in statistical inference with guaranteed error-rate control. The method wraps around a base inference algorithm. It runs the base method three times: (1) standard, (2) a more relaxed guardrail version using only real data, and (3) pooled real+synthetic. It then aggregates the outputs to ensure the final decision does not exceed an error-rate bound, even if the synthetic data is misaligned. Experiments span risk-controlled protein structure prediction, model comparison, out-of-distribution detection, and interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It addresses an important and timely problem: using synthetic data safely.\n2. The proposed framework is general, applies to various inference tasks, with finite-sample guarantees providing rigor and confidence in decision-making."}, "weaknesses": {"value": "1. The core idea resembles Synthetic-Powered Predictive Inference (SPI) (Bashari et al. 2025) with a wrapper reformulation. The conceptual advance over existing selective-use-of-synthetic-data methods is modest.\n2. The applications largely show numerical improvements but do not demonstrate meaningful decision changes attributable to GESPI. For example, in AlphaFold experiments, why should abstaining on slightly fewer residues matter biologically?\n3. Lack of baseline: each application should have more baselines. For example, the hypothesis testing should have PPI and PPI++ as baseline. Similar for other applications.\n4. The synthetic data in the experiments is unusually high-quality (e.g., AlphaFold MSAs), biasing results toward success scenarios. In practice, the synthetic data may not be of such high quality"}, "questions": {"value": "1. Can you provide one clear decision-making example where the guardrail version changes the outcome in a scientifically significant way?\n2. How will the other baseline perform in those tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2rUWwaR5mV", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_MhsE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_MhsE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942032905, "cdate": 1761942032905, "tmdate": 1762924858281, "mdate": 1762924858281, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GEPSI, a general framework for incorporating synthetic data into statistical inference while maintaining distribution-free, finite-sample guarantees. \nThe method applies to any inference procedure three times and aggregates the outputs to ensure that the overall error rate never exceeds \\alpha+\\epsilon.\nWhile the framework is conceptually interesting, the contribution is somewhat incremental relative to prior work on synthetic-powered inference (e.g., SPI) and conformal prediction. \nMore importantly, theoretically, should the proposed method maintain the error rate at \\alpha instead of \\alpha+\\epsilon?\nThe intuition is that, if one method has a relaxed error rate control, it should of course have a greater power.\nIn addition, the empirical studies are illustrative but limited in scope and depth, and the practical impact of the proposed method remains unclear."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The method is general and easy to implement, acting as a wrapper for existing inference procedures.\n\nFinite-sample, distribution-free guarantees are theoretically appealing and well-articulated."}, "weaknesses": {"value": "Incremental contribution: The proposed framework closely parallels earlier work such as Synthetic-Powered Predictive Inference (SPI). GESPI mainly reformulates SPI in a more general setting but adds limited new theoretical or methodological insight.\n\nWeak experimental evidence: The experiments are small-scale and largely illustrative. The improvements over the baseline (using real data only) are modest, and the synthetic data setups (e.g., AlphaFold MSA sequences or Olympiad math questions) feel somewhat ad hoc.\n\nLimited novelty in theory: The theoretical guarantees mostly extend standard monotonicity and total variation arguments; there is little fundamentally new mathematical insight.\n\nParameter sensitivity: The \\epsilon parameter plays a critical role in balancing power and validity, yet there is no principled or data-driven way to choose it.\n\nLack of strong baselines: The comparisons omit relevant existing methods for combining heterogeneous datasets, such as transfer learning, domain adaptation, or causal data fusion approaches.\n\nUnclear practical relevance: It is not evident that practitioners would find GESPI advantageous, given the need to rerun inference procedures multiple times and the modest empirical gains."}, "questions": {"value": "How does GESPI differ fundamentally from SPI beyond the reformulation to a more general inference framework?\n\nCould you provide theoretical or empirical comparisons with domain adaptation or semi-supervised learning approaches that also combine datasets from different distributions?\n\nHow sensitive is performance to \\epsilon, and could it be tuned automatically rather than chosen heuristically?\n\nCan the method be applied meaningfully at large scale, where repeated runs of the base inference algorithm may be infeasible?\n\nHow can one assess when synthetic data are sufficiently aligned to expect benefits from GESPI?\n\nShould the proposed method maintain the error rate at \\alpha instead of \\alpha+\\epsilon? Otherwise, it is not a fair comparison with the baseline which controls the error rate at \\alpha.\n\nIn all the numerical studies, should you compare with the method Real+Synth? Why OnlySynth?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Fgr8Nsctba", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_FjoW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_FjoW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960687394, "cdate": 1761960687394, "tmdate": 1762924857912, "mdate": 1762924857912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes General Synthetic-Powered Predictive Inference (GESPI) that can leverage synthetic data samples for statistical inference, while maintaining \"guardrails\" against synthetic data that differs (in quality, but probably also distribution) from the limited real data."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The proposed work is interesting and timely. Its approach is general and not tailored to any particular statistical inference model like prior works. The paper is well-written with a neat exposition that makes it easy to understand for even a general ML audience."}, "weaknesses": {"value": "I do not have any concerns about this work. Some questions I had about the theory are below. Comments related to writing are under \"questions.\"\n\n**Q1. Effect of $n$** and $N$: How does the number of real samples $n$ and the number of synthetic samples $N$ (or their ratio) affect the guarantees in Theorems 3.2 and 3.3?\n\n**Q2. Presence of low quality samples in real data**: If there were a few low quality samples in the real dataset and the synthetic data matched the distribution of good quality real samples, wouldn't GESPI essentially throw out some of the benefits from good quality synthetic data? I understand that this is not the exact scenario for which GESPI was designed, but I would like to know what its behavior would be.\n\n**Q3. Comparison with SPI**: Is it possible to compare GESPI with SPI in conformal prediction experiments on the datasets in this work or the SPI paper?"}, "questions": {"value": "Comments related to writing:\n\n**C1.** Line 284 says \"the synthetic-leveraging procedure...improves upon the standard procedure...\" Can the authors clarify what \"improve\" means here in formal terms?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iCdI3FuoKn", "forum": "Ww3cow5dO3", "replyto": "Ww3cow5dO3", "signatures": ["ICLR.cc/2026/Conference/Submission14457/Reviewer_SedH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14457/Reviewer_SedH"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14457/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971744662, "cdate": 1761971744662, "tmdate": 1762924857447, "mdate": 1762924857447, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}