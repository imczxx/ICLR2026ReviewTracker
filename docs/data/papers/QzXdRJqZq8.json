{"id": "QzXdRJqZq8", "number": 21458, "cdate": 1758317783449, "mdate": 1759896921044, "content": {"title": "SeekerGym: Benchmarking Agentic Information Seeking under Uncertainty", "abstract": "Effective information seeking is a prerequisite for AI agents, yet current systems often fail to autonomously identify, retrieve, and integrate relevant context. We propose SeekerGym, a modular environment for evaluating LLM agents on information-seeking tasks. Unlike prior benchmarks that focus on end-to-end task performance, SeekerGym evaluates agentic information seeking capabilities in two complex tasks: reconstructing Wikipedia pages and finding related literature for computer science survey papers. Furthermore, we design an information seeking agent called SeekerAgent, which employs various belief structuring pipelines including meta-reflection for cross-example learning. Through comprehensive experiments using SeekerGym, we evaluate several design choices for information seeking agents. We find that SeekerAgent improve recall by as much as 68% compared to frontier models.", "tldr": "", "keywords": ["Information Seeking", "POMDP", "Large Language Model", "Information Retrieval"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aea9bf7c0a9836720184b9de6e4135e8b01e736f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces SeekerGym, the authors formulate the task as a POMDP and provide curated Wikipedia and CS survey datasets, along with a comprehensive suite of belief-structuring pipelines for agent state representation. The modular SeekerAgent leverages various belief modeling approaches, including meta-reflection and explicit uncertainty modeling, and is evaluated extensively on the proposed benchmark. The experiments explore different LLM backbones, agent architectures, belief pipelines, and cost-performance tradeoffs, with detailed results and ablations."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper identifies and fills an important gap in the empirical evaluation of agentic LLMs by systematically isolating information-seeking from confounding downstream tasks, which clear focus on isolating information-seeking abilities.\n- The Wikipedia and computer science survey datasets are large, diverse, and constructed with explicit filtering and clustering strategies. (from description, and I haven't check the dataset.)\n- Results are broken down by topic, agent design, and model, offering a deep diagnostic view."}, "weaknesses": {"value": "- Writing related: \n    - 1. Related work is incomplete: Several directly relevant prior works on agentic information seeking are not listed. \n    - 2. some typo should be fixed. \n    - 3. more detailed caption is needed (eg. Table 2); and some caption should be concise (eg. Figure 3)\n\n- Lack of direct experimental comparison with existing benchmarks/methods: Despite detailed descriptions of the environment and agent pipeline, the paper lacks experiments against existing benchmarks, limiting assessment of SeekerGym's novelty and difficulty. It also provides no experimental results on how introdeced method perform on prior agentic benchmarks.\n\n- Insufficient novelty: The method is well-motivated but largely follows established RL conventions. Most contributions are architectural and limited. The belief structuring pipelines are software engineering contributions more than theoretical ones."}, "questions": {"value": "- Can the authors provide direct empirical comparisons against at least one or more prior agentic information-seeking benchmarks (e.g., WebArena, WebShop, GAIA, browsecomp-en/cn)? This would clarify SeekerGym's relative challenge and agent improvement.\n\n- More experimental results of your agent and more models is needed (which is necessary for a benchmark) on other open-sourced benchmarks, not just SeekerGym\n\n- More analysis on open-sourced/thinking/no-thinking models (not just api-based)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mqu7gDjAj5", "forum": "QzXdRJqZq8", "replyto": "QzXdRJqZq8", "signatures": ["ICLR.cc/2026/Conference/Submission21458/Reviewer_c1Hi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21458/Reviewer_c1Hi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760510612755, "cdate": 1760510612755, "tmdate": 1762941788720, "mdate": 1762941788720, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SeekerGym, a modular environment designed to evaluate large language models (LLMs) on information retrieval tasks. It includes two types of tasks: finding related literature for Computer Science(CS) survey papers and reconstructing Wikipedia pages.  SeekerGym formalizes information retrieval as a Partially Observable Markov Decision Process (POMDP) and incorporates a SeekerAgent that employs various belief-structuring strategies, including meta-reflection and uncertainty-augmented approach methods, leading to a substantial improvement in retrieval recall.  The experiments evaluate the impact of different belief pipeline configurations on performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.\tInformation retrieval has long been a key focus in the LLM community due to its strong application potential. Modeling this problem as a POMDP is an intuitive and reasonable approach.\n\n2.\tThe two environments designed in this paper: finding related literature for CS survey papers and reconstructing Wikipedia pages are sufficiently long-horizon and complex, closely aligned with real-world scenarios. The pipeline is carefully designed with well-considered data cleaning and filtering procedures.\n\n3.\tThe experimental section is organized around three key questions: which models demonstrate stronger information retrieval capabilities, how different belief pipelines affect model performance, and how to balance the cost–performance trade-off. The logic is relatively clear, and the analysis appropriately considers the constraints imposed by computational cost, adding practical significance to the study."}, "weaknesses": {"value": "1.\tThe writing of this paper presents some issues. The methodological description is overly detailed, making the paper resemble a technical report rather than a research article. Some hyperparameters and implementation details could be moved from the main text to the appendix, and the formatting of figures(Figure 4) and tables(Table 1-3) could be further optimized.\n\n2.\tThe overall workload appears limited. The paper presents an interactive system and explores the impact of different prompts on model information retrieval performance; however, the range of evaluated models is too narrow and focuses exclusively on closed-source models, which substantially weakens the validity and generalizability of the experimental conclusions. Conducting experiments on a wider range of models(such as Qwen3, GPT-5 and LLaMA-3.1) would make the conclusions more convincing and generalizable.\n\n3.\tThe references are too few and outdated, with only 16 citations (including two websites). The Related Work section lacks discussion of existing benchmarks for LLM-based information retrieval, not limited to agent settings. In addition, there is a factual error in Line 455: Memento and UoT have already proposed prompt-based retrieval augmentation methods.\n\n4.\tSection 3.1 states that Meta-Reflection is an improved version of Reflexion, but the paper lacks comparative experiments against the baseline Reflexion method. Moreover, since Meta-Reflection combines Reflexion with Deduplicated History, its novelty appears limited. In addition, Line 268 claims that Meta-Reflection “can be combined with any pipeline”, yet no experiments are provided to substantiate the general applicability of Reflexion.\n\n\nMinor Points: \n\n1.\tThe caption of Figure 3 is excessively long, spanning 11 lines. Moving part of the caption’s content into the main text would improve the paper’s readability and conciseness.\n\n2.\tThe paper does not clearly articulate the contribution and novelty of SeekerGym. Providing a comparison table highlighting the differences between SeekerGym and other existing benchmarks would substantially improve clarity and strengthen the presentation.\n\n[1] Zhou H, Chen Y, Guo S, et al. Memento: Fine-tuning llm agents without fine-tuning llms[J]. arXiv preprint arXiv:2508.16153, 2025.\n\n[2] Hu Z, Liu C, Feng X, et al. Uncertainty of thoughts: Uncertainty-aware planning enhances information seeking in large language models[J]. arXiv preprint arXiv:2402.03271, 2024."}, "questions": {"value": "1．\tIn Line 355, all models are configured with a temperature of 1, and no independent repeated experiments are reported. This setup may introduce excessive randomness and could undermine the reliability of the conclusions.\n\n2．\tI am curious whether the performance of different models on the SeekerGym benchmark is consistent with their performance on other information-seeking benchmarks. If discrepancies exist, what factors contribute to these differences? Additionally, I would like to know whether SeekerAgent also demonstrates strong performance on other benchmarks.\n\n3．\tIncluding several case studies(both successful and failed) would help readers better understand and engage with the paper.  I would like to know whether the design of Meta-Reflection encourages more diverse response patterns from the model, thereby contributing to its improved performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "P8snQmRvn5", "forum": "QzXdRJqZq8", "replyto": "QzXdRJqZq8", "signatures": ["ICLR.cc/2026/Conference/Submission21458/Reviewer_4MiK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21458/Reviewer_4MiK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896878741, "cdate": 1761896878741, "tmdate": 1762941788281, "mdate": 1762941788281, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper introduces SeekerGym, a new benchmarking environment for evaluating information-seeking behavior in LLM agents. The authors formalize the task as a Partially Observable Markov Decision Process and provide three benchmark datasets—Short Wikipedia, Long Wikipedia, and Computer Science Surveys—to test agentic exploration and retrieval capabilities. They also propose SeekerAgent, a modular agent architecture incorporating Belief pipelines and Query generation modules."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Rigorous Formalization: The POMDP formulation is mathematically sound and provides a principled framework for the information-seeking task with clear state/action/observation spaces.\n  - Modular Design: The compositional belief pipeline approach is elegant and allows for systematic ablation studies to understand which components contribute to performance."}, "weaknesses": {"value": "- Incomplete Paper: The paper mentions \"we train the agent separately for each cluster, and test on the corresponding set\" (line 214) and \"Train and test set\" (line 140), but the experimental section only uses existing APIs without any description or analysis of the training process.\n  - Limited Novelty: The proposed belief pipeline essentially only manages memory and optimizes query generation; the feedback mechanism of the constructed SeekerGym is oversimplified compared to real web environments, which is insufficient to validate the claimed improvement in information seeking capabilities.\n  - Missing Baseline Comparisons: No comparison with retrieval-augmented generation (RAG) baselines or specialized information retrieval methods."}, "questions": {"value": "- Testing Methodology: During testing, do you test each topic (cluster) separately and then average the results? Why not perform seeking in one large dataset? Would this approach result in lower recall?\n  - Interpretation of Figure 9: Does Figure 9 suggest that backend models may have different understanding of knowledge across professional domains due to training data differences, which affects query quality and ultimately leads to significant variance in average recall across different topics (clusters)? What would be the recall improvement of the proposed best belief pipeline in more challenging domains?\n  - Lack of Case Analysis: There is no case study showing how backend models respond differently to different belief pipelines.\n  - Limited Applicability: The proposed information retrieval approach seems only suitable for comprehensive integration tasks like survey papers. Would it be helpful for multi-hop QA tasks that require search?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AtZ0XeFxtr", "forum": "QzXdRJqZq8", "replyto": "QzXdRJqZq8", "signatures": ["ICLR.cc/2026/Conference/Submission21458/Reviewer_Z2dW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21458/Reviewer_Z2dW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904080972, "cdate": 1761904080972, "tmdate": 1762941787829, "mdate": 1762941787829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces SeekerGym, an environment for evaluation information-seeking agents. SeekerGym supports tasks constructed from two sources: wikipedia and CS survey papers. The metrics focuses on tracking the agents' abilities in reasoning about the exact missing information from trajectories. The author further propose SeekerAgent, featuring various belief structuring pipelines. Experiments show that the proposed pipelines effectively improves the performance of agents on SeekerGym."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This work contributes two environments for evaluating AI agents on challenging information-seeking tasks, which can be a meaningful resource for the community.\n2. The proposed belief structuring pipelines seem to be effective scaffolding methods for enhancing agent performance.\n3. Writing and presentation is overall clear."}, "weaknesses": {"value": "1. I am not sure whether the use of \"uncertainty\" is properly used in the title. This work refers to \"uncertainty\" as what to search next at each step in the information-seeking process. This is quite different from the more commonly used definition for \"uncertainty\" in AI research, which is related to model confidence. If this is actually the intended use, I do not see a metric that quantifies the uncertainty of agents.\n2. The metrics and reward is effectively tracking the change of recall of oracle documents in the information-seeking process. Which seems to be overly simple and can actually be used for any other deep research dataset with relevant documents/sources annotated. This potentially undermines the value of the SeekerGym as a separate benchmark.\n3.  The proposed belief structuring pipeline method is somewhat interesting and effective. However, I think this method is generally applicable to the context management of any information-seeking agents. Therefore, I would like to see it tested on at least one existing benchmarks to concrete the methodological contribution.\n4. The evaluation settings have issues. Firstly, why is each episode only evaluated with a single run instead of reporting average performance over multiple runs? Secondly, for RQ1, the conclusion regarding non-reasoning models perform better is not rigorous. I don't think comparing different models (Deepseek-R1/V3 and Gemini-2.0), which are trained very differently, under different inference setting (with and without reasoning) can lead to the conclusion.\n5. Regarding the train/test split (line 213-215), why does splitting each cluster into train and test sets and train agents for each cluster can \"facilitate learning\"? Shouldn't a larger and more diverse training set benefit performance? Also, there doesn't seem to be details about how agents are trained in the paper."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dKnkRILl6h", "forum": "QzXdRJqZq8", "replyto": "QzXdRJqZq8", "signatures": ["ICLR.cc/2026/Conference/Submission21458/Reviewer_mR8K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21458/Reviewer_mR8K"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984119999, "cdate": 1761984119999, "tmdate": 1762941787436, "mdate": 1762941787436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}