{"id": "LUnYc9Grm8", "number": 2863, "cdate": 1757292424204, "mdate": 1763541271169, "content": {"title": "Decide When Ready: Stepwise Incremental Inference with Early-Exit in Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) are well-suited for low-power, low-latency dynamic visual perception due to their event-driven computation. However, existing SNNs rely on fixed time steps for training and inference, which leads to buffering requirements and mismatches with neuromorphic hardware, thus neglecting the potential for early recognition using partial event streams. In neuromorphic computing, ideal dynamic visual perception should be event-driven, with models continuously updating states based on incoming events and producing results as soon as confidence criteria are met. To address this, we propose the Spiking Incremental Recognition Network (SIREN), an incremental inference architecture designed to approximate this ideal paradigm. During training, the model processes event streams in fixed steps, while at inference it processes event frames step by step, updating states continuously and making dynamic decisions. SIREN integrates multiple spiking neuron types and a Spiking State-Space Model (S-SSM) to capture multiscale temporal dependencies. It also combines Causal Time Self-Attention (CTSA) with early-exit strategies for efficient termination. We evaluate our approach on three Dynamic Vision Sensor (DVS) datasets, achieving state-of-the-art performance in recognition tasks, including SL-Animals-DVS, DVS128-Gesture and the THU-EACT-50 subset, with accuracies of 93.33%, 97.92% and 100% respectively. Concurrently, we reduce the average inference steps from 16 to 9.5, with fewer synaptic operations (SOPs), demonstrating its potential for deployment on neuromorphic edge devices.", "tldr": "We propose an incremental inference architecture for spiking neural networks that updates predictions online from event streams, reducing latency and redundancy, and is well-suited for neuromorphic edge deployment.", "keywords": ["Spiking neural networks", "neuromorphic computing", "incremental inference", "casual time attention", "early exit"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/181e4b46ebe1e68a87ff2140db716616e78ac86c.pdf", "supplementary_material": "/attachment/34d5ded2d967a41eb78d384851c6f09ecb4cae28.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a spiking neural network (SNN) framework that integrates LIF and RF neurons with a spiking state-space module (S-SSM). Additionally, this paper proposes causal spatial-temporal self-attention (CSTSA) and uses an early-exit mechanism to improve the inference efficiency. The author conducted experiments on three datasets and compared the results with other methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The experimental results show that the proposed method has advantages over other methods."}, "weaknesses": {"value": "1. **Unclear presentation**. Although the authors introduced the proposed S-SSM, C-STSA, and the early exit mechanism, Figure 2 indicates that their method also uses SpatialFormer and TemporalFormer, which are not described. Additionally, the author refers to the proposed method as SIREN. What, then, is ChronoSpikFormer in Figure 2? There is also no textual description of its overall architecture.\n\n2. **High complexity**. The proposed S-SSM is significantly more complex than the commonly used LIF neuron, which makes the proposed method difficult to implement. Additionally, Equation (14) shows that C-STSA introduces real-valued multiplication operations that are incompatible with the spike-driven characteristics of SNNs. Therefore, the advantages of the proposed method are still only theoretical.\n\n3. **Insufficient experiments**. \n\n* The performance reported in this paper on the three datasets is nearly saturated. To demonstrate their method's effectiveness, the authors should conduct experiments on more challenging datasets, such as CIFAR10-DVS, N-Caltech101, and ImageNet. \n\n* Furthermore, existing SNNs on DVS128-Gesture operate at a resolution of $48\\times48$. However, this paper uses a resolution of $128\\times128$, which makes for an unfair comparison.\n\n* Existing methods have achieved better performance than the present work. For example, QKFormer [1] attained an accuracy of 98.6% on the DVS-Gesture dataset. Therefore, the authors should compare their method with the latest methods.\n\n* To demonstrate its advantages, the author should compare their method with other early exit mechanisms.\n\n[1] QKFormer: Hierarchical Spiking Transformer using Q-K Attention. In NeurIPS. 2024."}, "questions": {"value": "Could the author explain why using entropy outperforms the maximum probability and marginal metrics by such a significant margin?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mSEsrIoAiq", "forum": "LUnYc9Grm8", "replyto": "LUnYc9Grm8", "signatures": ["ICLR.cc/2026/Conference/Submission2863/Reviewer_KzPq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2863/Reviewer_KzPq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761222991489, "cdate": 1761222991489, "tmdate": 1762916417971, "mdate": 1762916417971, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SIREN (Spiking Incremental Recognition Network), an incremental inference architecture for Spiking Neural Networks (SNNs). Its primary goal is to reduce the structural mismatch between conventional SNN algorithms, which typically require processing all time steps, and the event-driven, low-power nature of neuromorphic hardware. SIREN achieves this by processing events incrementally, making predictions as soon as sufficient information is available, thereby minimizing latency and energy use."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The incremental inference strategy is an intelligent early-exit mechanism contributing to very fast predictions for easy samples and lower average energy consumption.\n\nDemonstrates competitive results on the SL-Animals-DVS dataset and also other benchmarks."}, "weaknesses": {"value": "The performance advantage is not consistent across all datasets. Results on THU-EACT-50 are not markedly superior to previous methods, and performance on DVS128-Gesture is actually worse than existing algorithms. The absence of results on a standard benchmark like DVS-CIFAR-10 makes a comprehensive evaluation difficult.\n\nThe paper lacks a complete ablation study. It does not show the performance of an SNN baseline without the key proposed components (S-SA, S-SSM, CTSA), making it hard to isolate the individual contribution of each module.\n\nThe fundamental motivation of \"matching neuromorphic hardware\" is somewhat contradicted by the pre-processing step that converts event streams into fixed frames. A more hardware-native approach would directly process raw event timestamps.\n\nThe specific need for and the limitations of the S-SSM module are not thoroughly justified. It's unclear what the \"long-range\" dependencies are and at what distance conventional methods fail."}, "questions": {"value": "Could you provide the ablation results for an SNN baseline without the S-SA, S-SSM, and CTSA modules to clearly demonstrate the contribution of each component?\n\nWhat is the specific limitation in terms of \"range\" that the S-SSM module addresses? How was this limitation identified, and what is the performance gain compared to a simpler attention mechanism?\n\nHave you evaluated SIREN on the DVS-CIFAR-10 dataset? This is a standard benchmark, and its inclusion would allow for a more direct comparison with the broader literature.\n\nThe output layer uses a SoftMax function. How would this non-local, non-spiking operation be efficiently implemented on neuromorphic hardware, which is optimized for sparse, spike-based computations? Doesn't this create a structural mismatch?\n\nThe paper reports 100% accuracy on a subset of THU-EACT-50. Could you clarify the validation setup? Is this result on a test set or a validation set? If it's 100%, it raises questions about potential data leakage or an oversimplified evaluation split.\n\nCommon SNNs are trained with 4 timesteps for image-derived datasets and 16 for DVS datasets. Have you trained a regular (non-incremental) SNN on the DVS datasets using only 4 timesteps for a fairer comparison in terms of latency?\n\nThe incremental inference seems to be primarily driven by the early-exit strategy. Could similar latency reductions be achieved by simply applying an early-exit strategy to a conventional SNN, without the proposed SIREN architecture?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cw9WS0DmT4", "forum": "LUnYc9Grm8", "replyto": "LUnYc9Grm8", "signatures": ["ICLR.cc/2026/Conference/Submission2863/Reviewer_g62k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2863/Reviewer_g62k"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832193365, "cdate": 1761832193365, "tmdate": 1762916417669, "mdate": 1762916417669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SIREN (Spiking Incremental Recognition Network), a novel SNN architecture designed for efficient, event-driven dynamic visual perception. The core innovation lies in its incremental inference framework, which processes event streams step-by-step during inference (unlike traditional fixed-step SNNs) and employs an entropy-based early-exit mechanism to halt computation once a confident prediction is made. This approach addresses a mismatch between conventional SNN training/inference and the ideal asynchronous, event-driven operation of neuromorphic hardware."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is interesting and strong, with a clear motivation (the mismatch between fixed-step SNN training and event-driven neuromorphic operation is real, and the goal of stepwise incremental inference with early exit aligns well with deployment constraints), a well-designed methodology integrating several advanced concepts such as Spiking State-Space Model (S-SSM) and Causal Spatial-Temporal Self-Attention (C-STSA), and comprehensive experiments demonstrating state-of-the-art or competitive accuracy with significantly reduced computational cost and latency."}, "weaknesses": {"value": "The energy analysis uses SOP / FLOP proxies (per-op energies) which is common, but the paper should make explicit limitations and, if possible, provide on-device (Loihi / other) measurements or at least simulated neuromorphic runtimes.\n\nThere is a little lack of clarity between \"incremental inference\" and \"early-exit\": both concepts are related, yet they are distinct. The paper would benefit from a clearer delineation early on."}, "questions": {"value": "I feel that early-exit design choices need more justification. The entropy + patience rule seems reasonable, but authors should :\n- explain how theta and kappa generalise across datasets. Are thresholds tuned per dataset? How sensitive are results to theta choice?\n- show robustness: curves of accuracy vs. average step for different theta to show degradation.\n- clarify the role of EMA smoothing coefficient alpha -- any lag introduced and its effect on early exit latency.\n\nThe Causal Time Self-Attention (CTSA) softmax-free formulation is interesting. I recommend to give a short intuitive comparison to standard softmax attention (when does one outperform the other?), and discuss possible weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TLqQf78Ttf", "forum": "LUnYc9Grm8", "replyto": "LUnYc9Grm8", "signatures": ["ICLR.cc/2026/Conference/Submission2863/Reviewer_wECy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2863/Reviewer_wECy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933336033, "cdate": 1761933336033, "tmdate": 1762916416747, "mdate": 1762916416747, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies event-driven dynamic visual recognition with SNNs and proposes the Spiking Incremental Recognition Network, which performs incremental inference by updating states step-by-step and producing predictions once a confidence threshold is reached, rather than relying on fixed time windows. The design combines multiple existing components, diverse spiking neuron types, a spiking state-space model for multi-scale temporal modeling, causal time self-attention, and an early-exit mechanism, to better approximate ideal neuromorphic processing. Experiments on three DVS benchmarks show state-of-the-art accuracy while reducing inference steps and synaptic operations, indicating improved efficiency for potential edge deployment."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a relevant gap in SNNs by moving from fixed-window processing to incremental event-driven inference for neuromorphic deployment.\n\n2. Experiments are comprehensive across multiple DVS datasets, with strong results on both accuracy and efficiency (steps/SOPs), supported by useful ablations.\n\n3. Writing is clear and experiments are well-presented, with informative visualizations."}, "weaknesses": {"value": "1. The approach largely integrates known mechanisms (multiple spiking neurons, S-SSM, causal attention, early exit). The conceptual novelty lies more in system integration rather than a fundamentally new algorithmic principle.\n\n2. Related works on step-wise SNN inference and adaptive time-step SNN training frameworks need deeper positioning. For example: [a] Towards Low-Latency Event-Based Visual Recognition with Hybrid Step-Wise Distillation SNNs, [b] Adaptive Time-Step Training for Enhancing Spike-Based Neural Radiance Fields, and recent works on event-driven adaptive inference in neuromorphic computing\n\n3. The main framework figure is visually weak and does not communicate the incremental inference mechanism clearly. A timeline or event-accumulation visualization could greatly help understanding.\n\n4. Claims about neuromorphic deployment and continuous inference motivation are strong, but there is no hardware-based profiling or simulation beyond SOP estimates. Even lightweight profiling on Intel Loihi / NVIDIA DAVIS pipelines / microcontroller simulation would enhance significance."}, "questions": {"value": "1. Is SIRENâ€™s incremental strategy fundamentally dependent on S-SSM + CTSA, or could a simpler architecture yield similar gains?\n\n2. Can the authors quantitatively isolate the contribution of each module (multi-neuron fusion, S-SSM, CTSA, early exit) under incremental inference?\n\n3. How sensitive is performance to the confidence threshold? Is there a mechanism to guarantee monotonic confidence or prevent premature exit?\n\n4. Is S-SSM implementable efficiently on Loihi-like accelerators?\n\n5. Would SIREN extend to event-based tracking or segmentation? Does incremental inference scale to long sequences (e.g., E2Caltech)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fC4tgIROmO", "forum": "LUnYc9Grm8", "replyto": "LUnYc9Grm8", "signatures": ["ICLR.cc/2026/Conference/Submission2863/Reviewer_RFvo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2863/Reviewer_RFvo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762104800127, "cdate": 1762104800127, "tmdate": 1762916416073, "mdate": 1762916416073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}