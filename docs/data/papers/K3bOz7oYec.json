{"id": "K3bOz7oYec", "number": 5511, "cdate": 1757917085971, "mdate": 1759897970249, "content": {"title": "O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents", "abstract": "Recent advancements in LLM-powered agents have demonstrated significant potential in generating human-like responses; however, they continue to face challenges in maintaining long-term interactions within complex environments, primarily due to limitations in contextual consistency and dynamic personalization. Existing memory systems often depend on semantic grouping and the retrieval of past interaction groupings, which can overlook semantically irrelevant yet critical user information and introduce retrieval noise. To address these issues, we propose O-Mem, a novel memory framework based on active user profiling that dynamically extracts and updates user characteristics and event records from interactions. O-Mem supports hierarchical retrieval of persona attributes and topic-related context, enabling more adaptive and coherent personalized responses. Additionally, we introduce a new dataset designed to evaluate personalized long-text generation in memory-augmented agents. Experiments across three personalized tasks demonstrate that O-Mem consistently improves long-term human–AI interaction by scaling memory-time within interactions.", "tldr": "", "keywords": ["Memory Framework", "Agent"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bd93b24ded84ae19776a3988e8f8e4cbfdbdae92.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents O-Mem, a memory framework designed to help LLM-based agents maintain long-term, personalized conversations. Unlike chunk-based semantic retrieval systems that simply group and retrieve messages, O-Mem builds and updates a user profile, event memory, and topic memory. These three modules are queried together to form context at every turn. The method is evaluated on LoCoMo, and a new small benchmark called Personalized Deep Research Bench, showing improved personalization and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation and good problem definition.\n- The tri-memory structure (working, episodic, persona) is easy to understand.\n- Empirical results are consistent across several benchmarks and show clear efficiency improvements (up to 80% lower latency and 94% fewer tokens).\n- The token-controlled ablation is a nice touch to show that gains are not simply due to longer context.\n- Well-written and logically structured paper; figures and tables support the narrative."}, "weaknesses": {"value": "- Episodic retrieval is defined by selecting a single clue word, but the paper does not specify how it behaves for unseen or multi-word clues.\n- The retrieval hyperparameters (top-k, thresholds, similarity cutoffs) are not clearly stated. Since efficiency is a main claim, this missing detail makes replication difficult.\n- The new Personalized Deep Research Bench dataset is relatively small and not publicly available, which limits the impact towards the community.\n- Reproducibility: while the paper provides prompts, the code is not made public.\n- No detailed error analysis or failure cases are presented (e.g., wrong persona merges, noisy clues, context drift).\n- The deep research benchmark evaluation relies on LLM-as-judge scores without human evaluators, which weakens the reliability of reported gains."}, "questions": {"value": "- Provide all retrieval parameters (k, thresholds, backend) and report multi-seed variance.\n- Give more information about the new dataset (size, annotation, examples).\n- Add a short qualitative error analysis to understand where O-Mem fails.\n- Include a short paragraph on privacy and limitations of method.\n- Consider adding human evaluation rather than purely LLM-based"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "42dHl1kK3r", "forum": "K3bOz7oYec", "replyto": "K3bOz7oYec", "signatures": ["ICLR.cc/2026/Conference/Submission5511/Reviewer_kkEr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5511/Reviewer_kkEr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761270504789, "cdate": 1761270504789, "tmdate": 1762918102685, "mdate": 1762918102685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes O-Mem, a hierarchical memory framework for LLM-based agents that dynamically builds and updates user profiles through active persona extraction and event recording. By combining persona, episodic, and working memories, the system enables long-term personalized reasoning and shows consistent improvements over existing memory systems on three benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation of the paper is clear: it clearly illustrates why existing chunk-based or semantic retrieval memories fail at dynamic personalization and positions O-Mem as a principled solution.\n\n2. The integration of persona, episodic, and working memories into a unified retrieval pipeline (Eqs. 8–12) with active LLM-driven updates is interesting and reasonable.\n\n3. Experiments across three datasets (LoCoMo, PERSONAMEM, Personalized Deep Research Bench) show consistent gains."}, "weaknesses": {"value": "1. Several metrics rely on “LLM-as-a-Judge,” which introduces bias; no human validation or inter-rater reliability checks are reported.\n\n2. The efficiency and ablation results are strong, but in-depth qualitative analyses of what the model remembers or how errors occur are missing. \n\n3. More discussion on how often the persona-update operation (Op(ai) / Op(ei)) introduces noise or incorrect updates, and how error accumulation is mitigated, is not thoroughly discussed."}, "questions": {"value": "Some minor suggestions on the presentation:\n\n- “Sysytem” → “System” in Section 2 heading\n\n- Some inconsistent spacing in equations (3) and (4) (“ApplyOp(Pf , ei, Op(ei))”).\n\n- “we propose O-Mem” repeated across Abstract and Intro\n\nHow sensitive is O-Mem to the choice of the base embedding model (e.g., all-MiniLM-L6-v2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ErKokAXAwc", "forum": "K3bOz7oYec", "replyto": "K3bOz7oYec", "signatures": ["ICLR.cc/2026/Conference/Submission5511/Reviewer_pp3Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5511/Reviewer_pp3Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761587271540, "cdate": 1761587271540, "tmdate": 1762918102474, "mdate": 1762918102474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes O-Mem, a hierarchical memory framework for LLM-based agents that dynamically builds and updates user profiles through active persona extraction and event recording. By combining persona, episodic, and working memories, the system enables long-term personalized reasoning and shows consistent improvements over existing memory systems on three benchmarks.\n\nDisclaimer\nI am surprised to find that my review was labeled as \"fully llm-generated\" in https://iclr.pangram.com/. Here I would like to clarify that all the points I wrote here, as well as the score I gave, are my own judgments after reading the paper, and I used GPT to make the review more fluent."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation of the paper is clear: it clearly illustrates why existing chunk-based or semantic retrieval memories fail at dynamic personalization and positions O-Mem as a principled solution.\n\n2. The integration of persona, episodic, and working memories into a unified retrieval pipeline (Eqs. 8–12) with active LLM-driven updates is interesting and reasonable.\n\n3. Experiments across three datasets (LoCoMo, PERSONAMEM, Personalized Deep Research Bench) show consistent gains."}, "weaknesses": {"value": "1. Several metrics rely on “LLM-as-a-Judge,” which introduces bias; no human validation or inter-rater reliability checks are reported.\n\n2. The efficiency and ablation results are strong, but in-depth qualitative analyses of what the model remembers or how errors occur are missing. \n\n3. More discussion on how often the persona-update operation (Op(ai) / Op(ei)) introduces noise or incorrect updates, and how error accumulation is mitigated, is not thoroughly discussed."}, "questions": {"value": "Some minor suggestions on the presentation:\n\n- “Sysytem” → “System” in Section 2 heading\n\n- Some inconsistent spacing in equations (3) and (4) (“ApplyOp(Pf , ei, Op(ei))”).\n\n- “we propose O-Mem” repeated across Abstract and Intro\n\nHow sensitive is O-Mem to the choice of the base embedding model (e.g., all-MiniLM-L6-v2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ErKokAXAwc", "forum": "K3bOz7oYec", "replyto": "K3bOz7oYec", "signatures": ["ICLR.cc/2026/Conference/Submission5511/Reviewer_pp3Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5511/Reviewer_pp3Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761587271540, "cdate": 1761587271540, "tmdate": 1763342674807, "mdate": 1763342674807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the personalized response generation task in conversational ai scenario. Different from existing memory systems that relies solely on semantic retrieval, the authors propose a new memory system named O-Mem. O-Mem consists of three memories: user persona memory, working memory, episodic memory, and coupled with three retrieval strategies for obtaining context when responding to a user’s query. A new dataset is constructed and introduced."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "•\tA new dataset is introduced\n\n•\tThe designed memory system differentiates user past histories into three different types which aligns with personalization purpose"}, "weaknesses": {"value": "•\tThe presentation of this paper needs to be improved, e.g., the tables in experiment sections are sparse; a lot of content such as in line209-214 in Section 3 should be moved to appendix; the formulas in Section 3.2 and Section 3.3 are not necessary (they can either be put into appendix or in line with text), lacking more organized descriptions; in line 34-41, this would better be put into related work (intro would better contain more conclusion-like statements to explain current solutions to the limitations rather than stating who did what). There are more but I stop here, readers can check more in this stream.\n\n•\tThe O-Mem constructs three memories (user persona memory, working memory, episodic memory) via LLM and perform retrieval over the three memories when a user query raised. This is not new and the experiments lack the latency/cost comparisons on memory constructions, especially in line72-73 O-Mem seems actively updating user memory in the runtime.\n\n•\tIn line 82-85, the limitations of chunk size of retrieval etc. are not your contributions, these are commonly research questions in the community.\n\n•\tAre all baselines the same embedding model i.e., all-MiniLM-L6-v2 as O-Mem did? If they are, more embedding models should be tested as in their original design since this would help readers to understand if the improvements brought by the O-Mem design or the model used. If they are not, then the comparisons are not fair.\n\n•\tDatasets statistics such as utterance length, dialogue session numbers etc. are missing, even in the appendix. If the dataset is constructed casually and lacks evaluation/validation, this contribution is weak."}, "questions": {"value": "•\tIn Table 1, LangMemory beats MemoryOS in Open category with GPT4.1 but the situation reversed when with GPT-4o-mini, why is that?\n\n•\tIn Table 1, O-Mem is suboptimal in Open Category questions, why?\n\n•\tIn Table 1 temporal category with GPT-4o-mini, is it possible that the F1 score of O-Mem is better than MemoryOS while the B1 score is suboptimal than MemoryOS?\n\n•\tThe evaluation metrics are not convincing, the BLEU score is not a good indicator, how about BertScore/Faithfulness?\n\n•\tLoCoMo contains images, how do the authors deal with them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "EKYfUf7OGc", "forum": "K3bOz7oYec", "replyto": "K3bOz7oYec", "signatures": ["ICLR.cc/2026/Conference/Submission5511/Reviewer_b6E7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5511/Reviewer_b6E7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761603848942, "cdate": 1761603848942, "tmdate": 1762918102218, "mdate": 1762918102218, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces O-Mem, a memory framework aimed at improving long-term human-AI interaction by leveraging dynamic user profiling and hierarchical memory retrieval. The system aims to enhance personalization by maintaining evolving user profiles and incorporating them into response generation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of memory systems with dynamic user profiling is an interesting and promising direction.\n\n2. The paper is well-structured and clearly written, making it easy to follow the technical concepts and their practical applications."}, "weaknesses": {"value": "1. The main innovation in the paper appears to be the creation of a dedicated persona memory system that retrieves information based on user attributes. This seems like an incremental improvement over existing systems, with limited novel insights or breakthroughs. The contribution could be seen as a modification.\n\n2. The paper primarily evaluates the framework on only two models—GPT-4.1 and GPT-4o-mini. Expanding the evaluation to include other model families ( both open-source and closed-source, chat and reasoning models from different model families ) would provide a more comprehensive understanding of the framework's generalizability and robustness.\n\n3. The Personalized Deep Research Bench, a self-constructed key benchmark for evaluating the framework, lacks detailed construction explanations. It would be beneficial for readers to understand how the dataset was created and how it compares to existing benchmarks in terms of coverage and difficulty.\n\n4. Minor: In Table 1, there is an inappropriate use of bolding. The temporal F1 scores for MEMOS should be marked as the best model."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uETG07jL44", "forum": "K3bOz7oYec", "replyto": "K3bOz7oYec", "signatures": ["ICLR.cc/2026/Conference/Submission5511/Reviewer_ncJN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5511/Reviewer_ncJN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738664303, "cdate": 1761738664303, "tmdate": 1762918101886, "mdate": 1762918101886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}