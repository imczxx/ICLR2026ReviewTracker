{"id": "o4uLYNsVnS", "number": 14756, "cdate": 1758243096221, "mdate": 1762945454234, "content": {"title": "Explainable Error Detection in Integrated Circuits Image Segmentation via Graph Neural Networks", "abstract": "The nanoscale complexity of modern integrated circuits (ICs) and the low error tolerance in segmentation tasks pose significant challenges for automated quality control. While deep learning–based IC segmentation has advanced, most approaches still rely on manual inspection due to limited error interpretability. Existing CNN-based error detectors operate holistically on entire images, making it difficult to localize specific faults such as open or short circuits. We propose a novel, explainable error detection framework based on Graph Neural Networks (GNNs). By converting each connected component of a segmentation mask into a feature-annotated graph, our method enables localized reasoning and identification of segmentation errors through graph classification. This formulation allows the model to detect outlier components and precisely highlight erroneous regions, offering strong interpretability. Experiments across diverse IC layouts and imaging conditions demonstrate the robustness and generalizability of our approach, enabling accurate and interpretable error detection at the component level.", "tldr": "The paper proposes a error detection method of IC image segmentation using graph neural networks.", "keywords": ["IC image segmentation", "segmentation error detection", "graph neural networks"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/169084220003e2ab299c86ba0b69d0550da9513e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents an explainable error detection algorithm using a segmentation mask of integrated circuits (ICs). For that, each connected component of a segmentation mask is converted into a feature-annotated graph: the following features of component graphs\nare observed to be useful: (i) locations (for positional proximity) and (ii) lengths of edges and turning angles (for similarity in topology and geometric shape). The experiments are performed using multiple datasets, and comparisons have been made with benchmark algorithms."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is easy to read and follow.\n- The identification of faults in current complex integrated circuits is critical and essential.\n- The proposed idea of utilising a graph to represent the connected component is trivial."}, "weaknesses": {"value": "- While the paper and abstract suggest that the paper aims to develop an explainable error detection approach, the paper rarely focuses on interpretability. The section titled explainability talked about an ablation study instead of interpretability.\n- The algorithms used for comparison are old and not state-of-the-art. The recent algorithm used to report values in Table 2 is from the year 2021.\n- While the existing holistic approaches might be utilising full images, they might not be sensitive to the generated segmentation mask. Since the segmentation mask is one of the crucial components of the proposed approach, the analysis concerning faulty segmentation masks must also be explored.\n- Is there any rationale behind using the parameters mentioned in the paper, such as deciding the corner pixel based on $90^o \\pm \\triangle^o$ and the number of incident edges? The motivation and theoretical justification are weak. \n- Reporting the values in terms of F-1 is not sufficient. Moreover, are these F-1 values, weighted F-1 or normal F-1 (where equal weight is assigned to both classes)?\n- Further, the generalizability of the proposed approach is significantly lower than the holistic approaches. Interestingly, when trained on a small dataset (A1 or A2), the ED-ResNet yields poor performance on S1 (or S2). There is no reason to justify this phenomenon that has been provided."}, "questions": {"value": "- The explainability and interpretability of the proposed approach are weak.\n- Recent algorithms must be used for comparison.\n- The analysis concerning faulty segmentation masks must also be provided.\n- The motivation and theoretical justification of the parameters used in the proposed approach are required.\n- The results must be reported using either weighted F-1, and precision/recall/AUROC must also be reported.\n- Generalizability of the proposed approach is also a major concern."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TW7JpfrIpX", "forum": "o4uLYNsVnS", "replyto": "o4uLYNsVnS", "signatures": ["ICLR.cc/2026/Conference/Submission14756/Reviewer_zf7W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14756/Reviewer_zf7W"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14756/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761406460512, "cdate": 1761406460512, "tmdate": 1762925113660, "mdate": 1762925113660, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "H3FDsbI57y", "forum": "o4uLYNsVnS", "replyto": "o4uLYNsVnS", "signatures": ["ICLR.cc/2026/Conference/Submission14756/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14756/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762945453535, "cdate": 1762945453535, "tmdate": 1762945453535, "mdate": 1762945453535, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses automated detection of segmentation errors in IC SEM masks by converting each connected component of a binary mask into a feature‑annotated graph and classifying components with a custom Edge‑Aware Graph Isomorphism Network (EA‑GIN). Node features include normalized coordinates, node type (end/junction/corner), and incident angles. Edge features summarize geometry and mask width statistics along skeletonized paths. Classification is performed binary (normal/abnormal). Experiments on four proprietary datasets (A1, A2, S1, S2) report strong F1 on in‑distribution and cross‑dataset tests versus several GNN baselines (GIN, GINE, EGAT, CensNet) and a CNN image‑level baseline (ED‑ResNet). The paper also argues for 'explainability' via component‑level localization and provides a topology/metric framework (Appendix) motivating outlier detection of graph components."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "a. Clear problem formulation tailored to IC metrology\n\nThe paper motivates that IC foreground structures are defined more by topology than texture and thus benefit from a graph abstraction rather than holistic CNNs. It formalizes the goal as identifying 'unseen' component graphs relative to ground‑truth distributions and provides a pipeline from mask to skeleton to graph with explicit node and edge features (Figs. 3–5, Sec. 3.2)\n\nb. Simple architecture with edge features\n\nEA‑GIN augments GIN by turning edge features into attention‑like weights for message passing (Eqs. 3–5), a pragmatic design aligned with the task’s geometry (lengths, widths, turning angles). The model is compact (3 layers, small MLPs) and achieves large gains over plain GIN in all datasets (Table 2), highlighting the value of edge features.\n\nc. Convincing performance on several datasets\n\nOn image‑level error detection, EA‑GIN reaches F1=0.99 on A1/A2 and 0.90–0.92 on the more complex S2/S1 datasets, outperforming or matching GNN baselines and often surpassing the CNN baseline under cross‑dataset generalization (Table 2–3). The cross‑dataset results (e.g., train on A1/A2, test on S1/S2) are particularly interesting given limited graph diversity in ICs (Table 3).\n\nd. Explainability via component‑level flags\n\nComponent graphs with the top‑κ abnormal scores can localize errors (κ≤3 yields F1 close to 1.0 for A1/A2 and ≥0.97 for S2, Table 4, Fig. 7). This is useful for manual reviews and aligns with the thesis that errors are local."}, "weaknesses": {"value": "a. Uncertainty and Robustness\n\nThe authors report F1 scores without providing variance estimates, confidence intervals, or clarifying whether the metric is computed as micro-, macro-, or weighted F1. This is highly problematic given the extreme class imbalance (e.g., A1: 190 positives vs. 31k negatives) and makes the reported performance sensitive to split choice. Stratified, folded cross-validation or repeated runs with mean, std and confusion matrices have to be reported for statistical reliability.\n \nb. Cross-Dataset Performance Anomalies\n\nResults in Table 3 show anomalies: models trained on smaller datasets (A1, S1) sometimes outperform those trained on larger datasets when tested cross-domain (e.g., A1->A2 = 0.9962 vs. A2->A2 = 0.9953; S1->S2 = 0.9155 vs. S2->S2 = 0.8990). This suggests instabilities or overfitting, yet no diagnostic evidence (learning curves, calibration plots) is provided. It further highlights the need for uncertainty reporting.\n \nc. Baseline Comparison\n\nWhile as a CNN-based method it is a relatively weak baseline, ED-ResNet consistently outperforms EA-GIN on complex datasets (S1 and S2), achieving a near-perfect F1 (e.g., S2: 0.9951 vs. 0.8990). This contradicts the claim of broad superiority for the graph-based approach and indicates that EA-GIN may struggle with high-density layouts.\n \nd. Explainability and Evaluation\n\nWhile the method claims interpretability, evidence is qualitative (visual examples) without quantitative attribution or per-error-type breakdown.\n \ne. Missing Architectural and Computational Details\n\nHyperparameters (optimizer, learning rate, batch size, epochs) are not reported. Runtime and memory benchmarks for graph conversion and EA-GIN inference are also missing.\n \nf. Minor Typos and Terminology Issues\n\nInconsistent terminology such as 'metal line/metalline/meta-lines' and grammatical errors appear throughout (e.g. 'For the high-level idea [...]'). Figure captions could be more precise, and definitions should precede tables for clarity (e.g. Table 4)."}, "questions": {"value": "The approach is conceptually strong and shows promise on simpler datasets, but the lack of uncertainty quantification, anomalies in cross-dataset generalization, weak performance on complex cases, and incomplete evaluation undermine confidence in robustness and generality. Major revision recommended."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PSye1BFg9T", "forum": "o4uLYNsVnS", "replyto": "o4uLYNsVnS", "signatures": ["ICLR.cc/2026/Conference/Submission14756/Reviewer_4ny9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14756/Reviewer_4ny9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14756/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992227773, "cdate": 1761992227773, "tmdate": 1762925113130, "mdate": 1762925113130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an error detection framework for integrated circuit (IC) image segmentation using Graph Neural Networks (GNNs). The overall framework handles the problem by converting each connected component of a segmentation mask into a feature-annotated graph, enabling localized reasoning and error identification through graph classification. Their proposed method, called Edge-aware Graph Isomorphism Network (EA-GIN), incorporates both node and edge features to enhance detection accuracy and interpretability. Experiments across four IC datasets demonstrate that EA-GIN achieves robust, generalizable, and interpretable error detection at the component level, outperforming several benchmark models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "• Originality - The work aims at solving a critical problem in IC diagnosis. The way of transforming the task into GNN classification is innovative.\n• Explainability: The graph-based approach allows for precise localization of segmentation errors, making the model’s decisions more interpretable for practitioners.\n• Component-level Detection: By focusing on individual connected components, the method can pinpoint specific error regions, which is valuable for quality control in IC manufacturing.\n• Robustness and Generalization: EA-GIN demonstrates strong performance across diverse datasets and imaging conditions, and it generalizes well even when trained on smaller datasets."}, "weaknesses": {"value": "• Clarity can be improved: The way of explaining mathematical/topological terms can be improved for better readability.\n• Complexity of Graph Construction: The paper lacks the details of converting images into binary masks. The process of converting segmentation masks to graphs and extracting meaningful features may introduce additional computational overhead and implementation complexity. \n• Dependence on Quality of Segmentation Masks: The effectiveness of the approach relies on the quality of the initial segmentation; significant errors or artifacts in the mask could affect graph construction and subsequent error detection.\n• Limited to Structural Errors: While the method excels at detecting topological anomalies (e.g., open/short circuits), it may be less effective for errors that do not manifest as structural changes.\nPotential Overfitting in Large Datasets: The paper notes that training on larger datasets can sometimes lead to overfitting, suggesting that further work is needed to improve model regularization and scalability. The paper lacks the detailed discussion of how to prevent overfitting to the dataset."}, "questions": {"value": "What is the method used to convert images into binary masks?\nInstead of relying on CV to enhance the overall performance, why didn't you enhance the model and prevent overfitting issues?\nWhat are the sources of the database used in the experiments? What technology node is associated with them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qlW01cgbJC", "forum": "o4uLYNsVnS", "replyto": "o4uLYNsVnS", "signatures": ["ICLR.cc/2026/Conference/Submission14756/Reviewer_MHzX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14756/Reviewer_MHzX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14756/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762116640366, "cdate": 1762116640366, "tmdate": 1762925112656, "mdate": 1762925112656, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}