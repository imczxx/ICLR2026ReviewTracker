{"id": "S15Oo2hSlj", "number": 17487, "cdate": 1758276614827, "mdate": 1759897172090, "content": {"title": "Entropy Never Lies: Signed Entropy Integral Unmasks Mislabeled Data", "abstract": "Mislabeled samples in training datasets severely degrade the performance of deep networks, as overparameterized models tend to memorize erroneous labels. We address this challenge by proposing a novel approach for mislabeled data detection that leverages training dynamics. Our method is grounded in the key observation that correctly labeled samples exhibit consistent entropy decrease during training, while mislabeled samples maintain relatively high entropy throughout the training process. Building on this insight, we introduce a signed entropy integral (SEI) statistic that captures both the magnitude and temporal trend of prediction entropy across training epochs. SEI is broadly applicable to classification networks and demonstrates particular effectiveness when integrated with contrastive language-image pretraining (CLIP) architectures. Through extensive experiments on three medical imaging datasets---a domain particularly susceptible to labeling errors due to diagnostic complexity---spanning diverse modalities and pathologies, we demonstrate that SEI achieves state-of-the-art performance in mislabeled data identification, outperforming existing methods while maintaining computational efficiency and implementation simplicity.", "tldr": "", "keywords": ["mislabeled data detection", "signed entropy integral", "contrastive language-image pretraining (CLIP)"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/07a1b13ff5bcb8b2b3202ae0de6b78d0aa947d1c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses the problem of distinguishing mislabelled (noisy) samples from valuable clean samples that are difficult to classify. Motivated by medical data, it demonstrates that both mislabelled and clean samples exhibit high prediction entropy during training, which makes them difficult to distinguish. However, it is also observed that they have different training dynamics. To make use of this information, the paper proposes defining a 'signed entropy' statistic for self-supervision by introducing a sign function on top of the Shannon entropy. Additionally, the signed entropy integral is introduced to leverage the training dynamics across the entire training trajectory (rather than just one iteration). Finally, a data-driven threshold is used to separate clean samples from mislabelled ones. This approach was evaluated using three noisy label learning medical datasets and showed promising results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The idea is simple yet effective. It demonstrates its effectiveness with noisy and difficult-to-clean labels. \n\nThe paper is very well written and easy to follow. The proposed method is intuitively clear and well motivated. \n\nThe ablation studies effectively support the claim that the proposed sign is necessary for the entropy function. \n\nIn theory, the proposed method could be applied to any type of data, not just medical data."}, "weaknesses": {"value": "The paper is based only on medical datasets. There are standard benchmarks for noisy label learning to demonstrate generalisation, such as Clothing1M and WebVision, as well as small-scale datasets. \n\nThe paper is based purely on synthetic noisy scenarios. This is another clear limitation that needs to be addressed using real-world noise. \n\nIt would be helpful to make comparisons with entropy-based loss variations or temporal entropy integration. There are many methods for modifying standard entropy loss. For example, 'Learning from Training Dynamics: Identifying Mislabelled Data Beyond Manually Designed Features' (AAAI 2023) and 'Efficient Adaptive Label Refinement for Label Noise Learning' (Neurocomputing 2025). \n\nThe method can be computationally expensive due to the integration over training time. Presenting large-scale datasets would demonstrate this in practice. \n\nThe presented threshold is automatic, but is based purely on heuristics. This implies the need for particular tuning for different types of data. This is another reason for evaluation on standard benchmarks."}, "questions": {"value": "Why was the real-world noise experiment skipped? \n\nAlso, why are standard noisy label learning benchmarks missing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jk4wAS45Sf", "forum": "S15Oo2hSlj", "replyto": "S15Oo2hSlj", "signatures": ["ICLR.cc/2026/Conference/Submission17487/Reviewer_kas8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17487/Reviewer_kas8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805102176, "cdate": 1761805102176, "tmdate": 1762927369999, "mdate": 1762927369999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SEI, a signed-entropy–based training-dynamics metric to detect mislabeled samples, and reports state-of-the-art results on three medical imaging datasets. The core problem tackled is that overparameterized networks tend to memorize noisy labels, degrading performance; detecting and filtering mislabeled data during training is therefore critical. The key idea is that correctly labeled samples show a consistent drop in prediction entropy across epochs, whereas mislabeled samples maintain relatively high entropy; SEI integrates (signed) entropy over time to capture both magnitude and trend, with the sign reflecting label–prediction consistency. The implementation is simple and the method plugs into standard training loops. The claimed conclusion is that SEI is a simple, efficient, and broadly applicable metric that achieves SOTA mislabeled-data identification without architectural changes or complex training procedures."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly written and has a well-structured presentation. Figures and tables are clean and directly support the claims; the narrative is easy to follow.\n- The empirical section is strong within the chosen three datasets: ablations and compatibility checks against other SOTA training pipelines.\n- The method is simple and practical. No architectural changes needed; it integrates into existing training workflows with low overhead. This makes it work well with CLIP fine-tuning and, in principle, with standard classifiers.\n- The use of entropy trajectories makes the decision process intuitive and easy to reason about. This gives the approach an interpretability angle."}, "weaknesses": {"value": "- Limited novelty relative to prior entropy-based signals. The signed and temporal integration is a neat spin, but the conceptual jump may be incremental given prior work on entropy/uncertainty and training-dynamics signals.\n- The paper has a narrow domain scope. All results are on medical imaging; it’s unclear whether the approach generalizes to broader CV/ML settings. This also challenges the impact of the SOTA results and brings forward a question about how competitive is SEI when evaluated in standard benchmarks for label noise.\n- Similarly to the last point, the evaluation relies too much on synthetic noise. If the evaluation relies mainly on synthetic label noise, the conclusions may not carry over to real-world noisy datasets; this gap is well-documented in the literature.\n- SEI depends on training dynamics; thresholds and rankings might vary with epoch budget, LR schedules, data augmentation, label smoothing, or heavy regularization. This could be addressed with further discussion or ablation studies exploring the different design decisions made."}, "questions": {"value": "- Beyond CLIP, how does SEI perform with standard CNNs/ViTs trained from scratch or with supervised pretraining? Did the authors observe any meaningful differences in how different architectures present different entropy values/tendencies in noisy datasets?\n- How sensitive is SEI ranking to training length (early vs late epochs), LR schedules, strong augmentation, label smoothing, and weight decay? Is there a recommended epoch window for a stable ranking?   \n- Samples that are intrinsically hard or minority-pattern but correctly labeled may retain higher entropy and risk being flagged as noisy (class imbalance/long-tail scenarios). Do you have analyses showing that SEI does not systematically filter rare but correctly labeled patterns (e.g., minority subtypes)? Any per-class or per-subpopulation error analysis?\n- In which regimes does SEI struggle? Have you explored more extreme noise rates or class imbalances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IAvzTGqeZg", "forum": "S15Oo2hSlj", "replyto": "S15Oo2hSlj", "signatures": ["ICLR.cc/2026/Conference/Submission17487/Reviewer_GH2B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17487/Reviewer_GH2B"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995645731, "cdate": 1761995645731, "tmdate": 1762927368911, "mdate": 1762927368911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose a metric called SEI for identifying mislabeled data, considering both entropy dynamics and label-prediction consistency. The metric is motivated by the observation that correctly labeled samples exhibit consistent entropy decrease during training, while mislabeled samples maintain relatively high entropy throughout training. Experiments on multiple benchmarks shows competitive performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The approach is simple, architecture-agnostic, and easy to integrate. Experiments demonstrate strong performance across multiple benchmarks."}, "weaknesses": {"value": "my major concern is that the method is build upon empirical observation on a handful of dataset and noise setting. While the presented results seems promising, it is unclear when SEI is expected to succeed or fail.\n\nMore discussion and intuition is needed to explain why the proposed SEI works. For example, for high capacity network, the model has the potential to remember the wrong label, this might directly impact the label-prediction alignment pattern (one of the main component in the SEI).\n\nFurthermore, because the experiments rely on controlled, artificially generated noise, it is unclear whether the training-dynamics patterns SEI exploits are specific to these noise models or generalize to real world applications."}, "questions": {"value": "It seems odd to me to frame inter-observer variability as ‘label noise.’ In my view, such variability is more about uncertainty, not necessarily wrong labels. How should SEI handle inter-observer variability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8Q5bqkIp3h", "forum": "S15Oo2hSlj", "replyto": "S15Oo2hSlj", "signatures": ["ICLR.cc/2026/Conference/Submission17487/Reviewer_DQuc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17487/Reviewer_DQuc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762057603275, "cdate": 1762057603275, "tmdate": 1762927368242, "mdate": 1762927368242, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a simple yet effective method, Signed Entropy Integral (SEI), for detecting mislabeled samples in training datasets through analysis of training dynamics.  \nThe core insight is that correctly labeled samples exhibit a steady decrease in prediction entropy during training, whereas mislabeled samples maintain persistently high entropy due to model–label inconsistency.  \n\nSEI functions as an automatic, architecture-agnostic indicator of label noise.  \nA self-calibrating threshold is introduced, leveraging auxiliary-class pseudo-errors to distinguish clean from mislabeled samples without requiring external supervision.  \n\nExperiments conducted on three medical imaging datasets demonstrate that SEI achieves state-of-the-art performance for mislabeled data detection under both symmetric and confusion-calibrated noise conditions.  \n\nOverall, the paper presents a clear and well-motivated study with good empirical support.  It provides valuable insight into leveraging entropy trajectories for robust label noise detection, supported by transparent presentation and convincing experimental validation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**1. Clear Motivation and Conceptual Simplicity**\n\nThe paper addresses a well-motivated and underexplored problem—detecting mislabeled samples through training dynamics—and proposes a simple yet effective solution with clear conceptual grounding.\n\n---\n\n**2. Architecture-Agnostic Design and Practical Usability**\n\nSEI operates without architectural modifications and shows strong generalization across both CNN (ResNet) and Transformer (CLIP) backbones.  \nIts plug-and-play nature and minimal computational cost make it practical for real-world noisy-label scenarios.\n\n---\n\n**3. Interpretability and Diagnostic Insight**\n\nThe method provides an intuitive and interpretable perspective on model behavior under label noise.  \nBy linking entropy evolution to label correctness, it offers diagnostic insight into how neural networks react to mislabels during training."}, "weaknesses": {"value": "**1. Sensitivity to Training Configuration**\n\nSince SEI depends on entropy evolution across training, its stability under different optimization schedules remains unclear.  \nVariations in training duration, learning rate, or early stopping may affect the computed SEI values, raising concerns about reproducibility.\n\n---\n\n**2. Lack of Statistical Significance Analysis**\n\nAlthough the reported results show consistent improvements, no variance measures or statistical tests are provided.  \nWithout reporting standard deviations or confidence intervals, it is difficult to determine whether the gains are statistically meaningful.\n\n---\n\n**3. Lack of discussion on the stability and generality of the thresholding strategy.**\n\nThe auxiliary-class–based threshold still depends on a manually defined sampling ratio \\( N / (K + 1) \\).  \nIts robustness under data imbalance, limited samples, or multimodal settings has not been validated.\n\n---\n\n**4. Limited Domain Generalization**\n\nAll experiments are conducted on medical imaging datasets.  \nIt remains uncertain whether SEI’s entropy patterns generalize to other domains such as natural image or text classification, where label noise and model calibration behave differently."}, "questions": {"value": "**1. Sensitivity to Training Configuration**\n\nIt is unclear how sensitive SEI is to training hyperparameters such as the number of epochs or the learning rate.  \nSince the method relies on entropy trajectories over training, the stability of SEI under different optimization schedules (e.g., early stopping or extended training) should be clarified.\n\n> **Question:**  \n> How sensitive is SEI to training duration and learning rate choices?\n\n---\n\n**2. Lack of Statistical Significance Analysis**\n\nAlthough the experimental tables are comprehensive, they lack statistical tests such as confidence intervals or t-tests.  \nWithout measures of variability, it is difficult to judge whether the observed performance improvements are statistically significant or within the range of random fluctuation.\n\n> **Questions:**  \n> - Could the authors report standard deviations or statistical tests (e.g., t-test, CI) to validate the robustness of SEI’s improvements?  \n> - How consistent are the results across multiple random seeds?\n\n---\n\n**3. Stability of the Thresholding Strategy**\n\nThe proposed auxiliary-class–based adaptive threshold depends on the ratio \\( N / (K + 1) \\), which remains a manually defined proportion.  \nIt is unclear whether this strategy is stable under data imbalance or when applied to multimodal tasks.\n\n> **Questions:**  \n> - How sensitive is the SEI threshold to the number or sampling ratio of auxiliary-class samples?  \n> - Have the authors tested how performance changes when this ratio is varied?  \n\n---\n\n**4. Domain Generalization of the Entropy Trend**\n\nThe paper primarily focuses on medical imaging datasets.  \nHowever, it remains uncertain whether the same entropy evolution patterns hold in other domains such as natural images, where model calibration and noise characteristics differ.\n\n> **Question:**  \n> For non-medical tasks, would SEI exhibit similar entropy trajectories, or is this behavior domain-specific?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8lDVsnotgx", "forum": "S15Oo2hSlj", "replyto": "S15Oo2hSlj", "signatures": ["ICLR.cc/2026/Conference/Submission17487/Reviewer_tyJm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17487/Reviewer_tyJm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762070649849, "cdate": 1762070649849, "tmdate": 1762927367669, "mdate": 1762927367669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}