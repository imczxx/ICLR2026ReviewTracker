{"id": "Zt5Tu3Xdvw", "number": 21740, "cdate": 1758321149628, "mdate": 1759896905804, "content": {"title": "Consistent 3D Object Detection with Active LLM Reasoning", "abstract": "Maintaining semantic label consistency across multiple views is a persistent challenge in 3D semantic object detection. Existing zero-shot approaches that combine 2D detections with vision-language features often suffer from bias toward non-descriptive viewpoints and require a fixed label list to operate on. We propose a truly open-vocabulary algorithm that uses large language model (LLM) reasoning to relabel multi-view detections, mitigating errors from poor, ambiguous viewpoints and occlusions. Our method actively samples informative views based on feature diversity and uncertainty, generates new label hypotheses via LLM reasoning, and recomputes confidences to build a spatial-semantic representation of objects. Experiments on controlled single-object and diverse multi-object scenes show over 40\\% improvement, in accuracy and sampling rate over ubiquitous fusion methods using YOLO, and CLIP. We demonstrate in multiple cases that our LLM-guided Active Detection and Reasoning (LADR) balances detail preservation with reduced ambiguity and a low sampling rate.", "tldr": "An iterative method that actively uses an LLM to create consistant object detection in 3D space.", "keywords": ["Large Language model", "object detection", "exploration", "semantic labeling", "Large Vision Model"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3318ecb592d7cf443c04d0a200a532d49864ca15.pdf", "supplementary_material": "/attachment/3876963f12caabc531d5f0bc24d758865088b0d8.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes LADR, a method that leverages LLMs to refine multi-view 3D object labels by iteratively selecting informative views and prompting the LLM to generate or revise semantic labels. It claims improvements over baseline fusion strategies using YOLO and CLIP, particularly in label consistency and sampling efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The high-level idea of using LLMs to resolve viewpoint-induced label inconsistency is intuitive."}, "weaknesses": {"value": "(1) ***Technical Novelty***: The proposed method appears like a sequence of engineering steps rather than a principled algorithm. It is largely a straightforward pipeline stitching together off-the-shelf components (YOLO, CLIP, SAM, GPT-4V) with limited technical novelty.\n\n* **LLM-guided relabeling for 3D consistency**. This is an incremental adaptation of existing multimodal reasoning pipelines. The paper uses off-the-shelf YOLOE, OpenCLIP, SAM2, and GPT-4V to relabel detections. The “relabeling” step is not technically novel, as it amounts to prompting an LLM to reconcile labels across multiple 2D views. There is no new learning objective, model architecture, or mathematical formulation beyond basic feature averaging and LLM prompting.\n\n* **Smart sampling strategy**. While the idea of selecting informative views is framed as “active learning,” the implementation is heuristic. In “LLM-Sampling” (Section 5.2), informative views are chosen by computing cosine distances between CLIP embeddings. This is an established approach in active exploration literature. The variant “LLM-Polygon” (Section 5.3) uses a fixed polygon partition to spatially group detections, but this is again a geometric bookkeeping device, not a new algorithmic principle. The novelty lies mainly in combining these existing heuristics within a single loop, rather than proposing a new active sampling algorithm.\n\n* **Spatial-semantic mapping**. I do not see any new representational or fusion mechanism. The “polygon grounding” (Section 5.3) is a coarse geometric discretization, not a learned or optimized structure.\n \n\n(2) ***Experimental Validation***: The paper does not include any ablation studies, which are critical to validate its claims. A key missing ablation would be to isolate the contribution of LLM reasoning versus CLIP-only sampling. Other missing experiments include sensitivity to LLM prompt and model choice, statistical robustness, scalability, and runtime analysis."}, "questions": {"value": "Please refer to my comments in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CfW4rwlWyK", "forum": "Zt5Tu3Xdvw", "replyto": "Zt5Tu3Xdvw", "signatures": ["ICLR.cc/2026/Conference/Submission21740/Reviewer_RgHZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21740/Reviewer_RgHZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761758014460, "cdate": 1761758014460, "tmdate": 1762941912415, "mdate": 1762941912415, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces LADR, a framework for achieving consistent multi-view 3D object detection in open-vocabulary settings. The method uses large language models to reason about visual inputs from multiple viewpoints, actively sampling informative views and reweighting label hypotheses based on CLIP feature diversity and confidence. Three variants (LLM-Random, LLM-Sampling, and LLM-Polygon) progressively add structured sampling and spatial grounding. Experiments on single-object and multi-object synthetic datasets demonstrate improvements in label consistency and accuracy over other baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents an interesting direction, i.e., using LLMs not only as labelers but also as agents that reason about multiple viewpoints and guide data collection.\n\n- Both single- and multi-object scenarios are evaluated with quantitative metrics and qualitative examples, suggesting that the proposed idea yields consistent improvements.\n\n- The stepwise introduction of three algorithm variants provides a clear understanding of each component."}, "weaknesses": {"value": "- While the idea of combining LLM reasoning with CLIP features for 3D detection is interesting, much of the pipeline is a straightforward composition of existing components (YOLOE, SAM2, CLIP, GPT-4V) with a small amount of new learning or modeling innovations.\n\n- The method requires multiple inner-loop LLM queries per object and per iteration, which is computationally expensive and likely infeasible for real-time or large-scale applications.\n\n- Baselines such as CLIP or YOLO fusion are quite weak compared to the rich LLM pipeline. Stronger open-vocabulary 3D methods are not adequately compared.\n\n- The success rate metric relies on heuristic thresholds, making the quantitative gains somewhat fragile. Statistical significance or ablations of hyperparameters are missing."}, "questions": {"value": "- Could the authors provide the computational cost (LLM calls, latency, GPU hours) compared to CLIP or other baselines?\n- Since the method heavily depends on GPT-4V, how stable are the results across different LLMs or model versions?\n- Does the system generalize beyond object naming (e.g., affordance reasoning or relationship labeling), or is it limited to class identification?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KKAj4TEPkA", "forum": "Zt5Tu3Xdvw", "replyto": "Zt5Tu3Xdvw", "signatures": ["ICLR.cc/2026/Conference/Submission21740/Reviewer_DeFN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21740/Reviewer_DeFN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841747479, "cdate": 1761841747479, "tmdate": 1762941912184, "mdate": 1762941912184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LADR (LLM-guided Active Detection and Reasoning), a system integrating YOLOE, CLIP, and GPT-4V for multi-view 3D object labeling. It introduces three procedural variants (LLM-Random, LLM-Sampling, LLM-Polygon) that progressively incorporate CLIP-based sampling and spatial grounding to improve label consistency across viewpoints. Experiments are conducted in simulation on single- and multi-object datasets, showing numerical gains over YOLO/CLIP baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear: improving semantic consistency in open-vocabulary 3D detection.\n\n2. The system is well-engineered and described in detail, including clear workflow diagrams and ablation setups.\n\n3. Quantitative improvements are consistent across tasks."}, "weaknesses": {"value": "1. The contribution is primarily procedural integration of existing components (YOLOE + CLIP + GPT-4V + SAM2), with no novel learning formulation or analytical insight. The workflow could be implemented as an engineering prototype rather than a research contribution.\n\n2. Evaluation lacks depth. Experiments are all in simulated environments (Isaac Sim). No real-world data or generalization study. The claimed “40% improvement” is mostly due to poor baselines rather than a strong methodological leap.\n\n3. Despite claiming to be “truly open-vocabulary” and “reasoning-based,” the system fundamentally depends on CLIP’s embedding space and manually designed prompts. The reasoning is not learned or interpretable."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1V3YIsFVsU", "forum": "Zt5Tu3Xdvw", "replyto": "Zt5Tu3Xdvw", "signatures": ["ICLR.cc/2026/Conference/Submission21740/Reviewer_wymX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21740/Reviewer_wymX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990355995, "cdate": 1761990355995, "tmdate": 1762941911979, "mdate": 1762941911979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}