{"id": "LJk3ZbsTdO", "number": 20176, "cdate": 1758303321733, "mdate": 1763739070785, "content": {"title": "HOW TO MODEL HUMAN ACTIONS DISTRIBUTION WITH EVENT SEQUENCE DATA", "abstract": "This paper studies forecasting of the future distribution of events in human action sequences, a task essential in domains like retail, finance, healthcare, and recommendation systems where the precise temporal order is often less critical than the set of outcomes. We challenge the dominant autoregressive paradigm and investigate whether explicitly modeling the future distribution or order-invariant multi-token approaches outperform order-preserving methods. We analyze local order invariance and introduce a distribution-based metric to quantify temporal drift. We find that a simple explicit distribution forecasting objective consistently surpasses complex implicit baselines. We further analyze the emergence of mode collapse in predicted categories, identifying and evaluating key contributing mechanisms. This work provides a principled framework for selecting modeling strategies and offers practical guidance for building more accurate and robust forecasting systems. The code will be released upon publication.", "tldr": "", "keywords": ["event sequences"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/422423cc4b0eb94b3e2758ac92907b2741e3d65c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles a relevant question for sequence modelling tasks, especially in the era of LLMs and Transformers for non-NLP tasks. It investigates the central question of whether next-token prediction is the best paradigm for learning such models or whether the choice of learning task should be dataset / domain specific. In particular it introduces methods for identifying the order dependence of a dataset via the static-ness of the distribution of tokens in sliding windows over sequences. \n\nIt thoroughly evaluates how order dependency varies across domains and how various learning paradigms (next token prediction, multi token prediction, and direct future distribution prediction) perform in such domains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Overall this is an interesting paper that answers a relevant question regarding whether next token prediction should be the learning task for large models across domains. The experiments are extensive, with 4 reasonable baselines, 3 learning paradigms, and 4 different approaches to learning future event distributions (autoregressive loss, target loss, matched loss, and order-invariant loss). The authors provide analysis of the static-ness of various datasets with quantitative results using a novel metric."}, "weaknesses": {"value": "The authors could provide more exploration of and connection to previous work in quantifying distribution shift and static-ness of sequential data. Given the breadth of the experiments the authors undertake it would be helpful for them to tie them together - right now some things feel underexplained - for example what is the parameter lambda; how is section 4.3 connected to the rest of the paper; what is the GPT result reported alongside GRU everywhere?"}, "questions": {"value": "1) Why the choice of R=3 for the static-ness metric: is there analysis of the effect of R on the value of the static-ness metric, as this seems like a low number of anchor points.\n2) The connection of 4.3 to the rest of the paper is not entirely clear - how are these windows constructed? Centered windows are constructed at each position and then within that window random shuffling is applied? It sounds like these windows overlap if this is performed at each position. Is Fig. 2 the perplexity from a fixed, pre-trained model on the shuffled sequences? Or is it the perplexity achieved by training a model on shuffled sequences?\n3) What is λ - it is never explained and its relevance is not explored in the text?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vG7sC8CxOA", "forum": "LJk3ZbsTdO", "replyto": "LJk3ZbsTdO", "signatures": ["ICLR.cc/2026/Conference/Submission20176/Reviewer_FL9s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20176/Reviewer_FL9s"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761591452519, "cdate": 1761591452519, "tmdate": 1762933689158, "mdate": 1762933689158, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the performance of different forecasting models applied to event sequence data. Specifically, it challenges the prevailing autoregressive paradigm and examines models that explicitly represent the future distribution of events, independent of their temporal order. The central assumption underlying this work is that, in certain applications, the precise chronological ordering of events may not be essential for accurate prediction. To address this perspective, the authors propose a new formulation that focuses on predicting the distribution of future events within a specified temporal window. The study empirically compares four distinct prediction formulations: (1) predicting the next single event, (2) predicting the sequence of subsequent events, (3) predicting the set of subsequent events, and (4) predicting the distribution of subsequent events. The experimental results suggest that, on average, order-invariant models outperform order-based models. However, it is important to note that the evaluation relies on an order-invariant metric, which may inherently favor such models. The paper further introduces the staticity index, a novel measure designed to estimate the degree to which event order matters within a dataset. This index can assist in determining whether an order-based or order-invariant modeling paradigm is more suitable for a given application."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed concept of predicting the distribution of actions is interesting and potentially impactful. This formulation appears to be novel and is particularly relevant in scenarios where the local temporal order of events is not essential for accurate forecasting. The model is trained by optimizing the KL divergence between the predicted distribution and the empirical event distribution, which provides a principled approach for aligning the model’s outputs with the observed data.\n\n- The paper introduces a staticity index designed to estimate the degree to which the sequence order is important within a dataset. The staticity index quantifies how the empirical distribution of events within each sequence evolves over time. By capturing this temporal stability or variability, the index can serve as a diagnostic tool for determining whether an order-based or order-invariant problem formulation is more appropriate for a given dataset.\n\n- The empirical evaluation includes a comparison of four predictive formulations across eight benchmark datasets. The four problem formulations are: (1) predicting the next single event, (2) predicting the sequence of subsequent events, (3) predicting the set of subsequent events, and (4) predicting the distribution of subsequent events. The proposed approach demonstrates superior performance on five out of the eight datasets. These results suggest that when the temporal ordering of future events carries limited predictive information, modeling the distribution of event types alone can be sufficient for achieving strong forecasting performance.\n\n- The paper also introduces an order-invariant Matched-F1 score, an evaluation metric that treats sequences as unordered sets (bags) of events. This metric enables fair comparison between order-sensitive and order-invariant models, particularly in cases where the temporal order may not be relevant.\n\n- The paper is easy to read and understand. It provides enough context to understand the problem and the key contributions."}, "weaknesses": {"value": "- The paper would benefit from a more comprehensive analysis of the proposed GRU-dist model. Since this model represents the main model contribution, a deeper examination of its behavior and performance is essential to strengthen the paper’s empirical findings. For instance, it would be informative to provide a detailed comparison between GRU-dist and GRU-matched across several datasets, highlighting where and why the performance differences occur. Additionally, the paper could expand on the analysis of the sampling process used in order-invariant models.\n\n- The paper states that it introduces “a KL-based metric to quantify temporal drift,” but the conceptual link between the proposed metric and the KL divergence is not clearly explained or sufficiently justified. Providing a clearer theoretical motivation and detailing how the metric relates to the KL formulation would help the reader better understand its validity and relevance. Including an extended explanation or derivation in the supplementary material would be a suitable way to address this.\n\n- Because of the specific problem formulation adopted in the paper, the model does not evaluate the temporal prediction component typically considered in the standard TPP framework. The time-invariant formulation focuses exclusively on predicting event distributions rather than event timings. This distinction limits the direct comparability of the proposed method with traditional time-sensitive TPP models.\n\n- The evaluation metric introduced in the paper appears to favor order-invariant models, since it does not account for the temporal ordering of events. This bias could lead to an unfair comparison between order-based and order-invariant approaches. Models that are designed to capture event order are inherently penalized when evaluated using an order-agnostic metric. It would therefore be valuable for the paper to discuss this limitation and, if possible, include additional metrics that can more equitably assess both model types."}, "questions": {"value": "- As mentioned earlier, the paper would benefit from a deeper analysis of the performance and behavior of the proposed approach. Providing a more thorough interpretation of the results would help clarify the strengths and limitations of the model, as well as the conditions under which it performs best.\n\n- In Table 2, the meaning of the symbol S is not explained. The table caption should explicitly define this notation to ensure that the results are self-contained and easy to interpret without referring back to the main text.\n\n- In Table 3, it is unclear how many next events are being predicted. The caption currently mentions only N, but not its value.\n\n- In Table 3, it would be valuable to include an explanation or discussion of why the Repeat method performs better than other methods on three of the datasets. Understanding the reasons behind this result could provide useful insights into the characteristics of the datasets or the modeling assumptions that favor this method.\n\n- Also in Table 3, it would be helpful to explain why the GT performance for the Taobao dataset is not equal to 1.0."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pAMPXdKv0W", "forum": "LJk3ZbsTdO", "replyto": "LJk3ZbsTdO", "signatures": ["ICLR.cc/2026/Conference/Submission20176/Reviewer_aqT3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20176/Reviewer_aqT3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935063003, "cdate": 1761935063003, "tmdate": 1762933688351, "mdate": 1762933688351, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Forecasting human action sequence is an important task in various domains such as retail, finance, and recommendation.\nAn autoregressive model is a dominant solution in the field due to its huge success in NLP,\nyet they have limitations in this domain to address distributional imbalance or order irrelevance.\nThis paper studies how does GRU handle human action sequence forecasting."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "*\tLocal order irrelevant evaluation seems important in real-world situations.\n*\tAuthors conduct experiments in various datasets"}, "weaknesses": {"value": "*\tThe three hypotheses and four-step framework presented in the introduction are not sufficiently discussed or supported in the later sections.\n*\tThe novelty of the work appears limited. The main idea—modifying the GRU loss function to hit one of the k consecutive targets instead of a single one—seems rather trivial, given the stated goal of evaluating continuous k-hit performance.\n*\tThe paper lacks implementation details or released code to ensure reproducibility."}, "questions": {"value": "*\tWhat is the core contribution of this paper? Does it propose a new problem setting or a new method, or is it mainly an empirical study applying existing techniques to a new context?\n*\tAre the actual timestamps in the sequential data considered in the model or evaluation?\n*\tWhile experimental results are provided for GRU and its variants, what about Transformer-based models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "a3U8SO4KED", "forum": "LJk3ZbsTdO", "replyto": "LJk3ZbsTdO", "signatures": ["ICLR.cc/2026/Conference/Submission20176/Reviewer_6xsi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20176/Reviewer_6xsi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20176/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762767007602, "cdate": 1762767007602, "tmdate": 1762933687458, "mdate": 1762933687458, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Updated manuscript."}, "comment": {"value": "Dear Reviewers and Area Chair, \n\nThank you for your thoughtful feedback on our manuscript. In response to your comments, we have carefully revised the paper to address all concerns raised.  **The revised manuscript has been uploaded to the submission system with tracked changes in yellow color**."}}, "id": "h6FGJB4s3j", "forum": "LJk3ZbsTdO", "replyto": "LJk3ZbsTdO", "signatures": ["ICLR.cc/2026/Conference/Submission20176/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20176/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission20176/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763739701503, "cdate": 1763739701503, "tmdate": 1763739701503, "mdate": 1763739701503, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}