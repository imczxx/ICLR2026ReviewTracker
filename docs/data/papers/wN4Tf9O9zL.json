{"id": "wN4Tf9O9zL", "number": 18819, "cdate": 1758291136066, "mdate": 1759897079618, "content": {"title": "Physics-Informed Machine Learning under Climate Domain Shift: PDE-Free Physics Regularisation for Cloud Prediction", "abstract": "We study out‑of‑distribution generalisation in geophysical prediction and propose CC‑PINN, a physics‑informed multi-layer perceptron (MLP) that encodes the Clausius–Clapeyron thermodynamic relation as a gradient‑based regularisation term. Unlike prior PINNs, CC-PINN requires no explicit governing-equation. CC‑PINN introduces a lightweight constraint on humidity-temperature consistency without altering network architecture. Trained on atmospheric reanalysis data (temperature, pressure, relative humidity, specific humidity, vertical velocity) using modest computational resources, CC-PINN matches a capacity-matched MLP in-distribution and improves out-of-distribution performance. CC‑PINN achieves a 12.3\\% reduction in global area-weighted RMSE over a capacity‑matched MLP baseline. Under a stringent covariate-shift test - training only on the polar latitudes - CC‑PINN reduces tropical area-weighted root mean squared error (RMSE) by 22.6\\% relative to the baseline, while maintaining in‑distribution parity. Ablations show the performance gains are substantially attenuated when the physics term is removed, highlighting the role of targeted domain knowledge inclusion in improving extrapolation. These findings suggest that compact, domain‑motivated regularisation can deliver robust generalisation in scientific ML tasks.", "tldr": "TL;DR: A lightweight, PDE-free physics-in-the-loss (Clausius–Clapeyron) regulariser on temperature sensitivity makes an MLP generalise better for cloud fraction under domain shift—without hurting in-distribution accuracy.", "keywords": ["physics-in-the-loss", "PDE-free physics regularization", "Clausius–Clapeyron constraint", "cloud (cloud fraction) prediction", "out-of-distribution generalization", "climate domain shift", "geophysical machine learning", "atmospheric thermodynamics", "ERA5 reanalysis", "gradient supervision (temperature sensitivity)", "area-weighted RMSE", "physics-guided inductive bias", "Physics Informed Machine Learning", "Physics Informed Neural Networks"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1443111ed33b4b9c97e2e05cc181b063f539c39d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses the out-of-distribution (OOD) generalisation problem in climate prediction, specifically, cloud fraction estimation by proposing a lightweight physics-informed MLP based neural network called CC-PINN. CC-PINN introduces a physics-based regularisation term derived from the Clausius–Clapeyron (CC) thermodynamic relation, which links saturation vapour pressure to temperature. This CC-based term is added as a gradient supervision constraint that aligns the model’s temperature sensitivity with the physically expected CC slope, enforcing humidity–temperature consistency without explicitly encoding a PDE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "It reframes physics-informed learning as soft inductive bias alignment rather than explicit PDE supervision.\nIt applies this principle to the domain of climate OOD generalisation which is not addressed by data-driven models.\nThe Polar and Tropics transfer setup offers a novel experimental protocol mimicking climate regime shifts, further reinforcing originality in evaluation design. The approach is architecture-agnostic and computationally lightweight, making it efficient without large compute budgets."}, "weaknesses": {"value": "The evaluation uses only two fixed timestamps August 1, 2024 (training) and December 12, 2024 (testing), representing a single diurnal and seasonal pair. Since the stated goal is to test out-of-distribution (OOD) robustness under climate regime shifts, two discrete snapshots may not sufficiently capture the temporal variability.\nThe study evaluates only RMSE (with area weighting). Other metrics such as bias, correlation, and uncertainty quantification could strengthen the paper's proposed contributions. RMSE alone does not capture systematic bias, error asymmetry (e.g., over- vs. under-predicted cloud fraction), or uncertainty reliability, which are crucial for scientific interpretation.\nIn terms of climate variability qualitative evaluation is missing."}, "questions": {"value": "Could the authors clarify why only two timestamps (August and December 2024) were chosen?\nHow representative are these two snapshots of broader seasonal and inter annual variability in cloud–temperature–humidity coupling?\nWhy was RMSE chosen as the sole evaluation metric? \nCan authors provide Global error maps (absolute/bias) for baseline vs CC-PINN for better evaluation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PbXP7XZmaS", "forum": "wN4Tf9O9zL", "replyto": "wN4Tf9O9zL", "signatures": ["ICLR.cc/2026/Conference/Submission18819/Reviewer_Sxnv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18819/Reviewer_Sxnv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18819/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761105968256, "cdate": 1761105968256, "tmdate": 1762930529416, "mdate": 1762930529416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes adding a physics-based regularization term to better predict cloud fraction across the world. The Clausius-Clapeyron relation is a known thermodynamic relation describing cloud formation. The constraint is introduced in an established simple NN architecture and compared to the identical architecture without the constraint. The paper shows that on their test set, the cloud fraction prediction on ERA5 is improved."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The constraint is a nice physical relation; it is easy to add to the neural network presented, and it improves performance. The authors sufficiently show the effectiveness of the approach."}, "weaknesses": {"value": "I am a bit confused by the train and test set consisting of only one time step; this does not seem to be enough to show the usefulness of the constraint. More extensive temporal evaluation is definitely necessary. Additionally, most forecasting models are probabilistic, I would therefore recommend to asssess the constraint at least additionally in a probabilistic setup."}, "questions": {"value": "- What do you expect to change if you use more than one time step for training and testing?\n- What would you expect to change if a better dataset is used than ERA5 (as this one is known to be lacking in cloud fractions)?\n- Can you elaborate on why you do not do probabilistic forecasting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7NxYLglKGZ", "forum": "wN4Tf9O9zL", "replyto": "wN4Tf9O9zL", "signatures": ["ICLR.cc/2026/Conference/Submission18819/Reviewer_QKzk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18819/Reviewer_QKzk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18819/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841852661, "cdate": 1761841852661, "tmdate": 1762930502136, "mdate": 1762930502136, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a physics-informed neural network (CC-PINN) based on Clausius–Clapeyron thermodynamic relation targeting geophysical prediction. In particular, CC-PINN  is deployed for Cloud prediction. To demonstrate, a prediction accuracy-based comparison between NN and PINN is performed."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Using PINN in such application is very useful  as PINN was proposed to integrate knowledge of physical laws (in the form of partial differential equations). This leads to improvement in NN prediction accuracy. However, the paper made an excellent claim, indicating that the proposed CC-PINN  can perform without explicit governing-differential equations. Instead, CC-PINN uses a constraint ingratiated into the loss function (normalised, area-weighted objective)."}, "weaknesses": {"value": "The paper presentation arises three main concerns of the paper claim:\n- If eq(3) is used as a learning objective, then the proposed CC-PINN Is using differential equations to govern the training. Eq(3) needs the value of L_phy from eq(2), which is output of differential equations. Could you please clarify this point?\n- The results demonstrated in Figure 1 are a comparison between MLP-based PINN and the baseline MLP, and show that MLP-based PINN exhibits less RMSE. But is  it a fair comparison? As MLP-based PINN uses the physical knowledge, having lower RMSE is a straightforward result.  Why is there no comparison with the state of the art paper? Such extra comparison can be very valuable to show the work uniqueness and to quantify its novelty.  \n- Shouldn’t we compare first between analytical/ numerical Conventional methods and NN for this problem? Then, we can show CC-PINN is better. Such a comparison will show the actual motivation of the paper and provide more insights into physical perspectives i.e., the interpretation of prediction improvement in terms of RSME."}, "questions": {"value": "To improve the paper readability, please consider the following points:\n- In eq(1), what are these symbols? Please define all of them.\n- In eq(3) na eq(5), the authors used “B”. As it is the same set, please define in eq(3), not later. \n- Why did you propose eq(4) since it was introduced before at the end of section 3.3.?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZWiw0tjOOJ", "forum": "wN4Tf9O9zL", "replyto": "wN4Tf9O9zL", "signatures": ["ICLR.cc/2026/Conference/Submission18819/Reviewer_Ymhf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18819/Reviewer_Ymhf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18819/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762007234447, "cdate": 1762007234447, "tmdate": 1762930471616, "mdate": 1762930471616, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel method for improved out-of-distribution (OOD) generalization for deep learning-based cloud parametrization schemes in hybrid climate models. The authors advocate that a neural network predicting cloud fraction should have, up to constant scaling, the same partial derivative wrt. temperature than the derivative predicted by the Clausius–Clapeyron equation. To enforce this property, the authors propose to additional minimize the mean squared error between these two quantities. For validation, the authors train a small MLP to regress cloud fraction from atmospheric covariates, such as temperature and specific humidity, on ERA5 reanalysis data and compare results with and without the additional loss term. They find that when trained with the additional objective and on polar regions only (low temperature and humidity) the network better generalizes to the tropics (high temperature and humidity). The evaluation protocol is supposed to mimick the kind of distribution shift that is to be expected in a warmer climate."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper is overall well motivated and tries to tackle a highly relevant and under-explored problem. Namely, how physical priors can be utilized to make neural networks more robust to climate change and, thus, applicable for (hybrid) climate modelling. The argument for this is clearly laid out by the authors in the introduction. \n\nThis problem also bears significance to the broader machine learning community as a case study for a strong and continuous form of distribution shift.\nIn the context of climate modelling, the concrete task of cloud fraction parametrization is well chosen, and again, the authors clearly explain its significance. While the Clausius–Clapeyron equation has been utilized before to improve robustness to a warming climate, its direct use by the authors as target for the temperature sensitivity of a neural network is a novel and welcomed contribution. If effective, the suggested method could act as straightforward and simple way to improve robustness in cloud parametrization schemes."}, "weaknesses": {"value": "While the motivation and method of the paper are well founded, its main weakness is the lack of compelling evidence for the claims made therein. The paper could improve substantially by conducting more thorough experiments and evaluations.\n\n**W1. Insufficient data for training and evaluation**\n\nA major flaw is the use of only two (specific) time steps, i.e. hours out of roughly 400,000 available ones for training and evaluation. This problem is exaggerated even more by the fact that the grid cells stemming from a single time step are not independent but are highly correlated in space, especially for the temperature field or at pressure levels in the stratosphere. It is completely unclear whether the results presented in the paper are just a mere coincidence for one particular atmospheric state or whether they hold in the general. I suggest that the authors re-run their experiments on sufficiently long training, validation, and testing periods that span years to decades.\n\n**W2. Missing comparison to baseline methods**\n\nThe authors do not compare their results to existing methods for OOD generalization. This makes it difficult to gauge the overall effectiveness of the proposed method to alternative approaches. Moreover, no comparisons to existing cloud fraction prediction methods are made. While the main focus of the paper is not on a state-of-the-art cloud fraction prediction, comparing the method to existing results \nwould made it easier to understand how well the trained model solves the prediction task in the first place. I suggest that the authors include other baseline methods, both for OOD generalization, as well as cloud fraction prediction, in their evaluation.\n\n**W3. No direct experiments on climate change induced distribution shifts**\n\nThe stated purpose of the paper is to improve robustness in face of a warming climate. However, the authors explicitly decide to use a spatial distribution shift (polar vs tropic regions) as a proxy for a warming climate. ERA5 back-extends to 1950 and, thus, already contains significant amounts of data under a warming climate. The authors could have tested their hypothesis directly on ERA5 by training up until a certain date, for instance the year 2000, and reserve data past that date for evaluation. Such an evaluation protocol would exactly match the training setup of the targeted use-case of a data-driven hybrid climate model. To demonstrate robustness in the face of even stronger shifts than those captured by reanalysis data, climate model runs could have been used as additional verification tool. While a neural network would only be able to act as emulator in that case, such experiments could still be insightful to explore the generalization behavior, in particular under different forcings.\n\n**W4. Lack of qualitative evaluation and figures**\n\nThe main claims of the paper are primarily explored by investigating RMSE grouped by region or temperature. However, the paper is surprisingly void of figures, containing one in total. Possible approaches to generate more insights into the problem and increase confidence in the method could be, but are not limited to:\n\n1. Comparing spatially resolved cloud fraction maps between prediction and ground truth.\n2. Plotting RMSE as function of latitude and longitude, leading to a more detailed picture than mere grouping by latitudinal bands. E.g. to find differences between oceans and land surfaces.\n3. Plotting cloud fraction prediction against temperature for a specific sample. For instance, to see differences in smoothness between the regularized and unregularized version of the model.\n4. Scatter plots or kernel density estimates of temperature and humidity for both in-domain and out-of-domain data to visualize the underlying shift in the joint distribution.\n\n**W5. Small model size**\n\nResults are solely presented for a very small model with less than 500 parameters. Such model size might be particular appropriate for a hybrid climate model due to its low compute overhead. However, from a more theoretical point of view, the claim of the authors could be strengthened further if the method would yield comparable gains when scaled. \n\n**W6. Paper assumes (moderate) background in field-specific domain science**\n\nThe paper could be made more approachable for a general machine learning focused audience by explaining the geophysical background in more detail. For instance, by showcasing the Clausius–Clapeyron relation on a phase diagram and explaining its relationship to cloud cover."}, "questions": {"value": "**Q1:** Equation 6 is missing the normalization factor $\\frac{1}{\\sqrt{\\sum_{i \\in B}{w_i}}}$ (compare with Equation 3). Is this on purpose? If so, this will make comparison between different latitudes void.\n\n**Q2:** Why are two different tolerances $\\tau_g$ and $\\tau_s$ used in the definition of the directional agreement metric?\n\n**Q3:** The Clausius–Clapeyron relation assumes thermodynamic equilibrium and an ideal gas. Can there be situations where imposing it as soft constraint on a neural network can be detrimental? Have you looked into samples that showed a particular pronounced discrepancy between the regularized and unregularized version of the model?\n\n**Minor comments:**\n\n1. Captions in Figure 1 are significantly too small and are illegible when printed.\n2. Lines 191-192 seem to reiterate previously discussed points (compare with lines 166-171) and appear to be an artifact from a previous version of the text.\n3. Consider incorporating Footnote 2 on Page 4 into the main text.\n4. Table 3 on Page 7 is never referenced in the text and reiterates results from Figure 1. Either one could be placed in the Appendix.\n5. Equations in Section 5.4 on lines 340-348 are not numbered.\n6. The abbreviation *SEM* is first used on line 190 but not introduced until line 262.\n7. The $\\tau$ used in the definition of the tolerance-aware sign function is never introduced in the text.\n8. Section 4.4 explains standard procedure. The text could be made more concise and clear by moving it to the Appendix."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ISpIQwZvOB", "forum": "wN4Tf9O9zL", "replyto": "wN4Tf9O9zL", "signatures": ["ICLR.cc/2026/Conference/Submission18819/Reviewer_WRij"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18819/Reviewer_WRij"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18819/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762098510382, "cdate": 1762098510382, "tmdate": 1762930446340, "mdate": 1762930446340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}