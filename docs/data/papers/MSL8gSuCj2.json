{"id": "MSL8gSuCj2", "number": 6319, "cdate": 1757967888712, "mdate": 1763101700597, "content": {"title": "Can Weak Quantization Make World Models Physically Interpretable?", "abstract": "Deep learning models are increasingly employed for perception, prediction, and control in autonomous systems. For achieving realistic and consistent outputs, it is crucial to embed physical knowledge into their learned representations. \n However, doing so is difficult due to high-dimensional observation data, such as images, particularly under conditions of incomplete system knowledge and imprecise state sensing. To address this, we propose  Physically Interpretable World Models, a novel architecture that aligns learned latent representations with real-world physical quantities. To this end, our architecture combines a physical interpretable image autoencoding model and a partially known learnable dynamical model. We conduct an in-depth analysis of the latent space, evaluating the effects of continuous versus discrete representations, as well as intrinsic versus extrinsic physical interpretable encodings. The training incorporates weak distributional supervision to eliminate the impractical reliance on ground-truth physical knowledge. Through three case studies, we demonstrate that our approach not only provides physical interpretability but also achieves state prediction accuracy superior to state-of-the-art models, thus advancing interpretable representation learning.", "tldr": "", "keywords": ["World Models", "Physically Interpretable Representation Learning", "Autoencoders"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/e481d8d8a42f7ea3d9316702c5ab9f597c39fbcb.pdf", "supplementary_material": "/attachment/8e3033a601ed32f588bff2c703d9ea240e64a588.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes PIWM, which learn physics-aligned latent spaces from images using only weak supervision. It combines a visual autoencoder with a physics-based dynamics model that learns unknown parameters like friction or mass. Two designs are tested, first intrinsic (joint learning) and then extrinsic (two-stage), with the extrinsic version proving more stable and interpretable. Experiments on simple control tasks show that PIWM can make physically consistent predictions without full state supervision."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- I liked the ablation study. it’s clear that authors test different design choices like intrinsic vs. extrinsic and continuous vs. discrete setups. It helps justify the final model design instead of just showing one result.\n\n- The paper is well written and easy to follow. Including the algorithms in the appendix was a good idea and it makes the training process easier to understand.\n\n- The paper provides the code along with instructions, which is a good move. It helps with reproducibility and is appreciated by the community.\n\n- It’s good that the physics loss is reported separately. It clearly shows whether the model is actually learning the physical part. The reconstruction visualizations are also helpful to confirm that both the visual and physical parts are trained properly."}, "weaknesses": {"value": "- The paper lacks an explicit probabilistic formulation of the overall generative model. Unlike typical probabilistic world models that define a full joint likelihood/generative process, and then deriving approximations (e.g., through an ELBO either in theory or clearly stating that). Please see for example  eq. (3) and (6) in PlaNet paper.\nIn your model you present individual training losses without connecting them to a unified evidence objective (which are somehow direct Monte-Carlo approximation of your dismantled ELBO terms).\n\n- The paper does not clearly explain the training of the controller $h$. It remains unclear whether the controller is pretrained, jointly optimized with the encoders, or learned during the dynamics phase. Since the controller’s outputs $a$ directly affect the prediction and dynamics learning, the lack of detail on its training stage and objective makes it hard to follow up.\n\n- The exps mainly focus on Markovian systems, where transitions depend only on the most recent state and action. As a result, it remains unclear how the proposed model behaves under non-Markovian, where temporal dependencies extend beyond one step. Evaluating the model on a system with delayed effects could be a good practice to show how it generalizes (or if you believe this is not feasible in the current shape of your work, mention it as a limitation)\n\n\n- All evaluated exps rely on single-mode, continuous dynamics, and the model does not appear to address systems with multiple discrete or hybrid modes.  The paper would benefit from either (i) an additional experiment demonstrating the model’s behavior under multi-modal dynamics (for example a bouncing ball in gravity room, or NASCAR style dataset with multiple mode switches) or (ii) a clear discussion of how the current one could be extended to handle such scenario."}, "questions": {"value": "Thank you for your work and all efforts. I have some questions about the paper:\n\n- You describes the extrinsic representation learning as a two-stage process, that the visual encoder is first trained and then frozen before training the physical encoder and the dynamics model. In your Algorithm 1, it appears to combine all losses including $rec, state, latent$ and $dyn$ into a single joint optimization step. Could the authors clarify whether the dynamics parameters $\\theta$ are trained separately using $\\mathcal{L}_{dyn}$ or whether all losses are optimized simultaneously?\n\n- Could you clarify whether your model can be expressed as a full probabilistic generative process (for example defining the joint likelihood of states, physical parameters, and observations)? In probabilistic world models, it is common to first formulate the complete generative objective and then describe which components are approximated (e.g., via an ELBO). \n\n\n- Could the authors clarify how the controller is trained or obtained? Specifically, is it optimized jointly with the visual encoder, trained in a separate stage (e.g., after freezing the recognition or physical autoencoders), or assumed to be a fixed policy learned beforehand (e.g., via imitation or reinforcement learning)? \n\n- The experiments appear to assume single-mode, continuous dynamics (like a smooth Newtonian motion without discrete transitions). How would the proposed PIWM framework behave in a multi-modal setting, where the system dynamics change across discrete modes (e.g. consider a bouncing ball in gravity room, when after each bounce the dynamics change completely)? Can the model infer or represent such mode switches within its latent structure, or would it require an explicit discrete latent variable (as in hybrid or HMM-style models)? If not, how could PIWM be extended to handle such cases?\n\n\n\n- The dynamics model is trained using short, three-step temporal windows in your algorithm 1, that assumes the functional form of \n$\\phi()$ is known. This design choice is fine for systems with simple-univariate analytical dynamics (e.g., low-dimensional control setups) but may not generalize when \n$\\phi()$ is partially unknown, highly nonlinear, multiple systems seen in the obs, or exhibits delayed dependencies (your states evolve non-Markovian style). Could you discus under what conditions this local identification strategy remains valid and how to extend it to more general cases? For example, through multi-step rollouts, or latent recurrent updates ? \nThen what computational costs such extensions would need?\n\n- In lines 862-863: Why do the latent dimensions drift from physical meaning under weak supervision? Is there any intuition for that? Is this because of under-constrained optimization, entanglement with visual features, or the absence of strong temporal or structural regularization?\n\n- In the results, the continuous latent variant performs better under the intrinsic (one-stage) setup, while the discrete variant performs better under the extrinsic (two-stage) setup. Why is that happening? Is it related to the way the physical codebook vectors are hardcoded or constrained in the intrinsic model that may affect generalization, or are there other factors?\n\n\n---\na few minor issues:\n\n- In line 823 (line 10 algorithm 1), you model your dynamics model parameterized by two previous time steps. In your gradient calculation  (lines 790-800) it is changed to a single time step variable though. Please make your notation consistent.\n\n- In eq (9), L_latent ..., no?\n\n- Please provide details of setting hyperparameters like learning rates, optimization setup, etc. Also please explain how did you come up with such setting. \n\n- Your graphical model is in a single time step. Why not in multiple time steps to visualize the evolution of your world more clearly?\n\n---\n\nI am eager to further strengthen my positive opinion about the paper, depending on the authors response to my queries.\n\n---"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EwWdfSQ6KI", "forum": "MSL8gSuCj2", "replyto": "MSL8gSuCj2", "signatures": ["ICLR.cc/2026/Conference/Submission6319/Reviewer_4jhJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6319/Reviewer_4jhJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660449796, "cdate": 1761660449796, "tmdate": 1762918614570, "mdate": 1762918614570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "9jQ71ljzFE", "forum": "MSL8gSuCj2", "replyto": "MSL8gSuCj2", "signatures": ["ICLR.cc/2026/Conference/Submission6319/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6319/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763101699736, "cdate": 1763101699736, "tmdate": 1763101699736, "mdate": 1763101699736, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper approaches trajectory prediction with physically interpretable latent dynamics models.\nContinuous and quantized autoencoders are compared as well as intrinsic (only one AE) and extrinsic approaches (two-staged AE).\nCorrespondence to physical quantities is enforced on the second AE in the extrinsic variant and on a part of the latent space in the intrinsic variant.\nThis is done by minimizing the L2 loss of the latent to noisy ground-truth state values.\nThe parameters for known dynamic equations are also learned.\nFor these approaches and several baselines, the prediction performance over different horizons is evaluated.\nFor the proposed models, also the error of predicted physical states and parameters are evaluated.\nThe results indicate that the quantized extrinsic variant made provide a good trade-off for the evaluated problems."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The evaluation of different encoding approaches into a physical latent state space is interesting.\n- The technical description is well written and easy to follow.\n- The introduction of the formal notation of the physics-informed world model approach reads well and could be useful as a reference for follow-up works in the world model learning domain."}, "weaknesses": {"value": "Major\n- The main issue of this paper is that it uses samples from a distribution p(x) of ground truth state x for training and denotes this a \"weak supervision\", while it is clearly standard strong supervision. The noise model is not described in detail. Several experiments are also performed with noise level 0, meaning that actual ground truth values are used for training. While this dependency of the performance wrt to noise levels is interesting, the paper is clearly overstating by claiming weak supervision. Please revise!\n\n- Dynamics model: It is not clear to me how the structured dynamics model works in detail.\n  For example, does it only propagate the physical state or also the the visual latent?\n  Also assuming knowledge of ground truth dynamics (with only missing parameters) is a very strong assumption.\n  The state is not Markov. Instead, the state derivatives seem to be computed explicitly by finite differences to propagate the state using the manually designed physics-based dynamics model. Why not include state derivatives in the model and let the encoder learn to predict them too? This would require a recurrent encoder or multiple frames as input though. Please comment.\n  Crucially, it seems, the latent state does not encode dynamical properties at all, but is learned statically as an AE, which is a severe limitation.\n\n- Baselines: The LSTM and Transformer baselines are missing crucial details regarding their architecture and training.\n  Most importantly, since prediction error is evaluated in state space, it is not clear how they process the observation input.\n  Also, given the partially known dynamics, this comparison seems unfair.\n  IMO it would be important to also compare to a trusted baseline, such as a Dreamer Model.\n  I do not understand the comparison to DVBF, SindyC, Vid2Para which seem far more general than the assumption on known dynamics structure made here.\n  Generally, I do not see the contribution of the dynamic model presented here.\n\n- DVBF seems to be quite off in the experiments. Does it learn something meaningful at all? Is it correctly used?\n\n- The approach should be compared with state-of-the-art world model approaches like PlaNet [*1] and follow-up variants in Dreamer.\n[*1]  Hafner et al., Learning Latent Dynamics for Planning from Pixels. ICML 2018.\n\n \n- Motivation/Application: If one makes the assumption of noisy ground truth states available, it is unclear why one would train for observation reconstruction at all.\n  This is much rather a regression task of predicting the state given a high-dimensional observation.\n  A controller can be directly trained on this prediction.\n  Therefore, it is not clear why the core challenge in this paper, the conflicting objectives of reconstruction and closeness to physical state, needs to exist.\n\n- Trained controllers: Access to well-trained controllers is assumed to collect training data, which defeats a major reason to have a world model in the first place, which is to train these controllers.\n\n\nMinor\n- Sec 1: Le et. al. 2025 and Mosbach et al., 2025 seem unrelated to this work\n- Papers introducing the used environments should be cited."}, "questions": {"value": "- See weaknesses.\n- It seems unplausible that the quantized model is better for prediction than the continuous one in a continuous environment.\n  A much deeper evaluation of this phenomenon is required as well as details about the environments (are they continuous?)\n  Also, why does this relation flip for the intrinsic variant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YwlZNbzef5", "forum": "MSL8gSuCj2", "replyto": "MSL8gSuCj2", "signatures": ["ICLR.cc/2026/Conference/Submission6319/Reviewer_LYWn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6319/Reviewer_LYWn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906709274, "cdate": 1761906709274, "tmdate": 1762918614130, "mdate": 1762918614130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents Physically Interpretable World Models where the main idea is to constraint the physical information in the latent space. Two ideas - intrinsic and extrinsic are presented to investigate the same."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem is interesting and the idea of constraining the latent space provides an interesting take"}, "weaknesses": {"value": "Despite the problem being interesting, I found the approach to be quite limiting. For example, \"physically interpretable\" has been considered in a very weak sense. Physical interpretable in truest sense means satisfying the governing physics.\n\nAlso, some physical parameters need not be identifiable from image. Example, imagine a box of same size and shape - one of steel other of wood. The material properties will be different; but its not identifiable from image. How will the approach fair in such scenario is not clear.\n\nPhysical parameters also have constraints. For example, elastic modulus is non negative. How will the architecture handle it is not clear.\n\nLastly, the example is quite simple. Will it be able to handle more complex phenomenon - say fluid flow in turbulence zone. A world model should be able to handle such scenarios."}, "questions": {"value": "The weaknesses are posed as questions. I will like ot hear on those during the interaction phase."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9DD6FLbPsM", "forum": "MSL8gSuCj2", "replyto": "MSL8gSuCj2", "signatures": ["ICLR.cc/2026/Conference/Submission6319/Reviewer_EUjS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6319/Reviewer_EUjS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979296421, "cdate": 1761979296421, "tmdate": 1762918613751, "mdate": 1762918613751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work focuses on the physical interpretation of enhancing autonomous image-based control. The key designs include 1) providing weak supervision for the world model to align the latent information of states with learnable physical dynamics, and 2) splitting the latent space into physical and visual parts for separate construction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem scope is made clear and motivating. The idea of aligning the world model's latent space with physics under weak supervision is easy to follow, as are the designed mechanisms on the physical/visual split and quantized physical grid"}, "weaknesses": {"value": "From Section 2.1, the method relies on known functional forms of dynamics (learn only parameters). This is reasonable for some benchmarks, but the governing dynamics can be incomplete for many practical cases. It's better to define and justify for which domains such forms are available in practice. Then, more importantly, what if the real system deviates from the assumed form, e.g., the real-world complexity is usually larger than traditionally modeled? How does the proposed method degrade due to the mismatch?\n\nThe latent space is split to define different losses. It needs clarification of the necessity of this split.\n\nWhile the proposed idea is clear, the two-part design is enforced via losses (soft constraints). Are there identifiability/consistency guarantees for recovering physical factors (with or without quantization)?\n\nIn tests, different noise levels are considered for robustness, which may not be sufficient to show the significance of physical interpretability. As the target problem is control based on observation of the dynamic system, is unobservability considered to assess the proposed model? Also, the generalizability to unseen scenarios is a good indicator to test whether the proposed “extrinsic + discrete” remains stable for physical system modeling and control."}, "questions": {"value": "Please see concerns and questions in Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fjntFsA3DE", "forum": "MSL8gSuCj2", "replyto": "MSL8gSuCj2", "signatures": ["ICLR.cc/2026/Conference/Submission6319/Reviewer_TU9t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6319/Reviewer_TU9t"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6319/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998806709, "cdate": 1761998806709, "tmdate": 1762918613345, "mdate": 1762918613345, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}