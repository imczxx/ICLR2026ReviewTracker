{"id": "wTGcb3DxOn", "number": 8270, "cdate": 1758077034485, "mdate": 1759897795214, "content": {"title": "LLM Pretraining with Continuous Concepts", "abstract": "Next token prediction has been the standard training objective used in large language model pretraining. Representations are learned as a result of optimizing for token-level perplexity. We propose Continuous Concept Mixing (CoCoMix), a novel pretraining framework that combines discrete next token prediction with continuous concepts. Specifically, CoCoMix predicts ``continuous concepts'' learned from a pretrained sparse autoencoder and mixes them into the model's hidden state by interleaving with token hidden representations. Through experiments on multiple benchmarks, including language modeling and downstream reasoning tasks, we show that CoCoMix is more sample efficient and consistently outperforms standard next token prediction and knowledge distillation. We find that combining both concept learning and interleaving in an end-to-end framework is critical to performance gains. Furthermore, CoCoMix enhances interpretability and steerability by allowing direct inspection and modification of the predicted concept, offering a transparent way to guide the model’s internal reasoning process.", "tldr": "", "keywords": ["Large Language Models", "Pretraining", "Concepts", "Sparse Autoencoders"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dafb9e62d0345160ced835ea947b59d4fce70b53.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper, the authors design a new method to improve the next-token prediction and final performance. Specifically, they design CoCoMix, a new pretraining framework for large language models that augments standard next-token prediction with an additional objective: predicting “continuous concepts” derived from a sparse autoencoder and injecting those concepts directly into the model’s hidden states, interleaved with normal token representations. It improves both sample efficiency and downstream performance on language modeling and reasoning tasks. Beyond accuracy, CoCoMix also makes models more interpretable and steerable, because the predicted concepts can be inspected and edited to transparently influence the model’s internal reasoning. The provided figures and examples make this paper easier to understand. Overall, the quality of this paper will be further improved after addressing concerns listed below."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The topic is highly interesting and might generate broad impact to the LLM community. \n\nI like the visualizations of figures, which are clear and improve the readability of this paper. The reviewer appreciates the authors for doing this.  \n\nIn experiments, the analysis is solid and comprehensive."}, "weaknesses": {"value": "[1 ] To be honest, after reading Figure 1 alone or combined with the text in the introduction, the reviewer is still confused about how the extracted concepts benefit the next token prediction. More explanations might be helpful. \n\n[2] During the target concept selection process, it the attribution conducted in each training batch? \n\n[3] Another question is about clarification, after the concept selection, why it is necessary to conduct concept prediction? \n\n[4] In experiments, the model sizes are relatively small. The reviewer understand this might be because the limited budget in model training. Could you discuss whether the findings in this paper could generalize to larger models? \n\n[5] It will be great to disclose the training costs, e.g., GPU numbers, types, GPU hours. \n\n[6] While there are performance gain, will it brought other costs like training time when applying COOMIX?\n\n[7] Sumamrizing the performance gain will improve this paper further. For example, in the abstract, intro, captions of Figure 2 and 3, it will be great to introduce the performance gain. \n\n[8] The steering example is interesting. COuld you introduce how do we know which concept is related to “website” or “money”? The transparency will improve the readability of this paper."}, "questions": {"value": "[1 ] To be honest, after reading Figure 1 alone or combined with the text in the introduction, the reviewer is still confused about how the extracted concepts benefit the next token prediction. More explanations might be helpful. \n\n[2] During the target concept selection process, it the attribution conducted in each training batch? \n\n[3] Another question is about clarification, after the concept selection, why it is necessary to conduct concept prediction? \n\n[4] In experiments, the model sizes are relatively small. The reviewer understand this might be because the limited budget in model training. Could you discuss whether the findings in this paper could generalize to larger models? \n\n[5] It will be great to disclose the training costs, e.g., GPU numbers, types, GPU hours. \n\n[6] While there are performance gain, will it brought other costs like training time when applying COOMIX?\n\n[7] Sumamrizing the performance gain will improve this paper further. For example, in the abstract, intro, captions of Figure 2 and 3, it will be great to introduce the performance gain. \n\n[8] The steering example is interesting. COuld you introduce how do we know which concept is related to “website” or “money”? The transparency will improve the readability of this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wNyftpWJhI", "forum": "wTGcb3DxOn", "replyto": "wTGcb3DxOn", "signatures": ["ICLR.cc/2026/Conference/Submission8270/Reviewer_LpV1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8270/Reviewer_LpV1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761780901578, "cdate": 1761780901578, "tmdate": 1762920207316, "mdate": 1762920207316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work includes a range of experiments that demonstrate the model’s performance across multiple dimensions, such as downstream accuracy, efficiency, and steerability. Overall, the experiments are clearly presented and thoughtfully discussed. The chosen baselines are relevant, though somewhat limited. The analysis of the CocoMix model’s effectiveness is generally solid and supported by clear results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The CoCoMix model is well described, and the method is easy to follow.\n\n2. The proposal of combining next token prediction with continuous concepts in the pretraining paradigm is novel. This idea of integrating an interpretability mechanism (concept) into pretraining frameworks through SAE comes with significant originality. Such pretraining innovations remain rare in the field, and the model's effectiveness suggests potential incremental impact.\n\n3. This work includes a range of experiments that demonstrate the model’s performance across multiple dimensions, such as downstream accuracy, efficiency, and steerability. Overall, the experiments are clearly presented, and the chosen baselines are relevant, though somewhat limited. The analysis of the CocoMix model’s effectiveness is generally solid."}, "weaknesses": {"value": "1. Concept Interpretability: This work has been based on the assumption that the latent representation layer in SAE corresponds to human-interpretable concepts. Since this is central to the interpretability claims, more content addressing this assumption would be helpful, beyond what is described in the steerability section. How exactly does CoCoMix capture real, continuous mixture of concepts?\n\n2. Model Design Justifications: Some architectural choices could be better justified if the authors add more explanations or ablation studies. For example, what's the significance of compressing top concepts into a \"continuous\" one, instead of focusing on the top concept?\n\n3. The authors claim that their improvement on downstream tasks shows that CocoMix is better than NTP (Figure 3), but these differences in performance are minimal at best, and I'm not sure if they're significant. Is it worth the overhead?"}, "questions": {"value": "1. Figure 2 PPL scores -- are they computed using NTP objective for both models, or using NTP for the NTP baseline and the CocoMix PPL for the proposed method? If it's the latter, these scores are not really comparable...\n2. For reproducibility reasons, I suggest the authors provide a link to their repo containing the code for the implemented methods and the experiments.\n3. Does CoCoMix scale to larger LLMs?\n4. Are the differences reported in the paper statistically significant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eq2Go4qepp", "forum": "wTGcb3DxOn", "replyto": "wTGcb3DxOn", "signatures": ["ICLR.cc/2026/Conference/Submission8270/Reviewer_XEZ8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8270/Reviewer_XEZ8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862439870, "cdate": 1761862439870, "tmdate": 1762920206923, "mdate": 1762920206923, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a new pre-training paradigm based on \"continuous concepts\".\n\nSpecifically, the authors introduce an additional prediction head in a \"standard\" (transformer) LLM to produce continuous tokens based on \"concepts\". In order to train this additional prediction head the authors propose an additional training objective based on Sparse AutoEncoders (SAEs) and importance attribution using gradients.\n\nThe authors then validate their approach across various model sizes and baselines."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The main strenghts of the paper:\n1. Great pre-training analysis with a novel architecture.\n2. A working pre-training recipe that seems to improve performance\n3. A way of introducing steerable concepts into the models generation. This can open the door to a lot of interesting research."}, "weaknesses": {"value": "Main weaknesses:\n1. Model sizes are limited (but understandable).\n2. Hyper-parameter tuning was not discussed in detail and perhaps some of the scores can be attributed to poor hyper-params."}, "questions": {"value": "Q1: How can you make sure your results are not attributed to randomness in hyper-param tuning? Can you demonstrate anything to this effect?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aPtp6SCjQ4", "forum": "wTGcb3DxOn", "replyto": "wTGcb3DxOn", "signatures": ["ICLR.cc/2026/Conference/Submission8270/Reviewer_SsAp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8270/Reviewer_SsAp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762143806627, "cdate": 1762143806627, "tmdate": 1762920206357, "mdate": 1762920206357, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}