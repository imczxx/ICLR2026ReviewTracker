{"id": "gCUY6QIv8r", "number": 14463, "cdate": 1758236434602, "mdate": 1759897368500, "content": {"title": "CONCUR: A Framework for Continual Constrained and Unconstrained Routing", "abstract": "AI tasks differ in complexity and are best addressed with different computation strategies (e.g., combinations of models and decoding methods). Hence, an effective routing system that maps tasks to the appropriate strategies is crucial.\nMost prior methods build the routing framework by training a *single* model across *all* strategies, which demands full retraining whenever new strategies appear and leads to high overhead. Attempts at such continual routing, however, often face difficulties with generalization.\nPrior models also typically use a *single* input representation, limiting their ability to capture the full complexity of the routing problem and leading to sub-optimal routing decisions.\nTo address these gaps, we propose CONCUR, a **con**tinual routing framework that supports both **c**onstrained and **u**nconstrained **r**outing (i.e., routing with or without a budget).\nOur *modular* design trains a separate predictor model for each strategy, enabling seamless incorporation of new strategies with low additional training cost.\nOur predictors also leverage *multiple* representations of both tasks and computation strategies to better capture overall problem complexity.\nExperiments on both in-distribution and out-of-distribution, knowledge- and reasoning-intensive tasks show that our method outperforms the best single strategy and strong existing routing techniques with higher end-to-end accuracy and lower inference cost in both continual and non-continual settings, while also reducing training cost in the continual setting.", "tldr": "", "keywords": ["model routing", "continual routing", "constrained routing", "unconstrained routing"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/13f60aaf55c1d3b8c000841ca11e7245897bbaf6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces CONCUR, a modular framework for continual task routing among diverse computation strategies, addressing the challenge of efficiently mapping AI tasks to optimal computational configurations under both constrained (budget-aware) and unconstrained conditions. Unlike traditional monolithic routing approaches that require retraining a single model whenever new strategies are added, CONCUR proposes a modular design in which each computation strategy has its own predictor model estimating its accuracy and cost on a given task. These predictors rely on both general-purpose and task-specific representations, improving the granularity and flexibility of routing decisions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The modular predictor design allows new strategies to be added by training only their respective predictors, greatly reducing retraining cost and time compared to monolithic routers.\n2. Combines general-purpose embeddings (from pretrained encoders) with learnable task- and strategy-specific representations, demonstrating superior expressiveness over single-representation baselines.\n3. Comprehensive evaluation and analysis."}, "weaknesses": {"value": "1. While modularity is beneficial, training two predictors (accuracy + cost) per strategy may become cumbersome when the number of strategies grows very large.\n2. The paper lacks a deeper theoretical justification for why modular predictors generalize better than joint models and the optimization formulations are straightforward but not novel in theory.\n3. The predictors act as black boxes; it remains unclear how they capture task–strategy interactions or why they perform well in OOD tasks."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9Qy7RA0WxN", "forum": "gCUY6QIv8r", "replyto": "gCUY6QIv8r", "signatures": ["ICLR.cc/2026/Conference/Submission14463/Reviewer_DE3V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14463/Reviewer_DE3V"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760584259431, "cdate": 1760584259431, "tmdate": 1762924866268, "mdate": 1762924866268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a unified framework for routing among multiple LLMs and decoding strategies under both continual and non-continual settings. The main idea is to train modular predictors that estimate, for each model–decoding pair, its expected accuracy and computational cost on a given task. These predictors combine general text embeddings (from an off-the-shelf embedding model) with task-specific representations to capture both semantic and domain-specific information. Routing decisions are then formulated as an optimization problem that can be solved efficiently. Experimental results show that the proposed framework outperforms existing baselines in terms of both accuracy and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper addresses an important and practical problem. Effectively routing among multiple LLMs and decoding strategies under varying cost and performance constraints has become an increasingly relevant and widely discussed topic. This topic is relevant to the growing need for efficient deployment of large reasoning models, especially in settings where computational budgets and task distributions evolve over time. The formulation of both continual and non-continual routing scenarios adds further practical value to the work.\n\n- The proposed framework demonstrates consistent improvements over existing routing baselines across several reasoning and question-answering benchmarks. The experimental results suggest that the modular predictor design and optimization-based decision process lead to better accuracy–efficiency trade-offs, validating the effectiveness of the proposed approach in diverse routing settings."}, "weaknesses": {"value": "- Although the paper repeatedly discusses routing in both continual and non-continual settings, the problem itself is never formally defined. It remains unclear what exactly constitutes a routing input and output, and how the optimization objective is formulated in mathematical terms. The framework is presented primarily at a conceptual level, which makes it difficult to precisely understand the problem scope and to reproduce the approach in other contexts. As a result, the paper may not be self-contained for readers who are not already familiar with prior routing works such as RouteLLM or RTR, which substantially limits accessibility and clarity.\n\n- The overall framework follows a structure that is already common in related areas such as task planning and model selection. The paper mainly adapts existing ideas to the LLM routing setting, without introducing a fundamentally new algorithmic or theoretical insight. \n\n- The paper lacks a systematic ablation study quantifying the contribution of each component in the proposed framework. Is there any ablation study or experimental analysis addressing this? For example, how would the performance change if only the general-purpose representation or the task-specific representation were used?"}, "questions": {"value": "See the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CBGEtBOL6F", "forum": "gCUY6QIv8r", "replyto": "gCUY6QIv8r", "signatures": ["ICLR.cc/2026/Conference/Submission14463/Reviewer_dMBg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14463/Reviewer_dMBg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725804412, "cdate": 1761725804412, "tmdate": 1762924865611, "mdate": 1762924865611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CONCUR, a continual routing framework designed to address limitations in existing AI task routing systems, supporting both constrained (with cost budget) and unconstrained (no budget) routing scenarios. CONCUR outperforms baselines in both unconstrained and constrained routing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe modular predictor design directly solves the retraining overhead issue of existing methods. Integrating new strategies with minimal cost aligns with real-world needs (e.g., frequent updates of language models), making it highly scalable.\n\n2.\tBy combining general-purpose and task-specific representations, CONCUR captures both universal patterns (via general embeddings) and task/strategy-specific nuances (via learnable representations), which is empirically shown to improve routing decisions (e.g., higher accuracy on out-of-distribution tasks).\n\n3.\tSupporting both constrained and unconstrained scenarios broadens its applicability—unconstrained for use cases prioritizing performance balance, and constrained for resource-limited environments (e.g., edge devices with tight FLOP budgets).\n\n4.\tThe study uses diverse datasets (covering different task types and distribution shifts), standardized metrics (accuracy + FLOPs), and comparisons to strong baselines, ensuring the validity and generalizability of results."}, "weaknesses": {"value": "1.\tThe general-purpose representation relies on a frozen pre-trained embedding model (ALL-MPNET-BASE-v2). The paper does not evaluate how changes to this model (e.g., using a smaller/larger embedding model) affect predictor performance, raising concerns about its robustness to embedding choice.\n2.\tThe unconstrained routing uses a weight to balance accuracy and cost, but the paper does not analyze how different weight values (e.g., weight=0.1 for cost prioritization vs. weight=0.9 for accuracy prioritization) impact real-world utility, nor does it provide guidance on choosing this weight for specific use cases."}, "questions": {"value": "1.\tHow does replacing the ALL-MPNET-BASE-v2 model with other embedding models affect the accuracy and cost prediction of CONCUR? Is there a minimum embedding quality required for the framework to perform well?\n\n2.\tWhen integrating a completely new strategy with no historical task data (cold start), how does CONCUR perform? Do you have any initialization methods (e.g., transferring knowledge from similar strategies) to improve the cold-start prediction accuracy of new predictors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vch7fItjjO", "forum": "gCUY6QIv8r", "replyto": "gCUY6QIv8r", "signatures": ["ICLR.cc/2026/Conference/Submission14463/Reviewer_NPzC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14463/Reviewer_NPzC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892969902, "cdate": 1761892969902, "tmdate": 1762924864818, "mdate": 1762924864818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a routing method to choose the best model, maximizing efficiency and accuracy, for a continual learning setup, where the task based routing predictor can be updated to include new model variations (strategies) on the fly."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses a timely problem of efficiently routing between a growing variety of models to solve a task with maximum accuracy and efficiency (measured in FLOPs).\n2. The proposed method of learning a model specific predictor without retraining the strategy prediction backbone makes routing to new models seamless as also verified by the experiments in the paper."}, "weaknesses": {"value": "1. The authors use FLOPs to measure and learn the efficiency while choosing between models. Are the FLOPs measured by counting the number of multiply-add operations? If that is the case, the proposed method will not capture the efficiency achieved by quantized models, which can be much more efficient and still achieve similar accuracies (most models are now released with lightweight quantized version).\n2. It is unclear to me, how the base strategy predictor performs when the number of input strategies increase, i.e, what is the expressivity of this predictor and does it overfit to initial learnt strategies? \n3. Maybe this is a more high level question, but how would routing work in the case where the questions (tasks) are open ended and there does not exist a right answer to measure accuracy?"}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "79JpEJgCew", "forum": "gCUY6QIv8r", "replyto": "gCUY6QIv8r", "signatures": ["ICLR.cc/2026/Conference/Submission14463/Reviewer_d5bV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14463/Reviewer_d5bV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948607256, "cdate": 1761948607256, "tmdate": 1762924863577, "mdate": 1762924863577, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}