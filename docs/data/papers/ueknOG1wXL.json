{"id": "ueknOG1wXL", "number": 9504, "cdate": 1758125288829, "mdate": 1763610358814, "content": {"title": "Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment", "abstract": "The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability.\nIn this work, we propose a resource-efficient method for improving multilingual safety alignment. \nWe introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. \nBy improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.", "tldr": "We propose a multilingual consistency loss that can be plugged into existing alignment pipelines to improve multilingual safety of LLMs efficiently.", "keywords": ["Multilingual Enhancement", "Large Language Models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fed6d197644242e2e523092f64a1f78abc21d809.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a plug-and-play Multilingual Consistency (MLC) loss to make safety alignment transfer across languages without collecting response-level labels in every language. During alignment, the trainer feeds translated versions of the same prompt through the model, builds a small matrix of their internal representations and adds an auxiliary loss that pushes those representations to be rank-1 and that pushes their hidden representations toward dominant singular direction. The intuition is if the model interprets what safe looks like similarly in all languages at the hidden-state level, then a single-language alignment, usually English will lift safety everywhere. The loss is implemented via a temperature-softmax over the singular values of the representation matrix, encouraging the top singular value to dominate. The goal is to close the gap in safety where multilingual safety often lags far behind English."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The rank-1 and softmax-over-singular-values objective is a clean way to apply make language variants point the same way and can be easily integrated into standard pipelines. It is differentiable, easy to bolt on, and doesn't interfere with the main alignment loss. \n\n- No need for response-level labels in low resource languages, prompt translations are sufficient.\n\n- The method generalizes to unseen languages in MultiJail, supporting the claim that it regularizes a language-agnostic safety direction rather than overfitting to particular languages."}, "weaknesses": {"value": "- The paper does not clearly surface which layer the representations are extracted from or how the extractor is designed. Also, the main text does not show a quick sensitivity table or plot to convey how these choices affect results.\n\n- The connections between the spectral objective, its softmax relaxation over singular values and the final training loss are not well traced in the main part and that makes it hard for readers to follow the derivation without repeatedly jumping to the appendix.\n\n- The utility evaluation is summarized briefly and the paper does not give practical guidance on how to tune the auxiliary-loss weight or temperature to manage trade-offs between safety gains and general multilingual capability."}, "questions": {"value": "- Can you give reference to the MMMLU-lite dataset? What is that dataset? \n\n- How should practitioners tune the auxiliary-loss weight and temperature to balance safety gains against utility?\n\n- What happens when translations are imperfect such as noisy or partially wrong? Can you weight pairs by MT quality or be robust to mismatches?\n\n- Does the layer choice interact with backbone architecture?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "87zv0YTO8F", "forum": "ueknOG1wXL", "replyto": "ueknOG1wXL", "signatures": ["ICLR.cc/2026/Conference/Submission9504/Reviewer_4TKF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9504/Reviewer_4TKF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761771943551, "cdate": 1761771943551, "tmdate": 1762921078726, "mdate": 1762921078726, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a plug-and-play Multilingual Consistency loss to improve alignment across language representation and to transfer safety capabilities of LLMs from high-resource to low-resource languages. This auxiliary loss promotes consistency across languages by pushing the model to produce similar internal activations of queries written in different languages. The loss can also be integrated into various safety alignment paradigms, such as SFT and DPO. The results demonstrate improved safety performance across languages, notably closing the gap between high- and low-resource languages and largely preserves the general multilingual capability of the model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The objective is intuitive, effective and does not rely on any anchor languages.\n2. The auxiliary loss objective can be generalized and integrated to any post-training safety paradigms.\n3. The approach improves substantially safety performance of low-resource languages, while retaining that of high-resource languages."}, "weaknesses": {"value": "1. The approach is potentially sensitive to hyperparameters such as layer selection. The best layer where representation alignment is most effective also seems task sepcific.\n2. Scaling behavior of the objective is not tested beyond 7B. Divergence across languages may be beneficial for even larger models, where the consistency objective may not be effective."}, "questions": {"value": "1. Would the method be effective too for larger models, e.g., Qwen 14B / 32B?\n2. Beyond safety applications, can the method be used to reduce low- and high-resource language gaps exist for other multilingual capabilities? \n3. Could the method be harmful when handling culturally sensitive tasks? What about the possibility of altering cultural-specific knowledge in the model, which might be encoded in language-specific representation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "noOC93wmnU", "forum": "ueknOG1wXL", "replyto": "ueknOG1wXL", "signatures": ["ICLR.cc/2026/Conference/Submission9504/Reviewer_4nM1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9504/Reviewer_4nM1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977849135, "cdate": 1761977849135, "tmdate": 1762921077129, "mdate": 1762921077129, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a resource-efficient method to improve multilingual safety alignment in LLMs. The core contribution is a Multi-Lingual Consistency (MLC) loss, which enforces representational collinearity among semantically equivalent prompts across languages. The method aligns multilingual internal representations toward a shared semantic direction, improving safety consistency without requiring response-level supervision in low-resource languages.\n\nExperiments on Qwen and Gemma models demonstrate substantial improvements in safety rates, especially for low-resource languages, while maintaining general capabilities. The approach is presented as plug-and-play, compatible with existing alignment paradigms such as DPO and SFT, and efficient in data usage."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation: Addresses a real and underexplored challenge: multilingual imbalance in LLM safety alignment.\n\n- Conceptual simplicity: The MLC loss is an elegant addition that can integrate easily with existing pipelines.\n\n- Empirical breadth: Includes multiple backbones (Qwen, Gemma), alignment paradigms (DPO, SFT, SimPO, ORPO), and both in- and out-of-distribution tests.\n\n- Data efficiency: Claims strong multilingual gains with minimal additional data (∼1.8M tokens vs. 15M+ for comparable baselines).\n\n- Consistency analyses: Representation-space visualizations (Gram matrices) and PAG metrics provide insightful evidence of improved cross-lingual alignment."}, "weaknesses": {"value": "- Incremental contribution: The MLC loss is essentially a regularization of multilingual representations, conceptually simple and not a fundamentally new paradigm.\n\n- Theoretical shallowness:  Despite heavy mathematical framing (singular value decomposition, spectral view), the theoretical section adds little genuine insight beyond enforcing collinearity.\n\n-  Experimental bias: Evaluations rely on safety datasets constructed in English, potentially conflating multilingual improvement with translation artifacts rather than genuine alignment."}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vOaIbzFbDD", "forum": "ueknOG1wXL", "replyto": "ueknOG1wXL", "signatures": ["ICLR.cc/2026/Conference/Submission9504/Reviewer_94Ju"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9504/Reviewer_94Ju"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000717642, "cdate": 1762000717642, "tmdate": 1762921076899, "mdate": 1762921076899, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the challenge of multilingual safety alignment in large language models (ensuring models refuse harmful prompts consistently across languages). The authors propose a Multilingual Consistency (MLC) loss that complements existing post-training methods such as SFT or DPO. The loss encourages shared multilingual representations by promoting collinearity across query embeddings in different languages. Specifically, for each multilingual query set, the hidden representation of the last token in each language is linearly projected, normalized, and stacked into a matrix. The method minimizes the distance of this matrix from its best rank-1 approximation, derived via its top singular value, effectively enforcing a shared semantic direction.\n\nThe approach does not require multilingual responses, only crosslingual prompts, making it resource-efficient. Experiments on two safety benchmarks (PKU-SafeRLHF and MultiJail) across ten languages show substantial improvements in multilingual safety consistency, especially for low-resource languages, while maintaining general capabilities on MMLU."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Important problem:** The paper addresses the problem of ensuring safe and consistent behavior across languages in LLMs.\n- **Conceptually elegant and technically sound:** The proposed spectral regularization via rank-1 optimization is simple yet well motivated and theoretically grounded.\n- **Strong empirical results:** Comprehensive evaluations across datasets, languages, and base alignment paradigms demonstrate consistent gains, especially for low-resource settings.\n- **Practical and efficient:** The method is plug-and-play, adds minimal computational cost, and does not require multilingual response data."}, "weaknesses": {"value": "- **Weak related work discussion:** The discussion of multilingual alignment baselines (e.g., MPO, SDRRL) is both incomplete and difficult to follow. The main paper only names them without explanation, forcing readers to consult the appendix, which is itself hard to follow. As a result, it is difficult to understand how these baselines differ conceptually or why they are appropriate points of comparison.\n- **Limited baselines:** The paper lacks an upper-bound comparison, e.g., training with fully translated safety data across languages, to contextualize achievable performance ceilings.\n- **Evaluation of general capabilities is narrow:** The use of MMLU alone (amultiple-choice benchmark) provides a limited view of cross-lingual reasoning and generation quality. More generative evaluations could clarify whether safety alignment affects multilingual fluency or reasoning.\n- **Missing ablation studies:** The paper would benefit from ablations isolating the contribution of (i) the linear projection, (ii) the choice of singular-value-based regularization versus alternatives such as cosine similarity, and (iii) the temperature parameter τ."}, "questions": {"value": "- **Linear projection:** Is the linear extractor $W$ trained jointly with the model? Please clarify in Section 3.2.\n- **Baselines:** Briefly summarize how MPO and SDRRL operate in the main paper, this would make the comparison more self-contained.\n- **Ablations:** Could you provide results using alternative similarity measures (e.g., cosine loss) or removing the linear projection to test sensitivity?\n- **Capability evaluation:** MMLU is a multiple-choice benchmark and thus does not assess generation abilities or language control. I suggest adding a CoT-style evaluation where the model must generate reasoning in the target language. This would allow you to measure both accuracy and linguistic consistency (e.g., avoiding language mixing), providing a more complete picture of whether the proposed training preserves generative behavior across languages."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sncmUvr8b3", "forum": "ueknOG1wXL", "replyto": "ueknOG1wXL", "signatures": ["ICLR.cc/2026/Conference/Submission9504/Reviewer_xbQU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9504/Reviewer_xbQU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762115002481, "cdate": 1762115002481, "tmdate": 1762921076671, "mdate": 1762921076671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}