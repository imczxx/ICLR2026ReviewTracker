{"id": "rGnzZe10fq", "number": 23220, "cdate": 1758340960303, "mdate": 1759896825851, "content": {"title": "Adapting and Explaining Time Series Foundation Models with Concepts", "abstract": "Foundation models for time series have achieved impressive performance on high-dimensional temporal data, but their opacity remains a barrier to adoption in domains where transparency and trust are essential. While Concept Activation Vectors (CAVs) have proven effective for aligning model predictions with human-understandable concepts in vision, their application to temporal data is largely unexplored due to the complexity of sequential dynamics and the challenge of defining meaningful temporal concepts.\nIn this work, we propose COFT, the first framework that adapts CAVs to foundation models for time series. COFT  discovers dataset-specific temporal concepts through shapelet-based transformations and organizes them into a concept bank, enabling alignment between temporal subsequences and class labels. To integrate these concepts efficiently, COFT employs Low-Rank Adaptation (LoRA), allowing foundation models to internalize temporal concepts without sacrificing scalability or efficiency. Our experiments on diverse real-world benchmarks demonstrate that COFT not only improves interpretability quantified through concept alignment and CAV-based metrics, but also enhances predictive performance compared to state-of-the-art foundation models. Beyond accuracy, COFT provides a mechanism for human-centered explanations by linking model decisions to temporally meaningful concepts, offering practitioners new tools for diagnosis, trust, and refinement. Our work establishes a foundation for concept-based interpretability in time series modeling, bridging the gap between predictive power and human understanding.", "tldr": "COFT makes time-series foundation models interpretable by adapting Concept Activation Vectors, boosting both trust and accuracy", "keywords": ["Time Series", "Explainability", "Foundation Models"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c20425e421e33f9fd8d6c2cb306c5ed2aa93c836.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes COFT, a framework to adapt Concept Activation Vectors (CAVs) for time series foundation models by discovering and organizing temporal concepts through shapelet-based transformations. COFT applies Low-Rank Adaptation (LoRA) for efficient integration of concepts in models during fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n- The proposed method is novel and potentially impactful to improve model accuracy and interpretability\n- The paper includes both zero-shot and fine-tuned baselines for several models. The inclusion of tine-tuning baselines without COFT is valuable.\n- The proposed method achieves better accuracy than the compared baselines.\n- he authors use specific healthcare examples and patterns to motivate and contextualize their work."}, "weaknesses": {"value": "Weaknesses:\n- Limited baseline architectures. The baselines include only one time series foundation model (Chronos), despite the paper’s focus on embedding concepts in time series foundation models. This theme is explicitly highlighted in the title. Although Moment is frequently discussed in the text, it is not included in the empirical evaluation. Given that Moment is trained on the UCR/UEA classification archive (train set), its inclusion would be relevant.\n- Lack of representative baselines. The chosen baselines, a vanilla fully connected network (FCN) and a vanilla Transformer, are not the most competitive models commonly used with time series. Including additional baselines such as CNN-based models or patch-based tokenization Transformers (e.g., PatchTST) would better situate this work within the context of actively used models in practice.\n- No comparison with non–deep learning methods. Important classical baselines such as majority class prediction, random forecast, or XGBoost are not included. These comparisons would provide a clearer understanding of the relative gains from the proposed approach.\n- Limited evaluation data. The evaluation appears to rely primarily on the general UCR database. Considering additional classification benchmarks would strengthen the empirical analysis.\n- Lack of error measures. Figure 7 does not report variability (e.g., standard deviation or confidence intervals). Repeating experiments with multiple random seeds would help assess the robustness and variance of model performance.\n\nOther Comments:\n- Developing an open-source concept bank derived from real-world time series (excluding TSFM benchmark/test datasets) would be highly valuable and could provide a readily available resource for fine-tuning open-source TSFMs.\n- Line 294: The figure caption formatting appears inconsistent with the main text. It should be properly spaced from the surrounding paragraphs.\n- Extending the concept framework beyond medical data to domains such as finance could be compelling. For example, “flag” patterns are often used as indicators in financial time series.\n- Including a summary table listing each dataset’s name, domain, and the specific patterns (or subset of examples) extracted would improve clarity. Broadening the scope to include additional domains such as finance and energy would also enhance the paper’s impact."}, "questions": {"value": "Questions:\n- Lines 256–257: “A random forest classifier is trained on these features, and its classification accuracy provides a quantitative quality measure. This score is used to filter and retain only the most representative concepts.” How exactly is this score used for filtering? Is there a specific threshold applied to determine which concepts are retained?\n- Are the concepts extracted exclusively from the training sets of the datasets, or from external datasets? This distinction is important—concepts should not be extracted from the test sets used for evaluation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gMWiZE0N7m", "forum": "rGnzZe10fq", "replyto": "rGnzZe10fq", "signatures": ["ICLR.cc/2026/Conference/Submission23220/Reviewer_ryLn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23220/Reviewer_ryLn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760978437330, "cdate": 1760978437330, "tmdate": 1762942565704, "mdate": 1762942565704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduced COFT, the use of CAV (concept activation vectors) to explain time series. The \"concepts\" in the time series are in the form of shapelets, and it is used to explain a prediction in the time series. The authors also showed that these concepts can be used to improve the original model as well."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Using concepts or shapelets to explain time series is a good way to explain time series.\n- Apart from various minor problems in presentation, the paper is relatively easy to follow."}, "weaknesses": {"value": "- The focus of this paper is not clear. It seems that the author is aiming for using TCAV to explain or interpret a time series. But mainly it was focussing on the LoRA to improve the model instead. If the model can be improved, the explanation may change as well.\n- The experiments section are lacking. To few experiments were tested on the explainability side. The explainability experiments (fig5 and 6) are not convincing as well (as pointed in the \"questions\" section below.)\n- Some choices in the method section are not justified, or at least explained.\n- There are minor presentation problems (highlighted in the Questions below)"}, "questions": {"value": "- Citations needs to be updated in various paper throughout the paper. For example Line 268 (...LowRank Adaptation Hu et al. (2021) => LowRank Adaptation (Hu et al. 2021)). I believe it is the difference between \\citet and \\citep maybe?)\n- The ordering in section 3 is confusing. \n  - In the paragraph \"Time Series Concept Bank\", the \"distance based feature transformation\" is described along with the \"quality metric\". This is confusing for the reader as nothing here is explained. However, this algorithm is described in Section 3.2.1. So I think Section 3.2.1 should be moved earlier, within the \"Time Series Concept Bank\" paragraph. \n  - For equation 2, $\\phi$ is the \"convolution-based distance transformation\". In which I assume the formula is similar to equation 3? Can we put equation 3 (or similar) in the place near equation 2 for clarity?\n\n- Are there justification for using \"real\" convolutions (as in equation 3) rather than the cross-correlations (as in convolution neural networks)? It seems to me that for detecting patterns, using the cross-correlations makes more sense. \n\n- Are there justification on using a random forest model rather than other models? I suppose that the random forest model only splits on coordinate axis. So the convolution at each time point are treated separately?\n\n- Equation 1. Can you explain Equation 1? I think that we want to find $v_P$ that its direction derivative of \"f\" (abuse of notation as \"f\" here is from the representation space to the output) is maximized. Thus we want $v\\cdot\\nabla_h f(x_i)$ to be maximize if $y_i = +1$. Thus it should be argmax instead of argmin? It also does not make sense for the \"1\" to be in front. This is to compared with equation 9. that \"1\" is the indicator function. Here $y_i\\cdot (\\nabla_h f(x_i)\\cdot v)$ is not a boolean. Thus there should be no indicator function in equation 1.\n\n- Line after equation 4. I believe there is some formatting error on \"[t, t+ell]\". \n\n- Equation 4. Is there a description of Dynamic Time Warping (DTW)? Preferrably a formula?\n\n- For synthetic training example, do we need to account for OOD? Are s_t and x_t on the same scale? \n\n- For SDC and SSC (Fig 5 and 6), how does \"removing a concept\" work? Is it subtracting the latent representation with the concept vector? Are there any scaling involved? Also how does \"including a concept\" work? Is it just adding that concept vector to the latent representation?\n\n- If no concepts are included, why is the accuracy zero in Fig 5? If it is not a binary classification, how many total classes are there? And how does F1/Precision/Recall work - is it averaging across classes?\n\n- A better discovery would be comparing using \"concepts\" as explanations vs using \"features\" or \"observations\" as explanations, and compute there smallest sufficient (destroying) feature set vs smallest sufficient (destroying) concepts. This can motivate why we aim to use \"concepts\" as explainability.\n\n- Just to check. Is equation 9 only used in section 4.4.3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "na"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N7m1We3dLb", "forum": "rGnzZe10fq", "replyto": "rGnzZe10fq", "signatures": ["ICLR.cc/2026/Conference/Submission23220/Reviewer_a8i3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23220/Reviewer_a8i3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761675162184, "cdate": 1761675162184, "tmdate": 1762942565263, "mdate": 1762942565263, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical problem of opacity in time series foundation models, which limits their adoption in high-stakes domains like healthcare. The authors propose COFT (Concepts for Foundation Time series models), the first framework to adapt concept-based explainability, specifically Concept Activation Vectors (CAVs), to temporal data. COFT operates in three stages: 1) It automatically discovers high-quality, dataset-specific temporal concepts using shapelet-based transformations and organizes them into a \"concept bank\". 2) It adapts CAVs to quantify the foundation model's sensitivity to these temporal concepts. 3) It integrates these learned concepts directly into the model via a novel, concept-guided, parameter-efficient fine-tuning (PEFT) process using Low-Rank Adaptation (LoRA). Experiments on UCR benchmarks and a compelling EEG case study show that COFT achieves a significant dual benefit: it not only provides transparent, concept-level explanations but also consistently improves predictive accuracy over zero-shot and standard fine-tuning baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles a major, practical barrier to the adoption of powerful time series models: their lack of interpretability. It is, to my knowledge, the first work to successfully bridge concept-based explanations with time series foundation models and parameter-efficient fine-tuning.\n\nThe most compelling contribution is that COFT avoids the typical accuracy-interpretability trade-off. By explicitly teaching the model to recognize meaningful temporal patterns, the framework simultaneously improves predictive performance and enhances interpretability.\n\nThe EEG sleep dataset case study is a highlight. It demonstrates COFT's ability to build a concept bank of clinically salient patterns and shows that the fine-tuned Chronos-COFT model learns to assign higher importance to these patterns, effectively aligning the model's internal reasoning with that of a clinical expert."}, "weaknesses": {"value": "The paper equates \"concepts\" with \"maximally class-representative temporal subsequences\". While these are interpretable and discriminative, they are not guaranteed to align with human-defined semantic concepts. The framework finds what is predictive for a class, which may or may not be the same as what a domain expert finds meaningful. This nuance could be discussed more.\n\nThe concept-based fine-tuning process relies on data augmentation via perturbation. The ablation study in Figure 4 shows that this is a highly sensitive component: the \"Preserve\" strategy leads to a catastrophic drop in accuracy, while \"Mixing\" works very well. This suggests the method of augmentation is a critical hyperparameter, but the paper does not deeply explore the sensitivity to its parameters.\n\nThe concept bank is built using the Random Shapelet Transform. While the paper's ablation shows RST is efficient for the UCR datasets, the scalability of this discovery process to the massive, high-dimensional, and extremely long time series datasets that foundation models are often applied to is not fully explored."}, "questions": {"value": "Listed in weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SNwAN4UI2P", "forum": "rGnzZe10fq", "replyto": "rGnzZe10fq", "signatures": ["ICLR.cc/2026/Conference/Submission23220/Reviewer_U5hM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23220/Reviewer_U5hM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761711567403, "cdate": 1761711567403, "tmdate": 1762942563989, "mdate": 1762942563989, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The authors propose COFT (Concepts of Foundation Time series models) for incorporating temporal concepts and context into fine-tuning time series foundation models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The authors correctly identify the gap in incorporating time series specific nuances into the present fine-tuning paradigm, and propose novel framework drawing inspiration from the counterparts in computer vision."}, "weaknesses": {"value": "- The paper could improve vastly, by expanding on the datasets and baselines used for comparison in the work.\n- The evaluation is mostly focused on univariate time series classification, and could expand to multi-variate signals too.\n- Key implementation details are missing to support reproducibility. Learning rate, optimizers, which variant of Chronos, etc."}, "questions": {"value": "- Because the learning is actively seeking to incorporate dataset specificities, do the authors believe this would impact the model's generalizability capabilities? If yes, how to mitigate, if no then why?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yzQ9ECP940", "forum": "rGnzZe10fq", "replyto": "rGnzZe10fq", "signatures": ["ICLR.cc/2026/Conference/Submission23220/Reviewer_jSuK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23220/Reviewer_jSuK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940854926, "cdate": 1761940854926, "tmdate": 1762942563331, "mdate": 1762942563331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}