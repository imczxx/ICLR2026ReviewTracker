{"id": "XsEZcigEjq", "number": 21313, "cdate": 1758316167103, "mdate": 1759896928976, "content": {"title": "Hessian-Enhanced Token Attribution (HETA): Interpreting Autoregressive LLMs", "abstract": "Attribution methods seek to explain language model predictions by quantifying the contribution of input tokens to generated outputs. However, most existing techniques are designed for encoder-based architectures and rely on linear approximations that fail to capture the causal and semantic complexities of autoregressive generation in decoder-only models. To address these limitations, we propose **Hessian-Enhanced Token Attribution (HETA)**, a novel attribution framework tailored for decoder-only language models. HETA combines three complementary components: a semantic transition vector that captures token-to-token influence across layers, Hessian-based sensitivity scores that model second-order effects, and KL divergence to measure information loss when tokens are masked. This unified design produces context-aware, causally faithful, and semantically grounded attributions. Additionally, we introduce a **curated benchmark dataset** for systematically evaluating attribution quality in generative settings. Empirical evaluations across multiple models and datasets demonstrate that HETA consistently outperforms existing methods in attribution faithfulness and alignment with human annotations, establishing a new standard for interpretability in autoregressive language models.", "tldr": "", "keywords": ["Explainable AI", "Attribution", "LLMs"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8b4852827f43471c201eaccd235dcdf732304c1f.pdf", "supplementary_material": "/attachment/eb4a69b9869e2e7c4daa9aeafe2a3dc5236a654f.zip"}, "replies": [{"content": {"summary": {"value": "The work introduces a unified interpretability framework, Hessian-Enhanced Token Attribution (HETA), for decoder-only large language models that integrates gradient-based, second-order, and information-theoretic perspectives to improve attribution fidelity and robustness. The work proposes three complementary components: (1) Semantic Transition Influence, (2) Hessian-based Sensitivity, and (3) Information-Theoretic Impact, which measures token contribution using KL divergence between masked and unmasked predictions.\nMoreover, the work proposes a curated benchmark combining NarrativeQA and SciQ passages. Experiments on multiple LLMs show that HETA improves attribution faithfulness, alignment, and robustness under input perturbations compared to baselines methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The work is clearly written.\n- The work constructs a carefully designed benchmark by combining NarrativeQA and SciQ, with explicit separation of evidence and distractors."}, "weaknesses": {"value": "- While HETA presents itself as a unified framework, several of its core components have been explored in earlier studies. For example, the Semantic Transition Influence and Information-Theoretic Impact elements are conceptually similar to those in GiLOT [1], which models token influence through semantic transition and distributional shifts measured via OT distance and KL divergence. Besides, the Hessian-based Sensitivity component also builds on prior work using second-order derivatives for attribution [2,3]. In evaluation, the benchmark’s metrics resemble those used in previous interpretability benchmarks without citing relevant works [4,5]. As such, the incremental integration of known techniques, rather than a fundamentally new formulation, weakens the originality claim.\n\n- The experiments mainly compare HETA against older or general-purpose attribution methods, but omit several recent baselines [1,6] specifically designed for generative or autoregressive models. Without these baselines, it is difficult to assess whether HETA genuinely advances the interpretability frontier for generative LLMs.\n\n- The use of Hessian–vector products for second-order sensitivity introduces high computational cost, particularly for long-context LLMs. The paper lacks analysis of the method’s runtime, memory footprint, and scaling behavior. It is unclear whether HETA is feasible for real-world interpretability auditing of modern multi-billion-parameter models.\n\n---\n[1] Li, X., Chen, J., Chai, Y. and Xiong, H., 2024, July. Gilot: Interpreting generative language models via optimal transport. In Forty-first International Conference on Machine Learning.\n\n[2] Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. \"Axiomatic attribution for deep networks.\" International conference on machine learning. PMLR, 2017.\n\n[3] Reing, K., Ver Steeg, G. and Galstyan, A., 2021, March. Influence decompositions for neural network attribution. In International Conference on Artificial Intelligence and Statistics (pp. 2710-2718). PMLR.\n\n[4] Li, Xuhong, Mengnan Du, Jiamin Chen, Yekun Chai, Himabindu Lakkaraju, and Haoyi Xiong. \"M4: A Unified XAI Benchmark for Faithfulness Evaluation of Feature Attribution Methods across Metrics, Modalities, and Models.\" (2023).\n\n[5] DeYoung, Jay, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher, and Byron C. Wallace. \"ERASER: A benchmark to evaluate rationalized NLP models.\" arXiv preprint arXiv:1911.03429 (2019).\n\n[6] Xiang Yue, Boshi Wang, Ziru Chen, Kai Zhang, Yu Su, and Huan Sun. 2023. Automatic Evaluation of Attribution by Large Language Models. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 4615–4635, Singapore. Association for Computational Linguistics."}, "questions": {"value": "- Several components of HETA (e.g., Semantic Transition Influence, Information-Theoretic Impact, and Hessian-based Sensitivity) appear conceptually related to previous work. Could the authors clarify the conceptual and methodological distinctions between HETA and these existing approaches? Specifically, what unique insight or mechanism does HETA introduce beyond combining known ideas?\n\n- Could the authors provide quantitative analysis (e.g., runtime, GPU hours, memory footprint) or approximations used to make HETA feasible for billion-parameter LLMs? How does computational cost scale with sequence length and model size, and could this limit real-world applicability?\n\n- The evaluation focuses exclusively on internal consistency with the proposed benchmark. Have the authors conducted human evaluations, qualitative analyses, or causal interventions to validate whether the generated attributions are truly meaningful and interpretable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oad2dJuhCh", "forum": "XsEZcigEjq", "replyto": "XsEZcigEjq", "signatures": ["ICLR.cc/2026/Conference/Submission21313/Reviewer_uaYo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21313/Reviewer_uaYo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716273273, "cdate": 1761716273273, "tmdate": 1762941688500, "mdate": 1762941688500, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Hessian-Enhanced Token Attribution, a new interpretability framework for decoder-only language models. HETA combines semantic flow tracing, Hessian-based sensitivity, and KL-divergence information metrics to provide more faithful, context-aware token-level attributions in generative models. \n\nExperiments show that HETA outperforms existing methods in faithfulness, robustness, and human alignment, and the authors also release a curated benchmark dataset for evaluating attribution quality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It proposes a unified, principled framework (HETA) combining causal semantic flow, second-order sensitivity, and information-theoretic attribution.\n\n2. It addresses key flaws of attention-based and gradient-based methods, yielding more faithful and robust token-level explanations.\n\n3. It demonstrates strong empirical improvements in faithfulness, robustness, and human alignment.\n\n4. It introduces a new benchmark dataset for evaluating attribution in generative models."}, "weaknesses": {"value": "1. How does the computational cost compare with existing works, in terms of time and memory requirements? The proposed method seems to incur higher computational overhead, for example, due to the KL masking and Hessian–vector product operations. How do the authors balance effectiveness and efficiency in practice?\n\n2. The stochastic estimation depends on the number of Hutchinson samples m. How does the choice of m affect the empirical performance and stability of the results in the experiments?\n\n3. The authors employ several LLMs of different architectures and sizes, including Qwen2.5-3B, GPT-J-6B, Phi-3-Medium-4K-Instruct, and LLaMA-3.1-70B.\nI am curious how the proposed method performs across models of the same architecture but different sizes, for example, among different sizes of LLaMA-3. Would model scale affect the attribution behavior, stability, or the relative advantages of HETA compared with baselines?"}, "questions": {"value": "Please refer to Weaknesses.\n\n(1. How does the computational cost compare with existing works, in terms of time and memory requirements? The proposed method seems to incur higher computational overhead, for example, due to the KL masking and Hessian–vector product operations. How do the authors balance effectiveness and efficiency in practice?\n\n2. The stochastic estimation depends on the number of Hutchinson samples m. How does the choice of m affect the empirical performance and stability of the results in the experiments?\n\n3. The authors employ several LLMs of different architectures and sizes, including Qwen2.5-3B, GPT-J-6B, Phi-3-Medium-4K-Instruct, and LLaMA-3.1-70B.\nI am curious how the proposed method performs across models of the same architecture but different sizes, for example, among different sizes of LLaMA-3. Would model scale affect the attribution behavior, stability, or the relative advantages of HETA compared with baselines?)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pMd9NyMj92", "forum": "XsEZcigEjq", "replyto": "XsEZcigEjq", "signatures": ["ICLR.cc/2026/Conference/Submission21313/Reviewer_Du4D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21313/Reviewer_Du4D"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762113418709, "cdate": 1762113418709, "tmdate": 1762941688095, "mdate": 1762941688095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Hessian-Enhanced Token Attribution (HETA), a novel attribution framework for decoder-only language models that addresses limitations of existing methods. HETA integrates three complementary components: (1) a semantic transition vector capturing token-to-token influence through attention-value rollout with causal gating, (2) Hessian-based sensitivity scores modeling second-order curvature effects, and (3) KL divergence measuring information loss under token masking. The authors construct a curated evaluation dataset (NarrativeQA + SciQ) with 2,000 instances designed to assess attribution precision in controlled settings. Experiments across GPT-J, Phi-3, LLaMA-3.1, and Qwen2.5 models show that HETA consistently outperforms a set of existing attribution methods (ContextCite, Integrated Gradients, Peering, TDD-backward, etc.) on faithfulness metrics (Soft-NC, Soft-NS) and alignment with human annotations (DSA metric), while exhibiting robustness to decoding hyperparameters and syntactic rephrasings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: The HETA method proposed to combine established feature attribution approaches through a principled target-conditioned gating.\n- Quality: Authors conduct experimental evaluation across model scales (3B–70B), diverse tasks (LongRA, TellMeWhy, WikiBio), multiple metrics (Soft-NC/NS, DSA, AOPC), and systematic ablations. The robustness analyses (sensitivity to noise, active/passive paraphrases, decoding hyperparameters) are particularly thorough.\n- Clarity: The conceptual motivation of combining multiple components in the final attribution scores is motivated in a reasonable way, and a comprehensive discussion about the properties of the HETA method is provided in Appendix A2\n- Significance: the integration of semantic flow, curvature sensitivity, and information-theoretic measures addresses distinct failure modes of single-view methods, as demonstrated convincingly through ablations (Tables 5, 8, Figure 2). The proposed efficiency adaptations in A5 are a first step in addressing the important concern of scalability to bigger model and context sizes."}, "weaknesses": {"value": "In terms of originality, the main concern with this work is that the proposed method is that it amounts to a weighted combination of previous techniques, namely context mixing methods for extracting layerwise contributions, hessian for curvature sensitivity estimation and input masking.  The semantic flow approach representing the gate modulating target-directedness of the final HETA formulation in Eq. 5 is very related to the input attribution formulation of the ALTI method [1], which is not cited but also employs rollout for attention-weighted value vectors. Notably, the ALTI-Logit method [2] can be seen as an existing combination of semantic flow (through ALTI scores) and direct logit attribution, which reflects a per-component impact on output probability akin to the purpose of the KL-Divergence used in this work. Moreover, the rollout approach was criticized as a heuristic for aggregating contributions across layers, without explicitly decomposing the contribution of FFN layers [3, 4, 5]. The masking used for the KL-Divergence computation can also lead to unrealistic result for language tasks and particularly for generation, provided that masked inputs are likely to be out-of-distributions for the model [6].\n\nIn light of these comments, the choice for the proposed semantic flow approach should be justified and possibly modified to account for the aforementioned works in this area. Moreover, the criticism towards gradient-based approaches should account for more recent techniques specifically adapted for Transformer-based systems, in particular [7] that also provides a convenient implementation in the LXT PyPI package. Including some of these techniques---which are more established within the feature attribution community---as baselines for the evaluation of HETA would further reinforce the validity of the proposed method.\n\nIn terms of clarity, I found the introduction to the Hessian component handwavy, employing various specific terms such as Hessian–vector products (HVPs) with Hutchinson estimators and Pearlmutter’s trick without providing mathematical formulations or pointers. Moreover, the Soft-NC / Soft-NS metrics are not widely established and should be introduced more in detail at least in the appendix. As a minor comment, multiple citations and tables are formatted incorrectly (e.g. lines 270-275, line 295 bolded citation,  table 5 excessively large).\n\n**References:**\n\n- [1]: [Measuring the Mixing of Contextual Information in the Transformer](https://aclanthology.org/2022.emnlp-main.595/) (Ferrando et al., EMNLP 2022) \n- [2]: [Explaining How Transformers Use Context to Build Predictions](https://aclanthology.org/2023.acl-long.301/) (Ferrando et al., ACL 2023)\n- [3]: [Local Interpretation of Transformer Based on Linear Decomposition](https://aclanthology.org/2023.acl-long.572/)(Yang et al., ACL 2023)\n- [4]: [DecompX: Explaining Transformers Decisions by Propagating Token Decomposition](https://aclanthology.org/2023.acl-long.149/) (Modarressi et al., ACL 2023)\n- [5]: [Token-wise Decomposition of Autoregressive Language Model Hidden States for Analyzing Model Predictions](https://aclanthology.org/2023.acl-long.562/) (Oh & Schuler, ACL 2023)\n- [6] [Quantifying Context Mixing in Transformers](https://aclanthology.org/2023.eacl-main.245/) (Mohebbi et al., EACL 2023)\n- [7] [AttnLRP: attention-aware layer-wise relevance propagation for transformers](https://dl.acm.org/doi/10.5555/3692070.3692076) (Achtibat et al., ICML 2024)"}, "questions": {"value": "What concrete steps could be taken besides restricting curvature computation to a context window (Appendix A5) to ensure the practical usability of the HETA method on LLMs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hpkwJhxDoY", "forum": "XsEZcigEjq", "replyto": "XsEZcigEjq", "signatures": ["ICLR.cc/2026/Conference/Submission21313/Reviewer_XxTJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21313/Reviewer_XxTJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762136702659, "cdate": 1762136702659, "tmdate": 1762941687703, "mdate": 1762941687703, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HETA, an attribution framework tailored to decoder-only LLMs that combines three components: (1) Target-conditioned semantic flow via attention–value rollout to gate only tokens that have causal paths ending at the target position. (2) Second-order sensitivity using scalable Hessian–vector products (HVPs) with Hutchinson estimators to capture curvature and token interactions that first-order methods miss. (3) Information-theoretic contribution measured as the KL divergence between the original target distribution and the distribution after masking a given input token. The authors also introduce a curated evaluation benchmark for token-level attribution in generative settings by pairing NarrativeQA and SciQ text segments."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is straightforward: The integration of structural routing (target-conditioned rollout), geometric curvature (Hessian sensitivity), and information change (KL) is conceptually clean and well-motivated for autoregressive decoding.\n\n2. The curated corpus and DSA offers a controlled setting to check whether attribution concentrates on truly diagnostic spans rather than distractors.\n\n3. It targets at the attribution for decoder-only models, which has certain potentials for interpreting LLMs."}, "weaknesses": {"value": "1. Although the target-conditioned gate based on attention-value rollout is an improvement over pure attention attribution, it is still a heuristic causal proxy. Residual pathways and non-linear MLP transformations can confound causal flow. The paper did not directly validate causality with, e.g., causal mediation analysis, circuit-level interventions.\n\n2. The evaluation relies on LM-generated supervision for the curated set. The DSA construction uses the intersection of GPT-4o and GPT-5 annotations to reduce noise, but residual bias is possible, especially if systems trained on similar inductive biases label the data. Some human audit or a cross-annotation sanity-check would strengthen claims.\n\n3. The comparison with previous literature is not thorough. Previous studies on generative GPT models should also be discussed and compared, such as [1]. I also suggest the authors report metrics such as MoRF, LeRF, ABPC as in [1] for further comparison.\n\n4. Missing several baselines. A few classical perturbation baselines (ROAR/KAR, AOPC deletion/insertion curves) and model editing/tracing style checks could further improve the faithfulness. \n\n5. Format error. The reference style needs to be corrected.\n\nReferences:\n[1] GiLOT: Interpreting Generative Language Models via Optimal Transport. ICML 2024."}, "questions": {"value": "1. How does HETA behave when attributing to spans (e.g., the next 3–5 tokens, or an answer string) rather than a single onset token? Does gating generalize naturally by aggregating over targets, and how do costs scale?\n\n2. Could you provide a disagreement analysis between GPT-4o and GPT-5 annotations and a small human validation study on a stratified subset to calibrate false positives/negatives in the curated set?\n\n3. When does curvature help most, and when does KL dominate? Are there tasks where semantic gating alone is competitive?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EbRmrbdJhk", "forum": "XsEZcigEjq", "replyto": "XsEZcigEjq", "signatures": ["ICLR.cc/2026/Conference/Submission21313/Reviewer_icxv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21313/Reviewer_icxv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762164173225, "cdate": 1762164173225, "tmdate": 1762941687444, "mdate": 1762941687444, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}