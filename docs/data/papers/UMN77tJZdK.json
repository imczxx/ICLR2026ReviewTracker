{"id": "UMN77tJZdK", "number": 8709, "cdate": 1758095619362, "mdate": 1759897768496, "content": {"title": "GraphPlan: Graph-enhanced Planning via Thinking LLMs for Embodied Agents", "abstract": "Embodied agents that follow instructions to complete complex tasks in visual environments have attracted increasing attention. Large Language Models (LLMs) based planners, notwithstanding the progress achieved, still suffer from three main limitations: (i) a lack of physical grounding, often resulting in hallucinatory plans; (ii) poor generalization to unseen long-horizon tasks; and (iii) an absence of environmental awareness in the open-loop planning process. To address these issues, we propose GraphPlan, a novel framework that integrates a task graph to provide structured knowledge for robust planning and a scene graph to maintain environmental memory for event-driven replanning. Specifically, the task graph guides the LLM's reasoning through contextual prompting and iterative refinement, effectively mitigating planning hallucinations. Furthermore, within the GRPO framework, the task graph offers delicate reward design to train LLMs' reasoning, enhancing long-horizon planning capabilities and improving generalization. Finally, the memory constructed by a dynamic scene graph empowers an event-driven replanning module, enabling the agent to foster environment awareness and correct instruction misalignment within a closed-loop planning process. On the standard benchmark ALFRED, GraphPlan achieves state-of-the-art performance on the official leaderboard. Moreover, its high-level planner outperforms a series of leading API-based LLMs on both the validation set and unseen long-horizon tasks. Additional experiments reveal the promising potential of our graph-enhanced framework in few-shot or zero-shot learning scenarios.", "tldr": "", "keywords": ["Embodied Agent", "Instruction Following", "Task Planning", "Task Graph", "Reinforcement Learning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/10bc76996624c0f58cfc108b0549064a0e2e2701.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes GraphPlan, a graph-enhanced framework for embodied agents that integrates structured knowledge into LLM-based planning. It builds a task graph to constrain and verify language-generated plans, a scene graph to represent updating object relations, and a memory-aware low-level policy with replanning capability. It combines these components with an event-driven replanning mechanism and a reinforcement learning objective that rewards graph-consistent actions. The method is validated in the ALFRED benchmark and outperforms previous state-of-the-art methods by notable margins."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper tackles challenging and important issues for long-horizon planning.\n- The proposed method outperforms previous state-of-the-art methods with large margins.\n- Incorporating subtask structure in graph forms is straightforward sensible."}, "weaknesses": {"value": "- For task graph construction, the authors use four types of meta classes, but their motivation is not well described. Why should be they? In addition, the authors use subtasks from a specific benchmark. Can they generalize to novel tasks?\n- For task graph construction and its verification, the task graph is constructed from expert trajectories. How sensitive is the quality of the task graph to the number and diversity of the training samples? Quantitative analyses should be conducted. In addition, can the proposed method be used in case of tasks without training demos?\n- For memory-aware low-level action policy, logging waypoints and object masks has already been explored (e.g., Kim et al, 2023). What are the core differences from the prior work? And, why are they significant?\n- The proposed event-driven replanning is highly motivated by several failure modes in a specific benchmark, raising a concern of their generalizability.\n- Replanning has been actively explored [1,2], but little to no discussion about them is provided. What are the main difference with them?\n  - Huang et al., \"Inner monologue: Embodied reasoning through planning with language models,\" CoRL, 2022.\n  - Kim et al, \"Pre-emptive Action Revision by Environmental Feedback for Embodied Instruction Following Agents,\" CoRL, 2024.\n- It is unclear if the comparison with prior work in Table 1 is fair. For example, how many training samples are used compared to prior work? Some prior work (Song et al., 2023, Kim et al, 2025) uses only a small portion of the training samples (~100 samples). In addition, is the comparison done under the same LLMs?\n- The evaluation is conducted in a single benchmark, raising a generalizability concern. Can this approach be applied to other task setups?"}, "questions": {"value": "- In Sec. 3.3.2, how does the agent know if it fails at a task? Is it predicted by LLMs or measured by some predefined rules?\n- Due to the discrete nature of graphs, it might be hard to apply the proposed method to tasks with continuous state and action spaces. Can the proposed method be used for such tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Spr5cV7au3", "forum": "UMN77tJZdK", "replyto": "UMN77tJZdK", "signatures": ["ICLR.cc/2026/Conference/Submission8709/Reviewer_ADQz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8709/Reviewer_ADQz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761672598103, "cdate": 1761672598103, "tmdate": 1762920513650, "mdate": 1762920513650, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed GraphPlan, a framework that incorporates a Task Graph and a Scene Graph for embodied agent task completion in the ALFRED environment. The task graph is a detailed representation of task-specific related information, including objects, subtask relationships, attributes, affordance, etc. It aims to help high level planning, generate reward function for action executions, and provide task verification for reasoning. The method also includes a memory for task relevant object states and locations through waypoints and segmentations. The Scene graph is generated on the fly to store key objects (extracted by LLMs), view points of the objects, and the relationship among objects. It aims to help replanning when a low level action error or subtask planning error is encountered. The paper benchmarked the performance in comparison against multiple methods and demonstrated improvement on task success rate and goal condition success rate. The paper also conducted thorough ablation studies to showcase the importance of each components in the proposed framework. Further more, the paper collected a new datasets of 1396 samples to evaluate long-horizon high level planning capabilities in comparison against 3 closed-source models and varied prompting strategies. The proposed method demonstrated outstanding performance especially among long horizon tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well structured and well written.\n- The paper proposed a method for embodied agent planning and action prediction, leveraging a proposed task graph and a scene graph\n- The paper incorporated a replanning stage to improve long horizon task performance in case of errors\n- The paper conducted thorough experiments among baselines, evaluating the proposed method through task success rate, goal condition success rate, and numerous ablation studies. \n- The paper also collected a dataset specifically aiming at evaluating long horizon tasks, and conducted experiments against closed-source LLMs for high level planning"}, "weaknesses": {"value": "1. The paper is careful to highlight the that \"the subtask nodes can be expended as the low-level policy evolves\" and that \"the proposed task graph-based approach can generalize to planning tasks in other domains\". While they are indeed possible, the main question is really 'How useful is the method outside the ALFRED/simulated environment? In cases such as general home robot, takeout delivery robot, or disaster rescue robot, how feasible is it to manually generate the task-specific graphs, annotate all the key subtasks, and exhaust all possible/potential states/objects/attributes/conditions/relationships/subtasks?'\n2. Section 3.2: it was a bit unclear how exactly low-level action policies are designed & trained when incorporating a memory of object states a locations?  \n3. While evaluating the performance, the main metrics are Task Success Rate (SR) and Goal-Conditioned Success Rate (GC). Is task execution efficiency (e.g. #actions/#steps it took to reach a goal) a relevant metrics to consider perhaps?"}, "questions": {"value": "a. It is great that the scene graphs can be generated automatically on the fly. How truthful are the generated scene graphs? \nb. Figure 4: is there any reason why most of the models perform better in the valid unseen dataset compared to the valid seen dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7zpR1Ytepd", "forum": "UMN77tJZdK", "replyto": "UMN77tJZdK", "signatures": ["ICLR.cc/2026/Conference/Submission8709/Reviewer_JYqU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8709/Reviewer_JYqU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990247628, "cdate": 1761990247628, "tmdate": 1762920513218, "mdate": 1762920513218, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GraphPlan, a graph-enhanced planning framework for embodied agents that improves long-horizon reasoning and task execution in complex environments. It addresses key weaknesses of LLM planners such as hallucinated actions and poor generalization by integrating graph representations for reasoning. Through graph-guided prompting, verification, and RL, the system maintains grounded, feasible plans. Evaluated on the ALFRED benchmark, GraphPlan achieves SOTA performance, outperforming prior methods by about 6% in unseen success rate, and demonstrates strong generalization to long-horizon tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Symbolic structures for guiding LLM-based planning is novel and creative. The method is motivated intuitively. \n- The dual graph method (task and scene decoupled) for provides a principled way to make LLMs operate for planning. \n- The frameworks is well validated through comprehensive experiments, including ablations that isolate the contribution of each module."}, "weaknesses": {"value": "- The construction of task graphs appears handcrafted/domain-dependent, raising concerns about how easily GraphPlan generalizes to new environments.\n- In larger or more cluttered environments, these graphs could contain hundreds of nodes and relations. The paper assumes the LLM can interpret and reason over these graph descriptions accurately, but provides no analysis of performance degradation or prompt efficiency as graph complexity grows.\n- Do the authors empirically demonstrate how GraphPlan’s performance scales with increasing task horizon length? While the benchmark shows overall results, there’s no detailed analysis of degradation trends of whether other methods fail progressively with more subtasks (longer horizons) while GraphPlan remains stable."}, "questions": {"value": "- Could the authors provide additional evaluation of \"reasoning fidelity\". For example, how closely intermediate subgoals follow the intended logic of the instruction, or how often the model avoids invalid or redundant subtasks?\n- How robust is GraphPlan when the scene graph contains missing or incorrect relations? Could the LLM detect and repair such inconsistencies through reasoning?\n- While the long-horizon benchmark shows strong overall results, the paper doesn’t characterize computational or reasoning costs. How does inference time and #LLM calls scale with task length?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bzui0qRoFK", "forum": "UMN77tJZdK", "replyto": "UMN77tJZdK", "signatures": ["ICLR.cc/2026/Conference/Submission8709/Reviewer_aMND"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8709/Reviewer_aMND"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762071486099, "cdate": 1762071486099, "tmdate": 1762920512475, "mdate": 1762920512475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers use of LLM’s for embodied agent planning, and proposes GraphPlan that uses a task graph and scene graph.  The task graph is developed a priori and characterizes the possible sequences of actions (sub-tasks).  This can be used in an LLM planning prompt to ensure the plan adheres to the graph.  A scene graph is constructed that incorporates the entire environment, with all relevant objects and relationships discretely encoded. The scene graph will be updated when changes occur.  The method is used on the ALFRED benchmark and some comparisons are made."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The methodology discretizes both the action space and the scene in graphs, and this provides a framework for LLM-based plan generation, replanning, and adhering to feasible plans. The planning method might be useful for highly characterized environments with a fixed set of simple actions and set of objects with relations encoded.  \n\nGRPO is used to generate a policy and rewards are linked to the graph structures. This guides the GRPO within the constraints specified for the tasks and scene.\n\nThe method is easy to understand and intuitively clear."}, "weaknesses": {"value": "The method discretizes both action and scene, including objects and relationships.  This greatly simplifies the overall processing, which is logical but also highly constrained.  Given the task graph a priori, it isn't obvious that an LLM based planner is even needed, and why a graph searching type method can't be applied directly. \n\nScalability is unlikely.  The scene graph will grow with the scene size and will be a serious bottleneck, even in a highly controlled simple environment.  Adding new task and objects apparently requires a new policy training phase. \n\nThe overall novelty isn't obvious.  Learning scene graphs with objects has already been developed.  The verification of a finite LLM-plan has also been considered, e.g., by mapping to a finite automata type model. \n\nThe underlying task graph assumes each node can be reached (e.g., grasping), and this doesn't account for perception errors, incomplete sub-tasks, or other forms of real life conditions."}, "questions": {"value": "How does the task graph approach compare with other LLM-based encoders that choose among a set of actions?\n\nWhat is the novelty with respect to the scene graph?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v3A3outfEu", "forum": "UMN77tJZdK", "replyto": "UMN77tJZdK", "signatures": ["ICLR.cc/2026/Conference/Submission8709/Reviewer_MinK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8709/Reviewer_MinK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118243332, "cdate": 1762118243332, "tmdate": 1762920512125, "mdate": 1762920512125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}