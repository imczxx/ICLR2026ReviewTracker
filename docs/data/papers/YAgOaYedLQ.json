{"id": "YAgOaYedLQ", "number": 18131, "cdate": 1758284213129, "mdate": 1759897130222, "content": {"title": "Neural Multi-Objective Combinatorial Optimization for Flexible Job Shop Scheduling Problems", "abstract": "Neural combinatorial optimization (NCO) has made significant advances in applying deep learning techniques to efficiently and effectively solve single-objective flexible job shop scheduling problems (FJSPs). However, the more practical multi-objective FJSPs (MOFJSPs) remain underexplored, limiting the applicability of NCO in multi-criteria decision-making scenarios. In this paper, we propose a decomposition-based NCO method to solve MOFJSPs. We present the dual conditional attention network (DCAN), a neural network architecture that takes the objective preferences along with the problem instance, aiming to learn adaptable policies over the preferences. By decomposing an MOFJSP into a set of subproblems with different preferences, the learned DCAN policies generate a set of solutions that reflect the corresponding trade-offs. We customize the Proximal Policy Optimization algorithm based on decomposition to effectively train the policy network for multiple objectives and define the state and reward based on combinations of different objectives. Extensive results showcase that our approach outperforms traditional multi-objective optimization methods and generalizes well across diverse types of problem instances.", "tldr": "", "keywords": ["Neural Multi-Objective Combinatorial Optimization", "Flexible Job Shop Scheduling Problem", "Deep Reinforcement Learning"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7a1b36edf215ae2df6d4862424c377e8b6fb96dd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the flexible job shop scheduling problem with multiple objectives. The authors propose a Dual Conditional Attention Network that learns adaptable scheduling policies. They employ a decomposition-based neural combinatorial optimization approach, solving subproblems with different objective preferences, and use PPO for training. The learned policy can generate a set of Pareto-optimal solutions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a practically important and realistic problem, as real-world scheduling problems typically involve multiple conflicting objectives.\n\nThe approach of learning adaptable policies conditioned on objective preferences is promising and could improve generalization.\n\nGenerating a Pareto set of solutions using a single trained model is an attractive feature for practical multi-objective scheduling."}, "weaknesses": {"value": "The four considered objectives (makespan, total tardiness, average flow time, and total cost) are not well justified. The first three are closely correlated regular measures, while the inclusion of total cost lacks sufficient motivation or explanation regarding its relevance in real-world FJSPs.\n\nThe paper does not analyze the interrelationship among the four objectives, which limits understanding of the trade-offs the model learns.\n\nWhile the paper presents an interesting approach, the overall contribution remains unclear. It would be helpful to explicitly highlight what new insight or technical novelty it brings beyond existing multi-objective scheduling and NCO frameworks.\n\nThe method uses the lower bound of completion time as the state and reward, but this can cause instability in learning depending on the tightness of the bound. This issue should be discussed in detail.\n\nWhile several performance-enhancing techniques are proposed, the paper lacks an ablation study to quantify their individual contributions."}, "questions": {"value": "1. How can practical constraints such as setup times or machine dedication be incorporated into your framework?\n2. How does the model perform when including objectives that are not regular measures (e.g., earliness)?\n3. Many recent studies employ REINFORCE for scheduling. What motivated your choice of PPO?\n4. Using lower bounds as rewards can lead to inconsistent gradients depending on their tightness. How do you handle or mitigate this issue?\n5. Please provide an ablation study to analyze the contribution of each proposed component."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K2a7qZi5ok", "forum": "YAgOaYedLQ", "replyto": "YAgOaYedLQ", "signatures": ["ICLR.cc/2026/Conference/Submission18131/Reviewer_XAsV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18131/Reviewer_XAsV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761294521448, "cdate": 1761294521448, "tmdate": 1762927893588, "mdate": 1762927893588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents two extensions to an existing neural network architecture for the FJSSP, namely the Dual Attention Network, enabling it to address multi-objective combinatorial optimization problems. The authors aim to approximate the standard Pareto front and identify the corresponding Pareto set.\n\nThe first proposed method is a straightforward extension in which the weighted preference vector of the objectives is concatenated with each operation and machine feature. The rest of the network remains unchanged from the single-objective formulation. The second method integrates the preference vector directly into the update process of the operation and machine embeddings during the attention mechanism.\n\nThe authors investigate four optimization objectives: makespan, tardiness, flow time, and cost. The two proposed extensions are evaluated against standard metaheuristic algorithms and a mathematical solver across several benchmark datasets. Additionally, the approach is extended to two related problem types, the classical JSSP and the FFSP (discussed in the appendix).\n\nThe results demonstrate that both neural network extensions achieve significantly faster computation times compared to metaheuristic algorithms and solver-based methods across all instance types. However, the metaheuristics outperform the proposed approaches on certain, smaller problem instances, while the advantage of the proposed methods becomes particularly evident for larger instances that are computationally challenging for traditional optimization techniques. It was also shown that the second proposed approach, in which the preference is integrated into the attention mechanism, performs better than the approach where the preference vector is trivially inserted.\n\nThe authors want to publish code after acceptance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Well-motivated problem formulation, clearly highlighting that neural network architectures have rarely been applied to multi-objective variants of the Flexible Job Shop Scheduling Problem (FJSSP).\n\n- Introduction of two new methods that improve solution quality, particularly with respect to inference time: The first method, while not highly innovative, forms a solid baseline. The second method shows clear advancements beyond the baseline.\n\n- Comprehensive evaluation setup: Both methods are tested using greedy and sampling-based inference strategies. This allows a thorough assessment under different inference regimes.\n\n- Novel reward function design: Reward is defined based on the change in the theoretical minimum lower bound before and after an action for each metric. This differs from previous work, which typically uses dense or sparse rewards derived directly from the actual schedule rather than theoretical lower bounds.\n\n- Well-structured and informative appendix: Contains mathematical assumptions, details on key performance metrics, description of the critic network architecture (PPO), and a step-by-step reward calculation.\n\n- Transparent discussion of limitations: Authors acknowledge where their methods underperform on small instances. They provide a convincing explanation why their approach performs better on larger instances.\n\n- Demonstrates understanding of the problem characteristics and adds credibility to the evaluation."}, "weaknesses": {"value": "- Although the authors acknowledge that other deep learning solutions typically train separate models for individual preference vectors, no such method is included in the experiments. Including at least one representative baseline (e.g., policy-based or value-based DRL approaches from recent literature) would provide meaningful context and allow readers to better assess the relative performance and contribution of the proposed methods.\n\n- The description of how the preference vector is incorporated into the second method (architecture with dual inputs) remains unclear. A visual schematic, for example a processing pipeline similar to those used in DAN literature, would help illustrate how the model processes and uses preference information.\n\n- While the reward formulation (based on changes in theoretical lower bounds) is novel, the paper does not empirically justify why this reward is advantageous over more traditional dense or sparse scheduling rewards. A small ablation experiment (for example in the Appendix) comparing the proposed reward against a common baseline reward would strengthen the motivation and demonstrate its impact on learning behavior and performance."}, "questions": {"value": "1. Since the study introduces four distinct optimization objectives, why was the method not evaluated on all four objectives simultaneously? The experiments only include comparisons for selected two-objective and three-objective cases. Was this limitation due to the constraints of the metaheuristic algorithms and the solver, or does it reflect a limitation of the proposed model itself?\n2. In Table 3, it would be helpful to see results for additional sampling iterations. Given that the proposed method can generate substantially more samples within the same computational time as the metaheuristic approaches, it is possible that further sampling could enable it to outperform the metaheuristics. Could you clarify why this comparison was not included?\n3. For the ablation studies, why was only NSGA-II considered and not the newer NSGA-III? The latter represents a more state-of-the-art approach for multi-objective optimization.\n4. The focus of current research in multi-objective scheduling is shifting toward real-world applications, where objectives are defined for more practical use cases such as energy consumption and energy cost. Why were such abstract objectives chosen in this study? No citations were provided to justify the selection of the investigated objectives.\n5. There already exist methods that apply deep learning to multi-objective scheduling. Why were these methods ignored? At least some ablation studies, for example on small instances, should have been included as a comparison against the proposed method.\n6. The IGD+ metric was mentioned and used in the Appendix to compare different approaches. Why was it not included in all the tables? Since it represents an alternative to the hypervolume metric, wouldn’t it be reasonable to include both for completeness?\n7. Both methods do not appear to be overly complex, and it seems straightforward to combine them into a single approach—for instance, DCAN with the feature space of WI-CAN. Why was this not investigated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JhW5P0RxVn", "forum": "YAgOaYedLQ", "replyto": "YAgOaYedLQ", "signatures": ["ICLR.cc/2026/Conference/Submission18131/Reviewer_399M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18131/Reviewer_399M"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716439731, "cdate": 1761716439731, "tmdate": 1762927893133, "mdate": 1762927893133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a decomposition-based learning method to solve multi-objective flexible job shop scheduling (FJSP), where each subproblem associated with a preference vector. They define two neural architectures based on the DAN architecture from the previous literature for single-objective FSJP. WI-DAN concatenates the preference vector to the feature vector whereas DCAN leverages dual attention with conditional operation message attention block and conditional machine message attention block. The authors evaluate the performance of their proposed method on a variety of FSJP benchmarks, comparing with two commonly used multi-objective evolutionary algorithms, to show effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is easy to read and the proposed method makes sense for multi-objective optimization.\n\n2. Empirical results seem promising for the given method."}, "weaknesses": {"value": "1. There have been many works on learning for multi-objective combinatorial optimization for other COPs (e.g. routing). This paper does not give sufficient discussion of these related works (e.g. the related work section only mentions a few works for multi-objective FJSP, but not for other COPs at all). Similarly, there’s no discussion on (1) whether the learning method used in this paper has been applied to other COPs, and (2) whether techniques from other COPs can apply to FJSP considered in this paper. The authors should rewrite the related works and discussions to better connect to existing literature. \n\n2. In general, I’m concerned about the novelty of this paper. The decomposition based PPO algorithm seems to be a standard RL algorithm for multi-objective learning, and the neural architecture design seems to be a straightforward extension from the DAN architecture in the previous work. Given this, I’m worried that this paper does not meet the bar for a high quality ML conference like ICLR."}, "questions": {"value": "See the weaknesses. And further, based on the applicability of multi-objective learning methods for other COPs, the author should consider comparing with those applicable learning methods. Currently, I feel like the number of baselines the author compared is too few. And further, I think it will strengthen the paper if the authors can try to apply their proposed method to more scheduling variants beyond FJSP."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e2T4FVRpfr", "forum": "YAgOaYedLQ", "replyto": "YAgOaYedLQ", "signatures": ["ICLR.cc/2026/Conference/Submission18131/Reviewer_oBEa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18131/Reviewer_oBEa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716501160, "cdate": 1761716501160, "tmdate": 1762927892631, "mdate": 1762927892631, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes to use DRL for the multi objective FJSSP. It compares two different neural architectures and also compares to standard MOCO algorithms such as NSGAII. For large instances the algorithm that samples using the trained neural networks has good results. The conditional attention network outperforms the preference vector input network."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Good experimental results for large instances\nComparison of two neural architectures\nDesign of the DCAN architecture\nBetter results than meta-heuristic approaches"}, "weaknesses": {"value": "Simple sampling strategy\nNSGA-II has better result on public dataset instances for the 3-objective problem"}, "questions": {"value": "How does the results of best network evolve with samples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zn5fGHTvIH", "forum": "YAgOaYedLQ", "replyto": "YAgOaYedLQ", "signatures": ["ICLR.cc/2026/Conference/Submission18131/Reviewer_ck3N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18131/Reviewer_ck3N"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019826070, "cdate": 1762019826070, "tmdate": 1762927892050, "mdate": 1762927892050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}