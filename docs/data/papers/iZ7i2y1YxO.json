{"id": "iZ7i2y1YxO", "number": 4681, "cdate": 1757745016392, "mdate": 1759898020085, "content": {"title": "An Ensemble Framework for Unbiased Language Model Watermarking", "abstract": "As large language models become increasingly capable and widely deployed, verifying the provenance of machine-generated content is critical to ensuring trust, safety, and accountability. Watermarking techniques have emerged as a promising solution by embedding imperceptible statistical signals into the generation process. Among them, unbiased watermarking is particularly attractive due to its theoretical guarantee of preserving the language model's output distribution, thereby avoiding degradation in fluency or detectability through distributional shifts. However, existing unbiased watermarking schemes often suffer from weak detection power and limited robustness, especially under short text lengths or distributional perturbations. In this work, we propose ENS, a novel ensemble framework that enhances the detectability and robustness of logits-based unbiased watermarks while strictly preserving their unbiasedness. ENS sequentially composes multiple independent watermark instances, each governed by a distinct key, to amplify the watermark signal. We theoretically prove that the ensemble construction remains unbiased in expectation and demonstrate how it improves the signal-to-noise ratio for statistical detectors. Empirical evaluations on multiple LLM families show that ENS substantially reduces the number of tokens needed for reliable detection and increases resistance to smoothing and paraphrasing attacks without compromising generation quality.", "tldr": "", "keywords": ["LLM watermarking"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d1d3bf6c2378ca90707046110b52d184d7f87a2b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the problem of watermarks for language models. A watermark is a statistical signal hidden inside text that can be detected by anyone with access to a secret key but is intended to not distort the quality of text, thus remaining undetectable to observers without access to a secret key. Many schemes have been instantiated for autoregressive models by modifying the sampling procedure of models, with a prominent such scheme being the green list approach, where a hash function looks at the recent context and returns a pseudorandom subset of the vocabulary to upweight in generation.  This scheme proposes to construct an ensemble of watermarks by recursively applying a key-based reweighting scheme with different keys to the distribution of the next token in order to inject additional detection power.  The authors then instantiate their ensemble based approach with a variety of watermarking schemes and demonstrate empirical efficacy in improving watermark detectability and robustness after carefully selecting their hyperparameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "One strength of this paper is that they identify a new axis for improving the dectectability and robustness of language models."}, "weaknesses": {"value": "First, the authors incorrectly suggest that SynthID requires $2^{30}$ redundant tokens to generate a single token.  As the authors of that paper state clearly in the methods and in the appendix, they apply a vectorized approach to tournament sampling in practice that does not induce this redundancy.\n\nSecond, I am a little confused about the additional novelty of the present work with respect to tournament sampling.  While I agree that synth-id uses a particular instance of the ensembling framework introduced in definition 1, I think more clear differentiation could be described.\n\nThird, the statement on lines 204-205 about unbiasedness ensuring indistinguishability is not true.  See, e.g. *Black-box detection of\nlanguage model watermark* by Gloaguen et al 2025.\n\nFourth, the fact that there is non-monotonic improvement with $n$ is a bit unfortunate and seems like it is an artifact of the precise way that the elements of the ensemble instantiate the watermark, i.e. by using some fraction of the vocabulary as a greenlist which then becomes exponentially small in intersection.  This does not seem like a fundamental barrier but rather a specific pathology of the greenlist paradigm.  Tournament sampling for example does not suffer from this failure mode.  I think the authors should discuss this.\n\nFifth, I am curious as to the additional sampling time overhead required to implement this approach, as well as how this scales as a function of $n$.\n\nSixth, I think this paper can benefit from comparison with additional related work, such as those watermarks that are imbedded directly into the model weights, e.g. *GaussMark: A Practical Approach for Structural Watermarking of Language Models* by Block et al 2025."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HmHGsVw4lh", "forum": "iZ7i2y1YxO", "replyto": "iZ7i2y1YxO", "signatures": ["ICLR.cc/2026/Conference/Submission4681/Reviewer_mMdf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4681/Reviewer_mMdf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4681/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761285424428, "cdate": 1761285424428, "tmdate": 1762917510139, "mdate": 1762917510139, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ENS, an ensemble framework that enhances logit-based unbiased watermarks by amplifying the watermark signal. The idea is simple: each logit-based unbiased watermark can be viewed as a distribution reweighting function $f_i$. By ENS, different distribution reweighting functions are nested, i.e., $f_i( f_{i-1} (\\cdot) )$. Intuitively, the nested function is also unbiased but enhance watermark strength."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea is easy to implement but effective. \n2. The authors conduct different variants of ENS-enhanced watermarks, which all show the efficacy of ENS according to the experimental results. Specifically, the authors show the unbiasedness, robustness, and higher detectability via ENS."}, "weaknesses": {"value": "1. Potentially, if an unbiased watermark is enhanced, it is possible that the probability distribution is altered too much under certain watermark keys. Therefore, the method may not perform well in low-entropy scenarios. However, since this is not the focus, the authors could discuss this limitation in future work."}, "questions": {"value": "1. The authors can elaborate further on Section 4.3. Specifically, what is the effect of $n$? The authors argue that in practice, it is important to select $n$ close to the optimal by balancing the tradeoff between aggregation gain and sparsity loss. The experimental results also suggest that an intermediate $n$ achieves better performance. Although I generally understand the idea that a large $n$ reduces the detectability but not significantly, the analysis in Section 4.3 is not sufficiently clear. \n2. From Table 1, the TPR@0.1%FPR score of ENS-Dipmark seems to achieve its optimum when $n=5$. Theoretically, I am also curious about the performance gain bound by ENS. Could the authors provide some analysis of the improvement by ENS? For example, specifically for Dipmark, what is the expected gain in detectability for $n=2,3,\\cdots$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qJTTcRyTIE", "forum": "iZ7i2y1YxO", "replyto": "iZ7i2y1YxO", "signatures": ["ICLR.cc/2026/Conference/Submission4681/Reviewer_rySn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4681/Reviewer_rySn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4681/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761857965875, "cdate": 1761857965875, "tmdate": 1762917509834, "mdate": 1762917509834, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ENS, a general ensemble framework for logits-based unbiased watermarking in LLMs. The key idea is to sequentially compose multiple unbiased watermark instances (with independent keys), amplifying the watermark signal while theoretically preserving unbiasedness. The authors prove that ensemble compositions remain unbiased and show detection signal scales as $\\sqrt{n}$ with ensemble size. The authors also conducted evaluations on multiple LLM families and datasets to validate their algorithms."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. Clear Motivation: ENS addresses the main weakness of unbiased watermarks: weak detectability at short lengths.\n\n2. The proof of unbiasedness is rigorous, with extensions on independence assumptions and variance scaling.\n\n3. The experiments are comprehensive. The proposed method is compared against strong unbiased baselines e.g. SynthID. The experiments cover both detectability and robustness, using realistic paraphrasing and back-translation attacks.\n\n4. The experimental results are strong. There are significant TPR@FPR gains of ENS. Besides, ENS-MCMark achieves state-of-the-art robustness and detectability across attacks."}, "weaknesses": {"value": "1.\tENS requires multiple independent keys per generation step, which may introduce storage, distribution, and synchronization complexity in real deployment.\n2.\tDetection power declines for large ensemble sizes, aligning with theory but reducing scalability. Choosing optimal n becomes another hyperparameter to tune."}, "questions": {"value": "Do you have any advice for tuning the ensemble size?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wajhi1bHuH", "forum": "iZ7i2y1YxO", "replyto": "iZ7i2y1YxO", "signatures": ["ICLR.cc/2026/Conference/Submission4681/Reviewer_y1fL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4681/Reviewer_y1fL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4681/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959201503, "cdate": 1761959201503, "tmdate": 1762917509266, "mdate": 1762917509266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes, ENS, that composes several unbiased, logits-based watermarking steps keyed independently. The authors prove the composition stays unbiased in expectation and analyze how aggregating per-key detectors changes the testing signal. Empirically, they report improved detection and robustness across multiple model families, with little to no degradation in standard text quality metrics. However, I think the paper only studies the effects on standard generation metrics. \n\nThe mains claims are as follows\n- Unbiasedness under composition. If a single reweighting rule is unbiased, the n-fold ensemble remains unbiased when keys are i.i.d.; the proof is a short tower-property induction.\n- Detection scaling. With per-key scores that are (approximately) independent and bounded, the aggregate statistic has mean proportional to n and variance proportional to n, implying SNR ≈ (µ/σ)√n and p-values that improve with n.\n- Trade-off: Under “intersection-at-generation,” the per-step effect shrinks like (εγ)^n, so the exponent in the p-value bound behaves like n(εγ)^2n with an optimum n⋆≈1/[2log(1/(εγ))]."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper cleanly separates two questions: preserving unbiasedness and recovering detection power. Theorem 4.2 (composition stays unbiased) is simple and well scoped; I didn’t find hidden caveats beyond key independence.\n- The SNR and Hoeffding arguments are standard but appropriate for bounded per-key scores (e.g., DiPmark). The text is careful to say the exponential improvement can attenuate in practice.\n- Results include multiple LM families and several corruption settings (paraphrasing, back-translation, token replacements). The tables make it plausible that the ensemble generally helps and that quality remains close to baseline."}, "weaknesses": {"value": "- The SNR and p-value scaling assume per-key independence; the paper notes dependencies via overlapping n-grams and proposes bypassing repeats, but I didn’t see a quantitative study of how correlations impact power. This matters because the theoretical √n gain can compress substantially with even mild correlation. \n\t- Add a small study where you control n-gram overlap or reuse keys to measure empirical correlations among per-key scores and the resulting deviation from √n SNR. This would tell readers when the ideal scaling is trustworthy.\n- The trade-off section is framed for strict intersection; many practitioners would avoid hard intersections and instead add small centered logit shifts per key. It would help to show the same analysis (or an empirical proxy) for a soft/additive design where the (εγ)^n collapse is muted\n- The paper uses an aggregate statistic (one test), which avoids multiple-testing corrections, but it would help to explicitly say how thresholds are set to fix FPR across n (so readers don’t assume Bonferroni is needed).\n- Your theory predicts where detectability should peak.  Show an experiment that sweeps the relevant parameters so readers can see whether the peak occurs where theory says it should.\n- Recent work suggests watermarking can change model behavior beyond detectability/quality tradeoffs: Downstream Trade-offs of a Family of Text Watermarks (Ajith et al., EMNLP 2024) finds 10–20% drops on downstream tasks even for “unbiased” schemes like KGW; WaterJudge (Molenda et al., NAACL 2024) quantifies a detectability–quality trade-off; and Watermarking Degrades Alignment in Language Models (Verma et al., ICLR 2025) shows shifts in truthfulness/safety/helpfulness that can be partially mitigated with an external reward model. The paper would be stronger with a targeted experiment evaluating how ensembling affects alignment-relevant metrics (e.g., reward scores ), and a short discussion of these works to contextualize potential side effects.\n\n\n\n### Nits\n- Define ε and γ at first mention in the trade-off subsection; they appear earlier in the derivation than in the surrounding text.\n- Line 87 rejected-sampling , typo?\n- Line 119 putative text sequence, typo?\n- Line 190 DETECT EFFICIENCY -> Detection Efficiency?"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "W6n2sM0mjc", "forum": "iZ7i2y1YxO", "replyto": "iZ7i2y1YxO", "signatures": ["ICLR.cc/2026/Conference/Submission4681/Reviewer_SgCe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4681/Reviewer_SgCe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4681/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762036072616, "cdate": 1762036072616, "tmdate": 1762917508772, "mdate": 1762917508772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}