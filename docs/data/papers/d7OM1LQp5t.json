{"id": "d7OM1LQp5t", "number": 1218, "cdate": 1756865712111, "mdate": 1758806354897, "content": {"title": "Animer: Generating Editable Videos from Images and Text", "abstract": "Our method combines advanced computer vision techniques with natural language processing to create dynamic video content that maintains high visual fidelity while enabling subsequent editing operations. The proposed framework takes as input a collection of images along with descriptive text prompts, and synthesizes coherent video sequences with realistic motion, lighting, and temporal consistency. Key innovations include a multi-modal encoder that effectively fuses visual and textual information, a temporal generation module that ensures smooth frame transitions, and an editing-aware architecture that preserves video structure for post-generation modifications. Extensive experiments demonstrate that our approach outperforms existing methods in terms of video quality, motion realism, and editability metrics. The generated videos maintain semantic consistency with the input descriptions while allowing users to perform various editing operations such as object manipulation, scene modification, and style transfer without degrading visual quality. This work opens new possibilities for content creation applications in entertainment, education, and digital media production.", "tldr": "", "keywords": ["Video Generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "", "supplementary_material": ""}, "replies": [], "withdrawn": true}