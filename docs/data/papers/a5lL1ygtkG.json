{"id": "a5lL1ygtkG", "number": 19299, "cdate": 1758295179509, "mdate": 1763736829679, "content": {"title": "Divergence-Free Neural Networks with Application to Image Denoising", "abstract": "We introduce a resource-efficient neural network architecture with zero divergence by design, adapted for high-dimensional problems. Our method is directly applicable to image denoising, for which divergence-free estimators are particularly well-suited for self-supervised learning, in accordance with Stein's unbiased risk estimation theory. Comparisons of our parameterization on popular denoising datasets demonstrate that it retains sufficient expressivity to remain competitive with other divergence-based approaches, while outperforming its counterparts when the noise level is unknown and varies across the training data.", "tldr": "", "keywords": ["image denoising", "divergence", "Stein's unbiased risk estimate", "self-supervised learning", "incompressible vector fields"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/26552722fe186e5920f71579298f1e5ebed2d1c5.pdf", "supplementary_material": "/attachment/9611430f8a79b9a1cb2dcdd6ee28d7d0fefde12e.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a theoretically grounded framework for constructing neural networks that are divergence-free for image denoising. The authors propose a resource-efficient parameterization that represents the network output as a structured combination of conservative fields. The proposed divergence-free property is used to simplify SURE loss, avoiding the instability of Monte Carlo approximations and the expressivity limitations of blind-spot methods. The experimental results show that the proposed method achieves better performance against other divergence-based approaches"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The main strength of this paper is its rigorous mathematical analysis.\n+ The method for constructing the sparse, parameterized skew-symmetric matrices and sharing the scalar potential network is reasonable. It successfully makes the theoretical representer theorem computationally tractable for high-dimensional data like images."}, "weaknesses": {"value": "- The experimental evaluation is focused only on divergence-based self-supervised methods (MC-SURE, Noise2Self, UNSURE). The field of self-supervised (or unsupervised single-image) denoising is much broader and has developed significantly. The paper is missing crucial comparisons to other state-of-the-art methods that are not based on SURE, which makes it impossible to assess the true competitiveness of the proposed approach, e.g., [1-3]\n[1] High-quality self-supervised deep image denoising, NIPS 2019\n[2] Iterative denoiser and noise estimator for self-supervised image denoising, ICCV 2023\n[3] Positive2Negative: Breaking the Information-Lossy Barrier in Self-Supervised Single Image Denoising, CVPR 2025\n- The entire framework is demonstrated only for additive white Gaussian noise. While this is a standard setting for theoretical exploration, its practical use is unexplored. The paper itself acknowledges this limitation but does not provide any discussion or preliminary results on how the divergence-free constraint might perform with more complex, realistic noise models (e.g., Poisson-Gaussian, spatially correlated, or signal-dependent noise). The heavy reliance on SURE makes the direct extension non-trivial\n- The proposed parameterization is complex, though more efficient than the full model. This significant overhead could be a barrier to practical adoption, and this trade-off is not sufficiently emphasized in the results"}, "questions": {"value": "- The paper argues that the proposed method is more expressive than blind-spot methods because it doesn't ignore the central pixel. However, blind-spot methods are typically blind to the noise distribution, whereas DivFree's theoretical advantage requires knowing the noise level. Could you discuss this trade-off between expressivity and the need for prior information? How does your method perform if the provided noise level is not very precise"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "za8JEdCEMR", "forum": "a5lL1ygtkG", "replyto": "a5lL1ygtkG", "signatures": ["ICLR.cc/2026/Conference/Submission19299/Reviewer_o8EU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19299/Reviewer_o8EU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839467382, "cdate": 1761839467382, "tmdate": 1762931252502, "mdate": 1762931252502, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common response to all reviewers"}, "comment": {"value": "First of all, we would like to express our sincere gratitude to the reviewers for dedicating their valuable time to the evaluation of our paper and for providing us with constructive feedback. We thank the reviewers for highlighting the **rigorous mathematical analysis** (Reviewers o8EU and 7HQs) of our paper, noting its **excellent soundness and presentation** (Reviewer G54J), and recognizing it as a **solid piece of theoretical contribution** with **excellent coverage of prior work** (Reviewer zsZU). We have revised our paper, taking into account all the comments received. \n\nIn particular, **substantial revisions have been made to address the blind estimation setting**, as suggested by Reviewer 7HQs. We had not realized this point in the initial submission, but **our approach actually offers a key advantage over UNSURE: it naturally accommodates training with unknown random noise level $\\sigma$** (see Section 5 of the revised manuscript for further details). We believe that **this point significantly strengthens our contribution.** Our approach merits a name that better reflects it and we therefore rename DivFree to CENSURE (Concealed and Erratic Noise level with Stein’s Unbiased Risk Estimate). We have also included Figure 1 to more clearly situate our contribution within the broader context.\n\nCriticism from some reviewers focused on the application domain, namely denoising, while our approach could have been applied to other research fields related to physics-informed machine learning such as flow, optical-flow, or magnetic-field problems, where enforcing incompressibility of the estimator is often important in accordance with the fundamental physical laws. We chose denoising as our application mainly because the authors of this paper have expertise in image processing and because our approach fills a gap in self-supervised learning. Moreover, denoising is often considered as a testbed: it is one of the simplest high-dimensional problem but scaling challenges arise quickly. Nevertheless, we agree that extending our method beyond denoising represents an interesting direction for future work. \n\nA few reviewers observed that the present approach focuses exclusively on additive white Gaussian noise. This is because, among unbiased risk estimators for self-supervised denoising, SURE, the estimator for Gaussian noise, is the only one that depends solely on a divergence term, to the best of our knowledge. However, we do not view it as a major weakness as the primary goal of our work is to demonstrate the construction of divergence-free neural networks, with Gaussian denoising serving as an illustrative application. Furthermore, focusing exclusively on Gaussian noise is not particularly restrictive, as recent works [a, b] have shown that deep learning–based Gaussian denoisers could be leveraged in practical real-world scenarios.\n\nFinally, we agree with the reviewers that adding a comparison with non-divergence-based methods was necessary to better assess the competitiveness of the proposed approach. As recommended by Reviewer 7HQs, we added in Table 1 and 2 a comparison with Neighbor2Neighbor (unknown $\\sigma$ setting) and Noise2Score (known $\\sigma$ setting) as baselines. Note, however, that Neighbor2Neighbor is inherently limited to natural images, as it relies on the core assumption that two noise-free neighboring pixels share similar values most of the time. In contrast, divergence-free approaches are more general for denoising problems. We have also added comparisons with Monte Carlo approximation methods (MC-SURE and UNSURE) for another choice of hyperparameter $\\tau$ that we selected based on test-set performance (an oracle hyperparameter), which yielded improved results.\n\nFor further details, please refer to the specific responses to each reviewer comment.\n\n[a] S. Herbreteau and M. Unser. Self-calibrated variance-stabilizing transformations for real-world image denoising. ICCV'25.\n\n[b] T. Li et al. Positive2negative: Breaking the information-lossy barrier in self-supervised single image denoising. CVPR'25."}}, "id": "jPhAfdPU5w", "forum": "a5lL1ygtkG", "replyto": "a5lL1ygtkG", "signatures": ["ICLR.cc/2026/Conference/Submission19299/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19299/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19299/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763737085192, "cdate": 1763737085192, "tmdate": 1763737085192, "mdate": 1763737085192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SURE needs divergence. To get rid of the divergence, they introduce a constant divergence field S_DC (Eqn 10). Section 4 is about how to generate such a divergence field. The core trick is by means of a universal approximation (Theorem 1). Realization is given in Section 4.2."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Solid contribution.\n\nThe coverage of the prior work is excellent.\n\nIntuition of the field construction can be done better. But basically I get the idea that they want to ensure symmetry so that the field is valid (Eqn. 13 and Eqn 14).\n\nEmpirical results are okay. This is a piece of theoretical contribution."}, "weaknesses": {"value": "This is not a criticism but a general comment. Will not contribute to my judgment of the paper.\n\nSURE is a proxy for MSE, which assumes that the underlying noise is iid Gaussian. But if I know that the noise is iid Gaussian, I can literally just simulate training data and train my model in a supervised way. The cost of doing that is null. Even if we say that the noise level is unknown, worst case I just train a larger model with more data augmentation. So I have a hard time to convince myself that SURE is the right way to go. \n\nI can appreciate unsupervised learning, but it must be some bizarre unknown noise type that I cannot easily calibrate and know from my camera. But for this case, SURE doesn't seem to be the right approach to go.\n\nSo I am not sure about the utility down the road. Perhaps denoising is not a good showcase?? No need to address this in the rebuttal. Just some thoughts to share with the authors."}, "questions": {"value": "No major concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "udrJF8ObgG", "forum": "a5lL1ygtkG", "replyto": "a5lL1ygtkG", "signatures": ["ICLR.cc/2026/Conference/Submission19299/Reviewer_zsZU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19299/Reviewer_zsZU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923929383, "cdate": 1761923929383, "tmdate": 1762931251682, "mdate": 1762931251682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new class of divergence-free denoisers by interpolating the constraints of two prior classes of divergence-free denoisers and also a method for constructing denoisers that belong to the new class directly, without the need to use additional loss functions during training like prior methods. The authors show improved performance with known noise levels, and claim this is due to closer adherence to the divergence-free constraint, as well as comparable performance in the unknown noise level setting."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The idea of examining a class of objects (in this case, denoisers) in between two other existing classes in the literature is very well motivated. I could not find any issues with the theory, which is built on existing solid results in a reasonable way. The results also seem consistent with the understanding of the method presented in the paper, namely that in the known noise-level regime their more constrained method achieves higher performance than the less constrained baseline which does not enforce zero divergence strictly."}, "weaknesses": {"value": "I'm not sure about the resource efficiency claims. It seems that mostly the case rests on using far fewer terms than necessary as a basis to represent the divergence-free denoiser. I think the paper would be stronger if the authors could show what the exact influence of the number of components, K', is on the denoising performance and how close their denoiser is to being truly divergence free. My understanding of the theory is that it only guarantees a divergence-free field if the number of basis terms is n(n+1)/2, where n is input size, but far fewer basis terms are used for the sake of computational tractability. Additionally, the authors should compare the runtime of the various methods, since it appears that their denoiser requires effectively K'+1 network evaluations, combining forward and backward passes."}, "questions": {"value": "How does the following depend on K'?\n- denoising performance\n- runtime\n- divergence \n\nI would be willing to upgrade my score if the authors could provide a more thorough empirical validation of their method, in particular with respect to the major approximation that causes deviations from theory, the number of basis components of their divergence-free denoiser field."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Toercmx0QB", "forum": "a5lL1ygtkG", "replyto": "a5lL1ygtkG", "signatures": ["ICLR.cc/2026/Conference/Submission19299/Reviewer_G54J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19299/Reviewer_G54J"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927162657, "cdate": 1761927162657, "tmdate": 1762931251330, "mdate": 1762931251330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a **Divergence-Free Neural Network (DivFree)** designed for self-supervised Gaussian image denoising.  \nThe network is parameterized with skew-symmetric bases so that ∇·f(x)=0 holds exactly, thereby eliminating the need for Monte-Carlo divergence estimation used in SURE-based losses.  \nThe authors claim this leads to more stable training and improved performance compared to MC-SURE and UNSURE.  \nExperiments are limited to grayscale Gaussian noise (σ=15–50), with an additional “unknown σ” case that is not truly blind."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Mathematically consistent derivation of divergence-free vector fields using a skew-symmetric representation.  \n- Conceptually simple idea that connects physical conservation laws with SURE-based denoising.  \n- Reduces gradient variance by removing stochastic divergence estimation."}, "weaknesses": {"value": "- **Misleading “unknown σ” claim.** The model is trained with a fixed σ and only tested on slightly different noise levels; there is no random-σ training or blind estimation, so it cannot handle unknown noise.  \n- **Extremely narrow scope.** All experiments use grayscale Gaussian noise. There are no color image... The method is not validated on **Poisson**, **Gamma**, or real-world datasets, although its principle directly relates to unbiased risk estimators like **PURE (Poisson Unbiased Risk Estimator)**.  \n- **High computational cost.** The paper itself states that inference is about **9× slower** than DRUNet due to repeated gradient evaluations for enforcing divergence-free constraints.  \n- **Limited novelty.** The method merely re-parameterizes the denoising backbone to set div(f)=0, optimizing the same SURE objective as MC-SURE. The observed differences stem from reduced variance but increased structural bias.  \n- **Lack of generality.** Divergence-free constraints could naturally apply to flow, optical-flow, or magnetic-field problems, yet the paper confines itself to toy Gaussian denoising.\n\n## Minor\n- No visualization verifying that learned vector fields are actually divergence-free.  \n- Bias–variance trade-off introduced by the constraint is never quantified.  \n- Comparison baselines (Noise2Score, Blind2Unblind, Neighbor2Neighbor, diffusion-based denoisers) are missing."}, "questions": {"value": "1. How is the “unknown σ” setting defined? Was σ randomly sampled during training or fixed to one value?  \n2. Could the same architecture be evaluated on **Poisson denoising** using **PURE** to demonstrate generality beyond Gaussian SURE?  \n3. Why not apply divergence-free constraints to other tasks (e.g., optical flow, physics-based fields) where this property is physically meaningful?  \n4. Does enforcing div(f)=0 introduce measurable bias compared to the true SURE optimum?  \n5. Given the reported 9× inference cost, is the stability improvement practically worthwhile?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zHqIyq9CKT", "forum": "a5lL1ygtkG", "replyto": "a5lL1ygtkG", "signatures": ["ICLR.cc/2026/Conference/Submission19299/Reviewer_7HQs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19299/Reviewer_7HQs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762144943301, "cdate": 1762144943301, "tmdate": 1762931250918, "mdate": 1762931250918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}