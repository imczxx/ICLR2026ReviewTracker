{"id": "3iCEbbYIjV", "number": 2034, "cdate": 1756979133281, "mdate": 1759898172942, "content": {"title": "MoLD: Fine-Grained Multimodal Risk Assessment via Dynamic Analysis Weights", "abstract": "Current multimodal AI safety detection often lacks granularity, interpretability, and adaptability. To address these limitations, we introduce **MoLD** (Mixture of LoRA Detectors), a framework that uniquely assesses risk by dynamically analyzing the interplay of multiple Low-Rank Adaptation (LoRA) module weights. This approach yields fine-grained, interpretable assessments beyond binary classification, enables concurrent **multi-risk detection**, maintains robustness on long-sequence data, and supports low-cost modularity. Impressively, MoLD demonstrates state-of-the-art (**SOTA**) performance on textual and visual benchmarks while achieving exceptional **few-shot** learning, reducing data requirements by over **90\\%**. Thus, MoLD provides a powerful, scalable, and data-efficient path to robust, interpretable risk assessment in large-scale multimodal AI systems.", "tldr": "A novel framework for interpretable and efficient multimodal risk assessment via dynamic analysis of multiple LoRA module weights", "keywords": ["Large Model", "Multimodal", "Dynamic Weight Analysis", "Few-shot", "Cross-scale", "Risk Assessment", "Interpretability"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8194d843fd9e04958cc9cf8c4c85e9a3a8228cda.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces MoLD (Mixture of LoRA Detectors), a framework for fine-grained multimodal risk assessment that dynamically analyzes the weights of multiple LoRA modules to identify nuanced risk patterns beyond binary classification.\nBy optimizing inter- and intra-module weights, MoLD quantifies how textual and visual content aligns with different risk dimensions, enabling interpretable and concurrent multi-risk detection.\nExperiments show that MoLD achieves state-of-the-art accuracy in text and image safety detection while requiring over 90% less training data than traditional models.\nOverall, MoLD provides a scalable, data-efficient, and interpretable approach to robust multimodal AI safety assessment."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "+ The idea of using LoRA weight analysis to detect unsafe contents is cool. It is inspired from MoE. It can detect multiple risks together.\n+ Performance is good, especially on NLP tasks."}, "weaknesses": {"value": "- Presentation of this paper should be largely improved.\n- The set of risk dimensions and their corresponding “extreme” categories appear to be pre-defined and fixed (e.g., three textual dimensions with seven extremes, and two visual dimensions with six extremes). The paper does not clearly justify why these specific dimensions and extremes were chosen, nor does it discuss how the framework would generalize to other or newly emerging risk dimensions. This design choice limits the perceived flexibility and general applicability of the proposed approach.\n- The paper relies on GPT-4o–generated synthetic data without human verification. This raises concerns about data authenticity and potential stylistic divergence from real-world online discourse. Consequently, the model may inherit generator-specific biases and its external validity on naturally occurring data remains uncertain.\n- The choice of baselines is too limited and not representative of the current state of the field. In the text domain, the evaluation omits frontier LLMs such as GPT-4o, Gemini-2.5, and Claude-4, which are the most relevant comparators for assessing modern few-shot and safety-oriented performance. Similarly, for the visual domain, the study should include stronger multimodal baselines such as GPT-4o, Gemini-2.5, Claude-4, Qwen-VL, and InternVL to provide a fair and comprehensive comparison.\n- The theoretical motivation for using skewness as the primary metric to quantify intra-module bias is not sufficiently justified. While the paper empirically shows its effectiveness, it remains unclear why skewness is inherently suitable for representing directional tendencies of LoRA weight distributions. Alternative statistical measures, such as entropy (to capture uncertainty) or kurtosis (to capture tail concentration), might offer comparable or even superior interpretability. The lack of theoretical comparison or ablation across such alternatives weakens the methodological grounding of this design choice.\n- The paper does not include an ablation study or sensitivity analysis on the threshold selection (e.g., θ_w and θ_SK), which are critical parameters for determining the system’s detection sensitivity and specificity. Without this analysis, it is difficult to assess how robust MoLD’s performance is to variations in these hyperparameters.\n- The paper lacks sufficient transparency and discussion regarding the visual dataset construction. Specifically, as stated in Lines 325–326 (“For ‘Cartoon’ and ‘Realistic’ categories, 100 images and 50 short videos per category were collected from public online sources by the authors”), it is unclear how these samples were selected, whether they introduce potential source or cultural biases, and how such biases might affect the model’s evaluation and generalization. A more detailed description of the data collection process and mitigation strategies for bias would strengthen the work."}, "questions": {"value": "1. Can the MoLD work on multimodal inputs (i.e., having texts and images at the same time)?\n2. Is D_{content} text/image or the embedding of text/image?\n3. Should discuss the similarity and difference with MoE.\n\nMinor suggestions and typos:\n1. Missing spaces before many citations. For example, Line 036: “knowledge sharingSingh et al. (2022a),” Line 038: “hate speech and harassmentGarg et al. (2023).” There are many of that and I just list very few of them. Please proofread the whole paper for the format issues.\n2. Missing spaces before left brackets. Line 112: “Inter-Module Weights(w_i),” Line 118: “Layer-Specific Intra-Module Weights(w^k_i,l)”\n3. Should use \\citep instead of \\cite: Line 307-313, Line 325, Line 346-347, Line 377."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1CAVOD2vx4", "forum": "3iCEbbYIjV", "replyto": "3iCEbbYIjV", "signatures": ["ICLR.cc/2026/Conference/Submission2034/Reviewer_wqJx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2034/Reviewer_wqJx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761253325963, "cdate": 1761253325963, "tmdate": 1762915998804, "mdate": 1762915998804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MoLD, a framework for multimodal risk detection. It freezes a base model and attaches several risk-specific LoRA adapters. During inference, the system optimizes small scalar weights to determine how each adapter contributes to interpreting an input. By analyzing these dynamic weights—particularly using a modified skewness measure—MoLD generates fine-grained and interpretable risk labels. The framework supports text, image, and video inputs, offering efficient, scalable, and concurrent detection of multiple risks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. MoLD introduces a new perspective on risk detection, which analyzes dynamic LoRA weight behavior rather than model outputs. This weight-centric approach is conceptually original and can generalize across modalities.\n2. MoLD achieves strong results with very limited data by reusing a frozen base model and adding small LoRA modules.\n3. Unlike traditional models that handle one risk per run, MoLD can analyze multiple risk dimensions in a single inference pass, improving both speed and scalability for real-world tasks."}, "weaknesses": {"value": "1. The evaluation relies mainly on custom and partially synthetic datasets, without additional validation on established benchmarks. While this setup effectively demonstrates MoLD’s internal performance, it leaves some uncertainty about how well the approach would generalize to broader, real-world contexts.\n2. The paper claims that combining multiple pre-trained LoRAs with dynamic weighting improves specificity, but it provides no ablation comparing this to training a single multi-task LoRA. Without such evidence, the benefit of the proposed fusion strategy remains unverified.\n3. The captions for Figures 1 and 2 are not self-contained, making it difficult to understand the figures without referring back to the main text. Clearer, standalone captions would improve readability and interpretability."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "QS2Fgfrdgu", "forum": "3iCEbbYIjV", "replyto": "3iCEbbYIjV", "signatures": ["ICLR.cc/2026/Conference/Submission2034/Reviewer_Fhdu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2034/Reviewer_Fhdu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761536503882, "cdate": 1761536503882, "tmdate": 1762915998228, "mdate": 1762915998228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MoLD (“Mixture of LoRA Detectors”), which freezes a base model and many LoRA adapters, then optimizes per-input scalar weights across “modules” (risk themes) and their “extreme-tendency” sub-LoRAs during inference to produce fine-grained risk labels.The method integrates LoRAs via a hierarchical weighting, performs on-the-fly weight optimization by minimizing a task loss on the input, and converts the resulting weights into risk decisions using a bespoke skewness-based statistic with thresholds. Claims include SOTA performance, strong few-shot data efficiency (>90% reduction), long-sequence robustness, and parallel multi-risk detection across text, images, and videos."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. A unifying weight-analysis perspective for multi-risk scoring and an attempt to turn LoRA composition into interpretable diagnostics (inter- vs intra-module weights).\n\n2. Clear, modular presentation of the components (integration equation, optimization objective, histogram/skewness analysis) that could inspire future diagnostics work."}, "weaknesses": {"value": "1. Novelty over existing LoRA-composition / MoE literature is unclear. The core mechanism—combining multiple LoRAs with learned mixture weights; here, the novelty is framed as analyzing the learned weights for risk. However, the paper does not rigorously compare against established composition/routing baselines or show why the proposed skewness statistic and two-stage thresholds are preferable to standard discriminative heads trained on features.\n\n2. Evaluation design is fragile and partly synthetic: Several “risk themes” (e.g., Pro-Black, Meticulous, Careless) are synthetically generated by GPT-4o and then filtered by GPT-4o as the assessor, which risks circularity and bias (the same or similar models defining and judging the phenomenon). The paper does not quantify annotator agreement, inter-rater reliability, or distributional realism; nor does it examine failure cases or societal risks from synthetic curation.\n\n3. The paper optimizes per-input weights by minimizing the model’s own task loss on the same content without external labels at inference. It is unclear how this objective is well-posed for risk detection.\n\n4. Most reported metrics are accuracy/F1 (Tables 2, 4–7) with small test sets; there is no emphasis on AUROC/AUPR, FPR@TPR (e.g., FPR95), risk-coverage, or calibration—the standard suite for detection and safety. Safety-oriented multimodal baselines are limited, and it is unclear whether comparisons are conducted on identical data/label protocols.\n\n5. Although claims include long-sequence robustness and parallel risk detection, the paper lacks systematic shift experiments.\n\n6. The proposal of the method is not well-presented or motivated."}, "questions": {"value": "1. Please revise the paper on motivation and inspiration for the proposed method and its novelty beyond standard LoRA and MoE literature.\n\n2. Experimental setup should be refined so as to fully support the claims. For example, using other LLMs to synthesize the dataset.\n\n3. More baselines or appropriate methods should be included, and also some related works can be included."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CrA6MxU2Bq", "forum": "3iCEbbYIjV", "replyto": "3iCEbbYIjV", "signatures": ["ICLR.cc/2026/Conference/Submission2034/Reviewer_cjaf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2034/Reviewer_cjaf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916402823, "cdate": 1761916402823, "tmdate": 1762915997913, "mdate": 1762915997913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}