{"id": "FnF3UjiN11", "number": 6828, "cdate": 1757997153507, "mdate": 1759897891092, "content": {"title": "Composition-Grounded Instruction Synthesis for Visual Reasoning", "abstract": "Pretrained multi-modal large language models (MLLMs) demonstrate strong performance on diverse multimodal tasks, but remain limited in reasoning capabilities for domains where annotations are difficult to collect. In this work, we focus on artificial image domains such as charts, rendered documents, and webpages, which are abundant in practice yet lack large-scale human annotated reasoning datasets. We introduce COGS (COmposition-Grounded instruction Synthesis), a data-efficient framework for equipping MLLMs with advanced reasoning abilities from a small set of seed questions. The key idea is to decompose each seed question into primitive perception and reasoning *factors*, which can then be systematically recomposed with new images to generate large collections of synthetic question-answer pairs. Each generated question is paired with subquestions and intermediate answers, enabling reinforcement learning with factor-level process rewards. Experiments on chart reasoning show that COGS substantially improves performance on unseen questions, with the largest gains on reasoning-heavy and compositional questions. Moreover, training with a factor-level mixture of different seed data yields better transfer across multiple datasets, suggesting that COGS induces generalizable capabilities rather than dataset-specific overfitting. We further demonstrate that the framework extends beyond charts to other domains such as webpages. We release the code and data at https://cogsynthesis.github.io.", "tldr": "We propose COGS (COmposition-Grounded instruction Synthesis), a data-efficient framework compositionally generate reasoning data to equip MLLM with complex visual reasoning in Chart and WebGUI understanding tasks.", "keywords": ["Compositional data synthesis", "compositional generalization", "visual reasoning", "chart understanding", "Visual language model"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c9ee88dd302bbae48359d9ab3792bcecfdd0cd1a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes COGS (COmposition-Grounded instruction Synthesis), a three-stage pipeline to improve VLMs’ reasoning in artificial image domains (charts, rendered documents, webpages). Stage 1 decomposes a seed set of questions into interpretable perception and reasoning factors; Stage 2 recomposes sampled factors with new images to synthesize new questions; Stage 3 fine-tunes VLMs using GRPO with the generated questions. Experiment demonstrates the effectiveness of COGS on ChartQAPro and MMC-Bench."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe pipeline of COGS is clear and easy to follow. The method is intuitive.\n\n2.\tFactor-level sub-questions make the supervision more transparent and are practical for error analysis."}, "weaknesses": {"value": "1.\tEvaluation protocol risks leakage. The use of 33% of the test set as seeds violates the test-only usage and can tune the pipeline to the test distribution even without answer leakage. I checked the ChartQAPro benchmark, and it has 1341 charts for 1948 questions. Different questions may target the same image chart; this makes image-level leakage likely.\n\n2.\tThe process reward uses LLM-as-a-judge, which can cause significant training overhead. The paper should report efficiency statistics"}, "questions": {"value": "Please see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8LbqS3GM2A", "forum": "FnF3UjiN11", "replyto": "FnF3UjiN11", "signatures": ["ICLR.cc/2026/Conference/Submission6828/Reviewer_dvz5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6828/Reviewer_dvz5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760771872084, "cdate": 1760771872084, "tmdate": 1762919090350, "mdate": 1762919090350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes COGS (Composition-Grounded Instruction Synthesis), a data-efficient pipeline to endow MLLMs with visual reasoning skills in artificial image domains like charts, documents, webpages. The method (i) decomposes a small set of seed questions into atomic perception/reasoning factors, (ii) recomposes sampled factors with new images to synthesize QA pairs with sub-questions and sub-answers, and (iii) fine-tunes an MLLM via GRPO using process rewards computed at the factor level.  Experiments on ChartQAPro and VisualWebBench show consistent gains over strong open baselines, ablations on mixing factor pools across datasets, reward model, factor break down further demonstrate the effectiveness and scalability of the method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear, modular idea with practical upside. Factorizing seed questions then reusing those factors across unlabeled images is straightforward and domain-agnostic. The pipeline is well-motivated and broadly applicable.\n2. Process reward design with both theoretical and experimental justification. The ProcessRM-max objective is motivated by a simple but persuasive order-preservation argument and turns out to be effective.\n3. Transfer via data-level and factor-level mixing. The author provides a valid ablation on generalization over mixture of datasets, indicating the method captures reusable structure, not just surface patterns."}, "weaknesses": {"value": "**1. Positioning in prior data-synthesis work is thin.**\n\n The introduction and related work don’t really situate the paper within the broader line of data-synthesis methods that first generate sub-questions/functions and then recombine them into new examples. It would help to spell out what’s borrowed vs. what’s new, why existing approaches fall short for this setting, and how the paper’s factorization addresses those limits. Please cite a few representative strands to make the attribution explicit. See [1-3].\n\n**2. Comparisons skip broader synthesis and RL frameworks.**\n\n The experiments compare against chart/GUI-specific generators, but there are notable data-synthesis pipelines in RL and process-supervised training that should be part of the picture. Even a small, controlled head-to-head with one or two representative frameworks (same base model, same budget) would clarify what the proposed method adds beyond existing synthesis strategies. Some works can be found in [4-5].\n\n**3. Reliability of synthetic sub-questions/answers isn’t audited.**\n\nDecompositions can be inconsistent or non-minimal, and recomposition relies on an LLM to produce sub-answers. The order-preserving argument assumes a particular noise structure, but we don’t see concrete diagnostics. Although the results demonstrate the effectiveness of the pipeline, we still need more diagnostics like sub-answer error rates; factor-label drift across seeds/images; sensitivity of GRPO to sub-reward noise. Right now, reliability is assumed rather than demonstrated.\n\n**4. Model ablation is narrow.**\n\nResults are limited to Qwen2.5-VL-7B. It’s unclear whether the gains persist across families (and weaker/stronger baselines) or scale with model size. A light grid—e.g., a smaller and a larger open model, plus a different family—would make the real-world applicability much clearer.\n\n[1]. Self-Instruct: Aligning Language Models with Self-Generated Instructions\n\n[2]. WizardLM: Empowering large pre-trained language models to follow complex instructions\n\n[3]. Automatic Instruction Evolving for Large Language Models\n\n[4]. ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search\n\n[5]. Self-Rewarding Language Models"}, "questions": {"value": "1. Decomposition quality: What is the inter-run agreement for factor labels/sub-questions on the same seed? Any filtering or self-consistency checks?\n\n\n2. Mixture strategy: In factor-level mixing, how often do cross-dataset factors actually co-occur in recomposed questions? Can you provide some domain drift failure cases?\n\n\n3. Factor generation: When MLLM decomposes the main question and generate the subquestion with the Factor, how to make sure the number of the generated Factor is within a reasonable range?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OHPsVmIxre", "forum": "FnF3UjiN11", "replyto": "FnF3UjiN11", "signatures": ["ICLR.cc/2026/Conference/Submission6828/Reviewer_jHKn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6828/Reviewer_jHKn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761662014252, "cdate": 1761662014252, "tmdate": 1762919089661, "mdate": 1762919089661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents COGS, a framework for augmenting the reasoning capabilities of multimodal large language models (MLLMs) in domains lacking large annotated datasets, such as charts and webpages. The key idea is to decompose seed questions into primitive factors, and then systematically recompose these factors with new images to generate diverse, compositional training data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "COGS factorizes a small seed set into reusable perception/reasoning factors, recomposes them with new images to create diverse, grounded QA pairs , and uses the factor structure to supply process-level rewards, yielding richer supervision than final-answer matching alone."}, "weaknesses": {"value": "1. The authors state that the framework *does not require ground-truth subquestion answers*, but this appears to hold only for the *seed set*: during data synthesis, each sample includes LLM-generated sub-answers that are then used for process-level supervision in RL. If these pseudo-labels are noisy, errors may accumulate and be amplified through factor-level recomposition.\n\n2. The manuscript does not isolate the factor pool’s *direct* contribution, emphasizing cross-dataset ablations instead. Clarifying its substantive, incremental value, and distinguishing it from direct decomposing/recomposing method, would make the contribution more transparent.\n\n3. The title is *COMPOSITION-GROUNDED **INSTRUCTION SYNTHESIS**  FOR **VISUAL REASONING***, yet the manuscript does not clearly foreground *instruction synthesis* and *visual reasoning*; it predominantly centers on chart QA. The related-work section likewise emphasizes task descriptions rather than surveying these two threads. Moreover, while the introduction mentions tables and documents, the experiments are confined to a relatively narrow setting. Chart QA can serve as a proxy for visual reasoning, but the heavy focus on charts leaves the broader visual-reasoning aspect underdeveloped.\n\n4. The approach is mainly applicable when a task admits a reliable decomposition into subquestions; for complex cases that are not readily decomposable, its utility is limited.\n\n5. Minor editorial issues: on lines 71 and 205, ***Grouped Rollout Policy Optimization*** should be ***Grouped Relative Policy Optimization***; on line 184, the enumerator should be ***(i)***."}, "questions": {"value": "1. Does the manuscript describe any validation mechanism for the generated subquestion–answer pairs to prevent intermediate errors from propagating and compounding through the pipeline?\n\n2. Can the authors provide empirical results or error analyses examining the quality/diversity of the generated synthetic data? \n\n3. Is there any analysis of how the choice/size of the initial seed set $\\mathcal{Q}^0$ affects performance or coverage? For instance, how does model generalization degrade when the seed is minimal or unrepresentative?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PiLiIC0AwT", "forum": "FnF3UjiN11", "replyto": "FnF3UjiN11", "signatures": ["ICLR.cc/2026/Conference/Submission6828/Reviewer_ceC7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6828/Reviewer_ceC7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831026234, "cdate": 1761831026234, "tmdate": 1762919089135, "mdate": 1762919089135, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces COGS, a data-efficient framework for enhancing visual reasoning capabilities in multimodal large language models  for artificial image domains like charts and webpages. The key innovation is decomposing seed questions into primitive perception and reasoning \"factors,\" then systematically recombining these factors with new unlabeled images to generate synthetic training data. Each generated question includes subquestions and intermediate answers, enabling reinforcement learning with process-level rewards. The authors evaluate COGS primarily on chart reasoning (ChartQAPro, MMC-Bench) and webpage understanding (VisualWebBench), demonstrating substantial improvements over baseline models, with particularly strong gains on reasoning-heavy and compositional questions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- Novel compositional approach: The factor decomposition and recomposition strategy is intuitive and well-motivated, providing a principled way to scale up training data from limited seed examples while maintaining diversity and complexity.\n\n- Strong empirical results: COGS achieves meaningful improvements across multiple benchmarks (52.02% on ChartQAPro vs. 47.36% base model; 88.04% on VisualWebBench vs. 85.65% base), outperforming both general-purpose models and domain-specific baselines.\n\n- Transferability across datasets: The factor-level mixture experiments (Section 4.1.2) demonstrate that COGS induces generalizable reasoning capabilities rather than dataset-specific overfitting, with factor-level mixing outperforming data-level mixing.\n\n- Theoretical contribution: Proposition 3.1 provides valuable theoretical insight into why ProcessRM-max preserves policy ordering while ProcessRM-sum does not, backed by empirical validation.\n\n- Comprehensive evaluation: The paper includes thorough ablations (reward models, question complexity, factor types) and extends beyond charts to webpages, demonstrating generalizability."}, "weaknesses": {"value": "- The paper focuses exclusively on artificial image domains (charts, webpages). It's unclear whether this approach would transfer to natural images or other multimodal reasoning tasks. The restriction to domains with \"abundant unlabeled images\" may limit applicability.\n\n- Dependency on high-quality decomposition: The entire framework relies on an MLLM's ability to accurately decompose questions into factors. The paper doesn't thoroughly analyze decomposition quality or failure modes. What happens when decomposition is incorrect or incomplete?\n\n- Limited baseline comparisons: While the paper compares against several data synthesis approaches, it doesn't compare against other compositional reasoning methods or more sophisticated prompting techniques (e.g., self-consistency, tree-of-thoughts)."}, "questions": {"value": "Can factors learned from one domain (e.g., charts) transfer to another domain (e.g., webpages) without redecomposition? Would a shared factor pool improve multi-domain performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8xcO7kkiE2", "forum": "FnF3UjiN11", "replyto": "FnF3UjiN11", "signatures": ["ICLR.cc/2026/Conference/Submission6828/Reviewer_hVuu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6828/Reviewer_hVuu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762336300991, "cdate": 1762336300991, "tmdate": 1762919088730, "mdate": 1762919088730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}