{"id": "4o7Z0DDCEO", "number": 22670, "cdate": 1758334278898, "mdate": 1759896853183, "content": {"title": "Input-Adaptive Bayesian Model Averaging", "abstract": "This paper addresses prediction problems with multiple candidate models, where the goal is to combine their outputs. This task is especially challenging in heterogeneous settings, where different models may be better suited to different inputs. \nWe propose Input-Adaptive Bayesian Model Averaging (IABMA), a Bayesian method that assigns model weights conditional on the input.\nIABMA employs an input-adaptive prior, and yields a posterior distribution that adapts to each prediction, which we estimate via amortized variational inference.\nWe derive formal guarantees for its performance relative to any single predictor selected per input, and evaluate IABMA across regression and classification tasks, studying data from personalized cancer treatment, credit-card fraud detection, and UCI datasets. IABMA consistently delivers more accurate and better-calibrated predictions than both non-adaptive baselines and existing adaptive methods.", "tldr": "We propose a Bayesian framework for adaptive model averaging, casting it as inference with an input-adaptive prior and amortized variational posterior, enabling input-specific weighting", "keywords": ["Model averaging", "Variational inference", "Adaptivity"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1940dce11f1bc248bf1f8bc502225531dc3cd6e8.pdf", "supplementary_material": "/attachment/5f9adfea03a1da57f4900d0a81a207ca1b127d11.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge/difficulty of combining multiple predictive models, which is especially difficult in heterogeneous settings where different models may be optimal for different inputs. Standard model averaging uses a single set of global weights, which performs poorly in these scenarios. To solve this, the authors propose Input-Adaptive Bayesian Model Averaging (i.e. the IABMA method), a Bayesian method that calculates specific weights for each model conditional on the input data $x$.\n\nThe IABMA method models the choice of the best model as a random selector function g that depends on the input x. It uses an input-adaptive prior and then calculates a posterior distribution over which the model is most plausible given the training data ($D$) and the specific input $x$. This posterior distribution, estimated using amortized variational inference, directly gives the optimal, input-specific weights for combining the models. The authors derive formal guarantees for the performance of IABMA and then evaluate it on regression and classification tasks, including popular UCI datasets such as personalized cancer treatment and fraud detection. The results demonstrate that IABMA consistently delivers competitive performance to existing non-adaptive  and adaptive methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "One of the main strengths of the paper is that it is clearly written and structured. The authors lay out their argument in a straightforward manner, making the text and the core concepts of the proposed IABMA method relatively easy to follow.\n\nThe paper addresses an interesting and relevant problem in model averaging, particularly for heterogeneous data where input-specific models are needed. The proposal itself is presented in a \"clean\" and simple probabilistic formulation. The paragraphs are well written, the theory is well motivated and the flow of the paper is clear. The intuitive example in section 3.1 as well as the actual taking care of the problem (e.g. how to fit the variational distributions or how to optimize the KL divergence) are well formulated and explained.\n\nAdditionally, the authors provide motivation for their framework by connecting it to practical examples like personalized medicine and fraud detection. They also include some theoretical development to support their method, which helps to frame the potential benefits of the approach."}, "weaknesses": {"value": "While the core idea of the paper is clean and simple, this simplicity in my opinion necessitates a much stronger and elaborate set of experiments to fully justify its contribution. The initial motivation and theory are strong, but the paper ultimately falls short due to a weak and insufficiently comprehensive evaluation. This gap between the promising setup and the empirical evidence was a bit disappointing.\n\nIn my opinion, the existing experiments are not presented in a convincing manner. For instance, Figures 2 and 3 take a significant amount of space to present results that could be summarized more efficiently in a small table, especially since the paper has some space to spare. More importantly, it is not clear from the results that the authors have obtained if the performance differences between the proposed method and the baselines is statistically significant (it is not readable from the plots). The comparison to other adaptive competitors, such as Mixture of Experts for example, feels underdeveloped. In many cases, the results do not show a lcear advantage for IABMA over others, and the authors missed an opportunity to properly articulate why one would choose their method over existing, well-established alternatives.\n\nFurthermore, the scope of the analysis is quite limited. The authors only consider a small set of candidate models (e.g., four regressors), which leaves several important questions unanswered. A more thorough evaluation could have investigated:\n1.  How the method's performance scales with a larger number of candidate models.\n2.  How the method performs when several predictors yield similar (or maybe redundant) performance\n3.  The magnitude of the performance gain in a setting specifically designed to be highly heterogeneous, where input-adaptive averaging would be expected to clearly outperform input-agnostic methods.\n\nFinally, the paper could be strengthened by doing some rewriting of its analyses and its context. The qualitative analysis in Appendix B.1, for example, is quite interesting and a portion of it should have been included in the main text to provide better insight and overview of the performance. Given the community's shift toward larger datasets, the paper would also benefit from at least one or two analyses on a larger-scale benchmark to demonstrate its relevance and scalability. Also, there is no discussion of computational cost; it is unclear if fitting the amortized variational posterior is more or less costly than maximizing the likelihood in methods like MoE, or how the methods compare in terms of speed."}, "questions": {"value": "Please see weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aPO9UwTckW", "forum": "4o7Z0DDCEO", "replyto": "4o7Z0DDCEO", "signatures": ["ICLR.cc/2026/Conference/Submission22670/Reviewer_E3vv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22670/Reviewer_E3vv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914364717, "cdate": 1761914364717, "tmdate": 1762942329211, "mdate": 1762942329211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors study the interesting and important question of how to adaptively combine multiple prediction models, where here “adaptively” refers to a weighted mixture of the models with weights that depend on the test-point input covariates. The goal is both to improve overall performance relative to an individual model, as well as to improve “personalization,” meaning that the best model is used for a given input. The main claimed contribution is to present a *Bayesian* approach to adaptive model averaging--to contrast their contribution from prior work, the authors claim that “Previous adaptive approaches (see Section 1.1) addressed the task of specifying the adaptive weights $\\alpha_j(x)$ from a *frequentist* point of view[...]” (emphasis added). The authors claim a theoretical guarantee that compares the proposed approach to the performance of the individual models, and they present experiments on simulated data, as well as on cancer drug-response prediction and credit-card fraud detection."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "As mentioned, the authors study an important problem of how to best personalized combined models, that is, by taking an input-adaptive approach to model averaging. The approach seems reasonable, well-motivated, and empirical results appear okay. The theoretical analysis seems okay too, although I didn’t yet check it carefully due to the main weakness (see next section), for which is the main factor influencing my evaluation."}, "weaknesses": {"value": "**Originality/significance:** In my view, the main weakness of the paper is that it does not make clear if/how the proposed methods differ from or improve on prior approaches to input-adaptive model averaging, including Bayesian approaches. In particular, there are at least two large categories of methods that I think at least the related work, and probably also the experiments section, should compare against more thoroughly: (1) mixture-of-experts models and (2) dependent Bayesian mixture models (eg, dependent Dirichlet mixture models or even input-dependent Gaussian mixture models). \n\nFor example, in the related work, the authors claim “Few methods assign input-dependent weights” before only providing one citation on mixture-of-experts, despite this area having a very large literature on data-dependent model averaging. It’s also not clear to me why MoE is not considered Bayesian. Eg, the authors could consult the following review papers:\n- Masoudnia, S., & Ebrahimpour, R. (2014). Mixture of experts: a literature survey. Artificial Intelligence Review, 42(2), 275-293.\n- Mu, S., & Lin, S. (2025). A comprehensive survey of mixture-of-experts: Algorithms, theory, and applications. arXiv preprint arXiv:2503.07137.\n- Yuksel, S. E., Wilson, J. N., & Gader, P. D. (2012). Twenty years of mixture of experts. IEEE transactions on neural networks and learning systems, 23(8), 1177-1193.\n\nRegarding dependent Bayesian mixture models, the authors could consult the following reviews, in particular with an eye to methods that are “covariate-dependent” mixture models:\n- Barcella, W., De Iorio, M., & Baio, G. (2017). A comparative review of variable selection techniques for covariate dependent Dirichlet process mixture models. Canadian Journal of Statistics, 45(3), 254-273.\n- Quintana, F. A., Müller, P., Jara, A., & MacEachern, S. N. (2022). The dependent Dirichlet process and related models. Statistical Science, 37(1), 24-41."}, "questions": {"value": "Could the authors please clarify how the proposed methods relate to existing literature on mixture of experts and/or input/covariate-dependent Bayesian mixture models? This seems necessary to properly understanding the paper’s contribution, and I didn’t find this sufficiently discussed in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fhy25hneoN", "forum": "4o7Z0DDCEO", "replyto": "4o7Z0DDCEO", "signatures": ["ICLR.cc/2026/Conference/Submission22670/Reviewer_2n4B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22670/Reviewer_2n4B"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932819004, "cdate": 1761932819004, "tmdate": 1762942328936, "mdate": 1762942328936, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for combining multiple predictive models by assigning input-specific weights in a Bayesian manner. Unlike classical Bayesian Model Averaging (BMA), which uses global model weights, IABMA introduces an input-dependent prior over model-selection functions, leading to input-adaptive posterior weights. The posterior is approximated using amortized variational inference, yielding instance-specific model weightings. The authors derive a finite-sample likelihood guarantee showing that the proposed predictor performs competitively with the best per-input model selector."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Conceptual coherence: The probabilistic formulation that derives adaptive weights from a Bayesian posterior is principled and internally consistent.\n\nEmpirical breadth: The experiments span both regression and classification, synthetic and real datasets, with comparisons to multiple baselines."}, "weaknesses": {"value": "1.\tLimited novelty: The proposed approach is largely a Bayesian reinterpretation of existing adaptive ensemble methods such as Mixture of Experts and Bayesian Hierarchical Stacking . The key innovation, introducing an input-dependent prior, is conceptually modest and primarily repackages known ideas in new notation.\n\n2.\tSuperficial theoretical development: The likelihood guarantee is a straightforward adaptation of Jensen’s inequality, offering minimal insight into the behavior of the amortized inference procedure or its generalization properties. No convergence analysis, uncertainty quantification, or theoretical justification for the variational approximation is provided.\n\n3.\tLack of methodological clarity: The construction of the input-adaptive prior is heuristic, based on an “energy” integral that lacks intuitive interpretation and appears computationally impractical for high-dimensional continuous outcomes. The method relies on ad-hoc Monte Carlo approximations, raising concerns about scalability and stability.\n\n4.\tAmortized inference design is under-specified: The paper treats the amortized posterior network as a black box, without ablation or sensitivity analysis on architecture, optimization, or overfitting. It is unclear whether performance gains come from the variational parameterization or the adaptive prior itself.\n\n5.\tEmpirical evidence is weakly convincing: Improvements over baselines are small and inconsistent across datasets; Comparisons do not include recent or stronger baselines in adaptive ensembling (e.g., deep mixture-of-experts architectures); Some tasks (e.g., PRISM, fraud detection) lack details on train/test splits, data leakage control, and statistical significance of reported differences.\n\n6.\tOverstated claims: The paper claims “formal guarantees” and “Bayes-optimal adaptive weights,” but these rely on unverified approximations and assumptions. The results fall short of demonstrating real-world robustness or interpretability advantages.\n\n7.\tExpository issues: While the paper is long and dense, it lacks intuition; the heavy notation and abstract measure-theoretic framing (e.g., pushforward arguments) obscure rather than clarify the contribution."}, "questions": {"value": "How does IABMA differ in substance from Mixture of Experts with a Bayesian treatment of gating? What new insights or properties does the input-dependent prior confer?\n\nHow sensitive is the model to the design of the energy-based prior and the range of integration for continuous outcomes?\n\nWhat guarantees (if any) can be provided for the variational approximation quality or convergence of amortized inference?\n\nCould the same adaptive weighting effect be achieved more simply with a discriminatively trained gating network, without the Bayesian formalism?\n\nWhat is the computational complexity of evaluating Eq. (9) and optimizing the ELBO in large-scale settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "U7AA86YuCG", "forum": "4o7Z0DDCEO", "replyto": "4o7Z0DDCEO", "signatures": ["ICLR.cc/2026/Conference/Submission22670/Reviewer_ozkA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22670/Reviewer_ozkA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960373697, "cdate": 1761960373697, "tmdate": 1762942328700, "mdate": 1762942328700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies a Bayesian way to combine different models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Cannot assess"}, "weaknesses": {"value": "cannot assess"}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "wxTaBg3PcI", "forum": "4o7Z0DDCEO", "replyto": "4o7Z0DDCEO", "signatures": ["ICLR.cc/2026/Conference/Submission22670/Reviewer_nu4b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22670/Reviewer_nu4b"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762406503152, "cdate": 1762406503152, "tmdate": 1762942328472, "mdate": 1762942328472, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}