{"id": "HgTGjIwZ1l", "number": 24345, "cdate": 1758355957258, "mdate": 1759896770308, "content": {"title": "Post-Gating Bias: Restoring Affine Freedom in Transformer MLPs", "abstract": "Modern transformers often omit additive biases because normalization and attention preserve constant offsets that downstream linear maps can remap. The gated MLP (SwiGLU) is a notable exception: the elementwise product with a nonlinear gate destroys such offsets, removing affine freedom after the nonlinearity. We examine a simple modification—Post-Gating Bias (PGB), an additive term applied after the gated product and before the down-projection. PGB restores this degree of freedom with negligible computational cost.\nOur working hypothesis is that PGB mitigates training noise from dropout or from additive stochastic regularization (e.g., in VAEs) by shifting activation boundaries in a controlled way, thereby softening sharp transitions that otherwise amplify perturbations. We observe stability gains at higher learning rates and some robustness improvements in a ViT-VAE setting. We also show other settings where the effect is minimal. We present these observations to clarify where biases are redundant in transformer blocks and where multiplicative gating makes them potentially useful. Finally, we report a controlled study varying dropout and latent noise across multiple seeds to test this hypothesis.", "tldr": "Post-Gating Bias restores affine freedom lost in gated MLPs. By softening activation boundaries under noise from dropout or latent regularization, it sometimes stabilizes training or improves robustness at negligible cost.", "keywords": ["post-gating bias (PGB)", "gated MLPs", "transformer VAEs", "training stability"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cb6040b7e9bb52d916280a92e6c03aef9fd51733.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Post-Gating Bias, which is an additive bias inserted after the SwiGLU product and before the down-projection, to “restore affine freedom” lost by multiplicative gating, arguing this improves conditioning and reduces gradient variance in noisy regimes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The intervention is precisely defined by equations (1), (2), (3), (4), can be done in-place, and adds virtually no parameters or memory. This makes adoption easy and the ablation surface clean.\n\n- The paper explains why output-bias reconstructability fails after multiplicative gating and shows that PGB effectively removes a rank-1 outer-product from the Hessian, tightening the conditioning bound.\n\n- Results deliberately span regimes with/without stochastic latent noise: ViT-VAE shows shorter loss spikes and slightly better asymptotics; LLM pretraining shows no effect; gated-MLPs gain adversarial robustness."}, "weaknesses": {"value": "Overall, even with the caveats in the limitations, the contribution feels pretty narrow and incremental.\n\n- Section 2 is short and a bit selective—it covers GLUs and VAEs but doesn’t really place PGB in the bigger picture (bias placement in Transformers, centering/variance reduction, normalization choices). A deeper survey with more citations would help the case for novelty.\n\n- The paper admits there aren’t many runs, and there’s no gain in LLM pretraining. It’s still unclear when PGB reliably helps or how it scales. More seeds, bigger models/data, more tasks, and compute-matched baselines would make this stronger.\n\n- “FGSM with 10 steps (step size 0.015) + uniform input noise 0.2” sounds more like multi-step PGD than one-step FGSM. Please spell out the threat model (norm/$\\varepsilon$), step schedule, restarts, and the exact eval protocol so results are comparable.\n\n- No supplementary material was submitted; the paper includes a brief 1–2-page appendix with the necessary theoretical verifications, but no code is provided."}, "questions": {"value": "- Please consider expanding Section 2 to position PGB against prior work on bias placement in Transformers, centering/variance-reduction, and normalization choices, and explain what’s truly new relative to those lines?\n\n- Please add compute-matched, multi-seed results across a couple of larger models/datasets and report a scaling trend so we know when PGB reliably helps (and when it doesn’t)?\n\n- For robustness, was the attack FGSM or multi-step PGD? Please specify the threat model (norm/$\\varepsilon$), step size, number of steps, restarts, and dataset splits, and include a standard baseline (e.g., PGD-20 or AutoAttack) for comparability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FKGeed5fCk", "forum": "HgTGjIwZ1l", "replyto": "HgTGjIwZ1l", "signatures": ["ICLR.cc/2026/Conference/Submission24345/Reviewer_48XY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24345/Reviewer_48XY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761670118303, "cdate": 1761670118303, "tmdate": 1762943051796, "mdate": 1762943051796, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of how gating can suppress bias term information. It presents some theoretical analysis demonstrating this and how this may lead to unstable training. It then investigates how this issue can be rectified by a simple low-cost fix of adding a bias parameter after gating (post-gating bias or PGB). It presents some experiments evaluating its effect on training stability and adversarial robustness, showing that it can be useful for ViT-VAE models while the effects on language models are negligible."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper presents some theoretical analysis showing how gating can suppress bias terms that may lead to unstable training, and then presents a simple low-cost fix of adding a bias parameter after gating."}, "weaknesses": {"value": "The are several major weaknesses. \n\n### 1. The main experiments are not convincing enough to support the claims that the proposed fix PGB stabilizes training and improves adversarial robustness. \n\nFirst, the experiments in the paper are very limited. There is no gap for language models (Phi3, Gemma3). There is only one experiment showing results for ViT-VAE. Based on this, the authors conclude that PGB is beneficial “in architectures where stochastic noice interacts with latent encodings, as in VAEs”. This claim needs to be better supported with more experiments and ablations. The experiments on adversarial robustness are done using MLPs on CIFAR-10 or MNIST datasets, which may be sufficient to support theory, but are very simplistic to argue about performance gains. \n\nSecond, the results in Fig. 1 comparing ViT-VAE train loss with and without PGB look very similar. The differences are not significant enough to support the effectiveness of PGB. \n\nThird, the adversarial robustness experiments show some gains with PGB, however, the accuracies are still quite poor. \n\nIn summary, the effectiveness of PGB is not well-supported.\n\n### 2. The paper contributions are not significant enough, and it is not written well overall. \n\nFirst, the considered problem is very niche and not very well-motivated. Section 2 states observations from prior work and motivates this work stating “none have revisited the role of bias placement relative to dropout and gating”, which can justify the novelty but is not a strong motivation for the work itself. \n\nFurther, the theoretical analysis itself seems quite simplistic. For instance, Lemma 1 is a very standard result and doesn’t need to be stated as a Lemma. It should be cited from relevant prior work. \n\nThese factors, coupled with the unconvincing experiments, makes the significance of the contributions questionable.\n\nSecond, several parts of the paper read like it’s an in-progress work and not a finished one. For instance, the use of “working hypothesis” in the abstract, discussion of some experimental results in the section on Background and Related Work, omitted hyperlinks, e.g., in line 107, missing definitions of some terms in line 140, the phrase “an unexpected result emerged” in line 320, etc. Further, the figures are not made properly, especially Figs. 4-6 which are missing axis labels. Additionally, there is a lot of repetition in Sections 5 and 7, both of seem to be added to cover the additional pages due to lack of more results and contributions, rather than adding any important information."}, "questions": {"value": "Please see the weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dzQ7Hh8h2l", "forum": "HgTGjIwZ1l", "replyto": "HgTGjIwZ1l", "signatures": ["ICLR.cc/2026/Conference/Submission24345/Reviewer_H1At"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24345/Reviewer_H1At"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761686226558, "cdate": 1761686226558, "tmdate": 1762943051553, "mdate": 1762943051553, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits the common practice of omitting additive biases in transformer MLPs, focusing on the SwiGLU architecture where multiplicative gating destroys constant offsets and thus removes affine freedom after the nonlinearity. The authors propose a simple modification: Post-Gating Bias (PGB), which adds a bias term after the gated product and before the down-projection. Through theoretical analysis and empirical studies across Vision Transformer VAEs, language models, and gated MLP classifiers, the paper demonstrates that PGB can improve training stability and adversarial robustness in noisy or regularized settings, while having negligible effect in standard large-scale language model pretraining. The work highlights subtle but important roles for architectural elements often considered redundant."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The paper provides a solid theoretical justification for why biases are not always redundant in transformer blocks, especially after multiplicative gating, and analyzes the conditioning and variance reduction benefits of PGB.   \n(2) The proposed PGB modification is easy to implement, incurs negligible computational or memory cost, and can be adopted in existing architectures with minimal efforts.  \n(3) The authors evaluate PGB across diverse settings (ViT-VAEs, LLM pretraining, and stacked gated MLPs), providing evidence for its benefits and limitations."}, "weaknesses": {"value": "(1) From the experiments, we can see that the improvements from PGB are only visible in specific models (e.g., ViT-VAEs, stacked gated MLPs), and there is no improvement in standard LLM pretraining (see Figure 2 and 3 from the paper). This would limit the significance of the proposed method, because I feel that LLM is generally more widely used for transformer models than the other two models. Another model type that is interesting is vanilla ViT (see [1] from the list below). This paper would be strengthened if some experiments on vanilla ViT is included, because it's a crucial componet in many vision-language models.\n\n(2) The experiments on ViT-VAE showed some improvements, but it looks like the difference is quite small in terms of training loss. The authors mentioned that they used standard training/valiadtion/test splits for the CelebA dataset. However, only training loss is showed in the paper (see Figure 1). In addition, the paper does not investigate whether PGB leads to qualitatively different learned representations or downstream behaviors.\n\nOverall, I agree that the proposed method is interesting and worth investigating. But the experiments could be strengthened to better demonstrate the real benefits of the proposed method in practice, e.g., LLM, vanilla ViT which are popular settings where transformers are used.  \n\n**Reference**:  \n[1] Dosovitskiy, Alexey. \"An image is worth 16x16 words: Transformers for image recognition at scale.\" arXiv preprint arXiv:2010.11929 (2020)."}, "questions": {"value": "see my comments above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aV2mzqfkqq", "forum": "HgTGjIwZ1l", "replyto": "HgTGjIwZ1l", "signatures": ["ICLR.cc/2026/Conference/Submission24345/Reviewer_29dQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24345/Reviewer_29dQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952310874, "cdate": 1761952310874, "tmdate": 1762943051299, "mdate": 1762943051299, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes use of a bias term after multiplicative gating in gated neural networks, with the argument that this bias is hard to be absorbed by other parameters and normalization layers.  Variance and stability arguments are presented to suggest that, while the weight matrix that comes after gating can in theory learn to account for this bias, it is not a good idea to rely on it to do so.  Gated networks with such bias are evaluated in three scenarios: a VAE setup using vision transformer, stacked gated MLPs, and autoregressive pre-training."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Theoretical and empirical study of post-gating bias in gated neural networks"}, "weaknesses": {"value": "The empirical support for the proposed bias is quite weak for a few reasons:\n* In the ViT-VAE scenario the only evidence for value of bias is in Figure 1 which shows training loss over time.  Subjective observations are made on onset and duration of spikes in training loss, but looking at the picture one could argue the other way around as well.  A more quantitative analysis and comparison needs to be carried out.\n* The bias shows no effect in the pre-training scenario.\n* In the stacked gated MLP scenario, only adversarial robustness is discussed.  However, what is the model performance as compared to baseline models (including state of the art pre-trained/fine-tuned models) at the baseline classification tasks? The observed adversarial robustness is interesting but both baseline performance and adversarial robustness needs to be contrasted with state of the art pre-trained/fine-tuned models."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5YawB1Pd3P", "forum": "HgTGjIwZ1l", "replyto": "HgTGjIwZ1l", "signatures": ["ICLR.cc/2026/Conference/Submission24345/Reviewer_38f8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24345/Reviewer_38f8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012252659, "cdate": 1762012252659, "tmdate": 1762943050980, "mdate": 1762943050980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}