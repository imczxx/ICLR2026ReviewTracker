{"id": "bAG7lS1AUL", "number": 17990, "cdate": 1758282705999, "mdate": 1763645244300, "content": {"title": "Fused-Planes: Why Train a Thousand Tri-Planes When You Can Share?", "abstract": "Tri-Planar NeRFs enable the application of powerful 2D vision models for 3D tasks, by representing 3D objects using 2D planar structures.\nThis has made them the prevailing choice to model large collections of 3D objects.\nHowever, training Tri-Planes to model such large collections is computationally intensive and remains largely inefficient.\nThis is because the current approaches independently train one Tri-Plane per object, hence overlooking structural similarities in large classes of objects. \nIn response to this issue, we introduce Fused-Planes, a novel object representation that improves the resource efficiency of Tri-Planes when reconstructing object classes, all while retaining the same planar structure.\nOur approach explicitly captures structural similarities across objects through a latent space and a set of globally shared base planes.\nEach individual Fused-Planes is then represented as a decomposition over these base planes, augmented with object-specific features.\nFused-Planes showcase state-of-the-art efficiency among planar representations, demonstrating $7.2 \\times$ faster training and $3.2 \\times$ lower memory footprint than Tri-Planes while maintaining rendering quality.\nAn ultra-lightweight variant further cuts per-object memory usage by $1875 \\times$ with minimal quality loss.", "tldr": "Fused-Planes improves upon Tri-Planes for state-of-the-art resource efficiency when training large classes of objects, by leveraging shared representations in a latent space.", "keywords": ["Tri-Planes", "NeRF", "3D", "Latent"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5ad4385491a991b10144973f5e1d702c6066a6bc.pdf", "supplementary_material": "/attachment/a17a8b20df1cdda220f170c6dba8778fe5bf0182.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Fused-Planes, a tri-planar scene representation for efficiently training large collections of 3D object models. Specifically, each object’s planes are decomposed into an object-specific micro-plane and a class-level macro-plane. The training is conducted in a jointly learned 3D-aware latent space, supervised by both the latent and RGB domains. Experiments on ShapeNet and Basel Faces show that Fused-Planes achieves faster training speed and lower per-object memory than standard Tri-Planes, while maintaining comparable rendering quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper tackles a clear challenge in scaling object-centric Tri-Plane models and introduces both micro- and macro-decomposition to exploit inter-object redundancy.\n\n2. The proposed method uses a base-plane bank and a learned weighting mechanism to provide a compact and interpretable way to model class-level structures without sacrificing the planar format useful for 2D backbones.\n\n3. The performance is impressive. The proposed method significantly reduces the training consumption, including time and space overhead, while still maintaining comparable reconstruction performance."}, "weaknesses": {"value": "1. The memory of each object excludes the shared network components, including encoder, decoder, and base planes, which may lead to an unfair comparison with baselines. It would be better if the authors could provide a more balanced total-cost comparison across different values of N.\n\n2. The method is class-specific, which means it cannot be generalized to unknown classes.\n\n3. The evaluation is on object-centric, bounded scenes, e.g., ShapeNet categories and Basel Faces. The proposed method struggles with fine details and unbounded scenes, limiting its applicability relative to non-planar methods."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IXmixzTURB", "forum": "bAG7lS1AUL", "replyto": "bAG7lS1AUL", "signatures": ["ICLR.cc/2026/Conference/Submission17990/Reviewer_NFsJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17990/Reviewer_NFsJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900335073, "cdate": 1761900335073, "tmdate": 1762927785840, "mdate": 1762927785840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a resource-efficient tri-planar representation (namely, Fused-Planes) for modelling large collections of 3D objects. The core idea is to decompose each object's representation into object-specific 'micro' planes and shared 'macro' planes (constructed from learned base planes), trained in a 3D-aware latent space. The work addresses a real problem, i.e., the computational cost of training thousands of Tri-Planes, and demonstrates impressive efficiency gains while maintaining quality (7.2× faster training, 3.2× lower memory). The combination of micro-macro decomposition with latent space training is well-motivated, and ablations demonstrate both components are necessary. Experiments and ablations are extensively conducted across multiple baselines and datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The major strength of this paper is the significant resource savings (7.2× speed, 3.2× memory reduction vs Tri-Planes). Besides, the ultra-lightweight variant achieves 1875× memory reduction. And it maintains the rendering quality."}, "weaknesses": {"value": "The method only works within a single object class. For multiple classes with large visual variations, you need multiple instances of Fused-Planes. This significantly limits practical applicability. For diverse datasets, the overhead of multiple base plane sets could negate efficiency gains.\n\nFor open surfaces and unbounded scenes, this method is still limited like other triplane methods.\n\nTable 4, Fused-Planes (Micro)(latent space without macro planes) performs worse than Tri-Planes. This suggests the latent space itself introduces quality degradation, which is only compensated by the macro planes. This is concerning because it means the latent space is not providing a better representation per se. It's just enabling the sharing mechanism.\n\nDuring inference, each Fused-Planes requires computing the weighted sum at inference (Eq. 2). What's the computational cost of this operation compared to directly loading a Tri-Plane? For applications requiring real-time rendering, is this overhead acceptable? What are the runtime/FPS at inference time across different methods?"}, "questions": {"value": "What happens when you train on the entire ShapeNet dataset, not just per-category? How many base plane sets would be needed? What's the break-even point where efficiency gains disappear?\n\nAt what scale (N objects) does M=50 need to increase? Is there a theoretical or empirical relationship between M, N, and object class diversity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2l7xZqS4iv", "forum": "bAG7lS1AUL", "replyto": "bAG7lS1AUL", "signatures": ["ICLR.cc/2026/Conference/Submission17990/Reviewer_ymg3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17990/Reviewer_ymg3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927479094, "cdate": 1761927479094, "tmdate": 1762927785212, "mdate": 1762927785212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Fused-Planes, an efficient tri-plane–based method for reconstructing large classes of 3D objects. The approach incorporates a Micro component to capture object-specific features and a Macro component to encapsulate structural similarities shared across the object class. In addition, it leverages a 3D-aware latent space to accelerate both the rendering and training processes of Fused-Planes. Compared with the original Tri-Planes, Fused-Planes achieves 7.2× faster training and 3.2× lower memory consumption while maintaining comparable rendering quality. The authors further propose an ultra-lightweight variant that almost entirely omits the micro component, yielding a remarkable 1875× memory reduction. Experimental results demonstrate that Fused-Planes significantly outperforms existing plane-based methods such as Tri-Planes and K-Planes in terms of both training efficiency and memory scalability for large-scale multi-object reconstruction."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a 3D aware latent space as a form of shared representation in the object reconstruction domain, enabling the model to better capture structural similarities across object classes. According to the ablation study, employing this latent representation rather than directly optimizing in RGB space leads to faster convergence while maintaining comparable rendering quality.\n2. Compared to C3 NeRF, which scales only up to around 20 scenes, the proposed approach remains scalable to thousands of objects, demonstrating superior generalization and efficiency across large datasets.\n3. Under the current task setting, the method achieves significant advantages in training speed and memory efficiency over traditional KPlanes and TriPlanes approaches."}, "weaknesses": {"value": "1. Although the paper claims that Fused-Planes remains scalable to thousands of objects, I do not observe convincing evidence of this property from the presented experimental results or supplementary videos.\n2. In line 103, the paper states that TensoRF, 3DGS, and Instant-NGP cannot be reshaped into image-like tensors. However, to my knowledge, several recent works in the 3DGS domain, such as Animatable Gaussians, ASH, GaussianAvatar, and Reperformer, have successfully employed 2D UV unwrapping or Morton mapping strategies to project 3D point clouds into 2D grids and then apply image-based CNN architectures to learn the appearance of avatars under novel motions. I believe these 2D parameterization methods should be properly cited and discussed for completeness.\n3. While I understand the limitations of Tri-Planes in representing fine details and handling unbounded scenes, the object-centric datasets used in this paper (e.g., ShapeNet, Basel Faces) appear to be extremely simple in geometry. Despite such simplicity, both Fused-Planes and Fused-Planes-ULW still produce noticeably blurry renderings. This level of visual quality makes it difficult to assess the practical value and applicability of the proposed approach.\n4. To my knowledge, several tri-plane-based methods such as TeTriRF can generate highly detailed and realistic renderings of complex human data with relatively lightweight models. It is therefore unclear why the proposed method fails to achieve comparable quality even on synthetic datasets with simple geometries.\n5. Furthermore, in Fig. 5, where Fused-Planes is compared with other per-scene training methods in terms of size and training time, I believe this comparison is highly unfair"}, "questions": {"value": "As noted in the weaknesses section, the paper should better highlight its capability to scale up to thousands of objects. It should also provide a discussion of relevant references regarding the use of 2D parameterization in 3DGS, and clarify the factors contributing to its lower rendering quality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns of this paper."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EVFSo6dvqa", "forum": "bAG7lS1AUL", "replyto": "bAG7lS1AUL", "signatures": ["ICLR.cc/2026/Conference/Submission17990/Reviewer_C24d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17990/Reviewer_C24d"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762460449884, "cdate": 1762460449884, "tmdate": 1762927784670, "mdate": 1762927784670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Fused-Planes, a shared tri-planar representation that improves the efficiency of training large 3D object collections. Instead of training independent Tri-Planes for each object, the method decomposes each object’s planes into a micro component (object-specific details) and a macro component (a weighted sum of shared base planes capturing class-level structure). The model is trained jointly within a 3D-aware latent space, which further reduces computation. Experiments on ShapeNet and Basel Faces show strong results: up to 7.2× faster training, 3.2× smaller per-object memory, and comparable or better rendering quality than Tri-Planes. An ultra-lightweight variant achieves extreme compression with minor quality loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* **Clear and practical contribution.** The paper tackles a real inefficiency in Tri-Plane training and offers an intuitive solution that effectively shares structure within a class.\n* **Strong empirical gains.** Training speed, memory footprint, and quality all improve substantially. The ULW version demonstrates impressive compression with minimal degradation.\n* **Elegant design.** The micro–macro split is simple yet powerful, allowing reuse of planar architectures while amortizing cost across objects.\n* **Comprehensive evaluation.** The experiments, ablations, and comparisons are thorough and well-presented. The results convincingly support the claims.\n* **Readable and well-organized.** The paper is clear, figures are informative, and the setup is easy to follow."}, "weaknesses": {"value": "* **Single-class limitation.** The method assumes one class per model. Scaling to diverse datasets would require separate sets of base planes, reducing its flexibility.\n* **Limited analysis of shared bases.** The learned base planes are not explored in depth. It is unclear what structures they capture or how weights vary across instances.\n* **Restricted evaluation scope.** Experiments focus only on novel view synthesis of synthetic datasets. No tests on real or multi-class data, or on downstream tasks that might use the planar outputs.\n* **Dependence on latent space.** The model relies on a pretrained VAE initialization, but the sensitivity to this setup and its cost are not fully studied.\n* **Constant overhead.** While per-object cost drops sharply, the shared components introduce a large fixed memory load, which only becomes efficient at larger scales."}, "questions": {"value": "1. How sensitive is performance to the number of shared base planes and the micro–macro feature split?\n2. Can a single set of base planes handle multiple classes, perhaps with class-conditioned weights?\n3. What do the shared base planes actually learn? Visualizing or analyzing them could offer useful insight.\n4. How dependent is training on the pretrained latent codec? Could the system work with a smaller or scratch-trained encoder?\n5. Could Fused-Planes be tested on real multi-view datasets or downstream 2D-compatible tasks to demonstrate broader utility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Cq3qn16TAP", "forum": "bAG7lS1AUL", "replyto": "bAG7lS1AUL", "signatures": ["ICLR.cc/2026/Conference/Submission17990/Reviewer_QUGX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17990/Reviewer_QUGX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762588414653, "cdate": 1762588414653, "tmdate": 1762927784132, "mdate": 1762927784132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Paper revision"}, "comment": {"value": "We thank the reviewers for their constructive remarks. We have addressed each reviewer's concerns individually, and summarize below the changes we have integrated into our paper revision.\n\nOur animated results can be viewed at the following anonymous link: https://anon-supp.github.io/.\nIn the final paper, these animations will be hosted on a de-anonymized project page.\nNon-animated versions of the results are also included in the revised paper.\n\n\n- **Large-scale results.** We have added a visualization of our large-scale results in Figure 10 (C24d).\n- ***New experiments:* Multi-class training.** We have added new experiments on multi-class training (Section 4.2, Table 4) (QUGX, ymg3, NFsJ).\n- **Updated limitations.** We have updated the limitations section of our paper to take into account the new results on multi-class training.\n- ***New experiments:* Impact of $M$.** We have added an ablation study of the effect of the number of base planes $M$ on Fused-Planes in single and multi-class reconstruction (Section D.3, Table 9) (QUGX, ymg3).\n- ***New experiments:* Rendering speed.** We have added an analysis of rendering speed in Section D.4 (Section D.4, Tables 10 and 11). (ymg3).\n- ***New experiments:* Training with a low-budget VAE.** We have added experiments done on Fused-Planes using a low-budget AE (Section D.5, table 12) (QUGX).\n- ***New experiments:* Analysis of the base planes.** We have added in section E an analysis of the representations learned by the base planes (Figure 7), an analysis of the weights multiplying these base planes (Figure 8). We also added a new experiment in which we interpolate between learn weights (Figure 9) (QUGX).\n- **Analysis of the cost of Fused-Planes when $N$ varies.** We have added an analysis of the total cost across different values of $N$ (Section D.6, Tables 13, 14) (NFsJ).\n- **Related work.** We have revised the related work to include the works referenced by reviewer C24d.\n- **Clarification** We have revised the caption of Figure 5 (C24d).\n\nWe hope that our paper revision, along with the individual responses, address the reviewers' concerns. We remain open for further discussion."}}, "id": "W8OkHp9GWK", "forum": "bAG7lS1AUL", "replyto": "bAG7lS1AUL", "signatures": ["ICLR.cc/2026/Conference/Submission17990/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17990/Authors"], "number": 12, "invitations": ["ICLR.cc/2026/Conference/Submission17990/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763649023185, "cdate": 1763649023185, "tmdate": 1763649023185, "mdate": 1763649023185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}