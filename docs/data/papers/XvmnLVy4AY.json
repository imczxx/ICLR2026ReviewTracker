{"id": "XvmnLVy4AY", "number": 5434, "cdate": 1757909168608, "mdate": 1759897975704, "content": {"title": "Zero-Forgetting Class-Incremental Segmentation Via Dual-Phase Cognitive CasCades", "abstract": "Continual semantic segmentation (CSS) is a cornerstone task in computer vision that enables a large number of downstream applications, but faces the catastrophic forgetting challenge. In conventional class-incremental semantic segmentation (CISS) frameworks using Softmax-based classification heads, catastrophic forgetting originates from Catastrophic forgetting and task affiliation probability. We formulate these problems and provide a theoretical analysis to more deeply understand the limitations in existing CISS methods, particularly Strict Parameter Isolation (SPI). To address these challenges, we follow a dual-phase intuition from human annotators, and introduce \\textbf{Cog}nitive \\textbf{Ca}scade \\textbf{S}egmentation (CogCaS), a novel dual-phase cascade formulation for CSS tasks in the CISS setting. By decoupling the task into class-existence detection and class-specific segmentation, CogCaS enables more effective continual learning, preserving previously learned knowledge while incorporating new classes. Using two benchmark datasets PASCAL VOC 2012 and ADE20K, we have shown significant improvements in a variety of challenging scenarios, particularly those with long sequence of incremental tasks, when compared to exsiting state-of-the-art methods.", "tldr": "", "keywords": ["Continual Learning", "Semantic Segmentation", "Class Incremental Semantic Segmentation"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ae8cd17964559cb4dfa9961124852ddae4f3660b.pdf", "supplementary_material": "/attachment/9f9f81e3cd4bdbc1a41c404d26a3470fe8a14537.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses catastrophic forgetting in class-incremental semantic segmentation (CISS) by proposing Cognitive Cascade Segmentation (CogCaS), a dual-phase framework. CogCaS decouples the segmentation task into: (1) image-level multi-label classification to detect class existence, and (2) class-specific binary segmentation heads activated only for detected classes. By freezing parameters for previous tasks, it achieves zero-forgetting while maintaining plasticity for new classes. Experiments on PASCAL VOC 2012 and ADE20K demonstrate strong performance, particularly in long-sequence scenarios (e.g., VOC 1-1 with 20 tasks)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "## 1. Solid Theoretical Foundation\nThe formalization of zero-forgetting conditions (Theorem 3.3) and the cascade factorization (Theorem B.2 in Appendix) provide valuable theoretical insights into why SPI-based methods can achieve zero-forgetting. The analysis of the average forgetting rate and its relationship to parameter updates is rigorous and well-presented.\n\n## 2. Strong Empirical Results in Challenging Settings\nThe method shows remarkable performance in difficult long-sequence scenarios. On VOC 1-1 (20 tasks), CogCaS achieves 70.9% mIoU compared to 33.2% for IPSeg and 7.3% for PLOP+NeST, demonstrating substantially better robustness as task sequences grow.\n\n## 3. Comprehensive Experimental Evaluation\nThe paper includes extensive experiments across multiple datasets (VOC, ADE20K), various incremental settings (10-1, 15-5, 15-1, 1-1, 2-1, 2-2, 100-50, 100-10, 100-5), and comparisons with numerous baselines including recent state-of-the-art methods."}, "weaknesses": {"value": "## 1. Limited Novelty\nThe core technical contributions appear incremental when viewed against existing CISS methods. The proposed approach essentially combines two well-established components: (1) multi-label classification for class-existence detection, and (2) class-specific binary segmentation heads with Strict Parameter Isolation (SPI). While the combination is sensible, neither component represents a significant technical innovation:\n- Multi-label classification for determining class presence is a standard technique, and its application to route segmentation heads is a relatively straightforward design choice\n- Binary segmentation with frozen parameters closely follows the paradigm established by SSUL and IPSeg, which already employ sigmoid-based outputs and parameter freezing\n- The decoupling strategy is architecturally simple and lacks technical sophistication\n\nThe main value lies in the theoretical analysis, which provides useful insights into why SPI works. However, the practical instantiation feels like an incremental step from frozen/sigmoid-based models rather than a substantial architectural innovation meeting rigorous ICLR standards. \n\n## 2. Discussion of Related Work\nThe paper would benefit from discussing ECLIPSE (CVPR 2024), which explores related design principles, including independent class-specific components and binary mask prediction in a transformer-based framework. While multiple methods (SSUL, IPSeg, ECLIPSE) share similar goals through parameter freezing, sigmoid-based outputs, and class-specific designs, ECLIPSE's use of independent class tokens and binary segmentation bears particular conceptual similarity to CogCaS's dual-phase approach. \n\nWhile not essential given that ECLIPSE represents one instantiation among several methods exploring parameter isolation and binary formulations, such discussion would enhance the paper's positioning within the current state-of-the-art and help readers understand the trade-offs between different architectural choices.\n\n* Kim, Beomyoung, Joonsang Yu, and Sung Ju Hwang. \"Eclipse: Efficient continual learning in panoptic segmentation with visual prompt tuning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.\n\n## 3. Unconvinced Performance and Implausible Oracle Gap\nThe reported performance raises significant concerns about experimental validity.\n\n**A. Implausible Oracle Gap:**\nTable 5 shows extraordinarily small gaps between \"Full Model\" and \"Oracle\" on VOC:\n  - VOC 1-1: 70.9% vs 71.2% (0.3% gap)\n  - VOC 2-1: 71.9% vs 72.3% (0.4% gap)\n  - VOC 2-2: 71.5% vs 72.4% (0.9% gap)\n\nHowever, Table 4 reveals the classifier has 18% error (82.08% mAP) and misses 11.3% of classes (88.70% recall). This inconsistency is unexplained: how can a classifier with 18% error produce only 0.3-0.9% performance degradation in the full pipeline?\n\n**B. Unaddressed Class Confusion Problem:** Existing work (e.g., ECLIPSE) identifies class confusion between visually similar categories (cow/sheep, car/truck) as a fundamental challenge in incremental learning. The paper provides no analysis of (1) how the multi-label classifier handles such confusion cases and (2) whether \"near-OOD data\" accidentally addresses this in unrealistic ways.\n\n## 4. Missing Critical Ablations\nSeveral important ablation studies are absent:\n\n- Loss weight $\\lambda$: The full objective is $L$ = $L_{cls}$ + $\\lambda$$L_{seg}$ with $\\lambda=1$, but no ablation justifies this choice\n- Detection threshold $\\alpha$: Phase I uses threshold α to determine $C_{pred}$, but the sensitivity to this hyperparameter is not analyzed\n- Near-OOD data ratio: The 1:1 ratio is stated but not justified through ablation\n- Impact of near-OOD data construction: What happens without this component? This seems critical to the method's success but is not isolated\n\n## 5. Insufficient Information about Near-OOD Data Construction\nThe \"near-OOD data construction\" described in Appendix B.5 and Figure 5 appears crucial to the method's performance but is severely under-explained."}, "questions": {"value": "Distributed Fusion Strategy Details: Section 4.4 states that \"Distributed: prioritizes rare categories to preserve small objects\" but provides no implementation details. How exactly are rare categories identified (dataset statistics? prediction confidence? object size in the current image?)? How is the prioritization implemented algorithmically? Why does this strategy work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vRN0dpQBro", "forum": "XvmnLVy4AY", "replyto": "XvmnLVy4AY", "signatures": ["ICLR.cc/2026/Conference/Submission5434/Reviewer_aaNs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5434/Reviewer_aaNs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659854612, "cdate": 1761659854612, "tmdate": 1762918060179, "mdate": 1762918060179, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the challenge of catastrophic forgetting in Continual Semantic Segmentation, a novel dual-phase framework CogCaS is introduced. CogCaS decouples the problem into two stages: (i) a class-existence detection stage to determine which classes are present in an image, and (ii) a class-specific segmentation stage that is only activated for detected classes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "CogCaS presents a original, cognitively-inspired architecture that tackles CISS by fundamentally decoupling class existence from class location. This novel dual-stage design represents a clear departure from conventional paradigms."}, "weaknesses": {"value": "(1)\tLack of Quantitative Cost Analysis: The computational cost analysis is qualitative, noting the use of \"8 NVIDIA GeForce RTX 4090 GPUs\" and claiming LoRA increases inference time, but it provides no quantitative data (e.g., ms/image, training time comparisons). A practical evaluation requires these metrics to properly assess the trade-offs of the architecture.\n\n(2)\tStatistical Robustness of Results: The reported performance gains, especially in long-sequence settings (Table 3), are exceptionally large. For instance, in the VOC 1-1 setting, CogCaS achieves 70.9% mIoU while the next-best parameter-isolation method, IPSeg, only reaches 33.2%. However, the lack of statistical validation—such as results over multiple random seeds, standard deviations, or confidence intervals—makes it difficult to assess the robustness of these claims.\n\n(3)\tPotential Contradiction in Detector’s Role: Table 4 shows a modest recall of 47.5% for the class-existence detector on the challenging ADE20K dataset. This implies that for any given image, the detector fails to trigger the correct segmenter for more than half of the object classes actually present. This seems at odds with the strong overall system performance and the ablation in Table 5, where the “Segmentation Only” model’s performance collapses (e.g., to 7.6% mIoU on ADE20K). It is unclear how the model recovers so effectively from such a high miss rate at the crucial first stage."}, "questions": {"value": "(1)\tCould you please provide the formal proofs or at least a detailed sketch of the theoretical analysis mentioned in the introduction regarding the structural limitations of the Strict Parameter Isolation (SPI) strategy?\n\n(2)\tGiven the exceptionally large performance margins reported in Table 3, could you clarify if these results were averaged over multiple random seeds? Providing standard deviations would be crucial to confirm the statistical significance and robustness of these outstanding gains.\n\n(3)\tTable 4 indicates a recall of only 47.5% for the class-existence detector on ADE20K, suggesting it fails to activate the correct segmenter for over half of the present classes. How does the full model still achieve strong overall performance despite this high miss rate?\n\n(4)\t'the model demands substantial training resource' is mentioned in this paper. Could you please quantify this by providing (a) the approximate training time per incremental task (e.g., for the VOC 1-1 setting) and (b) the per-image inference latency of the full CogCaS model? How do these metrics compare to a key baseline like IPSeg?\n\n(5) What is the result of comparing methods related to large models?\n\n(6) Are the Zero-forgetting Conditions met in practical application scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AQwhVGyG5P", "forum": "XvmnLVy4AY", "replyto": "XvmnLVy4AY", "signatures": ["ICLR.cc/2026/Conference/Submission5434/Reviewer_WRgh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5434/Reviewer_WRgh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963458103, "cdate": 1761963458103, "tmdate": 1762918059551, "mdate": 1762918059551, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an approach for (if I understand it right) training a class-independent head model, by leveraging an image-level class presence detector. It targets keeping heads sufficiently separate to minimise the amount of destructive training on heads after they have been learnt, while at the same time leveraging past-heads for helping with training of future tasks. It demonstrates this on standard benchamarks for sematic segmentation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The approach appears to provide significant advantage over other existing approaches in the heavily constrained class-incremental learning setting. The experiments and evaluations are substantive, and the method appears for be performative. Practically, it looks like a good tool for the toolbox."}, "weaknesses": {"value": "(Please fix the references, and the capitalisation - it is not a great look to take poor care of your references to other people's work)\n\nFigure 1 is your key figure, but it is ambiguous what it is showing.\n\nI would like to see more discussion of your approach relative to https://arxiv.org/abs/2106.11562 and many of the papers following it (e.g.  Continual Segmentation with Disentangled Objectness Learning and Class Recognition). This paper gives very terse consideration for existing work, and I think that cannot be warranted given the extensive literature out there. The paper does something pretty simple: why is this not already understood?\n\nYou use\n\nEτ (θt) = Lvalτ (θt) − Lvalτ (θ∗τ )\n\nto define forgetting, but this is really loss of performance more than forgetting. It can be that future tasks improve performance on earlier tasks, while the information learnt before is still forgotten. This impacts the whole idea of average forgetting rate.\n\nThe theoretical analysis seems spurious. It makes the assumption that the magnitude of delta_t is  bounded by delta in order to do a linear first order analysis in Eq. 3. That also requires a missing assumption that \\theta*+\\deltat \\in Neighbourhood(\\theta^*). But if that were valid we would need to do multiple optimization steps on a task - we could do it in one hop. The whole reason that we do mulltiple steps of SGD (or whatever) is precisely because the landscape changes significantly between within-task steps, and so things change significantly over the whole change in params from the beginning to end of task t, which is what defines \\delta t.\n\nThe paper feels like a case of \"we did these experiments, now we need to inject some theory to make it more palatable to reviewers\". I think the theory is spurious, detracts from the point of the paper, and there is no need for this to motivate the really obvious statement that strict parameter isolation prevents forgetting: not changing parameter means they cannot forget the information they contain, so long as that information is used consistently.\n\nThe real focus of this paper is the approach, which can basically be summarised as an image-level attention mechanism over class- independent heads to determine which heads to leverage. \n\nEq 5 doesn't make sense, what is conditioning on c mean here? c is on both the left and right of the conditioning statement. Likewise eq 14 is broken. There needs to be a sum over c, and it needs to be clear what c is here. Furthermore the description in the paper and in the background so not seem to match. I would love to see a much more precise description: what exactly is the model definition at training, time and how precisely is training done: what is instantiated, and what is calculated, what is updated, and how are the gradients computed. Then how is the model used at inference time. At the moment these things are rather muddled. Higher levels of precision and organisation are needed.\n\nThe claim that this produces SPI feels dubious to me? How? There is cross-task sharing, in that the previously trained classes that are present are activated in training later tasks. SPI is also not ideal, in that it removes all possibility of cross-task generalisation and transfer. So one key point of machine learning is lost as a result. \n\nI do not see where the \"mask fusion\" element of the model is defined? I might have missed it.\n\nThe experiments are likely done well, but not always well explained. Has your method parameter matched previous methods, or is it just more powerful? Detailed captions are missing, I do not know what Joint-Ours versus Our is for example. The differences with previous approaches do not look dramatic in some settings but there does appear to be a performance gain. I would love to see some analysis against other methods, as to why there is a difference and what fundamentally makes the change.\n\nAltogether, I think this paper could be tightened up significantly. The spurious theory could be removed, leaving plenty of space to properly define the method precisely and carefully, and give _much_ more substantive discussion of its place within the body of previous work. Additional care in making sure all equations are squeaky clean, well described, everything is rigorously defined and the work is arranged carefully and methodologically would reap dividends."}, "questions": {"value": "What exactly makes your method work better, relative to dumb baselines (such as fused independent class v background learners, which is explicitly an SPI approach). Please explain where the advantage of your method comes from so we can gain insight from the work you present. Why does this add to our capability - where might this be useful in the future - this is submitted as a research paper, not a description of work, so what is the research insight we gain from this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ECVo6HTaSW", "forum": "XvmnLVy4AY", "replyto": "XvmnLVy4AY", "signatures": ["ICLR.cc/2026/Conference/Submission5434/Reviewer_We7C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5434/Reviewer_We7C"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762015729561, "cdate": 1762015729561, "tmdate": 1762918059099, "mdate": 1762918059099, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}