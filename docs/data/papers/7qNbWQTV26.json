{"id": "7qNbWQTV26", "number": 14755, "cdate": 1758243090244, "mdate": 1763680258818, "content": {"title": "Differentially Private Equilibrium Finding in Polymatrix Games", "abstract": "We study equilibrium finding in polymatrix games under differential privacy constraints. Prior work in this area fails to achieve both high-accuracy equilibria and a low privacy budget. To better understand the fundamental limitations of differential privacy in games, we show hardness results establishing that no algorithm can simultaneously obtain high accuracy and a vanishing privacy budget as the number of players tends to infinity. This impossibility holds in two regimes: (i) We seek to establish equilibrium approximation guarantees in terms of Euclidean \\emph{distance} to the equilibrium set, and (ii) The adversary has access to all communication channels. We then consider the more realistic setting in which the adversary can access only a bounded number of channels and propose a new distributed algorithm that: recovers strategies with simultaneously vanishing \\emph{Nash gap} (in expected utility, also referred to as \\emph{exploitability}) and \\emph{privacy budget} as the number of players increases. Our approach leverages structural properties of polymatrix games. To our knowledge, this is the first paper that can achieve this in equilibrium computation. Finally, we also provide numerical results to justify our algorithm.", "tldr": "Simultaneously achieves high accuracy and low differential privacy budget in computing the equilibria of polymatrix games", "keywords": ["Polymatrix Game", "Differential Privacy"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a31292c0d9894e90617a04fa886419b2d9e7399a.pdf", "supplementary_material": "/attachment/d68b977033b03e6558da1b86093808ad7c36e287.zip"}, "replies": [{"content": {"summary": {"value": "This work proves that for polymatrix games, if either adversary can access an arbitrary number of communication channels or the learning objective is to minimize the Euclidean distance to the equilibrium set, no algorithm can simultaneously find an accurate enough approximate equilibrium strategy profile and guarantee a low level of privacy. The authors further relax the restrictions to consider that the adversary can only access a bounded number of channels. Under this condition, the authors propose an algorithm that can simultaneously find an approximate coarse correlated equilibrium (CCE) strategy profile and guarantee a low level of privacy. Experiments with a varying number of players are conducted to validate the effectiveness of the proposed algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The presentation of most parts of the paper is clear."}, "weaknesses": {"value": "I’m concerned with the problem formulation, the motivation, and the design of the proposed algorithm. \n\nFirst, it is unclear to me whether the utility matrix $U\\_{i,j}$ for each $ (i, j) \\in E $ is known or unknown in Section 2. I guess the authors assume known $U\\_{i,j}$’s as the proposed algorithm explicitly uses $U\\_{i,j}$’s to compute the gradient $\\overline{\\boldsymbol{g}}\\_i^{(t)}$. However, if each $U\\_{i,j}$ is known, I think this problem is just an optimization problem and the equilibrium can be **computed** simply using an optimization method in an offline manner. In this sense, there is no need to use online learning to **learn** an approximate equilibrium strategy profile in an online manner. Consequently, I think no communications between agents and privacy-preserving are needed.\n\nFurther, even if each $U\\_{i,j}$ is known, there are many works in the literature studying how to learn the approximate equilibrium strategy profile under the bandit feedback (i.e., only the rewards of the chosen actions are revealed) in an uncoupled manner (say, [1,2]). These algorithms do not require any communication or coordination between the agents. As such, there is also no need to preserve privacy in these scenarios. \n\nTherefore, I think the motivation for studying privacy-preserving algorithms using the communication of the policy information between agents seems not very reasonable. This also casts doubt on the value of the proposed algorithm.\n\n[1] Cai et al. Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games with Bandit Feedback. NeurIPS, 23.\n\n[2] Ito et al. Instance-Dependent Regret Bounds for Learning Two-Player Zero-Sum Games with Bandit Feedback. COLT, 25."}, "questions": {"value": "Please see my questions in the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5GjqDYXxlY", "forum": "7qNbWQTV26", "replyto": "7qNbWQTV26", "signatures": ["ICLR.cc/2026/Conference/Submission14755/Reviewer_eMY6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14755/Reviewer_eMY6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900006227, "cdate": 1761900006227, "tmdate": 1762925113708, "mdate": 1762925113708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies equilibrium computation in polymatrix games under edge-DP (everything else is fixed in the neighboring \"games\" execpt the value of a single edge). The authors observe that existing works cannot simultaneously achieve high accuracy meaning good approximation to equilibrium) and low privacy budget in fully distributed setting.\n\nThe paper gives impossibility results which show that achieving vanishing privacy loss and vanishing error simultaneously is impossible under two regimes: when the accuracy metric is Euclidean, or when the adversary can access all communication channels.\n\nUnder more restricted conditions where an adversary can access only a limited number of channels, and accuracy measured by a certain exploitability metric, they design a distributed, DP algorithm where each player sends a noisy version of their message to neighbors and updates using a regularized proximal gradient step with an adaptive regularizer scaled by the player’s degree.\n\nIt is then shown that for this algorithm, both the expected exploitability and the privacy budget vanish as the number of players $N$ grows, in both sparse and dense graphs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-rigorous formalization of distributed equilibrium computation with DP using the adjacency notion from [Huang et al. (2015)](https://arxiv.org/pdf/1401.2596) (edge-DP).\n\n- The impossibility theorems are conceptual but insightful: they clarify why prior work could not achieve both accuracy and privacy simultaneously. These negative results provide valuable theoretical boundaries.\n\n- Novel distributed algorithm with the adaptive regularization which balances privacy noise and update stability, allowing performance to improve with scale.\n\n- Asymptotic trade-off analysis: Theorem 7.1 shows how both exploitability and privacy budget can converge to zero as number of players $N \\rightarrow \\infty$ a clear improvement over prior results in aggregative and network games."}, "weaknesses": {"value": "- Although the introduction cites “security games” and “financial markets” as motivating examples, the setting of the paper is quite abstract and conceptual. It is hard to imagine that actual scenarios in security or finance would actually fit into this framework, though I understand that the results give the theoretical limits in private fuly distributed games.\n\n- Limited privacy scope: The paper only considers the edge-DP definition considered by [Huang et al. (2015)](https://arxiv.org/pdf/1401.2596) (edge-DP). \n\n- Some central references seem to be missing: e.g. [Cyffers et al., 2022](https://proceedings.neurips.cc/paper_files/paper/2022/file/65d32185f73cbf4535449a792c63926f-Paper-Conference.pdf) is missing, as well as at other works by Cyffers and Bellet on decentralized ML. A recent paper by [El Mrini et al., 2024](https://proceedings.mlr.press/v235/mrini24a.html) also considers a local view of decentralized ML algorithms. [Cyffers et al., 2022](https://proceedings.neurips.cc/paper_files/paper/2022/file/65d32185f73cbf4535449a792c63926f-Paper-Conference.pdf) also considers a scenario where the adversary has only a local view and improve upon LDP guarantees. While the DP definitions are different: node-value level DP, meaning that the graph and edges stay constant instead of edge-DP like in this paper, I think thery are relevant.\n\n- The fact that Algorithm 1 requires the harmonic mean of players degrees, $\\bar{\\mathcal{N}}$ and total number of players, i.e., global information, makes it less practical since I think some central entity would be required to communicate that information."}, "questions": {"value": "- Why to only consider the edge-DP definition? Why not e.g. player-wise DP or DP for the values of the nodes?\n\n- Could you think of practical scenarios where the results of this paper would be useful?\n\n- Or: could you think of extending the results of this paper to a practical scenario where they would be useful?\n\n- In Thm. 6.1, what is the improvement over LDP scenario, i.e., when everything is observed? It seems as if the guarantees of Thm. 6.1 get weaker as $N$ grows, or am I reading it wrong? So the vanishing error of Thm. 7.1 comes somehow from the averaging effect?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XWagvR0g0Y", "forum": "7qNbWQTV26", "replyto": "7qNbWQTV26", "signatures": ["ICLR.cc/2026/Conference/Submission14755/Reviewer_UsT1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14755/Reviewer_UsT1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943194675, "cdate": 1761943194675, "tmdate": 1762925113305, "mdate": 1762925113305, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors establish both impossibility results and positive results in the problem of computing equilibria in polymatrix games. \nPaper demonstrates that achieving both high accuracy and low privacy budget is impossible if the adversary has access to all communication channels or if Euclidean distance is used as the accuracy metric. Conversely, the authors propose an algorithm that achieves differential privacy while converging to coarse correlated equilibrium (CCE) with guarantees on exploitability. A key contribution is demonstrating that both privacy and accuracy can improve as the number of players increases, particularly for dense or sparse graph structures, through careful regularization and noise injection."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "**Novel problem domain.** The work pioneers DP equilibrium computation in polymatrix games, a richer class than previously studied DP games such as \"Two-Player Zero-Sum\" games and \"Aggregative\" games. The notion of adjacent games that is used --- reasonable and simplifies the formal statements.\n\n**Impossibility results (Lemmas 3.1 and 3.2).** Prior DP game-theory work mostly considered aggregative games or centralized settings, but showing a lower bound on the Nash-gap for DP algorithms under full eavesdropping is a strong negative result, highlighting a fundamental privacy–accuracy trade-off.\n\n**Positive results (Th. 5.1–7.1).** Give us that both exploitability and privacy cost vanish as $N\\to\\infty$, this results is stated formally in Th. 7.1. The authors highlight differences with prior works, which suffer a differential privacy budget, no matter how large $N$ is, and vice versa.\n\n**Method.** The proposed algorithm (_Find CCE in polymatrix games with DP guarantee_) achieve both perfect accuracy and DP guarantees as the number of players in the game increases. Also, the efficient implementation on PyTorch is provided."}, "weaknesses": {"value": "**One limitation regarding the adversary model.** The positive results assume the adversary can only see a constant number of communication channels. In practice, an adversary might intercept many edges. If it sees $k$ channels, then the privacy cost scales by $k$. It would be helpful to discuss how realistic your “bounded channels” assumption is, and how performance degrades as $k$ grows.\n\n**You can extend the limitations a bit.** As mentioned in limitations, you only discuss polymatrix games. But I would clarify that your impossibility results focus on zero-sum polymatrix games; it is not clear if similar impossibility holds for general-sum cases.\n\n**Extended experiments.** I think you can add more problems to your codebase, e.g., different topologies of the polymatrix game’s graph."}, "questions": {"value": "**CCE vs Nash.** \nThe algorithm is analyzed in terms of coarse correlated equilibrium (CCE) regret. Do the authors have comments on whether a Nash equilibrium (or approximate NE) can be learned with DP under similar conditions? Could the algorithm be modified to target NE?\n\n**Graph assumptions.** Are there any assumptions on the polymatrix game’s graph? Since the privacy bound involves shortest path distances: could highly irregular graphs (e.g., diameter ~ log N vs diameter ~ N) affect the results then?\n\n**Parameter choice.** Th. 7.1 requires setting $\\eta,T,\\sigma$ as functions of $N$. How sensitive are the results to these choices? In practice, how would one tune these parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jVUPg0jp9X", "forum": "7qNbWQTV26", "replyto": "7qNbWQTV26", "signatures": ["ICLR.cc/2026/Conference/Submission14755/Reviewer_ssdW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14755/Reviewer_ssdW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965263425, "cdate": 1761965263425, "tmdate": 1762925112962, "mdate": 1762925112962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of zero-sum polymatrix games under differential privacy (DP). The notion of DP is defined over adjacent games that differ by a single utility matrix.\n\nBuilding on this definition, the authors establish two lower-bound results, showing that to achieve meaningful privacy and convergence guarantees, (i) the adversary must not have access to all communication channels, and (ii) the accuracy metric cannot be based on the Euclidean distance. The paper further provides upper-bound results demonstrating that low privacy parameters and small exploitability can be achieved when the adversary has access to only a single user’s communication channel."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The lower-bound results are solid contributions, as they establish the necessary conditions for ensuring valid privacy and utility guarantees. I also appreciate that the authors provide detailed explanations and intuitions behind most of the theoretical results, which greatly help readers better understand these concepts."}, "weaknesses": {"value": "1. In Theorem 6.1, the privacy of a single user’s observation is defined as the average privacy loss across all users. However, the corresponding privacy notion in Equation (7) is defined as a maximum over all users, i.e., it bounds the worst-case privacy loss. Therefore, the comparison between the lower- and upper-bound results may not be entirely fair, since Equation (7) imposes a stronger constraint on privacy loss (maximum vs. average). It would be helpful to clarify whether Theorem 6.1 still holds if we instead upper bound the maximum privacy loss rather than the average.\n2. Following Lemma 3.2 (Lines 279–281), the authors present an example illustrating the instability of the best response with respect to other players’ strategies. I am curious how this instability is circumvented when exploitability is used as the performance metric instead of Euclidean distance.\n3. The dependence on $N$ for both the accuracy and privacy loss in the upper-bound results appears quite weak, scaling with $O((\\log N)^{-1/3})$. The authors note that this is the first result showing diminishing accuracy with sufficiently large $N$, which is an interesting finding. It would strengthen the discussion to also include a comparison with the non-private convergence rate, to better illustrate the performance gap between private and non-private settings."}, "questions": {"value": "All questions are included in \"Weaknesses\" section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "mJMinYgjU9", "forum": "7qNbWQTV26", "replyto": "7qNbWQTV26", "signatures": ["ICLR.cc/2026/Conference/Submission14755/Reviewer_8A83"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14755/Reviewer_8A83"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968502436, "cdate": 1761968502436, "tmdate": 1762925112471, "mdate": 1762925112471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}