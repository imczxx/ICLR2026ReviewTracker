{"id": "NpQ8QZjL3o", "number": 19481, "cdate": 1758296608296, "mdate": 1759897036630, "content": {"title": "ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models", "abstract": "Vision Language Models (VLMs) show impressive capabilities in integrating and reasoning with both visual and language data. But these models make mistakes. A common finding -- similar to language models -- is their tendency to hallucinate, i.e., generate plausible-sounding text that is not grounded in the visual input, or at worst, is contradictory. A growing consensus attributes this behavior to an over-reliance on language -- especially as the generation progresses, the model suffers from a ``fading memory effect'' with respect to the provided visual input. We study mechanisms by which this behavior can be controlled. Specifically, using ideas from geometric algebra and relational compositions, we propose the addition of a small, trainable module (named ReCo) on top of any VLM -- no other modification is needed. We show that such a simple/lightweight module is able to mitigate the fading memory effect on the most widely used VLMs, where we see performance improvements on multiple benchmarks. Additionally, we show that our module can be combined with many of the other approaches for reducing hallucination, where we achieve improved results for each one.", "tldr": "", "keywords": ["VLM", "hallucination", "geometric algebra", "composition", "black-box"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6499b3745fb2a241d49802a6f3cf12fc29bbe0a9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces ReCo, a small trainable module that plugs into existing Vision-Language Models (VLMs) to counter their tendency to hallucinate—outputs that aren’t grounded in the image. Motivated by the observed fading memory effect (visual information’s influence diminishes as text generation proceeds), ReCo draws on ideas from geometric algebra and relational composition to explicitly recombine visual and textual signals before each next-token prediction, without modifying the base VLM. Applied to InstructBLIP, LLaVA, and MiniGPT-4, ReCo yields consistent gains across multiple benchmarks. The module is complementary to other hallucination-mitigation techniques, further improving results when combined."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- ReCo adds a tiny trainable layer before the prediction head, requiring no changes to the base VLM, minimal training, and negligible deployment overhead.\n\n\n- Demonstrates robust improvements across multiple VLMs (InstructBLIP, LLaVA, MiniGPT-4) and benchmarks (e.g., CHAIR, POPE, AMBER, HallusionBench), indicating broad applicability.\n\n\n- Stacks cleanly with prior decoding/mitigation techniques and yields further gains, supporting practical integration into real systems."}, "weaknesses": {"value": "- The images are too —they’re not vector graphics. \n- The citation format also looks incorrect.\n- Ablations don’t isolate the “composition” effect，such as gains from W_T​ vs. W_I​, image-token pooling choices, and alternative operators aren’t disentangled.\n- Most of the benchmarks used in the paper are discriminative. Consider adding generative benchmarks as well—for example, FaithScore: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models.\n\n- Motivation is unclear: the paper does not convincingly justify why geometric-algebra/VSA–style set/composition operations are needed here. \n- In addition, performance should be compared against training-based methods, such as Aligning Large Multimodal Models with Factually Augmented RLHF, FGAIF: Aligning Large Vision-Language Models with Fine-Grained AI Feedback, and Mitigating Object Hallucination in Large Vision-Language Models with Human-Free Reinforcement Learning. The paper also omits some training-free baselines, for example Woodpecker: Hallucination Correction for Multimodal Large Language Models and A Unified Hallucination Mitigation Framework for Large Vision-Language Models."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "G3T8oYvpgG", "forum": "NpQ8QZjL3o", "replyto": "NpQ8QZjL3o", "signatures": ["ICLR.cc/2026/Conference/Submission19481/Reviewer_tQ4u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19481/Reviewer_tQ4u"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760803436358, "cdate": 1760803436358, "tmdate": 1762931389885, "mdate": 1762931389885, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Reminder Composition (ReCo), a lightweight module designed to mitigate the fading memory effect in Vision-Language Models (VLMs). ReCo operates right before the language head, re-injecting visual embeddings at every decoding step to reinforce visual grounding. The process is formulated using Geometric Algebra (GA) and implemented as a small trainable layer, which can be trained independently or jointly with the entire model. Experimental results show consistent performance improvements across all evaluated VLMs, and ReCo can be combined with other hallucination-mitigation approaches such as VCD, M3ID, and AvisC. Furthermore, qualitative analyses demonstrate that ReCo not only reduces object-related hallucinations but also alleviates structural hallucinations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides an interpretation of the fading memory effect in VLMs through the lens of Geometric Algebra, offering a clear and conceptually motivated formulation of the proposed ReCo module.\n- The proposed method demonstrates consistent improvements across evaluated VLMs, supported by both quantitative and qualitative experiments that validate its effectiveness in reducing hallucinations and enhancing visual grounding."}, "weaknesses": {"value": "- The proposed method appears conceptually similar to Li et al. (ICML 2025), “The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering.” A more explicit discussion of the similarities and differences between ReCo and this prior work would clarify the paper’s unique contribution.\n- Continuously re-injecting image features at every decoding step may risk making the visual signal overly dominant, potentially reducing the language model’s contextual or semantic flexibility. An analysis of this trade-off would strengthen the argument.\n- The transition from the Geometric Algebra formulation (Eq. 5) to the implementation equation (Eq. 6) feels abrupt. A more detailed explanation of how the theoretical formulation maps to the practical design, and especially what constitutes the “small trainable layer,” would improve clarity.\n- Line 229: When the model is fine-tuned with $B_t$, it is unclear whether a distribution mismatch might occur at inference when only $T_t$ (without the reminder composition) is provided.\n- To demonstrate the general applicability of the proposed module, it would be valuable to evaluate it on a wider range of VLMs, including more recent and stronger models such as Qwen-VL or InternVL. This would clarify whether ReCo’s gains hold universally or are primarily effective on lower-performing baselines.\n- Including a user study for quantitative evaluation would further substantiate the qualitative claims and help assess perceived improvements in hallucination reduction.\n- The paper lacks an ablation study that isolates the contribution of ReCo’s design. Without such analysis, it is unclear whether the improvement stems from the proposed structure itself or simply from an attention refresh effect. It would be informative to explore how performance varies with respect to the injection timing/location of visual features and the weighting parameters $W_T$ and $W_I$.\n- In Section 4.2.2, the combination with AvisC seems less effective compared to other methods, yet the paper does not discuss why this interaction may be weaker.\n- In Section 4.2.5, including a text-only baseline would make the interpretation of results clearer and help isolate the visual contribution.\n- (Minor) References are currently written inline as plain text rather than enclosed in parentheses, which slightly disrupts readability. Consistent formatting, e.g., POPE (Li et al., 2023), would improve presentation quality."}, "questions": {"value": "Please refer to Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xZc5XyUTA4", "forum": "NpQ8QZjL3o", "replyto": "NpQ8QZjL3o", "signatures": ["ICLR.cc/2026/Conference/Submission19481/Reviewer_pxDz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19481/Reviewer_pxDz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760962100575, "cdate": 1760962100575, "tmdate": 1762931389380, "mdate": 1762931389380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ReCo, a lightweight and plug-and-play module designed to mitigate the fading memory effect in Vision-Language Models (VLMs). By explicitly enforcing compositional reasoning between visual and textual representations, ReCo effectively reduces hallucination behaviors without modifying the backbone architectures. The paper provides extensive experiments across multiple benchmarks and shows consistent improvements over several baselines. Overall, this work is well-motivated and technically sound, but certain aspects of presentation, experimental depth, and comparison to recent methods could be further improved."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides a clear and intuitive explanation of the fading memory effect, supported by a well-designed visualization in Figure 2. This helps readers quickly grasp the core problem that ReCo aims to solve.  \n2. The introduction and theoretical background sections are detailed and logically structured, giving readers a solid understanding of the motivation behind Reminder Composition.  \n3. Experiments are conducted across five diverse benchmarks, demonstrating the general effectiveness of ReCo in mitigating hallucinations across multiple VLM architectures (InstructBLIP, LLaVA, MiniGPT-4).  \n4. The proposed approach is model-agnostic and lightweight, requiring minimal additional training, which makes it easy to integrate into existing systems."}, "weaknesses": {"value": "1. In Figure 2, it is unclear which model the attention maps are derived from, and what the corresponding input data and generated tokens are. Clarifying these details would help readers better understand the relationship between visual attention and generated content.  \n2. While the introduction is well-written, it feels somewhat verbose. The authors might consider streamlining it and improving the logical transitions between paragraphs—for example, the sudden shift to the “Compositionality and Geometric Algebra” section disrupts the flow.  \n3. The comparison section mainly includes three hallucination mitigation baselines from roughly a year ago. It would strengthen the work to include more recent methods such as {Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration} and {Reducing Hallucinations in Large Vision-Language Models via Latent Space Steering}.  \n4. The experimental analysis would benefit from more detailed ablation studies and diagnostics. For example, analyzing sensitivity to hyperparameters, conducting error analysis, and comparing visual attention strength before and after applying ReCo could provide deeper insights into its behavior.  \n5. While ReCo’s cross-model applicability is partially validated on InstructBLIP, LLaVA, and MiniGPT-4, it would be valuable to evaluate the method on more recent and advanced models such as Qwen2.5-VL or InternVL2.5 to assess scalability.  \n6. Minor issue: All figures in the manuscript appear blurry. Using vector graphics could greatly improve readability, especially for small text and fine visual details."}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UzVNmkwIXV", "forum": "NpQ8QZjL3o", "replyto": "NpQ8QZjL3o", "signatures": ["ICLR.cc/2026/Conference/Submission19481/Reviewer_sYHB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19481/Reviewer_sYHB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761518691412, "cdate": 1761518691412, "tmdate": 1762931388966, "mdate": 1762931388966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The goal of \bthe paper is to mitigate hallucination in VLMs. The paper begins by describing the fading memory effect (also known as language prior or textual inertia), wherein VLMs progressively lose attention to visual tokens during the generation process. To balance visual and textual information, the paper considers the compositionality. Starting from Eq. (4), the paper introduces ReCo, which is composed of a linear combination of visual tokens and the current text tokens, thereby ensuring cross-modal attention during generation. The paper applies ReCo to the last layer using just two additional linear layers, which is minimal overhead in terms of parameters and computation. The paper shows the effectiveness of ReCo on hallucination benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**S1. Efficient.** ReCo requires a low number of parameters and is located on the final hidden representation, resulting in low computational overhead.\n\n**S2. Easy to Implement.** The method is straightforward to integrate, requiring only two lines of code.\n\n**S3. Effective Across Diverse Hallucination Benchmarks.** The proposed approach demonstrates the effectiveness across multiple benchmark datasets."}, "weaknesses": {"value": "**W1. Ambiguity of the black box.** Generally, we cannot access the last hidden layer in black-box models, such as GPT and Claude. With these black-box models, we can obtain only the generated results, namely the text. Thus, the proposed method cannot be used for black box models. \n\n**W2. Comparison with training methods.** Hallucination mitigation methods can be categorized into training-based and training-free approaches. The proposed method falls within the training-based approach. The paper requires a fair comparison with other training-based methods (M3ID + DPO, HACL). Showing performance gains when applied to contrastive decoding is insufficient; a direct comparison with existing training-based methods is needed.\n\n**W3. General task capabilities.** The proposed method requires training. Does ReCo preserve the general capabilities of VLMs across diverse general tasks?\n\n**W4. Lack of Ablation Study.** In the context of relational composition, the attention is matrix binding operator. Thus, cross-attention is also possible to balance compositionality."}, "questions": {"value": "While the paper provides an overview of Geometric Algebra, its relevance and contribution to the subsequent analysis are not entirely clear."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GFrKDBEGJ0", "forum": "NpQ8QZjL3o", "replyto": "NpQ8QZjL3o", "signatures": ["ICLR.cc/2026/Conference/Submission19481/Reviewer_Dm4D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19481/Reviewer_Dm4D"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903541548, "cdate": 1761903541548, "tmdate": 1762931388468, "mdate": 1762931388468, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}