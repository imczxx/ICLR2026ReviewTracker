{"id": "KFEaiNgon5", "number": 13309, "cdate": 1758216323260, "mdate": 1759897446219, "content": {"title": "CAUSAL REASONING WITH LARGE FOUNDATION MOD- ELS TO GUIDE DYNAMIC SYSTEM FORECASTING", "abstract": "Prevailing data-driven models for spatio-temporal forecasting excel at interpolating within known patterns but often falter in critical real-world scenarios. This failure stems from a fundamental flaw: they learn \\textbf{spurious correlations} from raw data, bypassing the underlying semantic and physical principles that form the true causal pathways. To address this, we introduce \\textbf{\\method{}} (Physics-informed Reasoning and Interpretation for Spatio-temporal Modeling), a framework that performs a \\textbf{principled causal intervention}. \\method{} employs a Vision-Language Model (VLM) to interpret spatio-temporal snapshots into semantic narratives, and a Large Language Model (LLM) to reason with these narratives and explicit physical laws, generating a causally-informed textual guidance. This guidance is then encoded to steer a downstream numerical predictor. Extensive experiments across fluid dynamics, weather forecasting, and urban traffic demonstrate that this intervention significantly enhances model capabilities. By repairing the causal chain,  boosts \\textit{out-of-distribution (OOD) generalization}, improves \\textit{prediction under data sparsity}, and sharpens \\textit{extreme event prediction}. Our work pioneers a new paradigm that unifies the pattern recognition of traditional models with the causal reasoning of large foundation models, paving the way for more reliable AI in science.", "tldr": "", "keywords": ["AI for Science"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e205f7e35fb5e3b5f2f67b6cf6ddca7db72473bc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies the spatio-temporal forecasting problem. The authors propose the Physics-informed Reasoning and Interpretation for Spatio-temporal Modeling (PRISM) method to address the spurious correlations problem. Specifically, PRISM utilizes the vision-language model (VLM) to process the spatial-temporal snapshots into semantic narratives, then an LLM will reason through the narratives to generate the causal textual guidance. Authors conduct experiments on several real-world applications (e.g., weather forecasting) to show the effectiveness of PRISM."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is sound and clearly demonstrated. I agree with the authors that the spatial-temporal modeling problem is important and challenging, and pure data-driven methods may lack the ability to capture causal or physical mechanisms.\n\n2. Figure 2 is well drawn, clearly showing the procedure of the proposed method.\n\n3. The main experiments and ablation studies are comprehensive, validating the authors' claims in the introduction."}, "weaknesses": {"value": "1. I suggest that authors revise Figure 1 (a). I believe the current version cannot truly reflect the spurious association. In causal inference, the spurious association is mainly represented by a common cause [1], rather than just an arrowhead or a shortcut. Besides, I think there exists a causal relationship between the historical information and true prediction (rather than pure spurious association). \n\n2. Since the spatial-temporal modeling is an active and important area and this work is inspired by causality. I would encourage authors to discuss more works of spatial-temporal causal inference, which include (but are not limited to): [2] and [3].\n\n3. I believe authors didn't discuss one of the most important works of MLLMs: LLaVA (visual instruction tuning) [4]. \n\n4. How did authors handle the hallucination problem of MLLMs or LLMs? I believe the current MLLMs may exhibit some serious hallucination problems. What if the outputs of MLLMs are incorrect or not accurate?\n\n5. I am not totally convinced by the authors' implementation of the prediction. It seems that the only causal (physical) part is the generation of the guidance text; the (most) important prediction part seems to be the simple fusion of text and historical features. I suggest that authors elaborate on this part.  \n\n> [1] Pearl J. Causal inference in statistics: An overview[J]. 2009.\n\n> [2] Li H, Chi H, Liu M, et al. Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation[C]//Forty-second International Conference on Machine Learning.\n\n> [3] Christiansen, R., Baumann, M., Kuemmerle, T., Mahecha, M. D., and Peters, J. Toward causal inference for spatio-temporal data: conflict and forest loss in colombia. Journal of the American Statistical Association, 117(538): 591–601, 2022.\n\n> [4] Liu H, Li C, Wu Q, et al. Visual instruction tuning[J]. Advances in neural information processing systems, 2023, 36: 34892-34916."}, "questions": {"value": "Please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "C27iTTTiMm", "forum": "KFEaiNgon5", "replyto": "KFEaiNgon5", "signatures": ["ICLR.cc/2026/Conference/Submission13309/Reviewer_ZMER"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13309/Reviewer_ZMER"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761208502038, "cdate": 1761208502038, "tmdate": 1762923974856, "mdate": 1762923974856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PRISM, a wrapper around a spatio-temporal predictor for short-horizon forecasting. The task can be described as follows: given historical grid frames, predict future frames on tasks like traffic flow, convective weather nowcasting, and 2D Navier-Stokes vorticity. PRISM uses a frozen VLM->LLM pipeline to convert recent history into text, combine it with textual \"physical priors\" and produce a guidance text. The text is embedded by a frozen encoder into a single vector $g$. A trainable cross-attention module uses $g$ as a query over the historical features that produces a context that is used to condition the decoder to forecast the future. Only the fusion system and the downstream predictor are trained. The system is evaluated on multiple model backbones."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles the important problem of dynamical systems forecasting.\n- Physically grounding the forecasting process is a sensible direction.\n- Evaluated across a broad set of backbone models.\n- Modular design, easy to graft to many backbones.\n- There are sizeable improvements on the evaluated tasks."}, "weaknesses": {"value": "The formalization, as presented, introduces ambiguity in several places:\n1) VLMs and LLMs are treated as deterministic operators.\n2) LLMs consume ordered token sequences, not sets.\n3) \"Causal intervention\" is rhetorical in the math. Eq 3 has no causal graph, no do operators, no invariances, no identification results.\n4) The LLM does not generate a probabilistic description of future states as claimed. In practice, the authors sample one $T_{\\text{guide}}$ and embed it.\n5) Attention weights are not faithful importance measures without conditions (Wiegreffe & Pinter, EMNLP-IJCNLP 2019; Serrano & Smith, ACL 2019; Bastings & Filippova, BlackboxNLP 2020; inter alia)\n\nFurthermore:\n- The methodology is unnecessarily complicated and hard to follow in its current state. Types (domains/codomains) for functions and variables are missing, obscuring their roles.\n- The manuscript uses promotional phrasing instead of neutral reporting (e.g., \"remarkable reduction\", \"chart-topping 0.089\", \"A Pioneering Paradigm\").\n- Overstated claims (examples):\nL101 \"Fundamentally enhancing its generalization and reliability,\"\nL319 \"universal applicability,\"\nL411 \"unequivocal evidence,\"\nL405 \"The results compellingly demonstrate,\"\nL470 \"proving that our method effectively compensates...\".\n- The paper uses causal terminology, but the setup is not causal.\n- Limited ablations on parts of the system, see questions.\n- Some experimental details are missing, see questions.\n- The linked repository appears to be a placeholder rather than complete, runnable code."}, "questions": {"value": "Questions/Remarks\n\n- Please consider removing causal claims beyond motivation. Describe it as text-guided conditioning instead.\n- Simplify the methodology. Consider dropping the \"reasoning prompt function\" over the powerset of text sets: this is just feeding the VLM summary into an LLM with a fixed prompt.\n- How do we sample relevant physical priors from the repository of physical knowledge? Specify the repository per domain (verbatim items), how priors are selected (rule or heuristic), their ordering, and token budgets. Include a control with shuffled/irrelevant priors.\n- Claim at L080–L084 (strong statement on the fundamental reason of OOD failures). Either cite supporting work or demonstrate it empirically in this paper.\n- Please replace overstatements with precise, statistics-backed statements and soften causal/priority claims to match the presented evidence.\n- Ablations:\n1) Skip the LLM path and use the VLM in its stead to investigate the need for the LLM.\n2) Use the LLM’s hidden representations (i.e., last hidden state) instead of decoding to language and then re-encoding where possible (open-weights models).\n3) Experiment with different fusion methods such as concatenation\n4) Experiment with multi-query vs single pooled vector ($g$).\n\n(You don’t have to run all of these. Pick the most informative.)\n\n- Table 1 contains counterexamples to the headline claims: UNO degrades on Navier Stokes and FNO doesn’t change at all. Analysis/explanation is needed.\n- The OOD split in experiments is described narratively, not formally. Define the OOD set precisely, explain why it is challenging.\n- Tuning parity: Document hyperparameters/search budgets and confirm parity with and without PRISM for each backbone.\n- The paper states ten backbones, but Table 1 enumerates nine (ResNet, U-Net, ViT, SWIN, SimVP, PastNet, FNO, CNO, UNO). Please either add the missing 10th model with results and training details, or correct the count to nine."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b3moxtJMjK", "forum": "KFEaiNgon5", "replyto": "KFEaiNgon5", "signatures": ["ICLR.cc/2026/Conference/Submission13309/Reviewer_dcVx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13309/Reviewer_dcVx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761261673137, "cdate": 1761261673137, "tmdate": 1762923974331, "mdate": 1762923974331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PRISM, a causal intervention framework that uses a VLM to extract semantic narratives from spatiotemporal observations and a LLM to incorporate physical principles into textual guidance that steers downstream predictors. Experiments demonstrate consistent performance gains across fluid dynamics, weather, and urban traffic forecasting tasks, especially in OOD and extreme-event scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The plug-and-play PRISM module yields consistent improvements across 10 architectures and 3 domains, showing usefulness beyond a single model. \n\n2. The OOD results show substantial reduction in degradation, supporting claims of better generalization."}, "weaknesses": {"value": "1.The causal argument is mainly motivational; there is no empirical test of causal variables or interventions beyond better metrics, making the “repair causal pathway” claim not fully justified. \n\n2. The generated semantic/physical guidance is not checked against ground truth expert physical reasoning, so improvements may come from generic feature enrichment rather than true causal reasoning.\n\n3. Prompting for VLM/LLM is critical (e.g., physical principles injected as text), but the paper omits prompt templates and reasoning examples, hurting reproducibility. The provided repository is empty."}, "questions": {"value": "1. Table 2 suggests performance scales with model capacity; could gains be primarily caused by richer text features rather than incorporation of physical laws, and can authors isolate this via prompts without physics input. \n\n\n2. Figure 3 shows guidance improves vortex prediction, but what evidence confirms the LLM actually reasons with Navier-Stokes equations, rather than hallucinating plausible phrases. \n\n\n3. Table 1 includes some negative improvement cases (e.g., ViT on TaxiBJ+ is +0.9% MSE worse); what conditions cause failure, and how does this align with the causal story. \n\n\n4. Guidance text length/quality could affect performance; did authors analyze whether longer guidance vs higher-quality semantics correlates better with improvement."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8IXCKEmsV8", "forum": "KFEaiNgon5", "replyto": "KFEaiNgon5", "signatures": ["ICLR.cc/2026/Conference/Submission13309/Reviewer_7y1c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13309/Reviewer_7y1c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761445229354, "cdate": 1761445229354, "tmdate": 1762923973967, "mdate": 1762923973967, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PRISM, a framework that addresses fundamental limitations in data-driven spatio-temporal forecasting models. The authors identify that traditional models learn spurious correlations by bypassing latent semantic states and physical principles. Extensive experiments demonstrate that PRISM consistently improves diverse architectures as a plug-and-play module, achieving substantial gains in OOD generalization, enhanced prediction accuracy, and improved extreme event forecasting. The work pioneers a new paradigm unifying traditional pattern recognition with symbolic causal reasoning from large foundation models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper convincingly argues for a new AI for Science paradigm where foundation models serve as reasoning partners rather than replacements for numerical methods.\n- The core insight that data-driven spatio-temporal models fail because they learn spurious correlations while bypassing latent semantic states and physical principles is a fresh perspective."}, "weaknesses": {"value": "- The paper frames its contribution as \"causal intervention\" but the evidence provided doesn't adequately support true causal mechanisms. The VLM-LLM pipeline generates descriptions and predictions about physical phenomena, but there's no evidence these capture actual causal pathways rather than sophisticated correlations. To substantiate causal claims, the paper should include intervention experiments. What happens if you deliberately inject incorrect physical principles or contradictory semantic descriptions? If the system is truly learning causal pathways, performance should degrade predictably.\n- The paper claims to bridge semantic and physics gaps but doesn't compare against physics-informed methods, such as PINNs with proper PDE loss terms.\n- The abstract and introduction claim PRISM \"improves prediction under data sparsity\" but this is barely evaluated.\n- Some similar works are not discussed.\n\n[1] Unveiling causal reasoning in large language models: Reality or mirage? NeurIPS, 2024.\n[2] Is knowledge all large language models needed for causal reasoning?"}, "questions": {"value": "- The motivation is not clear. They claimed that traditional models learn a spurious correlation by ignoring latent semantic and physical factors. Physical factors are clear. What is the definition of semantic factors here? They'd better explain it with a practical example. In my view, LLMs have semantic understanding capability.\n-  Running GPT-4V + GPT-4 Turbo for every training sample is likely expensive. How many API calls were made? What's the latency? For the TaxiBJ+ dataset, with presumably thousands of training samples, this could be prohibitive.\n-  Do VLMs genuinely extract semantic concepts or just perform sophisticated pattern matching? For example, does GPT-4V identify \"vortex merging\" because it understands fluid dynamics or because it pattern-matches visual features to text it was trained on?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ehHCetK11O", "forum": "KFEaiNgon5", "replyto": "KFEaiNgon5", "signatures": ["ICLR.cc/2026/Conference/Submission13309/Reviewer_Xipu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13309/Reviewer_Xipu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762234938235, "cdate": 1762234938235, "tmdate": 1762923973607, "mdate": 1762923973607, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}