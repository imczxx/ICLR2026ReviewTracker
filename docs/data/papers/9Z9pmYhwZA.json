{"id": "9Z9pmYhwZA", "number": 20062, "cdate": 1758302002751, "mdate": 1759897003786, "content": {"title": "The Early Bird Catches the Worm: A Positional Decay Reweighting Approach to Membership Inference in Large Language Models", "abstract": "Membership inference attack (MIA) against large language models (LLMs) aim to detect whether a specific data point was\nincluded in the training dataset of LLMs, which have become increasingly critical in many scenarios. \nExisting likelihood-based MIA methods against LLMs treat all token-level scores as equally important, with a latent assumption that the memorization signal is position-agnostic. We argue, however, that this signal is not uniformly distributed. \nInspired by the information-theoretic principle that conditioning reduces uncertainty, we hypothesize that the memorization signal is not uniformly distributed. Instead, it tends to be strongest at the beginning of a sequence—where model uncertainty is highest—and generally decays with token position. To leverage this insight, we introduce Positional Decay Reweighting (PDR), a simple and lightweight plug-and-play method. PDR applies decay functions to re-weight token-level scores from existing likelihood-based MIA methods, systematically amplifying the strong signals from early tokens while attenuating noise from later ones. Extensive experiments show that PDR consistently enhances a wide range of advanced methods across multiple benchmarks.", "tldr": "", "keywords": ["Pretrain Data Detection; Large Language Model;"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c2b12ac87e7c87a2050f47e90df4ef8df244b182.pdf", "supplementary_material": "/attachment/9bc2fb833605cd96959d628952ea673bc708fd5e.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a re-weighting scheme for likelihood based membership inference attacks and empirically tries to show that this redistribution leads to a more distinguishable separation between members and non-members. Several variations of re-weighting schemes have been tested in this work alongside many of the existing likelihood based membership inference attacks, highlighting one of the strengths of this work that this scheme is applicable to existing MIA attacks in a plug and play manner."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "I am listing the primary strengths of this paper as follows:\n\n- The re-weighting framework proposed is is plug-and-play it requires no model retraining or access to internals, and can be combined with existing likelihood-based attacks.\n- The paper covers comprehensive experiments across multiple benchmarks (WikiMIA, MIMIR) and model families (Pythia, LLaMA, OPT, GPT-NeoX), showing consistent improvements.\n- The approach is motivated by a clear information-theoretic principle (“conditioning reduces entropy”) and supported by empirical entropy trends in real text corpora."}, "weaknesses": {"value": "While this work builds from the sound theoretical standing that entropy would reduce as we further condition the generation of later tokens on the earlier generated tokens, it misses out one crucial research work: \"Context-Aware Membership Inference Attacks against Pre-trained Large Language Models\" (https://arxiv.org/pdf/2409.13745v1). \n\nThe authors of the current work test a static weighting functions like linear or exponential or polynomial decay re-weighting, the work \"Context-Aware Membership Inference Attacks against Pre-trained Large Language Models\" has already experimented with a dynamic re-weighting based on the perplexity of the tokens to be generated. They also present some of the assumptions and unique insights taken in the work under review (see Figure 3 where they demonstrate the losses for the beginning and end of sequence for members and non-members)\n\nThis static approach leads to another drawback where PDR assumes a monotonic decay of memorization signal, but this may not hold for heterogeneous or domain-specific datasets (e.g., ArXiv, HackerNews), where entropy trends are volatile. This shows up particularly when observing the results for short sequences.\n\nIn summary, while the work under review has done an excellent job in creating a comprehensive ablation study and testing different re-weighting functions, I find that the methodology proposed to be a primitive of what has already been done in the work linked above. This takes away most of the novelty presented in the work under review. The one part where this work still retains its novelty is where it presents the re-weighting scheme as a plug and play method with other MIA attacks."}, "questions": {"value": "- Kindly let me know why you missed this work in the literature review \"Context-Aware Membership Inference Attacks against Pre-trained Large Language Models\"?\n\n- Did you experiment with dynamic re-weighting?\n\n- If I missed any detail in the work which you believe is important, please let me know, I'm open to further discussion on this review."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3gU8tkv2P3", "forum": "9Z9pmYhwZA", "replyto": "9Z9pmYhwZA", "signatures": ["ICLR.cc/2026/Conference/Submission20062/Reviewer_NuRy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20062/Reviewer_NuRy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760810883399, "cdate": 1760810883399, "tmdate": 1762932954642, "mdate": 1762932954642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses membership inference attacks (MIA) on large language models, which determine whether specific data points were included in training datasets. The authors identify a critical limitation in existing likelihood-based MIA methods: they treat all token positions equally despite memorization signals being concentrated at sequence beginnings. The paper proposes Positional Decay Reweighting (PDR), a lightweight plug-and-play framework that applies monotonically decreasing weights to token-level scores based on position, systematically amplifying early signals while attenuating later noise.\n\n\nThe core insight is grounded in information theory and empirical observation. As autoregressive models process sequences, conditioning on more context reduces predictive uncertainty, leading to decreasing token-level entropy. The authors demonstrate that early high-entropy tokens exhibit larger discriminative gaps between member and non-member samples, while later tokens with abundant context offer diminishing discriminative power. Existing methods like Loss, Min-k%, and Min-k%++ are \"position-agnostic\" and dilute these strong early signals by averaging them with less informative later positions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "## Originality\n\nThe paper demonstrates strong originality by being the first to systematically analyze the positional nature of memorization signals in membership inference attacks, revealing that existing methods suffer from a fundamental \"position-agnostic\" limitation. The key insight—that memorization evidence concentrates at sequence beginnings where entropy is highest—is elegantly grounded in information theory yet represents a novel lens for understanding privacy leakage in LLMs. Rather than proposing another scoring function, the authors introduce a creative meta-level framework that enhances existing methods, marking genuine conceptual advancement.\n\n## Quality\n\nThe technical quality is exceptionally high, with comprehensive evaluation spanning two benchmarks (WikiMIA and MIMIR), nine model architectures, multiple sequence lengths, and achieving consistent improvements (up to +4.7 AUROC for Min-k%++). The ablation studies are thorough and insightful, systematically validating design choices including alternative weighting schemes, decay parameters, and timing of reweighting, while revealing that PDR's simple data-agnostic prior matches impractical dataset-level entropy approaches. \n\n## Clarity\n\nThe paper is well-written with clear motivation and excellent visual presentation. The methodology, experimental setup, and mathematical formulations are thoroughly documented with logical progression from theory to validation, making the work accessible and reproducible.\n\n## Significance\n\nThe works addresses critical real-world needs in data auditing and copyright detection while requiring no model retraining or infrastructure changes due to its plug-and-play nature. The methodological contribution demonstrates how information-theoretic principles can guide practical algorithm design in LLM security, potentially influencing broader approaches to privacy research for autoregressive models."}, "weaknesses": {"value": "## Limited Theoretical Analysis\n\nWhile the paper provides intuitive motivation through information theory, it lacks rigorous theoretical analysis of when and why PDR works. The connection between entropy reduction (H(z|x,y) ≤ H(z|y)) and discriminative power for membership inference is presented informally—the authors acknowledge comparing entropy of different random variables (x_t vs x_{t+1}) rather than the same variable under different conditions, which weakens the theoretical foundation. The paper would benefit from formal analysis establishing under what conditions positional decay maximizes separation between member/non-member distributions, perhaps through concentration inequalities or PAC-style bounds. Additionally, there is no theoretical explanation for why α=1 works well across settings or how to principally select decay functions and parameters for new domains, limiting the method's applicability beyond empirical trial-and-error.\n\n## Inconsistent Performance and Incomplete Characterization\n\nThe results show concerning inconsistencies that are insufficiently analyzed. On MIMIR, improvements are marginal (often <1 AUROC point) compared to WikiMIA's substantial gains, yet the paper primarily attributes this to \"heterogeneous\" datasets without deeper investigation. \n\n## Methodological Concerns in Experimental Design\n\nSeveral experimental choices lack justification and raise questions about generalizability. The hyperparameter selection appears inconsistent: α=1 for most settings but α=0.1 or 0.5 for T=32, with no principled rule provided for practitioners. Figure 4 shows that optimal α varies significantly by method (Loss/Ref prefer sharp decay at α=1, Min-k%/Min-k%++ prefer gentler decay), yet the main results use fixed α=1 for all methods, potentially underreporting PDR's ceiling performance. The paper evaluates only at FPR=0.1% for TPR metrics without justifying this choice or exploring performance across the full FPR range. Most critically, all experiments use pre-training MIA, but many real-world applications involve fine-tuned models where positional patterns may differ—limited FSD experiments don't fully address whether PDR transfers to this setting.\n\n## Insufficient Analysis of Failure Cases and Limitations\n\nThe paper provides minimal analysis of individual failure cases beyond aggregate metrics. While Figures 5 and 7-9 show successful examples where PDR separates previously-tied samples, no examples are shown where PDR incorrectly assigns higher scores to non-members or fails to separate them. What characteristics distinguish sequences where PDR helps versus hurts? Understanding these failure modes is critical for practitioners deciding when to apply PDR.\n\n## Statistical Rigor and Reproducibility\n\nThe paper lacks statistical significance testing—improvements are reported as point estimates without confidence intervals, standard deviations, or significance tests across multiple runs. This is particularly concerning for small improvements on MIMIR where gains are often <1 AUROC point and could be within noise. The paper doesn't specify random seeds, number of evaluation runs, or dataset sampling procedures, limiting reproducibility."}, "questions": {"value": "see weakness above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZWDHp0BnNU", "forum": "9Z9pmYhwZA", "replyto": "9Z9pmYhwZA", "signatures": ["ICLR.cc/2026/Conference/Submission20062/Reviewer_o2Y1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20062/Reviewer_o2Y1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059926795, "cdate": 1762059926795, "tmdate": 1762932954076, "mdate": 1762932954076, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Positional Decay Reweighting (PDR), a plug-and-play method for membership inference attacks (MIA) against LLMs. The authors argue that existing likelihood-based MIA methods are \"position-agnostic\" and claim that memorization signals are stronger at the beginning of sequences where entropy is higher. PDR reweights token-level scores using monotonically decreasing functions (linear, exponential, polynomial) to amplify early signals. The method is evaluated on WikiMIA and MIMIR benchmarks across multiple models, showing modest improvements over baselines like Min-k% and Min-k%++."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Interesting entropy-based motivation: The connection between token-level entropy and memorization signals is well-articulated and grounded in information theory. Figure 1(a) provides compelling empirical evidence for the entropy decay phenomenon.\n\n2. Positional reweighting as a contribution: While not addressing an entirely \"unaddressed\" limitation as claimed, the explicit positional reweighting idea is a reasonable contribution to the MIA literature.\n\n3. Plug-and-play nature: The method is easy to integrate with existing likelihood-based approaches, requiring no model architecture changes or retraining."}, "weaknesses": {"value": "1. **Fundamental mischaracterization of prior work**: The paper opens with the claim that existing methods \"share a fundamental, unaddressed limitation: they are position-agnostic\" (lines 071-073). This is inaccurate. Likelihood ratio attacks like LIRA (Carlini et al.) and critically the work by Mireshghallah et al. [1] are NOT position-agnostic—when computing likelihood ratios with respect to another model, the normalization implicitly adjusts probabilities in a position-dependent manner. More importantly, Min-k% itself is not truly position-agnostic because it selectively uses tokens based on their probabilities, which naturally correlates with position due to the entropy decay the authors themselves identify. This mischaracterization undermines the entire motivation and overstates the novelty of the contribution.\nMarginal and potentially insignificant improvements: Many improvements are quite small (e.g., +0.1 to +0.9 AUROC points in Table 1). The paper provides no confidence intervals or statistical significance testing. Are these improvements beyond noise margins? This is a critical gap that makes it difficult to assess whether PDR provides meaningful gains.\n\n\n2.**Missing critical baselines and citations**: The paper fails to compare against current state-of-the-art MIA methods:\n\nNo comparison with RMIA [2], which represents current SOTA for MIA\nNo comparison with neighborhood-based attacks [3], which are highly relevant\nMissing range membership inference attacks [4] in related work\nMissing Mireshghallah et al. [1] on MLM membership inference with likelihood-based methods\n\nThese omissions make it impossible to contextualize the contributions properly.\n\n3. **Limited exploration of alternatives**: The paper only explores pre-defined decay functions. Why not learn optimal position weights from data? This seems like a natural extension that could provide substantially stronger results. Similarly, why not compare against simple truncation baselines (finding optimal cutoff length)?\n\n4.**Lack of qualitative analysis**: Which specific tokens/positions matter most in practice? The paper shows aggregate statistics but no detailed analysis of what positions actually drive the membership signal. Case studies would substantially strengthen the work."}, "questions": {"value": "1. Learned weights: Have you considered learning the position weights rather than using pre-defined decay functions? Given that you have training data (member/non-member samples), a learned weighting scheme could substantially improve results and would be more principled than manually designed decay functions.\n\n2. Simple truncation baseline: What happens if you just find an optimal cutoff length and truncate sequences there, rather than continuous reweighting? This would be a much simpler method to compare against and would help isolate whether the benefit comes from emphasizing early tokens or from the specific functional form of the decay.\n\n3. Statistical significance: The improvements in many cases are quite small (e.g., Table 1 shows several entries with <1 point improvement). What are the confidence intervals or standard errors on these results? Are the improvements statistically significant or within noise margins? Without this analysis, it's unclear if PDR provides real gains.\n\n4. Qualitative analysis: Can you provide detailed analysis on which specific tokens or positions matter most? Some case studies showing which early tokens drive the membership signal would strengthen the paper considerably. What types of sequences benefit most from PDR? Which benefit least?\n\n5. SOTA comparisons: Why are comparisons with RMIA [2] and neighborhood methods [3] not included? These represent current state-of-the-art for this task. How does PDR compare when applied to these stronger baselines, or how does your best PDR-enhanced method compare against these methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zDv9nypHcW", "forum": "9Z9pmYhwZA", "replyto": "9Z9pmYhwZA", "signatures": ["ICLR.cc/2026/Conference/Submission20062/Reviewer_ab3N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20062/Reviewer_ab3N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20062/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096832416, "cdate": 1762096832416, "tmdate": 1762932953468, "mdate": 1762932953468, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}