{"id": "N22lDHYrXe", "number": 18530, "cdate": 1758288832244, "mdate": 1763318573725, "content": {"title": "Experience-based Knowledge Correction for Robust Planning in Minecraft", "abstract": "Large Language Model (LLM)-based planning has advanced embodied agents in long-horizon environments such as Minecraft, where acquiring latent knowledge of goal (or item) dependencies and feasible actions is critical. However, LLMs often begin with flawed priors and fail to correct them through prompting, even with feedback. We present XENON (eXpErience-based kNOwledge correctioN), an agent that algorithmically revises knowledge from experience, enabling robustness to flawed priors and sparse binary feedback. XENON integrates two mechanisms: Adaptive Dependency Graph, which corrects item dependencies using past successes, and Failure-aware Action Memory, which corrects action knowledge using past failures. Together, these components allow XENON to acquire complex dependencies despite limited guidance. Experiments across multiple Minecraft benchmarks show that XENON outperforms prior agents in both knowledge learning and long-horizon planning. Remarkably, with only a 7B open-weight LLM, XENON surpasses agents that rely on much larger proprietary models.", "tldr": "We propose an LLM-guided exploration algorithm robust to potential errors of LLM-generated high-level plans", "keywords": ["llm-guided exploration", "hierarchical planning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3654dc3946fe9d3aa365e499628b1ec351709e09.pdf", "supplementary_material": "/attachment/369da4bc1652951f74397b18ea2abd44287def81.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents XENON (eXpErience-based kNOwledge correctioN), an LLM-based planning framework for embodied agents in long-horizon environments such as Minecraft. The paper argues that LLMs often carry flawed priors about item dependencies and actions, and fail to self-correct even with feedback. XENON introduces two algorithmic mechanisms—Adaptive Dependency Graph (ADG) for dependency correction and Failure-aware Action Memory (FAM) for action correction—allowing the agent to revise its external knowledge from binary success/failure feedback. Experiments in several Minecraft environments demonstrate that XENON achieves strong performance and robustness, outperforming prior agents including those relying on larger proprietary LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly written and easy to follow. The modular decomposition into ADG and FAM makes the system architecture understandable and well-motivated.\n\n2. The implementation and experimental setup are extensive. The authors carefully evaluate across multiple environments (MineRL, Mineflayer, MC-TextWorld) and provide comprehensive ablations, demonstrating the effectiveness of each module.\n\n3. The work highlights an important issue — how to make lightweight LLM-based agents robust to flawed priors and minimal feedback. This direction is relevant to building scalable, open-weight embodied agents."}, "weaknesses": {"value": "1. The core contribution lies more in system design. The proposed ADG and FAM modules are essentially heuristic procedures (revision by analogy, empirical counting of failed/successful actions) that combine ideas from prior memory-based and failure-driven learning frameworks (e.g., Reflexion, DECKARD, ADAM).\nWhile the integration is clean, the novelty at the algorithmic level is modest.\n\n2. The evaluation is entirely confined to Minecraft-like environments, where planning graphs and item dependencies are discrete and well-defined. It remains unclear whether the proposed mechanisms generalize to less structured or continuous domains (e.g., physical robot control, household tasks).\n\n3. Although ablation studies are included, some aspects (e.g., sensitivity to hyperparameters like $c_0$, $\\alpha_i$, $x_0$) are not deeply explored. It is also unclear how well the algorithm scales when the number of items or actions grows substantially.\n\n4. While the paper argues for learning dependencies purely from interaction, it does not explain why using external structured sources such as Minecraft Wiki is undesirable or infeasible. Since such knowledge bases can already provide accurate dependency graphs, the motivation for building and correcting knowledge from scratch appears weak or artificially constrained. A discussion comparing learning from experience vs. retrieving from knowledge bases would strengthen the motivation."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "R68kXQBqGw", "forum": "N22lDHYrXe", "replyto": "N22lDHYrXe", "signatures": ["ICLR.cc/2026/Conference/Submission18530/Reviewer_S6YL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18530/Reviewer_S6YL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18530/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761230132627, "cdate": 1761230132627, "tmdate": 1762928226817, "mdate": 1762928226817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes XENON, an LLM-based agent that algorithmically corrects its external planning knowledge from interaction experience, aiming to overcome flawed LLM priors and sparse feedback in long-horizon Minecraft tasks. Two key components drive the method: (1) an Adaptive Dependency Graph (ADG) that initializes a dependency graph using an LLM and then revises it from successful trajectories via a procedure called RevisionByAnalogy; and (2) a Failure-aware Action Memory (FAM) that maintains empirical success/failure counts per (item, action) to prune invalid actions, explore under-tried ones, and trigger ADG revisions when all actions for an item are deemed invalid. The agent is evaluated across MineRL and Mineflayer. Experimental results show that XENON outperforms other baselines. With a 7B open-weight planner (Qwen2.5-VL-7B), it attains competitive or superior SR compared with agents that rely on larger proprietary models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles a real failure mode: LLM priors over item dependencies and actions are brittle and hard to self-correct with only binary feedback. Treating the LLM as a planner while moving correction into algorithmic external memory is a crisp, testable design choice.\n\n2. Using Qwen2.5-VL-7B, XENON outperforms or rivals methods using GPT-4/4V on several long-horizon task groups, particularly when oracle dependencies are provided. It still performs strongly with learned dependencies on challenging tasks.\n\n3. This paper provides a detailed account of the motivation and methodology, along with comprehensive implementation details and experimental setup, making it easy to follow."}, "weaknesses": {"value": "1. The proposed method is simple and intuitive, akin to prompting an LLM to correct memory and graphs, lacking technical innovation.\n\n2. The procedure references “similar, successfully obtained items” but the similarity function, features, and retrieval specifics are not fully spelled out in the main text (embedding choice, distance metric, negatives, and sensitivity). This matters because ADG’s replacement set can systematically bias learning if similarity is noisy.\n\n3. The design hinges on $c_0$, $x_0$, $a_i$, $a_s$. While intuitively motivated (hallucination handling, controller tolerance), the paper does not present comprehensive ablations on these hyperparameters or learning stability across seeds, leaving robustness to tuning somewhat unclear.\n\n4. The approach is tested only in Minecraft variants; claims about “practical embodied agents” would be stronger with at least one additional domain (e.g., household manipulation or web-based embodied tasks) or a clearer argument for portability."}, "questions": {"value": "Table 3 shows that some baselines, such as Optimus-1, outperform XENON on certain simple task groups, while XENON significantly outperforms the baseline on difficult task groups like Diamond. What causes this phenomenon? Are the experimental settings consistent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WWIqpXIbti", "forum": "N22lDHYrXe", "replyto": "N22lDHYrXe", "signatures": ["ICLR.cc/2026/Conference/Submission18530/Reviewer_DZb7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18530/Reviewer_DZb7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18530/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761311062406, "cdate": 1761311062406, "tmdate": 1762928226425, "mdate": 1762928226425, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes XENON, a method for learning Minecraft recipes and using this learned knowledge to solve Minecraft problems. XENON uses an LLM to generate an initial set of recipes (the graph). Then, it refines it by trying to use it and observing if it works or not. If it does not work, XENON tries to modify the recipe. After sufficient amount of tries, XENON will give up and state that the item is an hallucination. The author evaluate this on a standard set of Minecraft tasks from the MineRL benchmark and a text version of Minecraft."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tLearning the recipes by interacting with the environment makes sense and I appreciate its integration with the LLM agent. \n2.\tThe results show nice improvements over the ablation and baseline. \n3.\tThe solution is designed to handle execution delays"}, "weaknesses": {"value": "1.\tThe paper is not sufficiently self-contained. In particular, there authors assume the reader knows how DECKARD works (e.g.,in line 172). Note that DECKARD was only published in Arxiv and it not well known. \n2.\tI am not convinced about the generality of the approach because it relies on hyper parameters that I guess are tuned for this domain. \n3.\tSome details are not clear, and there are quite a few design choices that seem arbitrary to me. See below in the list of questions."}, "questions": {"value": "1.\tLines 127-128: It seems your graph does not support cases where crafting N items of one type create M>1 items of another type, since you only have q for the quantity of the resource, but no parameter for the quantity of the resulting items. For example, consider the case where CRAFT on two logs create four sticks. \n2.\tLine 138: When the controller executions these subgoals” – how does the controller do this? \n3.\tWere the parameters of XENON tuned differently for each test goal?\n4.\tWhat is a “context-aware reprompting” technique mentioned in line 268?\n\nLine 22: What makes an LLM be “open-weight”?\nLines 84-90: The first and second contribution are actually only one contribution. What is the difference between them? (one proposes XENON, the other explains how XENON works…)\nLine 104: What is a “… robust action correlation”?\nLine 114: What is a “parametric knowledge”?\nThe EGA metric: isn’t it just the mean over the metric you mentioned in (1)? Why do we need a new name for this metric? (line 288)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fSybLxgUv2", "forum": "N22lDHYrXe", "replyto": "N22lDHYrXe", "signatures": ["ICLR.cc/2026/Conference/Submission18530/Reviewer_JH8W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18530/Reviewer_JH8W"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18530/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876805206, "cdate": 1761876805206, "tmdate": 1762928223507, "mdate": 1762928223507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces XENON, an agent that provides a training-free solution to revise knowledge algorithmically from experience without changing the parameters of the LLM. This addresses hallucinations caused by flawed priors inherent in LLMs. Specifically, the paper models knowledge as a directed acyclic graph, where nodes represent Minecraft items and directed edges represent dependence and actions. The model initially uses an LLM to distill and initialize an imperfect Dependency Graph, which is then adaptively revised using the RevisionByAnalogy technique. If a dependency fails repeatedly during rollouts, it is deleted, while for less-tried items, a similar, previously obtained item is sampled to replace the original dependency. Action selection is optimized using Failure-aware Action Memory (FAM) through an elimination method. \nThe agent is validated using 7B-qwen2.5-vl in three different environments—MineRL, Mineflayer, and MC-TextWorld. The results show that XENON is uniquely robust to LLM hallucinations and adapts to different control policies, achieving state-of-the-art performance in the same domain."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a novel algorithmic approach for planning that does not require retraining LLMs, offering an efficient solution to improve LLMs’ knowledge representation from experience.\n- The ablation study clearly demonstrates that Adaptive Dependency Graph (ADG) and FAM are highly robust to initial errors. They effectively recover the correct dependency graph despite the presence of flawed priors. Moreover, no additional LLMs are required to generate these priors, which greatly enhances the efficiency of the ablation. The separate analysis of ADG and FAM’s impacts aids in understanding their individual contributions. This constitutes a well-designed experiment to validate the framework.\n- The visual quality of the figures is commendable. The graphical representations are intuitive and help readers easily grasp the experimental setup and results"}, "weaknesses": {"value": "1. The paper states (Line 126) that knowledge is modeled as a directed acyclic graph. However, it is unclear how the system detects and resolves cyclic structures that may arise during initialization ( e.g. when a wooden axe is required to obtain logs, logs produce planks, and planks are used to craft the axe). I suggest clarifying whether cycles are possible in practice and, if so, how they are algorithmically identified and dismantled.\n2. In Line 212, the method refers to selecting required items for less-tried nodes based on similarity. However, It seems that the notion of “similarity” is not formally defined in the current draft. \n3. The ADG is a relatively complex algorithm, and presenting it only with diagrams results in high information density. It is recommended to include pseudocode for better clarity and reproducibility.\n4. The paper discusses both the control policy and the XENON framework in detail; however, it lacks experimental analysis regarding the role of the LLM itself. If the initial dependency graph were directly provided without using an LLM, and actions were sampled using MCTS rather than LLM-based selection, would the agent still be able to complete the planning task? What is the essential contribution of the LLM within XENON? I believe an ablation study in this regard would be valuable."}, "questions": {"value": "1. In the MineRL environment, approximately how many episodes are required for the dependency-action graph to converge? Additionally, while the current experiments focus on 67 goals with a limited number of items, how does the method scale when the item space becomes significantly larger? A brief comment on scalability or computational complexity would be valuable for understanding the broader applicability of XENON."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DmRYCr4GaG", "forum": "N22lDHYrXe", "replyto": "N22lDHYrXe", "signatures": ["ICLR.cc/2026/Conference/Submission18530/Reviewer_VSc5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18530/Reviewer_VSc5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18530/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892053761, "cdate": 1761892053761, "tmdate": 1762928221916, "mdate": 1762928221916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}