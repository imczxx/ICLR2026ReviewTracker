{"id": "4XQVBihXUD", "number": 3099, "cdate": 1757332836157, "mdate": 1759898109428, "content": {"title": "Unsupervised Parallel MRI Reconstruction via Projected Conditional Flow Matching", "abstract": "Reconstructing high-quality images from substantially undersampled k-space data for accelerated MRI presents a challenging ill-posed inverse problem. Supervised deep learning has transformed the field by using large amounts of fully sampled ground-truth MR images, either to directly reconstruct undersampled data into fully sampled images with neural networks, or to learn the prior distribution of fully sampled images through generative models. However, in practical scenarios, acquiring ground-truth fully sampled MRI images is not viable due to the inherently slow nature of its data acquisition process. Despite advances in self-supervised/unsupervised MRI reconstruction, the performance remains inadequate at high acceleration rates. To address these gaps, we introduce the Projected Conditional Flow Matching (PCFM) and its unsupervised transformation, which is designed to learn the prior distribution of fully sampled parallel MRI by solely utilizing the undersampled k-space measurements. To reconstruct the image, we establish a novel relationship between the marginal vector field in the measurement space, which generates the associated probability flow in terms of the continuity equation, and the optimal solution to PCFM. This connection results in a cyclic dual-space sampling algorithm for unsupervised reconstruction. Our method was evaluated against contemporary state-of-the-art supervised, self-supervised, and unsupervised baseline techniques on parallel MRI using publicly available datasets fastMRI and CMRxRecon. Experimental results show that our technique significantly surpasses existing self-supervised and unsupervised baselines, while also yielding better performance than most supervised methods. Our code will be available at \\url{https://github.com/anonymous}.", "tldr": "", "keywords": ["unsupervised learning", "MRI reconstruction", "flow matching", "generative models"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c124355a57d6ffb87bbef6a72f46532fe3899adc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an unsupervised framework for parallel MRI reconstruction, termed Projected Conditional Flow Matching (PCFM). The method aims to learn a denoising process of fully sampled MR images using only undersampled $k$-space measurements, without requiring ground-truth data. Specifically, the authors formulate a PCFM objective inspired by the Generalized Stein's Unbiased Risk Estimator (GSURE). This allows learning the signal-space vector field through the MRI forward operator as a projection. A dual-space cyclic reconstruction algorithm is further introduced, performing forward and backward ODE integrations in both image and measurement spaces with data-consistency projections. Experiments with fastMRI and CMRxRecon show that PCFM achieves comparable or superior PSNR/SSIM to supervised and unsupervised baselines, while being computationally efficient (approximately 20 NFEs)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper addresses an important and practically challenging problem: MRI reconstruction without access to fully sampled ground-truth data.\n\n2. The derivation connecting signal- and measurement-space conditional vector fields via $\\mathbf{u}_t^Y = \\mathbf{A} \\mathbf{u}_t^X + a'_t \\mathbf{e}_0 + b'_t \\mathbf{e}_1$ is consistent and well-motivated. \nThe GSURE-inspired objective provides a theoretically clean way to train without paired supervision.\n\n3. The cyclic dual-space integration offers a balance between the interpretability of unrolled optimization and the flexibility of flow-based priors, achieving efficient inference.\n\n4. On the fastMRI knee and CMRxRecon datasets, PCFM performs on par with supervised methods and significantly outperforms previous unsupervised ones, validating the framework.\n\n5. The manuscript includes detailed derivations."}, "weaknesses": {"value": "1. **Substantial overlap with prior accepted work (IPMI 2025):**  The core technical content---including the formulation of dual-space conditional vector fields, the ground-truth-free flow-matching objective, the unbiased risk estimator (ENSURE/GSURE style), and the cyclic forward--backward reconstruction algorithm---is virtually identical to the paper \"Unsupervised Accelerated MRI Reconstruction via Ground-Truth-Free Flow Matching (GTF$^2$M)\" by Luo et al., already accepted to IPMI 2025. \nThat IPMI paper introduces a nearly identical induced forward model $\\mathbf{u}_t^Y = \\mathbf{A} \\mathbf{u}_t^X + a'_t \\mathbf{e}$ and defines a very similar loss: $L\\_{\\text{GTF$^2$M}} = \\mathbb{E} \\|| \\mathbf{R}_s  \\[ \\mathbf{h}\\_\\theta (\\mathbf{A}^\\ast \\mathbf{z}_t^Y, t) - \\hat{\\mathbf{u}}\\_{t,s}^{X,\\text{ML}} \\] \\||_2^2 + 2 a'_t a_t \\sigma^2 \\nabla\\_{\\mathbf{A}^\\ast \\mathbf{z}_t^Y} \\cdot (\\mathbf{R}_s^\\ast \\mathbf{R}_s \\mathbf{h}\\_\\theta (\\cdot) )$ (Eqs. (7)--(10) in that paper), and proposes the same cyclic dual-space integration (Algorithm 1). \nThe PCFM submission reproduces this formulation almost line-for-line, merely renaming the unbiased estimator as a \"GSURE-based projected loss.\" From a technical standpoint, the novelty relative to the already accepted GTF$^2$M appears minimal. \nWithout explicit acknowledgment or differentiation, this raises serious novelty and dual-submission concerns for ICLR.\n\n2. **Lack of clear differentiation.** If the authors intend PCFM as an extension of GTF$^2$M, the distinction must be mathematically or empirically meaningful. Simply replacing ENSURE with GSURE or rephrasing the projection operator is _not_ sufficient unless this change provably improves bias, variance, or convergence stability. \n\n3. **Lack of explicit mathematical analysis for parallel MRI** In parallel MRI, directly inverting a matrix of the form $\\mathbf{A}^\\top \\mathbf{A} + \\mathbf{I}$ is typically infeasible, yet the paper provides _no_ explicit mathematical analysis of how the projection operator is approximated (e.g., number of CG iterations and effect of errors in $\\mathbf{A}^+$).\nLikewise, although coil sensitivity maps are only estimated in practice, there is _no_ mathematical analysis of how such estimation errors propagate through the reconstruction process or affect performance.\n\n4. It's unclear if the sensitivity maps are estimated from under-sampled $k$-space data. It sounds that they are estimated from fully-sampled $k$-space data.\n\n5. For an ICLR audience, the contribution should transcend the MRI domain and offer insights relevant to general inverse problems or flow-based learning under measurement constraints.\nThe current paper is written almost entirely as an application paper; the methodology remains MRI-specific, and the potential extension to other linear inverse problems (e.g., CT and image deblurring) is not discussed.\n\n6. Although the authors briefly mention that the IPMI 2025 paper \"focused solely on a single-coil MRI model with a feasible weighted projection operator,\" while the present work \"introduces a rigorous GSURE-based projected CFM formulation for parallel MRI,\" this clarification remains insufficient.  \nThe claimed difference is stated only at a conceptual level and lacks mathematical or experimental evidence demonstrating that the GSURE-based projection or the parallel-coil setting leads to a substantively distinct formulation, objective, or reconstruction behavior.  \nWithout a rigorous theoretical or empirical comparison, the overlap in formulation and algorithmic structure still appears substantial."}, "questions": {"value": "1. What is the precise relationship between PCFM and the IPMI 2025 paper GTF$^2$M? Could you clarify which parts are new or substantially modified, other than replacing ENSURE with GSURE or rephrasing the projection operator?\n\n2. How does the GSURE-based loss differ mathematically from the ENSURE-based estimator in GTF$^2$M? Could you provide a proof or (at minimum) empirical evidence that this change improves bias, variance, or stability?\n\n3. Is the cyclic reconstruction algorithm (forward/backward ODE with proximal data-consistency updates) identical to Algorithm 1 in GTF$^2$M, or has any component been changed (again, other than effects from replacing ENSURE with GSURE or rephrasing the projection operator)?\n\n4. Could you provide a mathematical analysis or theoretical conditions describing how estimation errors in the sensitivity maps and approximation errors in the projection operators (e.g., due to CG iterations) affect reconstruction accuracy or stability?\n\n5. If so, what theoretical conditions are required on the forward operator and the associated projection operators to ensure convergence or unbiasedness of the learned flow field, particularly with respect to their approximation or estimation errors?\n\n6. Could you clarify if the sensitivity maps are estimated from under-sampled $k$-space data?"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "The submission appears to substantially overlap with an already accepted IPMI 2025 paper (\"Unsupervised Accelerated MRI Reconstruction via Ground-Truth-Free Flow Matching\"), sharing nearly identical formulations, equations, and algorithms.\nThe authors mention the prior work only briefly and without sufficient differentiation.\nThis raises potential concerns regarding duplicate or salami publication and lack of transparency about prior dissemination."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BPCSvW2E4o", "forum": "4XQVBihXUD", "replyto": "4XQVBihXUD", "signatures": ["ICLR.cc/2026/Conference/Submission3099/Reviewer_gf2W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3099/Reviewer_gf2W"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3099/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887141612, "cdate": 1761887141612, "tmdate": 1762916549764, "mdate": 1762916549764, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper provides a projected CFM for parallel MRI reconstruction. The paper largely follows the single-coil derivation of Luo et al, ICML, 2025 with some modifications for multi-coil operators. The results show good performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper derives projected CFM for multi-coil MRI setup. \n- Under the experimental conditions, the method shows very good performance."}, "weaknesses": {"value": "- The incremental contribution from Luo et al is minor. Most of the changes are related to using CG for numerically solving the projection-related formulations instead of using the closed form solutions in the single-coil setup used by Luo et al. But this does not require many major changes. \n- Most of the derivations are also not properly acknowledging the previous work. As one simple example (among others) Proposition 2 and in particular eq. 13 have direct corresponding terms in GTF^2M (around eq. 9).\n- The comparisons are not matched. Some methods (MoDL, ENSURE, MOI) are run with a MoDL based network, which uses a CG-based approach, while others (SSDU, Weighted SSDU, Robust SSDU, REI) use VarNet, which uses a gradient descent type optimization. It is hard to tease out if the differences are due to training or different network architectures.\n- No hypothesis is provided as to why the proposed framework performs better than all other methods, in fact also beating supervised methods by a large margin. This is especially surprising given the multiple steps of numerical approximations/integrations needed in Algorithm 1.\n\nMinor:\n- The delta-function type of conditional flow considered here is not the optimal transport flow, but the one from rectified flow. OT-CFM nominally defines a 2-Wasserstein optimal transport map on q, but this paper uses the independent coupling (I-CFM) with sigma = 0, yielding the rectified flow path. \n- A does not have to be rank-deficient in multi-coil MRI. Though I don't think this really affects downstream arguments, except making N(A) = {0}."}, "questions": {"value": "From weaknesses:\n- How does the performance comparisons change when different training methods use the same baseline networks?\n- What is the contribution over GTF^2M?\n- Why does the proposed framework so much better than all other methods, including supervised training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "U9Rd8DP4wP", "forum": "4XQVBihXUD", "replyto": "4XQVBihXUD", "signatures": ["ICLR.cc/2026/Conference/Submission3099/Reviewer_BTkw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3099/Reviewer_BTkw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3099/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940297678, "cdate": 1761940297678, "tmdate": 1762916549366, "mdate": 1762916549366, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Projected Conditional Flow Matching (PCFM), a novel unsupervised generative framework for reconstructing parallel MRI data without the need for fully sampled reference images.\n\nBuilding on the recently proposed Conditional Flow Matching (CFM) paradigm, the authors reformulate flow-matching losses in measurement space (k-space) by incorporating a projection operator that accounts for the non-invertibility of the MRI forward model. Using Generalized Stein’s Unbiased Risk Estimation (GSURE), they derive an unbiased unsupervised training objective that depends only on measurable quantities.\n\nThe approach is validated on parallel MRI datasets, demonstrating reconstruction quality comparable to (and sometimes exceeding) supervised diffusion-based and unrolled networks, while requiring no ground-truth images."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- **Novelty:** The paper makes a clear conceptual leap: transforming flow-matching generative modeling into an unsupervised reconstruction framework by embedding it in the measurable subspace defined by the MRI forward model.\n- **Theoretical Elegance:** The derivation of Projected Conditional Flow Matching (PCFM) from Conditional Flow Matching (CFM) is mathematically rigorous and clean. The transition from supervised conditional flows → projected flows → unsupervised GSURE form (Eq. 12) is logically coherent.\n- **Significance:** The ability to train high-quality MRI reconstructions entirely from undersampled data addresses one of the most pressing bottlenecks in MRI research (the scarcity of fully sampled datasets).\n- **Sound experiments:** The experiments compare PCFM to several strong baselines: unrolled networks, score-based diffusion methods, and other unsupervised/self-supervised approaches, and show its superior performance. The inclusion of ablations (e.g., with/without projection, divergence correction) helps isolate which parts of the method contribute most.\n- **Clarity:** The writing is dense but technically precise."}, "weaknesses": {"value": "- The derivations, particularly around Equations 10–13, are heavy and may be opaque to readers not familiar with flow-matching or GSURE theory. The paper would benefit from a more intuitive explanation of how the GSURE term arises and what role it plays in training stability and reconstruction quality. In particular, readers may find it unclear why the unsupervised objective does not collapse to trivial zero-filled solutions, given that the network only observes undersampled k-space measurements.\n- Although the experiments are solid, the datasets are relatively narrow (e.g., limited to brain and knee MRI). \n- The assumption that the noise model is Gaussian may limit applicability in practical MRI settings where noise is Rician or correlated across coils."}, "questions": {"value": "- How will PCFM behave when the sampling mask changes between training and inference?\n- Since the approach is unsupervised, how exactly does the model learn a prior over realistic MR images? Is it purely from the empirical distribution of undersampled measurements, or is there any explicit regularization or implicit bias introduced by the flow architecture?\n- How does this flow-matching framework compare intuitively and mathematically to diffusion-based unsupervised MRI methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "es1ED1BPJm", "forum": "4XQVBihXUD", "replyto": "4XQVBihXUD", "signatures": ["ICLR.cc/2026/Conference/Submission3099/Reviewer_QnzY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3099/Reviewer_QnzY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3099/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967783684, "cdate": 1761967783684, "tmdate": 1762916549073, "mdate": 1762916549073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an unsupervised framework for parallel MRI reconstruction called projected conditional flow matching (PCFM). The key problem it addresses is reconstructing a high-quality MR image from undersampled multi-coil k-space measurements without access to fully sampled ground truth images for training. The authors made three key contributions:\n1. They formulate a projected conditional flow matching objective. This adapts the standard flow matching loss, which requires ground truth data, by projecting the error onto the range space of the forward operator's adjoint, $\\mathcal{R}(A^T)$.\n2. They derive an unsupervised transformation of this objective using Stein's Risk Estimator, which enables learning vector fields lead to high quality image using undersampled measurements.\n3. They propose a dual-space cyclic integration algorithm for inference."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method is novel. The formulation of a projected flow matching objective (PCFM) to handle the rank-deficient parallel MRI operator and the subsequent \"unsupervised transformation\" (Proposition 2) are theoretical contributions. The derivation of the dual-space cyclic integration algorithm (Algorithm 1) for inference is also a non-trivial.\n2. The evaluation is robust. It uses two distinct and standard public datasets (brain and cardiac) , compares against a wide array of recent baselines from all three categories (supervised, self-supervised, and unsupervised) , and includes ablation studies (in Appendix E) that justify the components of the proposed inference algorithm.\n3. The paper demonstrates experimentally that this unsupervised method not only surpasses other unsupervised and self-supervised techniques but also performs competitively against several supervised methods on public datasets."}, "weaknesses": {"value": "1. The method's implementation appears highly complex. It relies on numerical approximation of the Moore-Penrose pseudoinverse ($A^+$) via the Conjugate Gradient (CG) method. This approximation is used both during the unsupervised training (for the projection P=$A^+A$) and during inference (for the data consistency step). The paper states 30 CG steps are used for inference. The stability of this \"inner loop\" (CG) within the \"outer loop\" (ODE integration) and its impact on training convergence are not fully explored.\n2. To me, the projection is kind of a way to recover high quality samples from undersampled measurements during the training. would it be possible to have a new baseline that is trained recovered samples?\n3. It is a question if the forward operator, $A$, is changing during the training or kept fixed? Other methods dealing with degraded data keep the $A$ operator un-fixed. Would you comment on this?"}, "questions": {"value": "1. The method GTF2M in this work is better than original publication? Considering the authors of GTF2M has not released their code, would you comment on this?\n2. The SSIMs for ENSURE and GTF2M at 4x acceleration are the same in Table 2. Is this a coincidence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FrKFGDQG8F", "forum": "4XQVBihXUD", "replyto": "4XQVBihXUD", "signatures": ["ICLR.cc/2026/Conference/Submission3099/Reviewer_5CF1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3099/Reviewer_5CF1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3099/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762357952614, "cdate": 1762357952614, "tmdate": 1762916548801, "mdate": 1762916548801, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}