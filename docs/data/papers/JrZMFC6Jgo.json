{"id": "JrZMFC6Jgo", "number": 25027, "cdate": 1758363345308, "mdate": 1762955463386, "content": {"title": "THE BLACK–WHITE-BOX OPTIMIZATION NETWORK", "abstract": "We introduce a \\textit{Black--White-Box Optimization Network} and its first instance, \\textit{Tensor-Train Creator (TTC)}, which couples Ising-style solves, a factorization-machine surrogate, and tensor-train (PROTES) search. Typed couplings, lattice realignment, and warm starts cut oracle calls and time-to-target. On black-box benchmarks and Max-Cut, TTC attains better values under the same evaluation budgets.", "tldr": "In this paper, we introduce TTC - a derivative-free optimization framework that couples HOFM surrogates, Ising solvers, and Tensor-Train.", "keywords": ["Derivative-free optimization", "Combinatorial optimization", "Higher-order energy", "HUBO", "QUBO", "Higher-Order Factorization Machines (HOFM)", "Ising seeding", "Tensor-Train (TT)"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/519521e3b849c26ffef02618bec007f1207bbee6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a new hybrid optimization framework called the Black–White-Box Optimization Network (BWBON), aiming to bridge black-box and white-box optimization paradigms. The authors introduce its first concrete implementation, the Tensor-Train Creator (TTC). The system operates iteratively: white-box Ising solves generate “seeds” that warm-start the TT-based sampler, while the surrogate helps realign the optimization lattice to reduce tensor ranks and accelerate convergence. The authors formalize this process as a typed solver graph that can mix different optimization modules through explicit couplings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper moves beyond simple grey-box or two-module hybrids toward a general multi-solver architecture.\n2. This paper provides insights into why dense QUBO problems are difficult for TT methods and how TTC mitigates this through lattice alignment.\n3. This paper includes formal complexity analysis and convergence-related theorems with explicit scaling laws."}, "weaknesses": {"value": "1. Experiments mainly focus on synthetic benchmarks and Max-Cut and no large-scale or real-world application is included.\n2. While annealer and surrogate costs are discussed, actual wall-clock trade-offs are not shown experimentally."}, "questions": {"value": "1. Could the method generalize to continuous or mixed-integer optimization problems beyond discrete QUBO/HUBO formulations?\n2. What is the empirical cost of the annealing-based shaping step compared to the overall optimization time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "i8fA8TXCwf", "forum": "JrZMFC6Jgo", "replyto": "JrZMFC6Jgo", "signatures": ["ICLR.cc/2026/Conference/Submission25027/Reviewer_ESWM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25027/Reviewer_ESWM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25027/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910679056, "cdate": 1761910679056, "tmdate": 1762943288810, "mdate": 1762943288810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "lEprwrlaoP", "forum": "JrZMFC6Jgo", "replyto": "JrZMFC6Jgo", "signatures": ["ICLR.cc/2026/Conference/Submission25027/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25027/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762955462616, "cdate": 1762955462616, "tmdate": 1762955462616, "mdate": 1762955462616, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Tensor-Train Creator (TTC), a hybrid framework for solving discrete optimization problems such as Max-Cut. TTC integrates three components: a Higher-Order Factorization Machine (HOFM) for modeling polynomial structures, a quantum-like solver for initialization, and PROTES, a tensor-train–based probabilistic search. The framework aims to unify white-box (structured) and black-box (oracle-based) optimization through tensorized “typed couplings.” Some theoretical motivation and limited experimental results are presented to suggest potential efficiency gains."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The proposed algorithm (Algorithm 1) is well laid out and conceptually clear in showing how TTC integrates surrogate modeling, annealing-based seeding, and tensor-train sampling."}, "weaknesses": {"value": "The paper is extremely difficult to follow. It lacks a clear and consistent problem formulation and precise definitions of basic concepts (e.g., what exactly is meant by “typed coupling” or “black–white box coupling”). Important terms like QUBO, HUBO, and TT decomposition appear without prior introduction or references for non-expert readers. For example, equation (3) uses a nonstandard inner product notation ⟨v_{i_1}^{(k)}, …, v_{i_k}^{(k)}⟩ that is never explicitly defined. These issues make the manuscript inaccessible even for an informed reader familiar with tensor optimization.\n\nThe manuscript mixes multiple ideas—Ising solvers, factorization machines, TT representations, QUBO/HUBO transformations—without providing sufficient intuition or connection among them. It is unclear what specific problem TTC is solving and how the submodules interact at each iteration in a mathematically rigorous way. For instance, PROTES and HOFM are each described in detail, but the way they exchange information is mostly described narratively rather than formally.\n\nThe numerical section (Table 2) is very minimal, lacking experimental setup details such as dataset sizes, number of evaluations, parameter settings, and runtime comparison methodology. No standard deviation or error metrics are given. This makes it impossible to assess reproducibility or robustness. The claim of “better values under the same evaluation budgets” is not substantiated with statistical evidence or ablation studies.\n\nWhile the architecture combines several existing techniques, it is unclear whether the observed improvements come from the combination itself or from specific hyperparameter tuning. There is no clear ablation showing the effect of each component (e.g., HOFM alone vs. PROTES alone vs. TTC). Moreover, the relationship between the theoretical discussion in Section 4 (QUBO vs. HUBO) and the practical implementation in Algorithm 1 is not clearly established.\n\nThe paper includes many formal statements and theorems that appear mathematically correct but are not directly validated or tied to the main contribution. Many results are re-statements of known properties of tensor-train decompositions and treewidth, yet presented as novel insights."}, "questions": {"value": "The paper is evidently not yet ready for submission. It requires major revisions to improve structure, clarity, and experimental rigor. Therefore, I have no specific technical questions to ask the authors at this stage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cGSZTLkmOV", "forum": "JrZMFC6Jgo", "replyto": "JrZMFC6Jgo", "signatures": ["ICLR.cc/2026/Conference/Submission25027/Reviewer_NpkF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25027/Reviewer_NpkF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25027/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915951239, "cdate": 1761915951239, "tmdate": 1762943288588, "mdate": 1762943288588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a Black–White-Box Optimization Network and instantiates it as the Tensor-Train Creator (TTC): a hybrid pipeline that interleaves an Ising/annealing “white-box” path with a tensor-train (TT)–based “black-box” search, using a surrogate (HOFM) to reveal low-rank structure and guide a TT sampler (PROTES). TTC warm-starts TT from annealer-derived solutions and realigns problem structure to keep TT ranks small, reducing oracle evaluations and time-to-target compared to standalone black-box or annealing methods. The paper also analyzes when TT methods struggle on dense QUBO and how structured QUBO→HUBO transformations can help, and reports empirical improvements on synthetic benchmarks and Max-Cut."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear modularity and novelty of composition. The “typed couplings” idea crisply formalizes how white- and black-box solvers exchange information\n\n2. Useful theory explaining TT behavior. The lattice-alignment result (treewidth/separator view) convincingly explains why dense QUBO induces large TT ranks and why certain HUBO re-embeddings help; this is a valuable conceptual contribution for TT-based optimizers."}, "weaknesses": {"value": "1. Experimental evidence appears light for an ICLR-level systems claim. While the abstract reports wins under equal budgets, the paper would benefit from fuller methodology: dataset/task details, variance across seeds, wall-clock vs. evaluation-count breakdowns, and stronger ablations (e.g., HOFM-only shaping, annealer-only warm-start, PROTES-only with tuned ranks). The current text does not yet show broad, statistically robust coverage commensurate with the breadth of claims.\n\n2. Reliance on annealing backends. TTC’s advantage hinges on (i) quality/latency of Ising solves and (ii) faithful QUBO extraction from HOFM; the paper acknowledges annealer overheads but more empirical quantification (TTS, reads, gauges) is needed to assess portability across devices and settings.\n\n3. Surrogate fidelity and stability. Restricting to the quadratic part for QUBO construction can misrepresent higher-order effects that HOFM models; guidance on when this truncation helps/hurts (and sensitivity to \\lambda/penalties) is limited. \n\n4. Scope of the HUBO construction. The constructive “near-chain” HUBO argument is compelling, but the paper stops short of giving automatic pipelines with approximation guarantees or empirical stress-tests on real-world dense instances.\n\n5. clarity and organization. The writing makes it difficult to clearly separate new contributions from prior methods. The technical narrative often mixes background, intuition, and algorithmic details without a clean progression. A clearer structure (e.g., “background → key insights → method → theory → experiments”) and explicit novelty call-outs would strengthen readability and impact."}, "questions": {"value": "1. TT rank guarantees: The theory explains when TT will fail on dense QUBO, but do you have formal bounds or probabilistic guarantees for success in the structured settings chosen?\n \n2. Why is the quadratic truncation of HOFM used for QUBO extraction? Is there empirical evidence that higher-order terms harm performance, or is this primarily for tractability?\n\n3. Ablations: Can you provide ablations to identify the contribution of each part? e.g,TT alone; TT+warm-start; surrogate-only shaping; TT + HUBO transformation without annealing\n\n4. Can you provide a detailed breakdown of wall-clock runtime, number of oracle calls, and annealer time? How sensitive are results to the relative cost of annealing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AXPI764kdk", "forum": "JrZMFC6Jgo", "replyto": "JrZMFC6Jgo", "signatures": ["ICLR.cc/2026/Conference/Submission25027/Reviewer_4brZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25027/Reviewer_4brZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25027/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923455500, "cdate": 1761923455500, "tmdate": 1762943288375, "mdate": 1762943288375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper formalizes the black-white-box optimization network and proposes the Tensor-Train Creator (TTC) for general optimization problems. The TTC framework interleaves black-box and white-box optimization to reap the benefits of both techniques. Specifically, TTC is composed of a higher-order factorization machine, an ising-machine that solves a component of the output of the HOFM (the white-box solver), and a Tensor-Train based black-box solver. Experiments show that under the same budget, TTC outperforms other baselines on several black-box optimization problems."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Novelty: the TTC framework is novel as far as I know, combining several components such as the Ising-machine and HOFM. Some of these components, such as the Ising-machine, can have a quantum backend which I find interesting.\n2. The paper gives a detailed analysis of the complexity of the procedure, and outlines when there is an advantage for using TTC compared to other methods.\n3. Several optimization experiments demonstrate that TTC outperforms other baselines under the same budget."}, "weaknesses": {"value": "1. My main concern is writing. The paper describes an optimization procedure, which is of broad interest to the ML community, but uses many terminologies that are not formally introduced in the paper with sufficient background. For example, what's QUBO and HUBO? On the first page, in the definition of HOFM, what are the w's and v's? \n\n2. Why does the Ising solver only solve the quadratic problem, instead of a higher-order problem? Does performance improve if we retain higher order factorizations?\n\n3. To clearly show the benefits of TTC, could the authors provide a breakdown of the cost of running TTC for the experimental benchmarks? For example, how much compute was spent in fitting the HOFM and solving the QUBO? It would also be interesting to quantify the benefit of warm-starts, and one potential experiment is to compare the quality of the points evaluated with and without warm-starts.\n\n4. Section 5 is missing exposition: what are the dimensions of these optimization problems, and what's the fixed budget in evaluating them? Is the budget fixed in terms of compute or number of evaluations? What are BS1 and BS2, and are they SOTA solvers for these problems?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0t7w47BjcZ", "forum": "JrZMFC6Jgo", "replyto": "JrZMFC6Jgo", "signatures": ["ICLR.cc/2026/Conference/Submission25027/Reviewer_Fp4i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25027/Reviewer_Fp4i"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25027/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762279209933, "cdate": 1762279209933, "tmdate": 1762943288140, "mdate": 1762943288140, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}