{"id": "RDAhLHEHDm", "number": 7811, "cdate": 1758037186345, "mdate": 1759897831104, "content": {"title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs", "abstract": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising frontier for accelerating biological discovery. However, these models face a fundamental challenge when processing raw biomolecular sequences: the tokenization dilemma. Whether treating sequences as a specialized language, risking the loss of functional motif information, or as a separate modality, introducing formidable alignment challenges, current strategies fundamentally limit their reasoning capacity. We challenge this sequence-centric paradigm by positing that a more effective strategy is to provide Sci-LLMs with high-level structured context derived from established bioinformatics tools, thereby bypassing the need to interpret low-level noisy sequence data directly. Through a systematic comparison of leading Sci-LLMs on biological reasoning tasks, we tested three input modes: sequence-only, context-only, and a combination of both. Our findings are striking: the context-only approach consistently and substantially outperforms all other modes. Even more revealing, the inclusion of the raw sequence alongside its high-level context consistently degrades performance, indicating that raw sequences act as informational noise, even for models with specialized tokenization schemes. These results suggest that the primary strength of existing Sci-LLMs lies not in their nascent ability to interpret biomolecular syntax from scratch, but in their profound capacity for reasoning over structured, human-readable knowledge. Therefore, we argue for reframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines over expert knowledge. This work lays the foundation for a new class of hybrid scientific AI agents, repositioning the developmental focus from direct sequence interpretation towards high-level knowledge synthesis.", "tldr": "", "keywords": ["Biomolecular learning", "Protein sequence"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2154dac981a3bdd838104ad73c8399d017cd574a.pdf", "supplementary_material": "/attachment/59eed86199298619bfd791ab69cab0ca9358c3d5.zip"}, "replies": [{"content": {"summary": {"value": "This paper identifies and investigates a fundamental challenge in Scientific Large Language Models (Sci-LLMs) for biomolecular understanding, which the authors term the \"tokenization dilemma.\" They argue that existing paradigms—\"sequence-as-language\" (tokenizing sequences into atomic units) and \"sequence-as-modality\" (encoding sequences via specialized encoders)—suffer from weak representation and semantic misalignment, respectively. As a solution, the authors propose a \"context-driven\" paradigm, which bypasses raw sequence input. Instead, it leverages established bioinformatics tools (e.g., InterProScan, BLASTp) to generate high-level, human-readable textual context (e.g., functional domains, GO terms) that is natively aligned with the LLM's linguistic space.  The authors evaluated three input modes: sequence-only, context-only, and a combination of both. Through extensive empirical evaluation on protein QA, EC number prediction, and DNA mutation tasks, the authors demonstrate that the context-only approach consistently and substantially outperforms all other modes. They find that adding raw sequence information to context often degrades performance, acting as \"informational noise.\""}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper clearly articulates the \"tokenization dilemma\" as a critical, yet overlooked, bottleneck in Sci-LLMs. The conceptual framing of the two existing paradigms and their respective weaknesses is compelling and well-supported by prior work.\n- The central claim—that raw sequences can be detrimental when combined with high-level context—is counter-intuitive and strongly supported by systematic experiments across multiple models (Intern-S1, Evolla, NatureLM, GPT-4o, etc.) and tasks (protein function, pathway, localization, EC prediction). The consistent performance drop in \"Sequence + Context\" settings is a powerful result.\n- The authors evaluate their method on a wide range of benchmarks, including their own reconstructed dataset, temporal splits, and sequence identity-based splits (Easy/Medium/Hard). The inclusion of DNA-based tasks also demonstrates generalizability beyond proteomics.\n- The paper goes beyond mere performance comparisons. The layer-wise analysis of Evolla (Section 5.3, Appendix F) convincingly shows how semantic alignment (via Q-Former) erases fine-grained mutation signals, providing a mechanistic explanation for the limitations of the sequence-as-modality approach."}, "weaknesses": {"value": "- The context-driven approach relies heavily on the quality and coverage of external tools (InterProScan, BLAST). While an ablation study is provided (Appendix E), it does not fully explore the performance ceiling—what happens when these tools fail completely on highly novel proteins? The method's performance is inherently tied to the underlying databases' completeness and timeliness.\n- The paper equates \"biomolecular understanding\" primarily with high-level functional annotation (GO terms, pathways). It does not assess whether the model gains *mechanistic* or *structural* insights that might require raw sequence analysis (e.g., predicting the effect of a point mutation). The limitation section (Appendix J) correctly notes this but underscores a fundamental constraint of the proposed paradigm.\n- The strong performance of general LLMs (Gemini, GPT) in the context-only setting raises questions about potential memorization of public protein annotations from their vast pre-training corpora. While the authors take care to prevent label leakage in their *context generation*, they do not explicitly audit whether the test proteins' annotations were already in the LLMs' training data.\n- The primary metric (LLM-Score) relies on another LLM (DeepSeek-V3) to judge answer quality. While this is a reasonable approach for open-ended QA, it introduces potential biases and lacks the objectivity of exact-match metrics used in tasks like EC prediction.\n- Code is not provided in the current submission, providing it would be helpful to make work reproducible."}, "questions": {"value": "- Given the high performance of general-purpose LLMs like Deepseek-v3, Gemini2.5 Pro and GPT-5, what steps did you take to ensure that the ground-truth annotations for your test proteins were not present in these models' pre-training data? Could the results be partly explained by memorization rather than reasoning?\n- Your approach depends on external tools. Can you provide a qualitative analysis or failure case study for proteins where InterProScan and BLASTp return no or incorrect hits? How does the performance of your method degrade in such \"orphan\" scenarios, and what are the potential remedies?\n- The paper convincingly shows that context is superior for *retrieving* known functional annotations. However, do you believe your paradigm can be extended to tasks that require *discovering* novel functions or reasoning about structure-sequence relationships that are not yet captured in existing databases?\n- You note your method is computationally efficient as it avoids Sci-LLM retraining. However, running InterProScan and BLASTp for every query in a real-time application could be costly and slow. Could you comment on the latency and scalability of the full context-generation pipeline compared to a single forward pass of a sequence-as-language and a sequence-as-modality model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b9E8GWVKK2", "forum": "RDAhLHEHDm", "replyto": "RDAhLHEHDm", "signatures": ["ICLR.cc/2026/Conference/Submission7811/Reviewer_2DYC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7811/Reviewer_2DYC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761718049613, "cdate": 1761718049613, "tmdate": 1762919851581, "mdate": 1762919851581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper argues that Scientific Large Language Models face a \"tokenization dilemma,\" struggling to interpret raw biomolecular sequences, which are either broken down into meaningless components or difficult to align with natural language. Through systematic experiments, the authors demonstrate that a \"context-only\" approach, where models are given high-level, human-readable knowledge from bioinformatics tools (like BLAST or Pfam) , consistently and substantially outperforms models given the raw sequence."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Pros:\n- The authors proposed a new “context-only” method, which achieved significantly \n- The context-driven approach achieve good performance."}, "weaknesses": {"value": "Cons:\n- Context-only approach sounds interesting. However, compared with raw biomolecular sequences input, an inevitable con of this approach would be significant information loss (by discarding too many detailed information).\n- The capability of this approach is capped by the bioinformatics tools being used, e.g., InterProScan and BLAST.\n- As the context-only model relies majority on prior, it may not be a good tool for exploring “novel” findings (which may be out of distribution a bit).\n- Why in Table 1, QWEN series of models are not considered, while in Figure 2, for “ours” model, the author choose to use Qwen-embedding. What about the embedding visualization for specialized language models [1] like ESM series\n\n\n[1] Zheng, Y., Koh, H. Y., Ju, J., Yang, M., May, L. T., Webb, G. I., ... & Church, G. (2025). Large language models for drug discovery and development. Patterns."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3XgS2SWa7e", "forum": "RDAhLHEHDm", "replyto": "RDAhLHEHDm", "signatures": ["ICLR.cc/2026/Conference/Submission7811/Reviewer_J4os"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7811/Reviewer_J4os"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930404329, "cdate": 1761930404329, "tmdate": 1762919851136, "mdate": 1762919851136, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a “paradigm shift” for how Scientific Large Language Models (Sci-LLMs) are trained, leveraging context-centric approaches driven by high-level structured knowledge from bioinformatics tools (e.g., GeneOntology, ProTrek, BLASTp, etc.).  The solution addresses two key tokenization “dilemmas” that have posed challenges on the Sci-LLM space: sequence-as-language and sequence-as-modality.  This approach accounts for multiple levels of language used to describe biomolecular phenomena – from human-encoded knowledge to genetics/evolutionary-encoded knowledge. Strikingly, the context-only approach largely outperforms joint context + raw sequences, suggesting that raw sequences contribute more to information noise.  The contribution suggests that Sci-LLMs don’t necessarily require solving complex biological “language” from scratch but can leverage decades of accumulated biological knowledge contained within structured databases."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tOverall: The paper and aims to address a novel challenge in the Sci-LLM space, making a case that Sci-LLMs are better served as “reasoning engines over expert knowledge”, rather than pure sequence decoders. While this is noted and there is some evidence that this is the case, it does raise some circular logic around the quality of the annotations derived from the bioinformatics knowledgebases (addressed below in the weaknesses).\n2.\tGeneralizability: The solution in generalizable, with applications ranging from known proteins to “novel” proteins, as well as different biomolecular types.\n3.\tPracticality: The solution as it is described is practical, as it allows to more easily keep models up to date with new biological knowledge with lower development costs.  (Although it could be argued that most of the effort is derived from maintaining the bioinformatics knowledgebases)."}, "weaknesses": {"value": "1.\tCircular Logic: The approach works well when high-quality annotations exist, yet the solution also exists to propose annotations to fill in knowledge gaps. This counter-intuitively raises a bit of a “Catch 22” scenario.\n2.\tCore Argument: The basis of the manuscript suggests that there is in fact valuable information encoded within the evolutionary language through sequence tokens, yet the results suggest the opposite – and that human context exclusively drives the value."}, "questions": {"value": "1.\tHow do you address the circular reasoning between the strengths of the approach (incorporating high-quality expert annotations) and using this approach to predict those annotations where they do not yet exist?  Could tool-calling agents solve this rather than building directly into the LLM?  What are the tradeoffs?\n2.\tAlong this line of questioning, does the core contribution put a focus on the LLMs, or are you simply demonstrating that tradition bioinformatics pipelines already solve most of the problems around understanding protein function?\n3.\tHave these results been validated against human expert annotators?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DHv82GdNeg", "forum": "RDAhLHEHDm", "replyto": "RDAhLHEHDm", "signatures": ["ICLR.cc/2026/Conference/Submission7811/Reviewer_CSFM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7811/Reviewer_CSFM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940454126, "cdate": 1761940454126, "tmdate": 1762919850326, "mdate": 1762919850326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles how Sci-LLMs handle biomolecular sequences. It argues current methods are stuck in a \"tokenization dilemma\": either they treat sequences as language, breaking up important motifs, or as a separate modality, which creates an alignment gap. The authors propose a \"context-driven\" approach, skipping raw sequences entirely. Instead, they use bioinformatics tools (BLAST, Pfam) to create a text summary for the LLM . Their experiments show this context-only method works best, and that adding the raw sequence back in actually hurts performance, acting like noise."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper's \"tokenization dilemma\" concept is a really clear and smart way to frame a major hurdle for Sci-LLMs. The main idea—that feeding LLMs text context from tools like BLAST is better than giving them the raw sequence—is surprising but backed up well by the experiments. The finding that raw sequences just add \"noise\" and make things worse is a big deal. The visualizations (like in Figure 3) showing how alignment fails are also very convincing . This work is important because it questions the push for end-to-end models and offers a practical, hybrid alternative."}, "weaknesses": {"value": "The main drawback, which the authors rightly point out, is that this method can't handle mutation effect prediction. The bio-tools (BLAST, etc.) used to create the context just aren't sensitive to tiny, single-point changes, so the context for a normal protein and its mutant look the same . This is a major limitation, as it rules out a big area of computational biology. Also, the claims about it working on DNA are mostly tucked away in the appendix, not fully explored in the main paper."}, "questions": {"value": "Given the issue with mutations, do you have ideas for how this context-driven method could be adapted for those tasks? Maybe by using different tools that are sensitive to mutations to generate the context?\n\nYou mention your method is efficient because it avoids retraining, but running tools like InterProScan and BLAST for every query isn't free. How does the real-world inference time/cost of your pipeline compare to running a big, end-to-end model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mP2ddusOo8", "forum": "RDAhLHEHDm", "replyto": "RDAhLHEHDm", "signatures": ["ICLR.cc/2026/Conference/Submission7811/Reviewer_oqHE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7811/Reviewer_oqHE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977301551, "cdate": 1761977301551, "tmdate": 1762919849625, "mdate": 1762919849625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}