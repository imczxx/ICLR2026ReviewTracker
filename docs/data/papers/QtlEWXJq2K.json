{"id": "QtlEWXJq2K", "number": 4549, "cdate": 1757705568323, "mdate": 1759898027165, "content": {"title": "Cube Kernel: Enabling Local Gradient Flow Across Channels in CNNs for Robust and Efficient Building Segmentation", "abstract": "Understanding inter-band and cross-channel relationships is fundamental to human color perception and object recognition. However, conventional CNN-based image processing fails to propagate local gradients across channels during backpropagation, limiting cross-channel interactions until the summation stage. To address this limitation, we develop Cube Kernel, a plug-and-play convolutional operator that enforces local cross-channel gradient coupling by mapping channels onto a finer spatial lattice through group-based re-construction. To further enhance flexibility in feature grouping, we introduce a learnable router that adaptively reorders channels and emphasizes task-relevant representations. This is combined with a spatial attention mechanism, which effectively suppresses redundant responses introduced during reconstruction. Across multiple CNN-based and Transformer-based backbones, Cube Kernel delivers consistent improvements on the WBD, WHU, and Inria datasets. ConvNeXt-U-Cube achieves an F1 score of 90.42% and an mIoU of 82.63% on Inria, surpassing recent state-of-the-art methods with reductions of 9.2% and 20.8% in parameters and GFLOPs, respectively. Ablations isolate the effect of re-construction, the router, and attention, and analysis shows stronger inter-channel decorrelation. Owing to its lightweight design, compatibility with diverse architectures, and ability to be stacked across layers, Cube Kernel is highly implantable and can serve as a strong default operator for structured channel mixing in dense prediction. All code will be made publicly available.", "tldr": "We propose Cube Kernel, a lightweight plug-and-play convolutional operator that enforces local cross-channel gradient coupling, achieving state-of-the-art building extraction performance with fewer parameters and FLOPs.", "keywords": ["Cube Kernel", "channel-wise convolution", "inter-channel gradient flow", "convolutional neural networks", "building rooftop extraction", "semantic segmentation", "remote sensing"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0f58f16f93b6fddfee06eb00e2e3bfc0b4b1c786.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles the segmentation task. The paper proposes Cube Kernel, a plug-and-play convolutional operator designed to enable local cross-channel gradient coupling by mapping channels. To enhance this mechanism, the authors further introduce a learnable routing module, which dynamically reassigns channel groupings based on learned patterns, and optionally integrate a spatial attention mechanism to refine the feature representation. Cube Kernel can be seamlessly incorporated into existing CNN-based segmentation models, and empirical results across multiple benchmark datasets demonstrate that its integration leads to consistent improvements in segmentation performance."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ The paper proposes the Cube Kernel, which encodes cross-channel relationships directly into the convolutional operation, effectively bridging the gap between spatially local convolutions and the global receptive transformers.\n\n+ By integrating the Cube Kernel into existing backbone architectures, the overall performance of the models has been enhanced. This demonstrates the effectiveness and generalizability of the proposed module across various network designs. \n\n+ Aside from its integration with SegFormer, the Cube Kernel also contributes to a reduction in both parameter count and FLOPs when applied to other backbone models, highlighting its efficiency across diverse architectures."}, "weaknesses": {"value": "- Although the paper highlights the importance of channel relationships, drawing on observations from prior work, it does not clearly articulate or provide concrete illustrations to support this claim within the current study.\n\n- The proposed method is evaluated on building-extraction benchmarks; however, the rationale for focusing on this specific task, rather than standard semantic segmentation benchmarks, is not clearly explained.\n\n- The method is evaluated using relatively outdated backbone architectures; it would be beneficial to include experiments with more recent and competitive backbones to demonstrate the method’s effectiveness and relevance better."}, "questions": {"value": "- Can the Cube Kernel be integrated into more recent and competitive backbone architectures beyond those evaluated in the paper?\n- Is the Cube Kernel applicable to broader benchmark datasets beyond building segmentation, such as general-purpose or multi-domain segmentation tasks?\n- Can the Cube Kernel be extended to other vision tasks, such as object detection, instance segmentation, or video understanding?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hSZhSy2m6q", "forum": "QtlEWXJq2K", "replyto": "QtlEWXJq2K", "signatures": ["ICLR.cc/2026/Conference/Submission4549/Reviewer_8SBB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4549/Reviewer_8SBB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761652723753, "cdate": 1761652723753, "tmdate": 1762917434087, "mdate": 1762917434087, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Paper introduces the following concepts:\n1. Channel Routing which is a 1x1 convolution.\n2. Channel Grouping and Reconstruction which groups channels in groups 4 and ressemble the feature matrix in interleaving pattern.\n3. Cube Kernel which is a depthwise 3x3 convlution with a stride of 2\n4. Finally a 1x1 convolution to fuse the features.\n\nThe papers also introduces Spatial Attention:\n1. 7x7 Convolution with sigmoid attention, on the max and avg pool channelwise of the input features after the channel routing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A simple plug-and-plug method to replace any standard convolution operator.\n2. Paper is describes the idea clearly.\n3. The paper showcases the benchmarks well."}, "weaknesses": {"value": "1. The paper does not explain why after training, the router weights will approach orthogonality.\n2. The paper did not justified the used of GELU activation."}, "questions": {"value": "1. Does the channel router increase the input size by 8 times? because after reconstruction how is the 2H x 2W x 2C generated from a H X W X C input matrix.\n2. How does cube reconstruction & cube kernel compare to a standard Convolution kernel of size 2x2?\n3. Under computational Efficiency how are the parameters obtained, what are the values for kernel k and grouping G?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1U79QjLnYM", "forum": "QtlEWXJq2K", "replyto": "QtlEWXJq2K", "signatures": ["ICLR.cc/2026/Conference/Submission4549/Reviewer_fW53"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4549/Reviewer_fW53"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911598209, "cdate": 1761911598209, "tmdate": 1762917433778, "mdate": 1762917433778, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "this work tackles the task of segmentation of buildings.\nauthors argue that standard cnn filters suffer from gradient failing to account for cross-channels.\ntherefore, they proposed cub-kernel where channels are intertwined, followed by router, and attention.\nthey argue that mixing channels allows better gradient flow.\nthe evaluate their method on 3 datasets, and reported their results in comparison to other methods.\nablations are also provided."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- the writing is good.\n- the paper tackles an important task that is image segmentation.\n- reported results are good.\n- ablations are provided."}, "weaknesses": {"value": "- limited novelty. the main claimed contribution in this work is cub-kernel.\nthe main claim is that standard cnn filters dont combine channels leading to poor local gradient that does not account for other channels. while this is true, the proposed 'cub-kernel' also have the same issue, unfortunately.\nyes, in standard cnn, the gradient of the convolution of will be dispatched to each kernel w (e.g. 4x4 = 16 components) by accounting only for its own input channel x - while ignoring the other input channels.\nhowever, mixing channels, will lead to the same thing. each component of the kernel (which process one pixel from a single channel) is processing one single pixel from one single channel (fig.2). so the gradient for w_ij will only account for the input x_ij = single location of one channel - therefore, the gradient does not account for cross-channels.\nin short, even if you shuffle the channels, at component level of filters, the gradient accounts only for one channel only - unless channels are multiplied into a single channel. also, the right side of eq.1 is the same as left side. the gradient of a filter component will account only for one channel only.\n\nthis can be seen in terms of results in the ablation (tab.3, case with cub-kernel only - line 403 is not different from using standard conv).\n\nnot sure why it is called cube-kernel as authors used standard 3x3 kernels. the only thing different is that the input channels are mixed.\n\nthe router module - second part- is based on a guess. - line 209.\nthe third part that is attention, is a simple attention mask.\n\nputting theses modules all together yields better performance. but, in terms of methodology and novelty, they are very limited.\n\nsee this paper for related work on shuffling pixels: Real-Time Single Image and Video Super-Resolution Using an Efficient\nSub-Pixel Convolutional Neural Network, cvpr 2016. https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf"}, "questions": {"value": "- style: please try to make the writing consistent in terms of font. changing between non-bold and bold frequently is distracting. try to use less bold, color. try to use italic - with moderation - to emphasis on something."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "none."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SEAfeuwTs8", "forum": "QtlEWXJq2K", "replyto": "QtlEWXJq2K", "signatures": ["ICLR.cc/2026/Conference/Submission4549/Reviewer_h3rb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4549/Reviewer_h3rb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915168454, "cdate": 1761915168454, "tmdate": 1762917433427, "mdate": 1762917433427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a convolutional operator called Cube Kernel that enforces local cross-channel gradient coupling by mapping channels onto a finer spatial lattice."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The idea of a new improved convolutional operator is interesting and relevant. \n\nResults show that the method often results in marginally superior image segmentation on three datasets Inria, WBD and WHU Datasets, at a lower computational complexity."}, "weaknesses": {"value": "Table 2: It would be good to organize this information such that the result could be better appreciated. Interleaving the results of this work is hard to appreciate. Maybe a graph.\n\nTable 1: Why is the authors ConvNeXt + Cube Kernel marked as bold “Best” for OA for 97.03, whereas ASLNet has higher 97.15?\nIt would be great to have standard deviations in the results.\n\nFigure 1 is distracting and uninformative, as is the use of color and bolding in the abstract.\n\nGiven the marginal improvements, it would be interesting to demonstrate the method works other datasets (e.g CoCo) and tasks, e.g. classification."}, "questions": {"value": "Please address the previously mentioned points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0Nsy7rgzre", "forum": "QtlEWXJq2K", "replyto": "QtlEWXJq2K", "signatures": ["ICLR.cc/2026/Conference/Submission4549/Reviewer_K58Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4549/Reviewer_K58Q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960313583, "cdate": 1761960313583, "tmdate": 1762917433211, "mdate": 1762917433211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}