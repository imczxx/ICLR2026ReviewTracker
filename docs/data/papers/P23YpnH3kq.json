{"id": "P23YpnH3kq", "number": 17357, "cdate": 1758274998777, "mdate": 1759897180126, "content": {"title": "Stepwise Feature Learning in Self-Supervised Learning", "abstract": "Recent advances in self-supervised learning (SSL) have shown remarkable progress in representation learning. However, SSL models often exhibit shortcut learning phenomenon, where they exploit dataset-specific biases rather than learning generalizable features, sometimes leading to severe over-optimization on particular datasets. We present a theoretical framework that analyzes this shortcut learning phenomenon through the lens of $\\textit{extent bias}$ and $\\textit{amplitude bias}$. By investigating the relations among extent bias, amplitude bias, and learning priorities in SSL, we demonstrate that learning dynamics is fundamentally governed by the dimensional properties and amplitude of features rather than their semantic importance. Our analysis reveals how the eigenvalues of the feature cross-correlation matrix influence which features are learned earlier, providing insights into why models preferentially learn shortcut features over more generalizable features.", "tldr": "", "keywords": ["shortcut learning", "self-supervised learning", "stepwise learning", "feature learning", "learning dynamics"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1ff2835fe6da1f19cf70d8ecd65bf084daed1d0d.pdf", "supplementary_material": "/attachment/6569a8c2d6f8f8ef65ce686d8ebdf0850a5c8e20.zip"}, "replies": [{"content": {"summary": {"value": "The paper analyzes stepwise feature learning dynamics in SSL through the lens of feature cross-correlation eigenvalues. It introduces the notions of extent bias and amplitude bias. It provides theoretical derivations on toy examples, and experiments on synthetic and semi-synthetic data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper provides a theoretical exposition of stepwise feature learning in SSL, connecting it to short cut learning.\n\n- In addition to the theoretical analysis, the paper presents synthetic experiments in more general settings as well as evaluations on semi-synthetic image datasets."}, "weaknesses": {"value": "- The definition of extent bias is conceptually vague. The theoretical example in line 160 does not clearly distinguish “extent” from “amplitude”. The example effectively has just two 1-dimensional features (along different directions), but different magnitudes (one of size $\\sqrt{m_l}$ and the other of size $\\sqrt{m_s}$). Hence the analysis effectively reduces to showing that features with larger magnitudes are learned earlier.\n\n- Following the previous point, both examples essentially show that features with larger magnitudes are learned earlier which is rather obvious, while offering little additional insight.\n\n- Overall, I don’t see what new insights or significant practical implications the paper offers. From the theoretical side, the claimed novelty over Simon et al. (2023) is limited. The paper largely shows the same stepwise dynamics for SSL but just on two specific toy examples, without introducing fundamentally new mechanisms or insights. Additionally, theoretical analysis on how features with larger magnitudes and higher dimensions can suppress the learning of other features in SSL already appears in earlier works such as [1]. On the experimental side, the results only confirm the stepwise phenomenon. It’s unclear what specific new guidance for practice can be drawn from this study. Overall, the work seems to lack theoretical depth, novelty, and practical significance.\n\n[1] Xue, Yihao, et al. \"Which features are learnt by contrastive learning? on the role of simplicity bias in class collapse and feature suppression.\" International Conference on Machine Learning. PMLR, 2023."}, "questions": {"value": "Please see the questions raised in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9SFIcBzCZw", "forum": "P23YpnH3kq", "replyto": "P23YpnH3kq", "signatures": ["ICLR.cc/2026/Conference/Submission17357/Reviewer_Q3Bm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17357/Reviewer_Q3Bm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807779114, "cdate": 1761807779114, "tmdate": 1762927272689, "mdate": 1762927272689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes self-supervised learning (SSL) algorithms through the theoretical framework introduced by Simon et al. (2023). This framework employs simplified toy one-layer linear models to examine the behavior of SSL objectives—particularly the Barlow Twins (BT) loss.\n\nWithin this setup, the authors first explore extent bias, aiming to understand how feature learning in SSL is influenced more by dimensional properties than by semantic content. They design a toy dataset in which each input is a concatenation of constant vectors of varying dimensionalities, randomly modulated in amplitude. Using the analytical tools developed by Simon et al. (2023), they study the temporal learning dynamics and show that the dimensional scale plays a key role in shaping learning behavior.\n\nThe second part of the study investigates amplitude bias, referring to the tendency of networks to favor low-frequency information during training. In this case, the inputs are modeled as superpositions of randomly weighted high- and low-frequency cosine signals. Applying the same analytical framework, the authors demonstrate that the learning dynamics depend primarily on the amplitude of spectral components rather than their frequency.\n\nIn the following sections, the paper examines the effect of the redundancy reduction coefficient of BT loss and elaborates on the extension of  the analysis to nonlinear networks. Finally, numerical experiments on the Colored MNIST and Waterbirds datasets are presented to support the theoretical findings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors present clear problem statements and theorems, supported by sound proofs in the Appendix, for both extent bias and amplitude bias. These analyses, based on linear toy models, are insightful and convincing. The fact that the findings are further validated through experiments on real data enhances their value.\n\n- The article is well-presented and easy, even pleasant, to read.\n\n- Overall, this work represents a valuable extension of prior research. Both extent bias and frequency (amplitude) bias have been recognized in the literature as important issues, and this paper provides additional insights by applying the analytical framework of Simon et al. (2023)."}, "weaknesses": {"value": "- The main limitation lies in the simplicity of the toy linear or single-layer model used in the analysis.\n\n- More comprehensive experiments with real-world datasets would further strengthen the empirical validity of the presented analysis results."}, "questions": {"value": "- What is the dependence of the $\\Gamma$ matrix on the chosen data augmentations?\n\n- Could you elaborate on the generalizability of the observations to other SSL algorithms? The derivations are based on the Barlow Twins loss, but can the underlying intuitions about common features of algorithms/losses to extend results to other losses or algorithmic designs?\n\n- Regarding the extent vs. semantic impact: would it be possible to conduct controlled experiments with manipulated data (e.g., keeping the objects fixed while modifying the background—by expanding, changing texture, etc.) to test the influence of these properties?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bkOpmeBMD8", "forum": "P23YpnH3kq", "replyto": "P23YpnH3kq", "signatures": ["ICLR.cc/2026/Conference/Submission17357/Reviewer_cfsZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17357/Reviewer_cfsZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893164302, "cdate": 1761893164302, "tmdate": 1762927272317, "mdate": 1762927272317, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a theoretical framework analyzing shortcut learning in self-supervised learning (SSL) through the lens of eigenvalue decomposition of feature cross-correlation matrices. The authors introduce two concepts: extent bias (prioritizing features based on dimensional coverage) and amplitude bias (prioritizing features based on magnitude). Building on Simon et al. (2023)'s work on stepwise learning dynamics, they demonstrate that learning priority is fundamentally governed by eigenvalues of the feature cross-correlation matrix rather than semantic importance. The theoretical analysis is validated through toy models (linear networks, MLPs) and extended to semi-realistic datasets (Colored-MNIST, Modified Waterbirds)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Rigorous theoretical framework: The eigenvalue decomposition analysis (Theorems 4.1, 4.2, 4.3, 5.1) provides precise mathematical characterization of when features are learned, with critical time points τⱼ ∝ 1/γⱼ clearly derived.\n\nClear experimental validation: Figure 1 demonstrates excellent alignment between theoretical predictions (dashed lines) and empirical results (solid lines) for loss, eigenvalues, and feature alignment evolution.\n\nComprehensive scope: Analysis extends beyond basic Barlow Twins to multiple SSL methods (SimCLR, VICReg - Section C), network architectures (linear, DLN, MLP - Sections B.1-B.3), and the redundancy reduction coefficient λ (Section 6.1, Figure 2).\n\nNovel formalization: Extent bias and amplitude bias provide useful conceptual frameworks. The connection between feature dimensionality (mₗ vs mₛ) and eigenvalue magnitude (γₗ = mₗ > γₛ = mₛ, Theorem 4.1) is elegantly established.\n\nSome empirical validation: Colored-MNIST experiments (Section 7.1, Figure 5) show the plateau at 70% accuracy directly validates the extent bias hypothesis in a controlled setting with varying object ratios."}, "weaknesses": {"value": "Limited novelty of core insight: The observation that models learn high-dimensional/high-amplitude features first is well-established in the spectral bias literature (Rahaman et al. 2019, Tancik et al. 2020 - cited by authors) and also formulated as various other names (easy-to-learn, low-variance features etc.) in the literature. The main contribution is formalizing this specifically for SSL eigenvalue dynamics.\n\nLimited actionable insights: While the paper explains why shortcut learning occurs, it offers minimal guidance on how to mitigate it. The conclusion mentions \"designing mechanisms to encourage learning of generalizable features\" but provides no concrete methods.\nExperimental scope:\n\nModified Waterbirds experiments (Section 7.2) are interesting but only briefly described in appendix.\nNo experiments on standard SSL benchmarks (ImageNet pretraining + downstream tasks) to assess real-world impact.\nThe 70% plateau observation in Figure 5 is compelling but limited to artificially constructed spurious correlations."}, "questions": {"value": "What do the authors think the key takeaway from this work should be? \n\nIs the goal to provide a theoretical framework for future analysis or does this yield some clear empirical insights for mitigating or discovering spurious correlations in practice already?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I6nV8cGAvK", "forum": "P23YpnH3kq", "replyto": "P23YpnH3kq", "signatures": ["ICLR.cc/2026/Conference/Submission17357/Reviewer_xbxN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17357/Reviewer_xbxN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939895724, "cdate": 1761939895724, "tmdate": 1762927271886, "mdate": 1762927271886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}