{"id": "IZHk6BXBST", "number": 14589, "cdate": 1758239549392, "mdate": 1759897360790, "content": {"title": "Rodrigues Network for Learning Robot Actions", "abstract": "Understanding and predicting articulated actions is important in robot learning. However, common architectures such as MLPs and Transformers lack inductive biases that reflect the underlying kinematic structure of articulated systems. To this end, we propose the **Neural Rodrigues Operator**, a learnable generalization of the classical forward kinematics operation, designed to inject kinematics-aware inductive bias into neural computation. Building on this operator, we design the **Rodrigues Network (RodriNet)**, a novel neural architecture specialized for processing actions. We evaluate the expressivity of our network on two synthetic tasks on kinematic and motion prediction, showing significant improvements compared to standard backbones. We further demonstrate its effectiveness in two realistic applications: (i) imitation learning on robotic benchmarks with the Diffusion Policy, and (ii) single-image 3D hand reconstruction. Our results suggest that integrating structured kinematic priors into the network architecture improves action learning in various domains.", "tldr": "We design a new neural network, the Rodrigues Network (RodriNet), that addresses the kinematic structural priors in articulated robot action learning.", "keywords": ["Robot learning", "Action understanding", "Neural architecture"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6d13665b2137f656079d7a1a343005fc22d6e1d5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Rodrigues network (rodrinet), a novel graph neural network architecture that encodes the kinematics-aware inductive bias. The authors evaluate the proposed architecture on forward/inverse kinematic fitting, robot manipulation, and hand reconstruction tasks, which show that rodrinet outperforms or is on par with existing popular architectures."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The overall presentation is very clear and straightforward, give enough background to understand the proposed method. \n2. The forward/inverse kinematic fitting experiments clearly demonstrate that the proposed architecture captures the inductive bias of articulated chains. Before that, I hesitated on this because GNN message passing is very different from sequential forward kinematic computation. \n3. The Rodriguez equation is an interesting perspective, and the authors conduct experiments over a diverse range of tasks. I very appreciate the authors' efforts."}, "weaknesses": {"value": "My major concerns (questions) are two below, which also link to the core weaknesses of this paper in my opinion.\n\n1. Why robot-kinematic-inductive bias matters? \n2. Does the performance gain from RodriNet justify the cost of an unorthodox design?\n\n[Q1]: Most of the current robotic applications use task space control (i.e., predicting the end-effector pose), aka the eef pose, which can be easily translated to joint torques with an op-space controller. In this case, the model does not need to consider the robot's own kinematic structure and can leave that to controller. \n\nIn this paper's experiment results, the most compelling results come from the forward/inverse kinematics fitting, which, however, has faster and flexible analytical solutions. On other tasks, the benefits are very marginal. Like in the robot manipulation experiments, even when Rodrinet outperforms the diffusion policy on PickCube and StackCube, I am not entirely convinced because these two tasks should not heavily depend on the robot kinematic chain. In the hand reconstruction task, the authors explicitly mention that modifications are made to RodriNet to suit MANO's configuration space (for example, fitting the hand shape beta parameters, which I assume are not tied to joint/link). This even make the results look less convincing. \n\n\n[Q2] Even if robot-kinematic-inductive bias may not matter in every task, having them for free does not hurt. However, this proposed architecture, which looks like another GNN variant, has limitations and cannot be used for free. \n\nFor example, all robot manipulation experiments are conducted in state space, rather than using visual inputs. This is a critical constraint. Additionally, using a GNN instead of a general transformer could make it challenging to interpolate with other transformer-based backbones. Using joint space and not task space actions can also make the prediction less visually grounded. In sum, these constraints outweigh the marginal performance gain.\n\nA side note: joint controllers are widely used in dexterous hands; maybe this technique can find its place in hand manipulation tasks, instead of parallel grippers."}, "questions": {"value": "(I list all questions in the weakness section)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NmdgR02Wt9", "forum": "IZHk6BXBST", "replyto": "IZHk6BXBST", "signatures": ["ICLR.cc/2026/Conference/Submission14589/Reviewer_wx1x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14589/Reviewer_wx1x"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761438174989, "cdate": 1761438174989, "tmdate": 1762924974289, "mdate": 1762924974289, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Rodrigues Network (RodriNet), a neural architecture that explicitly embeds articulated kinematic structure into its design. The key component is the Neural Rodrigues Operator, derived from Rodrigues’ rotation formula by separating “state-dependent” (sin θ, cos θ) terms from “structure-dependent” coefficients and making the latter learnable. This transforms parent–child relations in a kinematic tree into a learnable message-passing rule. A multi-channel variant updates per-link 4×4 features from per-joint inputs using both left and right multiplications. Stacking these operators forms Rodrigues Layers, complemented by a Joint Layer and a Self-Attention Layer for global interaction, with an optional global token handling shared variables such as base pose or gripper state.\nEmpirically, RodriNet (1) achieves superior fitting accuracy on forward kinematics for the LEAP Hand and improved Cartesian-trajectory prediction on the UR5 arm, (2) boosts simulated success rates in Diffusion Policy across five ManiSkill tasks, and (3) improves single-image 3D hand reconstruction on FreiHAND by replacing the transformer head in HaMeR, yielding small but consistent SOTA gains with significantly fewer parameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Principled inductive bias: The formulation of a learnable operator directly from Rodrigues’ rotation rule is mathematically clean and physically grounded. By explicitly modeling the basis (1, sin θ, cos θ), RodriNet captures rotational structure while preserving the kinematic tree topology.\n\n- Strong expressivity for kinematic mapping: On forward-kinematics fitting, RodriNet (Rodrigues Layers only) achieves orders-of-magnitude lower MSE and faster convergence than MLP, GCN, Transformer, or BoT baselines, demonstrating that the inductive bias aligns well with articulated geometry.\n\n- Effective bridging of Cartesian and joint spaces: The UR5 trajectory prediction task is a well-controlled test of inverse kinematics. RodriNet achieves lower train/test MSE and maintains accuracy under reduced data regimes, showing improved data efficiency.\n\n- Practical gains in imitation learning: Integrated into Diffusion Policy, RodriNet improves average success rate (0.61 vs. 0.58 for UNet-DP and 0.44 for Transformer-DP) across five ManiSkill tasks, with the largest gains on PickCube and StackCube. The global token cleanly handles gripper control.\n\n- Cross-domain transfer: When replacing the transformer head in HaMeR, RodriNet attains consistent SOTA on FreiHAND with far fewer parameters (10.7 M vs. 39.5 M), indicating that the inductive bias generalizes beyond robotics.\n\n- Thorough analysis and solid engineering: Ablations identify the Rodrigues Layer as the main contributor. Performance is stable under architectural scaling, and the custom CUDA implementation yields ~6× speedup in large configurations."}, "weaknesses": {"value": "- Lack of equivariance guarantees: The learnable operator applies unconstrained 4×4 left/right multiplications, offering no guarantee of SE(3) consistency or frame equivariance. Layer composition may not preserve physically valid transformations. The method serves as an inductive bias rather than a structured constraint; adding formal regularization (e.g., orthogonality or SE(3)-aware constraints) could strengthen the theoretical foundation.\n\n- Limited novelty relative to existing basis encodings: The operator performs a learned linear combination over {1, sin θ, cos θ} (and quadratic quaternion terms for MANO), similar in spirit to Fourier or harmonic encodings. The absence of comparisons to SE(3)-equivariant architectures (e.g., SE(3)-Transformer, EGNN) or differentiable FK layers leaves it unclear whether gains arise from kinematic-tree structure or from providing the correct trigonometric basis.\n\n- Restricted embodiment generalization: Kernels are defined per joint within a fixed kinematic tree, and experiments are conducted per robot (LEAP Hand, UR5, Franka). There is no evaluation of cross-morphology transfer, shared parameters across repeated structures, or conditioning on structural metadata for multi-embodiment generalization.\n\n- No real-world validation: Results in imitation learning are limited to simulation. For contact-rich tasks such as PegInsertionSide or PlugCharger, performance gains are minimal, suggesting limited robustness to real sensor or actuation noise.\n\n- Compute tradeoffs insufficiently analyzed: Training RodriNet for motion prediction requires longer runtime (2 h 22 m vs. ~1 h 20 m for Transformer/BoT), yet compute–accuracy tradeoffs are not fully discussed.\n\n- Scope limitations: The model handles only rotational joints and omits link geometry or prismatic motion. Its focus on imitation learning rather than closed-loop control narrows applicability to contact-rich or mobile-manipulation domains."}, "questions": {"value": "- Equivariance and structure validity: Does RodriNet satisfy any formal invariance or equivariance guarantees under changes of the base frame or re-rooting of the kinematic tree? Could initializing weights from analytical FK coefficients and applying soft orthogonality constraints improve SE(3) consistency while maintaining flexibility?\n\n- Comparison to SE(3)-aware models: How does RodriNet perform against SE(3)-equivariant architectures (e.g., SE(3)-Transformer, E3NN) or MLP/Transformer baselines with Fourier angle encodings and identical kinematic-graph wiring? This would clarify whether the Neural Rodrigues Operator contributes beyond periodic encodings and structural locality.\n\n- Cross-morphology generalization: Can the per-joint kernels be shared across joints of the same type or conditioned on metadata (axis, link transforms) to enable zero-shot transfer to unseen kinematic trees? A small multi-embodiment study would help test generality.\n\n- Feature interpretation: Do the learned 4×4 “link features” converge toward SE(3)-like structures in practice? Visualizing the 3×3 rotation blocks (e.g., via polar decomposition) could reveal whether the network implicitly maintains orthogonality.\n\n- Compute tradeoffs: RodriNet requires longer training time in the UR5 task. With the CUDA kernel acceleration, what is the effective wall-clock speedup compared to a Transformer at matched accuracy? Are there memory or scaling limits for large CL/CJ?\n\n- Simulation-to-real transfer: In tasks where simulated gains are limited (e.g., PegInsertionSide, PlugCharger), how does RodriNet handle tactile or force-feedback inputs? Any early evidence of transfer performance on hardware would strengthen the empirical case."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1oGfdEj4Dn", "forum": "IZHk6BXBST", "replyto": "IZHk6BXBST", "signatures": ["ICLR.cc/2026/Conference/Submission14589/Reviewer_4VZY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14589/Reviewer_4VZY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761491405246, "cdate": 1761491405246, "tmdate": 1762924973811, "mdate": 1762924973811, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors investigate incorporating structural inductive biases from kinematic models in neural network design. They propose the Rodriguez layer, which combines projecting joint features through the learned Rodriguez operator and aggregating features globally with self-attention. Experimentally, the authors show that for problems where agents have a rigid body structure (e.g., forward kinematics or solving manipulation tasks with imitation learning), their model design performs substantially better than neural architectures that lack these inductive biases."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "> Incorporating learnable kinematic models in robotics makes intuitive sense and seems to provide measurable improvements for applying machine learning on rigid body structures\n\n> The paper is well written and presents the proposed model clearly. The diagrams help summarize the approach. \n\n> The experiments show compelling results to validate the efficacy of the Rodriguez layer for rigid body agents. The inclusion of both robots and animated characters helps demonstrate the model's potential across several settings of embodied agents."}, "weaknesses": {"value": "> Some aspects of the work are a bit obvious. The results for forward kinematics are not surprising, particularly as the Rodriguez matrix is one of two major approaches to modelling rigid-body kinematics—the other being Denavit-Hartenberg parameters. It could strengthen the paper to show how directly predicting the kinematic model's parameters compares in this problem. \n\n> Some results could benefit from statistical hypothesis testing to confirm whether the observed benefits are statistically significant (e.g. the success rates in Table 2). \n\n> Something that might be helpful would be to include results for failure cases. Presumably, there are data modalities or scenarios in which assuming a kinematic relation negatively impacts performance. \n\nWriting Opinions:\n\nLine 063 - 068:  This paragraph can be cut with almost no loss of meaningful content to the paper. \n\nRelated Work: Consider looking at cross-embodiment works as potential related work. These models also consider agent structure as necessary to model explicitly. \n\n[1] Gupta, Agrim, et al. \"Metamorph: Learning universal controllers with transformers.\" arXiv preprint arXiv:2203.11931 (2022).\n\n[2] Xiong, Zheng, Jacob Beck, and Shimon Whiteson. \"Universal morphology control via contextual modulation.\" International Conference on Machine Learning. PMLR, 2023.\n\n> Figure 3: We suggest replacing \"backbone\" with \"architecture\" unless these models are pretrained, which, in our experience, is where this term is used more frequently. \n \n>line 353: replace backbone with \"architecture\" \n\n> Figure 5: Provide more information in the caption on what is shown in the diagram."}, "questions": {"value": "Q1: What's the reason for not comparing it to the Denavit–Hartenberg formulation of kinematic structure? A quick search reveals that the Rodrigues formulation does have some technical advantages, but this seems the more appropriate comparison. \n\nQ2: What kind of features are provided to the Rodriguez layers? Do the transformations process non-kinematic related features in some way? How would these layers work with non-kinematic associated features, for instance? \n\nQ3: What about the author's current work that limits their representation to only spherical joints as opposed to translational joints? \n\nQ4: What distinguishes the Rodriguez layer from running system identification to find the model's kinematics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "erICPkVuUU", "forum": "IZHk6BXBST", "replyto": "IZHk6BXBST", "signatures": ["ICLR.cc/2026/Conference/Submission14589/Reviewer_LiRT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14589/Reviewer_LiRT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761852681260, "cdate": 1761852681260, "tmdate": 1762924973344, "mdate": 1762924973344, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RodriNet, a neural architecture that embeds articulated-kinematics structure directly into its computation by learning a generalized version of Rodrigues’ rotation formula. Instead of treating joint values as flat vectors like MLPs or Transformers, the proposed Neural Rodrigues Operator replaces fixed trigonometric coefficients in classical forward-kinematics equations with learnable weights, enabling structured message passing along a robot's kinematic tree. RodriNet stacks these operators with joint-update and attention layers, yielding a model that naturally learns hierarchical motion patterns. Experiments show large gains in fitting forward kinematics, predicting 3D joint trajectories from Cartesian motions, improving imitation-learning performance when used as the backbone in Diffusion Policy, and achieving state-of-the-art results on 3D hand pose estimation, all with fewer parameters. Overall, the work argues for architectural priors tailored to robot embodiment as a path to more efficient and generalizable action learning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Introduces a learnable generalization of Rodrigues rotation to embed articulated-kinematics structure into neural networks, giving a principled inductive bias for articulated action learning\n\n- Presents a clear architecture (Rodrigues Layer, Joint Layer, self-attention) that mixes local kinematic structure with global information exchange\n\n- Demonstrates strong improvements across domains: forward kinematics, Cartesian-to-joint motion prediction, robotic imitation learning, and 3D hand reconstruction\n\n- Shows faster convergence and better data efficiency than standard architectures like MLPs, GCNs, and Transformers in modeling articulated motion"}, "weaknesses": {"value": "- Requires per-joint learnable parameters and tree-structured computation, which may introduce higher architectural complexity compared to simpler universal backbones\n\n- No ablation studying how much each component (Rodrigues layer vs joint layer vs attention) contributes, leaving uncertainty about which parts drive performance"}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZpYgdlPP4q", "forum": "IZHk6BXBST", "replyto": "IZHk6BXBST", "signatures": ["ICLR.cc/2026/Conference/Submission14589/Reviewer_fHxR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14589/Reviewer_fHxR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980548972, "cdate": 1761980548972, "tmdate": 1762924972719, "mdate": 1762924972719, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}