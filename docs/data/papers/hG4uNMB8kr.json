{"id": "hG4uNMB8kr", "number": 16186, "cdate": 1758261234925, "mdate": 1759897255865, "content": {"title": "Compact-A∗: Space-Efficient Fixed-Length Path Optimization", "abstract": "Several optimization problems seek a path in a state space to minimize a cost function under a length constraint. Traditionally, these are solved by A∗ search or dynamic programming (DP), as in Viterbi decoding for Hidden Markov Models. In all cases, solutions require memory commensurate with a search space that grows linearly in both state space size and path length. In this paper, we propose compact-A∗, a framework that limits the growth of the A∗ priority queue to determine the minimum cost for a path of predetermined length in a space-efficient manner and then constructs such a path by a divide-and-conquer strategy that eliminates the memory overhead. We apply compact-A∗ to Viterbi decoding and further highlight its generality with an application to V-optimal histogram construction. Our experimental results demonstrate significant improvements over state-of-the-art solutions in runtime and memory consumption.", "tldr": "We introduce space-efficient A*-based algorithms for fixed-length path search.", "keywords": ["path optimization", "decoding", "HMMs"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0ba9cfc00a1dad4b139bd23526e281b81f026645.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of finding an optimal sequence of a fixed length $L$ over a state space of size $n$, a task common in applications such as Viterbi decoding for Hidden Markov Models and V-optimal histogram segmentation.The authors highlight limitations in current standard approaches, specifically regarding the space-time trade-off. While Dynamic Programming (DP) and A* search are conventionally used, they often require $O(nL)$ space to memoize partial solutions for backtracking. Existing methods to reduce space to $O(n)$ either incur severe time overheads (e.g., $O(n^2L^2)$ by re-running algorithms) or rely on exhaustive breadth-first evaluations that limit scalability. Standard A* also struggles in this fixed-length context, as its priority queue and memoization needs grow to $O(nL)$ space.To overcome these bottlenecks, the paper introduces \"Compact-A*\", a framework designed for space- and time-efficient optimization of these fixed-length sequences. The key technical contributions involve using novel search strategies to control priority queue size and employing a divide-and-conquer approach to avoid traditional memoization, thereby achieving $O(n)$ space complexity. The authors validate Compact-A* on Viterbi decoding and V-optimal segmentation tasks, claiming improvements in both memory usage and runtime compared to prior work, particularly when dealing with skewed cost distributions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Interesting and novel improvements over the A* algorithm, along with non-trivial experimental results."}, "weaknesses": {"value": "While this paper presents an interesting topic, I believe it is not a strong fit for the ICLR venue. The work does not appear to focus on learning representations or deep learning/generative AI approaches, which are central themes for the ICLR community. Furthermore, statements such as \"In modern speech-recognition systems, the Viterbi algorithm runs...\" suggest a disconnect from current state-of-the-art practices. Modern speech recognition pipelines are predominantly end-to-end deep neural networks, and traditional methods like Viterbi are no longer considered \"modern\" in this context. This reinforces my impression that the paper may be better suited for a different venue."}, "questions": {"value": "No questions"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TD8Q8gYnGF", "forum": "hG4uNMB8kr", "replyto": "hG4uNMB8kr", "signatures": ["ICLR.cc/2026/Conference/Submission16186/Reviewer_ADPJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16186/Reviewer_ADPJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16186/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761422930417, "cdate": 1761422930417, "tmdate": 1762926349144, "mdate": 1762926349144, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce the compact-A* algorithm which space-efficiently addresses the fixed-length path optimization problems. They evaluate the performance of compact-A*-based implementations with several tasks such as Viterbi decoding and histogram construction.\n\nThe authors attempt to address challenging problems in computer science but the current paper has a couple of issues. \n\nFirst, the topic does not match the subjects of ICLR well. In my understanding, although ICLR accepts papers on optimization, the authors' optimization is about operations research/heuristic search and not about optimization on learning and/or representation.\n\nSecond, the paper is very poorly written and hard to understand. For example, there are no concrete examples that clearly illustrate the problems as well how their algorithm behaves with step-by-step traces. Figure 1 does not help understand the problem definitions and the algorithmic behavior, because how it does not describe how each value in each square is calculated and it does not describe how calculations of the values are omitted by compact A* (we need to define a heuristic function and show a trace of the priority queue). As a result, I cannot accurately assess the technical novelty and correctness of their approach.\n\nFinally, if I understand correctly, their divide-and-conquer strategy is an existing idea studied in solving the multiple sequence alignment problem. For example, Hirschberg's algorithm is the DP version, and Korf investigated both unidirectional and bidirectional A*. \nI do not list all of the papers but there are other follow-up papers to these approaches in the heuristic search community. \n\n1. Hirschberg, D.S., A linear space algorithm for computing maximal common subsequences, Communications of the ACM, Vol. 18, No. 6, June, 1975, pp. 341-343.\nhttps://dl.acm.org/doi/10.1145/360825.360861\n\n2. Richard E. Korf. Divide-and-Conquer Bidirectional Search: First Results. IJCAI 1999.\nhttps://www.ijcai.org/Proceedings/99-2/Papers/073.pdf\n\n4. Richard E. Korf and Weixiong Zhang. Divide-and-Conquer Frontier Search Applied to Optimal Sequence Alignment. AAAI 2000.\nhttps://cdn.aaai.org/AAAI/2000/AAAI00-140.pdf"}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Attempt to address the issue in search and discrete optimization\n\nAttempt to evaluate the performance of compact-A*-based implementations against other existing approaches"}, "weaknesses": {"value": "Topic which may not mach well to the scope of ICLR,  considereing that the authors' optimization is not about optimization on learning and/or representation but about a different type of optimization studied in the operations research/heuristic search communities\n\nPoor presentation because of the lack of concrete examples that clearly illustrate the problems as well how their algorithm behaves with step-by-step traces e.g., a trace of priority queues with a small, concrete heuristic function, which indicates how search efforts can be reduced \n\nCore idea which might have already been existing, especially the divide-and-conquer strategy of Hirschberg's DP algorithm and Korf's unidirectional and bidirectional A* in multiple sequence alginment"}, "questions": {"value": "How is the idea of compact A* similar to the existing approaches studied in multiple sequence alignment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SXmkvJN0eU", "forum": "hG4uNMB8kr", "replyto": "hG4uNMB8kr", "signatures": ["ICLR.cc/2026/Conference/Submission16186/Reviewer_xNKb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16186/Reviewer_xNKb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16186/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761709919796, "cdate": 1761709919796, "tmdate": 1762926348710, "mdate": 1762926348710, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of lowest-cost path finding under fixed-length constraint, and proposes Compact-A*, a framework for space and time efficient optimization of fixed-length solutions. To control the size of the priority queue, the paper considers two containment mechanisms, using either depth-first search or a new earliest-first search. The paper applies the proposed framework to two problems, namely Viterbi decoding and V-optimal histogram computation. The experiments show significant improvement over dynamic programming baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n----\n- New approach for fixed-length lowest-cost path search\n- Theoretical guarantees are provided for the proposed algorithms\n- Experiments show significant improvement over the dynamic programming baselines"}, "weaknesses": {"value": "Weaknesses:\n----\n- The extent and novelty of the technical contribution is not entirely clear to me: the base “Compact A*” algorithm seems like a limited-depth Dijkstra and not a new algorithm. It may be the first time such approach is applied to the two tasks considered but I am not convinced that this should be considered as a novel algorithm. I am also not sure why is it called “Compact A*” and not “Compact Dijkstra” as there is no heuristic function, only cost function (effectively a zero heuristic)?\n- The algorithms for controlling the queue size (DFS/EFS) are not sufficiently described: \n\t* It seems that the DFS is not an enhancement of the current approach but the algorithm just switches to a DFS once it reaches the limit. Is that correct?\n\t* The impact on worst-case runtime complexity of the whole approach when using DFS/EFS strategies is not clear.\n\t* It is not clear stated whether the provided proofs of correctness take into account these strategies (the proofs do not seem to cover these settings).\n- I found the separation between the base algorithm and the two instantiations of it (MINT/TECH) very confusing. In particular, the description of MINT is longer than the description of Compact A* with some repetition. Also not clear why propositions need to be proven for MINT rather than the base Compact A* framework or why the bidirectional variant is associated with MINT and not more broadly with the base algorithm."}, "questions": {"value": "Please see weaknesses above for my questions and concerns"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BnUMet6QKB", "forum": "hG4uNMB8kr", "replyto": "hG4uNMB8kr", "signatures": ["ICLR.cc/2026/Conference/Submission16186/Reviewer_jnNN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16186/Reviewer_jnNN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16186/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995373060, "cdate": 1761995373060, "tmdate": 1762926348228, "mdate": 1762926348228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}