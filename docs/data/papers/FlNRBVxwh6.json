{"id": "FlNRBVxwh6", "number": 12301, "cdate": 1758206928318, "mdate": 1763707971438, "content": {"title": "Differentially Private Federated Clustering with Random Rebalancing", "abstract": "Federated clustering aims to group similar clients into clusters and produce one model for each cluster. Such a personalization approach typically improves model performance compared with training a single model to serve all clients, but can be more vulnerable to privacy leakage. Directly applying client-level differentially private (DP) mechanisms to federated clustering could degrade the utilities significantly. We identify that such deficiencies are mainly due to the difficulties of averaging privacy noise within each cluster (following standard privacy mechanisms), as the number of clients assigned to the same clusters is uncontrolled. To this end, we propose a simple and effective technique, named RR-Cluster, that can be viewed as a light-weight add-on to many federated clustering algorithms. RR-Cluster achieves reduced privacy noise via randomly rebalancing cluster assignments, guaranteeing a minimum number of clients assigned to each cluster. We analyze the tradeoffs between decreased privacy noise variance and potentially increased bias from incorrect assignments and provide convergence bounds for RR-Cluster. Empirically, we demonstrate that RR-Cluster plugged into strong federated clustering algorithms results in significantly improved privacy/utility tradeoffs across both synthetic and real-world datasets.", "tldr": "We proposed an update rebalancing method to achieve a better privacy-utility trade-off in federated clustering.", "keywords": ["Federated Clustering", "Differential Privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0f3db21db0e04680610d058ef65a9684fa560c18.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper considers the problem of differential private federated clustering. The imbalanced cluster sizes leads to noise that may hurt utility of models. Then, this paper propose to use a general trick called random rebalancing cluster (RR Cluster) that downsamples large clusters to a fixed size to have more balanced clusters and thus better noise designs. Theoretical convergence rates are given in the paper. Empirical results suggest that RR-Cluster can significantly improve privacy / utility tradeoffs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Originality: The clustering algorithms and differential privacy mechanisms remain unchanged, the originality of RR-cluster that down sample large cluster is okish but not surprising.\n- Significance: having a plug-and-play trick is good and could be practical but may not be significant enough.\n- Clarity: The paper is mostly clear for readers who have some knowledge of the literature.\n- Quality: The motivation looks reasonable."}, "weaknesses": {"value": "- The overall convergence rate of Algorithm 2 (RR-Cluster-IFCA) is left in the appendix (Corollary 1) and the rates seem to be inconsistent with the baseline rates of IFCA (Checkout the Corollary 2 of the original IFCA paper) even when we ignore the  differential privacy part. I hope the authors can explain the difference.\n\n- The Theorem 2 is not good enough.\n    -  It is claimed in Line 53 that having $B=0$, the RR-Cluster type algorithm degenerate to base clustering algorithms. However, the upper bound of Theorem 2 goes to infinity as B shrinks to 0.\n\n- Writings can be improved:\n    - $F^j$ is used to denote both empirical and population loss between line 138 and 143.\n    - $\\hat{\\theta}^*$ looks kind of strange.\n    - When quantities, such as $q$, appear in the paper for the first time, are not explained (such as domain) which leads to some difficulty in reading.\n    - Algorithm 1 is not presented in a clear way. For example, line 5 says \"some information $s_i$\", and line 6 says \"privatizes $\\{s_i\\}$ into $\\{\\tilde{s}_i\\}$\". It is clearly better to articulate what are these information and perhaps reference to some equations that explain them."}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VWn0B3al2B", "forum": "FlNRBVxwh6", "replyto": "FlNRBVxwh6", "signatures": ["ICLR.cc/2026/Conference/Submission12301/Reviewer_NBjo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12301/Reviewer_NBjo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821411573, "cdate": 1761821411573, "tmdate": 1762923231214, "mdate": 1762923231214, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes RR-Cluster, a method designed to balance client contributions in differentially private federated clustering. It ensures that each cluster includes contributions from at least $B$ clients, thereby reducing the impact of differential privacy noise on small clusters compared with existing approaches. The authors provide both privacy and convergence analyses of RR-Cluster, and its effectiveness is further demonstrated through empirical experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written and easy to follow.\n\n2. The proposed RR-Cluster method is promising, as increasing the number of clients contributing to small clusters effectively mitigates the noise intensity introduced by differential privacy.\n\n3. The authors conduct both theoretical (privacy and convergence) and empirical evaluations of RR-Cluster. The derived theoretical bounds also capture the bias–variance trade-off introduced by the proposed mechanism."}, "weaknesses": {"value": "1. The paper lacks a detailed description of the defense and attack models, which is essential for readers to fully understand the assumptions and setup of the considered DP-FL system.\n\n2. The proposed RR-Cluster method appears to rely on the assumption that the server is fully honest. However, its effectiveness may significantly degrade—or even vanish—under an honest-but-curious server model, limiting its practical applicability.\n\n3. The final convergence bound presented in Corollary 1 seems overly loose, as it involves multiple assumed constants, reducing its interpretability and practical value.\n\n4. The RR-Cluster method inherently introduces a bias–variance trade-off, which necessitates careful hyperparameter tuning during implementation to achieve an appropriate balance between privacy preservation and model utility."}, "questions": {"value": "1. How can RR-Cluster be adapted to scenarios where the server is honest-but-curious? \n\n2. How does the client sampling rate affect the performance of RR-Cluster? For example, if the sampling rate increases to 0.5, each cluster is likely to become more balanced naturally. In such a case, would RR-Cluster remain effective, or would its advantages diminish, effectively reducing it to a standard federated clustering method without the need for additional rebalancing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a8135t2GIf", "forum": "FlNRBVxwh6", "replyto": "FlNRBVxwh6", "signatures": ["ICLR.cc/2026/Conference/Submission12301/Reviewer_ax89"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12301/Reviewer_ax89"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941291700, "cdate": 1761941291700, "tmdate": 1762923230980, "mdate": 1762923230980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces RR-Cluster, a lightweight technique for improving privacy-utility tradeoffs in differentially private federated clustering. The core idea is rebalancing the clusters in clustered FL to avoid having small clusters that require adding a lot of noise."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The random rebalancing approach can be integrated with various clustered FL algorithms\n- The derivations seem correct and consistent with standard DP theory. \n- Consistently outperforms baselines across datasets and privacy budgets."}, "weaknesses": {"value": "- The method assumes that rebalancing doesn't significantly hurt utility, but under concept shift (could be adversarial or not), incorrect assignments could accumulate bias. \n- Experiments focus on classification tasks with synthetic and benchmark datasets (despite claim in abstract of the use of real world datasets)\n- Only average results reported."}, "questions": {"value": ".-  How would RR-Cluster perform or be adapted in a setting with an untrusted server?\n- Can the authors report results for each cluster at least on some experiments? Average results mask how well the model performs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ms8g0Yvofc", "forum": "FlNRBVxwh6", "replyto": "FlNRBVxwh6", "signatures": ["ICLR.cc/2026/Conference/Submission12301/Reviewer_YgsE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12301/Reviewer_YgsE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988558493, "cdate": 1761988558493, "tmdate": 1762923230683, "mdate": 1762923230683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an add-on technique for existing clustered FL algorithms to enhance their performance when combined with DP. The technique’s core idea is guaranteeing a minimum number of clients assigned to each cluster in each round by random client assignment to smaller clusters. This idea is claimed to reduce the DP noise in the aggregated model updates on server within each cluster. However, this add-on technique induces a trade-off between DP noise reduction and clustering bias. The authors claim that this trade-off does not affect the clustering accuracy considerably."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed work addresses improving the performance of existing clustered FL algorithms when they are enhanced with DP guarantees, which is an important problem.\n\n2. An extensive set of experimental results are reported (however they need to be improved, see below)"}, "weaknesses": {"value": "While I have understood the point of the proposed idea completely, I strongly feel that the current experimental results do not evaluate it properly to validate the correctness of the claims in the paper. I list the existing weaknesses followed by my detailed questions in the next section for clarification.\n\n1. The privacy setting considers a trusted server, which may not always be available in FL settings.\n\n2. The experimental results are reported in an optimistic way that does not fully evaluate the proposed idea. For example, average accuracy is not enough and can be extended with worst accuracy across clients to investigate the effect of the proposed idea. Also, the used baselines can be extended/replaced with SoTA ones.\n\n3. The theoretical results about privacy guarantees do not have a clear and important message, and it mainly uses the composition property of RDP.\n\n4. The convergence analysis relies on strong convexity of loss functions. Yet, it has a clearer message than the privacy analysis.\n\n5. The chosen baselines can be improved. Current baselines (some SoTA are missing), metrics (avg accuracy) and experimental results (simple datasets) do not fully evaluate the proposed idea. Based on my experience, MNIST. FMNIST, EMNIST are easy dataset for clustered FL, compared to colured datasets like CIFAR10, Tiny ImageNet, ….\n\nI explain further in my questions below."}, "questions": {"value": "1. The main point in the proposed idea is that, considering the global DP setting and the trusted server, ensuring a minimum size for clients clusters in each round reduces the DP noise added by the server to the aggregated parameter within each cluster. As the authors claim, this improves performance. However, improving the performance of existing methods is valuable if it enables the methods to beat the existing SoTA approaches. Following this point, three main questions rise:\n\n1.1. The current data heterogeneity are “suitable” for the proposed random rebalancing idea. If the level of data heterogeneity across clusters is high, randomly mixing clients from different ground-truth clusters could affect utility severely. For example when concept shift exists across clusters (i.e. when $p(y|x)$ varies, see [1]). This is usually the assumption in clustered FL settings, otherwise personalized FL techniques could be used instead of clustered FL techniques (explained in the second question below) for moderate data heterogeneities. So investigating such data distributions will fully evaluate the applicability of the idea.\n\n1.2. Even if the data heterogeneity across clusters is not high (like the rotation and natural heterogeneities considered in the current results) and if aggregation for a larger number of clients reduces the effective DP noise, why not to use the MR-MTL (its DP extension [1,2], which is also shown in [1] to largely improve DP-FedAvg for sample-level DP)? This personalization technique is stronger than the considered FedPer, and has both the DP noise reduction (by aggregation across “all” clients on the server) as well as personalization (without even introducing “three” hyperparameters. Remember, RR-cluster introduces three hyper parameters $c_s$, $c_{\\theta}$ and $B$). Including this baseline is important because it benefits from the same noise reduction mechanism that RR-cluster does.\n\n1.3. The current used metric is the average accuracy. Reporting the best, average and worst test accuracy across clients will make the effect of incorporating random balancing clearer.\n\n[1] S. Malekmohammadi, et. al., Differentially Private Clustered Federated Learning, TMLR 2025.\n\n[2] Z. Liu, et. al., On Privacy and Personalization in Cross-Silo Federated Learning, Neurips 2022.\n\n2. The idea proposed in the work [1] above is for sample-level DP with untrusted server, yet it can directly be applied to truster server and global DP settings too, i.e. using a full batch size in the first round by clients followed by small batch sizes in the next rounds. This especially helps because in the considered trusted-server setting, clients send their “clean” model updates with no DP noise to the server, so using the full batch size idea in [1] can make detection of underlying clusters easy for the server. This would also be a strong baseline to consider as a SoTA.\n\n3. In line 188, it is mentioned that “Note that we can set $B$ so that any client update can only be sampled and reassigned to another cluster at most once”. Could the authors clarify further about this? Also, how is the client sampling from large clusters done? i.e. uniform without replacement? What if all are sampled from one “large” cluster, making it “small”?\n\n4. Line 377 implies that hyper parameters (at least the important ones like learning rate) are not set carefully for all algorithms. At least for the most strong baselines (recommended above) this should be the case. Also, in line 363, where is the set $k \\in \\\\{2,4\\\\}$ is coming from? In lines 383 to 365, you consider $k \\in \\\\{3,4\\\\}$ clusters, which is close to the above set chosen for experiments. Remember that the recommended MR-MTL baseline does not need to know number of clusters or an approximate of that. Also, the work [1] can approximate the underlying number of clusters, and it can do this even better especially in the considered trusted server setting that clients send their “clean” model updates to the server with no DP noise.\n\n5. In tables 1 (and 6), why do we observe improvement even when clusters are “balanced”? In this case, random rebalancing makes some clusters smaller and some larger (non-uniform).\nminor comments:\n\ntypo in line 036: clustered models -> cluster models\nline 269: theorem 1 -> proposition 1\nline 1011: Table 10 -> Table 5"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XcQ0kV9ikS", "forum": "FlNRBVxwh6", "replyto": "FlNRBVxwh6", "signatures": ["ICLR.cc/2026/Conference/Submission12301/Reviewer_i6N3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12301/Reviewer_i6N3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762178556133, "cdate": 1762178556133, "tmdate": 1762923230000, "mdate": 1762923230000, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}