{"id": "voBQXpnqKS", "number": 2704, "cdate": 1757213662641, "mdate": 1763515803806, "content": {"title": "SAMO: Semantic-Aware Model Optimization for Source-Free Domain Adaptive Object Detection", "abstract": "Source-Free Adaptive (SFA) object detection aims to adapt a pre-trained detector from a labeled source domain to an unlabeled target domain without access to source data. To address the performance degradation commonly observed in this setting, we introduce a novel Semantic-Aware Model Optimization (SAMO) framework that explicitly models the interplay between semantic perception and model optimization. Specifically, SAMO first performs semantic perception by categorizing target-domain regions into a confidence spectrum (from high to low) based on pseudo-labels generated by a static base detector. Building on this perception, we design an optimization strategy via detector decomposition and disentangled training. The detector is decoupled into shared modules and a specialized expert group, the latter equipped with a semantically aware gating network. Through disentangled training, expert units and shared modules are independently optimized according to their respective confidence spectrum ranges, thereby maintaining discriminative capacity across diverse semantic levels. Meanwhile, the gating network adaptively integrates expert features through learnable attention weights, enabling dynamic discrimination across semantic categories. This framework effectively alleviates the source-domain performance degradation caused by low-confidence regions, while simultaneously achieving significant improvements in the target domain. Extensive experiments on three domain adaptation benchmarks demonstrate the superior generalization ability of SAMO. Our code will be released.", "tldr": "", "keywords": ["Source-Free Domain Adaptive", "Object Detection", "Semantic-Aware", "Model Optimization"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/f064b79ba2fe9e0368e4eb0463828711762e8b1b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies source-free domain adaptive object detection (DAOD), which aims to adapt a detector pre-trained on a labeled source domain to an unlabeled target domain without access to source data. To address the common issue of performance degradation in source-free DAOD, the authors propose a Semantic-Aware Model Optimization (SAMO) framework. The key idea is to categorize target-domain regions into a confidence spectrum and design a corresponding optimization strategy through detector decomposition and disentangled training. Experiments on three standard DAOD benchmarks demonstrate that SAMO improves generalization on the target domain while maintaining performance on the source domain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies two major factors contributing to performance degradation in source-free DAOD and provides experimental evidence supporting these observations (e.g., Fig. 1).\n\n2. The proposed SAMO framework is conceptually coherent. It connects semantic perception and model optimization via a confidence spectrum, enabling disentangled training that helps balance adaptation and knowledge retention.\n\n3. The paper is well organized and easy to follow.\n\n4. The paper provides extensive experiments, including comparisons with state-of-the-art methods, ablation studies, and parameter analysis."}, "weaknesses": {"value": "1. The technical contribution is somewhat limited. While SAMO introduces a semantic-aware perspective, its main mechanism can be viewed as a fusion strategy that combines pseudo labels at different confidence levels through a gating mechanism. The novelty over prior teacher-student or mixture-of-experts–based DAOD frameworks appears incremental.\n\n2. The paper discusses performance degradation and forgetting, but no quantitative evidence is presented during training to support these claims. It would be valuable to include performance curves over training iterations to demonstrate that SAMO effectively stabilizes training and mitigates forgetting.\n\n3. The compared methods and adopted architectures are outdated. The experimental setup primarily relies on Faster R-CNN with VGG16 or ResNet-50 backbones. More recent detectors (e.g., ViT-based detectors such as DINO or Deformable DETR variants) should be included. Moreover, comparisons with recent vision-language model (VLM)–based domain adaptation methods would further strengthen the paper."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PG7bCXVhIW", "forum": "voBQXpnqKS", "replyto": "voBQXpnqKS", "signatures": ["ICLR.cc/2026/Conference/Submission2704/Reviewer_7bDa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2704/Reviewer_7bDa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761457302779, "cdate": 1761457302779, "tmdate": 1762916336506, "mdate": 1762916336506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "Pbadic3N1b", "forum": "voBQXpnqKS", "replyto": "voBQXpnqKS", "signatures": ["ICLR.cc/2026/Conference/Submission2704/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2704/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763515802516, "cdate": 1763515802516, "tmdate": 1763515802516, "mdate": 1763515802516, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Semantic-Aware Model Optimization (SAMO) framework to address the problem of performance drift in Source-Free Domain Adaptive (SFA) object detection. The core of the method lies in using semantic perception to categorize target-domain regions into a confidence spectrum. Based on this, it designs a disentangled training strategy and a gating network to balance performance across the source and target domains. The paper's experiments are extensive , demonstrating the method's effectiveness on multiple benchmarks. Overall, the work has practical value, but the details need further enhancement."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper introduces a semantic-aware model optimization framework, effectively addressing performance drift in SFA object detection by encoding the relationship between semantic awareness and model optimization.\n\n2.The approach of decoupling the detector and designing a gating network based on semantic perception allows for effective learning from diverse target-domain semantics, ensuring adaptive application of acquired knowledge.\n\n3.The paper proposes a disentangled training strategy to progressively train different parts of the detector, which helps mitigate the forgetting of source domain knowledge, demonstrating an efficient training methodology.\n\n4.The method exhibits strong effectiveness across various domain adaptation scenarios, showcasing its versatility and practical applicability in real-world settings."}, "weaknesses": {"value": "1.The SAMO framework introduces several new components, including expert groups, gating networks, and disentangled training strategies, which significantly increase the model's complexity. The document does not adequately discuss computational efficiency, such as training time, memory usage, or inference speed, which may pose bottlenecks for practical deployment.\n\n2.The SAMO framework introduces a large number of additional hyperparameters, but the authors do not provide any analysis on how to systematically determine these values, nor do they offer a comprehensive ablation study.\n\n3.The paper lacks theoretical analysis to support the effectiveness of SAMO,  which lowers the credibility of the method.\n\n4.The structure of the paper is somewhat disorganized, making it difficult to read. Some figures contain errors or are hard to understand."}, "questions": {"value": "1.Why is the gating network structure in Figure 4 designed in this way, and what are its advantages?\n\n2.What do the arrows in Figure 2, pointing from Expert 0 to subsequent experts, represent?\n\n3.In the Testing Phase in Figure 3, should it be the Student Detector instead?\n\n4.How were the hyperparameters for confidence intervals determined in the IMPLEMENTATION section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tGA22pbTIO", "forum": "voBQXpnqKS", "replyto": "voBQXpnqKS", "signatures": ["ICLR.cc/2026/Conference/Submission2704/Reviewer_YC6c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2704/Reviewer_YC6c"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761546368845, "cdate": 1761546368845, "tmdate": 1762916336324, "mdate": 1762916336324, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework called SAMO (Semantic Aware Model Optimization), specifically designed for source-free domain adaptive object detection (SFA-OD). SAMO aims to mitigate the performance degradation of SFA-OD by considering semantic variations in the target domain image and utilizing a confidence-based semantic awareness and decoupled training strategy. Experimental results show that SAMO can reduce performance drift and improve object detection accuracy in the target domain."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is easy to follow.\n* The key idea of the gated weights and feature fusion is reasonable."}, "weaknesses": {"value": "1. Limited novelty. Overall, the expert unit module acts as a prototype network, while the gated network provides corresponding weights for each prototype. This idea is very common and has been thoroughly studied in many works, such as [1]. In this respect, the proposed method is not particularly innovative.\n2. Misuse of new concepts. This paper uses the concept of MoE to refer to the proposed EU network. However, I believe this is a misconception. This is because the proposed EU network performs a weighted average on each output, with all layers participating in the computation, rather than utilizing the route activation parameters as in large-scale pre-trained models.\n3. The so-called MoE may introduce significant computational overhead. However, the paper seems to lack relevant discussion, making it impossible to determine whether the performance improvement comes from a better structural design or more parameters.\n\n[1]Bolya D, Zhou C, Xiao F, et al. Yolact: Real-time instance segmentation. CVPR 2019"}, "questions": {"value": "Please refer to Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "riRYvhwryq", "forum": "voBQXpnqKS", "replyto": "voBQXpnqKS", "signatures": ["ICLR.cc/2026/Conference/Submission2704/Reviewer_yp4D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2704/Reviewer_yp4D"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795220356, "cdate": 1761795220356, "tmdate": 1762916336095, "mdate": 1762916336095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles  source-free domain adaptive object detection. The proposed SAMO framework splits the detector into shared modules (to preserve source knowledge), a set of experts trained on different confidence ranges, and a spatial gating network that fuses expert outputs. Training is “disentangled,” starting from high-confidence regions and progressively moving to lower-confidence ones, with a teacher–student setup and EMA. Experiments on Cityscapes→FoggyCityscapes, Sim10k→Cityscapes, and VOC→Watercolor show solid target gains and relatively restrained source drift, plus ablations on the number/size of experts and gating thresholds."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Results are generally strong across three benchmarks and two backbones.\n\n2. The concept of using confidence as a proxy for domain shift is not new, but the way it's used here to explicitly manage a trade-off through a MoE architecture is novel and well-executed."}, "weaknesses": {"value": "1. From the system level, the novelty is more in the integration than in the components (teacher–student, pseudo-labeling by confidence, MoE with gating).\n\n2. The system is a bit complex. Not clean and neat enough for high impact.\n\n3. the proposed method introduces many hyperparameters.\n\n4. No training/inference computational cost is reported."}, "questions": {"value": "1. Can the authors provide a systematic ablation over the hyperparameters introduced? It is important to verify that the proposed method does not rely on cherry-picked hyperparameters."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZYnq7Kp5Ph", "forum": "voBQXpnqKS", "replyto": "voBQXpnqKS", "signatures": ["ICLR.cc/2026/Conference/Submission2704/Reviewer_y8MY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2704/Reviewer_y8MY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878947252, "cdate": 1761878947252, "tmdate": 1762916335904, "mdate": 1762916335904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}