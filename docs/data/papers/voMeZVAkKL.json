{"id": "voMeZVAkKL", "number": 24185, "cdate": 1758353778115, "mdate": 1759896778008, "content": {"title": "FAST‑DIPS: Adjoint‑Free Analytic Steps and Hard‑Constrained Likelihood Correction for Diffusion‑Prior Inverse Problems", "abstract": "$\\textbf{FAST-DIPS}$ is a training-free solver for diffusion-prior inverse problems, including nonlinear forward operators. At each noise level, a pretrained denoiser provides an anchor $ \\textbf{x} _ {0|t} $; we then perform a hard-constrained proximal correction in measurement space (AWGN) by solving\n$\\min_\\mathbf{x} \\tfrac{1}{2\\gamma_t}\\|\\mathbf{x}-\\mathbf{x}_{0|t}\\|^2 \\ \\text{s.t.} \\|\\mathcal{A}(\\mathbf{x})-\\mathbf{y}\\|\\le\\varepsilon$.\nThe correction is implemented via an adjoint-free ADMM with a closed-form projection onto the Euclidean ball and a few steepest-descent updates whose step size is analytic and computable from one VJP and one JVP—or a forward-difference surrogate—followed by decoupled re-annealing. We show this step minimizes a local quadratic model (with backtracking-based descent), any ADMM fixed point satisfies KKT for the hard-constraint, and mode substitution yields a bounded time-marginal error. We also derive a latent variant $\\mathcal{A}\\mapsto\\mathcal{A}\\circ\\mathcal{D}$ and a one-parameter pixel\\(\\rightarrow\\)latent hybrid schedule. Across eight linear and nonlinear tasks, FAST-DIPS matches or surpasses training-free baselines while reducing wall-clock by $5\\times$–$25\\times$, requiring only autodiff access to \\(A\\) and no hand-coded adjoints or inner MCMC.", "tldr": "", "keywords": ["inverse problem", "image reconstruction", "diffusion models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/78af1a89fb5ad2b7773b6c39a24aafedd43a844b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces FAST-DIPS which aims to improve both the speed and accuracy of existing diffusion-prior solvers. The core contribution is a two-stage update process applied at each step of the reverse diffusion chain: \"analytic step\" and \"hard-constrained likelihood correction\" step. The experimental results show that FAST-DIPS consistently outperforms state-of-the-art methods in terms of reconstruction quality and/or computational time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed combination of an analytic data consistency step with the hard-constrained likelihood correction is novel and appears highly effective. \n2. The paper provides compelling empirical evidence of its superiority, often delivering higher quality in a fraction of the time required by competing methods.\n3. The paper is theoretically sound and clearly structured."}, "weaknesses": {"value": "1. The Method section is dense and overly technical, relying heavily on acronyms and mathematical derivations with minimal intuition.\n\n2. The \"adjoint-free\" claim could be misleading. The method avoids computing the adjoint operator $A^T$ at each iteration by pre-computing a term involving $(A A^T)^{-1}$. This is only advantageous for a specific class of operators where this matrix is easy to compute and invert. \n\n3. The choice of $\\epsilon$ in the hard constraint is not well explained\n\n4. The extension of the method to non-linear problems like phase retrieval is handled by linearizing the forward operator at each step. This is a reasonable approach, but the paper provides very little detail or justification for it. \n\n5. The exclusive use of FFHQ restricts the generality of the conclusions."}, "questions": {"value": "1. Could the author please clarify the practical limitations of the adjoint-free formulation? For which classes of forward operators $A$ does the pre-computation of $(A A^T)^{-1} A$ become a bottleneck that outweighs the per-iteration speed-up?\n\n2. Though the experiment section has included various inverse problems, the selection of the dataset is very limited. Can the author please add at least one more dataset other than human face to benchmark the performance?\n\n3, The hybrid schedule introduces a switching threshold $\\sigma_\\text{switch}$. How is this parameter selected in practice, and how does performance vary with its value?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0EawWhJ5pg", "forum": "voMeZVAkKL", "replyto": "voMeZVAkKL", "signatures": ["ICLR.cc/2026/Conference/Submission24185/Reviewer_9UpX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24185/Reviewer_9UpX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761345114047, "cdate": 1761345114047, "tmdate": 1762942980648, "mdate": 1762942980648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FAST-DIPS, a fast and training-free solver for diffusion-prior inverse problems. The key idea is to perform a hard-constrained likelihood correction at each diffusion step through an adjoint-free ADMM scheme with analytic step size computation, thereby avoiding the need for hand-coded adjoints or inner MCMC loops. \nExperimental results across multiple linear and nonlinear inverse problems demonstrate that FAST-DIPS achieves comparable or superior reconstruction quality while reducing runtime compared to state-of-the-art training-free baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Clear and principled framework**:\nThe paper presents FAST-DIPS, a training-free and adjoint-free framework for diffusion-prior inverse problems, offering a clean and principled alternative to existing plug-and-play or posterior-sampling approaches.\n\n2. **Broad applicability and ease of use**:\nThe method supports both pixel-space and latent-space diffusion models through an adjoint-free design, making it versatile and easy to apply to a variety of inverse problems without hand-crafted adjoints or retraining.\n\n2. **Strong empirical performance**:\nThe proposed analytic-step ADMM correction eliminates the need for hand-crafted adjoints or inner MCMC loops, making the method broadly applicable to both linear and nonlinear operators while achieving 5×–25× faster inference."}, "weaknesses": {"value": "1. **Presentation issue**:\nTable 1 exceeds the page width and is difficult to read in its current format. The authors should consider reformatting or splitting the table across pages to improve readability and compliance with ICLR formatting guidelines."}, "questions": {"value": "1.The performance of the baseline algorithms in Table 1 differs from that reported in their original papers, even under the same experimental settings. For instance, the SITCOM paper reports a PSNR of 30.68 for the SR task, whereas Table 1 reports 29.555. A similar discrepancy is also observed for the DAPS algorithm. While Figure 3 effectively demonstrates the superiority of the proposed method under the same runtime, I would appreciate clarification regarding these inconsistencies."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PMa0CKOXOc", "forum": "voMeZVAkKL", "replyto": "voMeZVAkKL", "signatures": ["ICLR.cc/2026/Conference/Submission24185/Reviewer_pSwc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24185/Reviewer_pSwc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761467650880, "cdate": 1761467650880, "tmdate": 1762942980486, "mdate": 1762942980486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FAST-DIPS, a training-free diffusion-prior inverse problem solver. The core contributions are: (1) an adjoint-free correction step that (2) enforces a hard-constrained likelihood ($||\\mathcal{A}(x)-y||\\le\\epsilon$) using (3) an ADMM formulation, where the primal update is solved efficiently with an analytic, non-iterative step size derived from a local quadratic model. The method is further extended to latent and hybrid (pixel/latent) settings."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The adjoint-free ADMM formulation with analytic step sizes (via VJP/JVP or finite-difference approximations) is a clever way to minimize engineering overhead while ensuring efficient and deterministic updates.\n\n2. The paper provides strong local guarantees, including exact minimization of quadratic models (Proposition 3), KKT satisfaction at fixed points (Proposition 4), and descent properties with backtracking."}, "weaknesses": {"value": "1. My main concern is that, while adjoint-free, the method still requires autodiff through $\\mathcal{A}$, and the latent mode incurs repeated decoder calls. In my view, the engineering benefit of avoiding adjoints is somewhat offset by the computational cost of automatic differentiation through $\\mathcal{A}$.\n\n2. The method’s hard constraint ($||\\mathcal{A}(x)-y||\\le\\epsilon$) shifts the tuning burden from the likelihood weight to the credible set’s radius $\\epsilon$. Although this is briefly acknowledged in the limitations section, the paper should more thoroughly discuss how this critical hyperparameter is selected.\n\n3. Experiments are limited to FFHQ (faces only), which lacks diversity; no tests are conducted on broader datasets such as CelebA-HQ, LSUN, or natural images (e.g., ImageNet subsets). This raises concerns about generalization to non-face domains or higher resolutions.\n\n4. The complete algorithm, as presented in the appendix, is somewhat complex, making the method less elegant. Moreover, the writing could be improved for better clarity and flow."}, "questions": {"value": "1. How was the hyperparameter $\\epsilon$ (the radius of the credible set) determined for each of the eight experiments?\n\n2. The paper claims to use no inner MCMC, but the ADMM iterations ($K=3$–$5$) with $S=1$ descent appear to form mini-loops. Please clarify if I have misunderstood this point.\n\n3. For the latent variant, have you analyzed the computational cost of the JVP $J_{\\mathcal{A}\\circ\\mathcal{D}}(z)g$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gfBpKNw0yE", "forum": "voMeZVAkKL", "replyto": "voMeZVAkKL", "signatures": ["ICLR.cc/2026/Conference/Submission24185/Reviewer_6kKx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24185/Reviewer_6kKx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962228021, "cdate": 1761962228021, "tmdate": 1762942980268, "mdate": 1762942980268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FAST-DIPS, a training-free solver for diffusion-prior inverse problems, including those with nonlinear forward operators. The method's core is a hard-constrained proximal correction via an adjoint-free ADMM. This approach replaces costly inner MCMC loops or iterative optimization with an analytic step size, computable from one VJP and one JVP. Experiments across eight linear and nonlinear tasks demonstrate comparable or superior quality to state-of-the-art baselines, while achieving faster runtimes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  The method’s adjoint-free design is both interesting and practical, eliminating the need for hand-coded adjoints. By relying on standard automatic differentiation (VJP/JVP), the framework is directly applicable to a broad class of nonlinear inverse problems—a setting that remains challenging for many competing methods.\n\n2.  The framework is evaluated extensively and demonstrates a substantial speedup over baselines such as DAPS by replacing costly inner MCMC loops with an analytic step size, while maintaining—often even improving—reconstruction quality."}, "weaknesses": {"value": "1.  One concern is the method's reliance on differentiable forward operators. The entire framework is built upon the availability of VJP and JVP, making it inapplicable to common non-differentiable degradations such as JPEG restoration or quantization. This may limit its utility for many real-world degradation types.\n\n2.  Another concern is the need for task-specific hyperparameter tuning. The authors show that key parameters were set to different values for each of the eight tasks. This implies that users must perform a new, potentially expensive hyperparameter search for any novel problem, undermining its practicality as a plug-and-play solver. Moreover, I wonder if this hyperparameter selection is essential for other baselines as well. If so, we need to include the cost of hyperparameter selection to show practical speed-up in the usage of the proposed method.\n\n3. Moreover, I am skeptical about the method's scalability to higher resolutions. The computational cost of the VJP/JVP, especially for the latent variant, which requires backpropagation through the decoder, was manageable for the $256 \\times 256$ experiments. However, this computation and memory overhead is likely to become a significant bottleneck as resolution increases, potentially limiting the framework's applicability to large-scale problems."}, "questions": {"value": "Please see the Weaknesses for the details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "kIIt5pi3aU", "forum": "voMeZVAkKL", "replyto": "voMeZVAkKL", "signatures": ["ICLR.cc/2026/Conference/Submission24185/Reviewer_mDLA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24185/Reviewer_mDLA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762251325302, "cdate": 1762251325302, "tmdate": 1762942979637, "mdate": 1762942979637, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}