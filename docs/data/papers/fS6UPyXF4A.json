{"id": "fS6UPyXF4A", "number": 2762, "cdate": 1757241770191, "mdate": 1759898128655, "content": {"title": "SteerVLA: Steering Vision-Language-Action Models Toward Effective Long-Tail Driving", "abstract": "A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded, embodied experience necessary for safe vehicle control. Conversely, policies trained on driving data exhibit strong reactive skills, but often fail in novel scenarios that require abstract understanding.\nWe posit that an effective autonomous agent must leverage the world knowledge of VLMs to steer a grounded driving policy, rather than attempting to embed all knowledge into a single monolithic model. To this end, we propose SteerVLA, a hierarchical driving policy composed of a high-level VLM planner and a low-level vision–language–action (VLA) policy. The planner produces fine-grained language commands, which steer a flexible, low-level policy for control. To train these policies, we leverage VLMs to augment existing real-world and simulation data with dense annotations in hindsight, which we find is essential for strong reasoning and steerability. We evaluate SteerVLA in challenging real-world open-loop and simulated closed-loop long-tail scenarios, where it outperforms state-of-the-art methods.", "tldr": "", "keywords": ["Vision-Language-Action Models", "Autonomous Driving", "Steerability"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6072abea606755642e071027e93d90975685643c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper “SteerVLA: Steering Vision-Language-Action Models Toward Effective Long-Tail Driving” proposes a hierarchical vision-language-action (VLA) framework intended to improve autonomous driving in long-tail scenarios. The approach involves a high-level vision-language model (VLM) planner that generates meta-actions and reasoning traces, and a low-level controller that executes continuous control actions. The authors also introduce an auto-labeling pipeline to enhance data quality and claim to construct a new Bench2Drive-Hard subset to evaluate performance on challenging scenarios.\n\nWhile the paper aims to address an important problem—long-tail generalization in autonomous driving—its contributions appear incremental relative to prior work such as DriveVLM and DriveGPT. Furthermore, several methodological and experimental claims are under-specified or insufficiently supported, which limits confidence in the novelty and validity of the results."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The focus on long-tail driving and hierarchical perception-action modeling is timely and aligns with ongoing efforts in interpretable and robust autonomous driving.\n\nThe modular reasoning-control formulation is conceptually intuitive and potentially extensible to other embodied tasks."}, "weaknesses": {"value": "The weaknesses are listed here:\n\n1. The paper claims that it introduces a hierarchical vision-language-action decomposition, a novel design separating reasoning (language domain) from control (action domain). However, I believe DriveVLM(https://arxiv.org/pdf/2402.12289v4) already proposes a decomposed VLM + action planner system. And it has very similar design in terms of using a VLM to output meta action and a low-level planner outputs trajectory. \n\n2. The data generation pipeline is similar to label generation pipeline proposed from DriveVLM, DriveGPT, and etc. I don't find significant novelty in this step. \n\n3. The author stated that they created a subset of long-tail data from Bench2Drive, called Bench2Drive-Hard, to rigorously benchmark the model’s long-tail driving abilities. However, I didn't find any text describing how this Bench2Drive-Hard dataset is generated. It was not even mentioned out of the introduction paragraph. I am not even sure if the dataset is being used for evaluation. \n\n4. The results in Table1 does not show that SteerVLA has a significant lead over SimLingo. And based on my understanding, SimLingo's system is around 1B parameters and is much smaller compared to the 4B system used by SteerVLA. The marginal improvements may come from the additional model parameters rather than proposed methodology."}, "questions": {"value": "1. What's the major novelty in the data creation step, compared to DriveVLM and DriveGPT? \n2. How is your proposed method better than DriveVLM? (even from a conceptual perspective)\n3. How is Bench2Drive-Hard generated? And how is it used in this paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cONzTv6bZC", "forum": "fS6UPyXF4A", "replyto": "fS6UPyXF4A", "signatures": ["ICLR.cc/2026/Conference/Submission2762/Reviewer_PUZ2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2762/Reviewer_PUZ2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761179783945, "cdate": 1761179783945, "tmdate": 1762916364151, "mdate": 1762916364151, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a two stage hierarchical architecture for VLA for autonomous driving. The higher level is done by a VLM, fine-tuned on driving related visual question answering task. This produces both meta actions and reasoning traces about the scene and action. The lower level planner takes the meta action along with scene information and generates the trajectory. The authors present competitive performance with SOTA methods. There is also a pseudo label generation presented, that can be used for data augmentation in any VLA related tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. By splitting the driving task into two stages makes it flexible, adaptable to various scenarios. Even though hierarchical design is not new, two stage VLA design is quite new. This can potentially improve generalizability, especially helping with corner cases using the higher level reasoning for better overall performance.\n\n2. Refinement step can be seen as a generic data augmentation method that can be isolated out of this work and applicable to any other labeling use cases."}, "weaknesses": {"value": "1. Hierarchical design also introduces some complexities that the paper does not address. Like, choosing inference frequencies of the two stages or dealing with synchronization issues between the two systems are  difficult problems that should have been mentioned.\n\n2. The evaluation logic for the refinement step is questionable. As, speed and turning angle are what is used for refinement and also being used for measurement, this could cause data leakage issue. Ideally, this should be evaluated on a different dataset or with non-overlapping chunks using careful masking of the future state information."}, "questions": {"value": "1. The decision to remove 'force-to-move' heuristic from Similingo is not justified well. It is important to show full end-to-end system performance. It should have been reported and if possible be included into this method for a fair comparison.\n\n2. The baseline methods mostly use older VLM models like Intern VL2 etc. It is not clear if the performance jump is due to better VLM or from better algorithm design. An ablation study, showing the full system performance using the same VLM as the baseline methods would be convincing.\n\n3. As all the closed loop evaluations are done in simulation, there should be a mention of sim-to-real gaps and some possible ways to address them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "jKnmUzUIAy", "forum": "fS6UPyXF4A", "replyto": "fS6UPyXF4A", "signatures": ["ICLR.cc/2026/Conference/Submission2762/Reviewer_wN4f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2762/Reviewer_wN4f"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761608456881, "cdate": 1761608456881, "tmdate": 1762916363965, "mdate": 1762916363965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a VLA method named SteerVLA, which focuses on addressing the long-tail driving problem. Specifically, it consists of two stages: a high-level VLM planner that performs semantic and common-sense reasoning to analyze driving scenarios, and a low-level VLA actor that generates precise control actions based on those instructions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is strong, long-tail cases are indeed an important issue in autonomous driving.\n\n2. The experimental results look promising."}, "weaknesses": {"value": "1. Using VLMs to generate reasoning-based labels is not novel. For example, VLM-AD [1] adopts a similar strategy by automatically generating reasoning information through various designed prompts or questions. It would be better to include such related works and discuss how this method differs from or improves upon them.\n\n[1] Y. Xu et al., “VLM-AD: End-to-End Autonomous Driving through Vision-Language Model Supervision,” Proceedings of the 9th Annual Conference on Robot Learning (CoRL), 2025\n\n\n2. Some explanations are unclear. For example, how are meta-actions generated? How are the language–action labels created? Where does the reasoning originate?\n\n3. As mentioned in the introduction, this work focuses on long-tail cases. However, more experiments could be included to verify this claim. For instance, are there specific long-tail scenarios where the proposed method outperforms existing ones? What do the metrics look like under those corner cases?"}, "questions": {"value": "1. How is the quality of the generated labels evaluated? In other works, questionnaires or human evaluations are often used to ensure quality. If the quality is poor, since VLMs cannot guarantee 100% correctness in understanding driving scenarios, especially long-tail cases, does this not affect the reliability of the proposed method?\n\n2. How are the meta-action labels generated? As mentioned in Line 213, it is unclear how these meta-actions are defined. Is there a predefined list of meta-actions? Given the focus on long-tail cases, how is the coverage of possible actions ensured?\n\n3. In Section 3.2, if fine-grained labels are derived from the original ones, does that mean no additional information is introduced? If so, how are new reasoning traces generated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fEmTZQBNRT", "forum": "fS6UPyXF4A", "replyto": "fS6UPyXF4A", "signatures": ["ICLR.cc/2026/Conference/Submission2762/Reviewer_83of"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2762/Reviewer_83of"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964416778, "cdate": 1761964416778, "tmdate": 1762916363810, "mdate": 1762916363810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SteerVLA, to address the critical or long-tail scenarios of autonomous driving, where the proposed SteerVLA contains a hierarchical vision–language–action (VLA) framework aimed at improving complex reasoning and adaptability. SteerVLA consists of \n\n- High-level VLM planner: Performs semantic reasoning and outputs meta-actions (language-based driving instructions) and reasoning traces.\n- Low-level VLA actor: Converts meta-actions into precise control actions such as waypoints.\nTo train these components, the authors introduce an auto-labeling pipeline that generates fine-grained language labels and reasoning traces from driving data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- SteerrVLA contains separate reasoning and control, reducing knowledge collapse and improving generalization.\n- SteerVLA's data augmentation pipeline generates nuanced language labels and reasoning traces, improving steerability and language following.\n- SteerVLA's Interpretability benefits meta-actions and reasoning traces provide transparency in decision-making."}, "weaknesses": {"value": "- SteerVLA's claims they provided open-loop evaluations, but the Table is closed-loop evaluations on Bench2Drive, Table 2 is ablation study, and Table 3 is VLA policy on trajectory prediction. But there is open-loop evaluations are missing. As the authors claim the SteerVLA improves performance on long-tail scenarios. SteerVLA should compare with TOKEN, PARADrive and DiMA where they performed evaluation on long-tail scenarios on nuScenes Dataset. Or Authors should compare with AutoVLA on NAV-Hard test dataset to see how SteerVLA performs on critical autonomous driving cases.\n- The performance improvements of SteerVLA is minor, SteerVLA achieves a Driving score of 81.99 on Bench2Drive dataset, but SimLingo-Baseline achieves 85.94 driving score using 0.5 Billion model.\n- SteerVLA  claims  proposed data generation pipeline that can generate refined language labels, their experiments to show this claim are inadequate. The authors only one visualization example.\n\n- TOKEN:Tokenize the World into Object-level Knowledge to Address Long-tail Events in Autonomous Driving, CoRL 2024.\n- PARADrive, PARA-Drive: Parallelized Architecture for Real-time Autonomous Driving, CVPR 2024.\n- DiMA, Distilling Multi-modal Large Language Models for Autonomous Driving, CVPR 2025.\n- AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning, CVPR 2025."}, "questions": {"value": "- How robust is the auto-labeling pipeline of SteerVLA to domain shifts (e.g., different countries, weather, or sensor setups)?\n- What are the failure cases observed during evaluation, and how severe are they in terms of safety?\n- How does SteerVLA handle contradictory or ambiguous meta-actions in real-time traffic?\n- Can the hierarchical approach introduce latency issues in high-speed scenarios? Any benchmarks on inference time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VTvGn8AbXx", "forum": "fS6UPyXF4A", "replyto": "fS6UPyXF4A", "signatures": ["ICLR.cc/2026/Conference/Submission2762/Reviewer_dqkw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2762/Reviewer_dqkw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762034122978, "cdate": 1762034122978, "tmdate": 1762916363612, "mdate": 1762916363612, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}