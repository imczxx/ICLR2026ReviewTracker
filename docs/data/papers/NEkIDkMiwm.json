{"id": "NEkIDkMiwm", "number": 20864, "cdate": 1758311118964, "mdate": 1759896954626, "content": {"title": "URSA: The Universal Research and Scientific Agent", "abstract": "Large language models (LLMs) have moved far beyond their initial form as simple chatbots, now carrying out complex reasoning, planning, writing, coding, and research tasks. These skills overlap significantly with those that human scientists use day-to-day to solve complex problems that drive the cutting edge of research. Using LLMs in \"agentic\" AI has the potential to revolutionize modern science and remove bottlenecks to progress. In this work, we present URSA, a scientific agent ecosystem for accelerating research tasks. URSA consists of a set of modular agents and tools, including coupling to advanced physics simulation codes, that can be combined to address scientific problems of varied complexity and impact. This work highlights the architecture of URSA, as well as examples that highlight the potential of the system.", "tldr": "", "keywords": ["Agentic AI; Large Language Model; Simulation-based Optimal Design"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e7d81928c891a87ba648a5a07e1e6f21e07fe51c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes URSA (Universal Research and Scientific Agent), a modular ecosystem of scientific agents designed to accelerate research tasks by leveraging large language models (LLMs) for reasoning, planning, and tool invocation. URSA integrates physical simulation code with autonomous research workflows to solve scientific problems of varying complexity and remove research bottlenecks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. URSA proposes a modular design with specialized agents for planning, execution, research, hypothesis generation, ArXiv processing, etc. The modules can be flexibly composed with feedback loops to handle research tasks of varying complexity.\n\n2. Integrates high-fidelity physical simulation tools (e.g., the Helios radiation-hydrodynamics code) and supports automated design optimization (e.g., inertial confinement fusion experiment design), reducing the number of simulations required by traditional methods.\n\n3. Experiments show URSA outperforms Bayesian optimization in ICF design optimization, converging faster (10 simulations vs. BO’s 47–65).\n\n4. Execution agents include built-in safety checks (e.g., command risk assessment) and logging to prevent malicious code execution. Emphasizes running in sandboxed environments and follows the principle of least privilege to reduce risks of data leaks or system damage."}, "weaknesses": {"value": "1. Execution agents sometimes invent experimental steps and results (e.g., claiming to have completed low-temperature mechanical tests) that require human intervention to correct. In some cases they generate fake optimization curves (Fig. 10), so external verification is needed to ensure result authenticity.\n\n2. Current experiments focus on physical simulation and optimization tasks; applicability to disciplines requiring wet-lab experiments (biology, chemistry) has not been validated. Handling of multimodal data (e.g., experimental images, unstructured text) is also not fully demonstrated.\n\n3. Experiments use OpenAI models (e.g., o3-mini, o1) and do not evaluate compatibility with other open-source or domain-finetuned models."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xzPhZQhggy", "forum": "NEkIDkMiwm", "replyto": "NEkIDkMiwm", "signatures": ["ICLR.cc/2026/Conference/Submission20864/Reviewer_z6hj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20864/Reviewer_z6hj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760530864381, "cdate": 1760530864381, "tmdate": 1762999998328, "mdate": 1762999998328, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents URSA, a modular agent ecosystem designed to accelerate scientific research tasks by integrating large language models (LLMs) with advanced tools like physics simulators. The work addresses a critical gap in agentic AI—extending its utility from internet-scale tasks (e.g., web search, debugging) to high-impact scientific domains (e.g., inertial confinement fusion, materials modeling). The core strengths lie in its composable agent architecture, integration with domain-specific simulators (e.g., Helios), and empirical validation against standard methods (e.g., Bayesian optimization). However, the paper also has notable limitations in generalizability, failure mode mitigation, and methodological transparency that need addressing. Overall, the contribution is relevant to the ICLR community, as it advances AI-driven scientific discovery, but requires revisions to strengthen rigor and clarity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Sufficient statement of limitations: The paper’s Appendix B (on \"Interesting Failures\") is a standout strength. Unlike many agentic AI papers that downplay flaws, the authors explicitly document critical failure modes: hallucinated experimental results (e.g., URSA claiming to synthesize alloys despite no physical capability), fake data generation (e.g., inventing Helios optimization curves when the simulator wrapper failed), and environment manipulation (e.g., rolling back numpy versions). This honesty not only builds trust but also provides valuable guidance for future work (e.g., the need for sandboxing, as recommended in Section B.3).\n\n\nThe writing is easy to understand."}, "weaknesses": {"value": "(1) While this paper evaluate their methods on the physics, their quality has not been verified on other disciplines, such as chemistry and biology, with different tools (e.g., molecular dynamics simulators, genome analyzers) or data types (e.g., experimental lab data vs. astrophysical observations). Add a brief case study (even a proof-of-concept) in a non-physics domain to demonstrate generality. For example, could URSA use a tool like RDKit (for cheminformatics) to optimize molecular structures for drug discovery? Alternatively, discuss how the agent architecture would need to be modified for such tasks (e.g., adjusting the Research Agent to parse lab notebooks vs. arXiv papers). This would strengthen the claim that URSA is a \"universal\" scientific agent.\n\n\n(2) The author should clarify the following details. LLM-specific parameters: The authors mention using OpenAI’s o3-mini, o1, and o4-mini, but not the temperature, max tokens, or prompt engineering details (e.g., how the \"creativity prompt\" in Section 4.3 was phrased).\nSimulation setup: For the Helios ICF experiments, the paper does not specify key parameters (e.g., laser pulse duration, target material properties) or how URSA’s Hypothesizer agent prioritized design variables (e.g., why it focused on aluminum ablator thickness vs. DT fuel density).\nBaseline comparisons: For the BO vs. URSA comparison (Section 4.3), the authors mention \"Latin hypercube random design\" for BO initialization but do not specify the BO library used (e.g., GPyOpt, Optuna) or the kernel choice for the Gaussian process—details that could affect the baseline performance. \n\n(3) The design of this paper is somewhat similar toolUniverse (https://arxiv.org/abs/2509.23426). The authors are suggested to clarify their superior to it."}, "questions": {"value": "In Section 4.3, URSA leverages the text of Montgomery et al. (2018) to inform ICF design. How does URSA handle conflicting literature (e.g., two papers proposing contradictory models for ICF implosion)? Does the Hypothesizer Agent prioritize recent work, high-citation papers, or peer-reviewed studies?\nThe Execution Agent’s safety check (Code Block 2, lines 8–15) uses an LLM to validate commands. Have the authors tested how often this check fails to detect unsafe commands (e.g., rm -rf / or overwriting critical data)? What false positive/negative rates were observed?\nFor the ArXiv Agent (Section 3.5), the paper uses GPT-4 Vision to summarize figures. How does this compare to open-source vision-language models (e.g., LLaVA, Flamingo) in terms of accuracy (e.g., correctly interpreting scientific plots) and cost? Given that many scientific labs have restrictions on using closed-source models, is URSA compatible with open alternatives?\nIn Appendix B.1, URSA persists in hallucinating experimental steps even after repeated prompting. Have the authors tried fine-tuning the LLMs on a dataset of \"invalid tasks\" (e.g., \"do not propose physical synthesis\") to reduce such hallucinations? If so, what were the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7jHuWl1oOt", "forum": "NEkIDkMiwm", "replyto": "NEkIDkMiwm", "signatures": ["ICLR.cc/2026/Conference/Submission20864/Reviewer_jDM9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20864/Reviewer_jDM9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636334112, "cdate": 1761636334112, "tmdate": 1762937186613, "mdate": 1762937186613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a universal research and scientific agent system, URSA, designed to integrate large-scale language model–based planning, autonomous research, and LLM-driven design optimization. It provides an empirical study of AI systems that actively conduct scientific research."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The design logic of the composable agents for varying complexity is clear and well-structured, encompassing multiple types of agents.\n- This paper employs several concrete and scientifically meaningful tasks to demonstrate that the proposed method may possess the potential for scientific discovery.\n- The motivation of this paper is very clear and carries strong practical significance."}, "weaknesses": {"value": "- This paper lacks methodological comparisons.\n- The paper may lack evaluations on more general scientific benchmarks.\n- The system’s effectiveness may depend on the capabilities of the underlying LLM."}, "questions": {"value": "- How are the composable agents for varying complexity implemented, and what types of agents are involved in the composition?\n- The author should include experiments with different LLM backbones to evaluate the system’s efficiency.\n- For the execution agent, if the code still fails to run after reaching the maximum number of dialogue turns, how should this issue be addressed?\n- For the research agent and hypothesizer agent, the author should provide a clearer description of the differences between them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nlXumEgzi6", "forum": "NEkIDkMiwm", "replyto": "NEkIDkMiwm", "signatures": ["ICLR.cc/2026/Conference/Submission20864/Reviewer_bo9Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20864/Reviewer_bo9Z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761749437536, "cdate": 1761749437536, "tmdate": 1762937173926, "mdate": 1762937173926, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper presents URSA (Universal Research and Scientific Agent), an LLM-based agentic framework designed to accelerate scientific discovery through modular, composable agents.\n- The system integrates multiple specialized agents, each handling specific sub-tasks in the research workflow such as hypothesis generation, literature review, code execution, and experiment planning.\n- URSA’s performance is demonstrated on several examples with increasing complexity, including six-hump camel function, surrogate model building and benchmarking, and ICF optimization with Helios."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper provides a clear, detailed description of each URSA component, including pseudocode and workflow diagrams, which enhances its reproducibility.\n- URSA’s coupling of LLM agents with real scientific simulators demonstrates an important step toward practical AI-assisted science.\n- The paper provides an analysis of failure modes in the appendix."}, "weaknesses": {"value": "- The agentic architecture and workflow pattern (planning, execution, research, reflection, summarization) are largely consistent with prior works. URSA primarily re-implements these ideas with scientific examples rather than introducing a fundamentally new architectural contribution. As such, the technical novelty for the research community is limited.\n- The paper claims that URSA is a universal framework for research acceleration, but the experiments focus mainly on internal or specialized physics examples (e.g., ICF simulation). There are no quantitative comparisons on mainstream benchmarks that could substantiate generality.\n- The workflow composition appears to be largely human-defined. URSA acts more as a toolbox of agents than as a self-organizing system capable of autonomously selecting and orchestrating agents for arbitrary scientific tasks."}, "questions": {"value": "- Are the physics and ICF tasks used in the experiments considered frontier research challenges within their respective domains, or are they simplified demonstration cases? Clarifying this would help readers evaluate the real scientific impact of URSA.\n- Does URSA include any self-organizing or meta-planning mechanisms that allow agents to autonomously select or compose workflows for new problems, or is human intervention always required for agent orchestration?\n- A direct comparison with existing frameworks on standardized tasks would make the claimed universality more convincing.\n- An ablation study showing how performance degrades when certain agents are removed would strengthen the claim that URSA’s architecture is particularly suited for scientific discovery."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "P0hfAyGFQq", "forum": "NEkIDkMiwm", "replyto": "NEkIDkMiwm", "signatures": ["ICLR.cc/2026/Conference/Submission20864/Reviewer_GvUm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20864/Reviewer_GvUm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20864/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762051518209, "cdate": 1762051518209, "tmdate": 1762937098681, "mdate": 1762937098681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}