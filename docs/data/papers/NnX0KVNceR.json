{"id": "NnX0KVNceR", "number": 17822, "cdate": 1758280967235, "mdate": 1759897151851, "content": {"title": "Generalized Pref-SHAP to Explain Preference Functions", "abstract": "We address the problem of feature attribution for skew-symmetric preference functions in dueling data settings, using the cooperative game-theoretic concept of \\textit{Shapley values}. Building on Pref-SHAP~\\cite{hu2022explaining}, we propose \\textit{Generalized Pref-SHAP}, a framework that extends its applicability to a broader class of preference functions. Our method leverages a simple neural network to model arbitrary feature mappings while exploiting the canonical block structure inherent to skew-symmetric functions, enabling more meaningful explanations. Additionally, we explore foundational questions about Pref-SHAP, including its relationship with the block decomposition structure of generalized preference functions. We perform experiments on a range of synthetic datasets to demonstrate the effectiveness and efficiency of our approach.", "tldr": "A framework to explain generalized preference functions", "keywords": ["skew-symmetric", "preference"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/43b2bd0c3e7a132a4f8c786277bc59ae75c2c6fe.pdf", "supplementary_material": "/attachment/1e817d0e449149ad9763962c8257b9199179acb8.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Generalized Pref-SHAP (GPref-SHAP), an extension of the Pref-SHAP framework designed to explain skew-symmetric preference function. The authors identify a key limitation in the original Pref-SHAP: it fails to respect the inherent \"block structure\" of certain preference models when input features are statistically correlated. This can cause feature attributions to \"leak\" across conceptually separate feature blocks, potentially producing misleading explanations.\n\nTo address this, GPref-SHAP proposes an explanation-aware modeling approach. The method uses a neural network to explicitly learn a feature mapping, $\\phi$, from the original inputs. This learned representation is then fed into a fixed architecture that computes the preference score as a sum of decomposed, block-wise interactions\n\nBy enforcing this functional decomposition, the model is claimed to become interpretable by design, ensuring the resulting explanations align with its structure. Experiments on synthetic data claim that GPref-SHAP recovers ground-truth feature importance more accurately than the original Pref-SHAP and performs better on sanity checks involving inactive features."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper makes a good point on the independence assumption Pref-SHAP makes and how certain pathologies arise during computation of Shapley values when this is violated. The arguments for this is somewhat well presented."}, "weaknesses": {"value": "1. The proposed method immediately proposes neural network and the additional integrated gradient approach to get interpretable features from the block format. What are the computational overhead for this, Shapley values are generally expensive to compute so adding complexity and overhead must be done with great care. It would have been more convincing to introduce an example where Pref-SHAP explicitly breaks due to this correlation, and to quantify at what degree of multicollinearity Pref-SHAP breaks. \n2. In one of the experiments the proposed method seems to hamper predictive performance, how does improved explanations trade-off against predictive performance - i.e. when is it better to have slightly wrong explanations for a model that predicts very well or accurate explanations for a model that predicts wrongly. \n3. The exposition of the paper needs work, the plots are not very well formatted and unnecessarily big. \n4. Some more real-life experiments would strengthen the paper. \n5. In the Pokemon experiment, Pref-SHAP also finds speed to be the most important feature similar to GPref-SHAP. Is there case here where GPref-SHAP finds insights Pref-SHAP is unable to derive?"}, "questions": {"value": "1. When exactly does Pref-SHAP break? Can you provide a minimal empirical example that demonstrates using data exhibiting multicollinearity? \n2. Do we really need a neural network to satisfy the block requirement? Can't we just do 2-SLS or remove highly correlated features and see if things improve?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VC8YhubDhL", "forum": "NnX0KVNceR", "replyto": "NnX0KVNceR", "signatures": ["ICLR.cc/2026/Conference/Submission17822/Reviewer_8dmy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17822/Reviewer_8dmy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760740536104, "cdate": 1760740536104, "tmdate": 1762927663554, "mdate": 1762927663554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates an extension to PrefSHAP by considering a more general class of preference functions. The authors provide some results on the (extended) value function in this setting (Proposition 1), which uses feature independence or a \"block structure\". The authors then provide an example, and study theoretical properties in a setting with two features. Moreover, an algorithm is presented, and some empirical results are presented."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- Investigating more general forms of preference learning with Shapley values could possibly be interesting. However, an efficient computation of such Shapley values would be desirable by exploiting certain properties of this novel value function. I am doubtful, if this extensions will yield such insights."}, "weaknesses": {"value": "In my view, this paper, in its current form, should not have been submitted at any conference, and is far from most scientific standards: There are obvious formatting issues, e.g. typos, citations, exceeded margins, no clear structure, figures and descriptions are chaotic. Moreover, the contribution is very unclear. Block structures are not introduced well, the purpose of the algorithm is not clear at all. I did not understand any central part of the contribution, e.g. Section 3 discusses the Block Pattern, what should that be? I did not understand the example and its purpose. The properties examined in Section 4 with two features are very artificial, and I still did not understand the insight. The experiments use a single synthetic dataset with 4 (!) features. There might be some interesting insights in this method, but as it is being presented now, it is not understandable, and clearly not ready for being accepted at this conference."}, "questions": {"value": "I do not think my questions can be sufficiently addressed by the authors in the rebuttal, but some were stated under \"weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K9v5CLaKMo", "forum": "NnX0KVNceR", "replyto": "NnX0KVNceR", "signatures": ["ICLR.cc/2026/Conference/Submission17822/Reviewer_B9Cf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17822/Reviewer_B9Cf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760124855, "cdate": 1761760124855, "tmdate": 1762927662550, "mdate": 1762927662550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Generalized Pref‑SHAP, an extension of Pref‑SHAP for explaining pairwise preference functions with nonlinear feature mappings. It learns structured feature representations via neural networks while preserving the canonical skew‑symmetric block structure. The method improves interpretability, decomposability, and consistency across correlated features in preference learning models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors successfully preserve block‑wise interpretability in skew‑symmetric preference models.\n- This paper demonstrates that the framework supports nonlinear and learned feature mappings, making it more generalizable.\n- The proposed method achieves higher attribution accuracy and robustness compared with existing approaches."}, "weaknesses": {"value": "- The proposed method requires higher computational cost due to neural network training and multiple KRR models.\n- This paper relies on independence assumptions for certain theoretical guarantees, limiting universality.\n- The authors provide limited real‑world evaluation, focusing primarily on synthetic datasets."}, "questions": {"value": "- The proposed method requires higher computational cost due to neural network training and multiple KRR models.\n- This paper relies on independence assumptions for certain theoretical guarantees, limiting universality.\n- The authors provide limited real‑world evaluation, focusing primarily on synthetic datasets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CWivcEIcmh", "forum": "NnX0KVNceR", "replyto": "NnX0KVNceR", "signatures": ["ICLR.cc/2026/Conference/Submission17822/Reviewer_M585"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17822/Reviewer_M585"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894385655, "cdate": 1761894385655, "tmdate": 1762927661871, "mdate": 1762927661871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes extending Pref-SHAP (Hu et al., NeurIPS 2022), a method for explaining preference learning using Shapley values. Theoretical analysis gives a single proposition on the block decomposition of conditional Pref-SHAP under feature independence. Experiments with two synthetic tabular datasets compare the proposed Generalized Pref-SHAP to Pref-SHAP."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Unfortunately, it is challenging to find any."}, "weaknesses": {"value": "This work resembles more a preliminary workshop contribution rather than a complete conference publication:\n1. The motivation and significance of this research are weak. There are no impactful applications for the method. This is evident from the fact that experiments are conducted primarily with synthetic data. A single \"real-world\" example with a \"Pokémon\" dataset is shown in Appendix E, Figure 6. Furthermore, the paper does not reference any emerging applications.\n2. Discussion of related literature is limited to only 13 references. Why is this research important? The introduction provides no context for studying such a method.\n3. Presentation is subpar (see feedback below)."}, "questions": {"value": "1. Why is Appendix G empty?\n2. Can this research be motivated by reinforcement learning from human feedback and preference learning for LLMs?\n\nFeedback: \n- All figures can be much smaller, saving space for actual research content. You should not write \"Section 3.1: This discussion and the related literature are included in the appendix due to space constraint.\"\n- The critical example with \"real-world\" data should be included in the main text.\n- Figure 1 should be a Table. It is also too large in width.\n- Equation (11) shouldn't exceed the margin.\n- Why are citations written without parentheses like \"In the Pref-SHAP framework Hu et al. (2022),\" instead of \"In the Pref-SHAP framework (Hu et al., 2022),\"?\n- L315: typo in \"kernelChau et al. (2022a)\"\n- Figure 6 should list feature names next to bars, not in the caption.\n\nIn general, you can mimic the Pref-SHAP (Hu et al., NeurIPS 2022) paper to directly improve the presentation of this submission."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iHesJLKDvf", "forum": "NnX0KVNceR", "replyto": "NnX0KVNceR", "signatures": ["ICLR.cc/2026/Conference/Submission17822/Reviewer_mbpX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17822/Reviewer_mbpX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985606380, "cdate": 1761985606380, "tmdate": 1762927660990, "mdate": 1762927660990, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}