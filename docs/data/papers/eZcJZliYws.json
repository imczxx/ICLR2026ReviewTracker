{"id": "eZcJZliYws", "number": 22174, "cdate": 1758327189033, "mdate": 1759896882302, "content": {"title": "CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings", "abstract": "We propose CLoVE (Clustering of Loss Vector Embeddings), a novel algorithm for Clustered Federated Learning (CFL). In CFL, clients are naturally grouped into clusters based on their data distribution. However, identifying these clusters is challenging, as client assignments are unknown. CLoVE utilizes client embeddings derived from model losses on client data, and leverages the insight that clients in the same cluster share similar loss values, while those in different clusters exhibit distinct loss patterns. Based on these embeddings, CLoVE is able to iteratively identify and separate clients from different clusters and optimize cluster-specific models through federated aggregation. Key advantages of CLoVE over existing CFL algorithms are (1) its simplicity, (2) its applicability to both supervised and unsupervised settings, and (3) the fact that it eliminates the need for near-optimal model initialization, which makes it more robust and better suited for real-world applications. We establish theoretical convergence bounds, showing that CLoVE can recover clusters accurately with high probability in a single round and converges exponentially fast to optimal models in a linear setting. Our comprehensive experiments comparing with a variety of both CFL and generic Personalized Federated Learning (PFL) algorithms on different types of datasets and an extensive array of non-IID settings demonstrate that \\clove achieves highly accurate cluster recovery in just a few rounds of training, along with state-of-the-art model accuracy, across a variety of both supervised and unsupervised PFL tasks.", "tldr": "A novel algorithm for Clustered Federated Learning that is efficient and robust to initialization.", "keywords": ["federated learning", "personalized federated learning", "clustering", "embeddings"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2544b2e42fd71ce2d8d7d251775e0bb24bd52424.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a clustered FL algorithm that groups clients in clusters based on the similarities of the local loss functions, instead of working directly on clients' models, using k-means on the loss embeddings and then assigning the models with The authors motivate their result by providing a theoretical analysis conducted on a simple linear regression scenario. The algorithm performance is assessed on classical datasets (mnist variants, cifar10) and extend to text datasets and compared with relevant clustered and personalized FL baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The experimental evaluation compares their method with relevant CFL baselines, as well as with PFL algorithms. It is appreciable the theoretical comparison with IFCA in Appendix A3. Achieving early cluster stability is also an interesting property that permits to efficiently control the"}, "weaknesses": {"value": "1) Most of the theoretical claims, while complete, are limited to the linear regression case. This works well as a proof of concept, but further effort should be directed toward more complex and general cases. Providing a more general framework would definitely broaden the impact of the analysis. Furthermore, the mathematical soundness, clarity, and exposition could be improved.\n\n2) The authors build upon an interesting line of work paved by Cho et al. (2022), focusing on the loss function to evaluate clusters. The premises and methodology are reminiscent of FedGWC (Licciardi et al., 2025). I suggest that the authors compare their method with this CFL approach, which is based on the transformation of loss vector embeddings and claims that clients can be grouped according to similarities in their learning patterns.\n\n3) In FL protocols, it is usually preferable not to share private information with other clients (though some works are less stringent about this). My concern is that the algorithm lacks mechanisms to avoid degenerate clusters (i.e., a cluster with a single client). If this occurs, then during the broadcasting phase, every other client would gain access to the single client's model—and consequently, its data distribution—when cross-evaluating the loss functions. Furthermore, cross-evaluating models could be intractable in large-scale scenarios or in settings with full client participation.\n\n4) The description of how the number of clusters, K(t+1), is determined is somewhat vague in both the pseudocode and the main text. Additionally, how does the min-cost bipartite matching step impact the efficiency of each communication round during the training phase?\n\n5) To make the experimental framework more comparable with the standard FL literature, data heterogeneity should be controlled using a Dirichlet distribution. While the authors mention this in the appendix, clarifying this detail in the main experimental section would help the FL community better interpret the results.\n\n6) The method achieves strong results in clustering quality, as measured by the ARI. However, its test accuracy generally underperforms compared to other baselines. Do the authors have any insights into this discrepancy and its potential causes?\n\n7) I am a little doubtful on the algorithm's behaviour when the number of clusters is larger than the number of training clients per round -- something that could easily occur in a realistic framework. Does cluster optimality yield also in that scenario?\n\n-------\n- Cho, Yae Jee, Jianyu Wang, and Gauri Joshi. \"Towards understanding biased client selection in federated learning.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2022.\n- Licciardi, A., Leo, D., Fanì, E., Caputo, B., & Ciccone, M. Interaction-Aware Gaussian Weighting for Clustered Federated Learning. In Forty-second International Conference on Machine Learning."}, "questions": {"value": "Please, see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fexVH1Ivng", "forum": "eZcJZliYws", "replyto": "eZcJZliYws", "signatures": ["ICLR.cc/2026/Conference/Submission22174/Reviewer_3G9C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22174/Reviewer_3G9C"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22174/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760917538849, "cdate": 1760917538849, "tmdate": 1762942101194, "mdate": 1762942101194, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CLoVE (Clustering of Loss Vector Embeddings), an algorithm for Clustered Federated Learning (CFL). The authors propose using loss vector embeddings as a basis for clustering clients, thereby addressing limitations in prior CFL approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Although similar to the prior method Iterative Federated Clustering Algorithm (IFCA), which uses the loss to build cluster identities, CLoVE simultaneously estimate the underlying clusters and constructs models per cluster. It does not require prescribe number of clusters and not sensitive to the model initialization, which consequently decides the cluster initialization.\n\n* The manuscript is clearly written, methodologically solid, and well positioned within the current literature."}, "weaknesses": {"value": "* The experiments choose some relative simple datasets to validate its effectiveness. For example, for minist, cifar-10, and FMNIST, several baseline models already achieve test 100\\% accuracy. It's unclear how the methods perform on relative challenging datasets like Tiny-ImageNet.\n\n* My concerns are on the communication costs and storage costs. Before the clustering stabilized, in each communication round, the server needs to broadcast $K^{(t)}$ models and the clients need to store them. Compared to the FedAvg, the communication costs may be averaged out if the stabilization happens during the early stages and the algorithm convergence faster than FedAvg. Theorem 4.1 may justify for the simple scenario, yet CLoVE's actually performance in recovering the clusters is unclear. Maybe showing the training dynamic can help to justify. Nonetheless, the peak memory usage can still be large. Even though IFCA method, also suffers from this. I think this should be clearly discussed."}, "questions": {"value": "1. In Algorithm 1, what are the conditions to determine if the clustering is stabilized?\n\n2. Is CLoVE scalable to large number of clients? The main paper mentioned that \"We vary the number of clients between 20 and 1000.\" However, in appendix C, the number of clients ranging from 12 to 50. In the appendix D, it indeed varies the number of clients from 100 to 1000, but it only reports the test loss on MNIST. This is not convincing.\n\n**Minor Comments**\n1. Failed to disclose the usage of large language model as required."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YQSQnJh5Dn", "forum": "eZcJZliYws", "replyto": "eZcJZliYws", "signatures": ["ICLR.cc/2026/Conference/Submission22174/Reviewer_8Ay6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22174/Reviewer_8Ay6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22174/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722081147, "cdate": 1761722081147, "tmdate": 1762942100949, "mdate": 1762942100949, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "CLoVE introduces a paradigm for personalized federated learning through clustering of loss vector embeddings. By analyzing patterns of client losses across different models, the method achieves accurate client partitioning and collaborative optimization of cluster-specific models. Extensive experiments demonstrate that CLoVE rapidly converges in both supervised and unsupervised tasks, outperforming existing methods in clustering accuracy and model performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Proposes an approach using loss vector embeddings for client clustering, eliminating need for careful initialization.\n2. Provides rigorous convergence analysis for mixed linear regression, to Theoretical guarantees for cluster recovery\n3. Works in both supervised and unsupervised settings, with Simplicity and wide applicability"}, "weaknesses": {"value": "1. Analysis restricted to convex setting (linear regression), lacking guarantees for non-convex settings  commonly used in practice.\nMissing comparisons with recent (2024-2025) state-of-the-art methods addressing similar challenges .\n2. For the key challenge of sparse client participation in FL, the paper lacks corresponding theoretical analysis and systematic experimental validation.  For example, will the different setting of initicial K cluster number result in different results.\n3. Insufficient experimental validation of dynamic cluster number selection method and sensitivity to initial cluster count. The impact of different initial cluster numbers on the final performance has not been systematically studied through ablation experiments. This fails to assure that the algorithm is insensitive to the initial choice of K, which is a significant concern in practical applications."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Qv63xujfDr", "forum": "eZcJZliYws", "replyto": "eZcJZliYws", "signatures": ["ICLR.cc/2026/Conference/Submission22174/Reviewer_MEzt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22174/Reviewer_MEzt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22174/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887918094, "cdate": 1761887918094, "tmdate": 1762942100692, "mdate": 1762942100692, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a clustered PFL method that embeds each client by its vector of losses on multiple candidate models, then clusters these embeddings to assign clients and train per-cluster models. By iterating between “compute loss vectors → cluster clients → federated update per cluster,” it avoids IFCA-style sensitivity to initialization and does not require inter-cluster separation assumptions. The paper proves single-shot cluster recovery and exponential convergence in a linear regression setting and reports fast, accurate clustering across supervised and unsupervised non-IID benchmarks. Empirically, CLoVE converges in few rounds and tolerates partial participation/stragglers."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Using loss-vector embeddings sidesteps careful warm-starts and delivers quick, stable clustering in practice."}, "weaknesses": {"value": "1. guarantees are shown only for linear models; applicability to nonconvex deep networks remains unproven.\n\n2. clients must evaluate multiple models each round to form loss vectors, which increases local compute/communication and may leak information about client data through loss profiles.\n\n3. dynamic clustering with sparse participation, label noise, or malicious clients may oscillate or be exploitable, and robustness is not theoretically characterized."}, "questions": {"value": "1. What formal guarantees (if any) extend to nonconvex settings—e.g., bounds under smoothness/PL conditions—or at least empirical ablations isolating architecture depth/width?\n\n2. How does per-round cost scale with the number of clusters KKK, and can you reduce evaluations (e.g., sub-sampling models, proxy losses, or distillation) while preserving clustering accuracy?\n\n3. What privacy defenses (secure aggregation, DP on losses, or randomized response) are compatible with CLoVE, and how do they trade off against clustering fidelity and convergence under client drift or adversarial behavior?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "u9D01I7jAt", "forum": "eZcJZliYws", "replyto": "eZcJZliYws", "signatures": ["ICLR.cc/2026/Conference/Submission22174/Reviewer_ymcK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22174/Reviewer_ymcK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22174/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972110770, "cdate": 1761972110770, "tmdate": 1762942100492, "mdate": 1762942100492, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}