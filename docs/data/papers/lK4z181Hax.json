{"id": "lK4z181Hax", "number": 18609, "cdate": 1758289473153, "mdate": 1763732299778, "content": {"title": "Encoding Spatio-temporal Locations with Orthogonal Function Representations", "abstract": "Complex spatio-temporal dependencies govern many real-world processes -- from climate dynamics to disease spread.\nModeling these processes continuously using purpose-built neural network architectures, so-called location encoders, presents an emerging paradigm in analyzing and interpolating geographic data. In this work, we expand existing spatial location encoders and introduce a new time-informed architecture: the space-time encoder. \nOur method takes in geographic (latitude, longitude) and temporal information simultaneously and learns smooth, continuous functions in space and time. The inputs are first transformed using positional encoding functions and then fed into neural networks that allow the learning of complex functions.\nWe consider, via detailed experimental analysis, (1) how to integrate space and time encodings, (2) the effect of different choices of encoding functions for the time component and (3) frameworks for encouraging orthogonality of feature representations to improve representational power. We highlight the effectiveness and flexibility of the space-time encoder on a range of tasks representing different spatio-temporal dynamics, from climate prediction to animal species classification.", "tldr": "We investigate different ways to encode time for spatio-temporal interpolation tasks as well as a novel regularization for orthogonal function representations.", "keywords": ["climate and weather", "surrogate modelling", "geographic time series", "location encodings", "deep learning regularization"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/fe31480ad15a41fe61e2f2bd718c660a73493f30.pdf", "supplementary_material": "/attachment/56b934ee532555b420b6c4a8b36df1bdd43e18b0.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces the Space-Time Encoder, which maps spatio-temporal coordinates to high-dimensional features using pluggable orthogonal time encodings (Fourier/Legendre) and applies an orthogonal regularizer only to the final layer to eliminate redundancy. On climate regression and species classification tasks, this approach significantly improves accuracy and smoothness at minimal computational cost, demonstrating for the first time the critical role of orthogonal features in sparse spatio-temporal modeling."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The Space-Time Encoder presented in this work offers four key advantages: (1) its modular orthogonal time-encoding blocks—Fourier or Legendre—seamlessly capture periodic, trending or mixed temporal dynamics and can be plugged into any geospatial pipeline; (2) a lightweight orthogonal regularizer applied only to the final layer eliminates feature redundancy at O(NK²) cost, yielding large gains in accuracy and smoothness; (3) the same architecture consistently outperforms strong geo-prior baselines on both dense climate-field regression and fine-grained species-classification tasks, demonstrating broad generalizability; and (4) predicted monthly occurrence maps align tightly with official breeding/wintering ranges, furnishing an interpretable, physics-consistent visualization that validates the learned spatio-temporal laws—together establishing a new paradigm that balances performance, efficiency and interpretability for spatial-temporal representation learning."}, "weaknesses": {"value": "1. The novelty of this paper is far from the standard of ICLR, the framework in Figure2 is overly simple, it is suggested that the author make the work more complete before submission.\n\n2. The experiments are insufficient, and the workload is inadequate.\nConduct performance comparison with only one baseline models is not persuasive\n\n3. The number of downstream tasks is also not sufficient, existing works like [1,2] at least conduct experiments on 4+ downstream tasks.\n\n4. The ablation studies is not sufficient. The combination of spatial feature and time feature in Figure 2 can have multiple choice for feature fusion such as addition, concatenation, attentional fusion and so on. Why is the regularizer only applied on the final layer activations, what about applying it to the last few layers?\n\n---\n[1] Klemmer, Konstantin, et al. \"Satclip: Global, general-purpose location embeddings with satellite imagery.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39. No. 4. 2025.\n\n[2] Hao, Xixuan, et al. \"Nature makes no leaps: Building continuous location embeddings with satellite imagery from the web.\" Proceedings of the ACM on Web Conference 2025. 2025."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JWPNrIEyqr", "forum": "lK4z181Hax", "replyto": "lK4z181Hax", "signatures": ["ICLR.cc/2026/Conference/Submission18609/Reviewer_RTvp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18609/Reviewer_RTvp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761442527419, "cdate": 1761442527419, "tmdate": 1762928324986, "mdate": 1762928324986, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We thank the reviewers for their time and their valuable suggestions. After considering the reviews we decided to withdraw our manuscript."}}, "id": "8wmewrvKrm", "forum": "lK4z181Hax", "replyto": "lK4z181Hax", "signatures": ["ICLR.cc/2026/Conference/Submission18609/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18609/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763732299101, "cdate": 1763732299101, "tmdate": 1763732299101, "mdate": 1763732299101, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a space-time encoder framework that integrates spatial (latitude, longitude) and temporal encodings to model continuous spatio-temporal processes. Inputs are transformed via positional encoding functions and processed through neural networks to learn smooth functions. The authors explore combinations of space and time encodings, evaluate different temporal encoding functions, and introduce a novel orthonormal regularizer to promote orthogonality in representations. Experiments on datasets like ACE (climate emulation), BirdSnap, and iNaturalist (animal classification) claim improvements over baselines, attributed to the architecture and regularizer."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The work extends spatial location encoders to include time, addressing a gap in handling dynamic geospatial processes like climate or migration patterns.\n\n2. The orthonormal regularizer is a potentially useful addition for enhancing representation quality in positional encodings.\n\n3. Applications to diverse tasks (climate prediction, species classification) demonstrate flexibility."}, "weaknesses": {"value": "1. Theoretical Shortcomings: The methodological contributions lack rigorous theoretical grounding. For instance, the choice of encoding functions (e.g., positional encodings for time) and their combinations are explored empirically but without formal analysis of why certain functions (e.g., sinusoidal vs. others) are superior for temporal components. The orthonormal regularizer, while novel, is motivated superficially by prior work on orthogonality in spatial encoders (e.g., Rußwurm et al., 2024); there's no deeper proof or derivation showing how it uniquely improves expressivity or stability in spatio-temporal settings. Claims about \"encouraging orthogonality to improve representational power\" feel hand-wavy, especially without connections to information theory, spectral analysis, or optimization guarantees. This makes the framework seem more like an empirical tweak than a principled advance.\n\n2. Insufficient Experimental Validation: The experiments are limited in scope and depth, failing to convincingly demonstrate the method's robustness or superiority. Only three datasets are used (ACE, BirdSnap, iNaturalist), which may not capture the full diversity of spatio-temporal dynamics (e.g., no high-resolution remote sensing or urban mobility data). Ablations on encoding choices and regularizer hyperparameters appear preliminary, lacking sensitivity analyses or statistical significance tests. Cross-dataset generalization is mentioned but not quantified (e.g., via domain shift metrics). \n\n3. Novelty and Broader Impact: The space-time encoder builds incrementally on prior location encoders (e.g., Mac Aodha et al., 2019a; Mai et al., 2023), with time integration feeling like a straightforward extension rather than a breakthrough. Related works on temporal encodings (e.g., Mai et al., 2020; Dollinger et al., 2025) are cited but not sufficiently differentiated. The paper overstates impact (e.g., \"emerging paradigm\") without addressing limitations like scalability to global scales or integration with multimodal data (e.g., satellite imagery).\n\n4. Figures and examples (e.g., bird migration) are illustrative but could include more quantitative insights."}, "questions": {"value": "1. What is the theoretical justification for the orthonormal regularizer beyond empirical benefits? Can you provide bounds on representation capacity or optimization convergence?\n\n2. Have you tested on more diverse benchmarks (e.g., ERA5 for climate or mobility traces) or against time series of spatiotemporal foundation models?\n\n3. How does the encoder handle irregular time sampling or extreme domain shifts (e.g., climate change scenarios)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OCD23oGJ9Q", "forum": "lK4z181Hax", "replyto": "lK4z181Hax", "signatures": ["ICLR.cc/2026/Conference/Submission18609/Reviewer_ELun"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18609/Reviewer_ELun"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906113047, "cdate": 1761906113047, "tmdate": 1762928323713, "mdate": 1762928323713, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method to combine temporal embedding with location embedding, aiming at improving spatio-temporal process modeling. However, the contribution is very incremental. Both temporal embedding and location embedding are off-the-shelf from existing work. The main contribution claimed by the authors, i.e. the orthogonal regularization, has only dubious effects on performance (see Table 3). While ablation studies demonstrate that incorporating temporal factors is important in certain geospatial tasks (e.g. iNaturalist species modeling), the proposed method fails to prove its novelty and usefulness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Visual and experimental evidence that temporal factors are useful in many geospatial modelling tasks (e.g. migratory birds).\n\n2. Clear writing and easy to follow."}, "weaknesses": {"value": "1. The motivation of using orthogonal regularization is wrong and unfounded. The only statement the authors made is in Line 68-69: \"Motivated by existing studies on the value of orthogonal space-only location encodings (Rußwurm et al., 2024), our work introduces a novel regularizer that encourages representation orthogonality.\" This is a misunderstanding of orthogonality. In the work of Rußwurm, the orthogonality applies to the dimensions of spherical harmonics representations -- each dimension encodes the information at a given frequency, independent of other frequencies. It is clearly motivated by the need to model multi-scale effects. What does the orthogonality mean in this paper? The spatial and temporal embeddings are mixed up and passed to a neural network, through which each dimension of the resulting embedding combines semantics from various temporal and spatial scales. Why should we assume the orthogonality amongn these dimensions?\n\n2. The performance improvement in Table 3 comes from the introduction of temporal embedding (i.e. extra embedding semantics) rather than orthogonality. The results with ($\\alpha=0.0001$) and without ($\\alpha=0$) orthogonal regularizer are indistinguishable. I agree that some spatial tasks should take temporal factors into consideration, as Figure 4 proves, but the main claimed contribution of orthogonal regularization does not hold based on the experimental results.\n\n3. Experimental results are lacking. There are too few datasets and baseline models evaluated. For example, what if the dataset/task is not time sensitive? Will your embedding framework still work, or it may harm the performance?"}, "questions": {"value": "1. Have you ever tried other combinations of temporal and spatial embeddings? E.g. instead of element-wise multiplication, have you tried addition or concatenation? Do these alternatives work as well in your experiment setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X9PwvHXTTg", "forum": "lK4z181Hax", "replyto": "lK4z181Hax", "signatures": ["ICLR.cc/2026/Conference/Submission18609/Reviewer_xduE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18609/Reviewer_xduE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951705711, "cdate": 1761951705711, "tmdate": 1762928323234, "mdate": 1762928323234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a Space-Time encoder which also considers the Orthogonal Functional Representations. A orthogonal regularization loss is proposed to make the spatial and temporal representation orthogonal. Experiments show that this loss can improve the model performance in regression tasks but the impact on classification tasks are not clear."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The contributions of this paper are very clear.\n2. The proposed orthogonal regularization is very interesting."}, "weaknesses": {"value": "1. As shown in Figure 2, the outputs of the positional time encoder and position space encoder are concatenated and fed into an NN. The results are used for orthogonal regularization loss. Even the original space and time embeddings are orthogonal, after feeding into the NN, all activations become linear combinations of space and time embedding features. What is the meaning to make them orthogonal?\n2. Table 2 does not compare different existing location encoders. If we consider the recent location encoders, can we still see the large improvement by adding the time information and the orthogonal regularization loss? This needs to be tested.\n3. Similarly, Table 3 only considers (Mac Aodha et al 2019) as baselines which is 6 years ago. More recent location encoder methods such as Space2Vec, Sphere2Vec, and Sphereical Harmonics, need to be compared. \n4. The conclusion of this paper is not very clear. Which time encoder is the winner? Experiments do not show a global winner. I am also not sure whether the orthogonal regularization loss is useful. Although it is useful in the regression task, it shows no difference in the classification task. But the authors use the classification task as the motivation examples, which is a bit confusing."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ylCFfTmftC", "forum": "lK4z181Hax", "replyto": "lK4z181Hax", "signatures": ["ICLR.cc/2026/Conference/Submission18609/Reviewer_JmTi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18609/Reviewer_JmTi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965863163, "cdate": 1761965863163, "tmdate": 1762928322833, "mdate": 1762928322833, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}