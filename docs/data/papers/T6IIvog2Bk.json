{"id": "T6IIvog2Bk", "number": 20110, "cdate": 1758302570084, "mdate": 1759897001106, "content": {"title": "LLM Chemistry Estimation for Multi-LLM Recommendation", "abstract": "Multi-LLM collaboration promises accurate, robust, and context-aware solutions, yet existing approaches rely on implicit selection and output assessment without analyzing whether collaborating models truly complement or conflict. We introduce LLM Chemistry – a framework that measures when LLM combinations exhibit synergistic or antagonistic behaviors that shape collective performance beyond individual capabilities. We formalize the notion of chemistry among LLMs, propose algorithms that quantify it by analyzing interaction dependencies, and recommend optimal model ensembles accordingly. Our theoretical analysis shows that chemistry among collaborating LLMs is most evident under heterogeneous model profiles, with its outcome impact shaped by task type, group size, and complexity. Evaluation on classification, summarization, and program repair tasks provides initial evidence for these task-dependent effects, thereby reinforcing our theoretical results. This establishes LLM Chemistry as both a diagnostic factor in multi-LLM systems and a foundation for ensemble recommendation.", "tldr": "We introduce the notion of LLM Chemistry resulting in a framework that measures where model combinations exhibit synergistic or antagonistic behaviors that shape collective performance beyond individual capabilities.", "keywords": ["LLM Chemistry", "Multi-LLM Recommendation", "Multi-LLM Collaboration"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c0810b2144726d0d016332f3c8934851d4ebe084.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work proposes to quantify the \"chemistry\" between LLMs when used in collaboration, and motivate an approach for selecting models for a given task."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ model collaboration is an important research direction\n+ the problem formulation is interesting"}, "weaknesses": {"value": "- How do we estimate the max in equation 2? If the model set S is very large (for example, there are now >2m LMs on huggingface), is there an estimation/sampling step that we could take here?\n\n- On line 187 seems to be that the formulation focuses on \"pairs of LMs\". I'm sure there are ways to extend this formulation beyond pairwise estimation, if the authors could share more.\n\n- So the \"model diversity\" here is only considered as \"diverse performance profiles\". Would other \"diversity\" measurements, such as training data, architecture, or item response theory [1] be possible/better?\n\n- I want to like this paper and it is very interesting, however, I have to say that in many places, very strong/unrealistic assumptions are made to support the theoretical framing. For example, the \"pair of LMs\" thing above. For property 2 on page 4, the output/cost of one LM could certainly affect another's (one model convinced another model of a wrong answer, one larger model generating feedback for a smaller model's answer), and assuming \"no cross-terms\" is perhaps a stretch. For property 3 on page 4, what if the superset Y is X + a low-quality/malicious LM? In this way, the performance under Y could be worse than X, and adding a new LM to it wouldn't guarantee a larger benefit. Perhaps I misunderstood something, or this is not a thing at all. I understand all problem formulations need to make some assumptions to make things smooth.\n\n- One major concern is that the evaluation datasets (line 348) are unconventional for evaluating modern (2024-) language models. Things like QA, instruction following, reasoning, math, knowledge & factuality, safety, etc., come to mind, but they were not very covered here. The datasets are also sort of old/not the most popular ones. Perhaps the authors are not from a traditional NLP/LLM background, and perhaps this is fine.\n\n- All models employed in the experiments (lines 360-364) are general-purpose industry models. Would they really be \"performance diverse\", which is critical in the success by Theorem 1? Something like [2-3] seems to suggest otherwise.\n\n[1] Chen, Jianhao, et al. \"Learning Compact Representations of LLM Abilities via Item Response Theory.\"\n\n[2] Zhang, Lily Hong, et al. \"Cultivating pluralism in algorithmic monoculture: The community alignment dataset.\"\n\n[3] Jiang, Liwei, et al. \"Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond).\""}, "questions": {"value": "please see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gr0Ijkz7hf", "forum": "T6IIvog2Bk", "replyto": "T6IIvog2Bk", "signatures": ["ICLR.cc/2026/Conference/Submission20110/Reviewer_UtP3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20110/Reviewer_UtP3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761449914711, "cdate": 1761449914711, "tmdate": 1762933007774, "mdate": 1762933007774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of forming effective multi-LLM ensembles by shifting the focus from individual model selection to analyzing collaborative interactions. Its central research question is: For a given task, how can we identify which LLMs work best together? Then, they introduce a framework designed to quantify the synergistic or antagonistic interactions between models when they collaborate on a shared task. They propose the ChemE and RECOMMEND algorithms to compute chemistry and recommend optimal ensembles and demonstrate its impact on performance on 3 distinct tasks."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1)  Research goal and objectives are clear since the intro with a clear research question that is well motivated and sound.\n\n2)  Treating the problem as the combination of models modeling their interactions is crucial, and I agree with the author that it should be the way to go instead of evaluating each individually\n\n3)  Provides a solid theoretical foundation by formally defining chemistry, a cost function, and its key properties (monotonicity, linearity, submodularity), supported by mathematical proofs.\n\n4)  Complements the theory with practical algorithms (ChemE, Recommend) that obtain great results compared to other selection heuristics (e.g., top k)"}, "weaknesses": {"value": "1) As an ensemble selection model, which is conducted for each query (i.e., the best model for answering a particular instance). The authors must evaluate their performance against the ideal selection: The oracle (which is an abstract model that looks at the test set). \n\n2) The paper does not mention the specific prompts used or detail any prompt engineering strategy for the individual LLMs in their ensembles. How did they set each model (open and closed-source) effectively for each task? This point can have a significant impact [4]. The problem is even bigger as no code & data were published for review. This makes it difficult to assess whether the observed chemistry is a true property of the models or an artifact of suboptimal prompting.\n\n3) No source code availability, which is a major negative point, as we can’t assess whether the results are correct. This is a major flaw in reproducibility.\n\n4) The proposed \"chemistry\" metric is presented in isolation without contextualizing it within the rich body of ensemble selection literature. This field has long-established metrics for quantifying model complementarity, such as prediction diversity (e.g., Q-statistics, double-fault), and frameworks for multi-objective optimization that balance accuracy with cost or diversity. The paper fails to demonstrate how \"chemistry\" relates to or improves upon these existing measures, or why a new metric was necessary. This lack of comparative analysis, especially against static (pre-computed) and dynamic (instance-specific) ensemble selection baselines, makes it difficult to assess the true novelty and contribution of the concept. At the end I am not entirely sure whether this should be really considered a new concept or just a rebranding of existing ones from a different literature/ research community.\n\n5) Author mentions they use the Liar dataset, but does not mention which settings were considered and the source of info used. The paper fails to specify fundamental details such as the exact task formulation for each benchmark. For instance, whether the Liar dataset was used for binary or 6-class classification [3] , or what specific prompts and evaluation metrics were employed for summarization and program repair. Without a clear account of these implementation choices, the performance metrics and the resulting \"chemistry\" scores cannot be verified. This significantly impacts the paper soundness\n\n6) Not clear how/why the 3 datasets used falls in the low, medium and high complexity category\n\n7) Datasets used for testing (like Liar) were proposed before these LLMs were created and as such it is impossible to know whether they were part of their training data. This is a problem when doing research and assessing their performance on such standard benchmarks. Authors should comment on this problem [1] and consider techniques such as [2] to assess the contamination. To me the contamination becomes clear when the author mention a model saying exactly : “half-true, mostly-true, and true” (lines 48-52) which are exactly the labels used in the original liar dataset in which each statement is labeled as belonging to one of the following {pants-fire, false, barely- true, half-true, mostly-true, and true}. \n\n8) Lines 34-36: (1) before inference, e.g., LLM routers (Rosenbaum et al., 2018); But the work by Rosenbaum was never based on LLMs. Just a routing. This is misleading.\n\n9) Custom subset of models for each individual query is the defining characteristic of DES methods. The paper's failure to review this area and clearly differentiate its approach from existing DES techniques is a major scholarly oversight. Moreover, The goal of building a subset of models that complement each other's strengths and weaknesses is a long-standing objective in ensemble learning. The paper does not position its \"chemistry\" metric against these existing efforts.\n\n10)\tContinuing with the point above, some works like [5] also propose graph structure for modeling the he relationships between models and data instances and recommend the best ensembles which just adds to the point that this work need a more complete literature review on ensemble learning to proper potition their paper with the existing literature.\n\n11)\tLines 495 to 500 -  the authors mention “By guiding efficient ensemble formation, our framework can help mitigate these costs and support sustainability.” However,if the \"chemistry\" for a specific query Q is calculated based on the cost_Q(X) of different model subsets, this logically requires generating outputs from multiple models (or all models) for that very query Q before the best ensemble can be selected. Thus, even the final ensemble is smaller than the full set, the cost (compute, energy) won’t be lower.\n\n12)\tLastly, A motivation for multi-LLM collaboration is to surpass the capabilities of any single model. However, the evaluation exclusively compares different ensemble formation strategies (which, according to the author’s definitions, can even damage performance if not done properly) against each other. As such, they should consider a single model baseline as well (like the best single one for instance).\n\n**Refs:**\n\n[1] Dong, Yihong, et al. \"Generalization or memorization: Data contamination and trustworthy evaluation for large language models.\" arXiv preprint arXiv:2402.15938 (2024).\n\n[2] Yax, Nicolas, Pierre-Yves Oudeyer, and Stefano Palminteri. \"Assessing contamination in large language models: introducing the LogProber method.\" arXiv preprint arXiv:2408.14352 (2024).\n\n[3] Wang, William Yang. \"\" liar, liar pants on fire\": A new benchmark dataset for fake news detection.\" arXiv preprint arXiv:1705.00648 (2017).\n\n[4] Li, Yinheng. \"A practical survey on zero-shot prompt design for in-context learning.\" arXiv preprint arXiv:2309.13205 (2023).\n\n[5] Souza, Mariana A., et al. \"A dynamic multiple classifier system using graph neural network for high dimensional overlapped data.\" Information Fusion 103 (2024): 102145."}, "questions": {"value": "1)\tHow does “Chemistry” or the complimentary in this paper differ significantly from the notion of complemenraty in ensemble learning?\n\n2)\tHow does the \"Chemistry\" metric differ significantly from established notions of model diversity and complementarity in the ensemble learning literature (considering both: static and dynamic selection)?\n\n3)\tPlease specify the exact experimental setup for each benchmark (e.g., was Liar used for 2-class or 6-class classification? Which prompts were used for each task and models?. A detailed appendix on implementation details is crucial for soundness.\n\n4)\tGiven that benchmarks like Liar predate the LLMs used, have you assessed potential data contamination? Please refer to the papers mentioned in the weakness section for measuring that.\n\n5)\tcalculating cost_Q(X) for a query seems to require running multiple models on Q first. Can you clarify the operational workflow and how it avoids this inherent cost, making it truly more efficient than a fixed ensemble? Also can you provide the cost (FLOPS, inference time) of the proposal?\n\n6)\tHow does the performance of your final \"Chemistry\"-recommended ensemble compare to a simple baseline of using the single best-performing LLM (e.g., GPT-4o) in isolation? Furthermore, what is the performance gap between your method and an \"oracle\" selector that always chooses the best possible model(s) for each query?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vlESzzspsk", "forum": "T6IIvog2Bk", "replyto": "T6IIvog2Bk", "signatures": ["ICLR.cc/2026/Conference/Submission20110/Reviewer_qnij"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20110/Reviewer_qnij"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761538158244, "cdate": 1761538158244, "tmdate": 1762933007207, "mdate": 1762933007207, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces LLM Chemistry, a framework that measures when LLM combinations exhibit synergistic or antagonistic behaviors that shape collective performance beyond individual capabilities. The analysis shows that chemistry among collaborating LLMs is most evident under heterogeneous model profiles, with its outcome impact shaped by task type, group size, and complexity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This work shifts the focus of multi-LLM collaboration from allocation to interaction. Rather than treating LLMs as isolated units, the paper argues that understanding and leveraging synergistic cooperation among multiple models is a more critical direction.\n- The paper provides a clear and comprehensive definition of “LLM chemistry” and further incorporates optimization strategies for selecting complementary models."}, "weaknesses": {"value": "- As shown in Table 1, the performance gains of the proposed method are quite limited. Notably, the approach even results in a ~30% performance degradation on one benchmark, which raises significant concerns about its practical effectiveness. The chemistry-based selection appears to improve performance only under specific conditions (e.g., certain tasks and ensemble sizes), while potentially harming performance when ensembles are small or already saturated.\n\n- The rationale behind the quality score computation is unclear. The choice of MVLE as the scoring mechanism lacks justification.\n\n- The experimental settings are somewhat narrow. All benchmarks used are relatively old, which could cause data contamination issues. Additionally, the experiments focus exclusively on very large models, leaving open questions regarding applicability to more resource-constrained settings.\n\n- The framework does not consider computational cost, which is a critical factor in real-world deployment of multi-LLM systems. Ignoring such cost severely limits the practicality of the proposed method.\n\n- Although the paper aims to shift the focus of multi-LLM collaboration from allocation to interaction, the actual design appears to treat all LLMs as identical units following the same role assumptions. This suggests the method still fundamentally relies on allocation rather than enabling richer interaction dynamics."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "D7hOeOM7y3", "forum": "T6IIvog2Bk", "replyto": "T6IIvog2Bk", "signatures": ["ICLR.cc/2026/Conference/Submission20110/Reviewer_HaDC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20110/Reviewer_HaDC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761617801889, "cdate": 1761617801889, "tmdate": 1762933006565, "mdate": 1762933006565, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors formalize the concept of \"chemistry\" between LLMs as the change in benefit when models are combined, proposing the CHEME algorithm to compute chemistry scores using Model Interaction Graphs (MIGs) and the RECOMMEND algorithm for optimal ensemble selection. Theoretical analysis demonstrates that chemistry emerges primarily under heterogeneous model performance profiles, with effects modulated by task type, complexity, and ensemble size. Empirical evaluation on the benchmarks provide evidence that chemistry-based selection can improve ensemble effectiveness in specific contexts."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper makes a notable contribution by formalizing LLM interactions through a principled cost function framework with proven properties. Theorem 1 and Corollary 1 provide counterintuitive insights that chemistry emerges only under heterogeneous performance profiles, establishing clear theoretical boundaries for when the approach is applicable. \n2. The authors ground their novel concept in a solid mathematical framework, providing clear and formal definitions for cost, benefit, and chemistry.\n3. Rather than overclaiming effectiveness, the authors honestly report mixed results and provide thoughtful analysis of when chemistry helps versus hurts (e.g., saturation effects in high-performing ensembles, task complexity moderation)."}, "weaknesses": {"value": "1. My biggest concern lies in the computational complexity of the proposed CHEME algorithm. It requires finding the maximum interaction effect over all possible subsets X in S\\{a,b}. This complexity renders the method computationally intractable for any realistic scenario where the pool of candidate LLMs, $S$, is non-trivial (for example, |S| > 20)\n2. Despite claiming \"≈1,800 total experimental task executions,\" the actual dataset sizes are modest—only 10 records per trial across 10 trials means just 100 evaluation instances per configuration. For Liar benchmark (4,000 statements available), this represents 2.5% coverage. The high variance in results (e.g., Clinical Notes N=3 chemistry at 0.700 vs. baseline at 1.000) and the note about \"temporary service issues\" affecting claude-3-7 performance raise questions about result stability and whether observed differences reflect genuine chemistry effects or experimental noise.\n3. The core cost formulation (Equation 1) uses arbitrary weights (1/i) and a 75%/25% weighting between generation and review accuracy that lack principled justification. The paper doesn't explore sensitivity to these hyperparameter choices, leaving uncertainty about whether results depend critically on these specific formulations.\n4. The baseline selection strategies (Random, Performance, Local, Remote) are relatively simple. The paper doesn't compare against recent LLM routing methods (RouteLLM [1] , FrugalGPT [2] mentioned in related work), mixture-of-experts approaches, or learned selection (such as Smoothie [3] and RELM [4] which also uses a combination of model selection and evaluation) policies.\n\nRefs:\n1. Ong, Isaac, et al. \"Routellm: Learning to route llms with preference data.\" arXiv preprint arXiv:2406.18665 (2024).\n2. Chen, Lingjiao, Matei Zaharia, and James Zou. \"Frugalgpt: How to use large language models while reducing cost and improving performance.\" arXiv preprint arXiv:2305.05176 (2023).\n3. Guha, Neel, et al. \"Smoothie: Label free language model routing.\" Advances in Neural Information Processing Systems 37 (2024): 127645-127672.\n4. Kumar, Tarun, et al. \"Co-Optimizing Recommendation and Evaluation for LLM Selection\", ICLR 2025 Workshop on Foundation Models in the Wild."}, "questions": {"value": "0. Authors are requested to respond to my comments in the weakness section above.\n1. In line 119, the quality and accuracy scores are both defined over the same index $i$, but the quality is defined on the outputs, and accuracy is defined over the LLMs. Can you clarify this?\n2. Why does equation 2 need to account for the benefit of a w.r.t. X? Shouldn't the benefit (or cost) of a be only dependent on b?\n3. How much historical performance data is required to reliably construct MIGs and estimate chemistry? For a new task domain without existing performance histories, what cold-start strategy would you recommend?\n4. How does the proposed RECOMMEND algorithm distinguish between beneficial (synergistic) and detrimental (antagonistic) high-chemistry pairs? Would a signed (non-absolute) metric that explicitly separates synergy from antagonism be more appropriate for a recommendation task?\n5. The paper reports a negative correlation between chemistry and ensemble complementarity for medium- and high-complexity tasks, attributing this to \"saturation effects.\" Could this finding also be interpreted as a failure of the chemistry metric itself, where it preferentially assigns high scores to redundant model pairs (whose individual benefits drop sharply when combined), thus actively selecting for lower complementarity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "D0CMlZiMfq", "forum": "T6IIvog2Bk", "replyto": "T6IIvog2Bk", "signatures": ["ICLR.cc/2026/Conference/Submission20110/Reviewer_zKce"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20110/Reviewer_zKce"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20110/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904281742, "cdate": 1761904281742, "tmdate": 1762933004493, "mdate": 1762933004493, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}