{"id": "xBJXnorMJ7", "number": 2977, "cdate": 1757310444718, "mdate": 1763723464106, "content": {"title": "Diffusion Bridge or Flow Matching? A Unifying Framework and Comparative Analysis", "abstract": "Diffusion Bridge and Flow Matching have both demonstrated compelling empirical performance in transformation between arbitrary distributions. However, there remains confusion about which approach is generally preferable, and the substantial discrepancies in their modeling assumptions and practical implementations have hindered a unified theoretical account of their relative merits. We have, for the first time, provided a unified theoretical and experimental validation of these two models. We recast their frameworks through the lens of Stochastic Optimal Control and prove that the cost function of the Diffusion Bridge is lower, guiding the system toward more stable and natural trajectories. Simultaneously, from the perspective of Optimal Transport, interpolation coefficients $t$ and $1-t$ of Flow Matching become increasingly ineffective when the training data size is reduced. To corroborate these theoretical claims, we propose a novel, powerful architecture for Diffusion Bridge built on a latent Transformer, and implement a Flow Matching model with the same structure to enable a fair performance comparison in various experiments. Comprehensive experiments are conducted across Image Inpainting, Super-Resolution, Deblurring, Denoising, Translation, and Style Transfer tasks, systematically varying both the distributional discrepancy (different difficulty) and the training data size. Extensive empirical results align perfectly with our theoretical predictions and allow us to delineate the respective advantages and disadvantages of these two models. Our code is available at \\url{https://anonymous.4open.science/r/DBFM-3E8E/}.", "tldr": "Advantages and disadvantages of diffusion bridge and flow matching in system analysis", "keywords": ["diffusion bridge", "flow matching", "stochastic optimal control"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5f7edf4e8771f14d7a7475a1c87ac03a557a259e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The work proposed a unified formulation of Diffusion Bridge (DB) and Flow Matching (FM) models as specific cases of stochastic optimal control problems. For this, authors reformulated the dynamic optimal transport variational problem for the finding conditional flow with Wasserstein-2 transport cost as the optimal control problem and compared it with the deterministic ODE version of UniDB formulation of DB problem, which is based on the certainty equivalence principle. The main theoretical contributions of the work include: 1) proof of conditions, which lead to the degradation of FM problem to DB problem; 2) proof that the overall cost of respective optimal control problems for DB is less than for FM under specific condition of diffusion coefficient; 3) proof that the empirical McCann’s interpolation is asymptotically admits absolute continuity; 4) proof that for the quadratic cost the finite second moments ensures the validity of FM even for non-compact spaces. Experimental contributions include the quantitative analysis of the performance of DB and FM models for paired image restoration problems, including inpainting, super-resolution, deblurring, and denoising, using the same DiT architecture in the latent space of VAE and images from Celeba-HQ. Authors vary different parameters in the evaluation setup: 1) difficulty by increasing the size of masks in the inpainting problem; 2) size of the training dataset in the inpainting problem; 3) comparison in terms of training and inference time for DB and FM models. The numerical results of FID, LPIPS, SSIM, PSNR support the claims of Figure 1 about pros and cons of DB and FM models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) Theorem 4.2 provides a novel comparison of optimal control functionals between DB and FM models, which supports the claims of the Figure 1.\n2) The proposition to use the unified architecture of DiT to have a fair comparison and the results of experiments for DB and FM models on different image restoration problems in Table 1, 2, and Figure 3, 4 correctly show different pros and cons of DB and FM stated in Figure 1. In particular, the study of quantitative results for FM and DB models depending on the size of training data proves the substantial difference between the two generative modeling paradigms. \n3) Systematic profiling of training and inference time of DB and FM models in Figure 4 sums the natural efficiency of FM models due their simpler formulation. \n4) The variety of 6 tested image-to-image translation problems, including image restoration and additional visual results for style transfer and semantic-to-image translation, makes the experimental study to be wide and universal enough."}, "weaknesses": {"value": "1) The major limitation of the paper is a poor and unclear explanation of the implementation for training of DB and FM models in Section 5.1. According to the provided link for the code, one may suppose that the implementation of the DB relies on the implementation of UniDB, where for the training authors used the Algorithm 1 of UniDB in the ODE regime, while for the sampling they used the Algorithm 2 of UniDB. The implementation of FM models seems to have completely orthogonal implementation based on the code for Rectified Flow. Training and sampling pseudocodes for DB and FM models, which are similar to Algorithms 1 and 2 in UniDB, can improve the understanding of the work for the reader.\n2) The comparison between DB and FM in Table 1 does not provide any information about the relation of numerical results with existing DB and FM models for image restoration problems, for example, GOUB and BoostingFM [1]. Since the evaluation protocol does not match prior works it is impossible to estimate the hardness of the considered evaluation setup without any baseline even though other DB and FM models may use different U-Net architectures. \n3) The study does not provide the analysis of convergence DB and FM models with confusing information in lines 961-963. According to lines 961-963, the number of total training steps was set to 600k. At the same time, in different experiments the size of training data varied, so the training time for DB and FM models depends on the size of the training data, as shown in Table 3. There might be different criterions for the optimization stopping, which affect the results of Figure 4 and Table 3: convergence metrics/optimized objectives on validation/training data. Without these details the provided results are not clear.\n4) The presentation of background for Section 4.2, Appendix A.3 and A.4 is poor, see questions 1-4 below. \n\nReferences:\n\n[1] Boosting Latent Diffusion with Flow Matching. ECCV-2024."}, "questions": {"value": "1) Can you explain what is $T_{n}$ in the line 793? Trained image-to-image translation map on the dataset with the size $n$?\n2) Is it correct that $m$ in lines 827-828 and 834-835 is a typo and there should be no $m$ in the proof?\n3) In the line 830-831 is there a typo with extra comma in the formula $(1 - t)x_{i} + T_{n}(x_{i})$?\n4) Can you explain in details about \"By the stability above\" in lines 823-824? This part in unclear. \n5) Can you comment on the training-validation split in the Section 5: did all numerical results in Table 1, 2, Figure 3 represent the metrics of image-to-image translation DB and FM models on the hold out validation set? If so, what is the size of validation split and how it relates to sizes of the training data?\n6) Can you comment on the stopping criterion for DB and FM models for different training data size in Table 3? How did you ensure that the convergence of those models was achieved?\n7) Can you comment on the stability of training DB and FM models in Figure 3 and Table 3?\n8) Since DB and FM models have the same architecture and NFE during the inference can you comment why FM models have 2-3 times faster inference? \n9) Since the Figure 1 claims that DB models have longer training, but better performance compared with FM, there is question about trade-off on the quality of DB models under the same training time as FM models. Can you comment how the quality of DB models would change if you give them the same training budget as for FM models?\n10) Since the Table 3 shows that the inference time of DB models is 2-3 times slower compared with FM models under the same architecture and NFE=20, can you comment on the quality degradation of DB models with the same inference time as FM models, say, when DB models use NFE=10 while FM models use NFE=20? Do we really need to run DB models with longer training and many NFE steps? Pareto curve between image quality and inference NFE for DB and FM models may improve the claims of the Figure 1.\n11) Can you comment on the total number of training parameters in the DiT architecture you used for the training of DB and FM models and how it is related to other U-Net architectures used in UniDB and GOUB models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "G5YFNHlgYx", "forum": "xBJXnorMJ7", "replyto": "xBJXnorMJ7", "signatures": ["ICLR.cc/2026/Conference/Submission2977/Reviewer_JEWT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2977/Reviewer_JEWT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2977/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760981396686, "cdate": 1760981396686, "tmdate": 1762916477123, "mdate": 1762916477123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper compares Diffusion Bridge and Flow Matching for transforming data. The authors give the first unified theory of both methods using Stochastic Optimal Control. They show that Diffusion Bridge has a lower cost than Flow Matching. They also show that Flow Matching becomes worse when using less training data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "i) The paper makes a clear connection between Flow Matching and Diffusion Bridges using a shared theoretical framework based on Stochastic Optimal Control. To the best of my knowledge, this is the first work to do so.\n\nii) The authors validate their theory through a wide range of experiments. They also introduce a DiT-based architecture for Diffusion Bridge."}, "weaknesses": {"value": "i) A central claim of the paper is that lower total cost in the Diffusion Bridge framework leads to better generative performance, as stated in line 274:  \n   *“Lower total costs typically lead to smoother and more natural SDE/ODE trajectories, which helps to enhance the realistic visual quality of generated images and the robustness across tasks of varying difficulty.”*  \n   However, the theoretical justification for this claim remains unclear. While lower cost may correspond to smoother or straighter trajectories, as shown in [1, see Figure 2 and Theorem 3.5], it is not evident why this necessarily translates to improved visual quality or robustness. Given that this claim underpins much of the experimental motivation, a more detailed explanation or formal argument would significantly strengthen the paper.\n\nii) Several parts of the theoretical appendix are difficult to follow due to undefined or inconsistent notation. For example, in the proof of Theorem 4.2, the notation $\\overline{\\theta_{t:1}}$ and $\\overline{\\sigma_{t:1}}$ appears in line 736 without proper definition or alignment with the notation used in [2], making it hard to trace the logic. Similarly, in the proof of Remark 4.3, the term $S_{t}^{n,m}$ (line 832) is not defined, and therefore the use of limits involving $n,m \\to \\infty$ is not clearly justified.  \n   Appendix A.4 is also difficult to interpret. Although the authors claim in the main text that Flow Matching with linear schedule remains valid in non-compact latent spaces, the proof lacks a formal statement and does not make explicit use of the properties of Flow Matching models. \n\n\n\n\n[1] https://arxiv.org/abs/2209.03003 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow \n\n[2] https://arxiv.org/abs/2502.05749 UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control"}, "questions": {"value": "i) In Section 5.5, the authors present experimental evidence that Diffusion Bridges exhibit greater stability than Flow Matching under limited training data. However, while the paper provides a theoretical explanation for the degradation in Flow Matching performance as data size decreases, no analogous theoretical justification is given for the improved robustness of Diffusion Bridges. Could the authors clarify whether this observed stability is an inherent theoretical advantage of Diffusion Bridges, or if it may be dataset-specific? In other words, is this behavior expected to hold universally, or might there be scenarios where Flow Matching is more robust?\n\nii) The meaning of \"training time\" in Section 5.5 is unclear. Figure 4 shows that Diffusion Bridges take more training time than Flow Matching. Does this mean the models were trained for different wall-clock times? If yes, that could partly explain why Diffusion Bridges perform better. Also, it is unclear why Diffusion Bridges are slower at test time under the same NFE. Since the forward pass usually takes most of the time, a detailed breakdown of runtime would help clarify this.\n\niii) I believe there are typos in Equations (6), (7), (8), and (9). Specifically, the constraints currently refer to $x_t$ and $dx_t$, but should likely use $x_t^u$ and $dx_t^u$ to be consistent with the controlled process notation. Could the authors confirm and correct this if necessary?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "lYjhQAWb7Q", "forum": "xBJXnorMJ7", "replyto": "xBJXnorMJ7", "signatures": ["ICLR.cc/2026/Conference/Submission2977/Reviewer_D87E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2977/Reviewer_D87E"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2977/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761685273579, "cdate": 1761685273579, "tmdate": 1762916476393, "mdate": 1762916476393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper unifies flow matching (FM) and diffusion bridges (DB) through a stochastic optimal control (SOC) formulation and shows that FM emerges as a particular case of DB. This connection enables a theoretical comparison, showing that DB typically exhibits lower SOC costs. Also, FM is shown to be less effective for small data sizes. These theoretical results are confirmed by the experiments in the controlled setup on CelebA-HQ across different tasks, data sizes and task complexity levels."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**S1.** The paper provides an interesting and novel FM formulation via SOC, showing that FM can be viewed as a special case of DB. \n\n**S2.** Theoretical results in Theorem 4.2 and Sec 4.2 reveal two limitations of FM over DB: less stable trajectories and ineffectiveness in data-scarce regimes.\n\n**S3.** The experiments are well-designed and conducted across various tasks of diffirent complexity levels and training data sizes. The authors also compare training and inference wall-clock times and clearly discuss the accuracy-efficiency tradeoffs."}, "weaknesses": {"value": "**W1.** FM is only compared against the UniDB-GOU (GOUB) variant. DDBM-VP/VE also seem relevant options since both are also the special cases of UniDB. Could the authors provide the discussion on how DDBM relates to FM and compare with it?\n\n**W2.** The experiments are limited to a single dataset (CelebA-HQ). I would suggest confirming the results on one or two more datasets (preferably more challenging).\n\n**W3.** I recommend summarizing the training and sampling procedures for both frameworks in Appendix. This would also clarify what causes the efficiency differences. \n\n**W4.** The results are reported only for NFE=20. Different NFEs will show the performance range for both methods and address if FM may approach DB for the same compute budget in seconds."}, "questions": {"value": "**Q1.** Could the authors clarify why FM and DB have different training and inference times? I can see the comment in L448-449 but I still do not understand why DB is much slower for the same NFEs.\n\n**Q2.** If I understand correctly, $\\gamma$ is set to $\\infty$ in all DB runs. Would $\\gamma$ != $\\infty$ further improve the DB advantage (according to UniDB) with no additional training/inference cost?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "95K5XQ6zcJ", "forum": "xBJXnorMJ7", "replyto": "xBJXnorMJ7", "signatures": ["ICLR.cc/2026/Conference/Submission2977/Reviewer_4qbz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2977/Reviewer_4qbz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2977/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892291938, "cdate": 1761892291938, "tmdate": 1762916475438, "mdate": 1762916475438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides both theoretical and experimental analysis comparing two frameworks for distribution-to-distribution sampling (beyond the standard Gaussian-to-data setting): Diffusion Bridges (DB) and Flow Matching (FM).\nThe contributions for this comparative analysis are two-fold:\n1. **Theoretical part** The paper provides a unifying perspective by writing the DB and FM objectives as solutions of a Stochastic Optimal Control problem, with additional discussion on the choice of linear interpolation for the conditional path $x_t = (1-t)x_0 + tx_1$ in FM.\n2. **Experimental part** The paper provides an experimental evaluation where both methods DB and FM are implemented with the same architecture (Latent Transformer) and tested on multiple tasks (image restoration, image translation, style transfer)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The experimental section is detailed and shows, in a convincing manner, that DB outperforms FM on a substantial amount of the evaluated tasks. The ablation studies are relevant (including size of the train set), and a evaluation of the time cost of each method is performed.\n- The code is available, and includes a novel implementation of DB using Latent Transformers, which should be valuable for the community"}, "weaknesses": {"value": "The main weakness concerns the *clarity of the theoretical part*.\nHere are some comments / questions / recommendations that would make the paper easier to follow:\n\n1. **On the SOC framework**  The paper would benefit from a clearer and more rigorous presentation. First, it would be valuable to explicitly introduce the SOC framework (in a general setting) in Section 3 (Preliminaries). Second, there are notational inconsistencies: in Equations 6 and 7, should the state be denoted $\\mathbf x_t^u$ rather than $\\mathbf x_t$ ?\n2. **Conditional versus Total quantities** Throughout the paper, it is unclear what quantities are being analyzed. It seems that what is studied are the conditional paths $p_t(x_t | x_0, x_1)$ for DB and FM. For example, in the FM framework, the study is made on the conditional velocity field $x_1-x_0$. However, what we want to learn in the end is the true vector field $v_t (x) = \\mathbb E [x_1 - x_0 | x_t]$ (even if this is performed with the conditional FM loss).\n - Could you clarify what are the motivations / interests of studying such conditional quantities ?\nFor example, regarding the Flow Matching discussion, the goal is typically not to have conditionally optimal paths, but rather straight trajectories when following the true velocity field (as in Rectified Flows or MiniBatch OT Flow matching).\n3. **On the relation to OT** Section 4.2 would benefit from a rewriting. As it is, the main part of the section is related to discussing whether the conditional velocity field is the solution of an OT problem, which is well known (e.g. section 4.3 in Flow Matching Guide and code, Lipman et al.) and the main contribution appears to be the remark 4.3, which in this case should be highlighted.\nRegarding the content of this section 4.2: does stating that Brenier theorem does not apply anymore on discrete data really imply that the linear interpolation is not well suited ? It would be interesting to articulate the practical implications of this remark and justify them in a more detailed way."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rS3yVf1eeB", "forum": "xBJXnorMJ7", "replyto": "xBJXnorMJ7", "signatures": ["ICLR.cc/2026/Conference/Submission2977/Reviewer_rqBV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2977/Reviewer_rqBV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2977/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930188068, "cdate": 1761930188068, "tmdate": 1762916475014, "mdate": 1762916475014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}