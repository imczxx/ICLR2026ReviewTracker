{"id": "aAb26aqU1E", "number": 11171, "cdate": 1758191974199, "mdate": 1759897603008, "content": {"title": "LearnIR: Learnable Posterior Sampling for Real-World Image Restoration", "abstract": "Image restoration in real-world conditions is highly challenging due to heterogeneous degradations such as haze, noise, shadows, and blur. Existing diffusion-based methods remain limited: conditional generation struggles to balance fidelity and realism, inversion-based approaches accumulate errors, and posterior sampling requires a known forward operator that is rarely available. We introduce **LearnIR**, a learnable diffusion posterior sampling framework that eliminates this dependency by training a lightweight model to directly predict gradient correction distributions, enabling *Diffusion Posterior Sampling Correction (DPSC)* that maintains consistency with the true image distribution during sampling. In addition, a *Dynamic Resolution Module (DRM)* dynamically adjusts resolution to preserve global structures in early stages and refine fine textures later, while avoiding the need for a pretrained VAE. Experiments on ISTD, O-HAZE, HazyDet, and our new FaceShadow dataset show that LearnIR achieves state-of-the-art performance in PSNR and SSIM.", "tldr": "", "keywords": ["Image restoration", "diffusion model", "residual"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/640bae6e6a54598f28f471e395e428067418e47e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors study diffusion-based image restoration, proposing a posterior sampling correction method. They also propose a dynamic resolution module that downsamples/upsamples the input during training, both improving the results and accelerating the training.\n\nThe proposed method is evaluated on the task of haze removal and shadow removal, across four different datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is quite well written, few typos or similar issues.\n- The two introduced components, DPSC and DRM, make sense overall and both seem to improve the performance (Table 3, Figure 6).\n- The proposed method seems to perform well overall compared to recent baselines."}, "weaknesses": {"value": "- The proposed method could be presented/introduced better in Section 3. In particular, 3.1 would benefit from more commentary instead of just stacking definitions/theorems, the flow could be improved. The algorithms in 3.3 would also benefit from added descriptions/explanations.\n- The experimental evaluation could be more extensive/convincing. Only two different tasks. Results are compared with baselines mostly just in terms of PSNR and SSIM, lacking perceptual metrics. \n- The technical contribution/novelty seems somewhat limited, at least based on my understanding of the proposed approach."}, "questions": {"value": "Questions/suggestions:\n- In the abstract and introduction you write \"our new FaceShadow dataset\" and \"our newly constructed FaceShadow dataset\", but then in Section 4.1 you write \"three standard datasets: ISTD, [...] and FaceShadow (Zhang et al., 2020)\"?\n- In Table 1 and 2, why results only in terms of PSNR and SSIM? Why not also LPIPS and/or FID?\n- In Section 4.2, ISTD results, it's not clear to me what it means for a method to be mask-free? Also, in the Table 1 caption, should violet and blue be swapped?\n- Line 238, \"Based on Definitions 1 and 2, Eq. 3 can be expressed\": Should this be Eq. 4?\n- Could be interesting to evaluate methods also in terms of computational cost during training / at test-time, at least to see the effect of the proposed DRM?\n- Which dataset are the images in Figure 5 from?\n- Line 260, \"As illustrated in Figure 2, the model...\": This is not illustrated in a lot of detail in Figure 2 though? Perhaps consider tweaking.\n\n\n\n\n\n\nMinor things:\n- I think Section 2 could be tweaked to improve the overall flow a bit.\n- Figure 4 caption: \"(Visual comparisons on the HazyDet datasets)\" --> \"Visual comparisons on the HazyDet datasets\"?\n- Line 96, \"Experimental results clearly and consistently demonstrate that LearnIR consistently outperform\":  \"consistently\" twice, perhaps reformulate.\n- Line 146, \"To obtain an form of the\": typo.\n- Figure 2 caption, \"The blue line in Eq. 3 denotes timestep T', computed using the\": I don't quite understand what you mean, what blue line?\n- Figure 3, \"ShadowForme\" --> \"ShadowFormer\"?\n- Figure 4, \"Dehamer\" --> \"DeHamer\"?\n- Line 322, \"Hazy\" --> \"HazyDet\"?\n- O-Haze is not mentioned at the beginning of Section 4.1? \n- Line 371, \"We benchmark against Zhang et al. (Zhang et al., 2020)\" --> \"We benchmark against (Zhang et al., 2020)\", perhaps?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hrTxCQDHfK", "forum": "aAb26aqU1E", "replyto": "aAb26aqU1E", "signatures": ["ICLR.cc/2026/Conference/Submission11171/Reviewer_m8gP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11171/Reviewer_m8gP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906118388, "cdate": 1761906118388, "tmdate": 1762922331282, "mdate": 1762922331282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the LearnIR framework to address heterogeneous degradations in real-world image restoration, featuring a novel learnable diffusion posterior sampling mechanism. The method trains a lightweight model to directly predict the distribution of gradient correction terms, enabling diffusion posterior sampling correction without requiring a known forward operator. A dynamic resolution module dynamically adjusts image resolution during training, applying large-scale downscaling in early stages to preserve global structures and upscaling later to refine textures. Extensive experiments on multiple real-world datasets demonstrate significant improvements in PSNR and SSIM metrics, particularly in challenging facial shadow removal tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "‚óè The learnable posterior sampling correction mechanism eliminates the dependency on a known forward operator, addressing a key limitation of diffusion models in real-world degradation scenarios.\n‚óè The DRM effectively balances multi-scale feature extraction and computational efficiency while avoiding the need for a pretrained VAE.\n‚óè Extensive validation on multiple real-world datasets, including a newly constructed FaceShadow dataset, provides convincing results."}, "weaknesses": {"value": "‚óè The proposed method introduces training complexity. Joint training of DPSC and DRM modules requires careful hyperparameter tuning. Also, dynamic resolution switching may introduce training instability, with convergence issues insufficiently addressed.\n‚óè The major limitation of diffusion-based posterior sampling method is the scalability to real-world scenarios. However, most current experiments are conducted on synthetic degradation datasets, with the only real-world datasets available being limited to the facial domain. The authors are consider to extend the proposed method to more challenging scenarios such as real-world image super-resolution task and compare with the advanced methods."}, "questions": {"value": "‚óè Detailed illustrations need to be added for Sec. 3.3.\n‚óè The authors are highly recommended to provide image results in supplementary material."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AzUHHv5HnO", "forum": "aAb26aqU1E", "replyto": "aAb26aqU1E", "signatures": ["ICLR.cc/2026/Conference/Submission11171/Reviewer_KzEc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11171/Reviewer_KzEc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927001153, "cdate": 1761927001153, "tmdate": 1762922330947, "mdate": 1762922330947, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LearnIR, which uses a diffusion posterior sampling correction approach to enable robust real-world image restoration. The proposed approach overcomes the limitation of methods such as DPS which require the explicit modeling of the forward degradation operator. Additionally, LearnIR uses a dynamic resolution module instead of a VAE which allows faster restoration with better performance."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and easy to follow.\n2. The proposed DPSC method is well designed, intuitive and effective.\n3. LearnIR achieves state-of-the-art performance on real-world datasets."}, "weaknesses": {"value": "1. Lack of ablations regarding the effectiveness of the DRM module (see questions).\n2. Limited testing on out-of-domain real datasets to substantiate generalization claim (see questions)."}, "questions": {"value": "1. The proposed DRM module is compared with the frozen SD VAE in Sec. A6.2. However, was the SD VAE frozen and paired with the RDDM model for this experiment? The experiment which needs to be performed would be using the RDDM model with the SD VAE being fine-tuned, as the DRM is trained in LearnIR.\n2. In Sec. A6.1, was the DRM also trained with the DiT and DDIM backbones?\n3. For the comparisons, were all methods trained on the same datasets as LearnIR?\n4. While the authors show results on real-world data, the datasets were used for training LearnIR. To further validate generalization, can the authors provide experiments on other real-world haze datasets (such as [1])?\n5. The core approach involves learning to predict score of $p(y|x_t)$. However, this is intractable for real-world degradations and is approximated for learning (Line 144). Could this be considered a limitation of the method and be included as part of limitations?\n6. Experiments comparing computation complexities of VAEs and DRM need to be added to substantiate claims in Line 93.\n\n[1] Zhang, Xinyi, et al. \"Learning to restore hazy video: A new real-world dataset and a new method.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bdED5d5nHx", "forum": "aAb26aqU1E", "replyto": "aAb26aqU1E", "signatures": ["ICLR.cc/2026/Conference/Submission11171/Reviewer_ZY1D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11171/Reviewer_ZY1D"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952884031, "cdate": 1761952884031, "tmdate": 1762922330485, "mdate": 1762922330485, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LearnIR, a diffusion-based framework for real-world image restoration that eliminates the need for a known degradation forward operator‚Äîa long-standing bottleneck in diffusion posterior sampling (DPS) methods. The key innovation lies in Diffusion Posterior Sampling Correction (DPSC), which introduces a learnable model to predict the gradient correction distribution that replaces the explicit operator used in DPS. This approach allows posterior refinement without requiring analytical knowledge of the forward degradation process. In addition, the authors introduce a Dynamic Resolution Module (DRM) that adaptively adjusts image resolution during training to balance global structure preservation and fine detail generation while avoiding dependence on a pretrained VAE.\n\nThe method achieves state-of-the-art results on multiple benchmarks, including ISTD, O-HAZE, HazyDet, and a new FaceShadow dataset introduced by the authors. Quantitatively, LearnIR surpasses recent methods such as ResFusion, ShadowRefiner, and ConvIR in both PSNR and SSIM while maintaining efficiency and generalization to complex real-world degradations"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1. The proposed method bypasses the requirement for a known degradation operator in previous works, enabling the application of DPS-related methods in blind restoration tasks. I think this is an important contribution to the research field.\n2. The method outperforms recent state-of-the-art methods with a large margin, including ISTD, O-HAZE, HazyDet, and a new FaceShadow dataset."}, "weaknesses": {"value": "In summary, this is a very sound and impressive work, but with poor presentation. I'm happy to increase my rating based on the writing. \n\nMy main concern lies in the presentation and organization of the paper. While the technical contributions appear sound and potentially impactful, the paper is dense with mathematical formulations, and several notations are either inconsistent or insufficiently explained. These issues make the paper difficult to follow, especially for readers who are not deeply familiar with the DPS-related research line.\n\n1. In Section 3.1, the notation $z_t$ is introduced abruptly without prior explanation. Its definition only appears later in Section 3.2, which disrupts the logical flow and makes it challenging for readers to grasp the progression of ideas. Similarly, the notation $\\hat{x}_)$ in Eq. (4) also lacks explanation. I suggest re-checking the presentation so that all key notations are properly introduced before use and accompanied by clear definitions.\n\n2. Theorem 1 claims that Eq. (3) can be expressed as Eq. (16). However, these two equations seem unrelated or at least not directly derivable from one another as currently written. The authors should carefully verify this connection and, if necessary, correct or clarify the statement and its derivation.\n\n3. In step 4 of Algorithm 1, the operator $ùê∑^s$ takes $x_0$, $y_0$, and $x^{s-1}$ as inputs, while in other steps (e.g., step 5), it appears to only take $y$ as input. This inconsistency is confusing and suggests either a typographical error or an incomplete explanation of $D^s$'s input structure. A clearer, self-consistent description of the algorithmic steps is required.\n\nOverall, this is a technically solid and promising piece of work with interesting ideas. However, the presentation quality needs significant improvement. The current version suffers from poor organization and inconsistent notation, which hinders readability and comprehension. I would be happy to raise my rating if the authors substantially improve the clarity, consistency, and accessibility of the writing in the revision."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OtHLixn4yB", "forum": "aAb26aqU1E", "replyto": "aAb26aqU1E", "signatures": ["ICLR.cc/2026/Conference/Submission11171/Reviewer_Y9b8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11171/Reviewer_Y9b8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11171/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982313102, "cdate": 1761982313102, "tmdate": 1762922329393, "mdate": 1762922329393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}