{"id": "fHpRtccY4I", "number": 16811, "cdate": 1758268943668, "mdate": 1763632229483, "content": {"title": "ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning", "abstract": "Scaling federated learning (FL) to billion-parameter models introduces critical trade-offs between communication efficiency, network load distribution, model accuracy, and privacy guarantees. Existing solutions often tackle these challenges in isolation, sacrificing accuracy or relying on costly cryptographic tools. We propose ERIS, a serverless FL framework that balances privacy and accuracy while eliminating the server bottleneck and significantly reducing communication overhead. ERIS combines a model partitioning strategy, distributing aggregation across multiple client-side aggregators, with a distributed shifted gradient compression mechanism. We theoretically prove that ERIS (i) converges at the same rate as FedAvg under standard assumptions, and (ii) bounds mutual information leakage inversely with the number of aggregators, enabling strong privacy guarantees with no accuracy degradation. Extensive experiments on image and text datasets‚Äîranging from small networks to modern large language models‚Äîconfirm our theory: compared to six baselines, ERIS consistently outperforms all privacy-enhancing methods and matches the accuracy of non-private FedAvg, while reducing model distribution time by up to $1000\\times$ and communication cost by over 94\\%, lowering membership inference attack success rate from $\\sim$83\\% to $\\sim$65\\%‚Äîclose to the unattainable $\\sim$64\\% limit‚Äîand reducing data reconstruction to random-level quality. ERIS establishes a new Pareto frontier for scalable, privacy-preserving FL for next-generation foundation models without relying on heavy cryptography or noise injection.", "tldr": "ERIS is a serverless FL framework that combines model partitioning and gradient compression to reduce communication by 94%, eliminate the server bottleneck, and improve privacy guarantees without sacrificing accuracy.", "keywords": ["federated learning", "privacy", "scalability", "efficiency", "gradient compression", "membership inference attacks", "data reconstruction attacks"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fefcfb599f2cdfe49e1e3127fbbb59005fdd0dda.pdf", "supplementary_material": "/attachment/e8198ff517750fc705a7cf6a506ae07a575dc9ac.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes ERIS, a serverless federated learning framework that combines gradient partitioning across multiple client-side aggregators with shifted compression. The authors claim simultaneous improvements in communication efficiency, privacy, and convergence while maintaining equivalence to FedAvg. The work presents theoretical convergence guarantees and information-theoretic privacy bounds, validated through experiments on image and text datasets ranging from small networks to LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1- The paper provides formal convergence guarantees (Theorem 3.6) and information-theoretic privacy bounds (Theorem 3.7), with detailed proofs showing the approach maintains FedAvg equivalence.\nS2-  Evaluation spans multiple datasets (MNIST, CIFAR-10, IMDB, CNN/DailyMail), model scales (62K to 1.3B parameters), and compares against six baselines under different privacy attack scenarios (MIA, DRA).\nS3- The paper provides thorough ablation studies on the impact of compression and partitioning separately.\nS4- The framework successfully scales to billion-parameter models where many privacy-preserving baselines fail to maintain utility."}, "weaknesses": {"value": "W1- The paper conflates two orthogonal benefits throughout. Each client in ERIS uploads and downloads the same total amount of data (b' bits) as any compression-only method like SoteriaFL. The claimed \"communication efficiency\" actually refers to reduced distribution time through parallelization, not reduced per-client communication volume. Table 2 is particularly misleading‚ÄîERIS shows 1% vs SoteriaFL's 5% primarily due to more aggressive compression (different \\omega values), not the partitioning scheme. \nW2- The core techniques are from prior work: (a) distributed aggregation exists in Ako (2016), Shatter (2025), C-DFL (2022); (b) shifted compression is directly from Li et al. (2022d). The main contribution is combining these with a straightforward proof that partitioning with disjoint/complete masks preserves FedAvg convergence (Theorem B.1), which is relatively obvious since it merely reorders aggregation operations. \nW3- The privacy guarantees only hold against honest-but-curious aggregators who do not observe network traffic beyond their assigned shard. A realistic adversary monitoring network communications can reconstruct the full gradient by observing all client transmissions, reducing privacy to compression-only protection. Under collusion (Corollary D.2), privacy degrades linearly‚Äîif adversaries observe all A channels, privacy advantages vanish. The paper needs to discusses these limitations.\nW4- Despite aggregators being selected from clients (who \"may vary in computational resources and connection stability,\" Section 5.2), the paper does not provide analysis of aggregator dropout/failure during training rounds,  evaluation of model sensitivity to aggregator unavailability or discussion of aggregator selection strategies.\nW5- Figure 6 compares ERIS (A=50, with compression) against FedAvg (no compression), exaggerating gains. Fair comparisons should use identical compression ratios. \nW6- Theorem 3.6 shows convergence rate depends on œâ (compression), matching SoteriaFL. Partitioning contributes nothing to convergence improvement, it only redistributes computation. This should be stated explicitly."}, "questions": {"value": "Q1- Can you provide a detailed breakdown in Table 2 showing: (a) per-client upload bytes, (b) per-client download bytes, (c) compression ratio, and (d) distribution time, clearly separating gains from compression vs. parallelization?\nQ2- What happens when aggregators drop mid-round? Does training continue with (A-1) aggregators, restart the round, or fail? Please provide analysis of robustness to aggregator failures.\nQ3- Can you provide experiments where ERIS and SoteriaFL use identical compression ratios (same compression ratio)? This would isolate the benefit of distributed aggregation from compression.\nQ4- How do privacy guarantees degrade when adversaries can observe all network traffic (not just content at aggregators)? Can you quantify information leakage in this realistic threat model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1kXaFMxgPS", "forum": "fHpRtccY4I", "replyto": "fHpRtccY4I", "signatures": ["ICLR.cc/2026/Conference/Submission16811/Reviewer_RH9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16811/Reviewer_RH9A"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761866124196, "cdate": 1761866124196, "tmdate": 1762926841422, "mdate": 1762926841422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ERIS, a serverless federated learning (FL) framework designed to simultaneously improve communication efficiency, scalability, and privacy. The system replaces the central server with multiple decentralized aggregators, and combines this with a shifted gradient compression mechanism and gradient partitioning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides clear utility and privacy analysis.\n\n2. It is a new idea to have gradient partitioning scheme across multiple aggregators."}, "weaknesses": {"value": "1. The paper claimed a few \"the first\": \"ERIS is the first FL framework to simultaneously achieve decentralized aggregation, strong communication efficiency, and provable information-theoretic privacy guarantees without sacrificing model utility. ERIS is also the first to\nextend privacy-enhancing federated training to modern LLMs, demonstrating feasibility at scale where prior methods fail to preserve utility and efficiency.\" I think these claims are ambiguous because no proof or metrics to show them. For example, I suppose there are lots of works for privacy-enhancing federated training even to LLMs.\n\n2. The need for each client and aggregator to track the shifting reference vectors introduces extra memory and synchronization complexity.\n\n3. I have concerns about theorem 3.6 as it is not tight. For example, if we use SGD as the inner optimizer, Eq(6) shows that it converges to an error that is independent to learning rate. This is not a classic rate, different from existing decentralized optimization and federated optimization. Furthermore, a table of convergence rate comparison with existing baseline algorithms in decentralized optimization and federated optimization would be appreciated. \n\n4. The paper attempts to deliver multiple contributions simultaneously, which makes the overall narrative somewhat overwhelming. For example, the claimed communication efficiency is mainly derived from shifted compression, a technique that is not new. As a result, the contribution in this dimension may appear incremental unless more concrete empirical or theoretical advantages are demonstrated."}, "questions": {"value": "The contributions are about communication and privacy. I wonder if the authors can provide direct comparisons in each dimension with previous works. I suppose there are a lot baselines in decentralized optimizaiton and federated optimization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HuorLja5RP", "forum": "fHpRtccY4I", "replyto": "fHpRtccY4I", "signatures": ["ICLR.cc/2026/Conference/Submission16811/Reviewer_5ugv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16811/Reviewer_5ugv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877389439, "cdate": 1761877389439, "tmdate": 1762926840981, "mdate": 1762926840981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ERIS, a decentralized federated learning framework designed to achieve both communication efficiency and information-theoretic privacy guarantees without relying on a central server. The key idea is to partition model parameters into disjoint shards, each handled by a different client-side aggregator, and to apply a ‚Äúshifted compression‚Äù mechanism that reduces communication cost while limiting information leakage. The authors provide convergence and privacy analyses, showing that ERIS maintains FedAvg-like utility bounds(Thm. 3.6) and scales privacy guarantees with the number of aggregators(Thm. 3.7). Empirical evaluations demonstrate improved privacy‚Äìutility‚Äìcommunication trade-offs compared to existing decentralized or privacy-preserving FL baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a clear and well-motivated problem setup addressing privacy and communication challenges in decentralized FL.\n- The overall framework is interesting: partitioning parameters across aggregators leads to linear scalability and better privacy by design.\n- This paper includes solid theoretical analysis, providing convergence results and a clean information-theoretic privacy bound.\n- The paper systematically evaluates both MIAs and DRAs, includes a Pareto analysis, and reports per-round communication/time numbers."}, "weaknesses": {"value": "* The paper states ERIS is the first framework to simultaneously provide decentralized aggregation, communication efficiency, and provable information-theoretic privacy without sacrificing utility. However, it seems that the claims is too strong. Baslines in the experiments such as Shatter and SoterialFL as well as the other prior works (e.g., [Shen et al]) should be discussed and compared before the claim.\n* - Shen, Meng, et al. \"Secure decentralized aggregation to prevent membership privacy leakage in edge-based federated learning.\" IEEE Transactions on Network Science and Engineering 11.3 (2024): 3105-3119.\n\n- Algorithm 1 and ¬ß3.2 say masks can be predefined/shared or dynamically sampled by each client. For an aggregator-specific shard, it‚Äôs more natural that the aggregator (or a coordinator) samples/defines $m_{(a)}^t$ and broadcasts them to all clients per round to guarantee consistent slicing across clients. As written, ‚Äúdynamically sampled by each client‚Äù (line 202) invites inconsistent partitions unless there is a synchronization step. Please clarify the intended control flow (who samples? when? how are masks synchronized/broadcast?)\n- The main text analyzes an honest-but-curious non-colluding adversary who only sees a shard; Appendix D mentions an extension to colluding adversaries and ¬ß5.2 acknowledges that privacy benefits diminish with collusion, scaling with the number of colluding nodes (Corollary D.2). This is important enough to surface earlier: how much privacy remains if a small constant fraction of aggregators collude? What if an aggregator colludes with a subset of clients?\n- The experiments show performance degradation as $A$ grows (Figure 2) while Thm. 3.6 is agnostic to $ùê¥$. An intuitive explanation is missing. Is this because increasing$A$ shrinks each shard‚Äôs dimensionality and, together with compression, increases effective variance and error-feedback lag on each shard‚Äôs reference vector? That can slow optimization or accumulate bias in finite rounds even if the asymptotic bound does not expose an explicit $A$ term."}, "questions": {"value": "- Please see the weaknesses.\n- If $A \\rightarrow n$ (i.e., per-coordinate sharding), it there a stability/variance blow-up without increasing bandwidth? Any guidance on a practical range of $ùê¥$ w.r.t model dimension and client count?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OyU3vJi0qt", "forum": "fHpRtccY4I", "replyto": "fHpRtccY4I", "signatures": ["ICLR.cc/2026/Conference/Submission16811/Reviewer_u1h3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16811/Reviewer_u1h3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16811/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762082050069, "cdate": 1762082050069, "tmdate": 1762926840595, "mdate": 1762926840595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies serverless federated learning (FL) that balances the trade-offs among multiple objectives: communication efficiency, network load distribution, model accuracy, and privacy guarantees. Unlike many solutions in the literature, the proposed ERIS FL framework can achieve good balances among all these objectives. The fundamental technique that ERIS leverages is a combination of a model partitioning strategy and a distributed shifted gradient compression mechanism. The authors demonstrate the superior performance both theoretically and through extensive experiments on image and text datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. I like the nice illustration of ERIS in Figure 1. The authors are able to clearly show how ERIS works during the client computation, shifted compression, model partitioning, and distributed training.\n\n2. I also like it that the authors go beyond the small scale experiments on MNIST, FLMNIST many other papers would use and test the proposed methods on larger scale datasets and models such as 1.3B GPT-Neo."}, "weaknesses": {"value": "My major concern lies in the literature review. The authors consider balancing the trade-offs among many objectives: communication efficiency, network load distribution, model accuracy, and privacy guarantees. This clearly falls into the multi-objective /task federated learning domain. The authors also conduct the utility and privacy trade-off analysis and plot the Pareto frontier of the solutions in the experiments such as those in Figure 4. All of these indicate that the authors might have already been aware of the multi-objective nature of the problem. However, I did not see a systematic review of multi-objective federated learning papers. For example, \n\nYang, Haibo, et al. \"Federated multi-objective learning.\" Advances in neural information processing systems 36 (2023): 39602-39625.\n\nKang, Yan, et al. \"Optimizing privacy, utility and efficiency in constrained multi-objective federated learning.\" arXiv preprint arXiv:2305.00312 (2023).\n\nZhang, Xiaojin, et al. \"Trading off privacy, utility, and efficiency in federated learning.\" ACM Transactions on Intelligent Systems and Technology 14.6 (2023): 1-32."}, "questions": {"value": "Like what I have mentioned in the weakness section, I would like to see the authors have more discussion on the connections and differences with those literatures in multi-objective federated learning domains."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jopF9JtIr1", "forum": "fHpRtccY4I", "replyto": "fHpRtccY4I", "signatures": ["ICLR.cc/2026/Conference/Submission16811/Reviewer_Ge1m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16811/Reviewer_Ge1m"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16811/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763730183763, "cdate": 1763730183763, "tmdate": 1763730183763, "mdate": 1763730183763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}