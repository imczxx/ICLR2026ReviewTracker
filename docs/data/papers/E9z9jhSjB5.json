{"id": "E9z9jhSjB5", "number": 8085, "cdate": 1758060339469, "mdate": 1759897808830, "content": {"title": "Online Continual Learning under Real Concept Drift: A Statistical Perspective", "abstract": "Real-world data often exhibit non-stationarity, prompting growing interest in adaptive learning techniques. Continual learning, which aims to sequentially learn multiple tasks, provides a promising framework to address this challenge. However, learning under real concept drift, where the relationship between inputs and outputs evolves over time, remains relatively underexplored. In this paper, we propose a novel regularization-based method that incorporates a memory buffer to improve robustness against concept drift. Assuming the existence of a common center for the evolving true models, our method jointly constrains current and past task estimates, effectively bridging them to form a stable estimate that incorporates information across tasks. To further adapt to task variability, we develop an online algorithm that dynamically tunes task-specific regularization parameters. We also provide theoretical guarantees by deriving an error bound that characterizes the overall performance of the estimator, explicitly capturing the effects of task-relatedness, memory buffer size, and regularization strength. Extensive experiments demonstrate that our method achieves superior stability–plasticity trade-offs under varying degrees of task similarity.", "tldr": "", "keywords": ["Continual learning", "Concept drift", "Regularization", "Memory buffer", "Online algorithm"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/51d7636635f81cfd0bb5259d8f2c76f805702df9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a framework for continual learning in dynamic environments where the relationship between inputs and outputs changes over time. It proposes a regularization-based method that combines memory replay with adaptive tuning to balance knowledge retention and adaptability. The authors develop an efficient online algorithm with theoretical guarantees linking performance to task similarity, memory size, and regularization strength. Experiments on synthetic and real-world benchmarks show that the proposed method outperforms established continual learning baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-written and easy to follow.\n\n2. The proposed concept drift setting is interesting. It may apply to some specific scenarios such as recommendation systems.\n\n3. The proposed method is theoretically-grounded, and achieves strong performance in this particular setting."}, "weaknesses": {"value": "1. The use of memory buffer, although effective, may result in additional storage cost and privacy concerns. \n\n2. The compared methods are mainly traditional continual learning methods (EWC, ER, and AGEM). Is it possible to include more recent methods, such as continual unlearning methods?\n\n3. The experiments are mainly performed with relatively simple datasets, such as MNIST and CIFAR-10. Does the proposed method apply to larger-scale datasets, such as ImageNet (subsets)?\n\n4. Do the theoretical analysis and the proposed method only apply to online continual learning? Is it possible to extend them to other continual learning scenarios (e.g., offline continual learning)?"}, "questions": {"value": "My major concerns lie in the comparison baselines and applicability of the proposed method. Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0DqEsf4dTD", "forum": "E9z9jhSjB5", "replyto": "E9z9jhSjB5", "signatures": ["ICLR.cc/2026/Conference/Submission8085/Reviewer_s2AM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8085/Reviewer_s2AM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760883649283, "cdate": 1760883649283, "tmdate": 1762920073516, "mdate": 1762920073516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a regularization-based method leveraging a memory buffer to address real concept drift. This method connects past and present task estimations through a central point for evolving models, promoting both stability and adaptation. Theoretical bounds regarding generalization error are provided, and their method is benchmarked against SGD, EWC, ER, and AGEM on both synthetic and real-world datasets, including kidney transplantation data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Theoretical Contribution:** The paper contributes to the theoretical understanding of Continual Learning with the buffer size used. \n    \n2. **Clarity:** The overall writing is ok and accessible."}, "weaknesses": {"value": "1. **Notation**  As $|\\cdot|$ is defined as the absolute value of a real number or cardinality of a set, the definition in Assumption 1 is problematic, which should be  $\\|\\|w_j -w_0\\|\\|_2$. In addition, $J^c$ is undefined. In line 179, the definition of empirical loss of the $t$-th task $\\ell(w, z_t^i)$ is inconsistent with that in eq.(1), which is for the whole data set. \n2. **Insufficient Novelty and Related Work Discussion** I do not find obvious significance for the proposed methods against online/continual meta-learning approaches, where hyperparameters and regularizations are both considered for concept drift or more general shifts. This work is missing related works in this domain, e.g., [1-8]. \n    \n3. **Theoretical Results:**  \n    * Theorem 1 only measures the distance of a single $\\hat{\\theta}_T$ to every task optimal parameter; it's unclear how it affects the average population loss. \n    * Unclear definition of the $\\lambda$ in Theorem 1, whether all the tasks use the same $\\lambda$? What is its relation to the $\\lambda$s in eq(2)?  \n    * How does $a_1$ and $a_2$ affect the theoretical results?\n    \n4.  **Empirical Results:**  \n    * Potential Overfitting in Real-world Data: The paper indicates that theoretical assumptions might not fully apply in empirical evaluations, suggesting possible overfitting or adaptation challenges in diverse settings.\n    * The memory buffer size effectively affects the results. How can we make sure it's fairly compared with methods without a memory buffer? \n    * Except for Permuted MNIST or Split CIFAR-10, typical online/continual meta-learning approaches consider concept drifts by predicting different characters for each task, e.g., select different five characters from 10 to predict their classes.   \n    \n--- \n[1] Chelsea Finn, Aravind Rajeswaran, Sham Kakade, and Sergey Levine. Online meta-learning.\nIn International Conference on Machine Learning, pages 1920–1930. PMLR, 2019.\n\n[2] Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas\nPage-Caccia, Issam Hadj Laradji, Irina Rish, Alexandre Lacoste, David Vázquez, et al. Online\nfast adaptation and knowledge accumulation (osaka): a new approach to continual learning.\nAdvances in Neural Information Processing Systems, 33:16532–16545, 2020.\n\n[3] Giulia Denevi, Carlo Ciliberto, Riccardo Grazzi, and Massimiliano Pontil. Learning-to-learn\nstochastic gradient descent with biased regularization. In International Conference on Machine\nLearning, pages 1566–1575. PMLR, 2019.\n\n[4] Qi Chen, Changjian Shui, Ligong Han, and Mario Marchand. On the stability-plasticity dilemma\nin continual meta-learning: Theory and algorithm. Advances in Neural Information Processing\nSystems, 36:27414–27468, 2023.\n\n[5] Maria-Florina Balcan, Mikhail Khodak, and Ameet Talwalkar. Provable guarantees for gradientbased meta-learning. In International Conference on Machine Learning, pages 424–433. PMLR,\n2019.\n\n[6] Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Adaptive gradient-based metalearning methods. arXiv preprint arXiv:1906.02717, 2019.\n\n[7] Qiang Zhang, Jinyuan Fang, Zaiqiao Meng, Shangsong Liang, and Emine Yilmaz. Variational\ncontinual bayesian meta-learning. Advances in Neural Information Processing Systems, 34:\n24556–24568, 2021.\n\n[8] Xu, Kunlun, et al. \"Componential Prompt-Knowledge Alignment for Domain Incremental Learning.\" arXiv preprint arXiv:2505.04575 (2025)."}, "questions": {"value": "1. **Question on the Empirical Results:** When $\\delta=0$, which means all the tasks are the same, can you explain why the proposed method is better than others? \n\n2. **Generalization to Complex Tasks:** How does the method perform with tasks having complex dependencies beyond shared central models?\n    \n3. **Memory Buffer Adaptability:** Does the method adapt efficiently under varying memory constraints, significantly beyond tested scenarios?\n    \n4. **Implementation Details:** Given the overhead of dynamic parameter tuning, are there strategies to streamline this process without compromising learning efficacy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NWc9LgVD17", "forum": "E9z9jhSjB5", "replyto": "E9z9jhSjB5", "signatures": ["ICLR.cc/2026/Conference/Submission8085/Reviewer_YpUb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8085/Reviewer_YpUb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761494328126, "cdate": 1761494328126, "tmdate": 1762920073129, "mdate": 1762920073129, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of online continual learning under real concept drift — i.e., when the relationship between inputs and labels evolves over time — rather than the more common “task-incremental” setting in which tasks are static and well-defined. Their main contributions are:\n\n\n* The authors highlight that many continual learning (CL) works assume a fixed task boundary or static relationship, whereas in many real-world scenarios the underlying model “drifts” as new data arrive (inputs → outputs mapping changes). \n\n* To address concept drift, the authors propose a regularization-based methodology that uses a memory buffer of past examples and constrains the current model’s estimate jointly with past task estimates, under the assumption of a “common center” for the evolving true models. (i.e., current and past models cluster around a latent center)\n\n\n* In order to adapt to the variability between tasks (or time-segments), the algorithm dynamically tunes task‐specific regularization parameters in the online setting — enabling a better balance of plasticity vs. stability under drift. \n\n* The authors derive an error bound for their estimator, explicitly characterizing how performance depends on: task-relatedness (distance to the latent center), memory buffer size, and regularization strength."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The focus on “real concept drift” rather than idealised fixed-task CL is  relevant for practical deployments (e.g., streaming data, non-stationary domains).\n\n\n* The derivation of an error bound is a strong component; it connects method design (memory size, regularization) to performance guarantees.\n\n\n* The dynamic tuning of regularization strength per time‐segment is a meaningful advance over fixed hyper-parameters, enabling the method to adapt to varying drift severity."}, "weaknesses": {"value": "* A key assumption is that the evolving true models (over time) share a “common center” around which they drift. While convenient analytically, this may be unrealistic in many settings where the drift is large or the underlying tasks change drastically. The paper could benefit from discussion or analysis of what happens when the assumption fails.\n\n\n* If the drift is very abrupt (i.e., the new model is far from the previous center) or tasks are entirely unrelated, it is unclear how well the method will perform. The paper may not sufficiently explore worst‐case drift scenarios.\n\n\n\n* The experiment's evaluations are limited to a few synthetic or small‐scale drift settings; it may raise questions about how the method generalises to more complex domains (e.g., large-scale dataset, vision transformer model). The paper may not explore this breadth fully."}, "questions": {"value": "* Could you comment on scenarios where the “true models” do not cluster around a common center (for example, when the drift jumps to a new regime far from previous ones)? How does your algorithm behave in such cases?\n\n\n\n* In your experiments, what model sizes/dimensions and what streaming rates (data per time unit) did you consider? How would your method scale to large models, long sequence of time‐segments, or high data throughput?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MIxRzyqlVD", "forum": "E9z9jhSjB5", "replyto": "E9z9jhSjB5", "signatures": ["ICLR.cc/2026/Conference/Submission8085/Reviewer_dsCv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8085/Reviewer_dsCv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624964338, "cdate": 1761624964338, "tmdate": 1762920072394, "mdate": 1762920072394, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of online continual learning under real concept drift, where the underlying relationship between inputs and labels evolves over time. Unlike the more common task-incremental setting with static and well-defined tasks, the authors focus on dynamic, non-stationary environments. They introduce a regularization-based method enhanced with a memory buffer to improve robustness against concept drift. The paper provides theoretical analysis demonstrating the advantages of the proposed approach, and experiments across multiple benchmarks further validate its effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The focus on real concept drift rather than the common fixed-task CL is  relevant for practical learning scenarios (e.g., streaming data, non-stationary domains).\n\n\n* This paper provides theoretical analysis for the proposed approach.\n\n\n* The paper presentation is easy to follow."}, "weaknesses": {"value": "* The authors assume that evolving true models (over time) share a common center around which they drift. These assumptions may be unrealistic in many settings where the drift is large or the underlying tasks change drastically.  The paper should discuss whether the proposed method will work if the assumptions fail.\n\n* If the drift is very abrupt (i.e., the new model is far from the previous center) or tasks are entirely unrelated, it is unclear how well the method will perform. The paper may not sufficiently explore worst‐case drift scenarios. Providing deeper analysis would strengthen the paper contributions. \n\n\n\n\n\n* The experiment's evaluations are limited to a few synthetic or small‐scale drift settings; it would be better to evaluate how the method generalises to more complex domains (e.g., large-scale dataset, vision transformer model). This would strengthen the contributions."}, "questions": {"value": "* Could you comment on scenarios where the “true models” do not cluster around a common center? How does your algorithm behave in such cases?\n\n\n\n* In your experiments, how would your method scale to large models, large datasets and long task sequence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MIxRzyqlVD", "forum": "E9z9jhSjB5", "replyto": "E9z9jhSjB5", "signatures": ["ICLR.cc/2026/Conference/Submission8085/Reviewer_dsCv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8085/Reviewer_dsCv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624964338, "cdate": 1761624964338, "tmdate": 1763664103505, "mdate": 1763664103505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies online continual learning when the input stream stays roughly the same but the label rule changes over time (“concept drift”). The authors assume that most tasks are actually very similar to one hidden “center” model, and only a small portion can be different. On top of that, they propose an objective that learns from the current data, from a replay buffer, and at the same time pulls everything toward the shared center. They also add an online step that, at the start of each task, tries a few regularization strengths and picks the one that fits this task best. They give a generalization bound under this “all tasks are close to one center” setting, and they show experiments on synthetic data and on a medical dataset where the method beats common continual-learning baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Clear and tidy formulation that connects replay-style and regularization-style continual learning.\n\n2.Explicit assumption about how similar tasks are, which many CL papers do not write down.\n\n3.Practical online tuning step, so we do not have to hand-tune for each task.\n\n4.Analysis that clearly shows how task similarity, buffer size, and regularization strength matter."}, "weaknesses": {"value": "1.The intro sounds general, but the method and theory only work when almost all tasks are variants of the same model.\n\n2.The key assumption appears too late in the paper.\n\n3.The objective keeps three sets of parameters, even though in the end we only keep the shared one; this needs a clearer justification or an ablation.\n\n4.The weights between old data and new data only depend on how many samples we have, not on how different they are, which is odd for drift.\n\n5.The online tuning step seems to assume we know when a new task starts.\n\n6.The replay buffer is “blind” to the shared center; a center-aware buffer would match the story better.\n\n7.Theory is for the easiest case (all tasks close), not for the mixed case (some tasks far).\n\n8.Synthetic experiments are built exactly the way the assumption says, so the results are a bit circular.\n\n9.No baselines from the concept-drift community."}, "questions": {"value": "1.You claim “real concept drift,” yet assume a single latent center with (ε,δ)-related tasks. Are you actually studying center-constrained drift? If so, shouldn’t the title/intro say so explicitly, and why is this subclass representative of “real” drift in practice?\n\n2.Why is the central (ε,δ)-related assumption only introduced in Sec. 3? Could you front-load it in Sec. 1 and state applicability limits—e.g., which common drifts (directional, periodic, multi-center) are out of scope?\n\n3.Relative to OMTL/Lifelong learning with shared structure, is the novelty the integration (shared center + replay + online tuning) or a new form of sharing itself? Can you position this explicitly to avoid over-claiming originality?\n\n4.If the final output is θ, why not optimize a θ-only objective that blends past and current losses? What is the operational gain of explicit ω_past and ω_t—different λ/optimizers only, or real performance gains? Any θ-only ablation?\n\n5.Under strong drift, shouldn’t small fresh data outweigh large stale data? Why are a1,a2 purely count-based instead of similarity/drift-aware? Can Sec. 3.2’s pseudo-validation scores feed into (a1,a2) for a coherent stability-plasticity trade-off?\n\n6.Alg. 2 uses the first B samples as pseudo-validation—does this assume known task boundaries? If boundaries are unknown or intra-task drift exists, do you need sliding windows/change-point tests/periodic re-tuning? What’s the runtime vs. |Λ| and B?\n\n7.If the core idea is contraction toward θ, why keep θ-agnostic reservoir sampling? Could you test θ-aware buffering (e.g., gradient alignment, center/outlier discriminability, core-set selection) and show effects on the stability–plasticity trade-off?\n\n8.The main bound targets ε=0. For ε>0, how do errors scale with ε, δ, M, λ? Can you provide a relaxed bound or at least a “graceful degradation” analysis (to which baseline do we regress, up to what ε is it robust)?\n\n9.Synthetic setups mirror the single-center assumption. Under directional drift, two-center switching, periodic re-occurrence, or subspace-local drift, do you still beat ER/EWC/AGEM? Any stress tests that violate the assumption and profile failure modes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Dtz89sXQD2", "forum": "E9z9jhSjB5", "replyto": "E9z9jhSjB5", "signatures": ["ICLR.cc/2026/Conference/Submission8085/Reviewer_P1H5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8085/Reviewer_P1H5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816336031, "cdate": 1761816336031, "tmdate": 1762920072046, "mdate": 1762920072046, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}