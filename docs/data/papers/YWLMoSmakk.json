{"id": "YWLMoSmakk", "number": 24893, "cdate": 1758361647094, "mdate": 1759896743428, "content": {"title": "CR-Guided Transformers: Coherence-Based Redundancy Identification and Regularization", "abstract": "Current Transformer-based language models demonstrate excellent performance across various tasks. However, these models commonly produce redundant transformations in middle-to-deep layers. This manifests as transformations between the inputs and output in a layer containing pronounced linear correlation or near irrelevance components. This paper attributes its root cause to current training paradigms. These paradigms emphasize prediction accuracy while neglect the effectiveness of nonlinear transformations in model layers. Based on this observation, we propose criteria for identifying redundant transformations. To quantify the degree of redundancy, we further propose a Coherence-based Redundancy (CR) measure. Specifically, we treat the input and output of a model layer as sequence distributions. We leverage characteristic functions and Fourier transform to map the distributions to frequency-domain representations. Finally, we compute coherence in the complex plane and assess the effectiveness of transformations on a [0,1] coherence scale. To suppress redundant transformations at layer outputs, we propose two schemes: tree-structured residual paths and a coherence-based redundancy loss. These approaches guide middle-to-deep layers to produce effective transformations. At the same time, they supervise and regularize against redundant outputs. Our pre-training experiments on Llama3-130M with 12 layers demonstrate that the proposed methods significantly reduce redundant transformations. With training settings held constant, we successfully make the 12-layer model outperform the 14-layer baseline.", "tldr": "", "keywords": ["Redundancy Identification", "Coherence-based Redundancy measure", "Redundancy Regularization"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/91c3857fdd5f850e1c9ee98e384c8d1956534b8e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tries to address the problem that layers in mid-to-deep layers don't do too much anymore. The motivation is to make better use of the model parameters.\n\nSome additional residual connections are introduced: tree-structured residual path, which effectively reduces the total depth, to more directly connect to mid-to-deep layers.\n\nA new kind of regularization is introduced, based on the coherence between input and output of a layer. The coherence is measured in a differential way, and you specify a wanted target coherence, and then the squared difference between target coherence and actual coherence is added as an auxiliary loss for better regularization. \n\nLlama3-130M is used as the baseline for experiments, with 12 layers and 14 layers. It is trained on a subset of 11B token of The Pile. Evaluation is done via perplexity on some eval set.\n\nThe tree-structured residual path seems to contribute mostly to the performance, while the additional regularization only gives small improvements. It seems that a 12 layer model with that extra tree-structured residual path and the regularization slightly outperforms a 14 layer baseline model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* New tree-structured residual path.\n* New regularization method.\n* Some analysis of coherence of different layers."}, "weaknesses": {"value": "* The presentation has many issues (see questions/comments below).\n* Training speed / overhead for the tree-structured residual path not measured / reported.\n* Training speed / overhead for the additional regularization not measured / reported.\n* The experiments are way too limited. This is by far the biggest issue.\n  * 20k iterations is way too little training.\n  * Models are way too small.\n  * Model size variations / scaling law studies missing.\n  * Other (more relevant) model types not studied, e.g. Transformer++.\n  * Evaluation not done properly, should not just measure perplexity but also other benchmarks.\n  * Ablations way too limited.\n* No code published."}, "questions": {"value": "\"As shown in 1 (a) and 2 (a)\" and many more such examples: It misses some \"Figure\", i.e. \"as shown in Figure 1 (a)\".\n\nAdd equation numbers. That makes it easier to argue about.\n\nIn the def of L_CR, Coherence is not defined. Before, you define Coherence as a function of k, but here, it is not a function of k. What is it?\n\nAlso, in the def of L_CR, you should make proper use of Latex. Use `\\operatorname` or so.\n\nIn the def of L_CR, this is depending on the layer index L? (Btw, capital L is weird for layer index. Capital L is usually the num of layers.) But then, in the final loss, you also use L_CR, but there is no L anymore? So this does not fit together.\n\nLooking at Figure 4, it looks like most of the improvements are because of the tree-structured residual path, while the improvements from the new regularization is minimal?\n\nFigure 4 (a) and Figure 4 (c), why to have them separate and not in a single plot? They look like they should be together? Also, they look extremely similar anyway...\n\nWhat is the training speed overhead for the tree-structured residual path? Or is there any?\n\nWhat is the training speed overhead for the additional regularization? I assume this will be some overhead?\n\n20k iterations is way too little training. Train much longer. Also, train on larger models. Also, train on multiple different sizes, to better see the overall trends. Also, train with other model variants, e.g. Transformer++.\n\nAlso, don't just show perplexity. Do evaluation on some other benchmarks.\n\nThere could be more studies on variants of ways how to measure the coherence. There are many possible other ways how to measure it, e.g. any kind of similarity measure.\n\nFigure 1 (c) is a bit unclear. There is an outgoing arrow for E, 0 and 1. Where does it go? There is an incoming error for 0, 1 and 2. Where does it come from? Just connect all the arrows and don't let me guess on this. Also, I guess you also have the normal residual connections? Just make them all explicit. When you add them up, also make that explicit, by adding an \"+\" node in the graph.\n\nThe exact definition of the model with the tree-structured residual path is not clear for me. Despite Figure 1 (c) (which itself is not totally clear, see above), also write down the exact mathematical definition.\n\nNo code is published?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "."}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IJHOrULdz6", "forum": "YWLMoSmakk", "replyto": "YWLMoSmakk", "signatures": ["ICLR.cc/2026/Conference/Submission24893/Reviewer_UawZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24893/Reviewer_UawZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829893197, "cdate": 1761829893197, "tmdate": 1762943236432, "mdate": 1762943236432, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new transformer architecture using some newly proposed coherence-based redundancy metrics. The idea could compress the 14-layer model to 12 layers and has only been tested on one 130M LLaMA model. The writing is very poor, and the experiments are incomplete. Even the citation format is bad.\n\nThis paper just doesn't match my expectations for an ICLR paper (I actually asked several colleagues and they agree with me). Is this a test from the OpenReview foundation to let human reviewers review AI-generated papers?"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The only strength I could think is the proposed idea might work. But the current experiment is insufficient to prove this."}, "weaknesses": {"value": "1. Please use \\citep{} instead of \\cite{}. The citations of the whole paper are mixed with the main content.\n\n2. The logic is bad. At the very first in the abstract, there are words like \"redundant transformations\", \"nonlinear transformations\", \"Coherence-based Redundancy\", which I just have no idea what they are.\n\n3. The paper seems very redundant itself and is badly structured. The introduction takes up space until half of page 3, but there isn't any section discussion related works?\n\n4. Figure 1 is too simple to convey the research idea. I can understand the proposed tree-structure paths, but cannot get how the training and inference are conducted, and if there are any shared parameters.\n\n5. I did not examine the method section in detail due to time constraints, but the experimental evaluation appears highly incomplete. Using only a 130M LLaMA model and comparing perplexity against the base model itself is insufficient. A more comprehensive set of datasets, tasks, and baseline comparisons is necessary to meet the standards expected for ICLR publications.\n\nWith my full respect, I doubt this paper is AI-generated. It is possible that I just don't have enough background to understand this paper (I know transformers and common ML architectures very well, maybe the coherence-based redundancy topic requires a lot specific knowledge that I don't have yet)."}, "questions": {"value": "N/A\n\nIf there is any human author of this paper, could you let me know?\n\nI don't mean to be harsh, but not checking clear formatting issues before submission is already disrespectful to reviewers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6s8OnhfnEl", "forum": "YWLMoSmakk", "replyto": "YWLMoSmakk", "signatures": ["ICLR.cc/2026/Conference/Submission24893/Reviewer_Y61Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24893/Reviewer_Y61Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862001614, "cdate": 1761862001614, "tmdate": 1762943235752, "mdate": 1762943235752, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the phenomenon seen in many transformer models that layer features often have a high cosine similarity, indicating redundancy and inefficient training. A new measure of redundancy - coherence - is proposed, with the claim that it does a better job in indicating redundancy. A new architecture and training protocol is proposed which uses the coherence measure to control and reduce layer redundancy, resulting in enhanced performance with lower computation costs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper identifies an important shortcoming of current LLMs that of layer redundancy, and proposes a novel measure for indicating the redundancy and a novel training technique and architecture to remedy this problem. \nNon-trivial experiments show that the proposed technique can enhance accuracy of an LLM while reducing computation."}, "weaknesses": {"value": "The proposed approach may be good, but it is not explained very well in the paper. It is not clear why the proposed coherence measure is any better that the cosine similarity for the purpose of measuring and reducing feature redundancy. \n\nline 117: \"We elucidate the criteria for identifying redundant transformations.\" This is also mentioned in the abstract and in the conclusion. But nowhere in the paper is a criteria for identifying redundant transformations clearly defined. Since this is one of the stated contributions it should be very clearly defined in the text somewhere.\n\nline 140: This sentence doesn't make sense, and should be rewritten: \"It is very high that the average cosine similarity of some middle-to-deep transformer layers, as shown in 1 (a).\"\n\nThe notion of redundancy as being indicated by high cosine similarity is imprecise. Even a high (but not 1.0) cosine similarity indicates some difference between the features. It may be that this small difference is useful, or even critical, in performing the task, to represent small but crucial bits of detail distinguishing one class from another. The paper needs to be more precise in specifying what cosine similarity level constitutes an irredeemable redundancy.\n\nline 222: \"Although prior research Men et al. (2024) can simply obtain correlations between features by calculating cosine similarity.\" This sentence is grammatically incorrect and should be rewritten.\n\nline 238: \" Combined with the criteria for redundant transformations...\". What IS the criteria for redundant transformations?\n\nline 278: \"It [coherence] can reveal statistical structural differences after nonlinear transformations more effectively than cosine similarity, which relies solely on directional information. As shown in 1 (a) and 2 (a), in the baseline model the inputâ€“output coherence and the cosine similarity exhibit the same trend from 1 to 10 attention sub-layers\".  The second sentence contradicts the first, as it implies that coherence and cosine similarity give the same result. Why do we need to complicate matters using coherence? Why not just use cosine similarity to measure and control redundancy?"}, "questions": {"value": "It seems that what is not mentioned in this paper, which should be I think, is that layer redundancy also means that training time is being wasted. With large models taking very long times to train, resulting in high costs and resource usage, reducing training time or wasting less training time is an important consideration. I suggest the authors add this to the motivation for their method, as opposed to say pruning which reduces network size but does not reduce wasted training time.\nOf course, one counter-argument is that the issue is not inefficient training, but perhaps the redundancy is due to insufficient training. Would continued training, with new or augmented data force the network to reduce layer redundancy?\n\nLine 77: what proof or evidence is there that distributions are more easily separated in the complex plane?\n\nOn line 156: \"If the residual branch gradient term is too small, the derivative of this layer tends to approach the identity matrix\". But what evidence is there that this gradient term is actually too small? How small is too small?\n\nLine 183: \"this paper is devoted to accurately identifying redundant transformations\". How is accuracy defined here? Is there some ground truth for redundant transformations? If not, how can one talk about accuracy in this context?\n\nLine 237: \"And frequency-domain coherence is more analytical.\" What is meant by \"analytical\" here? With regard to complex signals, analytic refers to complex-valued signals with no negative frequency components.\n\nLine 286: \"Combined with the criteria for redundant transformations, it can be inferred as follows. When coherence approaches 0, it indicates invalid feature transformation. And when coherence approaches 1, it indicates insufficient nonlinear transformation between features.\". Where is the proof of these statements? Why does a coherence of 0 indicate an invalid feature transformation? Why does a coherence of 1 indicate insufficient nonlinear transformation between features? These statements may be true, but there is no proof given."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "u1ni5Sj2ZC", "forum": "YWLMoSmakk", "replyto": "YWLMoSmakk", "signatures": ["ICLR.cc/2026/Conference/Submission24893/Reviewer_5Rbt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24893/Reviewer_5Rbt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942407206, "cdate": 1761942407206, "tmdate": 1762943235486, "mdate": 1762943235486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies redundancy in Transformer layers. They formalize two intuitive criteria:\n1. if the input/output have approximately linear correlation\n2. the input/output have almost zero correlation\n\nwhere if one of the above is met, it means that the layer is redundant. \n\nInstead of using cosine similarity as previous work they propose to use characteristic functions and analysis in the frequency domain. The authors also propose to change the residual connection structure in the Transformer based on a tree structure to better model longer range dependencies between layers and redundancy regularization.\n\nMy main concern about this paper is insufficient experimental validation and comparison with alternative pruning techniques."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles an important problem of improving the information efficiency of the Transformer architecture."}, "weaknesses": {"value": "As mentioned above, the authors main experimental validation experiment is in Figure 4. The evaluation is based on perplexity and the authors' approach is only compared with a baseline model. It is essential that the author's also evaluate on downstream tasks/metrics and compare with other alternative techniques for layer pruning e.g. see  Hoefler et al. (https://arxiv.org/abs/2102.00554), Ma et al. (http://arxiv.org/abs/2305.11627), Men et al. (https://arxiv.org/abs/2403.03853) and the references therin."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VNlHy06H6f", "forum": "YWLMoSmakk", "replyto": "YWLMoSmakk", "signatures": ["ICLR.cc/2026/Conference/Submission24893/Reviewer_6rSa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24893/Reviewer_6rSa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762221851582, "cdate": 1762221851582, "tmdate": 1762943235157, "mdate": 1762943235157, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}