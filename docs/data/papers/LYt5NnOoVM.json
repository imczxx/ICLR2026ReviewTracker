{"id": "LYt5NnOoVM", "number": 15509, "cdate": 1758252113951, "mdate": 1759897302197, "content": {"title": "Language Specific Knowledge: Do Models Know Better in X than in English?", "abstract": "Often, multilingual language models are trained with the objective to map semantically similar content (in different languages) in the same latent space. In this paper, we show a nuance in this training objective, and find that by changing the language of the input query, we can improve the question answering ability of language models. Our contributions are two-fold. First, we introduce the term Language Specific Knowledge (LSK) to denote queries that are best answered in an \"expert language\" for a given LLM, thereby enhancing its question-answering ability. We introduce the problem of language selection---for some queries, language models can perform better when queried in languages other than English, sometimes even better in low-resource languages---and the goal is to select the optimal language for the query. Second, we introduce simple to strong baselines to test this problem. Additionally, as a first-pass solution to this novel problem, we design LSKExtractor to benchmark the language-specific knowledge present in a language model and then exploit it during inference. To test our framework, we employ three datasets that contain knowledge about both cultural and social behavioral norms. Overall, LSKExtractor achieves up to 10% relative improvement across datasets, and is competitive against strong baselines, while being feasible in real-world settings. Broadly, our research contributes to the open-source development of language models that are inclusive and more aligned with the cultural and linguistic contexts in which they are deployed.", "tldr": "We show that using different languages to ask questions elicits different answers, and exploit that to improve the question-answering ability of language models.", "keywords": ["Multilingual reasoning", "strategic behavior", "language modeling"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b7839ed1a22afe00c80c0ab7933e76bbf905645a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "# High-level summary\n\nThe authors tackle the problem of LLMs having specific knowledge / better capabilities in specific languages, which they term as Language Specific Knowledge (LSK). LSK is derived by claiming that LLMs perform better on question-answering tasks (QA) in specific languages (like English) as opposed to other languages. \n\n# Contributions \n\nTheir proposed contributions surrounding LSK has two parts - given a set of candidate languages: \n\n## Part 1 (Train-time): \n\ni) the query $Q^{train}$ is embedded and clustered using kmeans; ii) for each query in each cluster and each language $l \\in L$, accuracy of the LLM is calculated and mean accuracy is calculated for the cluster per language; iii) Best language per cluster is determined. \n\n## Part 2(Test-time):\n\nEach test query is assigned the nearest cluster, and the language associated with that cluster from train time is used to get the final answer. \n\n# Results\n\nThe authors experiment on three datasets: CultureAtlas, BLEnD, and Social IQa, all being/reformatted to match Multiple QA style benchmark setting and report classification accuracy.\n\n1. There is a clear result in the claim that there is/are languages that perform better from Figure 3 and other previous works cited in the paper.\n2. From Figure 3, it seems like Qwen3's family of models benefits the most from the proposed methods, other models less so (hypothesis: RL-post-trained family of models differing from the others)\n3. All models are poorly self-calibrated in general to know which language they know best.\n4. Distribution of the selected languages seems uniform in two datasets, but the third dataset (CultureAtlas) has wildly different distributions (which is an interesting result)."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "# Strengths\n\n1. The paper is clearly written and easy to follow. Props for providing the code.\n2. Clear experiments and ablations - the baselines seem well designed and performed."}, "weaknesses": {"value": "# Weaknesses\n\n1. The approach doesn't seem too different from [1] (cited in the paper). In [1], the authors train to classify whether a given task config and other runtime configs would work well by creating an embedding and show similar robustness to OOD tasks. Similarly, in this work, the authors first assign the query to some cluster whose best language is already known. Arguably, adding a new language here requires recomputing accuracies, as opposed to one that can be learnt online. Another visible difference is that the former method in [1] supports a lot of languages at query time, which this method would seem to require another mapping iteration. Lack of discussion comparing clear improvements, differences, and advantages/disadvantages seems critical. \n2. No hyperparameters, confidence intervals/error bars, or sensitivities of the result mentioned anywhere. For example, the robustness result can also be inferred to mean that multiple language distributions are very closely related, where any choice would have yielded similar results, which would indicate a one-to-many mapping for the right set of configurations. Similarly, the impact of temperature seems critical which is not mentioned anywhere. Lack of these details and analysis surrounding them makes the observations questionable.\n3. Control for thinking - in models like Qwen3, the _thinking_ mostly happens in English / Chinese; it is unclear how the authors control for thinking language/behavior and what the effect of language is in these models when thinking is enabled / disabled. \n4. performance cost - another missing metric is the training cost to perceived benefit. Assuming each input and output token has a constant cost, from Figure 3, it appears that calibrating the LLMs to choose the best language would yield the best cost-to-performance ratio. There is a paragraph on Pg. 9 that very briefly discusses this, but it seems like this warrants its own specific subsection in the main content/appendix. \n\n\n[1] S. Kumar, V. Balloli, M. Ranjit, K. Ahuja, S. Sitaram, K. Bali, T. Ganu, and A. Nambi. Bridging the language gap: Dynamic learning strategies for improving multilingual performance in llms. In O. Rambow, L. Wanner, M. Apidianaki, H. Al-Khalifa, B. D. Eugenio, and S. Schockaert, editors, Proceedings of the 31st International Conference on Computational Linguistics, page 9209â€“9223, Abu Dhabi, UAE, Jan. 2025. Association for Computational Linguistics. URLhttps://aclanthology.org/2025.coling-main.619/."}, "questions": {"value": "same as the weaknesses. I'm willing to update the score based on answers / clarifications to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AthzHm5ORN", "forum": "LYt5NnOoVM", "replyto": "LYt5NnOoVM", "signatures": ["ICLR.cc/2026/Conference/Submission15509/Reviewer_SyK3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15509/Reviewer_SyK3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761527401640, "cdate": 1761527401640, "tmdate": 1762925795998, "mdate": 1762925795998, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This study propose a method to QA task - measuring the ability of the LLMs by changing the language of the input query. \nIt introduces the teram \"Language Specific Knowledge (LSK)\" to denote question that are best answered in an *expert* language for an LLM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper formalizes \"Language Specific Knowledge (LSK)\"\" that some queries are better answered when the model reasons in a particular \"expert language\" and turns it into a concrete language-selection problem. The proposed two-stage LSKEXTRACTOR (map LSK via clustering and pick expert language at inference) is simple and well-motivated."}, "weaknesses": {"value": "- While two step-process is well-motivated, however, it is not very much clear why clustering was needed as in these datasets QAs are language specific already. Is it that find to create/find a cluster that represent an expert for a language? \n- The CultureAtlas binary -> MCQ reformulation is sensible how distractors/other options are generated is not clear.  \n- Queries/questions are translated, however, not manual verification (even on small samples) is provided. \n\nTypos/Grammatical/Minor issues\n- The math notation for CoT reasoning is not clear, it is conditioned with l. Any other notation can be used to define CoT. \n- L187: I assume queries also belongs to l."}, "questions": {"value": "- L150: What was the reason for translation? As mentioned in the weaknesses, datasets are already language specific, therefore, it is not clear why translation was needed?\n- L184: What is the reason to embed the English version only?\n- - What is the reason for majority voting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RhnNJqlZL4", "forum": "LYt5NnOoVM", "replyto": "LYt5NnOoVM", "signatures": ["ICLR.cc/2026/Conference/Submission15509/Reviewer_8FzN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15509/Reviewer_8FzN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762061714034, "cdate": 1762061714034, "tmdate": 1762925795566, "mdate": 1762925795566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work analyses phenomenon in which multilingual large language models process questions with identical meanings differently across languages, proposing the concept of Language-Specific Knowledge (LSK). The core assumption of LSK is that within large language model some languages contain more information about certain knowledge regions than others. To do this authors propose a method called LSKExtractor. During training, the model builds semantic embedding clusters, and during inference it uses these clusters to generate answers in the language that demonstrates best performance. The authors shows through experiments on 9 models and 3 datasets that language choice can enhance the model performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- A novel approach to enhance model performance by leveraging the language that yields best results rather than suppressing the use of other languages.\n- The method can improve the performance in a straightforward way, without any additional training."}, "weaknesses": {"value": "- The choice of expert language varies significantly depending on which dataset is used training the LSK map. In Figure 5, CultureAtlas results in diverse language selection, while BLEnD and Social IQa predominantly select English.\n- The paper does not address how to evaluate open-ended prompts that cannot be evaluated using accuracy. In real-world scenarios prompts are far more diverse in form and intent.\n- The paper focuses only on culturally grounded datasets without testing whether LSK also appears in other domains such as mathematics or coding. Adding experiments in these domains would help verify generality of the approach."}, "questions": {"value": "- Which embedding model was used? The paper does not specify which embedding model was employed.\n- Chinese is likely selected because it constitutes for a large portion of the training data, but why was Portuguese chosen as an expert language?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mJP0e29OQj", "forum": "LYt5NnOoVM", "replyto": "LYt5NnOoVM", "signatures": ["ICLR.cc/2026/Conference/Submission15509/Reviewer_akTQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15509/Reviewer_akTQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135717026, "cdate": 1762135717026, "tmdate": 1762925794945, "mdate": 1762925794945, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}