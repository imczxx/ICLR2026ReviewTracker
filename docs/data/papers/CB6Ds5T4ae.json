{"id": "CB6Ds5T4ae", "number": 9782, "cdate": 1758140172723, "mdate": 1759897697177, "content": {"title": "RADAR: Reasoning–Ability and Difficulty-Aware Routing in Language Models", "abstract": "Reasoning language models have demonstrated remarkable performance on many challenging tasks in math, science, and coding. Choosing the right reasoning model for practical deployment involves a performance and cost tradeoff at two key levels: model size and reasoning budget, where larger models and higher reasoning budget lead to better performance but with increased cost and latency. In this work, we tackle this tradeoff from the angle of model configuration routing for different queries, and present RADAR (Reasoning–Ability and Difficulty-Aware Routing), a lightweight, interpretable, and scalable routing framework. Inspired by psychometrics, RADAR learns an item response model from model responses with different budgets to different queries, with interpretable parameters including query difficulties and model-budget abilities. RADAR then routes queries with higher difficulty to model-budget pairs with higher ability, and vice versa. We conduct extensive experiments on 8 widely used challenging reasoning benchmarks, demonstrating the superior performance of RADAR compared to state-of-the-art model routing methods. RADAR also exhibits query generalization capabilities, showing strong performance on out-of-distribution queries in all benchmarks. RADAR is also scalable and can efficiently integrate additional models, by dynamically selecting a small set of evaluation queries to estimate their abilities.", "tldr": "", "keywords": ["routing", "adaptive reasoning", "item response theory", "reasoning models", "large language models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1f0b2c7053c297e576f89924ef188155926c2d48.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work considers the problem of query-based routing reasoning language models (RLM) with variable budget. \nThe authors here formulate such problems into multi-objective optimization (MOO) paradigm with certain scalarization (linear/Chebyshev) for both performance and cost. \nThe MOO's variables include 1) model-budget configuration and 2) query difficulty.\nModel-budget configurations are (model, token) pairs with reasoning token count discretized and the authors propose to leverage IRT (item response theory) to learn the difficulty/discrimination projector with a frozen embedding model and a model-configuration _ability_ parameter to maintain both interpretability (low parameter) and low latency during inference.\n\nThis paper is well written and the idea is well presented with good motivation and strong results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Well-motivated: authors propose a method to achieve pareto frontier in terms of performance vs. cost in the case of multiple RLMs with varying size and reasoning budgets. This is a very realistic scenario and could be rather impactful. In addition, the proposed method is easy to adapt to any sort of models as they are treated as black boxes and readily extensible to newer and hopefully stronger or faster models.\n2. Good performance: the authors compare RADAR against IRT Router and RouterBench and a couple of heuristics and show that RADAR achieves better hypervolume metric.\n3. Fast: for each inference (unseen) query, RADAR performs an embedding step through an embedding model and a proposed linear projector to get the difficulty/discrimination scalars and feed these 2 scalars into the IRT model. This is rather fast in comparison to the later pipeline considering the number of parameters and reasoning budget of the following models.\n4. Interpretability: IRT model only has two parameters (difficulty & discrimination in terms of input query) which affords natural interpretability."}, "weaknesses": {"value": "The IRT model used in the paper assumes monotonicity, and the projectors are linear with the input embedding model frozen. I know it is probable that using a more complex model could result in a mere marginal improvement in terms of hypervolume, but would like to see some results in this regard. So is the case with the IRT model"}, "questions": {"value": "Same as weaknesses, would love to see some experiments on some more capable difficulty/discrimination projectors or a bit more complex model than IRT. While it is very reasonable and probable to end up with the conclusion that these more complicated model could obfuscate the interpretability and spike up latency while yielding only marginal performance, it will further strengthen the argument for RADAR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fB6sJaDdf6", "forum": "CB6Ds5T4ae", "replyto": "CB6Ds5T4ae", "signatures": ["ICLR.cc/2026/Conference/Submission9782/Reviewer_LEBC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9782/Reviewer_LEBC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9782/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635139473, "cdate": 1761635139473, "tmdate": 1762921267990, "mdate": 1762921267990, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RADAR (Reasoning–Ability and Difficulty-Aware Routing), a lightweight and interpretable routing framework that optimizes the trade-off between performance and cost when deploying reasoning language models (RLMs) with varying model sizes and reasoning budgets.\nRADAR draws inspiration from Item Response Theory (IRT) in psychometrics to estimate query difficulty and model-budget ability. Using these interpretable parameters, it routes easier queries to cheaper, smaller models and harder ones to more capable configurations. The authors formalize routing as a multi-objective optimization (MOO) problem balancing performance and cost via linear and Chebyshev scalarization.\nExperiments across 8 reasoning benchmarks (AIME, MATH-500, GPQA, LSAT, MMLU, MMLU-Redux, MMLU-Pro, FRAMES) demonstrate that RADAR achieves superior performance-cost Pareto efficiency, generalizes well to out-of-distribution queries, and scales effectively when adding new models. It operates in real-time with ~7 ms routing latency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "First to frame reasoning model routing as a Multi-Objective Optimization (MOO) problem. Innovative use of Item Response Theory for modeling reasoning ability and query difficulty, an elegant and interpretable alternative to opaque routing regressors.\n\nThe methodology is rigorous, combining psychometric modeling with MOO and cost modeling in a consistent mathematical framework.\nExperiments are extensive, covering 8 benchmarks and both in-distribution (ID) and out-of-distribution (OOD) settings, with clear comparisons to baselines such as RouterBench and IRT-Router.\n\nThe paper is very well written and structured, with clear motivation.\n\nThe work offers a generalizable and practical approach for efficient LLM deployment under cost constraints."}, "weaknesses": {"value": "1. While RADAR clearly outperforms IRT-Router and RouterBench, the paper does not compare against mixture-of-experts or test-time adaptation methods that could serve as strong baselines for dynamic routing under cost constraints.\n2. More discussion on relation to cascading methods (e.g., FrugalGPT) would strengthen the positioning.\n3. Although latency is reported (~7 ms), no end-to-end system-level throughput analysis is provided. \n4. Some OOD performance dips (e.g., AIME benchmark) suggest the need for improved handling of unseen high-difficulty queries.\n5. The model for estimating difficulty is too simple and may not capture the real question difficulty."}, "questions": {"value": "Check weakness above.\n1. A comparison/discussion with previous works on selecting the best answer from different LLMs would have been useful for latency. \ni. Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems.\nii. Scalable best-of-n selection for large language models via self-certainty. \n2. Which embedding model was used to represent queries?\n3. Could RADAR dynamically adjust the user weight w₁ during a session (based on feedback or budget exhaustion) to continuously optimize global cost-performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cC7FC9cuXW", "forum": "CB6Ds5T4ae", "replyto": "CB6Ds5T4ae", "signatures": ["ICLR.cc/2026/Conference/Submission9782/Reviewer_EkVW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9782/Reviewer_EkVW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9782/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952572520, "cdate": 1761952572520, "tmdate": 1762921267664, "mdate": 1762921267664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors proposed RADAR (Reasoning–Ability and Difficulty-Aware Routing), a lightweight, interpretable, and scalable routing framework. They firstly show with statistics that reasoning models today struggle to balance between performances and budgets. The authors then proposed to model this problem as a multi-objective optimization problem. With extensive evaluations on multiple benchmarks, the authors showed that their methods are superior to other methods, and the advantage could generalize to new RLM settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and nicely presented.\n2. The method the authors proposed is simple, yet more reasonable to generalize."}, "weaknesses": {"value": "1. The authors did not well explain their experimental results. For example, the gain looks marginal on some benchmarks while significant on others. The authors could help readers better understand why the biases exist."}, "questions": {"value": "1.As I said above, could you give an explanation of your results?\n2. The cost function looks simple. For example, how can RADAR incorporate real-time latency, KV-cache reuse, or batching discounts into its cost function?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eFOaZ5Ce1a", "forum": "CB6Ds5T4ae", "replyto": "CB6Ds5T4ae", "signatures": ["ICLR.cc/2026/Conference/Submission9782/Reviewer_aypQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9782/Reviewer_aypQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9782/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982666978, "cdate": 1761982666978, "tmdate": 1762921267310, "mdate": 1762921267310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for the reasoning language model (RLM) routing problem, which aims to select the best RLM configuration for an input query, given a pool of RLMs,  the reasoning budget, and a user performance-cost trade-off profile. It leverages an item response theory model to estimate the query difficulty and RLM ability at different reasoning budget, by parameterizing the query difficulty and training on collected evaluation responses. Under the user performance-cost trade-off profile, it uses multi-objective optimization to find the Pareto optimal of model configurations, which is also empirically shown to be effective."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The problem setting of user-desired performance-cost trade-off profile is interesting and practical.\n- The proposed approach of modeling query difficulty and solving the multi-objetive optimization problem is reasonable.\n- RADAR can generalize to OOD queries.\n- Comprehensive empirical evaluation on different benchmarks."}, "weaknesses": {"value": "- Limited technical novelty against the baseline IRT-Router with conceptually similar approach of leveraging IRT.\n- It is not convincing that using a linear transformation on the embedding of questions could successfully model the underlying difficulty of the question. Using a more expressive parameterization would  intuitively give a better results given the high dimensionality of the embedding. However, no ablation has been shown to justify the linear transformation is sufficient.\n- The empirical gains are limited based on the results from Table 1, 2. The evaluation method CPT with only one threshold (i.e., CPT(90%)) is not convincing. More evaluation threshold should be shown to justify its effectiveness under different desirability.\n- Typos. E.g., there is a missing “running” before “configuration” in line 196.\n- Sec. 3.5 depends on a small set of evaluation queries, which can be adaptively updated. However, whether this set (queries with high Fisher information) approximates the global data distribution Q is unclear. Ablations on how this approach differs from uniform sampling or simply estimation from historical observations would be helpful."}, "questions": {"value": "See weaknesses  above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AeLC845er9", "forum": "CB6Ds5T4ae", "replyto": "CB6Ds5T4ae", "signatures": ["ICLR.cc/2026/Conference/Submission9782/Reviewer_St66"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9782/Reviewer_St66"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9782/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990866862, "cdate": 1761990866862, "tmdate": 1762921266878, "mdate": 1762921266878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}