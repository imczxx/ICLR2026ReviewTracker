{"id": "lXSrulux48", "number": 20298, "cdate": 1758304538497, "mdate": 1759896985413, "content": {"title": "Byzantine-Robust Federated Learning with Learnable Aggregation Weights", "abstract": "Federated Learning (FL) enables clients to collaboratively train a global model without sharing their private data. However, the presence of malicious (Byzantine) clients poses significant challenges to the robustness of FL, particularly when data distributions across clients are heterogeneous. In this paper, we propose a novel Byzantine-robust FL optimization problem that incorporates adaptive weighting into the aggregation process. Unlike conventional approaches, our formulation treats aggregation weights as learnable parameters, jointly optimizing them alongside the global model parameters. To solve this optimization problem, we develop an alternating minimization algorithm with strong convergence guarantees under adversarial attack. \nWe analyze the Byzantine resilience of the proposed objective.\nWe evaluate the performance of our algorithm against state-of-the-art Byzantine-robust FL approaches across various datasets and attack scenarios. Experimental results demonstrate that our method consistently outperforms existing approaches, particularly in settings with highly heterogeneous data and a large proportion of malicious clients.", "tldr": "We propose a Byzantine-robust federated learning method that jointly learns aggregation weights and model parameters, outperforming existing methods under heterogeneous data and strong attacks.", "keywords": ["Federated Learning", "Byzantine Robustness", "Distributed Optimization"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c3af8dc1e5f9b3fb5b456be29cd6ea249a60eacc.pdf", "supplementary_material": "/attachment/4bfe4c4ca203c829f027be01fd22e169a8b3cb20.zip"}, "replies": [{"content": {"summary": {"value": "This paper uses an alternating minimization algorithm with strong convergence guarantees to address Byzantine attacks in FL. This method treats aggregate weights as learnable parameters and optimizes them jointly with global model parameters. Furthermore, the paper conducts experiments on various datasets and attack scenarios, and provides theoretical and convergence analysis of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is highly clear. The methods section provides sufficient proof and comprehensive theoretical analysis.\n2. The appendix provides detailed information and experimental results supplementing the main text. The paper is highly comprehensive and logically organized. The experimental setting includes five different attack methods and various heterogeneous conditions.\n3. The paper proposes learnable aggregation weights, providing a new approach to addressing the convergence problem of equal-weighted average damage."}, "weaknesses": {"value": "1. Whether learnable aggregation weights increase the weight of byzantine clients and thus increase attack risk is lacking theoretical analysis and experimental proof.\n2. The experimental datasets used are MNIST and CIFAR10. Both datasets contain only 10 classes, which cannot demonstrate the effectiveness of the method on more complex dataset.\n3. In the main text, the method and theoretical analysis section of the paper lacks a figure explaining the pipeline, which increases the reading difficulty."}, "questions": {"value": "1. I'd like to know the specific experimental results of the algorithm on more complex datasets, such as CIFAR100 and TinyImageNet, which contain more classes.\n2. Would learnable aggregation weights exacerbate attacks by byzantine clients tricking the server into learning higher weights? I recommend that the paper provide theoretical analysis of this scenario."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uuGcx2zLxi", "forum": "lXSrulux48", "replyto": "lXSrulux48", "signatures": ["ICLR.cc/2026/Conference/Submission20298/Reviewer_YUPN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20298/Reviewer_YUPN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840530924, "cdate": 1761840530924, "tmdate": 1762933767432, "mdate": 1762933767432, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Byzantine robust federated learning algorithm where aggregation weights are learnt jointly with the model parameters via a nested optimization formulation. A Byzantine resilience analysis is provided, along with a convergence analysis. Experiments on MNIST and CIFAR-10 datasets show that the method outperforms baselines robust aggregations under varying heterogeneity scenarios, and for different Byzantine attacks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The method seems novel and provides a new avenue for research on Byzantine robustness. \n- The algorithm intuition is clearly described, and many details are given on how to implement the algorithm in practice. \n- The added computation and communication complexities are discussed in details, which is appreciated. \n- The theoretical analysis is provided for the both the cases when only the sent gradients are corrupted and when also the sent loss evaluations are corrupted (even though only the latter truly matters)."}, "weaknesses": {"value": "1. It seems to me there is something conceptually wrong with the proof, precisely when decomposing the error in part E3. The bound between $F$ and $\\tilde{F}$ assumes that the same byzantine clients will be selected by the aggregation for either the mini-batch or full gradients. This is wrong.\n2. It also seems that the proof uses the exact minimum of equation (6), whereas the algorithm provides an approximation through the first order decomposition. \n3. The theoretical results are not compared with baseline methods. Previous works such as [1] show robust methods that achieve the lower bounds, it is not clear how the presented method improves on those.\n4. I do not agree with Remark 1 of the authors. Comparing the performance based on the total number of communication rounds is not fair.\n5. Assumption (C) on Stochastic Gradient Model is not standard. Why isn’t the standard upper bound on the variance of the SGD noise (which seems to be used as inter-client variance in D1) enough for the guarantees ?\n6. The Byzantine resilience guarantees are given probabilistically, which is highly non-standard in the literature. Compared to state-of-the-art Byzantine robust methods, no fundamental randomization is added by the FedLAW algorithm that would justify probabilistic bounds.\n7. 321  “in practice $\\epsilon_k$ is typically very small even under a high heterogeneity” the authors do not provide any justification for this statement.\n8. 320 “Similarly, assuming bounded heterogeneity is a standard prerequisite for any non-IID analysis.” Can the authors please provide references for this ? The Magnitude Heterogeneity part does not look standard.\n9. In Table 7, the accuracy scores on CIFAR-10 seem abnormally high (reaching even 100% with backdoor attacks). \n\n**Minor issues**\n\n- Theorem 2 does not specify the choice of s and t (which are specified only in the proof in the appendix)\n- Shouldn’t the sparse unit capped operator be noted $\\Delta_{t,s}$ instead ?"}, "questions": {"value": "1. Is there any reason why the probabilistic framework is necessary for the resilience results ?\n2. It is not clear to me what the $g_i$s represent. The expectation on $v_{i,t}$ is taken with respect to what ?\n3. In 170, the authors claim that the method conceptually favors clients whose gradients align with the descent direction of $f_i(\\theta_k - \\alpha  G_k w)$. I believe this intuition needs to be explained further, as it is not clear why this should be the case ? Why does the descent direction of one single client matter ?\n4. In the experiments, why is the performance in the case of no defense almost the same as the other robust aggregation rules for many attacks and heterogeneity levels (and sometimes it is even better than some defenses)?\n5. As multiple local steps are shown to improve the performance in FL (including Byzantine robustness), can the method be extended to support multiple local steps ?\n\n**Minor questions**\n- Isn’t it possible to link $L_w$, the smoothness coefficient of $\\Phi_k$ to $L_{max}$ ?\n- What is the point of Theorem 7 ?\n- 270 $G_k^i$ is not defined. $v_{k,i}$ is defined in 253 as the full batch gradient"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZtOYKB6U4C", "forum": "lXSrulux48", "replyto": "lXSrulux48", "signatures": ["ICLR.cc/2026/Conference/Submission20298/Reviewer_LuYw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20298/Reviewer_LuYw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912563890, "cdate": 1761912563890, "tmdate": 1762933767030, "mdate": 1762933767030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FedLAW, a Byzantine-robust federated learning method that treats client aggregation weights as learnable parameters, jointly optimized with the global model. The key contributions are:\n\nA novel optimization problem formulation incorporating adaptive aggregation weights with sparsity constraints to exclude malicious clients.\n\nAn alternating minimization algorithm with theoretical convergence guarantees under adversarial settings.\n\nComprehensive theoretical analyses demonstrating Byzantine resilience and convergence properties.\n\nExtensive experiments on MNIST and CIFAR-10 under various attack scenarios and non-IID data settings, showing FedLAW outperforms state-of-the-art methods, especially under high heterogeneity and malicious client ratios."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper presents a genuinely novel approach to Byzantine-robust federated learning by treating aggregation weights as learnable parameters. This isn't just a minor tweak to existing methods—it represents a meaningful shift in how we approach the aggregation problem. The theoretical foundation is particularly impressive, providing not just convergence guarantees but also a detailed Byzantine resilience analysis that clearly explains why the method works. What makes the contribution stand out is how well the empirical results support the theory; the method maintains strong performance even under challenging conditions like 40% malicious clients and high data heterogeneity, which is exactly where many existing methods struggle. The writing is clear and the figures effectively illustrate the method's behavior, especially the weight evolution plots that show how it dynamically identifies and suppresses malicious clients."}, "weaknesses": {"value": "While the method is compelling, it does come with some practical trade-offs. The two-round communication per update is a noticeable overhead, and while the authors argue that faster convergence might compensate for this, the paper doesn't provide a conclusive analysis of the total communication cost compared to alternatives. Some of the theoretical assumptions, like the bounded gradient deviation and heterogeneity bounds, feel somewhat idealistic—in real-world non-IID settings, these assumptions might not hold as neatly. The experimental validation, while thorough on standard datasets, leaves me wondering how the method would scale to more complex problems or different data domains. The hyperparameter selection also seems non-trivial, particularly the sparsity level, which appears to require some knowledge of the malicious client ratio."}, "questions": {"value": "Communication Efficiency: Could the two-round communication be optimized? Can you provide a standardized comparison of total communication rounds versus accuracy?\n\nPracticality of Assumptions: How realistic are assumptions C1 and D1 in real non-IID settings? Are there methods to verify or relax them?\n\nScalability: How does FedLAW perform with a very large number of clients (e.g., >1000)? Are there distributed optimization strategies to improve efficiency?\n\nHyperparameter Tuning: Does the selection of $s$ and $t$ rely on prior knowledge of the malicious client ratio? Can these parameters be adapted dynamically?\n\nIntegration with Privacy Techniques: Can FedLAW be combined with differential privacy or cryptographic methods to enhance privacy protection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CpS1STT3UO", "forum": "lXSrulux48", "replyto": "lXSrulux48", "signatures": ["ICLR.cc/2026/Conference/Submission20298/Reviewer_8DwE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20298/Reviewer_8DwE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915765004, "cdate": 1761915765004, "tmdate": 1762933765844, "mdate": 1762933765844, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies proposes an algorithm that can learn the aggregation weights for benign clients in Byzantine attack environment. The idea is novel and is effective in enhancing accuracy after data in Byzantine attackers are ignored. The contributions include both new algorithm in robust federated learning and theoretical analyses for Byzantine resilience and algorithm convergence."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper studies Byzantine adversarial tolerance, which is an important problem in federated learning. \n2. The paper is well written and easy to follow.\n3. The theoretical analysis is rigorous and the experiments are extensive to support the effectiveness of the proposed algorithm."}, "weaknesses": {"value": "1. Figure 1 is not clear, with confusing color to denote different algorithms. \n2. How to enforce sparsity is not discussed, i.e., how to determine how many clients are malicious?"}, "questions": {"value": "1. Did you consider removing the malicious client identify step and automatically learning/assigning low weights to Byzantine clients?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AGPZSY1Mrl", "forum": "lXSrulux48", "replyto": "lXSrulux48", "signatures": ["ICLR.cc/2026/Conference/Submission20298/Reviewer_oBSd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20298/Reviewer_oBSd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762658555532, "cdate": 1762658555532, "tmdate": 1762933765241, "mdate": 1762933765241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}