{"id": "30u4c9soJu", "number": 4724, "cdate": 1757753416931, "mdate": 1759898017683, "content": {"title": "Refine, Don’t Rewrite: LearnFrom for Consistency-Aware LLM Decompilation", "abstract": "Decompilation aims to translate binary executables into high-level source code; yet, the task remains demanding. Traditional tools, such as Ghidra, yield output that is structurally faithful but rarely recompilable or linkable.     Recent methods built upon large language models improve readability and executability. However, unconstrained LLMs exhibit inherent stochasticity, they provide little guarantees of semantic consistency with the originating binary, which forces extensive cross-checking against the disassembly.  We introduce the LearnFrom to address this challenge by leveraging traditional decompiler outputs and treating a code block corresponding to each control-flow graph node as a minimal editable unit to constrain modification scope. This patch generation design limits potential semantic deviations while reducing verification overhead. To achieve better model performance on the patch generation task in the context of decompilation, we further construct an open-source dataset of two million functions with explicit control-flow graph annotations, then use it to fine-tune the DeepSeek-Coder model series for specialized adaptation to the patch generation task. Within the LearnFrom framework, strict preservation of CFG structural consistency is enforced throughout the editing process, ensuring reliable control-flow alignment. Under this constraint, identical base models achieve a 5\\% improvement in HumanEval re-execution rates over baseline systems, with further gains of 8\\% when substituting DeepSeek-Coder V2 followed by re-fine-tuning. These results confirm that CFG-aligned constraints offer the structural reliability essential for large-scale reverse engineering, while still permitting further optimization as foundational models advance.", "tldr": "", "keywords": ["Reverse Engineering", "Patch Generation", "Large Language Models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cae95446136f70c5832855bd9ec886bb45013f0a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper works on binary decompilation. Traditional decompilers like Ghidra preserve structure but seldom produce recompilable output, while recent large language model (LLM) approaches improve readability yet lack semantic consistency with the original binary. The authors propose LearnFrom, a framework that constrains LLM-based code editing using control-flow graph (CFG) nodes as minimal edit units, ensuring structural and semantic alignment. They also introduce a four-million-function dataset with explicit CFG annotations to fine-tune the DeepSeek-Coder models for this task. Experiments show that LearnFrom improves HumanEval re-execution rates by 5% and edit similarity by 6%, with further gains of 8% using DeepSeek-Coder V2 after re-finetuning. These results demonstrate that CFG-aligned constraints enhance the reliability of LLM-driven decompilation, offering a path toward more consistent and verifiable reverse engineering."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a framework for performing fragment-level edits on decompiled code. This approach enables localized modifications within specific code regions, rather than re-editing the entire decompiled output, which helps minimize unintended changes and preserve structural consistency."}, "weaknesses": {"value": "There're few points need to be clarify before making a final decision.\n\n## Clarity and Methodological Detail\nThe paper’s methodology is described in only one page, leaving many critical implementation details unclear. Key questions remain unanswered:\n\nHow exactly are the compilation test and libFuzzer-based fuzzing (mentioned on Page 4, Line 187) integrated into the workflow?\nWhat is the setup process for the compilation and fuzzing environments, especially for complex real-world programs with diverse dependencies?\n\n## Role of Validation Constraints in Code Evolution\nIt is unclear how the two validation constraints (compilation success and fuzzing correctness) guide the iterative refinement process. Are they used merely as binary (pass/fail) signals, or do error messages from the compiler or fuzzer actively inform and steer the code evolution? If the latter, what mechanisms translate these diagnostics into concrete edits?\n\n## Error Localization and Repair Strategy\nThe paper states that code revision operates block-wise, guided by control-flow graph (CFG) node locations extracted via Tree-sitter. However, this raises several concerns:\n\nWhat happens if the decompiled code cannot be parsed by Tree-sitter (e.g., due to syntax errors or unconventional constructs)?\nSince both validation steps require successful compilation, how does the system handle cases where the initial decompiled output is uncompilable?\nIn decompiled code riddled with low-level control-flow artifacts (e.g., goto statements, infinite loops like while(1)), can block-wise editing meaningfully reconstruct high-level, readable logic?\n\n## Mismatch Between Training and Evaluation Data\nThe model is trained on pairs of assembly and original source code, yet the refinement and evaluation are performed on pseudo-code generated by decompilers. This introduces a domain gap: how does a model trained on clean source code generalize to the noisy, often syntactically irregular output of decompilers? The paper does not justify this design choice or analyze its impact."}, "questions": {"value": "Please refer to weakness.\n\nWhere are the code and the models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "03xHzSrFD1", "forum": "30u4c9soJu", "replyto": "30u4c9soJu", "signatures": ["ICLR.cc/2026/Conference/Submission4724/Reviewer_3GE2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4724/Reviewer_3GE2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761357051119, "cdate": 1761357051119, "tmdate": 1762917534156, "mdate": 1762917534156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "a)\tThis paper proposes LearnFrom: a \"Refine, Don't Rewrite\" LLM decompilation framework. The core idea is to use CFG basic blocks as the smallest editable unit, performing constrained patch-style editing of the pseudo-C code generated by traditional decompilers (such as Ghidra/IDA), thereby reducing verification costs while suppressing semantic drift. To improve patch generation capabilities, the authors constructed a four-million-function, CFG-annotated FIM (fill-in-the-middle) corpus and fine-tuned the DeepSeek-Coder family with LoRA to obtain a domain adaptation model (LFM). Under strong CFG consistency constraints, the authors report improvements in both HumanEval-Decompile re-execution rate and edit similarity, with further gains achieved when re-tuning on a v2 base."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a controlled editing approach using structural constraints and version rollbacks effectively suppresses semantic drift and reduces verification costs. \n- The paper construct the training data using CFG and FIM, which is highly targeted."}, "weaknesses": {"value": "- The experimental results lack statistical and uncertainty information, and the analytical details presented are insufficient. Furthermore, the source details, licenses, deduplication, and isolation strategies for the four million functions from the test set need to be more transparent. The dataset may also require more detailed disclosure. While training computing power and duration are reported, the average number of iterations, rollbacks, and fuzz budget during the inference phase are not quantified.\n- The paper does not propose new learning objectives, structured decoders, formal semantic constraints, or verifiable reasoning mechanisms. The so-called \"semantic consistency control\" is essentially implemented by limiting the edit scope and checking branch keyword positions using CFG basic blocks, which is structural anchoring rather than semantic equivalence.\n- The experimental design lacks a strong semantic alignment metric (only compilation and I/O harness pass), making it difficult to support the claim that the modification can reliably preserve semantics. Furthermore, the lack of statistical robustness limits the credibility of the conclusions.\n- The base model (DeepSeekCoder-V2) is relatively out-of-date. More recent open models like Qwen3.\n- The experiments lack more recent baseline models.\n- Please mind the difference between \\citet and \\citep."}, "questions": {"value": "- Can you provide 95% CIs and paired tests for the main comparisons in Tables 1 and 3? This would significantly enhance the confidence of the conclusions.\n- In addition to keyword alignment, have you performed symbolic execution/path equivalence verification on a sampled dataset? If so, please provide the distribution of failure types.\n- How do you ensure the source/licensing and deduplication strategy for the millions of functions are consistent with HumanEval-Decompile and ExeBench? Can you provide more details?\n- What are the average number of iterations/rollbacks and fuzzing time on the earnFrom inference side? Are there any results on the sensitivity of hyperparameters to convergence speed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "54bcroUF6Y", "forum": "30u4c9soJu", "replyto": "30u4c9soJu", "signatures": ["ICLR.cc/2026/Conference/Submission4724/Reviewer_Xcer"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4724/Reviewer_Xcer"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761598369515, "cdate": 1761598369515, "tmdate": 1762917533828, "mdate": 1762917533828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LearnFrom proposes a CFG-constrained “patch generation” framework for LLM-based decompilation. Instead of end-to-end code synthesis, it edits only basic blocks aligned to CFG nodes in decompiler output, with hard checks that branch keywords and block placements remain consistent; compilation and libFuzzer tests guide iterative fixes under a rollback-capped “Version Manager.” They also build a ~4M-function CFG-annotated FIM dataset and LoRA-tune DeepSeek-Coder variants. On HumanEval-Decompile and ExeBench, they report higher “re-execution” (compile+tests pass) rates than several baselines, especially when pairing IDA/Ghidra with their fine-tuned model and fuzzing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "On HumanEval-Decompile, LFMv2+LFW averages 61.17% vs 52.74% for Ghidra+LLM4Decompile-Ref-6.7B; ExeBench rises to ≈25.57%."}, "weaknesses": {"value": "Several comparisons mix different decompilers (Ghidra vs. IDA) and models (Claude, DeepSeek, LLM4Decompile) with/without LearnFrom. It’s hard to isolate the contribution of CFG-scoped editing vs. stronger front-ends; an apples-to-apples grid (same decompiler, same backbone, ±LearnFrom) is only partially shown.\n\nThe best setting yields ≈25% re-execution, which suggests limited practicality for complex, real-world C—this deserves more analysis (failure modes, types/structs handling)."}, "questions": {"value": "Your branch-keyword check ensures if/while presence/placement, but how do you guard semantic equivalence for short-circuiting, switch fall-through, and early returns? Any cases where syntax passes your check yet CFG still changes?\n\nFor large functions, when the raw assembly plus masked code exceed context, what truncation or windowing strategy is used? Any measured failure rate vs. function size?\n\nCould you add rows with the same decompiler and same base model ±LearnFrom (and ±fuzzing) to quantify the isolated contribution, especially on ExeBench?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5a0I0Spi9I", "forum": "30u4c9soJu", "replyto": "30u4c9soJu", "signatures": ["ICLR.cc/2026/Conference/Submission4724/Reviewer_VCtt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4724/Reviewer_VCtt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914790605, "cdate": 1761914790605, "tmdate": 1762917533555, "mdate": 1762917533555, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Rule-based decompilation tools (e.g. Ghidra, RetDec) are accurate in structure.\nRecent LLM-based decompilers generate cleaner code but can change the meaning (semantic drift). This work proposes LearnFrom. This approach:\n- starts with a traditional decompiler output.\n- Lets an LLM edit basic blocks instead of rewriting everything.\n- Uses extensively tooling to improve the verification of each edit (comilation tests, fuzzing, etc).\n\nThe authors fine-tune DeepSeek-Coder with LoRA on 4 million functions annotated with CFG data, using FIM.\n\nUltimately, this improves decompilation results."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- Comprehensive ablation study, this is much appreciated.\n- The code slicer, version control, fuzzying, etc modules are very interesting and useful on their own.\n- Clever, effective use of FIM and LoRA.\n- Comprehensive evaluation."}, "weaknesses": {"value": "- The evaluation can be misleading: re-execution rate does not imply correctness. Any insights or analysis on whether this metric is working well here? \"Semantic fidelity to the original\nprogram is treated as a prerequisite rather than a tunable metric; therefore we do not report editsimilarity scores that earlier studies used for looser, token-level comparisons.\" The emphasis of this work on semantic correctness is appreciated, but isn't this a very strong statement given that you have no formal correctness guarantees? How good are the unit tests?\n- Presentation and writing: Figure 1 is important but impossible to read. Figure 2 is also hard to read should have a caption explaining the figure. The figures in general are hard to read. In the abstract, there are some sentences that are hard to read.\n- Inaccurate representation of related work: For example, Slade \"introduces intermediate-assisted decompilation: it first predicts a pseudo-high-level intermediate representation that captures control-flow edges, then realises the final C code in a constrained decoding step, reducing semantic drift without iterative search\". This is not at all what Slade does. A more accurate description would be the one you used for LLM4Decompile:  \"feeds assembly directly into a model that generates full C code in one pass\". In fact, Slade predates LLM4Decompile. Earlier in the introduction, when you say \" Three dominant paradigms have emerged. First, exemplified by LLM4Decompile-End Tan et al. (2024), feeds assembly directly into a model that generates full C code in one pass\". Here, and BTC [1] and Slade could be cited as earlier examples of this paradigm (in fact, LLM4Decompile cites them). \n\n\n\n\n[1] https://arxiv.org/abs/2212.08950\n\n\n\nOther details:\n- The citations don't have the right format. \n-  “highly preservation\"\n- Occasionally misses articles."}, "questions": {"value": "- What's the exact input the system receives? What assembly format?\n- The code slicer is interesting, can you give more details about its implementation?\n- \"When deciding how to expose the assembly context, we compared two alternatives: (i) indexing\nthe assembly into an external, queryable memory and (ii) injecting the raw assembly directly into\nthe prompt. Because typical functions produce a manageable amount of machine code—and the\nsecond option reduces system complexity—we adopt the direct-injection strategy.\" how would scale this to long basic blocks? E.g., unrolled loops.\n- How does CFG-scoped editing handle obfuscated or optimized binaries where basic blocks don’t map neatly?\n- Will this be open-sourced in any way?\n- How does LearnFrom compare to simpler prompt-only methods (without fine-tuning)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "veMOQNoe7n", "forum": "30u4c9soJu", "replyto": "30u4c9soJu", "signatures": ["ICLR.cc/2026/Conference/Submission4724/Reviewer_9Cji"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4724/Reviewer_9Cji"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4724/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915958301, "cdate": 1761915958301, "tmdate": 1762917533320, "mdate": 1762917533320, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}