{"id": "nrFMGXSGLX", "number": 18749, "cdate": 1758290614989, "mdate": 1759897083308, "content": {"title": "PCAInit: Training-Free Initialization for Image-Based Neural Representations", "abstract": "Implicit neural representations (INRs) have been widely used to model data as continuous functions parameterized by multi-layer perceptrons (MLPs). \nAlthough this approach is effective, it has two major limitations when applied to large-scale data such as video frames: (1) substantial GPU time is required for training and (2) subpar reconstruction quality. \nIn this paper, we tackle these two limitations and investigate three initialization strategies for INR training, using the sinusoidal representation network (SIREN) architecture as a baseline.\nOur first two methods leverage pretrained models, offering higher reconstruction quality at the cost of additional training time. \nFinally, our third method, PCAInit, is a novel training-free initialization approach derived from analyzing the relationship between image space and weight space through principal component analysis (PCA).\nWe show that this method achieves the best overall reconstruction quality without extra training time. For example, on a representative DAVIS 2017 video (bear, 480p), PCAInit improves PSNR by up to +37.1\\% over SIREN and +26.7\\% over meta-learned initialization, and also achieves the highest PSNR in the zero-shot super-resolution task. \nFurthermore, we show that PCAInit generalizes beyond video frames, achieving the best PSNR on collections of images as well. \nOur results reveal a promising research direction on the interplay between image space and weight space in INRs, opening new avenues for future research on efficient INRs with improved reconstruction quality and broader applicability.", "tldr": "We introduce PCAInit, a novel training-free initialization method derived from an analysis of the relation between image space and weight space through principal component analysis.", "keywords": ["Image Reconstruction", "Implicit Neural Representations (INRs)", "Representation Learning", "Representational Alignment", "Weight Initialization", "Weight Space"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/05647ddd07f6c9d6dfdc038e0f75dcd171ffce95.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for INR initialization. The method uses PCA to align the initial weight trajectory over time to that of video frames over time. This can also be applied to a collection of images in the same way. The method shows improved reconstruction accuracy over the naive initialization of several prior works."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The method is a simple, actionable, method for improving INR performance from better initialization"}, "weaknesses": {"value": "- Unclear if this affects bitrate\n- More comparisons would be nice"}, "questions": {"value": "This paper provides a simple framework for improving INR results by using a better initialization. Overall the method is simple, straightforward to implement, and achieves clear improvements in results. It's the kind of thing that I can imagine becoming standard in the INR world. I do have some minor issues which I think should be clarified though:\n\n1. How does the method perform on non-SIREN networks? I think the only evaluation was on SIREN but it could be applied to other methods as well. I expected to see a table comparing for several methods: \"Naive init\" vs \"Our init\". \n2. I think there should be some comparison to NIRVANA because they did some work on the initialization scheme as well"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AoR2qtcFQt", "forum": "nrFMGXSGLX", "replyto": "nrFMGXSGLX", "signatures": ["ICLR.cc/2026/Conference/Submission18749/Reviewer_pSrS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18749/Reviewer_pSrS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18749/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761319821576, "cdate": 1761319821576, "tmdate": 1762928469060, "mdate": 1762928469060, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on improving implicit neural representations (INRs) for video data, which are often limited by high training costs and suboptimal reconstruction quality. Using SIREN as the baseline, the authors explore three initialization strategies to accelerate INR training and enhance performance on large-scale video frames. Among them, the proposed PCAInit method is a training-free initialization derived from analyzing the relationship between video frame space and network weight space using principal component analysis (PCA)"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The discovery of a similar PCA trajectory between the image space and the weight space is highly insightful and provides a valuable perspective for understanding the internal structure of INRs.\n\n2. Building on this observation, the proposed PCA-based initialization (PCAInit) is conceptually sound and well-motivated, offering a clear rationale for improving INR performance in video reconstruction.\n\n3. The experimental evaluation is comprehensive and convincing, comparing PCAInit with multiple classical and meta-learned initialization methods across diverse datasets, which strongly supports the validity and effectiveness of the proposed approach."}, "weaknesses": {"value": "1. The method description lacks clarity. In lines 281–294, the phrase “use the PCA basis of ... weight space” is conceptually vague. The authors should present the method using clearly defined mathematical symbols and equations rather than verbal explanations. As written, it is difficult to understand the precise transformation steps between image and weight spaces.\n2. The abstract and introduction should emphasize the discovery of similar PCA trajectories in image and weight spaces, which I consider to be the paper’s most valuable contribution. In contrast, the Previous Frame and First Frame initialization strategies are relatively minor contributions and do not represent the core insight of the work, yet the current abstract and introduction fail to highlight this key finding.\n3. Although the paper defines its problem in the context of video representation, it uses SIREN, a model originally designed for static image representation. This design choice is unconvincing. The authors mention NeRV in the related works but incorrectly state that NeRV “focuses on compression at the cost of reconstruction quality.” In reality, NeRV provides faster and more accurate video representation, with compression as an added benefit. For representing videos, NeRV remains a more suitable and efficient choice than modeling each frame with separate MLPs.\n4. The training time comparison in Figure 1 is somewhat misleading. The reported speedup relies heavily on parallelization, effectively trading memory for time rather than reducing total computation. In scenarios without sufficient parallel hardware, the training time would remain long. This limitation further weakens the argument for applying the proposed method to video representation, where efficiency is crucial. That's why NeRV is more suitable for video representation.\n\nOverall, while the paper presents a valuable finding regarding the relationship between image and weight spaces, its practical applicability to video representation is limited due to methodological and architectural choices."}, "questions": {"value": "1. The statement in line 196 is confusing. Given the initialized weights $\\theta_t$, it is unclear why the model still needs to initialize $\\theta_t$ again. This redundancy suggests unclear notation or an inconsistency in the description of initialization steps.\n2. In line 305, for the “image collections” case, can the PCA be computed from a single image only, or does the method require multiple images to form the PCA basis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sCTss8m4En", "forum": "nrFMGXSGLX", "replyto": "nrFMGXSGLX", "signatures": ["ICLR.cc/2026/Conference/Submission18749/Reviewer_QzFL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18749/Reviewer_QzFL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18749/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663632651, "cdate": 1761663632651, "tmdate": 1762928468412, "mdate": 1762928468412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PCAInit, a training free initialization mechanism for INRs. The main\nidea is to leverage PCA-based alignment between image space and weight space. This\napproach is very insightful and explores the connection between weight space and image\nspace. I think this is the first work that explores this kind of connection for weight\ninitialization (haven’t checked the latest works). When it comes to results, it has shown\nstrong empirical results on the DAVIS dataset."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1). Paper is written very well and understandable. Further, the Figure1 helps to understand\nwhat is going on with the approach (overall).\nThe proposed approach has significant improvement over the baseline.\n2). The most interesting observation and the strength is this not only works for videos but also\nfor unrelated image collections. This is a huge plus.\n3). When it comes to novelty, as far as I know, this is a novel approach."}, "weaknesses": {"value": "1). I would like to know why authors specifically selected SIREN as the base architecture? Did authors attempt GAUSS, WIRE or any improved versions of SIREN (for instance FINER).\n\n2). As this paper focuses on improving initialization for video frames, how does PCAInit compare to architectures explicitly designed for videos, such as the NeRV family or related INR models? Can PCAInit also be applied to those networks, or are there\nstructural limitations?\n\n3). The evaluation is limited to 15 videos from DAVIS 2017, which are all natural videos. It would be valuable to understand how the approach performs on non-natural or AIgenerated videos, or on videos with abrupt scene transitions that break temporal\ncontinuity. \n\n4). The approach relies on the assumption that image and weight manifolds are related through an orthogonal transform plus a linear projection. This is a strong assumption, but the paper provides only empirical evidence. I would like to know can authors include at least some theoretical or intuitive justification for why this correspondence arises.\n\n5). Many of the new works on INRs have not been cited. specifically, video inr methods. \n\n6). For image-based evaluation, why PCAinit is not compared with meta-learning-based approach?"}, "questions": {"value": "Please see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nRYo2mKb5u", "forum": "nrFMGXSGLX", "replyto": "nrFMGXSGLX", "signatures": ["ICLR.cc/2026/Conference/Submission18749/Reviewer_8d9P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18749/Reviewer_8d9P"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18749/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942171379, "cdate": 1761942171379, "tmdate": 1762928467853, "mdate": 1762928467853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work the authors introduce a new method to initialize Video-INR systems to encode the videos much faster than the previous baselines. They introduce a novel training free PCA-based initialization method which outperforms MAML based methods and is also void of any sequential dependency. This work paves way towards more practical and faster encoding times for Video INRs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well written and easy to follow with most claims backed by theoretical/empirical analysis. \n- The idea of obtaining weight space initialization by using pseudo weight trajectories without any expensive MAML training is an important contribution to the field."}, "weaknesses": {"value": "- Initialization strategies like re-using previous frame/first frame have been explored in prior works like [1] and the authors should refrain from claiming it as \"main contributions\" in their paper.  \n- Impact on Compression: Apart from serving as general purpose representations, INRs can also be used for video compression. It would be interesting to see the impact of PCAInit on reducing the bits required for representing a video. \n- More analysis on how the content of the video used for calculating PCAinit influences the convergence speed/final quality would be helpful. That would help us answer few crucial questions like - does this transfer across datasets of videos? How does PCAInit fare when the initialization is derived from a completely different set and so on. \n- The paper restricts itself to 480p videos. Does it have the potential to scale ? or does that require substantial architectural changes? \nif it is the latter, then we might even need to revisit the assumptions made to derive the PCAinit weights. \n\n\n[1] https://arxiv.org/abs/2212.14593"}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lQeugH5pju", "forum": "nrFMGXSGLX", "replyto": "nrFMGXSGLX", "signatures": ["ICLR.cc/2026/Conference/Submission18749/Reviewer_dg3F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18749/Reviewer_dg3F"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18749/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762220968147, "cdate": 1762220968147, "tmdate": 1762928466418, "mdate": 1762928466418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}