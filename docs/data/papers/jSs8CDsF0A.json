{"id": "jSs8CDsF0A", "number": 17605, "cdate": 1758278203084, "mdate": 1759897165250, "content": {"title": "TrainRef: Curating Data with Label Distribution and Minimal Reference for Accurate Prediction and Reliable Confidence", "abstract": "Practical classification requires both high predictive accuracy and reliable confidence for human-AI collaboration. Given that a high-quality dataset is expensive and sometimes impossible, learning with noisy labels (LNL) is of great importance. The state-of-the-art works propose many denoising approaches by categorically correcting the label noise, i.e., change a label from one class to another. While effective in improving accuracy, they are less effective for learning reliable confidence. This happens especially when the number of classes grows, giving rise to more ambiguous samples. In addition, traditional approaches usually curate the training dataset (e.g., reweighting samples or correcting data labels) by intrinsically learning normalities from the noisy dataset. The curation performance can suffer when the noisy ratio is high enough to form a polluting normality.\n\nIn this work, we propose a training-time data-curation framework, TrainRef, to uniformly address predictive accuracy and confidence calibration by (1) an extrinsic small set of reference samples $D_{{ref}}$ to avoid normality pollution and (2) curate labels into a class distribution instead of a categorical class to handle sample ambiguity. Our insights lie in that the extrinsic information allows us to select more precise clean samples even when $|D_{{ref}}|$ equals to the number of classes (i.e., one sample per class). Technically, we design (1) a reference augmentation technique to select clean samples from the dataset based on $D_{{ref}}$; and (2) a model-dataset co-evolving technique for a near-perfect embedding space, which is used to vote on the class-distribution for the label of a noisy sample. Extensive experiments on CIFAR-100, Animal10N, and WebVision demonstrate that TrainRef outperform the state-of-the-art denoising techniques (DISC, L2B, and DivideMix) and model calibration techniques (label smoothing, Mixup, and temperature scaling). Furthermore, our user study shows that the model confidence trained by TrainRef well aligns with human intuition. More demonstration, proof, and experimental details are available at https://sites.google.com/view/train-ref.", "tldr": "", "keywords": ["Label misinformation", "data curation", "influence function"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fd00af3c3ddd0571407cc60f4fe263a335662ebf.pdf", "supplementary_material": "/attachment/75ef870dcb6ec44119a3cec2ef077fcea201a7e7.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces TrainRef, a training-time data-curation framework for learning with noisy labels that aims to improve both predictive accuracy and confidence calibration. The method assumes access to a small external reference set of clean samples (as small as one sample per class). TrainRef uses reference augmentation to identify and expand a clean subset from the noisy dataset and employs a model–dataset co-evolution strategy to construct an embedding space used to assign distributional labels (class probability vectors) rather than categorical labels, thereby addressing sample ambiguity. Experiments on several research benchmarks report competitive or state-of-the-art results against LNL methods and improved calibration relative to label smoothing, Mixup, and temperature scaling. A small user study is reported to support the human interpretability of model confidence."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The problem is clearly framed, and the pipeline has a cohesive design. The paper targets accuracy and calibration in LNL and aligns the design of TrainRef to those twin objectives.\n- Distributional labels for ambiguity: Replacing categorical relabeling with class distributions is a principled way to mitigate class ambiguity and improve calibration.\n- Results are strong across multiple datasets; comparisons include both LNL and calibration baselines.\n- The alternating “reference expansion - model training” scheme is simple enough to integrate with common backbones."}, "weaknesses": {"value": "- The concept of \"normality pollution\" is introduced in the abstract and briefly mentioned in the introduction. Since this is an important motivation for the paper, this phenomenon should be further discussed and evaluated.\n- The paper does not deeply study how the quality, coverage, or size of the reference set​ affects selection precision, convergence, or final performance. Robustness to partially wrong or class-imbalanced​ is not shown. This includes the intuition that different (more or less prototypical) samples in the reference set will affect model performance and convergence.\n- Several compared LNL baselines are not designed to use an external clean set. To isolate TrainRef’s contribution, ablations that (a) remove the reference set​, and (b) enable a comparable “oracle clean set” for baselines would clarify fairness.\n- The computational overhead of reference augmentation and model–dataset co-evolution (e.g., nearest-neighbor searches, embedding updates, voting) is not fully quantified; behavior with many classes and very high noise rates remains unclear."}, "questions": {"value": "- Iteratively expanding the “clean” pool may amplify early mistakes or biases in the data. Could the authors provide observations on these line of research? \n- What mechanisms prevent confirmation bias when expanding the clean set?\n- Can you elaborate on why “one sample per class” in the reference set suffices to avoid normality pollution and enable accurate clean-sample selection in high-class settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "55e6yTbhjf", "forum": "jSs8CDsF0A", "replyto": "jSs8CDsF0A", "signatures": ["ICLR.cc/2026/Conference/Submission17605/Reviewer_GRDX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17605/Reviewer_GRDX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761577650043, "cdate": 1761577650043, "tmdate": 1762927471378, "mdate": 1762927471378, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose a method to curate data label into soft-format using a clean reference dataset. The reference dataset is built with small number of examples and augmented using label-free features. The pipeline looks promising and novel and the results show improvement compared with previous method on different dataset and type of noise. Some analysis and ablations can be conducted to further improve the completeness。"}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The method utilize a reference set for data curation, and label-free embeddings to select data in reference set. Also the final phase conduct  a iteratively optimizing between model and label. The pipeline sounds novel and promising.\nThe motivation is clearly illustrated and easy to follow.\nThe cured label is in soft format, which is good for analysis and interpretability.\nThe experiments results look good compared with previous method and also work on different datasets."}, "weaknesses": {"value": "Some analysis and ablations can be conducted for better understanding of this method\nSee questions part below for details"}, "questions": {"value": "1. Section 2 claims two types of noise, Categorical Noise and Distributional Noise. Is there analysis on how good the proposed method is at dealing with each type? Like the after the curation, which type of noise will be more reduced.\n2. Section 2 also claims the challenge of Reference-set diversity. How to measure the diversity? Is the number of samples a good way of measuring? How the diversity of Reference-set affect the final results and how to set the threshold of influence score to select clean data? Actually the influence score will select similar examples as the initial reference dataset, so the diversity may not change much.\n3. What is the necessity of phase two? Is it a cold start for the EM optimization in phase three? What is the comparison of between with and without phase two\n4. How does the initial noise level and threshold of influence score affect the convergence of phase three."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kwDMl4InIO", "forum": "jSs8CDsF0A", "replyto": "jSs8CDsF0A", "signatures": ["ICLR.cc/2026/Conference/Submission17605/Reviewer_6MHt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17605/Reviewer_6MHt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950205977, "cdate": 1761950205977, "tmdate": 1762927470730, "mdate": 1762927470730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a training-time data curation approach. This method enables learning under label noise by using a small trusted reference set to avoid learning from contaminated label norms, while also utilising soft distributional labelling instead of the hard categorical labelling used in previous studies. It presents a three-phase method consisting of: (1) self-supervised pre-training using MIM to obtain a noise-robust embedding; (2) augmentation of the small reference set to create a larger, high-precision set; and (3) iterative co-evolution, in which the model and the curated soft labels are updated alternately. Experimental results demonstrate state-of-the-art performance on CIFAR-100, WebVision and Animal-10N, with high predictive accuracy and improved confidence calibration. The paper also includes ablation studies and a qualitative study involving human experts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and easy to follow. The method is clearly explained and the experimental part is described in quite a lot of detail.  \n\n2. The proposed method is well motivated and intuitive. It properly addresses the limitations of previous methods: miscalibration and ambiguous instances arising from hard re-labelling and noisy-set denoising only. \n\n3. The reported experimental results are strong. The improvements in CIFAR100, WebVision and Animal-10N in terms of both accuracy and calibration are substantial in both low- and high-noise environments. The experimentation is extensive. \n\n4. The paper also presents the results of a qualitative study involving data labelling experts. In this user study, the experts consistently preferred the predictions from TrainRef, demonstrating the method's effectiveness."}, "weaknesses": {"value": "1. A major limitation of this paper is that it does not explain how to select the initial reference set. In real-world settings, selecting an initial reference (e.g. one example per class) can introduce bias. Therefore, it is important to explain how to select the reference set and the extent to which this selection introduces additional bias.\n\n2. While the authors do provide a computational time comparison in the appendix, I assume that, as the dataset size increases, the computational overhead of TrainRef will also increase significantly. This needs to be clarified, and if possible, demonstrated empirically.\n\n3. The approach relies entirely on the Masked Image Modelling (MIM) architecture. It may not generalise to other architectures. \n\n4. Lastly, while the qualitative study in Section 4.3 is helpful, using only five human testers is insufficient for making any solid claims. It is unclear whether the qualitative results are biased. Therefore, it would be beneficial for the paper to include a brief explanation of how it was ensured that the qualitative results were not biased due to the small number of human experts involved."}, "questions": {"value": "1. The pipeline relies on MIM to create a noise-robust embedding. How important is this choice? Would other self-supervised methods produce similar results?\n\n2. How were the initial reference images selected for each dataset?\n\n3.How were the 100 test samples selected in the user study?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wHkp3Z89lr", "forum": "jSs8CDsF0A", "replyto": "jSs8CDsF0A", "signatures": ["ICLR.cc/2026/Conference/Submission17605/Reviewer_3eSK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17605/Reviewer_3eSK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17605/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985660068, "cdate": 1761985660068, "tmdate": 1762927469692, "mdate": 1762927469692, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}