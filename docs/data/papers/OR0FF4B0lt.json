{"id": "OR0FF4B0lt", "number": 1520, "cdate": 1756888947329, "mdate": 1763268754954, "content": {"title": "Harnessing Model Uncertainty for Adaptive Causal Debiasing in Visual Question Answering", "abstract": "Visual Question Answering (VQA) models often exploit spurious correlations, hindering true multimodal reasoning. While causal inference offers principled debiasing methods, current approaches pair complex causal graphs with overly simplistic, static counterfactual interventions (e.g., feature subtraction). This limits effectiveness. We challenge this by proposing a novel framework synergistically integrating uncertainty estimation with causal counterfactual reasoning for robust VQA debiasing. This is the first work, to our knowledge, to leverage uncertainty within a causal VQA framework. We systematically explore uncertainty quantification techniques (entropy, prediction margin) to assess model confidence. This estimated uncertainty dynamically modulates the counterfactual intervention, allowing adaptive adjustment of biased information sources based on real-time confidence. This moves beyond rigid interventions. Furthermore, we introduce a tailored Curriculum Learning strategy that dynamically assesses sample difficulty using uncertainty-aware metrics, enhancing the adaptive mechanism. Our uncertainty-guided intervention module is architecture-agnostic, enabling integration into diverse VQA networks. This adaptive, uncertainty-aware approach offers a more flexible, robust, and theoretically grounded pathway towards mitigating VQA biases.", "tldr": "", "keywords": ["Visual Question Answering (VQA)", "Causal Debiasing", "Uncertainty Estimation", "Counterfactual Reasoning", "Adaptive Intervention", "Curriculum Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2860cb7f325266421a6c7fe20f5f04e45c3a797e.pdf", "supplementary_material": "/attachment/9db4c01c1891cd75185d92e215a03c70807f82f0.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes an extension to the existing method for debiasing the VAQ models. VQA models have priors that are caused by the statistical answer distribution in training data. Many existing methods subtract a question-only baseline to correct the output logits. Currently, the question-only baseline is often a constant vector. This paper extends the constant to an adaptive estimate. The adaptation is done through a gating mechanism driven by a collection of uncertainty metrics. This enables a more flexible debiasing."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Using per-example uncertainty to adapt prior static subtraction methods is a meaningful exploration in VQA debiasing. Introducing uncertainty as a control signal for adaptive debiasing is reasonable.\n- The adaptive intervention is simple."}, "weaknesses": {"value": "- Method is a feature ablation, not counterfactuals. Counterfactuals involve abduction, action, prediction (do calculus). The method uses only contrastive residual. So causal semantics are overstated.\n- Various figures contradict the math. Figure 1 suggests cutting the question path, but the math replaces the vision and vision-question paths with a constant.\n- Sloppy/incorrect math at times. The gating mechanism involves a learnable sigmoid function; I believe that the author incorrectly forces the hyperparameter $\\gamma$ to be positive. Please check.\n- Novelty is modest compared with the claim. The core contribution is a soft, uncertainty-gated generalisation of an existing subtractive debiasing scheme (CF-VQA). It is overclaimed as \"the first to dynamically guide a causal intervention\"."}, "questions": {"value": "- What is C? How come the same C was used for both Z_{V} and Z_{VQ}?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ErG5YTZU2t", "forum": "OR0FF4B0lt", "replyto": "OR0FF4B0lt", "signatures": ["ICLR.cc/2026/Conference/Submission1520/Reviewer_jNhM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1520/Reviewer_jNhM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761182422624, "cdate": 1761182422624, "tmdate": 1762915790476, "mdate": 1762915790476, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework for debiasing Visual Question Answering (VQA) models by integrating uncertainty estimation with causal counterfactual reasoning, addressing the limitations of static interventions in existing methods. The proposed Adaptive Uncertainty-Guided Intervention (AUGI) module dynamically modulates counterfactual interventions based on model uncertainty metrics such as predictive entropy, prediction margin, or ensemble disagreement, allowing for instance-specific adjustments to mitigate spurious correlations. Complementing this, an Uncertainty-Aware Curriculum Learning (UACL) strategy sequences training samples from low to high uncertainty, enhancing the model's robustness, while the architecture-agnostic design ensures broad applicability across VQA models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Pros:\n1. The paper introduces uncertainty estimation into causal VQA debiasing, enabling adaptive intervention that dynamically adjusts debiasing strength per instance, overcoming the rigidity of static methods, e.g., over-correcting in some cases and under-correcting in others.\n2. The proposed UACL strategy sequences training from simple to hard samples, aligning learning progression with the adaptive mechanism and enhancing model robustness on challenging samples.\n3. Extensive experiments demonstrate improvements in debiasing performance over baselines, validating the effectiveness of the uncertainty-guided approach."}, "weaknesses": {"value": "Cons:\n1. The UACL strategy depends on initial uncertainty from a warm-up model and uses static scheduling post-warm-up, which may introduce instability if uncertainty evolves significantly during training.\n2. The bottom example in Figure 1 is misleading and does not reflect how Static Causal Intervention works. If \"eating\" is more common in the training set, Static Causal Intervention should reduce its probability on test cases, yet your figure shows \"cooking\" decreasing instead, which won't happen if you truly understood how Static Causal Intervention methods like CF-VQA works.  A correct illustration would show Static Causal Intervention over-correcting a true \"eating\" test case to \"cooking\", while your method correctly predicts \"eating\"."}, "questions": {"value": "Please address the above two questions I raised in the weaknesses. Your response will directly influence whether I raise or lower my final score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lJHh7HSFpC", "forum": "OR0FF4B0lt", "replyto": "OR0FF4B0lt", "signatures": ["ICLR.cc/2026/Conference/Submission1520/Reviewer_zfD9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1520/Reviewer_zfD9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761276292798, "cdate": 1761276292798, "tmdate": 1762915790313, "mdate": 1762915790313, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a VQA debiasing framework that couples uncertainty estimation with counterfactual intervention. Uncertainty drives instance-level intervention strength, and an uncertainty-aware curriculum schedules training. The design is backbone-agnostic and targets robust multimodal reasoning. The claims include introducing uncertainty into causal VQA for adaptive intervention (AUGI), an uncertainty-aware curriculum (UACL), and broad empirical gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear motivation that fixed, static interventions fail to match per-example bias intensity.\n2. Using uncertainty as the control signal improves adaptivity and aligns with robust learning principles.\n3. Learnable gating with α, consistency regularization, and training objectives form a coherent end-to-end procedure."}, "weaknesses": {"value": "1. Evaluation leans on older VQA backbones and lacks systematic tests on stronger Transformer-based or recent VLM architectures.\n2. Computational overhead remains unclear, especially with ensemble-style uncertainty and multi-head designs. No FLOPs, memory, or latency analysis.\n3. UACL orders samples by early uncertainty, which may interact with dataset bias. Sensitivity and robustness analyses are limited.\n4. Edge behavior when α approaches its limits could suppress the debiasing signal; theoretical and empirical analysis is thin."}, "questions": {"value": "1.How much training and inference overhead vs. CF-VQA in wall-clock time, memory, and latency, and what is the incremental cost attributable to ensembles or extra heads?\n2. Does the plug-in work with modern VLMs such as BLIP/BLIP-2 or LXMERT, and do trends hold on those backbones?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ldihWGjdsc", "forum": "OR0FF4B0lt", "replyto": "OR0FF4B0lt", "signatures": ["ICLR.cc/2026/Conference/Submission1520/Reviewer_RLtV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1520/Reviewer_RLtV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795976427, "cdate": 1761795976427, "tmdate": 1762915790182, "mdate": 1762915790182, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "1. The paper proposes a novel uncertainty-driven causal debiasing framework for Visual Question Answering (VQA), integrating uncertainty estimation with counterfactual reasoning to better assess model confidence and adapt intervention strength.\n\n2. The approach dynamically evaluates sample difficulty using uncertainty-aware metrics, forming an adaptive curriculum learning strategy that enhances training progression from easy to hard samples.\n\n3. Compared with baseline methods (e.g., CF-VQA), the proposed uncertainty-guided framework achieves superior performance on both VQA-CP v2 and VQA v2 datasets, demonstrating improved robustness and generalization."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a novel uncertainty-driven causal debiasing framework for Visual Question Answering (VQA), integrating uncertainty estimation with counterfactual reasoning to better assess model confidence and adapt intervention strength.\n\n2. The approach dynamically evaluates sample difficulty using uncertainty-aware metrics, forming an adaptive curriculum learning strategy that enhances training progression from easy to hard samples.\n\n3. Compared with baseline methods (e.g., CF-VQA), the proposed uncertainty-guided framework achieves superior performance on both VQA-CP v2 and VQA v2 datasets, demonstrating improved robustness and generalization."}, "weaknesses": {"value": "1. The paper does not clearly describe the underlying model architecture. A brief background subsection should be added to explain the baseline model pipeline to help readers understand how the model is trained. In addition, at line 211,the authors should explicitly cite CF-VQA (Niu et al., 2021) when it is mentioned as the “baseline our work builds upon.” In addition, the term should be consistently written as CF-VQA, not CFVQA, to maintain clarity and consistency throughout the paper.\n\n2. During writing, ensure references to Table 4 and Table 6 are explicitly mentioned where relevant to the discussion.\n\n3. In Figure 2, the purple arrow line representing UACL is visually unclear and should be enhanced for better readability.\n\n4. In LaTeX, the left double quotation mark should be written as two backticks (``) rather than a single quotation mark (\"). Otherwise, the rendered text will display incorrect quotation marks (e.g., ”...”)."}, "questions": {"value": "1. For current VQA tasks, large vision-language models (e.g., LLaVA, Qwen-VL) have become dominant. Could the proposed uncertainty-driven framework also be extended or fine-tuned within such large-scale VLM architectures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xnwko5kJfv", "forum": "OR0FF4B0lt", "replyto": "OR0FF4B0lt", "signatures": ["ICLR.cc/2026/Conference/Submission1520/Reviewer_PqBq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1520/Reviewer_PqBq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976019423, "cdate": 1761976019423, "tmdate": 1762915790011, "mdate": 1762915790011, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}