{"id": "r402yIwWGQ", "number": 14784, "cdate": 1758243679912, "mdate": 1759897349576, "content": {"title": "RAID: Towards Robust AI-Generated Image Detection with Bit Reversed Images", "abstract": "The rapid advancement of image generation models has made it increasingly difficult for people to distinguish AI-generated images from real ones. To prevent the potential risks associated with the misuse of fake images, AI-generated image detection has gained significant attention. Existing methods neglect the inherent differences between real and fake images, thus lacking robustness and generalization ability. In this work, we innovatively investigate AI-generated image detection using bit-planes, and introduce the bit reversed image. We propose a simple yet effective pipeline consisting of construction of bit reversed images, gradient-based patch selection and a convolutional classifier. Extensive experiments on more than 32 benchmarks verify the effectiveness of our approach across different settings, including evaluations of generalization capability and zero-shot performance. Particularly, our approach achieves nearly 100% accuracy on eight benchmarks for cross-generator evaluation on the GenImage dataset.", "tldr": "We innovatively tackle AI-generated image detection based on bit-planes and present a simple yet effective pipeline based on  bit reversed image.", "keywords": ["AI-Generated Image Detection", "Bit-Plane-Based Image Processing"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab313c1917b2c25a27c2fca1f6d61c7f8d865934.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes RAID, a novel framework for AI-generated image detection leveraging bit-plane decomposition and the introduction of Bit Reversed Images (BRI). By reversing bit-plane order, the method amplifies subtle artifacts invisible in original images. Combined with a gradient-based patch selection and a lightweight modified ResNet-50, RAID achieves strong cross-generator and zero-shot generalization across 40+ benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The idea of using bit-plane reversal for AI-generated image detection is fresh and unexplored. It introduces a simple yet conceptually interesting perspective beyond spatial and frequency domains. The method reinterprets bit-plane representation — commonly used in steganography — into a discriminative cue for forgery detection, showing creative cross-domain thinking.\nMoreover, the integration with a gradient-based patch selector (GBPS) is efficient and complements the novel bit-reversal transformation.\n- The experiments are extensive, covering multiple datasets (AIGCDB, GenImage, GID, GVD) and diverse setups (cross-generator, zero-shot, robustness).\n- Quantitative results are strong, with clear ablations demonstrating the role of each component.\n- The paper is generally well-structured, with detailed methodology and visualization of bit-planes, bit-reversed effects, and patch-level predictions.\n- Figures (e.g., Fig. 1–5) are informative and aid understanding of how bit reversal exposes artifacts.\n- Given the current importance of detecting synthetic images, this work contributes a lightweight, interpretable, and effective detector. Its generalization to unseen generators and real-world degradation scenarios underscores robustness and potential for deployment."}, "weaknesses": {"value": "- The paper lacks a clear theoretical justification for why bit reversal amplifies AI-specific artifacts. There is no spectral or statistical evidence to show that reversing bit-plane order meaningfully highlights generative inconsistencies rather than generic noise.\n- Some strong recent baselines (e.g., C2P-CLIP, NPR, FatFormer, CoD) are missing, limiting the claim of state-of-the-art performance.\n- The comparison under image perturbations (Table 6) includes only ESSP, while stronger pretrained universal detectors (e.g., UnivFD) are not discussed.\n- Table 4 shows certain bit-forward configurations nearly match bit-reversed performance (98.0% vs. 98.4%), raising questions about the true necessity of reversal. The paper should clarify why full reversal is superior beyond empirical coincidence.\n- It remains unclear whether bit reversal corresponds to frequency inversion (i.e., swapping high- and low-frequency components). Without clarifying this, it is hard to position the method relative to existing frequency-based approaches."}, "questions": {"value": "- Can the authors theoretically or empirically justify why bit reversal highlights generative artifacts? Is there a measurable spectral or statistical property supporting this observation?\n- Does the bit reversal operation correspond to swapping high- and low-frequency components in the frequency domain? If not, how does it differ from such transformations?\n- Table 4 shows bit-forward images can also reach 98.0% accuracy. Why, then, is full reversal necessary?\n- Why are comparisons under image perturbations limited to ESSP? How does RAID perform against pretrained universal detectors such as UnivFD, CoD, or FatFormer?\n- Could combining BRI with multi-scale or transformer-based architectures further enhance robustness or interpretability?\n- What I care most about is what traces the bit-reversed image extracts and its relationship with frequency inversion (i.e., swapping high- and low-frequency components). I will adjust the score based on the author's response."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "B9kuIdEypX", "forum": "r402yIwWGQ", "replyto": "r402yIwWGQ", "signatures": ["ICLR.cc/2026/Conference/Submission14784/Reviewer_iJPB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14784/Reviewer_iJPB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14784/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971956331, "cdate": 1761971956331, "tmdate": 1762925137700, "mdate": 1762925137700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes RAID, a robust AI-generated image detector that leverages bit-plane decomposition, specifically introducing “bit reversed images” as feature amplifiers for distinguishing real from synthetic imagery. The approach involves lossless bit-plane decomposition, strategic reordering to amplify high-frequency details, gradient-based patch selection for focusing on artifact-rich regions, and a modified ResNet-50 classifier. Extensive experiments are conducted on over 40 benchmarks (AIGCDB, GenImage, and new datasets), with comprehensive ablations and cross-generator/cross-dataset/zero-shot generalization analyses. RAID demonstrates superior performance and is computationally efficient."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is among the first to successfully operationalize bit-plane analysis and bit reversal as a signal for robust artifact amplification, providing a refreshingly simple yet powerful perspective in the deepfake detection landscape.\n2. The construction of bit reversed images, followed by gradient-based patch selection and adapted ResNet-50 deployment, is both theoretically sound and easy to implement. The method’s fast, non-parametric upfront steps (bit-reversal and patch selection) are especially appealing for scalability."}, "weaknesses": {"value": "1. The paper omits a discussion and experimental comparison with “LOTA: Bit-Planes Guided AI-Generated Image Detection” , which is highly relevant, as it also explores bit-plane signals for AI-image detection. The absence of this reference undermines the claim of being among the first to leverage bit-planes and makes it harder to gauge the true incremental value over related work. This missing context should be addressed both in the Related Work section and, ideally, with an experimental baseline.\n2. While the intuition for artifact amplification via bit reversal is plausible and empirical results are strong, Section 3.1 could benefit from a deeper mathematical analysis or visualization of why and how bit reversal leads to more pronounced differences in the artifacts between real and AI-generated images. For instance, it would be useful to connect this operation more formally to the types of noise and structure generated by different models.\n3. Although RAID is benchmarked against several prior patch-based and frequency/spatial methods, comparison to newer or alternative handcrafted artifact detectors—such as those utilizing global color analysis, learned mask regularization, or ensemble patch aggregation—appears limited. This is especially pertinent for Table 1 and Table 2, which emphasize detection efficacy and generalization, and could be expanded with additional strong baselines.\n4. For zero-shot and cross-dataset generalization, relying only on ImageNet real images may not be ideal, as ImageNet’s distribution biases could influence results. Consideration of multiple, diverse “real” datasets would strengthen generalization claims."}, "questions": {"value": "1. Could the authors provide a more formal or statistical explanation (beyond visual intuition) for why bit reversal amplifies artifacts in AI-generated images more than in real ones? Are there measurable frequency or entropy-based differences that could make this hypothesis falsifiable?\n2. Why was “LOTA” not covered or compared directly, given its direct relevance? Would including a LOTA baseline or at least a detailed discussion alter RAID’s claimed superiority or novelty?\n3. Are there any scenarios (dataset types, generative models, manipulations) where RAID demonstrably fails or produces high rates of false positives/negatives—and what are the typical characteristics of such cases?\n4. In Table 10, what constraints (if any) govern the selection/learning of bit-plane weights? Is there a principled pathway to learn these weights beyond brute-forcing variants, or to adapt them to novel distributions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "okzc5JoIWt", "forum": "r402yIwWGQ", "replyto": "r402yIwWGQ", "signatures": ["ICLR.cc/2026/Conference/Submission14784/Reviewer_JYbp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14784/Reviewer_JYbp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14784/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977229035, "cdate": 1761977229035, "tmdate": 1762925136908, "mdate": 1762925136908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes RAID, a novel and efficient method for detecting AI-generated images. This method reverses the bit-planes of images as a preprocessing step, and uses a gradient-based patch selection method to find the optimum patch from the bit-reversed image, which is passed to a CNN classifier for detecting AI-generated images. The authors validated their result on AIGCDB and GenImage benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The key strength of the paper is the creative application of bit-planes to AI-generated image detection. This method achieves a significantly improved score in the GenImage and AIGCDB benchmark and demonstrates superior generalization on unseen generators. The authors demonstrated that this method is highly efficient as well. Lastly, Table 4 provided interesting insight into the effect of bit reversal and bit forwarding in different generators."}, "weaknesses": {"value": "While the empirical results are significant, the paper lacks a deeper analysis of the effectiveness of Bit Reversed Images. The difference between the real and generated BRI images, as shown in Figure 1, needs to be more clearly demonstrated, as the provided samples do not provide a clearer picture of the difference between them.\n\nThe BRI is a novel method for highlighting high-frequency information, so a detailed discussion of why this specific transformation is capable of outperforming existing methods that utilize frequency domain information would have clarified the unique advantages of the paper.\n\nThe results, especially in Table 4, suggest that all the existing generators share a fundamental flaw in the statistical properties of the pixel-level noise, and this can be modeled using bit-reversed images. This generalization capability of BRI is highly interesting. But the paper did not explain or analyze its powerful implications more explicitly, which reduces its full impact."}, "questions": {"value": "1. The paper’s motivation is dependent on the claim that BRIs for generated images contain noticeable artifacts. Could the authors provide additional analysis to support this visual claim?\n2. Could the authors elaborate on why this specific transformation is more effective than prior frequency domain methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jRrIaboRA1", "forum": "r402yIwWGQ", "replyto": "r402yIwWGQ", "signatures": ["ICLR.cc/2026/Conference/Submission14784/Reviewer_vEgC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14784/Reviewer_vEgC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14784/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992819250, "cdate": 1761992819250, "tmdate": 1762925136274, "mdate": 1762925136274, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes **RAID** (“Robust AI-generated Image Detection”), a simple yet seemingly effective approach for detecting AI-generated images. The method converts each image into a *bit-reversed version*, where the least significant bits (LSBs) are assigned the highest intensity weights and vice versa, supposedly to highlight subtle generation artifacts. A gradient-based patch selector then chooses the region with the strongest signal, and a lightweight CNN performs classification. On multiple cross-generator benchmarks (e.g., GenImage), the method reports **>98% accuracy**, outperforming heavier baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The idea is **novel in presentation** — flipping bit-plane importance to emphasize low-level noise patterns is clever and computationally light.\n* The results, if reproducible, are **remarkably strong**, showing high cross-generator generalization, suggesting that the authors tapped into a genuinely discriminative low-level signal.\n* The ablation studies and bit-order experiments are thorough; the performance gains for the full bit-reversal and patch-selection combination are consistent."}, "weaknesses": {"value": "1. **Theoretical basis is weak.**\n   The paper speculates that diffusion or GAN generators fail to reproduce LSB-level noise distribution, and that reversing bit weights amplifies this difference. But there’s **no evidence or measurement** of these bit-plane distribution gaps. It’s a plausible but unverified hypothesis.\n\n2. **Amplifying features ≠ discovering new signal.**\n   Simply amplifying certain bit planes (like a hand-crafted high-pass filter) doesn’t guarantee generalization. A CNN or Transformer could, in principle, learn to emphasize LSBs or other frequency bands by itself. The gains might stem from shortcut cues or dataset quirks rather than truly meaningful LSB statistics.\n\n3. **Results feel too good for such a simple trick.**\n   The jump to ~98% accuracy across unseen generators using only a linear remapping plus a small CNN seems **disproportionately large**. Given the simplicity of the transformation, it’s unclear how such a method achieves such robust cross-distribution generalization without overfitting to codec or pipeline artifacts.\n\n4. **Lack of code, demo, or reproducibility.**\n   The paper doesn’t release code or pretrained models, making it impossible to verify the findings. Without replication, the very high reported numbers remain speculative.\n\n5. **Practical robustness missing.**\n   The method degrades sharply under realistic conditions — e.g., JPEG-90 or Gaussian blur reduce accuracy to ~75%. Social media and messaging platforms re-compress images heavily, so a real-world detector must survive such transformations."}, "questions": {"value": "1. **Detector vs. LSB patterns:**\n   You argue that standard CNN-based detectors cannot effectively learn small LSB-level differences, hence the need for bit-reversal. Can you provide **proof or analysis** supporting this claim?\n\n2. **Reproducibility and transparency:**\n   The reported results are exceptionally high for such a lightweight approach. Can you please **release code, pretrained weights, or a simple demo** so reviewers and researchers can test your method on *unseen images*?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qYaclELnvi", "forum": "r402yIwWGQ", "replyto": "r402yIwWGQ", "signatures": ["ICLR.cc/2026/Conference/Submission14784/Reviewer_uKGL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14784/Reviewer_uKGL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14784/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762115870827, "cdate": 1762115870827, "tmdate": 1762925135780, "mdate": 1762925135780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}