{"id": "kZabPVFfIM", "number": 14152, "cdate": 1758229331949, "mdate": 1759897387558, "content": {"title": "APlaud: Adaptive Personalized Low-Rank Decomposition for User-Specific LLM", "abstract": "In this paper, we introduce and study the problem of \\textit{personalized survey response prediction} using fine-tuned large language models (LLMs). This task poses unique challenges: limited per-user training data, scalability of model storage, and the need to exploit shared survey structures. To address these issues, we propose \\textbf{APlaud} (Adaptive Personalized Low-rank and User-specific Nested Decomposition), a lightweight and scalable framework for LLM personalization. APlaud extends the LoRA paradigm by separating adaptation into a frozen, shared low-rank basis and a compact user-specific correction, augmented with a rank-one residual for finer personalization. To further reduce per-user parameter cost and mitigate overfitting, the correction matrix can be factorized into an even lower-rank form. Empirical results demonstrate that APlaud achieves efficient, scalable personalization across users while outperforming state-of-the-art LoRA-based personalized LLM approaches in both generalization and inference efficiency.", "tldr": "", "keywords": ["Personalized Language Models", "Parameter-Efficient Fine-Tuning (PEFT)", "Low-Rank Adaptation (LoRA)", "User-Specific Adaptation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7df4ac9ab90500f407308972c6c4b776d8b4ccda.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes APlaud, a lightweight framework for personalizing LLMs to individual users without maintaining a full adapter per user. It first learns a shared adapter from all users, then decomposes it into common patterns and small user-specific components. Each user only stores a tiny correction layer that adjusts the shared representation, making personalization memory-efficient. A variant APlaud+ compresses these user modules even further."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- APlaud introduces a well-structured approach that distinguishes between global model knowledge shared across users and fine-grained user-specific differences. By reusing a shared representation and learning only small adjustments per user, the method effectively captures personalization while staying lightweight.\n- The framework achieves major savings in storage and computational cost compared to maintaining a separate adapter for each user. The results demonstrate that even when thousands of users are supported, the added storage and serving cost remain minimal."}, "weaknesses": {"value": "- Assumption that the shared subspace is “stable” may be fragile. In particular, claiming that U,V are “relatively stable across users” are plausible for shared question structure, but the paper doesn’t measure subspace drift across waves, topics, or time (ATP waves differ materially). If drift is non-trivial, freezing U,V could bake in population bias.\n- Inconsistent notations: Ablation Table 4 labels “TS” as Twitter Stance in the caption while the main text defines TS = Trust in Science, but this is rather a minor problem. \n- While storage and parameter counts are favorable, serving at million-user scale depends on how quickly per-user heads can be fetched/instantiated per request across multiple layers. The paper can maybe discuss a little about the latency/throughput under realistic multiplexing (e.g., cache hit rates, cold-start users)."}, "questions": {"value": "- What exactly is included in the LLM-generated user profile (the 30% question subset)? Could you discuss the results where no profile is used, or where profiles are built from non-overlapping meta-questions only?\n- How stable are the learned U,V across waves/topics/time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rkyYUEtO3X", "forum": "kZabPVFfIM", "replyto": "kZabPVFfIM", "signatures": ["ICLR.cc/2026/Conference/Submission14152/Reviewer_broL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14152/Reviewer_broL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14152/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760539238578, "cdate": 1760539238578, "tmdate": 1762924613790, "mdate": 1762924613790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a technique called APlaud (Adaptive Personalized Low-rank and User-specific Nested Decomposition), for personalized survey response prediction using fine-tuned LLMs. The paper discusses about synthetic response generation for surveys which appear like real human responses. There are some existing works in this domain but have few issues: a) works which involve LLM prompt strategies show some cultural biases b) works which involve fine-tuning (LoRA based) are able to generate model responses at sub-population level and cannot model user response at individual level. The paper claims that the amount of data available per user is often much smaller than the size of the personalised parameters (overfitting possible), the number of users could be very large, so training separate LoRA for each not very feasible and the users should not be treated in isolation, as survey involves same question across users there is a semantic correlation between the users. APlaud extends the LoRA paradigm by combining a shared low-rank basis with compact user-specific corrections and residual terms, further reducing parameter costs through nested low-rank factorization. The paper claims that this work is the first to explicitly formulate and study the survey prediction problem in the personalized LLM setting."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1: The paper is well written and organized. \n\nS2: The paper motivates well about the need for synthetic response generation for surveys to aliviet cost - albeit there are some practical drawbacks or lack of clarity in the solution approch. \n\nS3: The paper evalated the technique on a broad set of datasets and presents detailed ablation studies including noise injection."}, "weaknesses": {"value": "W1:  It is unclear that in real deployment situation - who will be creating these digital-twins. It is not practical that users themselves would be interested in doing these. So that practicality of the solution remains questionable. \n\nW2: Although the papers discusses about learning low rank matrices for all users, this could still be expensive for very large number of users.\n\nW3: Since this work is about personalisation, a comprehensive user survey could be useful.\n\nW4: The paper does not provide details on missing or incomplete responses. \n\nW5: The approach has similarities with recommender systems - some dedicated discussion is need to compare the novelty of the proposed technique compared to recommendation systems literature."}, "questions": {"value": "Q1: Method seems very restrictive to synthetic survey response generation. Whether the research problems need to changed drastically to use it for other open-ended tasks ?\n\nQ2: Most baseline are adapter/LoRA-style family based. Comparing the method against non-adapter based could be good such as methods like retrieval based (memory maintained for users and relevant context retrieved for response generation) ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "tLCqCoTOcJ", "forum": "kZabPVFfIM", "replyto": "kZabPVFfIM", "signatures": ["ICLR.cc/2026/Conference/Submission14152/Reviewer_oHND"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14152/Reviewer_oHND"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14152/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843754373, "cdate": 1761843754373, "tmdate": 1762924613270, "mdate": 1762924613270, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles personalized survey response prediction with LLMs under three constraints: scarce per-user data, storage/serving scalability, and shared survey structure. It proposes APlaud, which extends LoRA by splitting adaptation into a frozen shared low-rank basis and a compact user-specific correction, further refined by a rank-one residual; the correction can be factorized to cut per-user parameters and overfitting. Experiments (primarily classification) indicate APlaud achieves scalable personalization with improved generalization and inference efficiency over LoRA-based baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper conducts extensive experiments on classification tasks across many datasets.\n- The focus on time and space efficiency is well-motivated, and the paper includes experiments and analyses demonstrating the corresponding savings."}, "weaknesses": {"value": "- The method is evaluated only on classification tasks. While I understand the work focuses on survey response prediction, the approach should in principle be applicable to generation tasks as well. Notably, OPPU reports results on both generation and classification (e.g., on LAMP). The current evaluation therefore narrows the paper’s contribution.\n- The assumption of a stable shared SVD subspace is not strongly validated. It appears that the stage-2 users in training are drawn from the same population as stage-1. Given this coupling in the training data, it is unclear how stage-2 personalization can be cleanly disentangled into the residual component. More evidence is needed to show that the residual truly captures user-specific information rather than leakage from the shared component.\n- Users may have different amounts of available data, which could warrant different personalized ranks. The paper lacks fine-grained analysis on how the personalized rank should vary with per-user data volume (and the impact of this choice on performance and overfitting)."}, "questions": {"value": "Please see Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aRDAiRWfGQ", "forum": "kZabPVFfIM", "replyto": "kZabPVFfIM", "signatures": ["ICLR.cc/2026/Conference/Submission14152/Reviewer_ukg7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14152/Reviewer_ukg7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14152/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917952594, "cdate": 1761917952594, "tmdate": 1762924612694, "mdate": 1762924612694, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the APlaud method, which aims to address the problem of personalized questionnaire prediction for large models. Through low-rank decomposition combined with user-specific correction, it achieves efficient parameter savings with strong generalization capability. Experiments show that on multiple public social survey and personalized datasets, this method significantly reduces parameters while improving prediction accuracy compared to existing personalization approaches. The code has been open-sourced."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The main advantages of this paper are: First, it significantly reduces the number of personalized parameters per user compared to existing methods such as OPPU, making large-scale personalized modeling feasible; \n\nSecond, by combining a shared low-rank subspace with user-specific residuals, it not only saves memory but also maintains or even improves the generalization accuracy of personalized models, outperforming existing personalized LoRA methods on multiple public datasets."}, "weaknesses": {"value": "The main limitations of this paper are:\n1. The method's ability to express personalized residuals is highly dependent on the structural choice of low-rank decomposition. If user feature distributions vary significantly, the low-rank subspace may struggle to comprehensively cover all user needs, affecting performance in extreme personalization scenarios.\n\n2. The experiments mainly focus on questionnaire and text-based personalization tasks. The generalization capability for more complex, multimodal, or multi-turn deep personalization scenarios requires further validation."}, "questions": {"value": "In extreme personalization scenarios or with long-tail users (whose characteristics differ significantly from mainstream users), does the low-rank representation capability of the APlaud method experience substantial degradation? Have you considered implementing automatic detection of \"atypical\" users and dynamically adjusting the model architecture accordingly?\n\nWhile the current method primarily focuses on achieving high accuracy with minimal personalized parameters, how do you ensure user data security and privacy protection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7fAvfiGC7H", "forum": "kZabPVFfIM", "replyto": "kZabPVFfIM", "signatures": ["ICLR.cc/2026/Conference/Submission14152/Reviewer_DHHA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14152/Reviewer_DHHA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14152/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988257794, "cdate": 1761988257794, "tmdate": 1762924612045, "mdate": 1762924612045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}