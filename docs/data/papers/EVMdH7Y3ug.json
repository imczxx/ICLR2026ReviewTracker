{"id": "EVMdH7Y3ug", "number": 24180, "cdate": 1758353740683, "mdate": 1759896778275, "content": {"title": "DynGCN: Capturing Dynamic Correlation with Message Passing", "abstract": "A recent approach to modeling multivariate time series is to represent them as a graph, with time series as nodes and pairwise temporal correlations as edges. Advances in Graph Neural Networks (GNNs) have shown strong performance in multivariate time series forecasting by assuming a static graph topology and ag- gregating information from neighboring time series based on their correlations. In this work, we investigate the representational power of GNNs for short- and long-term forecasting under both static and dynamic correlation scenarios, i.e., when pairwise correlations remain fixed or evolve over time. We show that many popular GNNs generalize poorly in these settings and are even outperformed by structure-agnostic baselines. To address these limitations, we propose DYNGCN, a novel GNN framework enhanced by two theoretically justified designs: (D1) high-order moment based message passing and (D2) static and dynamic propa- gation seperation. These components improve learning under dynamic correla- tions while preserving robustness under static scenarios. Extensive experiments on synthetic and real-world benchmarks demonstrate that DYNGCN achieves up to 23.25% and 23.08% performance gains over state-of-the-art baselines.", "tldr": "SeriesGCN is a novel GNN framework that leverages high-order covariance modeling and dual graph aggregation to improve multivariate time series forecasting under both static and dynamic correlation scenarios, outperforming state-of-the-art baselines.", "keywords": ["Multivariante Time Series Forecasting", "Correlation Modeling", "Graph Neural Network"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2ee34707e1c1a0fab78c62c001f91e72fe94a2e0.pdf", "supplementary_material": "/attachment/20ab0e1e9b52b97fbb364cbd328ee02636124d4c.pdf"}, "replies": [{"content": {"summary": {"value": "The authors focus on graph-based time series forecasting, in the absence of underlying graph structure, and propose a GNN-based framework that captures static and dynamic time series correlations over time, beyond static graph topology. With extensive theoretical formulations, the authors propose an architectural design that incorporates high-order correlation-based message passing and considers static and dynamic propagation separation in the message passing. These considerations are shown to improve forecasting in the presence of dynamic correlations, in synthetic and real-world experiments against baselines, with significant margins in some cases."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **[S1: Quality - Mathematical Framework]** Different aspects of the proposed design choices are mathematically proven and connected to common time series statistical properties rather than heuristically chosen. \n- **[S2: Significance - Performance Improvements]** The proposed method achieves significantly improved performance against several baselines for several datasets.\n- **[S3: Clarity]** The paper is easy to follow, and the different points made are well-justified via experiments or mathematical proofs."}, "weaknesses": {"value": "- **[W1: Clarity - Positioning in Graph Structure Learning]** The positioning of the authors against related works in graph structure learning for time series forecasting is rather poor, both in the introduction and the related works section. Specifically, the authors mention that related works build on static graphs, disregarding dynamic correlations, yet those are assumed to be extracted via the raw time series sliding windows used as dynamic node features. Additionally, no distinction on the type of the structure extracted, fixed (based on time series correlation, such as FourierGNN) vs learnable (top-K operation on the transformed input vectors, such as MTGNN or learned with gumbel softmax, such as GTS (Shang et al, 2021)) is made with respect to how this affects correlation learning. This gap should be explicitly tackled in the relevant sections (e..g, Graph Topology Identification) to enable proper positioning of the paper. \n- **[W2: Clarity & Quality - Fully-Connected Adjacency Structure]** It seems that the authors focus on fully-connected weight adjacencies, specifically $X^TX$. Dense graph structures have been criticized in the relevant literature as backpropagating spurious relationships in time series forecasting, while hindering the interpretability aspect of the learned correlations, which is the main goal of non-structured time series graph-based forecasting and which can indeed be enabled via sparse learnable graphs (Cini et al., 2023). Addressing this design choice is crucial for the motivation behind the paper and its positioning in the time series graph-based literature. It is also unclear how the architectural designs can scale for large time series lengths and a high number of variables.\n- **[W3: Quality & Significance - Adjacency Separation]** The disentanglement in the message passing step for static and dynamic correlations is indeed interesting, while being also one of the main contributions of the paper, yet its effect seems incremental in the ablation study of Table 4. At the same time, this separation doubles the parameters of the message passing layer of the proposed model. Since no normalization is done, it is unclear if one of the parts can dominate the sum at the end. \n- **[W4: Quality & Significance - Time Cost Comparisons]** The authors should consider including time cost/memory comparisons with relevant baselines and the datasets used, to showcase how their architectural choices affect scalability in practice, combined with the achieved performance.\n- **[W5: Quality & Significance - Experimental Evaluation]** Some considered baselines in the time series forecasting literature are slightly outdated when it comes to sequential architectures (see more recent SOTA here: https://github.com/thuml/Time-Series-Library). Several benchmark datasets are also not considered (see datasets in FourierGNN and standard datasets in the time series community, such as ETT, Weather). Additional GNN-based baselines are also usually considered (Bai et al., 2020; Wu et al., 2019).\n- **[W6: Significance - Results]** The authors should show standard deviations for some datasets where performance improvements compared to baselines are small (at least in the appendix).\n\n--Shang, C., Chen, J., & Bi, J. (2021). Discrete graph structure learning for forecasting multiple time series. arXiv preprint arXiv:2101.06861.\nCini, A., Zambon, D., & Alippi, C. (2023). Sparse graph learning from spatiotemporal time series. Journal of Machine Learning Research, 24(242), 1-36.\n\n--Bai, L., Yao, L., Li, C., Wang, X., & Wang, C. (2020). Adaptive graph convolutional recurrent network for traffic forecasting. Advances in neural information processing systems, 33, 17804-17815.\n\n--Wu, Z., Pan, S., Long, G., Jiang, J., & Zhang, C. (2019). Graph wavenet for deep spatial-temporal graph modeling. arXiv preprint arXiv:1906.00121."}, "questions": {"value": "1. **[Based on W2]** Without any regularization/sparsification on the adjacency, it is unclear how the method differs from sequential models, eg, transformers, in capturing correlations for time series forecasting.\n2. **[Based on W1/W2]** Can the authors show visualizations of the correlations learned in forecasting? Could those be explainable when it comes to the input data and the task at hand?\n3. **[Based on W2/W4]** In the ablation, there is a small drop in performance when the two main architectural design choices are removed from the proposed method. Could the authors justify better where the large performance improvements for some datasets mainly come from?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vYbTbbpFt0", "forum": "EVMdH7Y3ug", "replyto": "EVMdH7Y3ug", "signatures": ["ICLR.cc/2026/Conference/Submission24180/Reviewer_nhq3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24180/Reviewer_nhq3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755775232, "cdate": 1761755775232, "tmdate": 1762942978748, "mdate": 1762942978748, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of modeling dynamic dependencies in multivariate time series by relying on graph representations. The proposed method models aims at modeling both dynamic and static edges within a message-passing framework. However, as discussed below, the paper suffers from severe issues in presentation, conceptualization, and experimental design."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* Accounting for dynamic inter-series relationships in time series forecasting is an important and relevant problem."}, "weaknesses": {"value": "One of the main issues of the paper is that most of the results concern modeling covariance, yet the paper presents them from the beginning as modeling generic relationships among time series. This leads to several conceptual problems.\n\n* **Poor presentation leading to several conceptual issues.** The structure and presentation of the paper are confusing and lack clarity in several respects.  \n    - The paper seems to use multiple, incompatible definitions of what an adjacency matrix is. In Section 2, the paper “defines” the adjacency matrix as the sample covariance. This is a major conceptual limitation, as covariance only accounts for specific linear dependencies, whereas the graph representations typically used in this context often model more complex relationships (e.g., the structure of a traffic network or spatial proximity in spatiotemporal data). Indeed, in lines 96–100, the paper states that existing methods use adjacency matrices that are not compatible with the definition in Eq. 1. This creates significant ambiguity throughout the paper.  For instance, Section 2.1 appears to list properties of the covariance matrix under certain assumptions on the data-generating process. Overall, conflating the dependencies modeled by a graph structure with covariance estimation is a major limitation, and the paper is ambiguous on this point. The presentation would be much clearer if the paper referred directly to the problem of estimating covariance matrices rather than generic graph structures and used the term “covariance matrix” instead of “adjacency matrix.” This would also allow for a more appropriate contextualization relative to related work.  \n    - In Section 2.2, the score in Eq. (2) can again only model linear dependencies — a major limitation that should be acknowledged and discussed.  \n    - It is unclear how the static and dynamic adjacency matrices are obtained. There is no precise mathematical definition of either anywhere in the paper.  \n    - It is also unclear how some of the theorems relate to the problems the paper claims to address, and several results are trivial given the assumptions made. For example, Theorem 1 states that if we assume the data are generated by a polynomial graph filter, then using a polynomial graph filter as a model is better than using a first-order convolution. This is a tautology. Similarly, assuming that the true adjacency can be decomposed into diagonal and off-diagonal terms, Theorem 2 concludes that using both is better than using only the diagonal terms. Again, this is trivial.\n\n* **Poor empirical design.** The empirical evaluation has several serious issues.  \n    - No standard deviations are reported for any of the results, making it difficult to draw meaningful conclusions. Moreover, the paper states that it directly uses results from prior works such as FourierGNN and StemGNN. This is problematic for several reasons: (1) even small differences in preprocessing, batching, or data splitting can lead to significantly different results, making a direct comparison meaningless; and (2) both FourierGNN and StemGNN suffer from reproducibility problems, with many open GitHub issues reported in their repositories. For instance, a known bug in StemGNN allowed the model to access future data. This makes the reported empirical results difficult to trust.  \n    - Showing that model performance deteriorates when the correlation structure becomes more dynamic (Tables 1 and 2) is unsurprising, as the task itself becomes harder. Indeed, performance deteriorates for all models, including DynGCN, and the largest performance gap in Table 2 w.r.t. TPGNN occurs for the lowest level of “TCV”.\n\n* **Limited technical contribution.** The use of polynomial graph filters is standard in many existing architectures, as acknowledged in the paper. Combining this with the use of different adjacency matrices is not particularly novel. Theorem 2 seems to imply that the static adjacency matrix is diagonal, which would make it equivalent (up to rescaling) to the identity matrix — effectively implementing a skip connection.\n\nThese flaws make the paper fall well below the acceptance threshold.\n\nAdditional comments:\n\n- Broken reference in line 219."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qCKxtZshFs", "forum": "EVMdH7Y3ug", "replyto": "EVMdH7Y3ug", "signatures": ["ICLR.cc/2026/Conference/Submission24180/Reviewer_mXrX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24180/Reviewer_mXrX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838940500, "cdate": 1761838940500, "tmdate": 1762942978557, "mdate": 1762942978557, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DYNGCN, a graph neural network (GNN) framework for multivariate time series forecasting (MTSF) that explicitly models dynamic correlations between variables. Traditional GNN-based MTSF methods assume a static correlation structure, limiting their effectiveness when relationships evolve over time. The framework introduces two key components: High-order correlation–based message passing and Static and dynamic propagation separation. The paper also introduces Temporal Correlation Volatility (TCV) to quantify how much pairwise correlations change over time, linking it to model performance degradation. The theoretical proofs and empirical evaluation on synthetic and six real-world datasets show significant performance gains over 21 baselines, including GNNs and Transformers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper addresses a key limitation of existing GNN-based forecasters: the assumption of static correlations. It convincingly argues and demonstrates that dynamic correlations degrade performance of many state-of-the-art GNN and Transformer baselines (e.g., Informer, Autoformer, MTGNN).\n\n2.\tStrong clarity in theoretical guarantees on the properties of the time-varying adjacency matrix (Locality, Soft-Transitivity, Diagonal-Dominance, Additivity).\n3.\tThe paper presents a novel quantitative measure (TCV), a model-agnostic measure to capture dynamic correlation shifts. It seems to add diagnostic value to time series analysis.\n4.\tExperiments are extensive and include memory and computational analysis."}, "weaknesses": {"value": "1.\tAppendix is cited in the paper, but it is not attached. I see some major flaws because of this. It makes it impossible to verify proofs, hyperparameter settings, and some theoretical derivations.\n\n2.\tThis omission significantly affects reproducibility and completeness.\n\n3.\tTechnical details are not clear/ incomplete. So, reproducibility is a concern. For e.g., the construction of the dynamic adj_matrix is not fully described. Does it rely on sliding-window covariance, online learned embeddings, or temporal smoothing? How are the polynomial coefficients are not described too.\n\n4.\tCovariance vs. Correlation: Definition 1 defines the adjacency matrix as the sample covariance (A = (1/T)XX^T), but the paper repeatedly refers to \"correlation.\" Covariance and correlation are different. And the mixed usage is confusing here. Or will both produce similar results? (Normalized vs unnormalized?)\n\n5.\tSome reported relative improvements (e.g., 98% MAE reduction on the Electricity dataset) seem implausibly large compared to prior literature. 98% improvement sounds unreasonable, or it is a groundbreaking methodology (not supported by other results)\n\n6.\tThe robustness analysis to noise and missing data is important for validating dynamic scenarios as mentioned in the problem statement. Also, the stability/scalability analysis.\n\n7.\tIn page 4, Theorem 1: The theorem claims that high-order GCN layers reduce prediction error under certain conditions, but the proof is missing or not cited correctly. \n\n8.\tIn page 5, theorem 2 proof is missing. Table 9 is cited but not present in the paper. The connection between \"expressiveness\" and \"empirical risk\" is unclear, and the assumption of a linear signal model undermines generalizability.\n\n9.\tNo visualization of correlation graph dynamics or qualitative examples of how TCV affects learned structure. Adding heatmaps or temporal edge-weight visualizations would strengthen insight."}, "questions": {"value": "Refer the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Pd1jkc4Mp7", "forum": "EVMdH7Y3ug", "replyto": "EVMdH7Y3ug", "signatures": ["ICLR.cc/2026/Conference/Submission24180/Reviewer_ka7G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24180/Reviewer_ka7G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761870363303, "cdate": 1761870363303, "tmdate": 1762942978298, "mdate": 1762942978298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of modeling dynamic correlations in multivariate time series forecasting. The authors propose DynGCN, a graph neural network framework that captures both high-order and time-varying correlations through two key designs: high-order message passing and static–dynamic propagation separation. The authors also introduce the Temporal Correlation Volatility (TCV) to quantify the degree of correlation dynamics."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies an important issue in multivariate time series forecasting—the dynamic nature of inter-variable correlations—and provides empirical evidence that many existing graph-based models fail under high TCV.\n\n2. The authors provide theoretical analyses supporting the benefits of high-order message passing and static–dynamic propagation separation."}, "weaknesses": {"value": "1. The presentation should be improved. For example, in Section 2, the proposed TCV metric is discussed together with general theoretical foundations, making it difficult to discern what is newly introduced in this work.\n\n2. The paper does not provide a clear definition or construction procedure for the two adjacency components $A_{stat}$ and $A_{dyn}$ in Eq. (7). It is unclear whether they are computed directly from time-varying correlations or learned implicitly through network parameters.\n\n3. The implementation of the DCRNN component appears inconsistent with the description in the paper, as the model files do not contain the core model logic. Moreover, the paper does not clearly explain how DynGCN handles sequential data —treating the graph propagation output directly as the final prediction seems conceptually incomplete or inadequate for a time series forecasting task.\n\n4. At line 300, the paper defines the output as $\\hat{Y} = softmax(H^{final} W_c)$ , implying that each node produces a prediction sequence of length $T$, followed by a softmax operation. This design choice is unusual, as softmax is typically unnecessary—and indeed inappropriate—for time series forecasting, where the outputs are continuous values rather than categorical probabilities. Applying softmax forces each node’s predictions to sum to one across the time dimension $\\sum_{t=1}^T\\hat{Y}_{n,t} = 1$, which treats the output as a probability distribution rather than a regression sequence.\n\n5. The experimental setup does not clearly explain how the sequential data are handled. While the baselines are all time-series forecasting models, the paper does not specify the input and output sequence lengths. In addition, most of the selected baseline methods are outdated."}, "questions": {"value": "See W1-W5."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AvWj1ffgbK", "forum": "EVMdH7Y3ug", "replyto": "EVMdH7Y3ug", "signatures": ["ICLR.cc/2026/Conference/Submission24180/Reviewer_o9FS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24180/Reviewer_o9FS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762178371581, "cdate": 1762178371581, "tmdate": 1762942977916, "mdate": 1762942977916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}