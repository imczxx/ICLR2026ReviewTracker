{"id": "j20Eld6rmT", "number": 16023, "cdate": 1758258766279, "mdate": 1759897266956, "content": {"title": "IndexNet: Timestamp and Variable-Aware Modeling for Time Series Forecasting", "abstract": "Multivariate time series forecasting (MTSF) plays a vital role in a wide range of real-world applications, such as weather prediction and traffic flow forecasting. Although recent advances have significantly improved the modeling of temporal dynamics and inter-variable dependencies, most existing methods overlook index-related descriptive information, such as timestamps and variable indices, which carry rich contextual semantics. To unlock the potential of such information and take advantage of the lightweight and powerful periodic capture ability of MLP-based architectures, we propose IndexNet, an MLP-based framework augmented with an Index Embedding (IE) module. The IE module consists of two key components: Timestamp Embedding (TE) and Channel Embedding (CE). Specifically, TE transforms timestamps into embedding vectors and injects them into the input sequence, thereby improving the model's ability to capture long-term complex periodic patterns. In parallel, CE assigns each variable a unique and trainable identity embedding based on its index, allowing the model to explicitly distinguish between heterogeneous variables and avoid homogenized predictions when input sequences seem close. Extensive experiments on 12 diverse real-world datasets demonstrate that IndexNet achieves comparable performance across mainstream baselines, validating the effectiveness of our temporally and variably aware design. Moreover, plug-and-play experiments and visualization analyses further reveal that IndexNet exhibits strong generality and interpretability, two aspects that remain underexplored in current MTSF research.", "tldr": "", "keywords": ["Multivariate Time Series Forecasting (MTSF)", "IndexNet", "Index Embedding (IE)", "Timestamp Embedding (TE)", "Channel Embedding (CE)"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/84455c0b0cee28b311637eb0e355b916c3a23c24.pdf", "supplementary_material": "/attachment/0f4e183609af2c0f5bb9a373cba3bc41d7a04d15.zip"}, "replies": [{"content": {"summary": {"value": "IndexNet proposes an MLP-based framework for multivariate time series forecasting, incorporating timestamp and variable index information through an Index Embedding module. The model demonstrates competitive performance on various datasets and offers interpretability through visualization of embeddings. However, the novelty and motivation of the approach require further justification, and the theoretical foundation could be strengthened."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Index Embedding:** The use of separate timestamp and variable index embeddings offers a unique perspective on incorporating index-related information into MTSF models, potentially capturing temporal and variable-specific dynamics effectively.\n\n**Competitive Performance:** IndexNet achieves competitive results compared to state-of-the-art models on diverse datasets, including both long-term and short-term forecasting tasks.\n\n**Analysis:** The visualization of embeddings provides valuable insights into the learned temporal patterns and variable relationships."}, "weaknesses": {"value": "**Limited Innovation:** The proposed approach builds upon existing MLP-based architectures, with the Index Embedding module being a relatively straightforward extension.\n\n**Weak Motivation:** The paper lacks a strong motivation for the proposed approach. A more detailed discussion on the limitations of existing methods and the specific benefits of incorporating index information would strengthen the paper’s rationale.\n\n**Theoretical Foundation:** The paper lacks a thorough theoretical foundation for the proposed method. Exploring the theoretical underpinnings of the Index Embedding module, such as its connection to existing time series analysis techniques, would enhance the paper’s depth.\n\n**Limited Effectiveness:** While the model demonstrates competitive performance, the improvements over existing methods are marginal."}, "questions": {"value": "Same as Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rr8pHQAajk", "forum": "j20Eld6rmT", "replyto": "j20Eld6rmT", "signatures": ["ICLR.cc/2026/Conference/Submission16023/Reviewer_zjSB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16023/Reviewer_zjSB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16023/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760844240740, "cdate": 1760844240740, "tmdate": 1762926228139, "mdate": 1762926228139, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents **IndexNet**, an MLP-based model for multivariate time-series forecasting that explicitly encodes **Timestamp** and **Channel Identity** via **Timestamp Embedding (TE)** and **Channel Embedding (CE)**. The MLP backbone captures short-term periodic-pattern capture with low computational cost; TE models long-term seasonalities, while CE distinguishes channel identities. Experiments show that IndexNet delivers superior performance with low computational cost and nice interpretability."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well organized: the method is clearly presented and the experiments are reasonably complete.\n\n2. The design is simple and efficient; visualizations of TE/CE convincingly demonstrate the model's interpretability.\n\n3. The method explicitly models timestamps and channel identities—the key factors often overlooked yet intuitively crucial for forecasting.\n\n4. Strong results on an MLP backbone, with consistent gains when integrated into CNN and Transformer backbones, showing nice generalization ability."}, "weaknesses": {"value": "1. Evaluation is largely confined to week/day/hour/minute cycles on relatively small datasets spanning only a few years, making the effectiveness on month/year seasonality insufficiently validated.\n\n2. Real-world periodicities are not always cleanly cyclic (e.g., week definitions vary; year sequences may have no natural endpoint). The paper would benefit from discussing or testing non-cyclic/irregular encodings.\n\n3. TE/CE yield striking gains on the MLP backbone but relative small improvements on CNN/Transformer backbones. Deeper analysis (e.g., interaction with attention/convs, capacity-matched baselines) would clarify the bottlenecks and strengthen the contribution."}, "questions": {"value": "1. As paper note (L246–L258), current evaluated datasets are small and short, making year/month seasonality hard to assess. Can you validate on larger, longer-span datasets?\n\n2. How to encode years in practice? Real data rarely form clean year-to-year cycles. What is your strategy for non-cyclic or drifting yearly patterns?\n\n3. TE/CE yield strong gains on the MLP backbone but relative smaller improvements on CNN/Transformer baselines. What explains this gap (e.g., redundancy with attention/convs, capacity limits, training dynamics)?\n\n4. Clarify differences from related work—especially methods in Figure 1(b). What is difference in IndexNet's TE/CE design compared with prior works(e.g. GLAFF, Autoformer), and how does it alter the modeling pipeline?\n\n5. In the NIPS 2024 workshop [1], some researchers pointed out that current methods sometimes use the \"drop-last\" trick [2] to improve performance. Therefore, It is recommended that you clarify whether the \"drop - last\" operation was used in your paper in the implementation details section of your paper for transparency.\n\n[1] Fundamental limitations of foundational forecasting models: The need for multimodality and rigorous evaluation\n\n[2] TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "V9bfHZvHAW", "forum": "j20Eld6rmT", "replyto": "j20Eld6rmT", "signatures": ["ICLR.cc/2026/Conference/Submission16023/Reviewer_wzzB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16023/Reviewer_wzzB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16023/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761565029831, "cdate": 1761565029831, "tmdate": 1762926227575, "mdate": 1762926227575, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "**Problem.** In multivariate time-series forecasting (MTSF), two major paradigms exist: Channel-Independent (CI) and Channel-Dependent (CD). The authors argue that existing methods either ignore the explicit timestamp semantics or overlook variable identity (channel index), limiting interpretability and robustness.\n\n**Method.** The paper proposes **IndexNet**, a lightweight MLP-based forecasting model enhanced with an **Index Embedding (IE)** module, including:\n\n- **Timestamp Embedding (TE):**  \n  Learns embeddings from discrete calendar fields such as minute/hour/day/week/month. These embeddings are indexed by timestamp and summed, then concatenated with the projected input representations. (Fig. 2, §3.3)\n\n- **Channel Embedding (CE):**  \n  Assigns a learnable identity vector to each variable, concatenated with time-aware features to distinguish channels explicitly. (§3.4)\n\n- **Backbone:**  \n  A residual MLP stack (two Linear + ReLU layers), followed by a linear prediction head for horizon *T*. (§3.5)\n\n**Results.** Evaluated on 12 datasets (Tab. 1, Tab. 7), IndexNet reportedly achieves comparable or better SOTA performance on average, especially with long lookback windows (L = 336) while reducing GFLOPs and inference latency (Tab. 3). Ablations (Tab. 2‒3, Tab. 9‒10) show both TE and CE contribute positively. PCA visualizations (Fig. 3‒4) claim to capture periodicity and variable similarity.\n\n**Claimed contributions**:  \nA general, interpretable, plug-and-play module (TE + CE) that works efficiently within CI/MLP frameworks for MTSF."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Simple & efficient: MLP + embedding concatenation yields strong latency/complexity profiles\n- Broad validation across 12 datasets and multiple horizons\n- Plug-and-play potential demonstrated on different models\n- Visual results improve interpretability for timestamp embedding"}, "weaknesses": {"value": "### (a) Inconsistent logic and notation\n- §3.3 states that each time embedding has dimension **L**, but the formulas later use **T_dim**, and concatenation yields **d_model + T_dim** (p.5).  \n  This conflicts with Fig. 2 and raises uncertainty about how TE aligns with the temporal dimension.\n- Subscripts of \\( z, z_t, z_{t,c} \\) are semantically inconsistent across §3.3‒3.5 (time steps vs. variable-level features), creating ambiguity for implementation.\n\n### (b) Complexity\n- The training cost (like duration, complexity) compared to previous work was not calculated.\n\n### (c) Ambiguity in plug-and-play evaluation\n- In Tab. 4 (§4.5), IE / TE / CE are stacked alongside other “plugins” (GALF / VH), but the label semantics are confusing, making it difficult to quantify the **stand-alone** contribution of IE.\n\n### (d) Prior art not properly acknowledged\nThe claim “timestamps and variable identity are ignored by existing methods” is overstated. Many works already incorporate:\n\n- **Time embeddings** in MTS models (e.g. Informer/TimesNet)\n- **Plug-and-play timestamp modules** (e.g., GLAFF)  \n- **Learnable semantic time vectors** (Time2Vec, D2Vformer)\n\n**Verdict:** Method is reasonable, but the paper needs clearer formulation, more rigorous and fair comparisons, and more accurate positioning in related work."}, "questions": {"value": "1. **Novelty claim inflation & insufficient related-work positioning**  \n   Must clarify differences vs. GLAFF, Time2Vec, D2Vformer.\n\n2. **Dimension & alignment not rigorously defined**  \n   TE shape and its sliding-window handling require precise tensor diagrams or pseudocode.\n\n3. **Generalization to new or reordered variables**  \n   CE depends on fixed indices—robustness to unseen channels not discussed.\n\n4. **Used of featrures**\n   Why were these calendar features chosen from the paper, and why weren't other features like \"quarters,\" \"holidays,\" and \"Month of Year\" included? It is unclear whether **all** baselines receive the same exogenous features; otherwise results are asymmetric."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "1. **Novelty overstated relative to existing literature**  \n   The paper frames the incorporation of timestamp semantics and variable identity as a neglected problem. However, these ideas have been widely explored:\n   - Timestamp embeddings in Transformer-based MTS models (e.g., Informer, Autoformer, TimesNet)\n   - Learnable timestamp representations (Time2Vec, D2Vformer)\n   - Plug-and-play timestamp modules (GLAFF)\n   The contribution appears incremental rather than conceptually new.\n\n2. **Inconsistency and ambiguity in tensor formulations**  \n   §3.3 introduces contradictory claims regarding TE dimension (**L** vs. **T_dim**) and the concatenated shape (**d_model + T_dim**).  \n   This creates uncertainty in how TE interacts with:\n   - Temporal axis alignment\n   - Sliding-window inference\n   - Positional encodings  \n   Implementation could easily diverge from author intentions.\n\n3. **Fairness issues in comparative studies**\n   - Traffic dataset uses extended external features (year/month), but it is unclear if **all** baselines were given the same inputs.  \n   - Table 4 does not isolate the independent contribution of IE (TE/CE), confounding plugin combinations with other modules.\n\n4. **Generalization and robustness concerns**\n   - CE strictly binds embeddings to observed channel indices.  \n     → What happens with **unseen variables**, reordered channels, or dynamic sensor sets?\n   - Timestamp construction via modulo could lead to misalignment across splits or test-time calendar shift.\n\n5. **Lack of direct comparisons against most relevant baselines**\n   Given the claim of plug-and-play design, a fair validation should compare **within identical backbones** against:\n   - Time2Vec / D2Vformer\n   - GLAFF (timestamp plugin)\n   Without such ablations, the empirical advantage of IE remains unclear."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "g6Imt8xOEU", "forum": "j20Eld6rmT", "replyto": "j20Eld6rmT", "signatures": ["ICLR.cc/2026/Conference/Submission16023/Reviewer_gtK3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16023/Reviewer_gtK3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16023/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849191808, "cdate": 1761849191808, "tmdate": 1762926227083, "mdate": 1762926227083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **IndexNet**, a multivariate time series forecasting model designed to effectively incorporate **timestamp** and **variable index** information using a lightweight MLP-based framework. It introduces an **Index Embedding (IE)** module, consisting of **Timestamp Embedding (TE)** and **Channel Embedding (CE)**, to improve prediction accuracy and model interpretability by leveraging the temporal and variable-specific patterns in the data. The model achieves competitive forecasting performance across multiple real-world datasets, demonstrating robustness and efficiency, especially in capturing periodic and heterogeneous dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. **Well-written**: The paper is clearly written, with a well-structured presentation of the methodology and results. The descriptions of the model and its components, such as the **Index Embedding (IE)** module and the **Timestamp Embedding (TE)** and **Channel Embedding (CE)** submodules, are clear and detailed, making it easy to follow the approach and understand its contributions.\n\n2. **Significant Experimental Results**: The experiments show that **IndexNet** outperforms several state-of-the-art models across a variety of real-world datasets, demonstrating its effectiveness in improving forecasting accuracy and reliability. The results are consistent and robust across different domains, validating the model’s ability to capture both temporal and variable-specific dynamics effectively."}, "weaknesses": {"value": "Here is the revised and translated version of your review:\n\n---\n\n**Weakness**:\nMy primary concern lies in the similarity between this paper and STID \\[1]. Although the paper cites STID, the methodology section appears to be almost identical to STID. The main difference between IndexNet and STID seems to be the addition of a few timestamp features. If that is indeed the case, I believe the innovation in this paper is nearly nonexistent and may raise potential ethical concerns.\n\n\\[1] Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting. CIKM 2022.\n\n---\n\nThis version maintains the essence of your review while improving clarity and flow in English."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vT30999cI2", "forum": "j20Eld6rmT", "replyto": "j20Eld6rmT", "signatures": ["ICLR.cc/2026/Conference/Submission16023/Reviewer_owj6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16023/Reviewer_owj6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16023/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010378406, "cdate": 1762010378406, "tmdate": 1762926226668, "mdate": 1762926226668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}