{"id": "imb1oWYpa8", "number": 14651, "cdate": 1758240832721, "mdate": 1759897357174, "content": {"title": "When Uncertainty, Coverage, and Representation Matter in Active Learning Frameworks", "abstract": "Active learning (AL) aims to reduce annotation costs by querying informative and representative samples for labeling. Despite significant progress, many AL methods remain heuristic and lack a unified theoretical foundation. We present the first systematic and theory-guided framework that connects the core principles of AL (uncertainty, representation, and coverage) to a decomposition of generalization error into empirical risk, distributional discrepancy, model complexity, and confidence. This mapping not only explains why different AL strategies excel under varying annotation budgets but also provides a blueprint for designing future methods, positioning our work as a foundation for principled AL development. Our analysis unifies prior empirical observations into a generalization-theoretic foundation, complemented by extensive experiments on CIFAR and ImageNet subsets with self-supervised embeddings and pretrained encoders. Results show that representation is critical in early rounds to address cold-start issues; coverage promotes diversity in mid-budget regimes; and uncertainty becomes most effective once decision boundaries are partially learned. We also observe that while per-sample reductions in model complexity are modest, their cumulative effect across acquisition rounds is substantial. We further assess runtime behavior, highlighting trade-offs between theoretical alignment and scalability.  Rather than proposing a new method, our contribution is a unifying and generalizable framework that explains strategies and guides principled AL design, bridging theory and practice.", "tldr": "In this work, we present a principled, theory-guided framework to explain and predict the behavior of diverse AL strategies across datasets, budget regimes, and training conditions.", "keywords": ["active learning", "deep learning", "generalization error", "self-supervised learning", "cold-start problem", "uncertainty", "scalability"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fa37953158ab69f9e2481e415c434b439cf9ab81.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a PAC learning-based theoretical framework for analyzing which active learning strategy is most effective in different sample size regimes."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The research question the paper focuses on is an exciting one: what sampling method works best for different data size regimes?\n- The paper presents extensive experiments."}, "weaknesses": {"value": "**Significance of the theoretical results.** It is unclear why the framework of risk bounds for domain adaptation is appropriate for capturing the benefits of active learning\n- Assuming the distributional setup proposed in the paper, the upper bound of Ben-David et al seems unsuitable for characterizing the risk of active learning. To illustrate this, let us assume a noiseless and realizable learning problem. Therefore, the minimizer of the empirical risk on $S$ can always have $0$ training error. Passive learning would lead to an upper bound in equation 11 with a vanishing discrepancy term. It is a well-known fact that an uncertainty-based sampling strategy can lead to exponential improvements in sample complexity in the large sample regime. However, such a strategy would lead to a distribution $P_Q$ concentrated close to the decision boundary, which in turn would lead to a large distribution discrepancy term. Therefore, the upper bound for the AL strategy is larger than the upper bound for passive learning.\n- Lines 256-258 claim that selecting samples with high loss leads to low error on the target distribution $P_Z$. This statement seems incorrect: the empirical risk term present in the left-hand side of the bound should be minimized in order to reduce the target risk, and hence, it suggests selecting samples with low loss, contrary to what uncertainty-based AL algorithms do.\n- The framework proposed in section 3 lacks lower bounds, which makes it impossible to draw conclusions about how to rank AL strategies in different sample size regimes.\n\n**Positioning in the literature.** There are a few claims in the paper that could benefit from being better placed in the context of prior works:\n- There are a number of works that discuss different sample size regimes and what optimal sampling algorithms perform better, e.g. https://arxiv.org/abs/1911.09162, https://arxiv.org/pdf/2212.00772. In particular, the latter also proposes theoretical arguments for why different strategies work better in different sample size regimes.\n- In addition to the works referenced in lines 105-109, there are a few others that propose sampling algorithms similar to uncertainty sampling which would be worth mentioning, such as https://www.cs.cmu.edu/~ninamf/papers/active-ls.pdf, https://arxiv.org/abs/1802.09841 etc. Notably, in this context “uncertainty sampling” can be a bit of a misnomer – uncertainty implies a notion of uncertainty which may or may not be implied by some of these methods (for instance margin-based sampling does not require that such a notion of uncertainty be assumed)\n\n\n**Minor issues**\n- figure 1 not particularly clear, both visually and in terms of its takeaway – while UHerding exhibits a clearly different sampling pattern at large budgets, the other methods seem largely similar \n- the empirical risk in equation 11 is defined later in equation 12 as the empirical mean of the cross-entropy loss; however, equation 11 is proved in Ben-David et al to hold for the 0-1 loss."}, "questions": {"value": "- what is the fundamental difference between representation-based and coverage-based sampling? from their definitions in section 2 they seem to target similar objectives"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lqUP0Mi2lC", "forum": "imb1oWYpa8", "replyto": "imb1oWYpa8", "signatures": ["ICLR.cc/2026/Conference/Submission14651/Reviewer_CEPw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14651/Reviewer_CEPw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761499699411, "cdate": 1761499699411, "tmdate": 1762925023868, "mdate": 1762925023868, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates active learning within a PAC learning framework, focusing on a bound that decomposes the generalization error (or true risk) into four distinct components: empirical risk, distributional discrepancy, model complexity, and confidence. The authors map the core principles of various AL strategies to these four theoretical components, offering a discussion on what each strategy effectively optimizes within the decomposition. The experimental evaluation utilizes image classification datasets and explores known AL phenomena, such as the impact of budget size or the cold-start problem."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is extremely well-written and easy to follow.\n- The problem addressed is highly important, as it provides theoretical insights into what AL strategies focus on through the lens of generalization.\n- The experiments cover a broad range of complexities by including CIFAR-10 and CIFAR-100, as well as different variants of ImageNet."}, "weaknesses": {"value": "**Clarity of Theoretical Contribution**\n\nMy primary concern relates to the novelty and scope of the theoretical contribution. The paper introduces the decomposition (Eq. 11) and states, \"We decompose the error into four components.\" However, the subsequent citation to Menden et al. suggests this decomposition may stem from related work, which leads to ambiguity, especially given that **no derivation** of the bound is provided.\n\n- **Contribution Clarity:** It is critical to clarify whether the decomposition of the bound itself is a novel contribution or if it originates from Menden et al. If the latter, this should be explicitly stated and highlighted in the introduction to ensure precision in defining the paper's scope.\n- **Framework Definition:** Given that the main body seems to be a discussion connecting established Active Learning (AL) strategies to specific terms in an existing bound, the claim of providing a \"framework\" needs clarification. Could you please elaborate on what constitutes the novel framework proposed here? Is it the novel combination, the specific interpretation, or something else entirely?\n- **Significance:** If the decomposition is not novel and the main body primarily consists of a discussion, the overall contribution of the paper is significantly diminished, which impacts my current score. Sharpening the wording regarding the origin of the decomposition is necessary to resolve this critical point.\n\n**Experimental Rigor and Reproducibility**\n\nThe presentation of the experimental methodology and results requires greater detail and rigor.\n\n- **Replication and Statistics:** The absence of statistical measures (such as standard error or deviation) is a significant limitation. Given the known high variability of AL experiments [1, 2], especially at low sample sizes, a single AL run is generally insufficient to draw reliable conclusions. Did the authors repeat experiments and average metrics, or was each experiment only a single AL run? This crucial information should be provided and discussed.\n- **Experimental Protocol:** While the authors mention following the protocol of Hacohen et al. (2022), this is insufficient detail. More comprehensive information regarding the experimental setup should be available, at least in the appendix, to ensure reproducibility.\n\n**Evaluation Scope and Connection to Theory**\n\nThe evaluation section is limited in scope and lacks a clear connection to the theoretical decomposition.\n\n- **Limited Evaluation Focus:** The evaluation primarily focuses on concepts already established in the literature (e.g., exploring early and refining late). This results in a repetition of known insights.\n- **Missing Theory-Experiment Link:** Despite occasional mentions of the decomposition, the experimental design does not appear to be clearly structured to systematically study the influence of the individual components within the bound. A clearer connection demonstrating how each experiment quantitatively isolates or studies a specific component of the decomposition would substantially strengthen the contribution.\n- **Qualitative Evidence:** Reliance on qualitative assessments, such as single-run t-SNE visualizations, is insufficient for drawing strong conclusions in highly variable AL settings. Quantitative metrics should be prioritized.\n\n**Related Work and Vague formulation:**\n\n- **Related Work:** The related work section is too limited. The discussion should be broadened to include works that have empirically investigated the influence of the specific factors (e.g., studies on uncertainty sampling [3, 4]). Discussing how the proposed theoretical perspective adds to or complements these existing empirical findings would significantly improve the paper's context and relevance.\n- **Conceptual Distinction:** The distinction between \"coverage\" and \"representativeness\" in Section 4.2 remains vague. The text states that \"representation-based methods capture broad data diversity\" and \"coverage-driven strategies... explor[e] the feature space more effectively.\" To an active learning researcher, both descriptions essentially imply exploring the feature space. Please provide a clear, precise, and formalized distinction between these two concepts.\n\n**Minor Issues:**\n\n- Fix citations to properly use parentheses.\n- Improve the DPI quality of TSNE Visualizations.\n\n[1] P. Munjal et al., “Towards Robust and Reproducible Active Learning Using Neural Networks\", in *CVPR*, 2022.\n\n[2] T. Werner et al. \"A cross-domain benchmark for active learning\", in *NeurIPS,* 2024.\n\n[3] J. Li et al. \"Bal: Balancing diversity and novelty for active learning.\" *in TPAMI* 2023.\n\n[4] D. Huseljic et al. “The Interplay of Uncertainty Modeling and Deep Active Learning: An Empirical Analysis in Image Classification”, in *TMLR*, 2024."}, "questions": {"value": "Could you comment on the points mentioned under “Weaknesses”?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4rimztGtJ7", "forum": "imb1oWYpa8", "replyto": "imb1oWYpa8", "signatures": ["ICLR.cc/2026/Conference/Submission14651/Reviewer_hnNz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14651/Reviewer_hnNz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904336209, "cdate": 1761904336209, "tmdate": 1762925023457, "mdate": 1762925023457, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for understanding active learning (AL) through the decomposition into four components: empirical risk, distributional discrepancy, model complexity, and confidence. The authors map these components to the three core AL principles—uncertainty, representation, and coverage—providing a unified view that explains the empirical success of diverse AL strategies under different labeling budgets. The framework is validated through experiments on CIFAR and ImageNet subsets, analyzing how various AL methods behave across budget regimes and dataset complexities."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(S1) The paper provides a theoretical lens linking active learning principles to generalization theory.\n(S2) The paper helps explaining previously observed trends (e.g., when uncertainty vs. diversity dominates).\n(S3) The paper is generally well structured and readable."}, "weaknesses": {"value": "(W1) Lack of Direct Validation of the Core Theoretical Claims: A central issue of the paper is that the proposed mapping between the four generalization error components and active learning principles is never directly validated. The empirical results mainly show accuracy trends and qualitative t-SNE visualizations, but do not quantify or isolate the claimed error terms. For example, the distribution discrepancy term is discussed; the model complexity term is linked to Rademacher complexity yet never estimated or tracked during learning; and empirical risk reduction is inferred from uncertainty sampling without measuring loss trajectories on queried samples. As a result, the framework functions more as a post-hoc interpretation of known AL behavior rather than a predictive and testable theory. The causal link between the four generalization components and observed performance remains largely speculative.\n(W2) Lacks ablation studies; moreover, the baseline methods are not directly tied to the core arguments of the paper. The baseline results cannot directly demonstrate the performance or the roles of the four key arguments proposed in the paper.\n(W3) Experiments rely on outdated datasets (CIFAR, small ImageNet subsets).\n(W4) Baseline methods are severely outdated and there’s limited discussion of modern large-scale or multimodal AL scenarios. Together with the reliance on outdated datasets, it limits the applicability of the findings to the latest image classification tasks and recent large models. The scalability of the proposed framework is highly questionable.\n(W5) The qualitative visualizations in Figure 1 only indicate where points are selected in the embedding space, which does not itself validate whether such selections are actually effective for improving performance. A behavior may look “reasonable” yet still lead to suboptimal learning outcomes. Robust conclusions also require quantitative evidence, not just visual intuition."}, "questions": {"value": "(Q1) How sensitive are your conclusions to model architecture or embedding dimensionality? Specifically, will the proposed framework reach similar findings when extended to large- or multimodal base models (e.g., CLIP, ViT, LLaVA)?\n(Q2) What is the real-world meaning of studying AL under the selected baseline models in this work? Specifically, it is true AL helps reduces annotation cost, but the lack of  studying under recent SOTA models severely limits the practical meaning of this work.\n\nPlease explain how you will modify the paper specifically. As reviewers, we are not interested in just private education but in how the manuscript will be improved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d2QCrp84MB", "forum": "imb1oWYpa8", "replyto": "imb1oWYpa8", "signatures": ["ICLR.cc/2026/Conference/Submission14651/Reviewer_jJe5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14651/Reviewer_jJe5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908366804, "cdate": 1761908366804, "tmdate": 1762925022992, "mdate": 1762925022992, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes an analysis framework that connects the traditional probably approximately correct (PAC) learning approach with the active learning (AL) process. Specifically, the authors decompose the generalization error of passive machine learning into empirical risk, model complexity, distributional discrepancy, and confidence terms. Based on this framework, they revisit the common design choice of active learning methods categorized into uncertainty, coverage, and representation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. They develop the analysis framework from the PAC learning and extend it to the AL framework, which reveals the differences, such as non-i.i.d. sampling and the impact of budget size.\n2. They give the empirical results to show that the uncertainty, coverage, and representation play different roles under various budget regimes, which might be useful to review the previous AL algorithms and for future design."}, "weaknesses": {"value": "1. **Need to discuss more related works.** About fitting the generalization error to the AL process, for example, (1) also proposed the unified framework of decomposing the generalization error (expected risk) into the empirical risk and the distribution discrepancy, and further proposed the practical solution for the deep active learning paradigm. Although this work focuses on the analysis framework without proposing a new method, it should also cover more related works to recall previous efforts in this area, such as (2).\n2. **Clarify the differences between Representation and Coverage.** While decoupling the terms of diversity-based methods (3) from the representation and coverage is novel, it should differentiate more carefully in Section 2. For example, *Coverage-based methods promote broad exploration of the input space using geometric or probabilistic criteria.* Even if we use probabilistic criteria, why can not we interpret it as a kind of representation-based method? Or, given the coverage aspect, what insights could we gain that are different from the representation-based method?\n3. Following 2., *TypiClust as representation-based clustering that selects typical (high-density) and diverse samples; ...; ProbCover that maximizes probabilistic coverage of the feature space*. What is the key difference between TypiClust and ProbCover beyond the different approaches to achieve more coverage of the feature spaces?\n4. **Reveal more parts of the experimental settings.** In your experiments, do you retrain the whole ResNet-X or only fine-tune the last or the penultimate layer?\n5. Following 4., Figure 1 seems to indicate that you keep the feature extraction layers, i.e., the layers before classifying. It seems obvious that the representation methods explore more in the early stages, given this setting. However, what if we retrain whole networks during the AL process? Does the observation still hold for the representation methods?\n6. **Provide more derivation of Eq. (11).** It is unclear to me how to obtain the *Model Complexity* and *Confidence term* given the previous Sections. Could you provide more explanations? For example, the probabilistic sample complexity tells us that $m = \\mathcal{O}(d, \\delta, \\epsilon)$. Why does the dimension $d$ disappear in Eq. (11) of the Confidence term?\n\n- (1) Shui, C., Zhou, F., Gagné, C., & Wang, B. (2020, June). Deep active learning: Unified and principled method for query and training. In International conference on artificial intelligence and statistics (pp. 1308-1318). PMLR.\n- (2) Wang, Z., & Ye, J. (2015). Querying discriminative and representative samples for batch mode active learning. ACM Transactions on Knowledge Discovery from Data (TKDD), 9(3), 1-23.\n- (3) Ren, P., Xiao, Y., Chang, X., Huang, P. Y., Li, Z., Gupta, B. B., ... & Wang, X. (2021). A survey of deep active learning. ACM computing surveys (CSUR), 54(9), 1-40."}, "questions": {"value": "1. For the Model Complexity, you refer to (4) (I guess that you refer to Sec 4.2?) to measure the empirical Rademacher complexity as the Eq. (14). However, their design for the neural networks is only explained for the two-layer neural networks. How could we ensure that the measurement still holds for the ResNet or other types of convolutional neural networks (CNNs)?\n\n- (4) Bartlett, P. L., & Mendelson, S. (2002). Rademacher and gaussian complexities: Risk bounds and structural results. Journal of machine learning research, 3(Nov), 463-482."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lM9QO5dici", "forum": "imb1oWYpa8", "replyto": "imb1oWYpa8", "signatures": ["ICLR.cc/2026/Conference/Submission14651/Reviewer_DEhC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14651/Reviewer_DEhC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933986185, "cdate": 1761933986185, "tmdate": 1762925022308, "mdate": 1762925022308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}