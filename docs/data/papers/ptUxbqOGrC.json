{"id": "ptUxbqOGrC", "number": 18118, "cdate": 1758284040909, "mdate": 1759897132445, "content": {"title": "Diversity for The Win: Towards Building Multi-Agent Systems with Heterogeneous LLMs", "abstract": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by enabling cooperation among multiple specialized agents. However, most existing MAS frameworks rely on a single LLM to drive all agents, constraining the system's intelligence to the limitations of that model. This paper explores the paradigm of heterogeneous LLM-driven MAS, aiming to elevate the system's potential to the collective intelligence of diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to evaluate the performance of various LLMs across different domains and MAS-related functions. Through an extensive empirical study, we assess 28 LLMs across 5 domains (encompassing 21 test sets) and 5 functions, conducting over 1.7 million evaluations to identify optimal model selections for each domain-function combination. Building on these findings, we demonstrate how transitioning from homogeneous to heterogeneous LLM-driven MAS can significantly enhance system performance without requiring structural redesign. Specifically, in a chatbot-only MAS scenario, the heterogeneous configuration yields up to 6.4% performance improvement for MAS methods on the MATH dataset. In a mixed chatbot-reasoner scenario, the heterogeneous MAS achieves up to 47% performance boost on the AIME dataset. Our results underscore the transformative potential of heterogeneous LLMs in MAS, highlighting a promising direction for future research in scalable, collaborative AI systems.", "tldr": "", "keywords": ["LLM", "Multi-Agent Systems"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/506a24b72be8040d63d83b11e1144d7ee587b6a2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper explores the homogeneity limitation in multi-agent systems (MAS) based on large language models (LLMs), where all agents are driven by a single LLM, thereby constraining the collective intelligence of the system. To address this, a heterogeneous LLM-driven MAS paradigm is proposed, aiming to leverage the collective intelligence of diverse LLMs to enhance system performance. Specifically, X-MAS-Bench was constructed, evaluating 27 LLMs across 5 MAS-related functions and 5 common domains, with over 1.7 million evaluations conducted. Furthermore, based on experimental findings, it is demonstrated that transitioning from homogeneous to heterogeneous MAS design can significantly and consistently improve system performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-written, with clear motivation and sound reasoning logic. Overall, it is highly comprehensible.\n2. The X-MAS-Bench constructed in this paper systematically evaluates LLM capabilities from multiple domain-function perspectives, providing valuable insights for subsequent research and further validating the importance of the heterogeneous LLM-MAS paradigm."}, "weaknesses": {"value": "1. X-MAS-Design relies on manual reference to X-MAS-Bench results for selecting the optimal LLM, which constitutes a simplistic and mechanistic approach.\n2. The implementation of X-MAS-Design is predicated on X-MAS-Bench identifying the optimal LLM combination. For task domains beyond the benchmark's scope, additional costs will be required to determine the optimal combination, thereby undermining the method's value."}, "questions": {"value": "1. There are multiple spelling errors in the text (e.g., \"financespanning\").\n2.  The paper introduces the design of a heterogeneous LLM MAS. can it provide analysis and discussion regarding costs?\n3. Could it provide a case study to demonstrate the LLM driver selection process in the heterogeneous LLM MAS design?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LZw2Xalcx2", "forum": "ptUxbqOGrC", "replyto": "ptUxbqOGrC", "signatures": ["ICLR.cc/2026/Conference/Submission18118/Reviewer_y77r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18118/Reviewer_y77r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878563438, "cdate": 1761878563438, "tmdate": 1762927883596, "mdate": 1762927883596, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces X-MAS-Bench, which is used to evaluate different LLMs with different Multi-agent systems.  The paper evaluates 27 LLMs across multiply test set and find that using heterogeneous LLMs can significantly improve MAS's performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper shows the performance of heterogeneous MAS systems through extensive experiments with different models and test sets. It also picks 5 representative MAS functions.\n- To test X-MAS-Design, the authors chooses different MAS methods and tests on different domains, and the performance of X-MAS-Design is obviously and consistently higher than homogeneous MAS systems."}, "weaknesses": {"value": "- X-MAS-Design picks “top performers” from X-MAS-Bench. While X-MAS-Bench covers a wide range of LLMs and domains and functions already, it cannot scale. For example, how would we decide if a new LLM is included?\n- While it is understandable to only include open-source local models, it would be interesting to include some experiments with state of the art proprietary models. If a model is strong enough, do we still need to spend time picking heterogeneous LLMs?"}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wbe9gVwvmm", "forum": "ptUxbqOGrC", "replyto": "ptUxbqOGrC", "signatures": ["ICLR.cc/2026/Conference/Submission18118/Reviewer_VkAd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18118/Reviewer_VkAd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978364164, "cdate": 1761978364164, "tmdate": 1762927883120, "mdate": 1762927883120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce X-MAS, a framework and large-scale benchmark (X-MAS-Bench) for systematically evaluating MAS built from heterogeneous LLMs. \nResults show that combining diverse LLMs often leads to higher accuracy, robustness, and complementary strengths than using a single model for all agents."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is generally well-organized.\n\n2. Provides a large-scale empirical study (X-MAS-Bench) evaluating 27 LLMs across 5 functional and 5 domain dimensions, with over 1.7 million evaluations.\n\n3. Will releases code and data, promoting reproducibility and further research."}, "weaknesses": {"value": "1. While the heterogeneous-LLM concept is valuable, the system mainly relies on model substitution rather than introducing a fundamentally new MAS design or coordination mechanism.\n\n2. The overall contribution and scope of the paper are somewhat unclear. As an evaluation work, the number of evaluated models is quite limited; as a method paper, the proposed approach lacks sufficient novelty to stand out.\n\n3. All three baselines are from October or May 2023, which makes them somewhat outdated given the rapid progress in multi-agent LLM research.\n\n4. The reported performance improvements may largely stem from differences in individual model capabilities rather than from the effect of diversity itself. It remains unclear whether the same gains would persist if all constituent models were comparably strong. A controlled experiment with equally capable LLMs would help isolate the true impact of heterogeneity.\n\n5. The ablation results are somewhat confusing. The finding that model combinations must be carefully selected based on extensive prior evaluations seems to suggest that the observed performance gains stem mainly from differences in individual model capabilities rather than from the proposed framework design itself. Moreover, this approach appears non-generalizable and impractical—if each new task requires large-scale evaluations to identify an effective heterogeneous design, the method would be too costly to deploy in practice."}, "questions": {"value": "Please refer to the weaknesses section for main questions. More minor questions are given below:\n\nThe description of X-MAS-Proto is quite confusing. From the paper, it seems that X-MAS-Proto is treated as one of the MAS frameworks (similar to LLM-Debate or DyLAN), but its exact nature is unclear. Could the authors clarify whether X-MAS-Proto itself is a MAS framework? It looks like it can be applied in both homogeneous and heterogeneous settings, though I’m not entirely sure if I’m interpreting this correctly.\n\nAdditionally, X-MAS-Proto is first mentioned around line 312 with the phrase “The system (see the MAS in Figure 1)”, but it does not appear explicitly in Figure 1, making it difficult to connect the description to the depicted architecture. I suspect that X-MAS-Proto corresponds to the upper-right structure in Figure 1, though this is never clearly stated in the text. A more explicit and self-contained introduction to X-MAS-Proto earlier in the paper would greatly improve clarity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xR7IMENG3t", "forum": "ptUxbqOGrC", "replyto": "ptUxbqOGrC", "signatures": ["ICLR.cc/2026/Conference/Submission18118/Reviewer_t6B1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18118/Reviewer_t6B1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984361217, "cdate": 1761984361217, "tmdate": 1762927882768, "mdate": 1762927882768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work studies how task performance is influenced when adopting heterogeneous LLMs within multi-agent systems. The authors perform a large-scale empirical analysis and find that heterogeneous configurations consistently outperform homogeneous ones. Their results indicate that no single model is universally optimal; instead, combining diverse LLMs can exploit complementary strengths across domains and functions, leading to performance gains in both chatbot-only and mixed chatbot-reasoner settings."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The problem of studying optimizing multi-agent system is important in the modern context."}, "weaknesses": {"value": "- The writing could be improved to more closely follow standard academic structure. Currently, citations are embedded directly in the text, which makes the narrative hardly readable (e.g., Experimental setups. line 240-255)\n- For a benchmark paper, the presented MAS structures seem limited, and the extent of data diversity is not clearly articulated.\n- Several closely related works with similar problem setups and benchmarking goals are not cited or discussed, such as LLMSelector (“Optimizing Model Selection for Compound AI Systems”), Optimas (“Optimas: Optimizing Compound AI Systems with Globally Aligned Local Rewards”), and Dylan (\"A Dynamic LLM-Powered Agent Network for Task-Oriented Agent Collaboration\") among others in recent literature.\n- The novelty of the benchmarks does not seem to be convincing, given the setting is a bit simplified or in similar complicity compared to the existing works.\n\nMinor comments:\n- The term “system intelligence” could be defined more clearly. For example, in the introduction you state: “This manner inherently limits the systems intelligence to that of the underlying model.” It would be helpful to clarify what aspects of intelligence this refers to.\n- There are a few minor typos (e.g., `˘a` on line 199)."}, "questions": {"value": "- How exactly does this work differ from the datasets used in LLMSelector and Optimas and Dylan?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sxgXPTZVUY", "forum": "ptUxbqOGrC", "replyto": "ptUxbqOGrC", "signatures": ["ICLR.cc/2026/Conference/Submission18118/Reviewer_SHSH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18118/Reviewer_SHSH"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762646603112, "cdate": 1762646603112, "tmdate": 1762927882325, "mdate": 1762927882325, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}