{"id": "dXJB9O8fLd", "number": 13056, "cdate": 1758213158161, "mdate": 1759897468414, "content": {"title": "Bayesian Attention Mechanism: A Probabilistic Framework for Positional Encoding and Context Length Extrapolation", "abstract": "Transformer-based language models rely on positional encoding (PE) to handle token order and support context length extrapolation. \nHowever, existing PE methods lack theoretical clarity and rely on limited evaluation metrics to substantiate their extrapolation claims. \nWe propose the Bayesian Attention Mechanism (BAM), a theoretical framework that formulates positional encoding as a prior within a probabilistic model. \nBAM unifies existing methods (e.g., NoPE and ALiBi) and motivates a new Generalized Gaussian positional prior that substantially improves long-context generalization. \nEmpirically, BAM enables accurate information retrieval at $500\\times$ the training context length, outperforming previous state-of-the-art context length generalization by more than $25\\times$ in retrieval accuracy while maintaining comparable perplexity and introducing minimal additional parameters.", "tldr": "We introduce BAM, a Bayesian theoretical framework for positional encoding (PE) that interprets existing methods as prior distributions within Bayesian attention, enabling significant improvements in transformers' long-context performance.", "keywords": ["Positional Encoding", "Large Language Model", "Transformer", "Long Context", "Attention Mechanism"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/13e18b1cd10492de974fff99e27334a0933ff856.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes the Bayesian Attention Mechanism (BAM), framing positional encoding as a Bayesian positional prior that unifies methods like NoPE and ALiBi and introduces GGD-BAM, achieving strong long-context retrieval up to ≈256K tokens with <1000 extra parameters and improved stability when combined with SSMax on models from 120M–1.1B trained on FineWeb10B/Wikipedia."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Formalizes positional encoding as a Bayesian prior, providing a useful theoretical advance.\n- Demonstrates robust long-context retrieval (≈256K tokens) with minimal parameter overhead.\n- Presents ablations and visualizations that enhance interpretability.\n- Supplies clear experimental documentation and reproducibility details in the appendices."}, "weaknesses": {"value": "1. Experiments stop at 1.1B parameters, leaving scaling behavior at 7B/13B+ unknown.\n2. Evaluation is narrow (FineWeb, Wikipedia, passkey retrieval, RULER–NIAH) and omits broader benchmarks and domain corpora.\n3. Training overhead analysis lacks detailed wall-clock and memory cost measurements for ultra-long fine-tuning."}, "questions": {"value": "1. Is there an empirical correlation between the normalization $Z$ and long-context extrapolation, and can $Z$ be optimized or learned to extend coverage?\n2. Does the optimal $β$ shift with larger training contexts (e.g., 2048), and can you provide experiments across different training-context regimes?\n3. Why do larger models (1.1B) tend to overfit the training context more, and can you analyze the representation or optimization dynamics behind this?\n4. Could a per-layer or learned $β$ schedule better balance local vs. long-range dependencies and reduce local-context suppression when $β<0$?\n\nOverall, while the idea is conceptually interesting and well-presented, the current empirical evidence is insufficient to justify acceptance at this venue."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5R8UrRvrhL", "forum": "dXJB9O8fLd", "replyto": "dXJB9O8fLd", "signatures": ["ICLR.cc/2026/Conference/Submission13056/Reviewer_b3U5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13056/Reviewer_b3U5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551966210, "cdate": 1761551966210, "tmdate": 1762923787527, "mdate": 1762923787527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new positional encoding design, BAM, which is a variant and improvement of the existing ALiBi. \nThe authors reformulate current positional encodings from a Bayesian perspective and provide a clear motivation for their proposed modification. Experiments in long-context perplexity and in-context copying tasks (PassKey Retrieval and NIAH) demonstrate BAM's effectiveness in length extrapolation for language models with up to 1B parameters."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The perspective on improving ALiBi is both interesting and well-motivated.\n\n- The authors provide a theoretical analysis that explains their motivation and supports the proposed approach.\n\n- The authors conduct extensive experiments to demonstrate the effectiveness of their method, providing compelling evidence for its validity."}, "weaknesses": {"value": "- Some experimental results are not convincing enough to support the authors’ contributions (See Questions).\n\n- The presentation of this paper could be improved. \nThe section on theoretical proofs somewhat detracts from the main focus of the work. \nWhile naming the new PE \"Bayesian Attention Mechanism\" is justifiable, it make sense but feels somewhat forced. \nSeveral important experimental conclusions are scattered throughout the Appendix, which makes it challenging for reviewers to follow."}, "questions": {"value": "---\nQ1: Can the authors include additonal baselines to better demonstrate the effectiveness of BAM methods?\n\nSome relevant methods are missing and should be discussed in the experiments. For example, the RoPE variants (PI, NTK, YaRN, etc), which build on RoPE, should be included .   \nThey are the unique benefits of RoPE design, enabling length extraploation either at little to no cost.\n\nMoreover, discussing the latest design in relative positional encodings [1] would further strengthen the case for BAM's effectiveness.\n\n[1] HoPE: A Novel Positional Encoding Without Long-Term Decay for\nEnhanced Context Awareness and Extrapolation.\n\n---\nQ2: Can the authors continual pre-train these models with more tokens?\n\nWe appreciate the authors's efforts in conducting these experiments.\nHowever, the training corpus used for the pre-training of these toy models remains limited.\nGiven this, conclusions drawn from such a limited number of pre-training tokens are not entirely convincing. \nIt is well known that ALiBi can accelerate convergence during training. \nSo, will BAM still exhibit its advantages when pre-training with more tokens (at least 100B tokens)? \nHope the authors can clarify that.\n\n---\nQ3: More comprehensive evaluation of the long-context abilities.\n\nThe existing experiments (PassKey and NIAH) provide some preliminary evidence of BAM's in-context copying ability for long contexts. \nHowever, BAM's other abilities in long-context is still underexplored, such as many-shot ICL, integration, and reasoning?\n\nBuilding on the resolution of Q1 & Q2, could the authors test BAM on real-word tasks of long-context benchmarks (e.g., LongBench and L-Eval)?\n\n--- \nQ4: What's the generative abilities of these PEs with normal lengths.\n\nWe acknowledge the authors' experiment in Appendix D.1, where RoPE shows lower perplexity than BAM on Wikipedia.\nWe agree with the authors that perplexity alone does not accurately reflect these models' ability.\nSo, what is the performance of these models at different scales, using different PEs, on language modeling tasks such as ARC, Hellaswag, PiQA, etc.?\nCould the length-extrapolation ability of BAM emerge at the cost of its performance on shorter texts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wOddoLzkJW", "forum": "dXJB9O8fLd", "replyto": "dXJB9O8fLd", "signatures": ["ICLR.cc/2026/Conference/Submission13056/Reviewer_R1bm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13056/Reviewer_R1bm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760428095, "cdate": 1761760428095, "tmdate": 1762923786953, "mdate": 1762923786953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Bayesian Attention Mechanism (BAM), a probabilistic formulation of self-attention where positional encoding (PE) is treated as an explicit prior over token positions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Disclaimer: I don't know the field of positional encoding. I've alerted AC for my lack of knowledge in the domain.\n\nThe method can enable retrieval for context length far beyond training context length with small number of parameters added, which seems nice to me."}, "weaknesses": {"value": "Disclaimer: I don't know the field of positional encoding. I've alerted AC for my lack of knowledge in the domain.\n\nI'm unsure about the experimental analysis section of the paper. I don't know if the benchmarks used in the paper includes most of the popular ones in the field of positional encoding. I don't know if the paper uses enough baselines to compare their method with."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "9wzZqyAVcv", "forum": "dXJB9O8fLd", "replyto": "dXJB9O8fLd", "signatures": ["ICLR.cc/2026/Conference/Submission13056/Reviewer_giCK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13056/Reviewer_giCK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840782541, "cdate": 1761840782541, "tmdate": 1762923786658, "mdate": 1762923786658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Bayesian Attention Mechanism (BAM), a theoretical framework that reformulates self-attention as a probabilistic model where positional encoding (PE) acts as a prior over token positions. The authors show that existing PEs like NoPE and ALiBi correspond to specific priors (Uniform and Laplace) and propose a new Generalized Gaussian prior (GGD-BAM) to improve long-context extrapolation. They validate the approach empirically on language modeling, passkey retrieval, and the RULER benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a clear and rigorous probabilistic interpretation of positional encoding in self-attention, unifying multiple existing approaches under a single Bayesian view. The derivations are mathematically consistent and offer new insight into the role of priors in attention mechanisms.\n2. Framing positional encoding as a prior elegantly connects methods like NoPE and ALiBi that were previously viewed as unrelated heuristics. This contributes to a more principled understanding of extrapolation in transformers.\n3. The visualizations of positional priors and learned β values provide interpretability, showing how certain heads specialize in long-range retrieval."}, "weaknesses": {"value": "1. The main experiments are restricted to models with limited parameters. It remains unclear whether the extrapolation benefits persist at the scale of modern large language models (7B–70B), where positional behaviors often change.\n2. The work focuses on retrieval and perplexity but does not assess downstream tasks like long context QA or summarization, where long-context comprehension is critical."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5OPUt5n85x", "forum": "dXJB9O8fLd", "replyto": "dXJB9O8fLd", "signatures": ["ICLR.cc/2026/Conference/Submission13056/Reviewer_xnWw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13056/Reviewer_xnWw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963112073, "cdate": 1761963112073, "tmdate": 1762923786371, "mdate": 1762923786371, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}