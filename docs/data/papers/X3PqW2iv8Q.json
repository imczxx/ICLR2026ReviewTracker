{"id": "X3PqW2iv8Q", "number": 23100, "cdate": 1758339576918, "mdate": 1759896832323, "content": {"title": "Trust-Gated State Space Models for Budgeted Decisions with Online Risk Control", "abstract": "Deployed predictors increasingly operate with unreliable inputs and strict resource budgets, where labels can be noisy, sensors fail, and conditions drift. We introduce Trust-Gated State Space Models (TG–SSM), a compact approach that treats reliability as a first-class control signal. TG–SSM augments a lightweight statespace backbone with gates that modulate input injection, state mixing, and output temperature using on-the-fly reliability features; a small conformal layer then converts probabilities into calibrated prediction sets for budgeted decision-making with target risk 1 − α. On CIFAR-10N (noisy labels), TG–SSM with weighted conformal prediction (WCP) reduces ECE from 0.124 to 0.048 while increasing coverage from 0.894 to 0.905 at α = 0.1 (mean set size ≈ 9.08). Averaged over CIFAR 10C severities 1–5, TG–SSM+WCP achieves near-nominal coverage (0.905) with markedly improved calibration (ECE 0.104–0.109) and compact sets (≈ 6.74). On Camelyon17/WILDS (domain shift), a validation-quantile variant attains AUROC 0.949 with average coverage 0.844 and set size ≈ 0.989, while a shift-aware (importance-weighted) variant yields smaller sets (≈ 0.737) with AUROC 0.936. Overall, TG–SSM provides a simple, hardware-efficient recipe for turning uncertain predictions into actionable, budgeted decisions.", "tldr": "A tiny SSM with reliability gates plus online, recency-weighted conformal prediction that optimizes budgeted decisions while keeping miscoverage near target under drift.", "keywords": ["reliable machine learning", "decision making", "budgeted abstention", "conformal prediction", "uncertainty calibration", "online learning", "distribution shift", "state space models", "Mamba", "risk control", "edge deployment"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/418ccd09b6e1e9892e68c1550fcdf925e587f41a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a way to \"gate\" the state space model which are updated with online data, where the gating controls the the degree to which the inputs influence the updates to the hidden state space, state mixing, and the temperature for the softmax prediction. The authors using a \"reliability vector\" which looks at different statistics from the logits such as entropy, margin (best minus second best), confidence change over time and a smoothed cross-entropy loss (through time). Experiments are conducted on noisy/corrupted cifar and camelyon17, demonstrating that the confidence estimates get a bit better ECE wise."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "On the surface, the overall idea of using reliability signals for gating makes sense."}, "weaknesses": {"value": "The biggest issue here is that the paper is very sparse, background works are not discussed appropriately, problem is not presented properly, methods and variables are not described in detail and the experimental discussions and details are also very sparse. The authors must really expand on each and every aspect of the paper. The paper is currently only 4 pages, the authors need to expand substantially to outline every aspect. \n\nThe experiments themselves are quite sparse as well, just two datasets and very few benchmarks for comparisons (essentially gate v/s no gate?) are shown. I see some others but they have not been properly described as well. \n\nLastly, there are many works for online adjustments of predictive confidence/uncertainty based on various signals. Online uncertainty estimation in general has seen many works. So it is not clear to me what advantages this gated SSM based approach brings w.r.t other approaches. Discussions are needed as well. \n\n[1] Online Bootstrap Confidence Intervals for the Stochastic Gradient Descent Estimator\n[2] Statistical Inference for Model Parameters in Stochastic Gradient Descent\n[3] Calibrated confidence learning for large-scale real-time crash and severity prediction\n[4] Conformal Inference for Online Prediction with Arbitrary Distribution Shifts\n[5] Adaptive conformal inference under distribution shift.\n[6] Adaptive Conformal Predictions for Time Series"}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Govzx8REWj", "forum": "X3PqW2iv8Q", "replyto": "X3PqW2iv8Q", "signatures": ["ICLR.cc/2026/Conference/Submission23100/Reviewer_F77H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23100/Reviewer_F77H"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837432005, "cdate": 1761837432005, "tmdate": 1762942511641, "mdate": 1762942511641, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of making reliable, budget-aware predictions under data noise and distribution shifts by incorporating trust signals directly into model dynamics. For that, the authors propose Trust-Gated State Space Models (TG-SSM), which augment a lightweight state-space model with learned gating mechanisms."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Due to the heavy use of unexplained jargon and the lack of clarity (despite the paper being well below the 9-page limit), I struggled to follow the technical content of the paper. However, the core motivation (handling unreliable inputs and strict computational budgets) is both timely and relevant to the ML community.\n\nI kindly encourage the authors to revise the manuscript to significantly improve clarity, potentially by studying previously accepted ICLR papers to guide writing style and presentation. This would allow the community to properly evaluate the strengths of this work which I'm sure have a lot of potential."}, "weaknesses": {"value": "Overall, I'm rejecting this paper given such lack of clarity and explanations, which do not allow for a proper evaluation of this work. Despite this, I further detail more weaknesses:\n\n1. The authors should spend more space in properly formalising/defining what they mean by many concepts and statements, like \"first-class control signal\", \"coverage\", \"stateless with respect to reliability\", \"evidence quality\", \"EMA\", \"Mondrian (class-conditional) sets\", \"(low) trust\", \"reliability vector\". Overall though, the key terms that are not properly defined and are certainly the main ones that need a formal definition is \"trust\" and \"reliability\". Furthermore, there are inconsistencies in notation, as for example $\\alpha$ is used as a step size in equation 1, and then as a target miscoverage in section 3.2.\n2. It is unclear how well the proposed method would scale to much larger architectures or more complex datasets.\n3. The experiments lacks comparison to other uncertainty or robustness methods. The benefit of adding these so-called trust gates seems to be compared to a single baseline (\"No-Gate). However, the paper does not compare against alternative approaches and I'd imagine that the works mentioned in Related Work could be used, but even other uncertainty-aware models like deep ensembles or Bayesian neural nets seem that could be compared against this method. Without these other baselines, it is hard to quantify how much added value the proposed gates provide over simpler approaches (for example, could a standard model with post-hoc calibration achieve similar results?)\n4. The model seems to introduce 3 gates in section 4, but there is no ablation study to determine which of these gates contribute the most to the performances reported in section 5.\n5. While the authors describe what the trust gates are intended to do (without defining \"trust\" or \"reliability\"), there's no insight or evidence of how these gates behave in practice. There are no visualisations or case studies of gating values. This lack of \"interpretability\" could be addressed by reporting, for instance, the distribution of gate values or examples of the model’s behaviour on specific challenging inputs.\n6. All experiments are on vision classification tasks (CIFAR-10 variants and Camelyon17 pathology images). It remains untested whether TG-SSM would be effective in other domains like as natural language processing or time-series forecasting, where I'd imagine state-space models would be more applicable.\n7. The results overly rely on reported averages (e.g., averaging over all types of corruptions and severities in CIFAR-10C), and thus the paper is not reporting important measures of variability. Standard deviation would be a good starting point, but other points would be very interesting too; for instance, perhaps TG-SSM performs very well on some corruption types but less so on others, or maybe certain class labels or subpopulations in Camelyon17 still have poor coverage. Does the method struggle on the most severe corruptions, or on particular domain shifts?\n8. Some references have mistakes, I was able to spot that the links are wrong for (Barber et al. 2022) and (Romano et al. 2020). And that (Elkan 2001) has a broken link."}, "questions": {"value": "1. How is the learned trust-gate encoder trained in practice, and what measures ensure it doesn't overfit to spurious features? In Limitations, you mention the risk of learned gates overfitting to spurious cues, so have you tried techniques like regularisation or did you observe any failure cases?\n2. Did you consider comparing TG-SSM (or combining it) with other uncertainty mitigation or adaptation methods?\n3. Can you provide more intuition or evidence on how the trust gates respond to unreliable inputs in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jrzvxtpqXH", "forum": "X3PqW2iv8Q", "replyto": "X3PqW2iv8Q", "signatures": ["ICLR.cc/2026/Conference/Submission23100/Reviewer_hiqX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23100/Reviewer_hiqX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950687591, "cdate": 1761950687591, "tmdate": 1762942511258, "mdate": 1762942511258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Trust-Gated State Space Models (TG-SSM) to enhance prediction reliability in State Space Models (SSMs). The method introduces a conformal prediction layer for online risk control and adaptive uncertainty calibration. The framework is evaluated on CIFAR-10N (noisy labels) and Camelyon17/WILDS (domain shift) datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The topic could be interesting and relevant, as model reliability in state-space architectures is underexplored compared to transformers or CNNs."}, "weaknesses": {"value": "**Insufficient Technical Clarity**\n- The technical part is too short and lacks sufficient detail for readers to reproduce the results or fully understand the internal design.  \n- The related works section is also sparse, missing a deeper discussion of prior efforts on conformal prediction in reliability control or uncertainty calibration, which would help contextualize the contribution.  \n\n**Lack of Motivation and Justification**\n- The paper does not clearly articulate **why conformal prediction is specifically suited for SSMs**.  \n- It remains unclear whether **SSMs inherently suffer from poorer calibration or reliability** compared to other architectures such as Transformers."}, "questions": {"value": "See **Weaknesses**. \n\nThe most critical issue is that the current presentation lacks sufficient details for readers to fully grasp both the motivation and the technical aspects of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "OOzvrQFTeX", "forum": "X3PqW2iv8Q", "replyto": "X3PqW2iv8Q", "signatures": ["ICLR.cc/2026/Conference/Submission23100/Reviewer_LLMf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23100/Reviewer_LLMf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762614405636, "cdate": 1762614405636, "tmdate": 1762942510581, "mdate": 1762942510581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Trust-Gated State Space Models (TG–SSM), a novel approach that integrates reliability-awareness into state space models (SSMs) for budget-constrained, uncertainty-aware decision-making. The core idea is to embed “trust gates” — small control modules driven by on-the-fly reliability signals (e.g., entropy, confidence margins, loss proxies) — that dynamically modulate input strength, state mixing, and output temperature.\n\nA lightweight conformal prediction layer is then added to translate model probabilities into calibrated prediction sets, ensuring user-specified coverage levels under distributional shifts, noisy labels, or domain corruptions. The method effectively treats reliability as a control signal and achieves online risk control without retraining or test-time adaptation.\n\nEmpirical evaluations across CIFAR-10N (noisy labels), CIFAR-10C (corruptions), and Camelyon17/WILDS (domain shift) show that TG–SSM with weighted conformal prediction (WCP) substantially reduces Expected Calibration Error (ECE) and maintains near-nominal coverage (≈0.90) with compact set sizes and negligible computational overhead (<0.2% parameters).\n\nThe key contributions include:\n\t1.\tA reliability-gated SSM architecture that adapts its dynamics based on trust estimates.\n\t2.\tA conformal layer for online, risk-aware set prediction supporting decision budgets.\n\t3.\tExtensive evaluation under realistic reliability degradation scenarios.\n\t4.\tDemonstrated practicality for efficient, deployable AI under uncertainty.\n\nOverall, TG–SSM bridges model calibration, conformal inference, and reliability-aware sequence modeling to produce trust-regulated, hardware-efficient systems for safe and resource-aware deployment."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Motivation and Relevance:\nThe paper addresses a timely and important problem — how to maintain reliability and calibration in state space models (SSMs) under uncertainty and resource constraints. This focus on risk-aware and budgeted decision-making is relevant for safety-critical or real-time applications.\n\t•\tConceptual Integration:\nThe proposed Trust-Gated State Space Model (TG-SSM) integrates ideas from reliability estimation, conformal prediction, and gating in sequence modeling. While individually known, this combination is conceptually coherent and shows creative engineering intuition.\n\t•\tEfficiency and Practicality:\nThe approach is computationally lightweight, adding minimal overhead through simple gating and conformal layers. This practical focus aligns well with real-time decision constraints and edge deployment contexts.\n\t•\tEmpirical Breadth:\nThe experiments span different uncertainty settings (label noise, domain shift, corruption), showing consistent robustness improvements over baseline SSMs. The results, while modest, demonstrate that the trust mechanism can generalize across conditions.\n\t•\tClear Writing in Method Section:\nThe section describing the gating mechanism and conformal calibration pipeline is reasonably well-organized, making the main algorithm easy to follow. Figures illustrating the gating structure aid comprehension.\n\nOverall Strength Summary:\nThe paper’s strength lies in its relevance, engineering practicality, and conceptual synthesis of existing uncertainty and calibration methods within a dynamic SSM framework. It offers useful empirical insights for improving model reliability, even if the theoretical and methodological novelty remain limited."}, "weaknesses": {"value": "Limited Theoretical Depth:\nThe proposed “trust gating” mechanism lacks formal justification. There is no theoretical derivation showing that the gating improves calibration, maintains statistical coverage, or guarantees bounded risk. The absence of formal analysis or proofs makes the approach appear heuristic rather than principled.\nSuggestion: Include a risk control or PAC-style bound linking the gating function to conformal prediction guarantees.\n\t•\tIncremental Novelty:\nThe work reads as an engineering extension that combines existing tools — e.g., conformal calibration and confidence-based gating — rather than introducing a fundamentally new idea.\nPrior works like Calibrated SSMs, Confidence-Controlled Networks (Geifman & El-Yaniv, 2019), and Conformal Risk Control (Angelopoulos & Bates, 2021) already address similar problems.\nSuggestion: Better contextualize novelty by explicitly contrasting TG-SSM with these models, explaining what unique benefit the gating structure provides.\n\t•\tExperimental Limitations:\nThe experiments focus mostly on CIFAR variants and Camelyon17, which are small-scale benchmarks. There are no large-scale sequence or temporal tasks, even though the model is a state space model.\nThis weakens claims about the method’s generality and scalability.\nSuggestion: Add results on sequential datasets (e.g., IMDB, SpeechCommands) or demonstrate time-series calibration behavior.\n\t•\tUnclear Definition of “Trust”:\nThe concept of “trust” is introduced intuitively but never formally defined. It remains unclear whether it represents epistemic uncertainty, aleatoric noise, or a mix of both.\nWithout a precise formulation, the gating logic risks being seen as ad hoc.\nSuggestion: Define “trust” mathematically and explain how it is computed, normalized, and propagated across layers.\n\t•\tWeak Baseline Comparisons:\nThe study compares TG-SSM mainly against vanilla SSMs and temperature scaling, omitting stronger baselines such as Deep Ensembles, MC-Dropout, or Bayesian SSMs. This makes it difficult to judge its real advantage.\nSuggestion: Include comparisons against these uncertainty estimation baselines to position TG-SSM more clearly within the literature.\n\t•\tCalibration Metrics Missing:\nAlthough coverage and risk are reported, calibration metrics (ECE, NLL, Brier score) are not discussed in detail. Given that calibration is central to the claimed contribution, this omission weakens the empirical argument.\nSuggestion: Provide full calibration metrics and visual reliability diagrams.\n\t•\tPresentation and Clarity Issues:\nThe narrative is dense and jargon-heavy, with several buzzword combinations (“budgeted online risk”, “trust-aware calibration”) that obscure the main contribution.\nFigures could be improved to better depict information flow and reliability dynamics.\n\nOverall Weakness Summary:\nThe paper presents a creative idea but lacks the theoretical rigor, empirical breadth, and clear novelty required for ICLR acceptance. Strengthening formal justification, testing on genuine sequence tasks, and improving conceptual clarity around “trust” would make this work substantially stronger."}, "questions": {"value": "1.\tFormal Definition of “Trust”\n\t•\tThe concept of “trust” appears central to your model but remains ambiguous.\n\t•\tHow exactly is it computed — is it derived from entropy, prediction margin, or a learned auxiliary variable?\n\t•\tDoes it measure epistemic or aleatoric uncertainty (or both)?\n\t•\tA clear mathematical definition or illustrative example (e.g., trust dynamics across layers) would help clarify how it functions within the state update mechanism.\n2.\tGating Dynamics and Theoretical Basis\n\t•\tThe trust-gating mechanism seems heuristically defined.\n\t•\tCan you provide theoretical justification or intuition on how gating based on trust improves calibration or robustness?\n\t•\tIs there any guarantee that the gating will not reduce stability in the state transitions of the SSM?\n3.\tComparison with Related Work\n\t•\tHow does TG-SSM compare to existing calibrated or uncertainty-aware SSMs, such as Risk-Controlled Conformal Prediction (Angelopoulos & Bates, 2021) or Uncertainty-Calibrated SSMs (2023)?\n\t•\tCould you provide a table contrasting architectural or conceptual differences with these models to clarify what’s genuinely novel in TG-SSM?\n4.\tEmpirical Scope and Scalability\n\t•\tThe experiments rely primarily on small-scale datasets (CIFAR, Camelyon17).\n\t•\tHow does TG-SSM perform on large-scale or sequential datasets, which are more natural fits for SSMs (e.g., speech, text, time series)?\n\t•\tIs there evidence that the model scales gracefully to higher-dimensional or temporally correlated data?\n5.\tEvaluation Metrics\n\t•\tWhile you report coverage and reliability, standard calibration metrics (ECE, Brier score, NLL) are missing.\n\t•\tCan you include these metrics to assess calibration quality more quantitatively?\n\t•\tThis would also enable fairer comparison to existing uncertainty calibration baselines.\n6.\tInterpretation of Conformal Layer Interaction\n\t•\tHow exactly does the conformal prediction layer integrate with the trust-gated SSM?\n\t•\tIs it applied independently post-hoc, or does it influence training via feedback?\n\t•\tIf it is a purely post-hoc adjustment, what is the computational overhead at inference time?\n7.\tAblation on Trust Gate Design\n\t•\tHow sensitive are results to the gating function design (e.g., sigmoid vs. softmax vs. thresholded step)?\n\t•\tCould a simpler or linear gating mechanism achieve similar results?\n\t•\tA sensitivity study could make the approach more interpretable.\n8.\tEffect on Temporal Stability\n\t•\tSince SSMs depend on stable recurrent dynamics, does the trust gate risk introducing instability in long sequences?\n\t•\tHave you analyzed how gating frequency or trust volatility affects temporal prediction quality?\n9.\tGenerality Across Architectures\n\t•\tCould the trust gating idea generalize to transformers or recurrent architectures beyond SSMs?\n\t•\tIf yes, what modifications would be required to preserve stability and calibration guarantees?\n10.\tReproducibility and Implementation Availability\n\n\t•\tIs there a plan to release implementation details or code for TG-SSM?\n\t•\tProviding reproducible results and open-sourcing the gating mechanism would significantly strengthen the paper’s impact.\n\nSummary:\nThe main clarifications needed concern the mathematical grounding of “trust”, the integration with conformal prediction, and scalability to larger or sequential datasets. Addressing these points could improve the paper’s clarity, reproducibility, and credibility during rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The paper presents a technical contribution — a reliability-aware state space model architecture — without involving human subjects, personal data, or sensitive content.\nAll experiments use public, standard datasets (e.g., CIFAR, Camelyon17/WILDS), which have existing ethical clearance for machine learning research.\nThere is no discussion or application context that could lead to potential harmful deployment, data privacy, or bias amplification risks."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vZB7Xn1BCX", "forum": "X3PqW2iv8Q", "replyto": "X3PqW2iv8Q", "signatures": ["ICLR.cc/2026/Conference/Submission23100/Reviewer_kvow"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23100/Reviewer_kvow"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23100/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763144832920, "cdate": 1763144832920, "tmdate": 1763144832920, "mdate": 1763144832920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}