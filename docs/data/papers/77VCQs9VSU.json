{"id": "77VCQs9VSU", "number": 15908, "cdate": 1758256950601, "mdate": 1759897273806, "content": {"title": "From Assistants to Companions: Towards the Usefulness of Improving Theory of Mind for Human-AI Symbiosis", "abstract": "Theory of Mind (ToM) is crucial for successful human-AI (HAI) interactions. It is a key capability for AI to attribute humans' mental states based on dynamic interactions from a first-person perspective and then improve responses to humans accordingly. However, the existing benchmarks for Large Language Models (LLMs) focus on testing their ToM capability with story-reading from a third-person perspective, leading to a critical gap between benchmark performance and practical competence in HAI collaborative and supportive tasks. To bridge this gap, we introduce a novel evaluation framework within HAI contexts, shifting from static test-taking to dynamic, first-person engagement. Our framework assesses LLM performance across two fundamental types of interaction scenarios derived from cognitive science: goal-oriented tasks (e.g., coding, math) and experience-oriented tasks (e.g., counseling). With the framework, we systematically evaluate LLMs and related techniques to improve their ToM across four synthesized benchmarks and a crowdsourcing user study with 100 participants. Our findings reveal that improvements on static benchmarks do not always translate to better performance in dynamic HAI interactions. This paper offers critical insights into ToM evaluation, highlighting the necessity of interaction-based assessments and providing a roadmap for developing next-generation, socially aware LLMs for HAI symbiosis.", "tldr": "", "keywords": ["Theory of Mind", "Large Language Model", "Human-AI Interaction"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5ecbc58decc405b3d8758577e99823ae66a0a889.pdf", "supplementary_material": "/attachment/aaf211cd14ddb74f6c89719bc9651ec539bdfcc9.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces an evaluation framework for LLMs' ToM in the human-AI (HAI) context, shifting from static third-person story-acting to dynamic engagement. The authors assess LLM performance on two interaction scenarios (goal-oriented and experience-oriented) via existing benchmarks and a crowdsourcing user study (N=100). The experiments reveal that static benchmark improvements do not always translate to better dynamic HAI interaction performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The challenges and motivation proposed in this paper are clear, promising, and interesting. I like the problem revealed: \"the existing benchmarks for Large Language Models (LLMs) focus on testing their ToM capability with story-reading from a third-person perspective, leading to a critical gap between benchmark performance and practical competence in HAI collaborative and supportive tasks.\"\n2. The problem shifting from test-based assessments to dynamic, real-world interaction challenges is intuitive and interesting.\n3. This paper propose a comprehensive benchmarking framework and conduct a user study to support the findings."}, "weaknesses": {"value": "1. Although I acknowledge the limitation of previous ToM benchmarking work stated in this paper (third-person, story acting), I have doubts about using **code and math** tasks to test ToM. These two tasks seem to have a **weak connection to ToM**.\n2. The authors propose a framework, but they use previous data for evaluation instead of constructing their own, which weakens the contribution. I believe the **user study** (N=100) is a more significant contribution, yet the paper devotes insufficient space and analysis to it. Therefore, the focus of this paper may require some reorganization.\n3. The performance gap between ToM and the tasks in this paper, from the perspective of deep learning, seems to stem more from the **inconsistency between training objectives and downstream tasks**. The paper's analysis remains at a **superficial**, result-oriented level (both quantitative and qualitative), lacking in - depth analysis of intermediate processes. For instance, it fails to explore the **specific role of ToM** when LLMs perform various tasks, as well as the explicit connection between ToM and these specific tasks."}, "questions": {"value": "1. Are there any target-oriented tasks that require collaborative LLMs to be aware of each other‚Äôs thoughts (ToM)?\n2. Do the tasks evaluated in the paper explicitly or implicitly use any results or intermediate steps enhanced by ToM? This is crucial, if not, the performance will naturally not improve (target-oriented tasks); if yes, it can explain why the improvement occurs (experience-oriented tasks)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kzBpgVQE40", "forum": "77VCQs9VSU", "replyto": "77VCQs9VSU", "signatures": ["ICLR.cc/2026/Conference/Submission15908/Reviewer_DeuF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15908/Reviewer_DeuF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761472658624, "cdate": 1761472658624, "tmdate": 1762926127239, "mdate": 1762926127239, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework to evaluate LLMs‚Äô Theory of Mind (ToM) capabilities in dynamic, first-person human‚ÄìAI interactions. It claims to cover both goal-oriented tasks (e.g., coding, math) and experience-oriented tasks (e.g., counseling), aiming to bridge the gap between traditional third-person story-based benchmarks and real-world interactive scenarios. The framework includes four synthesized benchmarks and a crowdsourcing user study to assess LLM performance.\n\nHowever, in practice, the proposed evaluation is largely superficial: it consists mainly of trivial modifications to existing datasets, such as changing character names or narrative perspective, without actually modeling or analyzing any mental states. The evaluation methodology itself is not grounded in ToM reasoning, and thus the framework does not meaningfully capture the dynamic, interactive capabilities that the paper claims to address. Essentially, the study applies a ToM label to out-of-domain tasks rather than genuinely evaluating dynamic ToM in human‚ÄìAI interaction."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Figures are pretty."}, "weaknesses": {"value": "1. It is unclear what type of ToM the authors intend to evaluate, and the term ‚Äúdynamic‚Äù is not formally defined. The only apparent modification is a shift in narrative perspective (first-person vs third-person), which does not constitute genuine dynamic or interactive reasoning. Evaluation metrics are largely task-dependent rather than analyzing any mental states, raising doubts about whether the methodology truly reflects dynamic, interactive ToM.\n2. Evaluating ToM on math and code generation tasks appears unnecessary, as these tasks primarily require formal reasoning and problem-solving rather than modeling mental states or intentions. The chat-like format does not involve genuine interaction, suggesting a limited understanding of ToM and undermining the relevance of the results. The results in Table 1 prove this.\n3. The three contributions listed by the authors are not clearly reflected in the experiments and the method design.\n4. Experiments focus mainly on task performance, but it is unclear whether the LLMs actually perform ToM reasoning, since none of the ToM components are explicitly analyzed.\n5. The study does not include an experiment comparing the effectiveness of ‚Äúdynamic‚Äù versus ‚Äústatic‚Äù ToM in HAI interactions, as claimed in the abstract.\n6. Ambiguity in tables: The meaning of values in Table 1 and Table 2 is unclear‚Äîare they ùëÄŒì(ùúãùê¥, ùëá) scores or task success rates?\n7. Minor typos: Line 144: ‚Äúa active participant‚Äù ‚Üí ‚Äúan active participant.‚Äù Line 145: ‚Äúfrom the first-person perspective‚Äù ‚Üí ‚Äúfrom a first-person perspective.‚Äù"}, "questions": {"value": "1. What is the meaning of the values in Tables 1 & 2? And how are these numbers computed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TF9mLmivlD", "forum": "77VCQs9VSU", "replyto": "77VCQs9VSU", "signatures": ["ICLR.cc/2026/Conference/Submission15908/Reviewer_Y1BR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15908/Reviewer_Y1BR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923837373, "cdate": 1761923837373, "tmdate": 1762926126550, "mdate": 1762926126550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper raises the important point that there exists a significant gap between benchmark performance and practical competence in Human-AI (HAI) collaboration, and proposes an evaluation protocol that shifts from third-person story-based assessment to first-person interactive evaluation. The authors introduce a novel framework that categorizes HAI scenarios into goal-oriented tasks (e.g., coding, math problem-solving) and experience-oriented tasks (e.g., counseling, emotional support) and systematically evaluate four existing ToM enhancement methods (FaR, PT, SFT, RL) across two model families (GPT-4o and Llama-3.1-8B) using both synthetic benchmarks and a crowdsourced user study with 100 participants. Key findings reveal a significant performance gap: improvements on static ToM benchmarks do not translate to better performance in dynamic HAI interactions, demonstrating the necessity of interaction-based assessment and revealing that current methods fail in goal-oriented tasks while showing modest gains in experience-oriented scenarios.\n\nOverall, this is an interesting paper addressing an important hypothesis. However, it feels more suited for a findings paper rather than a main conference contribution, as the primary contribution is empirical validation of intuitive concerns about benchmark-reality gaps."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Strong motivation and intuition:** Addresses the fundamental problem of static benchmark limitations by proposing a shift to first-person perspective evaluation, which better reflects real-world HAI interactions where models must understand users' mental states dynamically.\n- **Well-designed experimental framework:** The experiments are systematically conducted under the proposed framework, with the authors validating results through real human user studies involving 100 participants across six experience-oriented tasks, which is crucial for a HAI symbiosis topic where human perception matters.\n- **Methodological rigor:** The authors clearly formalize the evaluation shift through mathematical notation (Equations 1-4), systematically adapt existing ToM methods for first-person scenarios, and provide detailed statistical analysis across multiple benchmarks, establishing a solid foundation for reproducible evaluation."}, "weaknesses": {"value": "- **Limited novelty and scope:** The contribution is primarily empirical evaluation under the proposed framework rather than methodological innovation, making it more suitable for a findings paper.\n- **Oversimplified methodology adaptation:** The conversion from third-person to first-person scenarios relies on simple rule-based transformations (e.g., replacing protagonist names with \"I\"), which seems to maintain the fundamental structure of static scenarios and not well-justified for capturing the complexities of real world, first-person-perspective conversations"}, "questions": {"value": "- Given that the third-person to first-person conversion is rule-based and static, does this transformation still capture the dynamic nature of real HAI interactions that the authors claim to evaluate? The conversion seems to maintain the fundamental structure of static scenarios.\n- The paper mentions \"the top-ranked response is used to continue the dialogue\" - this means different models could be used in different turns within a single dialogue. How does this multi-model approach affect the validity of model-specific performance evaluation, and how do you isolate individual model contributions?\n- The conclusion that \"limited gains are not strongly perceived by users, failing to translate into a clear preference\" needs better quantification. Is this based on the lack of statistical significance in ranking differences, the small effect sizes observed in Table 3, or the qualitative feedback analysis? The paper would benefit from clearer statistical thresholds and effect size reporting for these claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "yzR4VWwmnH", "forum": "77VCQs9VSU", "replyto": "77VCQs9VSU", "signatures": ["ICLR.cc/2026/Conference/Submission15908/Reviewer_9NNL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15908/Reviewer_9NNL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973782826, "cdate": 1761973782826, "tmdate": 1762926126023, "mdate": 1762926126023, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "It proposes a dynamic, first-person evaluation framework that reveals how improvements on static Theory of Mind benchmarks for LLMs do not necessarily translate to better real-world human-AI performance, highlighting the need for interaction-based assessment and socially aware models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-written and well-motivated. It points to the importance of ToM in human-AI interaction experience.\n\n- The paper highlights the importance of first-person view tasks. It includes both goal-oriented and experience-oriented scenarios.\n\n- It shifts the evaluation from static to dynamic interaction setting."}, "weaknesses": {"value": "- The main weakness of this paper is the test data is from existing benchmarks which lower the weight of the contribution.\n\n- The GPT-4o is a little bit old, the author should add more SOTA models into the evaluation.\n\n- In my view, ToM is about the cognitive facets, why do you conduct the experiments on goal-oriented tasks? What problem would you like to study?\n\n- There lacks in-depth analysis about why SFT and RL methods do not show the advantages on the tested benchmarks in Table 2. Currently, more description about the results scores in Section 4.2.1 and 4.2.2, it should have more analysis."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ljYTKgnAfU", "forum": "77VCQs9VSU", "replyto": "77VCQs9VSU", "signatures": ["ICLR.cc/2026/Conference/Submission15908/Reviewer_1ry9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15908/Reviewer_1ry9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991507418, "cdate": 1761991507418, "tmdate": 1762926125318, "mdate": 1762926125318, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}