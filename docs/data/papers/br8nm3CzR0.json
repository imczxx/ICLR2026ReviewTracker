{"id": "br8nm3CzR0", "number": 755, "cdate": 1756816880310, "mdate": 1759898243437, "content": {"title": "TimeSeed: Effective Time Series Forecasting with Sparse  Endogenous Variables", "abstract": "Time series forecasting is widely applied across various domains. In real-world applications, there are many scenarios where endogenous variables are missing. Recent studies show that incorporating exogenous variables can significantly enhance the predictive accuracy of endogenous variables. However, the lack of a complete historical context introduces significant uncertainty in temporal dependence capture, particularly in systems characterized by non-stationary behavior. To address these challenges, we propose TimeSeed, specifically designed for scenarios with sparsely observed endogenous variables. Technically, TimeSeed reconstructs l sufficient endogenous series from both complete exogenous series and sparsely observed endogenous series, utilizing two types of data to extract stable information. Building on this foundation, we effectively transforming the challenging original prediction task into a sequence-based prediction task. Moreover, TimeSeed is built entirely upon linear layers, which significantly reduces computational costs. Experiments conduct on seven real-world datasets demonstrate that TimeSeed consistently outperforms state-of-the-art models in forecasting accuracy, achieving an average reduction of 13.01\\% in MSE and 7.54\\% in MAE, with a model size of only 0.19M parameters. Code is available at this repository: \\url{https://anonymous.4open.science/r/Alistair-7}.", "tldr": "", "keywords": ["Time series forecasting"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7dca8e1208eaeff28cf296c0d4380240705b42fe.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduce TimeSeed which is specifically designed for time series forecasting scenarios with sparsely observed endogenous variables. Technically, TimeSeed leverages dense exogenous and sparse endogenous sequences within a two-stage paradigm of context reconstruction and hierarchical prediction. Experiments demonstrate that TimeSeed consistently outperforms state-of-the-art models in forecasting accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is well-organized and easy to follow.\n2. The proposed TimeSeed is a lightweight model built entirely upon linear layers, which significantly reduces computational costs. \n3. The experiment is extensive and quite detailed."}, "weaknesses": {"value": "1. The paper focuses on the sparse forecasting scenario, which is a conceptually complex and challenging scenario. However, practical evidence on this setting is limited, as the experiments primarily rely on existing multivariate benchmarks. \n2. The presentation of TimeSeed lacks clarity. For instance, line 162 of the main text states, \"we design the TDA and FDA blocks to predict trend and periodic features for sparse endogenous sequences, respectively.\" In contrast, line 171 states, \"the TDA is designed to learn the periodic features of endogenous variables by leveraging exogenous variables.\"\n3. Furthermore, the paper does not provide adequate explanations or experimental validation regarding the significance and effectiveness of decomposing and modeling the time domain and frequency domain separately.\n4. The term \"physical similarity\" in line 53 is unclear in the context of time series forecasting. A more precise explanation is required."}, "questions": {"value": "1. Why did the authors choose to introduce a two-stage decomposition and forecasting paradigm based on reconstruction instead of directly predicting the future of endogenous variables? The paper lacks detailed explanations and experimental evidence to justify this choice.\n2. In Figure 3 (right), the authors used the Pearson coefficient to estimate the correlation between the reconstructed sequences and the ground truth. Why did the authors choose the Pearson coefficient instead of Dynamic Time Warping (DTW), which is generally more suitable for time series data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3EmcpRFGr1", "forum": "br8nm3CzR0", "replyto": "br8nm3CzR0", "signatures": ["ICLR.cc/2026/Conference/Submission755/Reviewer_b1Px"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission755/Reviewer_b1Px"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760951006332, "cdate": 1760951006332, "tmdate": 1762915598846, "mdate": 1762915598846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TimeSeed, a model for time series forecasting under the specific and challenging setting where the target (endogenous) variable is sparsely observed, while correlated (exogenous) variables are fully observed. The proposed method operates in a \"reconstruct-then-predict\" fashion. It first generates a complete historical representation of the target series by aggregating information from three modules: a Time Domain Aggregator (TDA) for periodic patterns, a Frequency Domain Aggregator (FDA) for trend information (both derived from exogenous series), and an Adaptive Scale Reconstructor (ASR) which incorporates the sparse endogenous signal itself. This reconstructed series is then fed into a simple linear forecaster. The authors show that this efficient, linear-based model achieves state-of-the-art results on seven benchmark datasets under this sparse setting, outperforming numerous recent and complex models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper formalizes and tackles the f(X, S) -> Y problem, a relevant and common scenario in real-world applications where a target signal is costly or difficult to measure continuously.\n\n2) Strong Empirical Results: Within its defined experimental setup, TimeSeed demonstrates a significant and consistent performance advantage over a wide range of strong baselines.\n\n3) The model is extremely lightweight and computationally efficient, making it a practical and attractive solution for deployment.\n\n4) The authors' commitment to re-running all baselines under a fair and unified framework is a major strength."}, "weaknesses": {"value": "1) The main weakness is the limited conceptual novelty. The model is largely a thoughtful recombination of existing ideas (patching, FFT) from recent time series literature, applied to a new problem variant. The contribution feels more like system-building than the introduction of a new fundamental modeling principle.\n\n2) The central \"reconstruction\" narrative is not backed by an explicit reconstruction loss, which makes the model's inner workings less interpretable and the claims less grounded than they appear. The model is not learning to reconstruct the past per se, but rather learning a useful latent representation for forecasting.\n\n3) The evaluation is almost entirely based on a uniform sparsity pattern, which is not representative of many real-world missing data scenarios (e.g., random or block-wise missingness). The model's robustness to more realistic data imperfection is not sufficiently demonstrated.\n\n4) The paper does not compare against a straightforward two-stage pipeline of \"imputation model + forecasting model.\" This baseline is essential for determining if the proposed integrated architecture provides a tangible benefit over a simple, modular approach."}, "questions": {"value": "Could you clarify the design choice of not using a direct reconstruction loss on the historical window? Given the paper's central narrative is \"reconstruction,\" it seems this would not only align the training objective with the story but also provide a more grounded way to supervise and evaluate the TDA, FDA, and ASR modules.\n\nThe ASR module uses Gumbel-Softmax for a hard selection of a single resolution. What is the justification for this restrictive choice over a soft, weighted combination of features from all reconstructed scales (O_q), which would be a more general approach and potentially capture information across multiple resolutions simultaneously?\n\nA critical baseline seems to be missing: a two-stage approach where a state-of-the-art imputation model (e.g., SAITS, or even a masked version of a model like PatchTST) is first used to fill the sparse endogenous series, followed by a separate state-of-the-art forecasting model. How do you expect TimeSeed to perform against such a pipeline? This comparison is crucial to validate the benefits of your integrated \"reconstruct-then-predict\" architecture.\n\nHow does the model's performance degrade as the sparsity pattern becomes more challenging, for example, with large, contiguous blocks of missing data instead of uniform samples? The current reliance on TDA/FDA might be robust, but this needs to be empirically verified to claim general applicability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rBlJVhVMft", "forum": "br8nm3CzR0", "replyto": "br8nm3CzR0", "signatures": ["ICLR.cc/2026/Conference/Submission755/Reviewer_eg86"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission755/Reviewer_eg86"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761888976455, "cdate": 1761888976455, "tmdate": 1762915598670, "mdate": 1762915598670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents TimeSeed, a simple yet effective framework for forecasting when the target variable is only sparsely observed. It rebuilds a dense context of the target using exogenous variables and the few available target points, then forecasts normally. The model combines three parts: 1) Time-Domain Aggregator captures periodic patterns; 2) Frequency-Domain Aggregator extracts trend information using FFTs; 3) Adaptive Scale Reconstructor upsamples sparse data at multiple resolutions. TimeSeed is fully linear, very lightweight, and achieves improvements over baselines across seven datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. TimeSeed presents a effective approach to forecasting with sparse target data. It reframes the problem as a reconstruction-forecasting task, using simple linear modules that separate periodic and trend information through time- and frequency-domain modeling. \n\n2. The paper is clearly written and supported by various experiments, showing consistent gains on ablations that validate each component.\n\n3. The model’s clarity, lightweight design, and efficiency make it practical for real-world deployment, while its empirical results show contribution for scenarios with limited target observations."}, "weaknesses": {"value": "1. The authors did not use real datasets with sparsely observed endogenous variables and fully available exogenous variables. Instead, they created such conditions artificially by applying predefined sparsity ratios to general datasets that originally contain complete endogenous and exogenous information. This design choice somewhat weakens the paper’s practical significance. To better demonstrate the real-world relevance of this problem, it would be valuable for the authors to identify or include datasets that naturally reflect this sparse-endogenous scenario.\n\n2. How exactly is the sparsity ratio implemented? Providing a detailed description of how the sparse endogenous variables are constructed from the full datasets would help alleviate concerns about selection bias and fairness in comparison. When the sparsity ratio is high, different random seeds could substantially alter the time series behavior (e.g. especially for data with sparse-peak patterns). The impact of such randomness and its implications for statistical significance should be discussed more thoroughly.\n\n3. Additionally, were the baselines trained on the imputed, non-observed timesteps? Training models on data points known to be inaccurate could cause them to learn false inter-series relationships, which would unfairly hurt the performance of the models that focus on learning precise inter-series dependencies."}, "questions": {"value": "1. In Tables 1 and 2, it seems unusual that DLinear outperforms almost all other baselines, given that it does not take exogenous variables as input and has very few parameters. This observation reinforces the concern raised in Weakness 3 about how the baselines are adapted or trained. Moreover, the setup of the experiment in Table 2 needs clearer explanation: in Section 4.1, the paper states that “endogenous variables are missing.” In that case, what exactly does a DLinear-type model use as input?\n\n2. Is the Adaptive Scale Reconstructor reconstructing the fully dense time series, or only the sparsely observed parts? How is the reconstruction quality of the historical series evaluated. Does the model apply a reconstruction loss on the full series?\n\n3. For input lengths longer than 96, how does extending the context window affect performance? It would be helpful if the authors could include additional experiments or discussion on this aspect.\n\nIf the authors' response adequately addresses my questions and concerns mentioned above, I am willing to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "15l91Fo9PY", "forum": "br8nm3CzR0", "replyto": "br8nm3CzR0", "signatures": ["ICLR.cc/2026/Conference/Submission755/Reviewer_e8px"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission755/Reviewer_e8px"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission755/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969256949, "cdate": 1761969256949, "tmdate": 1762915598537, "mdate": 1762915598537, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}