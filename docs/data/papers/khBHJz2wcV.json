{"id": "khBHJz2wcV", "number": 17809, "cdate": 1758280783282, "mdate": 1759897152287, "content": {"title": "Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems", "abstract": "We present a framework for fine-tuning flow-matching generative models to enforce physical constraints and solve inverse problems in scientific systems. Starting from a model trained on low-fidelity or observational data, we apply a differentiable post-training procedure that minimizes weak-form residuals of governing partial differential equations (PDEs), promoting physical consistency and adherence to boundary conditions without distorting the underlying learned distribution. To infer unknown physical inputs, such as source terms, material parameters, or boundary data, we augment the generative process with a learnable latent parameter predictor and propose a joint optimization strategy. The resulting model produces physically valid field solutions alongside plausible estimates of hidden parameters, effectively addressing ill-posed inverse problems in a data-driven yet physics-aware manner. We validate our method on canonical PDE problems, demonstrating improved satisfaction of physical constraints and accurate recovery of latent coefficients. Further, we confirm cross-domain utility through fine-tuning of natural-image models. Our approach bridges generative modelling and scientific inference, opening new avenues for simulation-augmented discovery and data-efficient modelling of physical systems.", "tldr": "", "keywords": ["Generative Modeling", "Physics‑Informed Machine Learning", "Inverse Problems", "Parameter Identification"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f614aa588c8d7c0dc4f291df3cf757455f9acd4b.pdf", "supplementary_material": "/attachment/31af82a68d8c2d764654675d29c5798cbeb8796c.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a physics-consrtained post-training scheme for pre-trained flow-matching generators that enforces PDE consistency and simultaneously infers latent physical parameters for inverse problems without paired (state, parameter) supervision. The key idea is to treat weak-form PDE residuals as a reward and fine-tune the generator via Adjoint Matching. Experiments on Darcy flow, linear elasticity and natural images demonstrate PDE residual reduction and parameter recovery."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "## Originality\n- Novel problem formulation. Enforcing parameter-dependent PDE constraints without paired (parameter, solution) training data.\n- Creative architecture design. Joint state-parameter evolution with surrogate base flows constructed via inverse predictor.\n- Technical contribution. Scaled memoryless noise schedule (Lemma 1) provides useful numerical stabilization.\n- Weak-form residual approach.Stochastic sampling of Wendland-wavelet test functions is practical and avoids instabilities of strong-form residuals\n\n## Quality\n- solid theoretical grounding via adjoint matching framework.\n- thoughtful multi-faced regularization with clear ablations.\n- diverse experimental scenarios covering denoising, sparse conditioning and boundary misspecification\n- extensive reproducibility details \n\n## Clarity\nGood visual explanation, well-motivated problem setup\n\n## Significance\nPost-training paradigm is more practical than training from scratch. Proof-of-concept establishes feasibility of joint parameter-solution generation post-training, potentially inspiring future work."}, "weaknesses": {"value": "## Unacceptable Absence of Quantitive Results\nThe paper is almost entirely based on qualitative visualizations with virtually no quantitative evaluation. Only Figure 3 quantifies how the hyperparameters mediate the trade-off between staying close to the base model and reducing the (weak) PDE residual. Everyting else is visualizations of cherry picked samples. No quantitive parameter recovery metrics despite solving \"inverse problems\". No numerical residual comparisons with other methods despite claiming constraint enforcement. No baseline comparison tables of even one numerical metric despite comparing with ECI. \nThe absence of quantitive results makes it impossible to assess\n- Whether the method actually works reliably?\n- How it compares to alternatives (I am not talking about a comprehensive benchmarking agains other SOTA methods)\n- When it succeeds vs fails\n- what design choice actually matter.\n\nThe authors are encouraged to conduct thorough quantitative experiments for future submissions of this work."}, "questions": {"value": "Please refer to weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "voHngDO1tb", "forum": "khBHJz2wcV", "replyto": "khBHJz2wcV", "signatures": ["ICLR.cc/2026/Conference/Submission17809/Reviewer_n7dD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17809/Reviewer_n7dD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772954280, "cdate": 1761772954280, "tmdate": 1762927652484, "mdate": 1762927652484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a post-training framework that fine-tunes flow-matching generators using randomized weak-form PDE residuals and a joint latent-parameter pathway, so the model produces physics-consistent fields while simultaneously inferring hidden coefficients; experiments on canonical PDE tasks indicate reduced residuals with limited impact on sample diversity.\n\nContributions.\n1) Post-training physics alignment: turns an already trained flow-matching model into a physics-respecting generator by minimizing weak-form residuals with compact test functions, avoiding unstable high-order derivatives and limiting drift from the base distribution.\n2) Joint state–parameter generation: augments the generator with a learned evolution for latent physical parameters and an inverse predictor, and fine-tunes both under an adjoint-matching objective (with a scaled memoryless schedule) to couple solutions and parameters.\n3) Practical control and coverage: demonstrates denoising, sparse-observation guidance, and boundary-condition adaptation, and exposes simple knobs to trade off constraint strength versus fidelity/diversity, with lightweight fine-tuning overhead."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) Proposes a post-training route to impose physics on pretrained flow-matching models via weak-form PDE residuals, coupled with joint latent-parameter evolution for inverse problems without paired labels; also introduces a scaled memoryless noise schedule within adjoint matching.\n\n2) Grounds the method in adjoint matching and implements randomized local test functions for stable weak residuals; experiments span Darcy denoising, sparse-observation guidance, linear-elasticity boundary adaptation, and a small natural-image recoloring case, with ablations showing a residual–diversity trade-off.\n\n3) Clearly states goals and contributions, provides a pipeline diagram, derives the weak forms and test-function design, includes a full training algorithm and detailed dataset/backbone specs, and offers a reproducibility statement."}, "weaknesses": {"value": "1) Diversity objective may be misaligned for PDE solvers. For well-posed forward/inverse PDEs the target is a single solution; promoting output “diversity” is not desirable, and when partial observations make the task ill-posed, diversity stems from the problem, not the pipeline. The paper treats diversity as a knob/metric (SSIM-based) and studies its trade-off against residuals (Fig.\\ 3), which can conflict with PDE goals.\n\n2) Test problems are not comprehensive. Evaluations focus on Darcy denoising, sparse-obs guidance, and a linear-elasticity boundary change, plus a small image recoloring demo; there is no coverage of more challenging PDEs such as Poisson, Navier–Stokes, or Helmholtz, nor larger-scale or multi-physics settings.\n\n3) Limited baselines and quantitative recovery metrics. Beyond an ECI comparison in the elasticity case, there is no systematic head-to-head with alternative physics-constrained generative methods, and the paper provides little quantitative evaluation of latent-parameter recovery accuracy or real-data tests (most results are residual reductions and visuals)."}, "questions": {"value": "1) Diversity vs. PDE correctness. For well-posed forward/inverse PDEs, please justify when output diversity is desirable; otherwise, replace or augment SSIM-based diversity with task metrics (solution error L2/H1, weak/strong residual distributions, boundary-violation rates) and, for partial-observation settings, include posterior calibration (coverage vs. nominal).\n\n2) Scope of test problems. Add at least one oscillatory elliptic case (Poisson/Helmholtz) and one basic incompressible flow (e.g., lid-driven cavity or cylinder shedding); if new runs are infeasible, provide higher-resolution or 3D variants or a brief scaling analysis (compute, stability bottlenecks).\n\n3) Baselines and recovery metrics. Include matched-compute head-to-head with (i) training-time physics-regularized flow matching, (ii) inference-time projection/ECI, and (iii) a classical PDE-constrained inversion baseline. Report solution error, boundary violations, weak/strong residuals, latent-parameter MAE/RMSE, and wall-clock.\n\n4) Ablations for method choices. Provide a small ablation comparing weak vs. strong residuals (stability, final residuals) and sensitivity to test-function sampling; show how the scaled memoryless parameter kappa affects stability, residual reduction, and drift from the base distribution."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zOIoPgVHjN", "forum": "khBHJz2wcV", "replyto": "khBHJz2wcV", "signatures": ["ICLR.cc/2026/Conference/Submission17809/Reviewer_Pud7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17809/Reviewer_Pud7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982203504, "cdate": 1761982203504, "tmdate": 1762927652140, "mdate": 1762927652140, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a physics-constrained fine-tuning framework for pretrained flow-matching generative models, enabling them to satisfy PDE-based physical laws and jointly infer latent parameters without retraining from scratch. It casts the physics-constrained fine-tuning as  Adjoint-Matching loss for distribution-level correction and a lightweight architectural extension with residual heads for joint state–parameter evolution. Overall, it positions itself as a general and data-efficient bridge between physics-informed learning and modern generative modeling."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**S1.** The paper recasts physics-based simulation as an adjoint-matching control framework, elegantly linking preference-aligned generative fine-tuning with physics-constrained inference. This bridges simulation-augmented modeling and stochastic optimal control, enabling physically consistent generative trajectories.\n\n**S2.** The method’s joint treatment of state and latent parameters allows simultaneous forward generation and inverse recovery within a unified flow-matching model.\n\n**S3.** The experimental evaluation is broad and convincing, demonstrating consistent improvements in physics residuals and inverse reconstruction accuracy across multiple PDE benchmarks, while maintaining generative fidelity and efficiency."}, "weaknesses": {"value": "**W1**: A core conceptual weakness of the paper is that it does not truly model the joint state–parameter distribution $(x, α)$. The latent variable $α$ is introduced post hoc through a frozen inverse predictor $\\phi(x_1)$, which breaks end-to-end coupling between physical states and governing parameters. I would be interested know what tradeoffs do this approach have. An ablation where the base model jointly learns $(x, α)$ during pretraining would help clarify the effectiveness of the two-stage setup or if a single joint flow $v_t(x, α)$ could achieve stronger physical coherence and lower residuals.\n\n\n**W2:** The mathematical notation is dense and inconsistent, making the exposition difficult to follow even for technically skilled readers. Symbols like ($v_t$), ($b_t$), and ($u_t$) are overloaded across base, fine-tuned, and control flows, while stochastic and deterministic forms are interleaved without clear separation. Algorithm 1 is not self consistent, missing how for e.g. $\\phi$ is used. As a result, the formalism obscures theoretical contributions and could benefit from a clearer hierarchy of variables (e.g., consistently distinguishing state vs. parameter flows) and unified notation across sections.\n\n**W3:** The theoretical novelty of the paper is incremental over the original Adjoint Matching framework (Domingo-Enrich et al., 2025). The core stochastic optimal control formulation, adjoint dynamics, and lean-adjoint optimization are directly inherited, with the main contribution being their adaptation to PDE-constrained fine-tuning. While this is a valuable and well-motivated extension, it constitutes more of an application-level adaptation than a fundamentally new methodological advance."}, "questions": {"value": "Q1: How does the proposed fine-tuning framework scale to nonlinearity where PDE constraints become non-analytic or high-dimensional? Are there stability or performance guarantees in such regimes?\n\nQ2: Could the authors clarify which aspects of their method represent core methodological contributions beyond the existing Adjoint Matching framework (Domingo-Enrich et al., 2025)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3t7QZxiKLP", "forum": "khBHJz2wcV", "replyto": "khBHJz2wcV", "signatures": ["ICLR.cc/2026/Conference/Submission17809/Reviewer_ZYUG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17809/Reviewer_ZYUG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986076438, "cdate": 1761986076438, "tmdate": 1762927651744, "mdate": 1762927651744, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a post-training scheme that takes a pretrained flow-matching generator and tilts its distribution toward PDE-consistent samples by minimizing weak-form PDE residuals—so you can enforce physics (and boundary conditions) without retraining from scratch or having paired (state, parameter) data. Fine-tuning is posed as Adjoint Matching (a memoryless stochastic optimal control) with a small theoretical extension that scales the noise schedule for stability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-The key selling point is the enforcement of PDEs via weak-form residuals on a pretrained flow-matching model—no paired data or full retraining while keeping the base model’s inference cost.\n\n-The model jointly evolves state and latent parameters with an inverse predictor, enabling guided sampling from sparse parameter observations and adaptation under model misspecification."}, "weaknesses": {"value": "The proposed method is practical for post-training physics enforcement for flow matching (no paired data or full retraining). It is useful and timely, but quite incremental rather than foundational.\n\nPhysics is imposed via a weak-form residual penalty added to the flow-matching objective; it aligns the denoiser with PDE residuals but does not guarantee exact constraint satisfaction.\n\nThe method relies on several heuristics and hyperparameters, such as scaled “memoryless” noise with factor κ, time-grid tilting (q = 0.9), and computing loss on only a subset of late steps (K_last, K). These improve stability but introduce tuning sensitivity without a comprehensive robustness study."}, "questions": {"value": "Since physics is enforced via weak-form residual penalties (not hard projections), could you report post–fine-tuning feasibility diagnostics—e.g., distributions of PDE residual norms, boundary-condition violations, and conservation drift?\n\nCan you provide sensitivity curves (accuracy and residuals) versus the hyperparameters across datasets, along with any principled guidance or conditions that ensure stability without ad-hoc tuning? \n\nBecause dense weak-residual evaluation is costly, you use compact test functions and patch-based subsampling. Could you quantify coverage (e.g., how many test centers are required to achieve a target residual error) and explore adaptive sampling that targets high-residual regions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "150xxQEo77", "forum": "khBHJz2wcV", "replyto": "khBHJz2wcV", "signatures": ["ICLR.cc/2026/Conference/Submission17809/Reviewer_Mbyw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17809/Reviewer_Mbyw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762328526392, "cdate": 1762328526392, "tmdate": 1762927651295, "mdate": 1762927651295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}