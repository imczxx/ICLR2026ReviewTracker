{"id": "SiqK9UzqNT", "number": 13040, "cdate": 1758212999130, "mdate": 1759897469439, "content": {"title": "Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Models", "abstract": "Differentially private (DP) synthetic data, which closely resembles the original private data while maintaining strong privacy guarantees, has become a key tool for unlocking the value of private data without compromising privacy. Recently, Private Evolution (PE) has emerged as a promising method for generating DP synthetic data. Unlike other training-based approaches, PE only requires access to inference APIs from foundation models, enabling it to harness the power of state-of-the-art (SoTA) models. However, a suitable foundation model for a specific private data domain is not always available. In this paper, we discover that the PE framework is sufficiently general to allow APIs beyond foundation models. In particular, we demonstrate that many SoTA data synthesizers that do not rely on neural networks—such as computer graphics-based image generators, which we refer to as simulators—can be effectively integrated into PE. This insight significantly broadens PE’s applicability and unlocks the potential of powerful simulators for DP data synthesis. We explore this approach, named Sim-PE, in the context of image synthesis. Across four diverse simulators, Sim-PE performs well, improving the downstream classification accuracy of PE by up to 3X and reducing FID by up to 80%. We also show that simulators and foundation models can be easily leveraged together within PE to achieve further improvements.", "tldr": "Generating differentially private images WITHOUT machine learning models", "keywords": ["private evolution", "synthetic data", "simulators"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/24b8bcc48acdca4d160f438ecc7eb13a0b26c960.pdf", "supplementary_material": "/attachment/b836b89b7da36ecf96fc31246534c92fb518ce81.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Sim-PE, an extension of Private Evolution (PE) that replaces foundation models with simulators as the generative backend. Sim-PE supports two scenarios: when simulator APIs are accessible, the RANDOM and VARIATION APIs are implemented by sampling from the feasible parameter space; and when only a large pool of simulator-generated data is available, the VARIATION API is realized through nearest-neighbor sampling. Experiments on image datasets show that Sim-PE outperforms PE under strong distribution shifts and further benefits from combining simulators with foundation models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- A simple but effective approach that 1) improves over PE; 2) demonstrates the generality of the core mechanism of PE\n\n- Comprehensive experiments on image synthesis, covering diverse simulator types, access settings, and combinations with foundation models"}, "weaknesses": {"value": "- The technical novelty is limited. The PE framework remains essentially unchanged, and adapting its RANDOM and VARIATION APIs to simulators is straightforward. Key limitations of PE persist, including but not limited to mode collapse, sampling bias (e.g., top-K), and non-monotonic performance w.r.t. iterations.\n\n- The main contribution lies in identifying simulators as a new data source rather than introducing a new algorithmic insight. The empirical study is confined to image data, where the use of simulators is somewhat obvious and less compelling. More interesting domains such as robotics or physical simulation are left unexplored.\n\n- The strong results (Sec 4.2) largely stem from cases where the simulator distribution is already well aligned with the private data (rendering digits with Python PIL). It remains unclear how to choose or adapt a simulator for arbitrary private datasets, which limits the general applicability of the proposed approach. As a concrete question, what simulator would you consider if the goal is to generate clinical or biometric data?\n\nOverall, this work identifies an interesting direction but lacks sufficient technical depth for ICLR."}, "questions": {"value": "Sim-PE heavily depends on the choice of the similarity metric or embedding space used for the DP-NN voting and for the VARIATION API (nearest-neighbor sampling). In your experiments, this embedding comes from pretrained vision models like CLIP, which themselves are trained on massive web data. Doesn’t this reintroduce reliance on large foundation models, the very dependency Sim-PE claims to eliminate? How would Sim-PE operate in a domain where no strong pretrained embedding exists?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Q239kdXT3C", "forum": "SiqK9UzqNT", "replyto": "SiqK9UzqNT", "signatures": ["ICLR.cc/2026/Conference/Submission13040/Reviewer_kg1H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13040/Reviewer_kg1H"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13040/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760645587871, "cdate": 1760645587871, "tmdate": 1762923774575, "mdate": 1762923774575, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a key limitation of Private Evolution (PE), a state-of-the-art framework for generating differentially private (DP) synthetic data. The standard PE framework relies on inference APIs from foundation models (FMs), but its performance degrades significantly when a suitable FM for the private data domain is unavailable (e.g., using an ImageNet-trained FM for MNIST data).\n\nThe authors' key insight is that the PE framework is general and only requires two abstract APIs: a `RANDOM_API` to generate initial samples and a `VARIATION_API` to produce variations of a given sample. The paper proposes **Sim-PE**, a novel approach that implements these APIs using non-neural-network data synthesizers, which the authors refer to as \"simulators\".\n\nThe paper introduces two practical methods for integrating simulators:\n1.  **Simulator Access:** When the simulator's code is available, `RANDOM_API` renders images with random parameters, and `VARIATION_API` renders images with slightly perturbed parameters.\n2.  **Data Access:** When only a large, simulator-generated dataset is available (e.g., due to proprietary assets), `RANDOM_API` samples a random image from the dataset, and `VARIATION_API` selects a random nearest neighbor of a given image.\n\nThe authors also demonstrate that simulators and FMs can be used together in a hybrid approach, for instance, by using a simulator for diverse initialization and an FM for refinement.\n\nExperiments show that Sim-PE is highly effective. \n- On MNIST, where standard PE fails (27.9% accuracy), Sim-PE with a text-rendering simulator achieves 89.1% accuracy, a 3x improvement. \n- On CelebA, Sim-PE successfully selects high-utility samples from a public dataset and a hybrid approach with a weak simulator outperforms using either the simulator or the FM alone. \n- Finally, Sim-PE is shown to be up to 80x more computationally efficient than standard PE."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The core idea is simple and elegant. While not groundbreaking, this paper opens up PE to a new class of generative tools beyond foundation models. \nThe presentation is very clear. I especially appreciate the underlying motivation for the choice of experiments as well as the ablation studies."}, "weaknesses": {"value": "- While the authors show that it is not necessary to have a foundation model that is aligned with the private data, it doesn't directly solve the issue of cold starts, but instead shifts the dependency on a good foundation model to a good simulator."}, "questions": {"value": "-  The hybrid model is very promising. Have the authors considered a \"mixed\" or \"parallel\" strategy? For example, within a single iteration, could the variation API somehow combine a simulator and FM? This seems possible given the framework's modularity.\n- How sensitive is the performance of SIM-PE to the choice of simulator? While ImageNet FM -> private MNIST has low utility due to a mismatch with the foundation model, how does the utility of SIM-PE degrade with mismatched simulators?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SA2WBE2rg1", "forum": "SiqK9UzqNT", "replyto": "SiqK9UzqNT", "signatures": ["ICLR.cc/2026/Conference/Submission13040/Reviewer_SEY6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13040/Reviewer_SEY6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13040/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841558311, "cdate": 1761841558311, "tmdate": 1762923773488, "mdate": 1762923773488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work extends Private Evolution framework from foundation model APIs to simulators and simulator-generated datasets. Key insight: PE's privacy guarantee depends only on DP Nearest Neighbors Histogram, so generation backend can be abstracted via RANDOM and VARIATION APIs. For accessible simulators, APIs implemented through parameter perturbation. For data-only simulators, nearest-neighbor variation avoids wasting privacy budget on distant samples. On MNIST with ε=1, Sim-PE achieves 89.1% classification accuracy versus PE's 27.9%, reducing FID by 80%. Framework enables combining simulators with foundation models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Backend-agnostic design demonstrates real impact. MNIST shows foundation model pretrained on ImageNet achieves 27.9% on digits while text renderer achieves 89.1% (Table 1). When distribution mismatch exists, appropriate backend selection matters.\n- Handles realistic deployment scenarios: accessible simulator with direct parameter control, and data-only simulator common when proprietary assets involved.\n- Nearest-neighbor iterative refinement (Section 3.3) avoids privacy budget waste on irrelevant samples. Table 3 shows clear improvement over naïve approaches.\n- Combination strategy (Table 2) demonstrates framework flexibility: simulator + foundation model outperforms either alone on CelebA (FID 11.9 vs 22.0 for PE alone, 99.5 for weak simulator alone)."}, "weaknesses": {"value": "- My main concern is with the privacy accounting for the data-based Sim-PE (Sec 3.3). The method uses an external embedding model (Inception, Appendix F.1) for its nearest-neighbor search, but the privacy properties of this embedding are never analyzed. If this embedding was trained on related private data, it could leak information, and this seems to be an unaddressed gap in the privacy proof."}, "questions": {"value": "- Could the authors clarify the privacy accounting for the external embedding model? How can we be sure it doesn't leak information, and shouldn't it be consistent across all baselines for a fair comparison?\n- How sensitive is the data-based Sim-PE to the choice of the embedding model? Does performance change significantly if using CLIP, DINOv2, or other task-specific embeddings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eSeFkRACJO", "forum": "SiqK9UzqNT", "replyto": "SiqK9UzqNT", "signatures": ["ICLR.cc/2026/Conference/Submission13040/Reviewer_XMoB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13040/Reviewer_XMoB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13040/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893278677, "cdate": 1761893278677, "tmdate": 1762923773094, "mdate": 1762923773094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces simPE, an extension of PE. In traditional PE, the work relies on foundational models. In simPE, the authors show that PE framework can be extended to other simulators as well and not rely on only foundational models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and easy to understand. The work proposed is simple to use but powerful and extends PE to work with simulators. The work also provides clear, actionable guidelines for both simulator access and data-only scenarios."}, "weaknesses": {"value": "1. The paper's contribution is minimal. It extends the same framework of PE to work with simulators. Since PE itself needs only APIs, the main contribution of the paper seems to be replacing foundational models behind the APIs with simulators.\n2. The work focuses mainly on image generation because of dependencies on simulators. The quality of the images also depend on the availability of the simulator's capability to generate data similar to the original dataset."}, "questions": {"value": "1. How sensitive is Sim-PE to simulator quality?\n2. How do biases in simulators transfer to the synthetic data? Are there ways to detect or mitigate such transfers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RkgWnGuYTD", "forum": "SiqK9UzqNT", "replyto": "SiqK9UzqNT", "signatures": ["ICLR.cc/2026/Conference/Submission13040/Reviewer_BegZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13040/Reviewer_BegZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13040/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983067641, "cdate": 1761983067641, "tmdate": 1762923772605, "mdate": 1762923772605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}