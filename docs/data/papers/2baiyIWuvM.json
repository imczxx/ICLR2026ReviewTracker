{"id": "2baiyIWuvM", "number": 18850, "cdate": 1758291441223, "mdate": 1759897077793, "content": {"title": "MolTextNet: A Two-Million Molecule-Text Dataset for Multimodal Molecular Learning", "abstract": "Small molecules are essential to drug discovery, and graph–language models hold promise for learning molecular properties and functions from text. However, existing molecule–text datasets are limited in scale and informativeness, restricting the training of generalizable multimodal models. We present MolTextNet, a dataset of 2.5 million high-quality molecule–text pairs designed to overcome these limitations. To construct it, we propose a synthetic text generation pipeline that integrates structural features, computed properties, bioactivity data, and synthetic complexity. Using GPT-4o-mini, we create structured descriptions for 2.5 million molecules from ChEMBL35, with text over 10 times longer than prior datasets. MolTextNet supports diverse downstream tasks, including property prediction and structure retrieval. Pretraining CLIP-style models with Graph Neural Networks and ModernBERT on MolTextNet yields improved performance, highlighting its potential for advancing foundational multimodal modeling in molecular science.", "tldr": "", "keywords": ["Large-scale Molecule-text Dataset", "Multimodal learning", "Contrastive Pretraining", "Molecular Representation Learning"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1c50a813c7d5726d07efc870451b33d7438d1880.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces MolTextNet, a large-scale molecule–text dataset built from ChEMBL35 and USPTO-derived cues. The authors generate approximately 2.5M molecule–text pairs by prompting GPT-4o-mini to synthesize structured, 100–500-word scientific descriptions that tie structural motifs, physicochemical properties, assay outcomes, and synthesis difficulty together; critical tokens (names, SMILES, numbers) are preserved and unit normalization plus filtering are applied to control quality. Compared with PubChem-300K and ChEBI-20, MolTextNet offers longer, denser text and broader coverage. The paper validates the dataset by pretraining CLIP-style models using a GIN graph encoder and a long-context ModernBERT text encoder, then fine-tuning on OGB classification and regression tasks and testing zero-shot structure retrieval formed as functional-group queries. Across 10 downstream tasks the models pretrained on MolTextNet-300K subsets generally outperform those trained on prior datasets, with additional analyses on text encoders and topic coverage."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- MolTextNet reports about 2.5M pairs with far longer descriptions than PubChem-300K and ChEBI-20, with explicit attempts to include structure, property, and synthesis dimensions. This improves lexical and conceptual grounding for multimodal pretraining. \n\n- The paper details how SMILES and compound names are validated, how properties and assays are collected and normalized, how numeric tokens are preserved, and how chunking is handled for ultra-long entries. This level of detail supports reuse. \n\n- Consistent gains when pretraining on MolTextNet subsets are shown across seven OGB classification and three regression tasks, and the functional-group retrieval task highlights alignment between text and structure learned by CLIP-style training. \n\n- Using ModernBERT for long context shows why a longer-context encoder matters; the SciBERT ablation underscores the cost of truncation. Compute and training settings are stated."}, "weaknesses": {"value": "- The paper relies on post-generation rules (length, token consistency) but does not quantify error rates for numeric values, assay units, or misattributed functional groups. A small-scale human or programmatic audit (e.g., SMILES-parsed substructure counts vs. described counts, unit conversions) would strengthen trust in the synthetic text. (major)\n\n- The zero-shot retrieval task is built from simple functional-group templates; it does not test richer assay semantics, property trends, or synthesis narratives. Broader retrieval formulations (e.g., “two para-substituted phenyl rings and high polar surface area”) or caption-to-graph matching on held-out families could better reflect the dataset’s intent. \n\n- Only a GIN encoder is studied on the graph side; modern graph transformers or message-passing variants could show whether the benefit generalizes across inductive biases. The text side focuses on two encoders; more comparisons (e.g., Longformer-style scientific encoders) would provide a fuller picture. \n\n- Coverage claims would be stronger with quantitative chemical-space measures beyond t-SNE and topic models, such as Bemis–Murcko scaffold diversity, ECFP-based internal diversity, pairwise Tanimoto distributions against downstream tasks, and assay-type entropy. Current plots are informative but not sufficient to support generalization claims on their own."}, "questions": {"value": "1. Can you report a measured error rate for numeric fields and substructure mentions by cross-checking generated text against RDKit-computed counts and standardized pChEMBL values after unit conversion? A 1–2% sampled audit with confidence intervals would help. \n\n1. You state overlap with OGB was removed and remains below 7%. Please provide the exact overlap counts per OGB dataset, the hashing or SMILES canonicalization used, and an independent hash list to enable external verification. \n\n1. For the 401 ultra-long entries, how often did iterative summarization change earlier facts? Do you have a checksum-based or programmatic equivalence test to ensure no loss or drift across chunks? \n\n1. Can you add queries that combine structural patterns with property statements (e.g., “three aromatic rings and high ALogP with low HBD”) and report mAP/Recall@k to demonstrate semantic alignment beyond pure substructure counting? \n\n1. Do the MolTextNet gains transfer to Graphormer or PSP-style graph transformers? Even a small subset experiment would help position the dataset for broader use."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vM2eYmgRhd", "forum": "2baiyIWuvM", "replyto": "2baiyIWuvM", "signatures": ["ICLR.cc/2026/Conference/Submission18850/Reviewer_NFq3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18850/Reviewer_NFq3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757615251, "cdate": 1761757615251, "tmdate": 1762930818190, "mdate": 1762930818190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MolTextNet, a large-scale dataset consisting of approximately 2.5 million molecule–text pairs constructed from ChEMBL35. The authors develop a synthetic text generation pipeline using GPT-4o-mini to produce long, structured descriptions that integrate molecular structure, physicochemical properties, bioactivity assays, and synthesis complexity. Compared with existing resources such as PubChem-300K and ChEBI-20, MolTextNet provides significantly longer and richer textual annotations, improving coverage across chemical space. The authors validate the dataset by pretraining CLIP-style models combining GIN and ModernBERT, showing consistent gains on standard property-prediction benchmarks (OGB tasks) and demonstrating better zero-shot structure retrieval. The work highlights the potential of synthetic molecule-text data for multimodal molecular modeling and aims to provide a new foundation for future research."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Presents the largest molecule–text dataset so far, combining structure, property, and synthesis aspects.  \n2.The data pipeline is transparent and well-documented, facilitating reproducibility.  \n3.Empirical results confirm consistent improvements over prior datasets in multiple downstream benchmarks."}, "weaknesses": {"value": "1.The novelty is primarily engineering-driven (data expansion) rather than conceptual.  \n2.The paper mainly focuses on CLIP-style retrieval; broader evaluations (e.g., text-to-molecule generation or reasoning tasks) are missing.  \n3.No systematic human evaluation or statistical verification of data correctness is reported.  \n4.Limited exploration of biases across molecular domains."}, "questions": {"value": "1.How is factual correctness of generated molecular descriptions quantitatively validated?  \n2.Are there examples where GPT-4o-mini introduces incorrect or speculative statements, and how are they filtered?  \n3.What percentage of molecules lack valid synthesis or assay annotations after filtering?  \n4.Can you share the exact prompting strategy or scripts used for text generation?  \n5.How do generated texts compare qualitatively to real literature descriptions?  \n6.Have you analyzed inter-molecule text similarity to confirm linguistic diversity?  \n7.How would MolTextNet perform in cross-domain transfer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "z2Y9wqWomC", "forum": "2baiyIWuvM", "replyto": "2baiyIWuvM", "signatures": ["ICLR.cc/2026/Conference/Submission18850/Reviewer_uLf8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18850/Reviewer_uLf8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806864297, "cdate": 1761806864297, "tmdate": 1762930817862, "mdate": 1762930817862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present MolTextNet, a new, large-scale dataset of 2.5 million molecule-text pairs. The work is motivated by the significant limitations of existing datasets like PubChem-300K, which are relatively small-scale and, more importantly, contain extremely sparse and uninformative textual descriptions (e.g., a median length of 13 words). The core contribution is a synthetic data generation pipeline to create rich, informative descriptions. The authors start with 2.5 million molecules from ChEMBL35  and aggregate a comprehensive set of annotations for each molecule, including Structure, Properties, and Synthesizability.\n\nThis structured dictionary of annotations is then fed to an LLM (GPT-40-mini) using a specific prompt template. This prompt explicitly instructs the model to analyze and reason about the relationships between structure, properties, and synthesis, rather than simply listing the annotations. The resulting dataset has descriptions over 10 times longer on average than previous datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper addresses a clear and widely acknowledged bottleneck in multimodal molecular ML: the lack of large-scale, high-quality, and informative molecule-text data. A dataset of 2.5 million pairs with rich descriptions is a substantial contribution that could unlock new modeling capabilities.\n- Good empirical results"}, "weaknesses": {"value": "- The most significant concern is that the entire text corpus is generated by an LLM. The paper trains models to align molecular graphs with a model's interpretation of chemical data, not with human-generated scientific text.\n- The quality control section (3.3) is procedurally robust but semantically weak. The authors check for valid SMILES, deduplicate entries, and filter based on length or missing fields. However, there is no human expert validation of the generated text. \n- The generator LLM (GPT-40-mini) was almost certainly trained on a corpus that includes PubChem, ChEMBL, and the OGB benchmarks. The authors state they filter explicit molecule overlaps with OGBG, which is good. However, this does not prevent conceptual leakage. The LLM's pre-existing knowledge of structure-property relationships (e.g., which scaffolds are common in HIV inhibitors) could be \"leaked\" into the generated text descriptions. This could, in turn, make the downstream OGBG-HIV task artificially easier, not because the GNN learned better chemical principles, but because the text-side provided \"hints\" that originate from the test set itself.\n- The zero-shot retrieval task is a toy problem based on identifying simple functional groups. A much stronger validation would be to query for properties or bioactivity (e.g., \"Retrieve molecules that inhibit DNA gyrase and have a low pKa\"). This would actually test the novel property and synthesis information that MolTextNet claims to provide."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rfPExle9x6", "forum": "2baiyIWuvM", "replyto": "2baiyIWuvM", "signatures": ["ICLR.cc/2026/Conference/Submission18850/Reviewer_dJnV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18850/Reviewer_dJnV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762085081084, "cdate": 1762085081084, "tmdate": 1762930817300, "mdate": 1762930817300, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MolTextNet, a dataset comprising over 2 million molecule-text pairs to support multimodal learning between molecular structures and language. The dataset is constructed by integrating captions generated from public databases (PubChem, ChEMBL) and augmenting missing textual descriptions using ChatGPT-assisted caption synthesis and RDKiT based properties. Further, the authors train foundation models on MolTextNet and evaluate performance on downstream tasks such as property prediction, text–molecule retrieval, and molecule captioning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. MolTextNet is impressive in size (~2 million molecule-caption pairs) and could serve as a valuable resource for pre-training large multimodal models in chemistry and biomedicine. \n2. The data sourcing and pipeline design are clearly explained.\n3. The design considerations are reasonable, by integrating information from a wide-range structural, chemical properties and integrating with functional annotations."}, "weaknesses": {"value": "1. Reliability and hallucination concerns: A significant portion of captions are generated using ChatGPT, yet the paper provides no systematic validation or human evaluation of correctness. Prior work (e.g., MolTextQA) has reported high hallucination rates which raises serious concerns about factual accuracy. Larger synthetic datasets without validation may introduce noise rather than provide meaningful supervision\n2. The dataset is not available for access, and the supplementary materials do not include even a small verification subset. For a dataset-driven paper, accessibility is critical to assess quality, and impact. Without at least a partial release, it is difficult to evaluate the contribution.\n3. Reported performance gains over existing datasets such as PubChem-300K are small (often <1-2 %), and no statistical tests are presented to establish significance. This makes it unclear about the utility of the dataset.\n4. The experiments focus on property prediction and molecule-text retrieval, but there is no evaluation on captioning quality itself, which is common with other works in the area.\n5. The paper overlooks several directly relevant prior datasets:\n    - MolQA (Xingyu et al., 2024) - a QA dataset with focus on factual validity. \n    - MolTextQA (Laghuvarapu et al., 2025) – 500 K+ molecule-QA pairs connecting structure and textual semantics;\n    - 3DMolLM (Sihang et al., 2024) – multimodal dataset incorporating molecular geometry and captions.\nThese works must be cited and compared in terms of dataset composition, along with any other missing related works.\n\n[1] Lu, Xingyu, et al. \"MoleculeQA: A dataset to evaluate factual accuracy in molecular comprehension.\" arXiv preprint arXiv:2403.08192 (2024).\n[2] Laghuvarapu, Siddhartha, et al. \"MolTextQA: A Question-Answering Dataset and Benchmark for Evaluating Multimodal Architectures and LLMs on Molecular Structure–Text Understanding.\" Journal of Data-centric Machine Learning Research (2025).\n[3] Li, Sihang, et al. \"Towards 3d molecule-text interpretation in language models.\" arXiv preprint arXiv:2401.13923 (2024)."}, "questions": {"value": "1. Have you performed any human evaluation of the generated captions’ correctness?\n2. What procedures were used to detect or reduce hallucinations in ChatGPT-generated text? Were chemical rules, filters, or expert checks applied?\n3. Are the reported improvements over PubChem-300K statistically significant? Could you provide significance tests?\n4. What are the licensing and hosting plans for the dataset ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xm5NWyKkKG", "forum": "2baiyIWuvM", "replyto": "2baiyIWuvM", "signatures": ["ICLR.cc/2026/Conference/Submission18850/Reviewer_pqf7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18850/Reviewer_pqf7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105843229, "cdate": 1762105843229, "tmdate": 1762930816780, "mdate": 1762930816780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}