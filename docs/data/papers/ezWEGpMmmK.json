{"id": "ezWEGpMmmK", "number": 1788, "cdate": 1756927677953, "mdate": 1759898186796, "content": {"title": "Every Step Counts: Decoding Trajectories as Authorship Fingerprints of dLLMs", "abstract": "Discrete Diffusion Large Language Models (dLLMs) have recently emerged as a competitive paradigm for non-autoregressive language modeling. Their distinctive decoding mechanism enables faster inference speed and strong performance in code generation and mathematical tasks. In this work, we show that the decoding mechanism of dLLMs not only enhances model utility but also can be used as a powerful tool for model attribution. Specifically, by analyzing the decoding trajectory associated with a given response, we can effectively identify its source model, thereby helping to mitigate risks of harmful content caused by model misuse. A key challenge in this problem lies in the diversity of attribution scenarios, including distinguishing between different models as well as between different checkpoints or backups of the same model. To ensure broad applicability, we identify two fundamental problems: **what information to extract from the decoding trajectory, and how to utilize it effectively.** We first observe that relying directly on per-step model confidence yields poor performance. This is mainly due to the bidirectional decoding nature of dLLMs: each newly decoded token influences the confidence of other decoded tokens, making model confidence highly redundant and washing out structural signal regarding decoding order or dependencies. To overcome this, we propose a novel information extraction scheme called the **Directed Decoding Map (DDM)**, which captures structural relationships between decoding steps and better reveals model-specific behaviors. Furthermore, to make full use of the extracted structural information during attribution, we propose **Gaussian-Trajectory Attribution (GTA)**, where we fit a cell-wise Gaussian distribution at each decoding position for each target model, and define the log-likelihood difference of a trajectory under different distributions as the attribution score: if a trajectory exhibits higher log-likelihood under the distribution of a specific model, it is more likely to have been generated by that model. Extensive experiments under different settings validate the utility of our methods.", "tldr": "", "keywords": ["Model Attribution", "Discrete Diffusion LLMs"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c1b79c7957ba4eb94c7b777f9e325ef0100eaefe.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a model attribution method targeting discrete diffusion large language models. Diverging from conventional methods reliant solely on the final text output, this work utilizes the dLLMs' unique non-autoregressive decoding trajectory as a model \"fingerprint\". By analyzing how the model’s internal states evolve over timesteps during the denoising process (i.e., the decoding trajectory), it is possible to effectively determine the source model responsible for generating a particular response. \n\nHowever, this innovation is severely limited by a lack of theoretical robustness proof and significant practical deployment challenges."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Model attribution is an interesting and timely research direction.\n\n2. The experimental results preliminarily demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The decoding process of diffusion models is inherently highly stochastic and sampling-dependent. The paper fails to provide clear empirical and theoretical arguments on how the extracted \"trajectory fingerprint\" maintains its uniqueness and stability under varying critical conditions, such as different random seeds, sampling temperatures, and other decoding hyperparameter settings, which are essential for its qualification as a robust \"fingerprint.\"\n\n2. The proposed method requires logging the entire internal state at every single time step ($T$ steps) during the decoding process. This generates massive storage and computational overhead compared to storing just the final output text, making large-scale practical deployment highly impractical. Additionally, trajectory-based attribution requires access to intermediate outputs during model decoding, which is a typical white-box or gray-box assumption. For commercial closed-source LLM services like OpenAI or Google, users cannot access these decoding trajectories, rendering the method entirely infeasible.\n\n3. A proper comparative analysis is missing. The authors must incorporate, or at least fully discuss the limitations of, established attribution methods for autoregressive models, such as those based on final response log-likelihood or watermarking techniques.\n\n4. The paper only considers two small-scale models: LLaDA-8B-Instruct and Dream-7B-Instruct. The robustness of the approach across larger and more diverse model architectures remains unproven.\n\n5. All key symbols used in the formulas should be listed in a symbol table to aid reader comprehension.\n\n6. The paper appears not to conduct cross-domain generalization tests."}, "questions": {"value": "1. Which part of the decoding trajectory contributes most to attribution? Theoretical analysis should provide insights into the information content of different timesteps to support feature extraction design.\n\n2. What metrics are used to quantify and compare the similarity or difference between two decoding trajectories?\n\n3. The paper abbreviates “Discrete Diffusion Large Language Models” as dLLM, but in other literature, diffusion LLMs may not be explicitly discrete. Why did the authors include “Discrete”? What is the standard terminology, and is the proposed method not applicable in continuous spaces?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Q420rW7RNq", "forum": "ezWEGpMmmK", "replyto": "ezWEGpMmmK", "signatures": ["ICLR.cc/2026/Conference/Submission1788/Reviewer_3QFe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1788/Reviewer_3QFe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761381137772, "cdate": 1761381137772, "tmdate": 1762915890787, "mdate": 1762915890787, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the model attribution problem in dLLMs by proposing DDM to extract decoded trajectory structure information and GTA to achieve attribution through Gaussian distribution. It performs well in multi-scenario experiments across models and is superior to the baseline. It is also effective in black-box scenarios, thus helping to manage the risks of dLLMs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper presents the first study on model attribution in DLLMs.\n\n- This work is experimentally comprehensive, investigating various scenarios, such as different numbers of models and black-box states."}, "weaknesses": {"value": "- Lack of analysis explaining why GTA can capture structural patterns rather than dominant modes.\n\n- Lack of a detailed definition or calculation formula for confidence.\n\n- The authors mention the high efficiency of GTA, but lack specific experimental data.\n\n- For Cross-Checkpoint Attribution (CCA), the paper does not provide specific numerical values ​​for the epoch interval, nor does it experimentally compare the minimum epoch interval that different methods can measure."}, "questions": {"value": "- What do the values ​​in Figure 8 mean? Are they model similarity? If so, what is the accuracy of the model attribution?\n\n- Why not directly compare the SVD of the DDM, but instead use a log-likelihood to compare similarity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4l4SyuQn6J", "forum": "ezWEGpMmmK", "replyto": "ezWEGpMmmK", "signatures": ["ICLR.cc/2026/Conference/Submission1788/Reviewer_dGL7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1788/Reviewer_dGL7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789742478, "cdate": 1761789742478, "tmdate": 1762915890393, "mdate": 1762915890393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies model attribution for discrete diffusion large language models (dLLMs) by exploiting their iterative decoding trajectories. It proposes the Directed Decoding Map (DDM), a second-order representation that encodes how newly decoded tokens affect previously decoded tokens, and Gaussian-Trajectory Attribution (GTA), which fits cell-wise Gaussian fingerprints over DDMs for attribution scoring. Experiments across cross-model, independent-run, and cross-checkpoint settings report strong AUCs—especially for GTA+DDM—compared to perplexity, clustering, and distance baselines. The paper argues that discriminative signal lives in fine-grained (tail) components (SVD analysis) and that results are robust to effect-value choices and decoding strategies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear, novel framing: leverages unique bidirectional, iterative decoding of dLLMs to form attribution features (DDMs) rather than raw confidences.\n\n- Method is simple, lightweight, and gray-/black-box compatible (cell-wise Gaussians; black-box variant uses only decoded tokens).\n\n- Strong empirical gains over PPL/cluster/distance baselines across scenarios; thorough ROC/AUC reporting.\n\n- Insightful SVD analyses showing signal in tail components; ablations on effect values and structure preservation."}, "weaknesses": {"value": "- Independence assumption: GTA models each cell independently; correlations across steps/tokens appear important per SVD/structure results, yet are not modeled (risking suboptimality). Please justify and/or compare to structured densities (e.g., low-rank Gaussians).\n\n- Definition of “confidence” $c_i(j)$ is underspecified (distribution over what, pre/post-masking calibration, temperature), affecting DDM entries. Clarify computation and normalization across steps/models.\n\n- Effect values $(\\alpha,\\beta,\\gamma)$ are fixed hyperparameters; although robustness is claimed, the choice (e.g., $\\alpha=10,\\beta=0.5,\\gamma=2$) seems ad hoc and may encode scale information from confidences. Provide calibration/normalization or learning-based selection."}, "questions": {"value": "- [How exactly is $c_i(j)$ computed (logits→probabilities? temperature? masking convention)? \n\n- Why independent cell Gaussians? Did you try low-rank covariance, Kronecker or HMM-like temporal models to capture step/token dependencies?\n\n-  How many samples N per model are needed to fit stable GTA fingerprints? Provide AUC vs N and confidence intervals.\n\n- Does performance hold under domain shift (e.g., train GTA on GSM8K, test attribution on CodeAlpaca) and under adversarial imitation of DDM patterns?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "YYfY2vSO59", "forum": "ezWEGpMmmK", "replyto": "ezWEGpMmmK", "signatures": ["ICLR.cc/2026/Conference/Submission1788/Reviewer_gzXx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1788/Reviewer_gzXx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997183512, "cdate": 1761997183512, "tmdate": 1762915890180, "mdate": 1762915890180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the problem of model attribution, with a focus on diffusion language models as an emerging architecture. It proposes the design of DMM along with a corresponding GTA approach for second-order modeling and learning, which is validated and analyzed on the Dream and LLADA models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This work represents one of the first efforts to address model attribution from the perspective of diffusion models and demonstrates the effectiveness of the proposed approach.\n- The methodology is straightforward and built upon a reasonable foundation."}, "weaknesses": {"value": "- As the study focuses on second-order modeling and analysis of different decoding strategies, it lacks exploration of recent blockwise diffusion models (e.g., SDAR[1], dllm-var[2]). The applicability of the proposed method to such models remains unclear.\n- Beyond mathematical and code reasoning tasks, the evaluation does not assess performance on knowledge-intensive tasks, leaving the method’s effectiveness in such domains unverified.\n- The generalization capability of the method, along with the impact of key hyperparameters, requires further analysis and insight.\n\n[1] SDAR: A Synergistic Diffusion-AutoRegression Paradigm for Scalable Sequence Generation\n\n[2] Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way"}, "questions": {"value": "- Given that the dominant model architecture remains autoregressive, is the proposed method suitable for autoregressive decoding schemes? How can it be efficiently adapted to autoregressive models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aVfUfB8WdL", "forum": "ezWEGpMmmK", "replyto": "ezWEGpMmmK", "signatures": ["ICLR.cc/2026/Conference/Submission1788/Reviewer_UBPg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1788/Reviewer_UBPg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762562349672, "cdate": 1762562349672, "tmdate": 1762915889988, "mdate": 1762915889988, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}