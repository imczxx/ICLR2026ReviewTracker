{"id": "CoxruEzsd2", "number": 23661, "cdate": 1758346844813, "mdate": 1759896802599, "content": {"title": "Zero-Shot Visual Generalization in Model-Based Reinforcement Learning via Latent Consistency", "abstract": "Model-based reinforcement learning (MBRL) has shown remarkable success in pixel-based control by planning within learned latent dynamics. However, its robustness degrades significantly when test-time observations deviate from the training distribution due to unseen distractions such as shadows, viewpoint, or background variations. In this paper, we propose **Vi**sual **G**eneralization in **MO**del-based RL (**ViGMO**), a novel framework that achieves zero-shot generalization to unseen visual distractions while preserving high sample efficiency. ViGMO integrates three key components: (i) a *mixed weak-to-strong augmentation* strategy to balance efficient learning with robustness, (ii) *latent-consistency learning* to enforce stable transition predictions under distribution shifts, and (iii) *encoder regularization* to preserve task-relevant features and prevent representational collapses. Extensive evaluations on the DeepMind Control suite and Robosuite with challenging unseen distractions demonstrate that ViGMO outperforms state-of-the-art model-free and model-based baselines, improving zero-shot generalization by up to $13\\\\%$ over the strongest baseline while maintaining the hallmark efficiency of latent-space MBRL.", "tldr": "Mixed weak-to-strong augmentation and latent consistency regularization make world models generalizable to unseen visual distractions", "keywords": ["Model-based Reinforcement Learning", "Visual Reinforcement Learning", "Representation Learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bf54735e7a29afc7c64d97a36141e22f05af18dc.pdf", "supplementary_material": "/attachment/329a4bc59954f761eeb21a9bb9e0e61d42f48026.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes ViGMO (Visual Generalization in Model-based RL), a model-based reinforcement learning (MBRL) framework that addresses the problem of visual generalization. To mitigate the severe performance degradation of policies under visual perturbations (e.g., changes in lighting, background, or texture) at test time, ViGMO is designed to learn latent dynamics consistency and is composed of three key components:\n\n* MA (Mixed Weak-to-Strong Augmentation) – applies strong augmentations to only half of each mini-batch to balance sample efficiency and robustness.\n* LC (Latent Consistency) – enforces augmentation-invariant transition consistency in latent space by using weak/strong view pairs generated by MA.\n* ER (Encoder Regularization) – aligns weak-only and weak→strong latent representations of the same frame to stabilize encoder features.\n\nThe framework is implemented on top of TD-MPC2, and experimental results on the RL-ViGen benchmark show that ViGMO outperforms both MFRL methods (e.g., SVEA, DrQ-v2, SGQN) and MBRL methods (e.g., DreamerV3, Dr. G, TD-MPC2), achieving up to 13% improvement in performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The idea of enforcing latent-space consistency in model-based RL is not new; it was already introduced in Dr. G (Ha et al., 2023) through dual contrastive learning and inverse dynamics. ViGMO’s contribution lies mainly in simplifying this idea into a decoder-free, MSE-based formulation compatible with TD-MPC2."}, "weaknesses": {"value": "### (1) Limited conceptual novelty:\nThe central idea of enforcing latent dynamics consistency is not conceptually new.\nPrior works such as Dr. G (Ha et al., 2023) and SPD (Kim et al., 2022) have already introduced consistency regularization at the latent-dynamics level.\nIn particular, Dr. G, a model-based framework, combines dual contrastive learning and recurrent inverse-dynamics losses to achieve consistency across visual perturbations.\nViGMO’s ER loss closely resembles the approach in SODA (Hansen & Wang, 2021), with its main novelty being the application of this loss within TD-MPC2.\nThis constitutes a useful engineering simplification but not a fundamentally new algorithmic insight.\n\n### (2) Reproducibility and evaluation-benchmark ambiguity.\nViGMO is evaluated on the RL-ViGen benchmark, whereas Dr. G was originally assessed on DMControl-GB.\nThese benchmarks differ in rendering pipeline, camera randomization, and observation normalization,\nwhich likely explains the large performance drop of Dr. G reported in this paper.\nWithout cross-benchmark replication or normalization of rendering settings,\nit remains unclear whether the reported improvements stem from algorithmic advances or from environmental discrepancies.\n\n### Overall assessment.\nViGMO demonstrates solid empirical results but offers only incremental novelty over prior latent-consistency frameworks such as SODA, SPD, and Dr. G. The main weaknesses lie in the unclear theoretical distinction, benchmark inconsistency, and limited mechanistic analysis."}, "questions": {"value": "1. Use of mixed weak & strong augmentations\nMany prior works already employ a combination of weak and strong augmentations for visual robustness.\nBeyond reusing this common strategy, what specific contribution or new insight does ViGMO introduce?\n\n2. Latent-dynamics consistency\nThe idea of enforcing consistency in latent dynamics was emphasized in Dr. G (Ha et al., 2023) and SPD (Kim et al., 2022).\nHow does ViGMO’s Latent Consistency (LC) differ conceptually or functionally from these prior formulations?\n\n3. Encoder Regularization (ER)\nThe proposed ER component appears very similar to the feature-alignment regularization used in SODA (2021).\nCould the authors clarify what is novel or distinct in their formulation?\n\n4. Performance discrepancy of Dr. G\nIn prior literature, Dr. G consistently demonstrated strong visual robustness on both DMC and Robosuite benchmarks (evaluated on DMControl-GB). In contrast, the reported results here show a severe degradation of Dr. G’s performance.\nCould the authors investigate and explain the cause of this gap—e.g., differences in benchmark version, rendering pipeline, or implementation details?\n\n5. Missing comparison with recent state-of-the-art work (SMD, Zhang et al., 2024)\nThe paper omits comparison with the recent study “Focus on What Matters: Separated Models for Visual-Based RL Generalization (SMD, Zhang et al., 2024)”, which also tackles visual generalization in RL by separating representation and dynamics learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "MUoYm4ExHr", "forum": "CoxruEzsd2", "replyto": "CoxruEzsd2", "signatures": ["ICLR.cc/2026/Conference/Submission23661/Reviewer_MxSJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23661/Reviewer_MxSJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23661/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761530739695, "cdate": 1761530739695, "tmdate": 1762942752416, "mdate": 1762942752416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a critical limitation in current Model-Based Reinforcement Learning (MBRL): catastrophic performance degradation when facing unseen visual distractions at test time (zero-shot generalization). The authors propose ViGMO (Visual Generalization in Model-based RL), a framework built atop TD-MPC2. ViGMO introduces three complementary components to robustify latent-space planning without sacrificing sample efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Preservation of Sample Efficiency: A major contribution is achieving robustness without the typical sample efficiency tax associated with domain randomization or heavy augmentation in MBRL. By using standard TD-MPC2 as a backbone and employing the Mixed Augmentation (MA) strategy, ViGMO matches the learning curves of non-robust MBRL baselines on clean tasks. This addresses a key pain point in applying robust RL to real-world scenarios where data is expensive.\n2. Effective Decomposition of the Problem: The separation of concerns between Encoder Regularization (ER) and Latent-Consistency (LC) is well-motivated for MBRL. The authors correctly identify that in MBRL, it is insufficient for just the observations to be encoded invariantly; the transition dynamics must also be robust to perturbations to prevent compounding errors during multi-step planning. The ablation studies (Table 2) clearly vindicate this design, showing that removing LC leads to catastrophic failure in severe shift scenarios (Robosuite), while ER is necessary for stability.\n3. Insightful Analysis of Latent Space: Figure 6 and Appendix D.5 provide compelling qualitative evidence that ViGMO successfully maintains a compact, aligned latent manifold under perturbation, whereas baselines like Dr. G and TD-MPC2 show significant latent state divergence when exposed to distractions."}, "weaknesses": {"value": "1. Incremental Technical Novelty: While the combination and application to MBRL are effective, the individual components are largely adaptations of existing techniques. The MA strategy resembles techniques used in semi-supervised learning or robust MFRL (like SVEA), and ER is explicitly identified as an adaptation of SODA. The primary novelty lies in the LC loss specifically targeting the dynamics model $(d_\\theta)$ using mixed augmentations.\n2. Dependency on Specific Augmentations: The framework relies heavily on the choice of \"random-overlay\" as the strong augmentation. While the ablation in Figure 15 shows it outperforms \"random-conv\" for these specific benchmarks, this might be an artifact of the benchmarks themselves (which often involve background replacements). The paper might overclaim \"general\" robustness when it is specifically highly robust to overlay-style distractions.\n3. Lack of Computational Overhead Analysis: The paper claims MA avoids computational overhead by splitting the batch13. While it avoids doubling the batch size, computing strong augmentations (especially overlays requiring external datasets) likely incurs a wall-clock time penalty compared to simple weak augmentations. A wall-clock time comparison is missing to fully substantiate the \"efficiency\" claim beyond just sample counts."}, "questions": {"value": "1. Does ViGMO generalize to spectrally different shifts (e.g., sensor noise, realistic lighting physics) not well-modeled by the random-overlay training augmentation?\n2. Why are dynamic augmentations superior over short horizons ($H=3$) when real-world distractions often exhibit temporal consistency?\n3. Does the effectiveness of Latent-Consistency (LC) learning degrade at longer planning horizons ($H>3$) where MBRL typically suffers from compounding errors?\n4. What is the actual wall-clock training time penalty of ViGMO compared to TD-MPC2, accounting for complex augmentations and auxiliary losses?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "7qC3snricD", "forum": "CoxruEzsd2", "replyto": "CoxruEzsd2", "signatures": ["ICLR.cc/2026/Conference/Submission23661/Reviewer_kVE1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23661/Reviewer_kVE1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23661/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979000384, "cdate": 1761979000384, "tmdate": 1762942751855, "mdate": 1762942751855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ViGMO (Visual Generalization in Model-based Reinforcement Learning), a novel framework designed to achieve zero-shot visual generalization in model-based reinforcement learning (MBRL). While conventional MBRL methods are highly sample-efficient, they often fail when facing unseen visual distractions such as background, lighting, or viewpoint changes. ViGMO addresses this limitation by incorporating three key components into the latent-space world model: a mixed weak-to-strong augmentation (MA) strategy that balances efficient learning with robustness, a latent-consistency learning (LC) module that enforces consistent latent transitions across augmented views to stabilize predictions under distribution shifts, and an encoder regularization (ER) term that preserves task-relevant features and prevents representational collapse. These components can be easily integrated into existing MBRL backbones such as TD-MPC2 without changing the planner or optimization procedure. \n\nExperiments on the DeepMind Control Suite and Robosuite show that ViGMO significantly improves robustness under unseen distractions, achieving up to 13% higher zero-shot generalization than the strongest baseline while maintaining similar sample efficiency. Ablation studies further verify that both LC and ER are essential for stable latent dynamics and representation robustness, and visual analyses demonstrate that ViGMO maintains well-aligned latent manifolds under perturbations, unlike competing methods. Overall, ViGMO provides a simple yet effective solution for enabling model-based agents to generalize to unseen visual conditions without fine-tuning, achieving a strong balance between robustness and efficiency in visual RL."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "On both the DeepMind Control Suite and Robosuite, ViGMO achieves state-of-the-art zero-shot generalization while maintaining similar sample efficiency to TD-MPC2. As reported in Table 1, ViGMO improves mean returns by up to 13% over the strongest baseline and remains stable across three difficulty levels (easy, hard, and extreme). These results demonstrate that ViGMO effectively balances robustness and efficiency. \n\nThe paper includes detailed ablations on the contribution of each component (Table 2) and design choice (Figure 5), clearly showing that both LC and ER are crucial for performance. The analysis in Section 4.4 and Figure 6 further provides visual evidence that ViGMO preserves latent-space consistency under distribution shifts."}, "weaknesses": {"value": "While the paper reports up to 13% improvement in zero-shot generalization (Table 1), the absolute gains over strong baselines such as TD-MPC2 and SVEA are modest on some simpler DMC tasks. The per-task results (Appendix D.1) suggest that ViGMO’s advantage is most evident under extreme visual distractions, but less consistent in easier settings.\n\nViGMO introduces additional training costs through dual augmentations (weak and strong) and two auxiliary losses (LC and ER). However, the paper does not provide quantitative comparisons of training time or GPU usage relative to the TD-MPC2 baseline. Without such data, it is difficult to assess the efficiency–robustness trade-off in practical use.\n\nThe experiments are mainly conducted on a few tasks from the DeepMind Control Suite and Robosuite (Figure 3). Although these benchmarks include some distractions such as background color, object color, and video overlays, they do not fully represent more complex or real-world domain shifts. The method’s ability to generalize to unseen dynamics changes, camera viewpoints, or object appearances remains unclear."}, "questions": {"value": "The experiments mainly consider visual distractions (e.g., color and texture changes). Have you tested ViGMO under non-visual domain shifts, such as changes in dynamics or camera viewpoint? How well would the method generalize in those cases?\n\nWhy did you choose random-overlay and random-shift specifically as the strong and weak augmentations? Did you compare with other candidates like color jitter, random convolution, or domain randomization (e.g., from Figure 5)? How sensitive is ViGMO to these augmentation choices?\n\nThe experiments are performed entirely in simulation. Do you anticipate any challenges when applying ViGMO to real-robot settings where visual distractions and dynamics changes occur simultaneously?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "I0epV68PiF", "forum": "CoxruEzsd2", "replyto": "CoxruEzsd2", "signatures": ["ICLR.cc/2026/Conference/Submission23661/Reviewer_2G6K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23661/Reviewer_2G6K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23661/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096848974, "cdate": 1762096848974, "tmdate": 1762942751412, "mdate": 1762942751412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}