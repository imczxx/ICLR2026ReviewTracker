{"id": "WnH6NQ9x7h", "number": 9136, "cdate": 1758112509447, "mdate": 1759897741522, "content": {"title": "Score-based generative modeling through anisotropic SPDEs", "abstract": "Score-based generative modeling (SBGM) has achieved state-of-the-art performance in image generation, with the quality of generated images highly dependent on the design of the forward (diffusion) process. Among these, models based on stochastic differential equations have proven particularly effective.\n \nWhile traditional methods aim to progressively destroy all image information to enable reconstruction from pure noise, we introduce a novel class of anisotropic stochastic partial differential equations (SPDEs) that preserve the geometric structure of the data throughout the transformation. These SPDEs consist of a drift term that enforces deterministic destruction via structured smoothing, and a diffusion coefficient that enables random destruction through noise injection. Both components are governed by anisotropy coefficients, enabling controlled, direction-dependent information degradation. \n\nThis framework provides the theoretical foundation for a novel anisotropic SBGM. Due to geometry-aware degradation, the data generation process can exploit residual geometric cues, leading to improved fidelity in image reconstruction. We empirically validate this improvement in a proof-of-concept implementation on unconditional image generation, showing that anisotropic diffusion can achieve superior image quality metrics.", "tldr": "Score-based generative image modeling with geometric-aware transformations described by anisotropic stochastic partial differential equations", "keywords": ["generative modeling", "score-based generative modeling", "stochastic differential equations", "stochastic partial differential equations", "sde", "spde", "image generation", "generative image modeling", "score-based generative image modeling", "numerical simulation", "numerical spde"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4c70070a3a789afee661c0e87ac3a9bd87f5ece8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an anisotropic nonlinear diffusion process. The authors claim to allow both the drift and diffusion coefficients to evolve dynamically based on the current state. However, their implementation in this paper appears to focus solely on the drift term. While stochastic differential equations (SDEs) with state-dependent drift and diffusion coefficients are well-established in theory, in my view, incorporating such dynamics into a generative diffusion model requires a rigorous framework to demonstrate that the backward diffusion process can recover the initial prior distribution. However, I could not find a clear explanation  of such framework presented in this paper. It needs a major revision."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "This paper proposes an anisotropic nonlinear diffusion process."}, "weaknesses": {"value": "This paper is poorly written. It does not flow well. It lacks clarity and coherence, making it difficult to follow.  I listed below some examples of specific problems:\n1. The authors used non-standard  statistical terms such as \"$\\mu$-distributed sequence\" \n2. P3. Line 128, That authors stated that, during the forward process, \"the dynamics\nof the transformation realized by the forward process are learned (by a neural network)\". This seems like a wrong statement.\n3. Lack proper reference:  anisotropic nonlinear diffusion process has been investigate intensively in multiscale image analysis, however, this paper did not discuss the relevant of this topic in their introduction. Here are some references:\n 1).  P Perona and J Malik, Scale-space and edge detection using anisotropic diffusion.\n 2).  P. Guidotti  Anisotropic Diffusions of Image Processing From Perona-Malik\n 3). Y Bao; H. Krim Smart nonlinear diffusion: a probabilistic approach\n:4). W Feng, P Qiao, X Xi, and Y Chen,  Image Denoising via Multiscale Nonlinear Diffusion Models\n 5). Y You , W Xu, A Tannenbaum, M Kaveh, Behavioral analysis of anisotropic diffusion in image processing\n\n4. Repeating: \nfor example P7, Line 361: We now begin by describing specific instances of our framework\n                    P7, Line 363: We now describe the specific instances of our framework considered\n5, The selection of drift and diffusion coefficients in Eqns (7)-(9): The definition of sigma in eqn. (8) was not used in the new algorithm in section 5.2 and 5.3. More importantly, there is no proof on why the selection of the coefficients will lead to preserving structures in images."}, "questions": {"value": "1. Is there a timeline problem in the following statement:\nP2. Lin 90: The authors stated that:\nRissanen et al. (2023) considered a stochastic heat equation with isotropic noise, which is effectively destroying the data by blurring up to complete dissipation. This is in contrast to earlier approaches that typically destroyeddata into pure noise. Hoogeboom & Salimans (2022) extended this idea by introducing a temporally increasing isotropic noise term, further refining the blurring process over time.\n\n2. Eqns. (4) (5) is not used anywhere, any discussion on this and how it is used in the proposed algorithm?\n\n3.There is a $v$ in Eqn. (8), but there is no $v$ given in Eqn. (6)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "jYYgTtmhrD", "forum": "WnH6NQ9x7h", "replyto": "WnH6NQ9x7h", "signatures": ["ICLR.cc/2026/Conference/Submission9136/Reviewer_PX5s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9136/Reviewer_PX5s"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761623481521, "cdate": 1761623481521, "tmdate": 1762920827010, "mdate": 1762920827010, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method that employs an anisotropic destruction process, rather than the isotropic noising common in existing diffusion models. Through small-scale experiments, the paper demonstrates performance that is superior or comparable to existing diffusion model families, such as score-based models and flow-matching models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper challenges the convention in the diffusion model literature that we should use an isotropic diffusion process, and it demonstrates the potential of anisotropic SPDEs through comparisons with existing models.\n\n- It clearly explains the conceptual similarities and differences compared to prior work."}, "weaknesses": {"value": "- Standard Gaussian noise-based diffusion models already benefit from schedules that rapidly destroy the image, such as the cosine noise schedule in IDDPM or timestep shifting in Stable Diffusion 3, improving both training and inference.\nIt is questionable whether the proposed method's superior performance could be achieved in existing score-based or flow-matching models simply by applying more advanced noise schedules.\n\n- The \"blurring diffusion models\" (Hoogeboom & Salimans), which are only briefly mentioned in the related works, are conceptually very similar as they also use both noise and a blurring drift. A more detailed conceptual and experimental comparison against them is necessary."}, "questions": {"value": "While qualitative comparisons are provided in the appendix, they are limited to CIFAR-10. Can you show qualitative results for ImageNet and LSUN?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "R1o9U41Ys2", "forum": "WnH6NQ9x7h", "replyto": "WnH6NQ9x7h", "signatures": ["ICLR.cc/2026/Conference/Submission9136/Reviewer_2Hsy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9136/Reviewer_2Hsy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761633553823, "cdate": 1761633553823, "tmdate": 1762920826661, "mdate": 1762920826661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework for Score-Based Generative Modeling that\nuses anisotropic Stochastic Partial Differential Equations to govern the\ndiffusion process. The main goal is to enhance image generation quality by preserving the\ngeometric structure of data during the forward (destruction) process, a departure from\ntraditional methods that aim to destroy all image information to pure noise. Their forward\nprocess is modeled as the formal solution to SPDE, where it has two components, namely\ndrift term which enforces deterministic destruction through structural smoothing, and\ndiffusion term which enables random destruction through noise injection."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1). This paper introduces a novel framework that keeps some geometrical structural clues when data destruction, helping the resemblance of geometric features in generative sampling.\n\n\n2). This paper showcases the proposed method through experiments, and it obtains superior results on both qualitative and quantitative comparisons.\n\n3). One of the main strengths is this unifies formulation of SBGM. i.e., providing a common framework for existing SBGMs and a new anisotropic diffusion process."}, "weaknesses": {"value": "1). I feel even though this paper has the mathematical rigor, it lacks the intuitive and logical building of the proposed method. I suggest authors to add more intuitive explanation that will enable readers to understand the paper much better. Otherwise, the current version is\nbit hard to follow and grasp the concepts. If possible, try to add a figure that explaining the concept.\n\n\n2). The experimental section only compares against methods up to 2023. For completeness, I suggest including comparisons or discussions of more recent works such as “Edge-Preserving Noise for Diffusion Models” (2024), which shares a similar motivation of geometry-aware corruption.\n\n3). The proposed method requires almost 2000 score evolutions. This I feel a major limitation compared to recent works.\n\n4). The authors mainly used \\( \\ell = 0 \\) for the noise process. I would like to know whether introducing a finite \\( \\ell > 0 \\) — i.e., spatially correlated noise could help capture textured patterns or reduce artifacts, or if it would mainly complicate the sampling\nprocess. \n\n5). In this paper, both the drift and diffusion terms depend on the local gradient. I would like to know whether it is possible to understand how sensitive the model’s performance is to this gradient dependence. For instance, if ( g_1 ) varies too sharply with ( \\nabla u ), could it lead to unstable training dynamics? I feel some empirical or theoretical insight into this behavior would be useful.\n\n\n6). The core idea centers on the argument of a “residual dependence on the initial image.” I would like to know whether the authors attempted to measure how much information about the initial image remains at t=T. Can this dependence be quantified using a specific metric or statistical measure? I believe such an analysis would provide deeper insight into the behavior and effectiveness of the proposed method."}, "questions": {"value": "see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rc3BOQaxV8", "forum": "WnH6NQ9x7h", "replyto": "WnH6NQ9x7h", "signatures": ["ICLR.cc/2026/Conference/Submission9136/Reviewer_eGcS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9136/Reviewer_eGcS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963287640, "cdate": 1761963287640, "tmdate": 1762920826288, "mdate": 1762920826288, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an extension of score-based generative models (SBGMs) by formulating the forward diffusion process using anisotropic Stochastic Partial Differential Equations (SPDEs) instead of the more common Stochastic Differential Equations (SDEs). The authors argue that traditional SDE-based methods, which are typically isotropic, destroy all information uniformly, including valuable geometric structures.\n\nThe core contribution is the introduction of nonlinear, spatially-dependent SPDEs where the drift and diffusion coefficients are influenced by anisotropy coefficients. The goal with this formulation is to more generally preserve spatially relevant information such as edges during the forward process, so that the reverse process can in turn leverage these geometric cues to sample images with higher fidelity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I believe the paper's formulation is novel and interesting. Some strengths are:  \n\n**(S1)**: Novel theoretical contribution. A general framework for spatially-dependent diffusion processes is quite valuable as it can capture more complex dynamics in structured data like images. I particularly like how many different forms of data corruption in the forward process are subsumed under the same framework. I would like to see this extended further across modalities.\n\n**(S2)**: Experimental validation on pre-trained model. The authors demonstrate that their training on top of an existing diffusion model yields improvements in standard image generation quality metrics such as FID and inception score.  \n\n**(S3)**: Clear presentation for the theoretical section. I appreciate the care with which the authors explained the differences in diffusion frameworks and then unified it under one umbrella. This set up the motivation and intuition for the core method well-- preserving geometric structures via anisotropy will aid in reconstruction.  \n\nOverall, I think the idea is interesting and deserves further exploration."}, "weaknesses": {"value": "**(W1)**: Lack of thorough experimental validation. This is my main concern with the paper. There are a number of baselines and prior relevant work that have not been included in the experimental results (eg: Table 1). This makes it hard to judge the efficacy of the method. E.g. [1] achieved an FID of 1.97 on CIFAR-10. [2] tackles a similar problem as this paper, but results have not been compared. \n\n**(W2)**: Computational cost. The forward and backward process requires the computation of spatial gradients (eq 7, 8) via finite differences, for every time step. This would arguably make training and inference much slower. A comparison between the quality / performance tradeoff with prior work and baselines is critical and is missing.\n\n**(W3)**: Extension to latent diffusion models. While the theoretical framework should apply equally to standard and latent diffusion models, I would be curious to see empirical results on latent diffusion models, which have become the standard today. Do the findings still hold? This is important for broader relevance and applicability. \n\n**(W4)**: While the authors do discuss the anisotropy, diffusivity and intensity coefficients in Appendix A, experimental validation for different choices of hyperparameters is missing. There are multiple new hyperparameters introduced in this paper and a detailed ablation would be quite important.\n\nThe weaknesses slightly outweigh the strengths for me. I would encourage the authors to present more extensive empirical results to support their claims.\n\n---  \nReferences:  \n[1] Elucidating the Design Space of Diffusion-Based Generative Models, NeurIPS 2022.  \n[2] Edge-preserving noise for diffusion models, arXiv 2410.01540."}, "questions": {"value": "**(Q1)**: L456. \"Notably, according to the original authors, continuing training with their own method did not yield further metric improvements.\"  \nWas this verified via experimental results on your side?\n\n**(Q2)**: Table 1. Why is the Ours (Isotropic) version so much worse on FID than the anisotropic version? What are the results on the remaining datasets? \n\n**(Q3)**: Are there any results on the fully anisotropic variant? Where both the diffusion and drift terms are anisotropic. \n\n**(Q4)**: The fine-tuning experiment (Figure 2)  is interesting. Does this imply that the primary benefit is in the sampling path (i.e., the backward SDE derived from the anisotropic SPDE is simply a better path from noise to data), or is the score model itself being fundamentally retrained to leverage geometric information that it was previously ignoring?\n\n**(Q5)**: The exposition on different diffusion methods was clear and well-written. Section 4.1 was a bit opaque to me. It was a bit difficult for me to get an intuitive sense of the terms in eqs. 7, 8, 9. Some additional explanation would be valuable for this section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NjybXLH4BT", "forum": "WnH6NQ9x7h", "replyto": "WnH6NQ9x7h", "signatures": ["ICLR.cc/2026/Conference/Submission9136/Reviewer_HKrC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9136/Reviewer_HKrC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150378460, "cdate": 1762150378460, "tmdate": 1762920825655, "mdate": 1762920825655, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}