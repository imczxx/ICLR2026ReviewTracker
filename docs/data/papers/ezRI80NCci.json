{"id": "ezRI80NCci", "number": 17356, "cdate": 1758274981344, "mdate": 1759897180265, "content": {"title": "Towards Seed-Invariant Safety Alignment in Text-to-Image Models", "abstract": "Text-to-image diffusion models have achieved remarkable success in generating high-quality images, yet existing safety mechanisms exhibit critical cross-seed instability where defense performance varies significantly under different random seed conditions. This instability stems from the fact that a single malicious prompt generates diverse harmful variants across different noise initializations, forming complex distributional clusters that current methods cannot adequately address. We investigate extending Noise Contrastive Alignment (NCA) to diffusion models due to its native capability of handling multiple negative samples through probabilistic weighting, but our theoretical analysis reveals two fundamental flaws in direct extension: gradient reversal caused by positive regularization terms that paradoxically penalize safe content generation, and uniform suppression of harmful samples that ignores severity variations. To tackle these issues, we propose Noise Contrastive Diffusion (NCD), which incorporates targeted algorithmic modifications including elimination of problematic regularization and introduction of pairwise regularization mechanisms that establish individualized preference relationships between safe and harmful variants. Extensive experiments further demonstrate that NCD achieves superior cross-seed stability, reducing attack success rates (ASRs) from 11.1% to 6.2% compared to SOTA methods while maintaining exceptional generation quality, exhibiting robust resistance against sophisticated jailbreak prompts and strong generalizability across different T2I architectures. WARNING: This paper may contain examples of harmful texts and images.", "tldr": "", "keywords": ["Text-to-Image Safety", "Seed-Invariant Defense", "Diffusion Models", "Noise Contrastive Alignment", "Harmful Content Mitigation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/73d52680678d9c7a0292dd3dbeb070957b232c02.pdf", "supplementary_material": "/attachment/74121c9ee4af5feff2689498670bcd8c55a5e3ba.pdf"}, "replies": [{"content": {"summary": {"value": "This paper focuses on a critical yet overlooked issue in text-to-image (T2I) diffusion models: cross-seed safety alignment instability. Specifically, the same malicious prompt may generate diverse harmful image variants under different random seeds, while existing safety mechanisms (e.g., filters, concept erasure, model editing) exhibit significant variations in defense effectiveness against these variants, creating vulnerabilities in real-world deployment.\n\nThe authors first attempt to extend the recently proposed Noise Contrastive Alignment (NCA) framework to diffusion models to simultaneously handle multiple harmful samples generated from different seeds. However, theoretical analysis reveals two fundamental flaws in direct extension: First, the gradient reversal problem—the positive sample regularization term in NCA paradoxically penalizes safe content generation as safety alignment progresses. Second, uniform suppression of harmful samples—ignoring severity variations among different harmful samples prevents the model from developing fine-grained discriminative capabilities.\n\nTo address these issues, the authors propose Noise Contrastive Diffusion (NCD), which incorporates two core improvements: removing the regularization term causing gradient reversal, and introducing a pairwise regularization mechanism that establishes individualized preference relationships between safe samples and each harmful variant.\n\nExperiments demonstrate that NCD significantly outperforms existing SOTA methods across multiple benchmarks (I2P-Sexual, NSFW-56K, Sneaky-Prompt, MMA-Diffusion), reducing SSR-10 (the success rate of generating at least one harmful image across 10 seeds) from 11.1% to 6.2%, while maintaining or even surpassing baseline generation quality on COCO-30K (CLIP Score 26.39, FID 19.85). NCD also exhibits strong generalizability on both SD-v2.1 and SDXL."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is the first to systematically identify and formalize the problem of \"seed-invariant safety alignment,\" revealing the vulnerability of existing methods in this dimension. While NCA has been used in language models, the authors not only identify its theoretical flaws in diffusion models (gradient reversal, uniform suppression) but also propose targeted algorithmic corrections (removing regularization terms + pairwise preferences), representing a creative adaptation and improvement of existing ideas to solve new problems. The problem definition itself is novel and crucial for practical deployment safety.\n\n2. The theoretical analysis is rigorous (e.g., gradient derivation in Theorem 3.1), and the experimental design is comprehensive: it covers various types of safety mechanisms (filtering, concept erasure, editing, alignment); uses multiple authoritative harmful prompt benchmarks, including adversarial jailbreak datasets; introduces SSR-N (Seed Success Rate), an evaluation metric closer to real-world risks; validates generalizability and robustness across models (SD-v1.5/v2.1/XL) and seed counts (N=3–50); provides ablation studies to verify the contribution of each component; and constructs the NCD-10K dataset, which includes safe/harmful image pairs and multi-seed variants with a reasonable pipeline (using GPT-4 for safe rewriting + image inpainting).\n\n3. As T2I models are widely deployed, their safety robustness is critical. The \"cross-seed instability\" revealed in this paper is a significant blind spot in existing safety solutions, and NCD provides an effective and practical resolution."}, "weaknesses": {"value": "The coverage of the NCD-10K dataset is limited: although it includes seven categories of harmful content, sexual content accounts for two-thirds (page 13), and the dataset is filtered based on DiffusionDB and GPT-4. This may lead to an overestimation of the model's generalization capability on other categories (e.g., hate, illegal). Table 4 shows that NCD achieves limited improvement in categories such as \"Self-harm\" and \"Hate\" (e.g., Self-harm improved from 39.95% → 17.2%), but the reasons are not thoroughly analyzed. It is recommended to include specialized evaluations for long-tail harmful categories."}, "questions": {"value": "Can you provide dynamic curves showing the safe sample reward Rθ(x^w_t) and its corresponding gradient direction throughout the training process? This evidence would directly demonstrate the practical impact described in Theorem 3.1.\n\nWhile NCD eliminates the uniform negative sample regularization term from NCA, does the pairwise loss (Eq. 11) inherently treat all harmful samples equally? For potentially more dangerous harmful samples, could a severity-based weighted pairwise loss be incorporated?\n\nFigure 2 indicates that NCD still maintains a 36.1% failure rate on MMA-Diffusion under SSR-50 conditions. Does a theoretical upper limit exist for this performance? Could further improvements be achieved by increasing the number of training seeds or implementing adversarial seed sampling?\n\nHave comparisons with multi-response extensions of DPO (such as IPO and SimPO) been considered? These methods might also help address seed instability but weren't included in the experimental comparisons.\n\nWhile the paper mentions plans for open-source release with strict review protocols, would there be commitment to publishing a safe subset of NCD-10K that excludes genuinely harmful images to facilitate community research?"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns"]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Trf2kEWvfI", "forum": "ezRI80NCci", "replyto": "ezRI80NCci", "signatures": ["ICLR.cc/2026/Conference/Submission17356/Reviewer_cxrR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17356/Reviewer_cxrR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761640515666, "cdate": 1761640515666, "tmdate": 1762927272228, "mdate": 1762927272228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors observed an interesting phenomenon that erased models can generate harmful images under different random seeds for harmful inputs. Then they introduce Noise Contrastive Alignment and analyze its drawbacks mathmatically, and further propose Noise Contrastive Diffusion to address these problems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, easy for readers to follow.\n2. The paper introduce an interesting phenomenon.\n3. The paper propose some incremental optimizations on the DPO and NCA algorthm."}, "weaknesses": {"value": "1. Relationship between the phenomenon and the proposed method. I acknowledge that the cross-seed instability phenomenon has not been intruduced in previous studies, but I think the authors did not provide a targeted explanation. They only said that \"current approaches fail to establish *robust* safety alignment\" but it has also been mentioned many times in previous studies. In fact, in the training, we usually do not set random seed in each training iteration. Therefore, the seed is changing also in the training. In other words, I want to know what is the difference between the reason for this observation and for the robustness issue?\n\n2. Introduction of pair-wise dataset. NCA is proposed to address  the limitation of DPO methods which can only handle pairwise preference data but this paper propose NCD to introduce pairwise data again. It increase the difficulty of implementing this method, as evidenced in Appendix A.2. And the authors themselves also said that \" our NCD-10K dataset may not capture all emerging harmful patterns\".\n\n3. The baselines are old. Please compare your methods with more recent methods, especially adversarial methods such as Receler and AdvUnlearn."}, "questions": {"value": "See weaknesses. If my concerns can be address, I will change my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lCnRT3h3Ov", "forum": "ezRI80NCci", "replyto": "ezRI80NCci", "signatures": ["ICLR.cc/2026/Conference/Submission17356/Reviewer_dHZV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17356/Reviewer_dHZV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903357285, "cdate": 1761903357285, "tmdate": 1762927271863, "mdate": 1762927271863, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is the first to discuss the problem of insufficient robustness in current T2I safety mechanisms when facing the influence of random seeds, and it attempts to solve this using preference alignment. Compared to naive DPO, this method proposes the Noise Contrastive Diffusion (NCD) Framework, to achieve a) eliminating the problematic regularization term to prevent gradient reversal and b) introducing a pairwise regularization mechanism to establish individualized preference relationships between the safe sample and each harmful variant."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a practical problem: cross-seed instability in T2I safety alignment.\n2. The method is well-motivated, with a theoretical analysis (Theorem 3.1) of the flaws in a direct NCA extension (i.e., gradient reversal).\n3. The proposed Seed Success Rate (SSR-N) metric is a reasonable and valuable tool for evaluating this specific problem.\n4. The experimental results are comprehensive and demonstrate state-of-the-art performance across multiple models."}, "weaknesses": {"value": "1. Although the authors propose a seemingly practical task setting, the argument that \"existing safety alignment methods are vulnerable when generating with different seeds\" is not well-supported: a) The authors only provide a few generated examples and lack an analysis of _why_ existing methods are vulnerable in this scenario. b) Is this problem equivalent to the problem of \"insufficient safety in existing alignment methods\"? In fact, the authors only show a few early concept erasure methods and overlook the discussion of methods with stronger safety capabilities[1,2,3,4]. With more powerful methods, the risk bring by seed may be small.\n2. The practical novelty of NCD is questionable. The final forms of Eq10 and Eq11 appear to be a variation of (1, N) Direct Preference Optimization (DPO). This paper fails to clearly differentiate its contribution from this baseline.\n3. Considering Weakness 1, the authors have actually overlooked a baseline directly related to the task (DUO[5]). This work also improves DPO techniques for T2I safety alignment tasks.\n4. The experimental evaluation has some confusing points. First, in Figure 3, the training data shown includes NSFW concepts other than sexual content (e.g., drug, bloody, etc.). The test datasets used are also multi-concept NSFW datasets. All indications suggest the authors are trying to demonstrate that the proposed method is compatible with aligning various types of NSFW concepts. However, when conducting quantitative evaluation and visualization, they only consider the sexual concept (evaluated by NudeNet).\n5. Following up on Weakness 4, the authors should consider adding evaluations for other NSFW concepts. Additionally, there should be some discussion on the method's compatibility with important tasks like celebrity and style.\n6. Newer models such as SD3.5 and FLUX should also be included in the discussion.\n\n[1] Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models, nips24\n[2] Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, cvpr25\n[3]  TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models, iccv25\n[4] Safetydpo: Scalable safety alignment for text-to-image generation, iccv25\n[5] Direct Unlearning Optimization for Robust and Safe Text-to-Image Models, nips24"}, "questions": {"value": "Please address the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "tajn6QqiA7", "forum": "ezRI80NCci", "replyto": "ezRI80NCci", "signatures": ["ICLR.cc/2026/Conference/Submission17356/Reviewer_AdHF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17356/Reviewer_AdHF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914219558, "cdate": 1761914219558, "tmdate": 1762927271510, "mdate": 1762927271510, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the safety challenges faced by text-to-image diffusion models due to cross-seed instability, where malicious prompts generate diverse harmful variants.  It reveals flaws in extending Noise Contrastive Alignment (NCA) to diffusion models, including gradient reversal from positive regularisation and uniform suppression of harmful samples. Therefore, a method called Noise Contrastive Diffusion (NCD) is proposed to address issues by eliminating problematic regularisation and introducing pairwise regularisation mechanisms."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This work aims to bridge the gap in applying the NCA method, which was originally designed for language models, to diffusion models. By analysing the back-propagation in NCA, they identify a \"Gradient Reversal\" issue in the original framework and propose a modified version for diffusion models to avoid such an issue. Furthermore, a \"Uniform Treatment\" issue is also investigated, which is then addressed by a pairwise regularisation."}, "weaknesses": {"value": "1. Firstly, the proposed methods cannot guarantee the invariance of the models or explicitly optimise them for invariance. The primary challenges this work aims to address are the cross-seed instability of existing safety mechanisms. However, the proposed method did not explicitly focus on the instability or invariance. Instead, it merely included more negative samples by extending the NCA method, which appears to be a \"brute-force\" approach. Furthermore, the core idea of NCA is to optimise the absolute likelihood for each response rather than adjusting the relative likelihood across different responses, which does not inherently provide a guarantee of invariance. The paper conducts a theoretical analysis of back-propagation in NCA, but it focuses on the gradient direction and does not explicitly address the crucial question: how to guarantee stability and invariance.\n\n2. Secondly, the experiment results further demonstrate that the proposed method did not effectively address the instability issue. As shown in Fig. 2, the paper proposed a novel SSR-N metric. While the proposed method consistently achieves lower ASR compared to previous methods, the trend of ASR exhibits a clearly increasing pattern as the number \"N\" increases, similar to previous methods. There is no clear suppression of this increasing trend or a plateau. This highlights the drawback of simply increasing the number of negative samples, as the number of malicious attempts increases, the defence becomes weakened.\n\n3. Ideally, the derivation of Theorem 3.1 should be provided. Although this derivation is relatively straightforward, providing a detailed process would facilitate readers in verifying its correctness."}, "questions": {"value": "Please address the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kZ8OONOKkR", "forum": "ezRI80NCci", "replyto": "ezRI80NCci", "signatures": ["ICLR.cc/2026/Conference/Submission17356/Reviewer_DEWM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17356/Reviewer_DEWM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762184439057, "cdate": 1762184439057, "tmdate": 1762927271074, "mdate": 1762927271074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}