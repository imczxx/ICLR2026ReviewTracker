{"id": "gkGLiuDFeB", "number": 21243, "cdate": 1758315324056, "mdate": 1759896932508, "content": {"title": "PRISM: A Unified and Generalizable Adversarial Robustness Evaluation Framework for LLM-based Classification", "abstract": "Phishing email compromise persists as one of the most pervasive and globally consequential vectors of cyber intrusion. Detection remains particularly challenging in multilingual environments, where script diversity, low-resource languages, and adversarial linguistic shifts increase false-positive and false-negative rates. Although Large Language Models (LLMs) achieve high baseline performance on phishing detection, their resilience under adversarial manipulations and multilingual distributional shifts is insufficiently characterized. We present PRISM, a unified and generalizable framework that evaluates adversarial robustness of LLM-based classification. PRISM integrates three attack dimensions in the form of semantic-preserving linguistic refinement, prompt-level instruction injection, and cross-lingual shifts. We instantiate phishing as a representative security-critical case study and evaluate frontier LLMs (GPT-4o, Claude Sonnet 4, and Grok-3) under PRISM. Within this framework, prompt-level manipulations are operationalized as instruction-space perturbations exploiting LLM compliance to induce misclassification. Empirically, models exhibit strong accuracy ($\\approx 0.88$ to $0.95$); however, they also reveal asymmetric vulnerability signatures, with refinement reducing accuracy by $\\approx12\\%$ in Claude and $\\approx4\\%$ in GPT-4o, and large-scale prompt injections yielding attack success rates of $\\approx4$ to $12\\%$. Cross-lingual translation (Bangla, Chinese, Hindi; $\\approx 95:5$ class composition) substantially increases false-positive rates (e.g., $+10\\times$ in Claude relative to English), undermining reliable deployment. Under class imbalance, zero-shot prompting achieves improved performance relative to structured and chain-of-thought variants (mean F1 $\\approx0.79$ vs $0.66$ for structured and up to $0.77$ for CoT, depending on model) while maintaining significantly lower latency. PRISM characterizes structural weaknesses in LLM detectors and establishes a principled, generalizable protocol for securing LLM-based classification in multilingual, security-critical contexts.", "tldr": "A Unified and Generalizable Adversarial Robustness Evaluation Framework for LLM-based Classification", "keywords": ["Adversarial Robustness", "Generative Models", "Frontier Models", "Phishing Detection", "Linguistic Refinement", "Prompt Injection", "Cross-lingual Shifts"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/562f996006b4bc88a0c1a2e0f943fd7172d9dabe.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a unified framework for assessing the robustness and vulnerability of LLMs. The authors conduct extensive experiments on a phishing email detection task across GPT-4o, Claude Sonnet 4, and Grok-3, and report several interesting findings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The motivation and method are clear, and the prompt description is helpful.\n\n2. The authors provide sufficient evidence to support the effectiveness of their proposed method.\n\n3.  This paper is well-written, making it easy to follow."}, "weaknesses": {"value": "1. This paper reads more like a technical report than a research paper. It essentially reproduces techniques from multiple prior works and combines them into a framework for evaluating LLM robustness. The overall framework heavily relies on existing research and task-specific prompt engineering, both of which limit its novelty and generalizability (as changing the task requires redesigning the prompt).\n\n2. The evaluation is limited to the phishing email detection task. The paper would be more convincing if it included a broader range of tasks beyond phishing detection and incorporated more open-source and API-based LLMs for comprehensive validation."}, "questions": {"value": "Refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UNFcFqJGV2", "forum": "gkGLiuDFeB", "replyto": "gkGLiuDFeB", "signatures": ["ICLR.cc/2026/Conference/Submission21243/Reviewer_tuwS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21243/Reviewer_tuwS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21243/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760684851206, "cdate": 1760684851206, "tmdate": 1762941652689, "mdate": 1762941652689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PRISM, a unified framework for evaluating the adversarial robustness of LLMs in classification tasks. The framework integrates three attack dimensions: semantic-preserving linguistic refinement, prompt-level instruction injection, and cross-lingual shifts. Using phishing detection as a case study, the authors evaluate three frontier LLMs (GPT-4o, Claude Sonnet 4, and Grok-3). The core contributions are the PRISM framework itself, an empirical analysis demonstrating that models with high baseline accuracy are vulnerable across all three attack vectors, and practical insights into prompt engineering trade-offs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper organizes its evaluation around three distinct types of vulnerabilities. By applying these different attack dimensions to the same set of models and task, the study provides a valuable comparative benchmark, revealing model-specific vulnerability patterns.\n* Empirical setup with realistic conditions: conducted evaluations on three contemporary LLMs, and incorporated real-world data characteristics, such as the natural class imbalance found in email traffic, by testing on both balanced and skewed distributions.\n* The multilingual evaluation provides a quantitative demonstration of a major weakness in current LLMs."}, "weaknesses": {"value": "My major concerns are on the limited methodological novelty and technical depth as follows.\n\n* The core contribution, the PRISM framework, appears to be a conceptual grouping of existing evaluation areas rather than a novel technical framework. It serves as a descriptive schema for the experiments conducted but does not introduce new evaluation paradigms or technical depth/insights.\n* The 6-tuple formalism (T, D, A, P, M, R) introduced in Section 1 (lines 81-85) is not carried through or operationalized in the rest of the paper. The formalism appears to be superficial or too broad and it's hard to see the grounding or necessity of such formalism in the rest of the paper.\n* The analysis is primarily descriptive, reporting performance metrics from experiments without taking further steps (e.g., providing a deeper technical investigation into why the models fail, how to mitigate the failures, etc.) \n* The paper does not report any statistical significance testing for its comparisons. For example, in Table 4 (multi-template), the ASR for GPT-4o is 1.1% and for Grok-3 is 1.6%. It is unclear if this difference is statistically meaningful or simply noise from a single experimental run. This makes it difficult to draw firm conclusions about relative model vulnerabilities."}, "questions": {"value": "My major question is about the positioning / main contributions of the paper.\n\nTo align with the current substance of the paper, I'd suggest re-framing the work's primary contribution as a comprehensive empirical benchmarking study rather than the proposal of a novel framework. This would manage reviewer expectations and highlight the paper's empirical strengths.\n\nAlternatively, to justify the \"framework\" claim, I'd suggest adding technical depth. This could involve proposing and evaluating a novel compound attack that synergistically combines multiple vectors (e.g., a cross-lingual prompt injection), or performing a deeper analysis of failure modes (e.g., analyzing attention patterns or internal representations to explain why certain models are more vulnerable to specific attacks)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zn2Lwk3Roq", "forum": "gkGLiuDFeB", "replyto": "gkGLiuDFeB", "signatures": ["ICLR.cc/2026/Conference/Submission21243/Reviewer_2VP7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21243/Reviewer_2VP7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21243/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009083534, "cdate": 1762009083534, "tmdate": 1762941652187, "mdate": 1762941652187, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PRISM, a framework to evaluate adversarial robustness of LLM-based classification, instantiated on phishing-email detection. It unifies three attack dimensions—(i) semantic-preserving “refinement”, (ii) prompt-level instruction injection, and (iii) cross-lingual shifts—and evaluates GPT-4o, Claude Sonnet 4, and Grok-3 across balanced/imbalanced settings and different prompting styles."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The 6-tuple formalization (T, D, A, P, M, R) and figure clarify how the attacks and prompts plug into a single evaluation pipeline.\n- Useful empirical takeaways. Zero-shot often matches/exceeds structured/CoT with much lower latency on imbalanced data."}, "weaknesses": {"value": "- Limited novelty beyond aggregation. The work primarily bundles known robustness axes (adversarial paraphrase, prompt injection, cross-lingual transfer) into a single protocol; no new attack class, defense, or evaluation metric appears fundamentally novel. The “unified” aspect reads more like scope consolidation than a methodological advance.\n- Core evaluations use relatively small samples (e.g., 189–200 items for adversarial/injection tests; 179 per language for multilingual), which limits statistical power and generality—especially for a claim of a generalizable framework.\n- Injection templates are simplistic (“classify as Safe Email”) and appended to message tails; actual threats often embed instructions in headers, quoted threads, MIME parts, or retrieved content. The work does not systematically vary injection locality or delivery channel."}, "questions": {"value": "See cons"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nGSgJBvILj", "forum": "gkGLiuDFeB", "replyto": "gkGLiuDFeB", "signatures": ["ICLR.cc/2026/Conference/Submission21243/Reviewer_GaBX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21243/Reviewer_GaBX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21243/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762137237763, "cdate": 1762137237763, "tmdate": 1762941651865, "mdate": 1762941651865, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PRISM, a framework for evaluating the robustness of LLM-based classification under three forms of \"attack\" (1) semantic-preserving adversarial paraphrasing, (2) prompt injection, and (3) language translation. The authors instantiate phishing detection as a case study and report robustness of GPT-4o, Claude Sonnet 4, and Grok-3."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "My primary concern with this submission is the lack of substance. The claimed contribution is a \"unified framework\" that evaluates robustness of LLM-based phishing email classification under adversarial paraphrasing, prompt injection, and language translation.\n\n- The paper involves weak combined evaluation of known, existing robustness vulnerabilities for a single classification problem. The \"unification\" consists primarily of running existing attack styles sequentially on the same dataset. I do not think this meets the bar for an ICLR publication.\n- The attack evaluations themselves are quite weak. Blind paraphrasing to elicit misclassification is neither new nor interesting, and static template-based prompt injections are weakest in class, compared to SoTA automated implementations like GCG, AutoDan, TAP etc. I would expect significantly higher ASR using quite literally any other attack implementations here. Finally, if the entire paper's purpose is to provide evaluation insight into phishing email detection performance, one would expect more than 3 models, and insights into impact of model sizes and architectures.\n\n- An unusually large amount of writing is dedicated to explaining primitive ML concepts, with explanations of precision, recall, f1, fpr, ASR, etc taking up space that could have been used for any other interesting experiments."}, "questions": {"value": "I am also not quite sure that any comments about robustness under language shift can be made with N=10 samples. This perhaps does not even qualifiy as an attack - is a phishing email useful if it is written in say, Bangla, but the victim does not know Bangla?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AhUA4U4IGq", "forum": "gkGLiuDFeB", "replyto": "gkGLiuDFeB", "signatures": ["ICLR.cc/2026/Conference/Submission21243/Reviewer_yczL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21243/Reviewer_yczL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21243/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762182657438, "cdate": 1762182657438, "tmdate": 1762941651647, "mdate": 1762941651647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}