{"id": "tiG9ZSr21N", "number": 8028, "cdate": 1758052913492, "mdate": 1763058951760, "content": {"title": "Saint: Spatial Guidance for Inpainting", "abstract": "We introduce Saint, a framework for image inpainting with large-scale diffusion and flow-based transformers in a latent multi-variable setup. Existing methods for latent image inpainting rely on RePaint-like sampling or mask concatenation, which either does not make use of the masked image as strong conditioning at all or neglects the fact that the denoising model has been already trained for masking via noising. In contrast, Saint fine-tunes pre-trained Diffusion Transformers (DiTs) as Spatial Reasoning Models (SRMs) with varying noise levels across masked and unmasked regions, allowing to condition the model directly via the partially noised latent. This more effective conditioning scheme improves inpainting performance on binary masks and further extends to continuous masks. Moreover, the multi-variable formulation of SRMs allows us to formulate a Spatial Classifier-Free Guidance strategy tailored for inpainting as well as a token-caching scheme for efficient local edits. We evaluate Saint on ImageNet1k and JourneyDB datasets for a variety of inpainting scenarios and show that it consistently improves on the state of the art in generative and reconstruction metrics. Our codebase and the models will be released publicly upon acceptance of the paper.", "tldr": "", "keywords": ["image inpainting", "diffusion models", "transformers"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/4298359073df2b1952ee5b678292aad62ea7e510.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Saint, a framework for highly flexible image inpainting that leverages diffusion (or flow) transformer models. The framewor supports inpainting for arbitrary mask shapes and extends this capability to continuous-valued masks. The main methodological idea is to transform the input mask into a patch-wise denoising timestep signal. The diffusion model is then specifically fine-tuned to handle these differently noised patches.\n\nFor improved performance, the authors apply spatial classifier-free guidance (CFG), and they introduce a token caching mechanism to enable faster inference. The authors conduct a thorough experimental evaluation, comparing Saint against baselines such as RePaint, LDM, TD-Paint, and Differential Diffusion on various inpainting tasks across multiple datasets. Saint demonstrates strong performance across the board, and the beneficial effects of both CFG and the proposed caching mechanism are experimentally demonstrated."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-written and is easy to follow. The experiments are quite comrehensive and demonstrate different claims of the paper."}, "weaknesses": {"value": "One weakness I can see is the lack of error bars in the metrics reported in the paper. Are these results significantly different? Besides that, I have quite a few questions that are detailed in the next section."}, "questions": {"value": "**The task definition and transformation to latent space**\n\n- In the inpainting tasks in this paper, it is assumed that both the full image $I$ and mask $M$ are given. Then the image is encoded to $X$ by the VAE encoder and the mask is bilinearly downsampled to $T$. Therefore, the task is not to inpaint $X$ given the continuous mask $T$. However, typically in inpainting tasks only the non-masked part of the image is known. How do the authors deal with those cases, since a partial image will be out of distribution for the VAE encoder?\n- A more important concern along the same lines is whether there is information leak from the non-observed parts of the image to the latent parts?\n\n**Experiments**\n\nWhile the results are quite impressive, they raise a few questions:\n\n- Why does LDM do much worse compared to Saint on binary mask inpainting tasks? As far as I understand, at inference time, with binary masks, LDM and Saint are effectively identical. They both start with the maximum noise level for all the patches, and follow the same sampling loop. LDM just has an extra channel for the mask, which makes the model even larger than the Saint model. They are also both fine-tuned for the same number of iterations. Therefore, my expectation was that LDM does similar to Saint (if not better) on the binary masks tasks. What is the authors' comments on why it is doing much worse?\n\n- Do the Saint model results in Table 1 and Table 2 use spatial CFG? If so, I think another row for \"Saint w/o spatial CFG\" should be added for a clearer picture and more fair comparison.\n\n- Is there any reported metrics measuring the diversity of the samples and overfitting of the model? A model that simply memorizes the dataset can achieve optimal scores on the metrics in Table 1 and 2.\n\n**Token Caching**\n\n- The authors assume that the tokens do not change significantly between consecutive sampling steps. While the authors show the effectiveness of their method empirically, it is not clear to me why this assumption should be true, and whether this assumption is generalizable to other architectures. Do the authors have any comments on this?\n\nI am keen to see authors' comments and willing to revise my score depending on the authors' response to my questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QCZv4Lp9k5", "forum": "tiG9ZSr21N", "replyto": "tiG9ZSr21N", "signatures": ["ICLR.cc/2026/Conference/Submission8028/Reviewer_P4Wz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8028/Reviewer_P4Wz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761787274328, "cdate": 1761787274328, "tmdate": 1762920026305, "mdate": 1762920026305, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "i4cAfXs8tU", "forum": "tiG9ZSr21N", "replyto": "tiG9ZSr21N", "signatures": ["ICLR.cc/2026/Conference/Submission8028/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8028/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763058951027, "cdate": 1763058951027, "tmdate": 1763058951027, "mdate": 1763058951027, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Saint, which finetunes a latent large-scale DiTs for image inpainting based on Spatial Reasoning Model. It proposes to encode binary/continuous and directly use it as the noise level instead of take it as the input to the denoising network via concatenation. It further proposes spatial classifier-free guidance, which enforces consistency between the generated samples and the history of already generated tokens. To accelerate sampling during inference time, clean token caching is introduced which only denoises tokens that needs to be denoised and save key and query for the conditioning variables. It also shows promising results in the experiment section."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "I am not an expert in the inpainting field, and here are my opinons:\n\n1. This paper apply classifier-free guidance on the top of Spatial reasoning models, which was originally used for small-scale toy problems and it is an reasonable combination to do the latent image inpainting tasks.\n2. The clean token caching strategy which caches keys and values for conditioning variables speed up the sampling.\n3. The experimental results show that the proposed method performs other existing work most of time."}, "weaknesses": {"value": "1. I found it hard to parse Algorithm 1 to construct unconditional input X', until section 3.2 it verbally explains that every clean token is replaced by gaussian noise. I can see that the current algorithm looks concise, but it is difficult to understand.\n2. Since we know the trade-off between diversity and fidelity using classifier-free guidance, which is also mentioned in the paper, but diversity is not measure in the paper."}, "questions": {"value": "1. In section 3.1.2, it says 10% is used to train the denoiser for the conditional case. How is this proportion decided?\n2. I am wondering how the mask size could affect the performance in the experiment. It could have an ablation study here.\n3. This is an open question, but I consider this masked diffusion to inpainting could be related to discrete diffusion in LLM. What do you think about the relationship between them?\n4. This paper chose to fine-tune pre-trained DiTs to avoid training from scratch, but during inference time, it requires two forward passes at each sampling step. Then the inference time is doubled and I am not sure whether the clean token caching will rescue here effectively."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9L01pWkoRd", "forum": "tiG9ZSr21N", "replyto": "tiG9ZSr21N", "signatures": ["ICLR.cc/2026/Conference/Submission8028/Reviewer_Z58A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8028/Reviewer_Z58A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884818719, "cdate": 1761884818719, "tmdate": 1762920025940, "mdate": 1762920025940, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an image inpainting framework Saint based on latent multi-variable architecture, combining large-scale diffusion models with flow-based transformers. Saint fine-tunes pre-trained DiTs as Spatial Reasoning Models (SRMs) by applying different noise levels to masked and unmasked regions, enabling the model to directly condition on partially noised latent variables. This improves inpainting performance under both binary masks and continuous masks. Additionally, the proposed Spatial Classifier-Free Guidance and Clean Token Caching (CTC) strategies enhance the quality and consistency of inpainted images while accelerating fine-grained inpainting."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The overall writing and organization of the paper are clear and easy to follow. The proposed method is effectively presented and well-illustrated through Figures 2, 3.\n2. The authors conducted sufficient experiments and outperformed SOTA methods, such as TD-Paint.\n3. The proposed Clean Token Caching is interesting and significantly reduces inference time for small-scale editing scenarios."}, "weaknesses": {"value": "1. TD-Paint also applies different noise levels to different pixels, so Saint's unique contribution in this aspect is not particularly prominent.\n2. The authors did not explain why SRM can improve inpainting performance by combining masked images with input images. Therefore, the motivation for introducing SRM is not sufficiently justified.\n3. The authors proposed the CTC strategy to accelerate the inpainting process, but did not compare inference efficiency with the latest methods under different patch sizes, so the contribution of CTC remains insignificant. Additionally, authors are encouraged to evaluate the memory consumption of CTC. It would better demonstrate its contribution if CTC could be validated on other inpainting frameworks.\n4. It is suggested that the authors add experiments on portrait datasets, such as CelebA-HQ.\n5. It is suggested that the authors add metrics like CLIP-I to evaluate consistency with the input image."}, "questions": {"value": "See the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PinuJym8Te", "forum": "tiG9ZSr21N", "replyto": "tiG9ZSr21N", "signatures": ["ICLR.cc/2026/Conference/Submission8028/Reviewer_WWAz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8028/Reviewer_WWAz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900789282, "cdate": 1761900789282, "tmdate": 1762920025469, "mdate": 1762920025469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new inpainting method based on LDM. The main motivation is to design a spatially asynchronous generation framework based on LDM. The proposed method can be viewed as an LDM counterpart of TD-Paint and RAD, which are based on pixel-space diffusion models. The paper achieves this by rearranging SRM in the spatial domain. Some interesting amendments are added, i.e., spatial \"classifier-free guidance\" to expedite consistency and clean token caching for reducing computational burden. Experiments demonstrate that the proposed method achieves state-of-the-art results."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The design of the proposed method is plausible and convincing.\n\n- State-of-the-art results."}, "weaknesses": {"value": "- The level of novelty is somewhat low. The main part of the method relies largely on SRM and the spatially asynchronous generation idea of TD-Paint and RAD. Accordingly, the core part is somewhat straightforward.\n\n- The spatial CFG idea is somewhat interesting, though. It is clever, and the improvement due to this is convincing. At the same time, however, it is also somewhat controversial. Is it really CFG? Indeed, time steps (especially the spatially variant ones shown in this setting) can be viewed as an indirect form of conditioning, but they are intertwined with the diffusion process and are not conditions in a classical sense. What I'm pointing out here is that, even though I'm convinced by the effectiveness, it feels like more theoretical justification is needed here. For example, the original CFG paper provides some probabilistic justification for the technique. Is the justification still valid when the conditions are replaced with time steps? Or, are there any other justifications (other than simply mimicking the technique)?\n\n- Clean token caching is a nice touch, but it is more like adopting an already well-established technique."}, "questions": {"value": "Please see the above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YSu1IZduFU", "forum": "tiG9ZSr21N", "replyto": "tiG9ZSr21N", "signatures": ["ICLR.cc/2026/Conference/Submission8028/Reviewer_wno3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8028/Reviewer_wno3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762015244021, "cdate": 1762015244021, "tmdate": 1762920024718, "mdate": 1762920024718, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}