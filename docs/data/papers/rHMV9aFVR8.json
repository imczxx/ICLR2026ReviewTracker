{"id": "rHMV9aFVR8", "number": 13402, "cdate": 1758217426039, "mdate": 1759897440132, "content": {"title": "Testing Cross-Lingual Text Comprehension in LLMs Using Next Sentence Prediction.", "abstract": "While large language models are trained on massive datasets, this data is heavily skewed towards English. Does their impressive performance reflect genuine ability or just this data advantage? To find out, we tested them in a setting where they couldn’t rely on data abundance: low-resource languages. Building on prior work (Agarwal et al., 2025) that used Next Sentence Prediction (NSP) as a test, we created a large-scale benchmark with 10,000 questions each for English (a high-resource language), Swahili (medium-resource), and Hausa (low-resource). We then tested several top models, including GPT-4 Turbo, Gemini 1.5 Flash, and LLaMA 3 70B, to see how their performance holds up. The results painted a clear picture of how levels of language resources impact outcomes. While all models excelled in English, their accuracy dropped in Swahili and fell sharply in Hausa, with LLaMA 3 struggling the most. The story became even more interesting when we introduced Chain-of-Thought (CoT) prompting. For the struggling LLaMA 3, CoT acted as a helpful guide, significantly boosting its accuracy. However, for the more capable GPT-4 and Gemini, the same technique often backfired, leading to a kind of “overthinking” that hurt their results in the cross-lingual context. This reveals that Chain-of-Thought is not a universal solution; its effectiveness depends heavily on the model’s baseline capability and the specific context of the task. Our framework pinpoints LLM weaknesses, highlights when CoT helps or hinders cross-lingual NSP performance, and factors influencing their decisions.", "tldr": "", "keywords": ["Next Sentence Prediction", "Large Language Models", "Cross-Lingual NLP", "Text Comprehension", "Low-Resource Languages", "Chain-of-Thought Prompting", "Semantic Similarity", "Perplexity", "Educational NLP", "Benchmarking"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8bcf550a7fe68e194eedeea27c7dd8f8083b8d80.pdf", "supplementary_material": "/attachment/42d166601ecb9aed0278482aa54f97d0c57c7344.zip"}, "replies": [{"content": {"summary": {"value": "The authors study the Next-Sentence-Prediction capabilities in LLMs (GPT-4-Turbo, Gemini-1.5-Pro, Llama-70b) using a dataset built using publicly available books in 3 languages (English, Swahili, Hausa). They benchmark this ability using vanilla prompting and Chain-of-Thought, and find that CoT might hurt the performance in low-resource languages."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper works on 2 important low and medium-resource African languages, Swahili and Hausa, and develops a new benchmark to assess the reading comprehension of LLMs."}, "weaknesses": {"value": "- This paper is not well-written and has too many dramatic adjectives, as if heavily refined by an AI. At the current state, the paper is more like a technical report (more information provided below). It feels like this is an old paper that was resubmitted here. \n- Several previous works ([Ahuja _et al._, 2024a](https://aclanthology.org/2023.emnlp-main.258/), [Ahuja _et al._, 2024b](https://aclanthology.org/2024.naacl-long.143/)) have shown and clearly benchmarked the performance of LLMs across various standard tasks, including low-resource African languages, and have shown the performance drops. Also, given that these models are not SOTA anymore (Gemini-2.5, and GPT-5 which claim to be better at multilingual), these findings might not hold. \n- Also, the Chain-of-Thought analysis is quite bland and incomplete. During CoT, what language did the model use to reason? It could that that reasoning in a low-resource language could be detrimental. Also, use of \"overthinking\" is a stretch (for me). Overthinking is generally attributed to spending more tokens on reasoning for a simple problem, and somehow, the word does not sit well with the current experiment design. Given the availability of reasoning models, the authors should have studied their performance, especially while reasoning in English and the query's native language ([Ahuja _et al._, 2025b](https://arxiv.org/abs/2507.00246)). I feel some analysis of the CoT trace should also be conducted, i.e., the number of tokens on easier and harder classification problems. \n- As mentioned before, the study is bland and just revolves around benchmarking models on a single classification task, NSP, and contains some unnecessary technical details. The prompt used for CoT is also a very rudimentary one-liner, and I am not sure about its efficacy.\n- No mitigation strategies or improvement methodologies are discussed. \n- Another interesting analysis would be pre/post CoT, i.e., _reason-and-answer_ (vs) _answer-and-reason_. This woudl motivate how the LLM can \"fix and justify\" a CoT to a wrong answer as well. \n- While predicting A/B, no option-bias is analysed, which is important for classification tasks with LLMs. \n- I believe this paper requires a much deeper analysis and problem motivation for ICLR. I believe this work is superseded by the large-scale benchmarking studies and works like [Ahuja 2025a](https://arxiv.org/abs/2504.11900)."}, "questions": {"value": "- Was sampling disabled for these experiments? \n- While scraping the data, was the license of the books respected?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XrOKti3Qsc", "forum": "rHMV9aFVR8", "replyto": "rHMV9aFVR8", "signatures": ["ICLR.cc/2026/Conference/Submission13402/Reviewer_sHY8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13402/Reviewer_sHY8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761460193328, "cdate": 1761460193328, "tmdate": 1762924036638, "mdate": 1762924036638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a next sentence prediction (NSP) evaluation dataset with data in 3 languages (English, Hausa, Swahili). The authors argue this task (NSP) provides a new way to evaluate a model's conceptual understanding of a narrative. This dataset is then used to evaluate three LLMs and compare them to a number of heuristic features. These heuristic features each have a strong relationship with the results. Then, CoT prompting is evaluated and results in very inconsistent impact on this benchmark."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. the paper has clear motivation and presentation. It is easy to read and understand.\n2. the paper provides sufficient details for reproducibility"}, "weaknesses": {"value": "*Major*:\n1. The paper displays little awareness of the field it seeks to contribute to (multilingual NLP or NLP in general). \n- related works section doesn't discuss any prior work on evaluating multilingual text comprehension\n- paper doesn't discuss any prior work on multilingual CoT prompting\n- paper never compares this method and dataset to alternatives, never frames results with respect to other recent literature, and never discusses linguistic features that could relate.\n\nAs a result, given the complete lack of contextualization, the contributions of this paper are very unconvincing.\n\n*Other*:\n1. NSP was abandoned in the field of NLP as models got better (as the authors mention in the related works paper, citing the RoBERTa). The paper fails to display why NSP would be a useful test (relative to all the evaluations available) with the tremendous advancements of LLMs. The paper shows the relationship with surface-level features (e.g. distractor length) as a finding, which is exactly why NSP is no longer useful. As a reviewer, I am unconvinced that NSP = comprehension.\n1. Perplexity analysis is quite unsound. Not only, is perplexity evaluated using smaller/weaker models, but multiple of them are Llama-3 based. Authors fail to address how strongly related perplexity (i.e. next token prediction) is to next sentence prediction (especially within same model family) and\n1. Comparison across languages with different data. The paper does cross-lingual comparisons of performance, but the dataset splits were built on individual texts, meaning there's no validation that, for example, the Hausa storybooks are simply much more difficult to do NSP on than the other languages. In addition, linguistic considerations are not mentioned. Could NSP be fundamentally more difficult in different languages.\n1. Analysis shows correlations, but doesn't run any ablations to display a higher level of relationship (e.g. causality).\n1. Lack of statistical details (variance, error bars, stat sig). Notably, the CoT results don't seem stat sig given just 1000 questions with only two choices.\n\n*Minutia*:\n1. L80 \"While vital for measuring AI’s progress, these benchmarks are often\ntoo complex for simple and scalable use in practical applications like educational apps.\"\n1. L87 \"superficial cues\" ?\n1. L302 why is this surprising ?\n1. no evidence \n1. lots of overstated language / unsupported claims across the paper (L14, L53, L139, L262, L356, L427, to name a few)\n1. informal language across the paper"}, "questions": {"value": "Questions:\n* Is this work targeting the education space ? If so, clearer links should be made. If not, the recurring mentions of education seem out of place. What is RoboTutor ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rgQTKtgD45", "forum": "rHMV9aFVR8", "replyto": "rHMV9aFVR8", "signatures": ["ICLR.cc/2026/Conference/Submission13402/Reviewer_raRS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13402/Reviewer_raRS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761516839050, "cdate": 1761516839050, "tmdate": 1762924036226, "mdate": 1762924036226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new cross-lingual benchmark to evaluate text comprehension in large language models (LLMs) using a Next Sentence Prediction (NSP) task. The authors constructed a balanced dataset of 10,000 questions for English, Swahili, and Hausa. They evaluated three high-performance models (GPT-4 Turbo, Gemini 1.5 Flash, and LLaMA 3 70B) and analyzed their performance with and without Chain-of-Thought (CoT) prompting. The authors claim that model accuracy degrades significantly in low-resource settings and that CoT prompting hurts stronger models due to \"overthinking.\" However, the study's conclusions about \"genuine comprehension\" and \"reasoning\" are built on a methodologically fragile foundation, and the evidence presented is insufficient to support its primary claims."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The creation of a large, balanced, three-language dataset sourced from African Storybooks is a notable contribution to the community. This resource could be valuable for future research, if the number of languages would be increased further."}, "weaknesses": {"value": "Task Misalignment: NSP is an inadequate proxy for “comprehension” or “reasoning”. Its reliance on shallow heuristics invalidates the core claims.\n\nLack of Statistical Rigor: No significance testing, confidence intervals, or regression coefficients are reported. Claims of “most influential factors” and CoT effects are unsupported.\n\nNo Human Baseline: Without human performance, the reported accuracies are uninterpretable.\n\nLimited Model Diversity: Only three large models are tested, leading to overgeneralized conclusions about “stronger” vs. “weaker” systems.\n\nOverstated Conclusions: The findings likely reflect heuristic transfer, not true cross-lingual reasoning.\n\nMissing important/relevant references: \nhttps://arxiv.org/abs/2505.14395\nhttps://aclanthology.org/2025.naacl-long.139/\nhttps://aclanthology.org/2024.sigtyp-1.14/\nhttps://arxiv.org/abs/2412.00948"}, "questions": {"value": "How do you justify using Next Sentence Prediction (NSP) as evidence of “comprehension” or “reasoning”? \n\nAre the reported differences in accuracy and “most influential factors” statistically significant? Please provide confidence intervals or test results to substantiate these claims.\n\nWhat is human performance on your benchmark, and how does it contextualize the reported model accuracies?\n\nModel Scope: Why were only three large proprietary models evaluated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YaZ0Qdrs21", "forum": "rHMV9aFVR8", "replyto": "rHMV9aFVR8", "signatures": ["ICLR.cc/2026/Conference/Submission13402/Reviewer_1mxT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13402/Reviewer_1mxT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010456131, "cdate": 1762010456131, "tmdate": 1762924035833, "mdate": 1762924035833, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper builds a large, balanced cross-lingual benchmark for Next Sentence Prediction (NSP) with 10,000 items each in English (high-resource), Swahili (medium-resource), and Hausa (low-resource). It evaluates GPT-4 Turbo, Gemini 1.5 Flash, and LLaMA-3-70B, and studies factors such as distractor distance/length, semantic similarity, and (masked) perplexity. Key findings: accuracy degrades as language resources decrease; Chain-of-Thought (CoT) helps the weakest model (LLaMA-3) but often hurts stronger models (GPT-4/Gemini) in lower-resource languages; and models fail most when “delta” similarity/perplexity between options is near zero (a “zone of ambiguity”). The paper also proposes using CoT explanations pedagogically.  \n\nOverall, I think this could be a useful benchmark/analysis paper. With several clarifications and stronger experimental controls (detailed below), I’d be willing to raise my score."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Balanced, large-scale cross-lingual NSP (10k per language) sourced from African Storybooks with a clear generation pipeline.\n2. Thoughtful analyses (logistic regression feature importance; ambiguity via delta-PPL and delta-similarity)."}, "weaknesses": {"value": "1. The paper states it is the first to systematically apply/analyze CoT for cross-lingual NSP and proposes pedagogical use. Please situate this claim relative to prior CoT-style multilingual comprehension work and clarify what “systematically” entails (e.g., prompt design/search, coverage across languages/models).\n\n2. NSP can be susceptible to shallow cues. The paper mitigates this with engineered features and analyses, but please discuss residual artifacts that NSP may still capture vs. “true” discourse comprehension—especially across languages with different morphology/length distributions."}, "questions": {"value": "1. Table 3 reports the “single most influential factor.” Was this from single-feature logistic models or a multivariate model with standardized coefficients? If single-feature, consider providing multivariate results or SHAP-style analyses to avoid confounds between distance/length/similarity.\n\nMinor Comments / Typos\n1. The section/TOC listing at the end seems to duplicate “Analysis of Factors Influencing Errors.” Consider deduplicating/renaming subsections (e.g., 5.1 vs 5.1.1)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pq8n3hYD75", "forum": "rHMV9aFVR8", "replyto": "rHMV9aFVR8", "signatures": ["ICLR.cc/2026/Conference/Submission13402/Reviewer_dJXM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13402/Reviewer_dJXM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762712316705, "cdate": 1762712316705, "tmdate": 1762924035173, "mdate": 1762924035173, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}