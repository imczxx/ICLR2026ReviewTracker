{"id": "RdtQiM9gyB", "number": 14007, "cdate": 1758226757008, "mdate": 1763705161989, "content": {"title": "LEGATO: Large-scale End-to-end Generalizable Approach to Typeset OMR", "abstract": "We propose Legato, a new end-to-end  model for optical music recognition (OMR), a task of converting music score images to machine-readable documents. Legato is the first large-scale pretrained OMR model capable of recognizing full-page or multi-page typeset music scores and the first to generate documents in ABC notation, a concise, human-readable format for symbolic music. Bringing together a pretrained vision encoder with an ABC decoder trained on a dataset of more than 214K images, our model exhibits the strong ability to generalize across various typeset scores. We conduct comprehensive experiments on a range of datasets and metrics and demonstrate that Legato outperforms the previous state of the art. On our most realistic dataset, we see a 68\\% and 47.6\\% absolute error reduction on the standard metrics TEDn and OMR-NED, respectively.", "tldr": "Legato is the first large-scale pretrained OMR model that achieves the state of the art on various datasets.", "keywords": ["Optical Music Recognition", "AI for Music", "Multimodal Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/599d01309409256d85b166d4a0e84ea5cd99f362.pdf", "supplementary_material": "/attachment/8b12048022c50b2b17e04d05456472b73ab4bd1a.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Legato, the first large-scale end-to-end optical music recognition (OMR) model capable of transcribing multi-page typeset scores into ABC notation. Legato combines a frozen pretrained vision encoder from Llama 3.2 with a trained transformer decoder, processing segmented images rather than requiring pre-split pages or systems. The authors construct PDMX-Synth, a dataset of 238,386 image-ABC pairs derived from the PDMX dataset. Evaluation on multiple held-out datasets shows that Legato substantially outperforms Sheet Music Transformer++ on the TEDn metric."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Legato is the first model to handle multi-page typeset scores end-to-end without the need of pre-splitting scores into pages or systems.\n* The evaluation results show substantial improvements across multiple datasets and metrics, particularly on realistic camera images.\n* Publicly releasing implementation code and PDMX-Synth dataset with 238k (multi-page typeset score image, ABC) pairs is beneficial to the community.\n* Multiple held-out datasets for the evaluation."}, "weaknesses": {"value": "* Legato is essentially multimodal Llama with a smaller transforemer decoder for OMR task. It has very limited architectural novelty.\n* Applying BPE tokenization needs more justification than just providing 4 examples in Figure 3. and writing the tokenizer 'captures some composite musical concepts.'  Since ABC-notation have limited number of symbols and combinations, there could be a more efficient domain-knowledge-based method of tokenization. To support BPE tokenization, authors need to provide more systematic vocabulary analysis and comparison with expert-defined tokenization.\n* The comparion between Legato and SMT++ heavily relies on the format conversion, which cannot ensure intergrity of the output.\n* Legato and SMT++ have drastically different number of parameters. Additionally Legato includes pre-trained vision encoder compared to SMT++'s vision encoder, which is trained from scratch.\n* Since the main difference of Legato and SMT++ is the vision encoder part and SMT++'s implementation is publicly available, the authors could have applied an enlarged SMT++ model with a matching number of parameters in the decoder trained on the same PDMX dataset.\n* The GPT-5 evaluation's prompting strategy could be explored more thoroughly."}, "questions": {"value": "No further question"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HRVwDey0ur", "forum": "RdtQiM9gyB", "replyto": "RdtQiM9gyB", "signatures": ["ICLR.cc/2026/Conference/Submission14007/Reviewer_qebB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14007/Reviewer_qebB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761297461161, "cdate": 1761297461161, "tmdate": 1762924501471, "mdate": 1762924501471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper proposes a large-scale end-to-end generalizable approach to typeset OMR. The authors created paired image–ABC data from the PDMX dataset. The training system adopts a vision encoder and language decoder architecture. The proposed system is capable of recognizing full-page and multi-page typeset music scores into ABC notation. Although there is a lack of research on comparing different vision encoders and extending the LLM decoder to larger, the overall framework shows its effectiveness. The results are promising. I like this work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- OMR is an interesting and important research topic in music information retrieval with strong ongoing research interest.\n\n- The proposed vision encoder and Transformer decoder form a well-designed architecture for OMR.\n\n- The system is trained on a large-scale dataset of 214k images, demonstrating strong generalization ability.\n\n- The procedure for creating the dataset is well-designed and systematic.\n\n- Comprehensive experiments are conducted across a range of datasets, showing state-of-the-art performance.\n\n- The training and testing datasets are separate, further validating the system’s generalization capability.\n\n- The recognition results shown in the Appendix are impressive and of high quality."}, "weaknesses": {"value": "- The proposed PDMX-Synth dataset is derived from the PDMX dataset; therefore, it is effectively a subset and smaller in scale. Will this affect the performance?\n\n- The model architecture shares similarities with the design of SMT++, indicating limited novelty in architectural design.\n\n- There is limited comparison of different vision encoders and more decoder sizes, leading to the technical part a bit weak. \n\n- There is a lack of equations, such as autoregressive prediction, and loss functions to show how the LLM is trained. \n\n- The paper lacks discussion on human manuscript transcription — how would the system’s performance degrade in that case?"}, "questions": {"value": "- How would different vision encoders affect the recognition performance?\n\n- As Table 1 shows, Legato outperforms Legato_small by a large margin. Would increasing the decoder size further improve system performance?\n\n- Will hyperparameters, such as temperature affect the prediction performance? Do authors choose the best or are there randomness in next token prediction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7ieTqqOlS3", "forum": "RdtQiM9gyB", "replyto": "RdtQiM9gyB", "signatures": ["ICLR.cc/2026/Conference/Submission14007/Reviewer_zT9i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14007/Reviewer_zT9i"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831736080, "cdate": 1761831736080, "tmdate": 1762924501053, "mdate": 1762924501053, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Legato, an end-to-end OMR system that converts full-page/multi-page typeset score images into ABC notation using a frozen pretrained vision encoder (Llama-3.2-Vision) and a lightweight transformer decoder with a multimodal projector. Training uses a new 214K-image synthetic corpus (PDMX-Synth). Evaluation is standardized via MusicXML conversion and measured with TEDn and OMR-NED, where Legato reports large absolute error reductions (e.g., −68% TEDn, −47.6% OMR-NED) over prior work (e.g., SMT++). The paper also presents a data-driven tokenization that appears to learn composite musical concepts (e.g., triads, short phrases)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clear problem focus & scope. Tackles practical, full-page OMR with multi-system/stave layouts—beyond monophonic or single-system settings.\n\nStrong empirical gains. Large improvements on TEDn/OMR-NED across several datasets, including an IMSLP sample.\n\nStandardized evaluation. Using MusicXML as a unifying target for comparison reduces format bias; reporting ABC/kern helps triangulate.\n\nScalable training recipe. Pretrained vision encoder + compact decoder yields a seemingly efficient path to high accuracy.\n\nTokenizer insight. Data-driven tokenization that captures chords/phrases is promising and could simplify decoding of frequent musical patterns."}, "weaknesses": {"value": "Attribution of gains is unclear. It’s hard to disentangle where improvements come from: ABC target format, frozen VLM encoder, data scale (214K), or architecture. A dedicated ablation is missing.\n\nEvaluation confounds. Conversions among ABC/ kern/MusicXML may introduce asymmetric errors; conversion failure rates and their impact on metrics are not reported.\n\nMetric interpretability. TEDn/OMR-NED reductions are compelling but lack qualitative error analysis or audible case studies linking metric changes to musically meaningful differences.\n\nGeneralization gaps. Focus is on typeset scores; robustness to handwritten, degraded scans, complex lyrics/ornaments, and non-Western notation is not demonstrated.\n\nRobustness & reliability. No tests on scan noise, resolution changes, staff skew, lighting artifacts, transposition/key/time-signature shifts, or symbol vocabulary tails."}, "questions": {"value": "Why better than SMT++?\nPlease quantify the contribution of (a) ABC output vs. MusicXML/kern, (b) data scale (learning curves), (c) using a pretrained vision encoder (frozen vs. finetuned), and (d) decoder capacity. A controlled ablation matrix would clarify attribution.\n\nCase studies & perceptual relevance.\nProvide score-level examples where Legato reduces TEDn/OMR-NED, with before/after renderings and (ideally) audio renderings to illustrate musically meaningful fixes (e.g., rhythm beaming, voice assignment, chord spelling).\n\nHandwritten & degraded inputs.\nHow does Legato perform on handwritten scores (e.g., MUSCIMA++, historical manuscripts) or noisy scans? Any domain-adaptation strategy planned?\nPlease include perturbation tests (resolution, blur, skew, lighting, JPEG artifacts) and transposition/key/time-signature shifts to probe symbol and structure invariance.\n\nData hygiene & licensing.\nClarify licensing of PDMX-Synth sources and safeguards against train-test leakage across editions/engraving variants of the same piece.\n\nExtending beyond rhythm/pitch.\nDo you plan to evaluate semantic elements (lyrics alignment, articulations, ornaments, dynamics) and non-Western notation to support broader claims of generalizability?"}, "flag_for_ethics_review": {"value": ["Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "details_of_ethics_concerns": {"value": "whether the music score has copyright issues need to be clarified."}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Mi6EhFa5r1", "forum": "RdtQiM9gyB", "replyto": "RdtQiM9gyB", "signatures": ["ICLR.cc/2026/Conference/Submission14007/Reviewer_aT3R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14007/Reviewer_aT3R"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938311312, "cdate": 1761938311312, "tmdate": 1762924500499, "mdate": 1762924500499, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a comprehensive solution for OMR on long and complex real-world music sheets, including the collection and preprocessing of a large-scale dataset, as well as an end-to-end recognition model, LEGATO. Experimental results demonstrate that LEGATO exhibits superior performance and generalization capabilities, outperforming both prior specialized OMR model SMT++ and general-purpose vision-language model GPT-5."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The PDMX-Synth dataset curated in this paper addresses the scarcity of real-world, complex music score data for OMR. Its public release would significantly benefit research in this field.\n- Experimental results demonstrate that LEGATO significantly outperforms both SMT++ and GPT-5, with strong performance on real-world scenarios (camera versions of OpenScore String Quartets and OpenScore Lieder)—highlighting the effectiveness and practicality of the proposed approach."}, "weaknesses": {"value": "1. Limited in performance analysis of general VLMs. \n    1. The paper relies solely on GPT-5 as the representative general-purpose vision-language model for comparison, which somewhat limits the persuasiveness of the evaluation. Including additional state-of-the-art multimodal models—such as those from the Gemini, Claude, and Qwen families—would provide a more comprehensive and robust assessment.\n    2. The evaluation of GPT-5 lacks sufficient detail. The paper does not specify the prompts provided to the model, nor does it indicate whether exemplars were used in the input to optimize the model's output. Furthermore, the absence of a comparative case study between the outputs of GPT-5 and LAGETO prevents a thorough analysis of GPT-5's deficiencies. This raises concerns about whether the authors have adequately explored the capabilities of the general VLMs.\n2. Lack of experimental analysis regarding the training data. The large-scale dataset introduced in this paper constitutes one of its core contributions, and considerable space is devoted to detailing the dataset’s collection and preprocessing pipeline. However, the paper does not include experimental comparisons evaluating the impact of the proposed dataset versus existing datasets on model performance (although the new dataset is strongly likely to yield better results). Moreover, the authors do not provide empirical ablation studies to assess the effectiveness of their data cleaning and data augmentation strategies."}, "questions": {"value": "1. When calculating the TEDn metric, did the authors attempt to have GPT-5 directly output MusicXML? If so, were there any changes in the results?\n2. Have the authors attempted more data augmentation strategies such as adjusting brightness, applying affine transformations, or adding noise—on the rendered score images in the training data to better align them with real-world scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0U5Z9TCtka", "forum": "RdtQiM9gyB", "replyto": "RdtQiM9gyB", "signatures": ["ICLR.cc/2026/Conference/Submission14007/Reviewer_H56V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14007/Reviewer_H56V"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994513289, "cdate": 1761994513289, "tmdate": 1762924500194, "mdate": 1762924500194, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Thank you all for your comments and questions. To address everybody's concerns we:\n- Added ablations in Appendix B.1, training:\n    - Regular SMT++ on Grandstaff in ABC\n    - Large SMT++ on Grandstaff in ABC\n    - Large SMT++ on PDMX-Synth\n- Added learning curves of Legato on PDMX-Synth in Appendix B.2\n- Reported the conversion failure rate of SMT++ in Appendix B.3 and added the number of samples being tested in the main Table 1.\n- Performed more experiments in Appendix B.4 on our comparison to a VLM, including:\n    - More prompt engineering for GPT-5 and Gemini 2.5 Pro\n    - In-context learning for GPT-5 and Gemini 2.5 Pro\n    - Evaluate other models like Gemini and Qwen (at publication)\n- Checked overlap between PDMX-Synth and our test datasets, and carefully reviewed the CC0 licensing of PDMX to ensure that our construction and use of PDMX-Synth is compliant.\n- Added qualitative examples with rendered audio (see supplementary files)\n\nThese additions lead us to three main conclusions. First, the SMT++ ablations show that, for this baseline, one important source of improvement is the choice of output format and tokenizer: switching from **kern to ABC alone yields a large reduction in error, while increasing model size or training SMT++ on PDMX-Synth brings little additional benefit. At the same time, Legato achieves substantially better performance under the same ABC/PDMX-Synth setting, indicating that its gains go beyond format alone and arise from the synergy between its pre-trained encoder, architecture, and large, diverse training data. Second, our additional experiments with GPT-5, Gemini 2.5 Pro, and Qwen demonstrate that stronger prompting and test-time scaling (e.g., in-context learning, MusicXML prompting) are indeed helpful and yield non-trivial improvements over naive prompting; however, even under these strengthened settings, general-purpose VLMs consistently remain below Legato on our OMR benchmarks. This confirms and further reinforces the conclusions of the original submission. Third, our overlap and licensing checks increase confidence in the fairness, validity, and reusability of our dataset and experimental setup.\n\nIn all of these cases we found that our Legato model held up to scrutiny, and that it is still the best performing OMR model available today. We thank the reviewers for their help in making our paper as strong as it could be, and bringing this resource-limited challenge to the audience of a general AI conference."}}, "id": "XahpOVtKqt", "forum": "RdtQiM9gyB", "replyto": "RdtQiM9gyB", "signatures": ["ICLR.cc/2026/Conference/Submission14007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14007/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission14007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763707560640, "cdate": 1763707560640, "tmdate": 1763707560640, "mdate": 1763707560640, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}