{"id": "VFAPBswx8E", "number": 18770, "cdate": 1758290756347, "mdate": 1759897082184, "content": {"title": "DiffCont: Continual Anomaly Detection with Diffusion Models and Outlier Rejection", "abstract": "We address continual anomaly detection in industrial inspection where new data flows in periodically in the form on new categories or newer types of defective samples. In such a setting, we would want the model to generalize to newer categories and shifting data distributions whilst maintaining its performance on previously learnt categories. Building on a diffusion-based U-Net with conditional generation and an auxiliary classifier, we introduce a Weibull-guided pipeline that serves two roles: (i) as a representative conditional generative distillation model, where a per-class Weibull model is fit on a projected embedding space and accepts only strong exemplar replay samples via threshold; (ii) as a per-class anomaly detection model, where the same heavy-tailed Weibull fit on the tail of normal embeddings converts distances into outlier probabilities for open-set anomaly detection. On MVTec-AD dataset split into 15 class-incremental experiences, our method achieves superior performance across experiences while presenting a light-weight anomaly detection workflow fit for industrial use.", "tldr": "Continual Anomaly Detection: Efficient distillation of diffusion U-Nets with outlier rejection achieves competitive performance on MVTec-AD", "keywords": ["Continual Learning", "Anomaly Detection", "Diffusion Models", "UNet", "Outlier Rejection", "Openset Recognition"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5257f313319eb09129bad3ed7aa04793a17a06a2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a continual anomaly detection framework built on a class-conditional diffusion model with generative replay. Instead of storing raw exemplars, a frozen teacher model is used to regenerate past normal samples after each task, and a Weibull-based filter selects only “high-quality” generations for replay. A fixed projection layer defines a latent space where per-class EVT (Weibull) distributions are fitted and later used at inference time to classify test samples as normal or anomalous. Experiments are conducted on MVTec-AD in an object-incremental setup, reporting image-level AUPR, accuracy, and F1 across experiences."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper addresses a relatively under-explored problem setting, continual anomaly detection with generative replay, which is still emerging.\n- The proposed pipeline is simple and modular: a class-conditional diffusion U-Net with an auxiliary classifier, a frozen projector with whitening to define a stable embedding space, and per-class EVT fits used for scoring. This makes the method easy to implement and ablate. The same EVT machinery is used for two roles: gating generative replay samples and producing class-specific anomaly scores at test time, which is coherent."}, "weaknesses": {"value": "- The opening sentence frames the problem as one of temporal drift and distributional evolution within a single data stream (for example, tooling changes, sensor drift, or evolving definitions of “normal”), suggesting a continuous adaptation scenario. However, the actual formulation and experiments correspond to object-incremental learning, where each MVTec category is a distinct, static domain introduced sequentially. This disconnect makes the framing misleading and weakens the motivation of the proposed approach.\n- The proposed method lacks motivation for the use of EVT/Weibull modeling. The approach seems heuristic. \n- The related work section is underdeveloped and omits several key papers on continual anomaly detection and generative replay. Recent CAD frameworks on MVTec/VisA,such as UCAD [1], as well as more recent pixel-level continual anomaly detection studies [2], and IUF [3], should be acknowledged, as they adopt the same object-incremental setting. Likewise, diffusion-based replay approaches like ReplayCAD [4] and CDAD [5] are highly relevant yet unmentioned. Without engaging with these works, the paper’s positioning and baseline choices are difficult to evaluate.\n- The evaluation protocol is incomplete. The paper only reports image-level F1 / AUCPR / Accuracy, whereas pixel-wise localization metrics such as PRO / AUPRO / pixel-wise AUROC are standard for anomaly detection (especially on MVTec). Without pixel-level results, it is unclear whether the model is actually detecting where anomalies occur or just performing binary classification.\n- The proposed method underperforms compared to most baselines reported in the paper, calling into question the claimed advantages of the approach and the effectiveness of the proposed components.\n- The paper lacks substance and polish in presentation. Many sections are very short, some figure have undescriptive captions, and some tables are missing descriptive titles or commentary. Some pages contain only a few small plots with large unused whitespace, and the submission does not come close to the page limit. While length alone is not a criterion, the overall layout suggests underdeveloped analysis, with missing discussion, qualitative inspection, or deeper ablations that would normally be expected in a full ICLR submission.\n\n**References**\n\n[1] Jiaqi Liu et al., “Unsupervised Continual Anomaly Detection with Contrastively-learned Prompt,” AAAI 2024. \n\n[2] Nikola Bugarin et al., “A Benchmark for Pixel-Level Anomaly Detection in Continual Learning,” CVPR Workshops 2024.\n\n[3] Jiaming Tang et al., “An Incremental Unified Framework for Small Defect Detection in Industrial Inspection,” ECCV 2024.\n\n[4] Lei Hu et al., “ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection,” IJCAI 2025.\n\n[5] Xiaofan Li et al., “One-for-More: Continual Diffusion Model for Anomaly Detection,” CVPR 2025."}, "questions": {"value": "- Why is quality-gated replay needed if training data are normal? If the real training images are clean, gating only makes sense if teacher-generated replay is sometimes off-manifold. Please justify.\n- What is the quality of the reconstructed images? Why not use them instead of doing a projection on a U-Net layer?\n- What hyperparameters were used? What are the weights used for each component of the loss?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5kKJyuWMZm", "forum": "VFAPBswx8E", "replyto": "VFAPBswx8E", "signatures": ["ICLR.cc/2026/Conference/Submission18770/Reviewer_iPdY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18770/Reviewer_iPdY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760560644471, "cdate": 1760560644471, "tmdate": 1762928512109, "mdate": 1762928512109, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DiffCont, a continual anomaly detection framework designed for industrial inspection tasks where new classes or defect types arrive over time. The key idea is to combine diffusion-based generative replay with Weibull-based outlier rejection."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The method is efficient and realistic for industrial use cases."}, "weaknesses": {"value": "1. The paper is poorly written and far from the standard of a publication. The overall writing, formatting, and organization are confusing, figures and tables are misaligned, captions are unclear, and many sentences are grammatically incorrect or lack precision. These issues make the paper difficult to read and significantly reduce its credibility.\n2. The experimental section is confusing and lacks substance. Only a single dataset (MVTec-AD) is used, and the setup of “Experiment 1/2/3” is confusing. Moreover, the proposed method performs worse than baselines with a large gap. And no analysis on the experimental results. Overall, the experimental validation is incomplete and fails to support the claimed contributions.\n3. The proposed method merely stitches together existing components diffusion-based replay and Weibull tail modeling without any genuine algorithmic innovation or theoretical insight. There is no deeper analysis of why the combination works, nor any exploration beyond this straightforward integration. Given that the results are also weak, the overall contribution is limited.\n\nOverall, the paper is significantly below the expected standard for conference publication."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6mT4FsrMmj", "forum": "VFAPBswx8E", "replyto": "VFAPBswx8E", "signatures": ["ICLR.cc/2026/Conference/Submission18770/Reviewer_wtpC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18770/Reviewer_wtpC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761380247047, "cdate": 1761380247047, "tmdate": 1762928508903, "mdate": 1762928508903, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of continual anomaly detection in a class-incremental setting, motivated by industrial inspection scenarios where new object categories are introduced over time. The authors propose DiffCont, a method centered on a class-conditional diffusion U-Net. The method is evaluated on a challenging 15 class-incremental benchmark derived from the MVTec-AD dataset."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses the continual anomaly detection in a class-incremental setting, which is a challenging and practical scenario."}, "weaknesses": {"value": "1. The paper looks like a report, not a paper.\n\n2. No analysis on any experiments, only tables"}, "questions": {"value": "1.  Could the authors clarify the experimental setup for the baselines in Table 2? Were models like PatchCore and CFA trained in the same class-incremental setting? If so, how were they adapted? If not, why are they considered appropriate comparisons for a continual learning method?\n\n2.  The method relies on at least 5 loss-weighting hyperparameters. How were these selected, and how sensitive is the model's performance to these choices?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d681SMGKEP", "forum": "VFAPBswx8E", "replyto": "VFAPBswx8E", "signatures": ["ICLR.cc/2026/Conference/Submission18770/Reviewer_Eak6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18770/Reviewer_Eak6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973553714, "cdate": 1761973553714, "tmdate": 1762928507550, "mdate": 1762928507550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DiffCont, a continual anomaly detection framework that integrates diffusion models, outlier rejection via Weibull modeling, and generative replay for industrial inspection tasks. The approach targets the challenge of adapting to new data distributions, e.g. new defect categories while preventing catastrophic forgetting. Experiments are conducted on the MVTec-AD dataset in a class-incremental setting (15 sequential tasks)."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "-   The paper effectively combines diffusion-based generative replay with EVT-based (Weibull) outlier rejection, bridging continual learning, anomaly detection, and open-set recognition.\n\n- The use of Weibull tail modeling is theoretically grounded in Extreme Value Theory (EVT). This gives a principled approach to sample acceptance and anomaly scoring."}, "weaknesses": {"value": "- Although the paper presents baseline results, the comparison is mainly restricted to *static anomaly detection* methods. It lacks experiments against continual-learning-based anomaly detection or generative replay baselines. Moreover, the comparison does not include more recent methods from the past one or two years. The experimental evaluation is also limited to MVTec-AD. Datasets such as **RealIAD** or **MVTec 3D** are not explored. In Section 3.3 (Generation Memory Budget), the claimed advantages are not supported by experiments or quantitative evidence. The explanations accompanying tables and figures are insufficient to clearly demonstrate the effectiveness of the proposed approach. Overall, the experimental scope and baselines are insufficient to support the claims.\n\n- Only two simple ablations are presented (number of epochs and tail size). More insightful analyses such as removing the outlier rejection module, freezing or unfreezing the projector, changing replay sample quality, or disabling the distillation loss would provide a deeper understanding of the causal contributions of each component. It remains unclear why the ablations are not conducted across multiple modules or losses.\n\n- The overall writing and presentation are poor. There are many broken sentences and unfinished paragrahs. It feels like the paper is not ready for submission yet."}, "questions": {"value": "- The authors should further improve the writing and presentation before submission."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "84jiFTDuih", "forum": "VFAPBswx8E", "replyto": "VFAPBswx8E", "signatures": ["ICLR.cc/2026/Conference/Submission18770/Reviewer_Pa7i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18770/Reviewer_Pa7i"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986125878, "cdate": 1761986125878, "tmdate": 1762928506540, "mdate": 1762928506540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}