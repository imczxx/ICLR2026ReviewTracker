{"id": "qr4d8S1Qpt", "number": 2505, "cdate": 1757127307214, "mdate": 1759898144249, "content": {"title": "Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair", "abstract": "Effective information seeking in the vast and ever-growing digital landscape requires balancing expansive search with strategic reasoning. Current large language model (LLM)-based agents struggle to achieve this balance due to limitations in search breadth and reasoning depth, where slow, serial querying restricts coverage of relevant sources and noisy raw inputs disrupt the continuity of multi-step reasoning. To address these challenges, we propose BrowseMaster, a scalable framework built around a programmatically augmented planner-executor agent pair. The planner formulates and adapts search strategies based on task constraints, while the executor conducts efficient, targeted retrieval to supply the planner with concise, relevant evidence.  This division of labor preserves coherent, long-horizon reasoning while sustaining broad and systematic exploration, overcoming the trade-off that limits existing agents. \nFor agent training, we introduce BrowseMaster-QA, a challenging search dataset synthesized by an agentic pipeline. With tasks that demand complex reasoning and persistent search, it provides a crucial resource for training capable web agents. Extensive experiments on challenging English and Chinese benchmarks show that BrowseMaster consistently outperforms open-source and proprietary baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh, demonstrating its strong capability in complex, reasoning-heavy information-seeking tasks at scale.\nCode and data will be available.", "tldr": "", "keywords": ["Web Browsing", "Tool-Using Agent", "Multi-agent"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9914b2dff30487cb3d1b6704de79239fd6cb20e6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a novel agentic search agent framework, BrowseMaster, to combine expansive search with strategic reasoning that increases both the depth and breadth of the search. The BrowseMaster is designed to be a planner-executor agent pair. The planner can assign the executor with search tasks and prepares the high-level searching plan, and iterating on solutions until its self-assigned confidence score reaches a threshold. The executors are scalable search engines; they invoke a set of standardized programming primitives that conducts parallel searches, keyword generation and filtering. To train such data, a novel dataset, BrowseMaster-QA, is curated, on which supervised finetuning is conducted. The dataset is curated by a synthetic workflow, which first initialize task from Wikipedia and then enhance the search difficulty by adding uncertainty and removing shortcuts. BrowseMaster works well on existing challenging benchmarks such as BrowseComp-en and BrowseComp-zh."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written and easy to follow. The two main contributions of this paper, agent framework and dataset, are both clearly introduced in Sec. 2 and 3 respectively; the examples illustrated in the appendix clearly illustrates how BrowseMaster works.\n\n2. The proposed idea is very intuitive: to split the role of high-level planning and low-level execution, and to enable code interpreter as tool use for the executor.\n\n3. The proposed BrowseMaster-QA dataset is a valuable source for future search agent training with a large number of tool calls and complicated, multi-hop questions. The authors also proved that the agent finetuned on their dataset outperforms the agents finetuned on baseline datasets, which shows that the dataset can be extended to other future works."}, "weaknesses": {"value": "1. This work is a multi-agent work (as it features a planner-executor pair), but lacks discussion on the LLM multi-agent area as related works (the word \"multi-agent\" does not seem to appear in the manuscript). The idea of high-level planner and low-level executor is not new in multi-agent LLM frameworks; it is widely used in works such as LLM for complex reasoning [1] and decision-making tasks [2], and is even more common when the lower-level agent is not a LLM agent [3]. While this work applies such an idea onto the search-based task, I think it still misses some discussion on this topic. \n\n2. To expand the work into real-life applications, extensive efforts might be required to curate of the \"basic functions\", especially search in batches and filtering. This is because search results in real-life could be noisy, and may require more human labour to adapt to different types of return (html, xml, plain text etc.) and develop accurate filters for these results.\n\n3. The paper lacks details on the implementation of Supervised FineTuning (SFT) and deployment of the models, which lowers the reproducibility of the work. For example, Sec. 3.2 \"supervised fine-tuning\" only has a single paragraph; it does not mention anything on training details. While Sec. 4.1 mentions some configurations such as \"Qwen3-8B, 3 epochs, batch size 32 and maximum context length of 50000\", it still has many details missing, e.g., learning rate, optimizer, number of total gradient steps, GPU utilized, training (wall clock) time, etc. The paper also does not mention how the models are deployed - for example, line 738 mentioned about \"isolated execution environment with persistent memory\". Is this implemented via a docker, and what is the configuration for the memory? Is there any resources that the agent can utilize except for a python interpreter? What are the states for the \"stateful code execution sandbox\"?\n\n4. The paper does not explain what \"BrowseMaster-8B\" and \"BrowseMaster-R1\" in Tab. 1 is - does the former not involve any R1 for both the planner and the executor? If this is not the case, then the comparison against open-source agents might be unfair - R1 as a planner is much stronger than the other models no larger than 32B, let alone the doubled context length brought by the multi-agent system.\n\n**Minor Weakness**\n\n1. The caption of Fig. 1 is not informative; a brief introduction to the picture will better help readers to understand the work.\n\n2. The caption of Fig. 2 misses a period.\n\n**References**\n\n[1] A. Li et al. Agent-Oriented Planning in Multi-Agent Systems. In ICLR, 2025.\n\n[2] M. Geng et al. L2M2: A Hierarchical Framework Integrating Large Language Model and Multi-agent Reinforcement Learning. In IJCAI, 2025.\n\n[3] W. Tan et al. Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study. ArXiv:2403.03186, 2024."}, "questions": {"value": "I have several questions:\n\n1. Since the success of DeepSeek-R1, Reinforcement Learning (RL) has become very popular in post-training. Did the author try whether RL can improve the performance of the search agent?\n\n2. Why some results in Tab. 1 for baselines are missing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TPtVxZyVlP", "forum": "qr4d8S1Qpt", "replyto": "qr4d8S1Qpt", "signatures": ["ICLR.cc/2026/Conference/Submission2505/Reviewer_wGcb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2505/Reviewer_wGcb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2505/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761261342690, "cdate": 1761261342690, "tmdate": 1762916258686, "mdate": 1762916258686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BrowseMaster, a planner-executor approach for information seeking tasks. The framework adopts a two-agent planner-executor structure, where the executor is enhanced by predefined programmatic primitives for efficient and effective search. The authors also provide a BrowseMaster-QA dataset, which uses GLM4.5 to generate synthetic training data for challenging query-answer pairs. The proposed approach outperforms baselines across several benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed approach outperforms salient baselines such as WebSailor, WebThinker, WebDancer across the benchmarks.\n- The ablation study helps to understand the contribution of components.\n- The paper is clearly written and easy to follow."}, "weaknesses": {"value": "- The planner-actor hierarchy has been extensively explored in the agent space, and the paper misses the discussion of such planning-acting frameworks in web domains is missing [1,2,3]. \n- A distinction of the paper is the addition of programmatic search primitives for the executor, but the primitives are heuristically/manually defined, and this feels more like an engineering contribution than a research one. The ablations show that without the primitives, the performance of the proposed approach (11.0% accuracy on BrowseComp) is essentially same as the DeepSeek-R1-0528 baseline (8.9% accuracy), indicating that the performance relies heavily on these primitives.\n- The synthetic data generation involves a much larger and powerful GLM4.5 model, but results with this model are not reported, so it is unclear how much of the Executor-8B-SFT/BrowseMaster-8B results are due to data generation with a more powerful model.\n\n[1] Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks. Erdogan et al., ICML 2025\n\n[2] WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration. Zhang et al., AAAI 2025\n\n[3] SteP: Stacked LLM Policies for Web Actions. Sodhi et al., COLM 2024"}, "questions": {"value": "- Did the authors try training with a version of BrowseMaster-QA which does not leverage the difficulty enhancement? I'm curious whether the injecting the difficulty could make the tasks too ambiguous/ too out of distribution for realistic queries.\n- Could the authors discuss more the apparent synergy between the primitives and the planner? Without primitives, adding the planner increases performance marginally (9.5->11.0), but with primitives, the adding the planner doubles the performance (15.0->30.0).\n- Could the authors provide more details on the planner and executor prompts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1OMr7BN0mc", "forum": "qr4d8S1Qpt", "replyto": "qr4d8S1Qpt", "signatures": ["ICLR.cc/2026/Conference/Submission2505/Reviewer_AAiB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2505/Reviewer_AAiB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2505/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978104464, "cdate": 1761978104464, "tmdate": 1762916258287, "mdate": 1762916258287, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BrowseMaster, a  framework for LLM-based web browsing/search agents that separates high-level reasoning from low-level execution through a \"planner-executor agent pair\" design. The planner focuses on high-level reasoning and task decomposition. The executor conducts programmatic, tool-augmented searches using code primitives. Additionally, the paper also introduces BrowseMaster-QA, a dataset of complex multi-hop search questions synthesized through a two-stage agentic pipeline (task initialization + difficulty enhancement). Experiments across multiple benchmarks (BrowseComp, BrowseComp-zh, xBench-DeepSearch, WebWalkerQA) show substantial improvements over both open-source and proprietary agents like o1, Gemini 2.5 Pro."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Comprehensive evaluation & strong result: Results are competitive with or better than many open-source and closed-source baselines across English and Chinese benchmarks\n2. Dataset contribution: The BrowseMaster-QA dataset is a meaningful contribution that could be useful to the research community due  to its emphasis on long-horizon, reasoning-intensive search."}, "weaknesses": {"value": "1. Limited novelty: The idea of leveraging a planner and an executor has been quite common in multi-agent systems for computer use design. The only difference might be that the paper leverages code whereas existing work use other formats.\n2. Limited generalization: It's unclear how this code-use design generalizes to other cases beyond just search, like os-world tasks. It would be better if there's a diverse set of application domains being evaluated in the paper.\n3. More analysis: How does the proposed method scales wrt dataset size or model size, compute?"}, "questions": {"value": "1. How robust is the planner–executor communication to execution errors? Is the generated code always valid?\n2. Is there a metric/study showing that the task decomposition made by the planner make sense intuitively?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HoEYXcCwvu", "forum": "qr4d8S1Qpt", "replyto": "qr4d8S1Qpt", "signatures": ["ICLR.cc/2026/Conference/Submission2505/Reviewer_ePTc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2505/Reviewer_ePTc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2505/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987726602, "cdate": 1761987726602, "tmdate": 1762916257958, "mdate": 1762916257958, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a planner–executor architecture for web-browsing agents. The planner maintains long-horizon reasoning and delegates subtasks; the executor uses a stateful Python sandbox with predefined primitives to run batched web queries and filter results programmatically. A synthetic dataset with obfuscated constraints and uniqueness checks is used to supervise the executor. Experiments show improved performance over recent agentic baselines on BrowseComp and similar benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- the problem to study is very interesting and urgent, and will pontentially have significant impact. \n\n- introduction of a new benchmark that is potentially of further usage."}, "weaknesses": {"value": "- I have some major concerns regarding the novelty of the paper:\n   - the Planner–executor design is fairly standard in current agent literature. \n   - Code-based primitives also have already been extensively explored in prior agent work. \n   - thus the core innovation seems to be mainly about putting these things together, while it might be a significant efforts, probably not the best fit for this venue. \n\n- The empirical baseline also raise questions: the comparisons are mostly done to compare single agents of this area, if the proposed method is a multi-agent one, it will make more sense to compare with classical multi-agent system."}, "questions": {"value": "- expanding the empirical comparisons will be helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nlyqstg4xP", "forum": "qr4d8S1Qpt", "replyto": "qr4d8S1Qpt", "signatures": ["ICLR.cc/2026/Conference/Submission2505/Reviewer_WdBc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2505/Reviewer_WdBc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2505/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762062398758, "cdate": 1762062398758, "tmdate": 1762916257052, "mdate": 1762916257052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}