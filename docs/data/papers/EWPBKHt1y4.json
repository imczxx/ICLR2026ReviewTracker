{"id": "EWPBKHt1y4", "number": 14492, "cdate": 1758237165272, "mdate": 1759897367184, "content": {"title": "Hierarchical Molecular Representation Learning via Fragment-Based Self-Supervised Embedding Prediction", "abstract": "Graph self-supervised learning (GSSL) has demonstrated strong potential for generating expressive graph embeddings without the need for human annotations, making it particularly valuable in domains with high labeling costs such as molecular graph analysis. However, existing GSSL methods mostly focus on node- or edge-level information, often ignoring chemically relevant substructures which strongly influence molecular properties. In this work, we propose Graph Semantic Predictive Network (GraSPNet), a hierarchical architecture that predicts both node and semantically meaningful fragments of a graph in the embedding space. GraSPNet decomposes molecular graphs into meaningful fragments without relying on predefined chemical vocabulary and learns graph representations through message-passing graph neural networks. It further captures fragment-level semantics by encoding fragment information and modeling interactions through node-fragment and fragment-fragment message passing. By performing masked prediction of node and fragment features in semantic space, GraSPNet captures structural information at multiple resolutions. Experiments show that GraSPNet is both expressive and generalizable, outperforming existing state-of-the-art methods on multiple molecular property prediction benchmarks in transfer learning settings. The code will be released upon acceptance.", "tldr": "Self-supervised molecule graph representation learning through hierarchical fragment based embedding prediction", "keywords": ["Hierarchical Molecule representation learning", "fragment based", "Embedding prediction"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/95f90e89ed621fd1fbc0e73652d51a9c20ac26b6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors present GraSPNet (Graph Semantic Predictive Network), a hierarchical SSL framework for molecular representation learning, modeling semantically meaningful molecular fragments, allowing the network to capture hierarchical and chemically relevant substructures without relying on a predefined vocabulary.\nIt first decomposes molecular graphs into fragments, encodes them using message-passing GNNs, and models interactions between nodes and fragments through node-fragment and fragment-fragment message passing. GraSPNet employs masked embedding prediction at both node and fragment levels to jointly capture fine-grained and high-level semantic dependencies."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The introduction of both node- and fragment-level prediction enables multi-resolution representation learning, which is biologically and chemically intuitive.\n\n- To avoid predefined chemical substructures makes the approach flexible and domain-agnostic, Self-Supervised and Vocabulary-Free allow it to generalize across molecular datasets."}, "weaknesses": {"value": "- The idea of leveraging molecular fragments for hierarchical or semantic representation learning is not entirely new. Recent studies, such as GraphFG, S-CGIB, and other fragment- or motif-based molecular pretraining methods, have already explored similar directions.\n\n- While the empirical results are strong, there is no theoretical discussion about the expressive power of the proposed hierarchical GNN relative to existing architectures (e.g., WL hierarchy).\n\n- Both node- and fragment-level masked prediction could lead to overlapping learning signals; an ablation study is needed to disentangle their respective contributions."}, "questions": {"value": "- From a theoretical perspective, does GraSPNet offer higher expressive power than 1-WL GNNs? For instance, can fragment-level reasoning distinguish certain non-isomorphic molecular structures that node-level GNNs cannot?\n\n- How GraSPNet captures chemically meaningful substructures?\n\n- To me, the prediction task is somehow not related to the molecular graph structure preservation, as they are from different perspectives. It is difficult to say that the model could transfer the correct patterns well to downstream datasets. Is there any theoretical analysis or proof that a prediction task is sufficient for an SSL task (in both structural and semantic preservation)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J6c9zsUXt6", "forum": "EWPBKHt1y4", "replyto": "EWPBKHt1y4", "signatures": ["ICLR.cc/2026/Conference/Submission14492/Reviewer_Um5C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14492/Reviewer_Um5C"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760783421296, "cdate": 1760783421296, "tmdate": 1762924891236, "mdate": 1762924891236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GraSPNet (Graph Semantic Predictive Network), a framework that addresses the neglect of chemical substructures in existing graph self-supervised learning methods. It uses a fragmentation technique to decompose molecules into rings, paths, and articulation points, constructing a multi-level graph structure. GraSPNet employs a self-supervised task similar to MAE, masking nodes and fragments, and predicts their embeddings using a context encoder."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The model achieves state-of-the-art or near-state-of-the-art performance on several challenging molecular property prediction benchmarks, particularly in transfer learning settings, demonstrating the effectiveness of its pretraining strategy and strong generalization ability.\n\n2. The model explicitly models information transfer between atom-fragment and fragment-fragment, enabling it to capture higher-level chemical semantics that standard GNNs may overlook."}, "weaknesses": {"value": "1. The fragmentation strategy is a fixed decomposition method based on heuristic rules. It remains unclear whether this decomposition approach is optimal for all downstream tasks. For example, some tasks may require substructure partitions with different granularities or types. Simply applying this method of partitioning could potentially disrupt the information carried within the molecular graph.\n\n2. The \"fragment-based\" approach is not novel; utilizing substructures or motifs to enhance molecular graph representation learning has long been an established research direction in cheminformatics and graph machine learning.\n\n3. Masking data at the fragment level directly could potentially disrupt the semantics represented by the data. After all, the premise of contrastive learning is to ensure that the semantics to be learned in the positive samples remain unchanged."}, "questions": {"value": "1. Could you explain whether the fragmentation approach used is reasonable and preserves the molecular property features?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "83n2FqwRrO", "forum": "EWPBKHt1y4", "replyto": "EWPBKHt1y4", "signatures": ["ICLR.cc/2026/Conference/Submission14492/Reviewer_rAXs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14492/Reviewer_rAXs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786181218, "cdate": 1761786181218, "tmdate": 1762924890760, "mdate": 1762924890760, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents GraSPNet, a hierarchical self-supervised framework for molecular graphs. It decomposes molecules into rings, paths, and articulation points as semantic fragments and jointly predicts node- and fragment-level embeddings through dual-channel message passing (node→fragment and fragment→fragment). Experiments on MoleculeNet benchmarks show consistent gains over prior self-supervised methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Programmatic Fragmentation Strategy:** The model partitions molecules into structural subgraphs (rings, paths, articulation points) through a deterministic graph algorithm, ensuring reproducibility without predefined vocabularies.\n\n2. **Hierarchical Message Passing:** The dual-channel design captures both local atomic and global fragment semantics.\n\n3. **Comprehensive Experiments:** Evaluated on 8 classification and 3 regression benchmarks, showing consistent performance gains over GraphCL, GraphMAE, and MGSSL."}, "weaknesses": {"value": "1. **Limited Novelty:** The core idea of hierarchical molecular representation has been explored in [1][2][3], and similar fragment-based or hierarchical pretraining exists. GraSPNet mainly integrates known techniques (fragment-level modeling + masked prediction + hierarchical GNN).\n\n2. **Heuristic Fragment Extraction:** Although the method avoids chemical vocabularies, it still depends on hand-crafted structural heuristics (rings, paths, articulation points). A comparison with functional groups [4] or principal subgraph mining [5] is missing.\n\n3. **Insufficient Analysis of Chemical Validity:** There is no visualization or quantitative evidence showing that extracted fragments correspond to meaningful chemical motifs.\n\nReferences\n\n[1] Li, Yuquan. Learning Hierarchical Interaction for Accurate Molecular Property Prediction. (2025).\n[2] Jin, Wengong, Regina Barzilay, and Tommi Jaakkola. Hierarchical Generation of Molecular Graphs Using Structural Motifs. ICML, 2020.\n[3] Luong, Kha-Dinh, and Ambuj K. Singh. Fragment-Based Pretraining and Finetuning on Molecular Graphs. NeurIPS 36 (2023): 17584–17601.\n[4] Chen, Fangying, Junyoung Park, and Jinkyoo Park. A Molecular Hyper-Message Passing Network with Functional Group Information. arXiv:2106.01028 (2021).\n[5] Kong, Xiangzhe, et al. Molecule Generation by Principal Subgraph Mining and Assembling. NeurIPS 35 (2022): 2550–2563.\n[6] Zhang, Yikun, et al. Atomas: Hierarchical Adaptive Alignment on Molecule-Text for Unified Molecule Understanding and Generation. ICLR 2025."}, "questions": {"value": "1. Could the authors integrate a **learned principal-subgraph** extraction mechanism (as in PS-VAE [5]) instead of fixed heuristics to enhance adaptability?\n\n2. How does GraSPNet’s hierarchy differ from Atomas [6], which also performs automatic atom→fragment→molecule decomposition?\n\n3. Have the authors analyzed the **distribution or diversity** of extracted fragments to ensure chemical representativeness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mVwAkzXnVK", "forum": "EWPBKHt1y4", "replyto": "EWPBKHt1y4", "signatures": ["ICLR.cc/2026/Conference/Submission14492/Reviewer_NHXX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14492/Reviewer_NHXX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877280664, "cdate": 1761877280664, "tmdate": 1762924890228, "mdate": 1762924890228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GraSPNet, a novel self-supervised learning framework for molecular graphs that learns hierarchical representations by jointly predicting node and fragment-level embeddings. The goal is to improve molecular property prediction (for downstream tasks). This is done by capturing semantically rich pre-defined substructures (e.g., rings, paths, articulation points) during pretraining. Authors have shown that their proposed fragmentation strategy can effectively capture richer semantics, which will later be used for training their model."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1-\tThe paper proposed a novel approach to capture both node and fragment-level semantics. The proposed GraSPNet architecture introduces a dual-level semantic prediction mechanism, which is underexplored in graph self-supervised learning (GSSL).\n2-\tThe proposed fragmentation strategy looks promising. Moreover, the WL-test example in Figure 2 clearly demonstrates how fragment-level abstraction helps distinguish structurally similar but semantically distinct molecules. This is a strong theoretical motivation.\n3-\tAuthors have conducted an inclusive ablation study with respect to fragmentation. They have tested with and without fragmentation to demonstrate the effect of their proposed fragmentation strategy. Moreover, they have evaluated different fragmentation strategies to study the effectiveness of their proposed method compared to MGSSL, S-CGIB, and HiMOL methods."}, "weaknesses": {"value": "1-\tThe baselines are outdated. Especially the graph contrastive learning methods. Here a list of GCL methods that have been published more recently and outperform current baselines:\nGRACE: Zhu, Y., Xu, Y., Yu, F., Liu, Q., Wu, S., & Wang, L. (2020). Deep graph contrastive representation learning. arXiv preprint arXiv:2006.04131.\nGCA: Zhu, Y., Xu, Y., Yu, F., Liu, Q., Wu, S., & Wang, L. (2021, April). Graph contrastive learning with adaptive augmentation. In Proceedings of the web conference 2021 (pp. 2069-2080).\nGREET: Liu, Y., Zheng, Y., Zhang, D., Lee, V. C., & Pan, S. (2023, June). Beyond smoothing: Unsupervised graph representation learning with edge heterophily discriminating. In Proceedings of the AAAI conference on artificial intelligence (Vol. 37, No. 4, pp. 4516-4524).\nEPAGCL: Xu, Y., Huang, S., Zhang, H., & Li, X. (2025, April). Why does dropping edges usually outperform adding edges in graph contrastive learning?. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 39, No. 20, pp. 21824-21832).\n2-\tThe authors have not included any analysis of training or inference cost as the graph size increases. Fragment graphs can become large and dense, but memory/runtime implications are not discussed.\n3-\tThe paper needs an additional round of proofreading. There are several grammatical errors:\na.\tLine 069: “at three semantic levels—node (atoms), fragment (e.g., functional groups)” -> “at three semantic levels: node (atoms), fragment (e.g., functional groups)”\nb.\tLine 182: GNNS -> GNNs\nc.\tLine 187: “can be more powerful than 2-WL test in distinguish graph isomorphic.\" -> “can be more powerful than the 2-WL test in distinguishing graph isomorphisms.”\nd.\tLing 265: “to each nodes and fragments” -> “to each node and fragment”\ne.\tLine 811: “The code will be release upon acception.” -> “The code will be released upon acceptance.”"}, "questions": {"value": "a.\tHow do different fragmentation rules contribute to performance? It would be interesting to have an ablation study comparing different fragmentation schemes (e.g., rings-only, no articulation)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1Gvlu7sAwn", "forum": "EWPBKHt1y4", "replyto": "EWPBKHt1y4", "signatures": ["ICLR.cc/2026/Conference/Submission14492/Reviewer_duzi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14492/Reviewer_duzi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762463558282, "cdate": 1762463558282, "tmdate": 1762924889871, "mdate": 1762924889871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}