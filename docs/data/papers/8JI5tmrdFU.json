{"id": "8JI5tmrdFU", "number": 6320, "cdate": 1757967897805, "mdate": 1759897922365, "content": {"title": "Focus on Likely Classes for Test-Time Prediction", "abstract": "We ask: Does focusing on classes predicted as likely improve model predictions? We aim for an affirmative answer by proposing two novel test-time fine-tuning methods to improve uncertain model predictions. Instead of greedily selecting the most likely class, we introduce an additional step, focus on the likely classes, to refine predictions. By applying a single gradient descent step with a large learning rate, we refine predictions when an initial forward pass indicates high uncertainty. This aligns predictions more closely with the ideal of assigning zero probability to less plausible outcomes. The experimental evaluation demonstrates accuracy gains for one of our methods on average, which emphasizes shared features among likely classes, across diverse text and image domain models.", "tldr": "", "keywords": ["test-time computing", "fine-tuning", "reflection", "reasoning"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/704ed52f2d4695da8950780e5acd8720292a1673.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a test-time fine-tuning approach designed to improve model predictions under uncertainty. Their method encourages the model to focus on the most likely classes in order to refine its outputs. Concretely, they introduce two complementary strategies: doFo (Decrease Out-of-Focus), which suppresses the logits of unlikely classes, and iFo (Increase Focus), which amplifies the logits of likely ones. Extensive experiments across diverse datasets and architectures—covering both text generation and image recognition tasks—demonstrate the effectiveness and generality of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors conduct extensive experiments across multiple models and datasets on both text and image tasks to validate the effectiveness of doFo and iFo, demonstrating the comprehensiveness of their evaluation.\n2. Figure 1 and Figure 2 effectively illustrate the core ideas and workflow of the proposed approach, making the methodology easy to understand for readers."}, "weaknesses": {"value": "1. In the field of test-time adaptation, there exists a related approach called PASLE [1], which partitions data into confident and uncertain subsets—assigning one-hot labels to confident samples and candidate label sets to uncertain ones. Its mechanism of assigning 1 to likely classes and 0 to unlikely ones is conceptually similar to the authors’ strategy of “focusing on the likely classes.” However, this prior work is not discussed or compared in the paper. I recommend the authors include a discussion and experimental comparison with PASLE to clarify the novelty and advantage of their method.\n2. The experimental section lacks comparisons with any baseline methods, which makes it difficult to assess the absolute performance of the proposed approach. The authors are encouraged to identify and include several relevant methods from the literature for empirical comparison, especially from adjacent domains such as test-time adaptation.\n3. The manuscript contains several overly long paragraphs that affect readability. The authors are advised to split long paragraphs into shorter ones to improve clarity, logical flow, and overall presentation quality.\n\n[1] Selective Label Enhancement Learning for Test-Time Adaptation. ICLR 2025"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o1bm0k77E0", "forum": "8JI5tmrdFU", "replyto": "8JI5tmrdFU", "signatures": ["ICLR.cc/2026/Conference/Submission6320/Reviewer_tKs6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6320/Reviewer_tKs6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6320/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761363524101, "cdate": 1761363524101, "tmdate": 1762918615557, "mdate": 1762918615557, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies whether focusing on likely classes can improve model predictions during test time. The authors introduce two simple fine-tuning strategies—iFo (increasing focus) and doFo (decreasing out-of-focus)—that apply one gradient descent step only when the model shows high uncertainty (measured by the top-1/top-2 probability gap). iFo aims to enhance shared features among likely classes, while doFo suppresses unlikely ones. Experiments across 70+ model-dataset pairs (vision and language) show that iFo consistently improves accuracy, while doFo often does not."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Novel yet simple idea – The “focus on likely classes” concept is intuitive and differs from classical entropy minimization or confidence-based TTA.\n\nThe method is tested on diverse image (CNNs/ViTs) and text (GPT-2, LLaMA-3, Gemma-3, etc.) models, showing broad empirical coverage.\n\nOnly one gradient step and per-sample adaptation make the method computationally efficient."}, "weaknesses": {"value": "Although the paper cites Tent and related works, it does not directly compare with them in experiments (e.g., Tent, TTT++, CoTTA, etc.). As a test-time method, more quantitative comparisons with test-time adaptation approaches would strengthen claims.\n\nThe reported gains are relatively modest (e.g., +0.1–0.3%), which raises concerns about their practical significance. While the aggregated metrics (mean, standard deviation, and p-values) provide some support, they are not entirely convincing. In this context, comparisons with direct most-likely-class-based approaches such as Tent and ReCap [Region Confidence Proxy for Wild Test-Time Adaptation, ICML 2025] would be particularly important to better demonstrate the method’s advantage."}, "questions": {"value": "How does the proposed method perform on out-of-distribution (OOD) datasets (e.g., ImageNet-Corruption), which are commonly used for evaluating test-time learning approaches?\n\nMore detailed and clearer ablation studies analyzing the effectiveness of iFo and doFo would also be preferred."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8LLCd8TcoF", "forum": "8JI5tmrdFU", "replyto": "8JI5tmrdFU", "signatures": ["ICLR.cc/2026/Conference/Submission6320/Reviewer_moFk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6320/Reviewer_moFk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6320/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761888359592, "cdate": 1761888359592, "tmdate": 1762918614837, "mdate": 1762918614837, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes two test-time fine-tuning methods, Increasing outputs for Focus classes (iFo) and Decreasing outputs of Out-of-Focus classes (doFo), to improve predictions on uncertain samples by focusing on likely classes via a single large-step gradient descent. An uncertainty assessment based on probability differences triggers optimization only when needed. Theoretical analysis highlights how iFo amplifies shared features among likely classes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Efficient single-step optimization with large LR approximates multi-step results, minimizing computational overhead.\n2. Comprehensive evaluation across diverse models (e.g., ViTs, ResNets, LLMs like GPT-2, Llama) and datasets (ImageNet, OpenWebText, etc.), demonstrating consistent gains for iFo (e.g., up to 2.2% on WideResNet).\n3. Ablations on hyperparameters (LR, uncertainty threshold, iterations) and comparisons (e.g., input tuning) provide thorough insights.\n4. Practical applicability: No auxiliary tasks or source data needed, works on pre-trained models."}, "weaknesses": {"value": "1. Main concern: The method's primary motivation and approach seem to have appeared in prior TTA work [1] (Selective Label Enhancement Learning for Test-Time Adaptation, ICLR); authors need to further explain and strengthen the novelty and advantages of their method.\n\n2. Images should be optimized for display and layout, preferably using vector graphics.\n\n3. Some typos exist, e.g., line 266 has an extra \".\"."}, "questions": {"value": "1. Can the method integrate with existing TTA techniques (e.g., entropy minimization) for further gains?\n\n2. What architectural factors (e.g., transformers vs. CNNs) influence gains, and why?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PDgxEF1e2n", "forum": "8JI5tmrdFU", "replyto": "8JI5tmrdFU", "signatures": ["ICLR.cc/2026/Conference/Submission6320/Reviewer_utqt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6320/Reviewer_utqt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6320/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995849434, "cdate": 1761995849434, "tmdate": 1762918614433, "mdate": 1762918614433, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes test-time fine-tuning to improve uncertain predictions by focusing on likely classes. When uncertainty is high (difference between top-2 probabilities less than 0.16), two methods are applied: (1) iFo increases outputs of focus classes by maximizing their weighted logits, and (2) doFo decreases outputs of unlikely classes by minimizing their average logits. Single gradient step with large learning rate modifies logits. Evaluated on 70+ model-dataset pairs (ImageNet with CNNs/ViTs, 6 LLMs on 6 text corpora), iFo shows consistent 1-2% improvements while doFo fails."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Simple and Practical**: Elegantly simple - single gradient step on logits when uncertainty is high. Uncertainty measure (difference between top two probabilities) requires no calibration. Architecture-agnostic with easy implementation (code in Appendix B.2). Requires only one extra forward-backward pass.\n\n**Broad Evaluation**: 70+ model-dataset pairs across vision (ImageNet on ResNet/DenseNet/EfficientNet/MobileNet/ViT) and language (GPT-2, Llama, QWEN, Fox-1, StableLM, Gemma on diverse corpora). Output spaces range 1K-100K+ classes. Honest reporting of doFo failures adds credibility."}, "weaknesses": {"value": "**Limited Novelty**: Test-time gradient adaptation is established in TTA/domain adaptation. Main distinction (multiple likely classes vs. single class) is incremental. No comparison with existing TTA methods (Tent, TTT, MEMO) or calibration methods (temperature scaling, Platt scaling). Single-step optimization is a practical trick, not a conceptual advance.\n\n **Modest Gains Without Context**: Consistent 1-2% improvements but missing: (a) wall-clock time overhead measurements, (b) comparison with simple baselines (ensembles, calibration), (c) whether gains justify deployment complexity, (d) failure rate analysis - what percentage worsen? Figure 6 aggregates results without showing variance or per-sample effects."}, "questions": {"value": "Please refer to the Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F3clvFPI6o", "forum": "8JI5tmrdFU", "replyto": "8JI5tmrdFU", "signatures": ["ICLR.cc/2026/Conference/Submission6320/Reviewer_qYqW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6320/Reviewer_qYqW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6320/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001379793, "cdate": 1762001379793, "tmdate": 1762918614061, "mdate": 1762918614061, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}