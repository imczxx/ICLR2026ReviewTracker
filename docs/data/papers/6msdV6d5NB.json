{"id": "6msdV6d5NB", "number": 12000, "cdate": 1758205138019, "mdate": 1759897540263, "content": {"title": "Semantic Data Inflation: Adaptive Augmentation for Contrastive Representation Learning", "abstract": "Self-supervised representation learning requires semantically meaningful data augmentations to learn effective features. However, current augmentation strategies either disrupt semantic structures or risk semantic drift. We present Semantic Data Inflation (SDI), a novel framework inspired by the human visual system that leverages explicit semantic guidance from pre-trained models to enhance representation quality. SDI extracts multi-level semantic cues to create consistent augmented views while maintaining critical object identities. Our multi-scale adaptive mechanism dynamically selects optimal semantic extraction strategies based on image characteristics, ensuring robust performance across diverse conditions. Extensive experiments demonstrate that SDI consistently outperforms baseline and generative methods across multiple contrastive learning frameworks, achieving state-of-the-art results in self-supervised classification. On ImageNette, our approach reaches 95.75% linear evaluation accuracy, surpassing standard (+3.88%) and generative (+3.65%) methods. Further analysis confirms SDI produces more discriminative features with improved semantic consistency. Our code is available at https://anonymous.4open.science/r/Semantic-Data-Inflation-8D7D/", "tldr": "A novel semantic-guided data augmentation framework that improves contrastive learning by preserving object identity while maximizing feature diversity.", "keywords": ["contrastive learning", "semantic data augmentation", "self-supervised learning", "representation learning", "multi-scale"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/75e15e869bab1577913102df0c5ca952849bafef.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new approach to data augmentation within the contrastive learning framework. Unlike the widely used methods that rely on predefined transformations or generative models, the proposed approach employs deterministic models such as YOLO and SAM for detection and segmentation. This design enables data-adaptive transformations and produces more reliable outputs compared to conventional generative approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The main strength of this paper lies in its originality and balance between flexibility and reliability. If no similar work has been previously published, the idea itself is quite innovative and promising. The proposed approach takes advantage of task-specific deterministic models to guide data augmentation, which could indeed offer a meaningful alternative to generative methods. In addition, the numerical experiments show consistent improvements in both performance and auxiliary metrics, such as running efficiency and out-of-domain generalization. These results support the potential of the method in practical applications."}, "weaknesses": {"value": "However, I find two important weaknesses in the paper. The first concerns the theoretical analysis in Section 4.2 and the additional proofs presented in the appendix. This part is unclear and lacks rigor. It is not evident what the main theoretical claim is or why such analysis is necessary. For example, the claim that a larger mutual information value results from the assumption “semantic-guided augmentation preserves more semantic content” (line 723) is problematic. The notion of “semantic content” is not formally defined, making the argument vague and not mathematically rigorous, as the authors suggest in line 215. As a result, this section adds little theoretical value and even weakens the paper’s logical foundation.\n\nThe second weakness is that the usefulness of the proposed approach appears to depend heavily on the choice of the detection or segmentation model. Different underlying models may lead to different transformations and hence very different performance outcomes. This sensitivity should be systematically investigated to establish the robustness of the proposed framework. While I appreciate that the authors partially acknowledge this limitation, placing it only in the “Limitations” section is insufficient. A thorough empirical analysis on how the choice of model influences the results is essential to strengthen the paper’s contribution."}, "questions": {"value": "I have no further questions about the paper. Please address the second weakness I mentioned above, as a more comprehensive study on the dependency of the approach on model selection would make the work more convincing. I would be happy to adjust the score if the authors can provide additional evidence showing that the proposed approach has been sufficiently investigated beyond simple performance evaluation.\n\nLLM Usage Disclosure:\nThis review was refined using a large language model (OpenAI GPT-5) to improve clarity and grammar. The assessment, analysis, and opinions expressed are entirely my own."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Cyhk67fC5o", "forum": "6msdV6d5NB", "replyto": "6msdV6d5NB", "signatures": ["ICLR.cc/2026/Conference/Submission12000/Reviewer_rYyY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12000/Reviewer_rYyY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12000/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761638547860, "cdate": 1761638547860, "tmdate": 1762922992040, "mdate": 1762922992040, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers data augmentation strategies for contrastive representation learning. This work proposes an adaptive augmentation strategy by employing pretrained detection/segmentation models and generate augmentations based on their outputs to better preserve semantic consistency. Experimental results show the effectiveness of the proposed methods on image datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ Data augmentation for contrastive representation learning is an important topic.\n\n+ The proposed method sounds interesting, and the performance gain is consistent throughout experiments."}, "weaknesses": {"value": "- What is Raw Duplication? It requires explanation. Does it mean that all positive pairs have identical inputs?\n\n- The description on the proposed method is insufficient. Figure 3 is not enough to fully understand the proposed method. What are \"Multi-scale adaptive mechanism\", \"Segmentic guided Augmentation\", and \"Semantic Feature Enhancement\"? \n\n- The proposed policy introduces hyperparameters, while no hyperparameter analysis on them is provided.\n\n- The theoretical analysis seems not so related to the proposed method, and the statement is not justified. For example, the claim in L246, \"semantic guidance reduces the conditional entropy of the original representation given the augmented one\" is not justified. Considering out-of-domain transfer learning, the pretrained model might lack sufficient domain knowledge for target tasks.\n\n- Experiments are limited to small image datasets; for example, ImageNette has only 10 classes. Hence, it is not sure if the observation is scalable.\n\n- No out-of-domain transfer learning results, which is crucial for representation learning.\n\n- If handcrafted augmentations are experimented on CPU following the standard deep learning library implementations, then the authors might want to try GPU-based augmentation with libraries such as Kornia for a more fair comparison, particularly around Figure 5."}, "questions": {"value": "Please address concerns in Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wsk0nqESiT", "forum": "6msdV6d5NB", "replyto": "6msdV6d5NB", "signatures": ["ICLR.cc/2026/Conference/Submission12000/Reviewer_97FG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12000/Reviewer_97FG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12000/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932863973, "cdate": 1761932863973, "tmdate": 1762922991577, "mdate": 1762922991577, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "I think this work tackles a problem in contrastive learning: current augmentations are either fast but semantically \"blind,\" creating \"false positives\" , or generative, which are slow and can cause \"semantic drift\" . So the authors propose Semantic Data Inflation (SDI), which is a  solution that uses existing models like YOLO and SAM as semantic oracles to guide augmentations to ensure the main object is always preserved . What I find most important is its multi-scale adaptive mechanism, which they try to first analyze image quality and then dynamically chooses between coarse bounding boxes (for low-quality images) or precise segmentation masks (for high-quality images) . So I think this method proves effective, and they also outperform baselines while being 4-5x faster than generative methods. The resulting features also show generalization to new domains and ViT architectures"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I think the primary strength is the simple solution to the \"false positive\" problem. Using off-the-shelf models as \"semantic oracles\" is an effective way to achieve both semantic consistency and computational efficiency . In my opinion, the multi-scale adaptive mechanism selects guidance granularity based on image quality, a design that is justified by the ablation studies in Table 7. This design is backed by  several results. The authors also show the performance gains with a +3.8-4.1% average on ImageNette (Table 2). Finally, I think the method's practicality is a plus: it's 4-5x faster than generative alternatives and it generalizes well to ViT architectures and other downstream tasks like object detection."}, "weaknesses": {"value": "Here are some major limitations after reading this paper.\n\nIn my opinion, the first weakness is that the entire framework is dependent on the quality of the upstream semantic oracles. If YOLO or SAM fail to find an object (maybe it's a class they weren't trained on, or the image is too abstract), then SDI would presumably fail as well. It's transferring semantic understanding, not learning it. I wonder if the author could elaborate this with several analysis? what if the image is complex which has multi-object composition.\n\nI think while it's much faster than generative models, it's still more computationally expensive than the standard augmentation pipeline. It requires an extra forward pass from a powerful model like YOLO or SAM for each image. Table 1 shows it's about 2-3x slower than the standard augmentation. I just wonder if this training scheme is actually needed during the large-scale training. I think the authors should have more analysis related to this effect instead of just showing the average time difference."}, "questions": {"value": "Please see the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8hpNmBRyGZ", "forum": "6msdV6d5NB", "replyto": "6msdV6d5NB", "signatures": ["ICLR.cc/2026/Conference/Submission12000/Reviewer_MWNm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12000/Reviewer_MWNm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12000/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762069723676, "cdate": 1762069723676, "tmdate": 1762922991272, "mdate": 1762922991272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Semantic Data Inflation (SDI) addresses the “semantic consistency–efficiency–diversity” trilemma in self-supervised contrastive learning. SDI first leverages off-the-shelf detection/segmentation models (e.g., YOLO and SAM) to extract multi-scale semantic cues, then applies transformations within these “semantic protection zones,” and uses an image-quality-weighted adaptive mechanism to choose among detection-level, segmentation-level, or mixed-level operations. The authors report that SDI outperforms manual augmentations and generative data inflation across various contrastive frameworks and datasets (e.g., achieving 95.75% linear evaluation on ImageNette, a +3.88% improvement over standard augmentation), and demonstrates modest gains across domains, architectures, and downstream detection/segmentation tasks. Overall, SDI is a systematic engineering integration of “semantics-guided data augmentation,” emphasizing improved semantic fidelity and representation discriminability without significantly increasing training overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. decouples “semantic extraction — enhancement within semantics — adaptive selection,” making it easy to integrate into existing contrastive learning frameworks.\n\n2. shows consistent gains across multiple frameworks (SimCLR, MoCo, BYOL, Barlow) on datasets like ImageNette; provides transfer results to ViT-S, small-scale downstream detection/segmentation, and medical imaging.\n\n3. positioned as a lightweight alternative to diffusion-based data inflation, avoiding the high overhead and semantic drift risks of generative methods (with reasonable justification).\n\n4. Some interpretability: offers intuition from mutual information/invariance perspectives, and formalizes “adaptive scale selection” in the appendix."}, "weaknesses": {"value": "1. he rationalization mainly relies on mutual information and tightening inequalities, with limited novelty; the relationship to hard negatives and in-batch distribution in practical training is not thoroughly explored. Compared with systematic baselines guided by “saliency/self-supervised segmentation features/other semantic priors,” the comparisons are insufficient; the main contribution novelty lies in engineering integration and heuristic/empirical strategies.\n\n2. lacks pretraining validation at mainstream scales such as ImageNet-1k; systematic evaluation and failure-case analysis for more complex scenarios (multi-object, heavy occlusion, small objects) are not sufficient.\n\n3.  heavily depends on detectors/segmenters trained on large-scale labeled data, introducing supervised priors; the paper under-discusses whether comparisons against SSL baselines that do not rely on external models are fair, and whether there are risks of data overlap/information leakage.\n\n4. the appendix formulates the selection strategy as a learnable policy, but the implementation in the main text appears heuristic, lacking end-to-end learning and results on stability/generalization. It is recommended to supplement empirical results and ablations for the “learned policy.”"}, "questions": {"value": "- Has your adaptive selection been truly trained end-to-end? Please report comparisons against heuristic thresholds, the stability of learned α, β, γ, and cross-dataset/architecture transfer performance.\n\n- How do you control fairness and potential leakage from external model priors? Please specify their overlap with pretraining/evaluation data, and how performance degrades when replaced with weaker or cross-domain models.\n\n- Please supplement ImageNet-1k scale pretraining and systematic evaluations in more complex scenarios (multi-object/occlusion/small objects), along with visualizations of failure cases.\n\n- Can you provide sensitivity curves to upstream errors (e.g., by modulating YOLO/SAM confidence/recall) and the corresponding robustness strategies (multi-candidate fusion/confidence gating)?\n\n- Can the theory section further integrate analyses of hard negatives and in-batch distributions to explain SDI’s concrete impact on InfoNCE training dynamics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h5gBOkwP9X", "forum": "6msdV6d5NB", "replyto": "6msdV6d5NB", "signatures": ["ICLR.cc/2026/Conference/Submission12000/Reviewer_EdeE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12000/Reviewer_EdeE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12000/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762098676193, "cdate": 1762098676193, "tmdate": 1762922990769, "mdate": 1762922990769, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}