{"id": "YByrzVSK9S", "number": 6465, "cdate": 1757985949717, "mdate": 1763639371037, "content": {"title": "Last Layer Logits to Logic: Empowering LLMs with Logic-Consistent Structured Knowledge Reasoning", "abstract": "Large Language Models (LLMs) achieve excellent performance in natural language reasoning tasks through pre-training on vast unstructured text, enabling them to understand the logic in natural language and generate logic-consistent responses. However, the representational differences between unstructured and structured knowledge make LLMs inherently struggle to maintain logic consistency, leading to *Logic Drift* challenges in structured knowledge reasoning tasks such as Knowledge Graph Question Answering (KGQA).\nExisting methods address this limitation by designing complex workflows embedded in prompts to guide LLM reasoning. Nevertheless, these approaches only provide input-level guidance and fail to fundamentally address the *Logic Drift* in LLM outputs. Additionally, their inflexible reasoning workflows cannot adapt to different tasks and knowledge graphs.\nTo enhance LLMs' logic consistency in structured knowledge reasoning, we specifically target the logits output from the autoregressive generation process. We propose the *Logits-to-Logic* framework, which incorporates logits strengthening and logits filtering as core modules to correct logical defects in LLM outputs. Extensive experiments show that our approach significantly improves LLMs' logic consistency in structured knowledge reasoning and achieves state-of-the-art performance on multiple KGQA benchmarks.", "tldr": "This paper presents Logits-to-Logic, a novel output-perspective approach addressing the Logic Drift of large language models (LLMs) in structured knowledge reasoning, with deeper insights into maintaining logic-consistent reasoning in LLMs.", "keywords": ["Large Language Models", "Structured Knowledge", "Logic Drift", "Logic-Consistent Reasoning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e2beaa8648f260517f1fbf3bda8fe57a2287d024.pdf", "supplementary_material": "/attachment/1e6adf8efe90361b3e26731d1c8dda38b5549c17.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a decoding-time framework to reduce logic drift when LLMs reason over knowledge graphs. The framework includes multiple stages, like compiling legal KG paths into NFAs for ranking, and modifying the last-layer logits via \"strengthening\" and \"filtering\". Experiments report gains on several KBQA benchmarks across KGs and tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Presents a clear motivation and introduces an interesting approach to mitigate logical inconsistencies in LLM reasoning over structured KG on output-side logit corrections rather than only prompt-level guidance\n2. The proposed method is model-agnostic and can be plugged into any decoder without retraining\n3. The use of NFAs to model KG paths and constrain decoding is a clever way to improve path validity\n4. Extensive ablation studies and visualizations that help to illustrate the impact of core modules"}, "weaknesses": {"value": "1.The evaluation suite relies mostly on older KGQA datasets. This limits the external validity of the SOTA claim and may underrepresent contemporary KG schemas and LLM-era challenges. \n2. Several mathematical derivations need to be clarified: the overall objective in Sec. 3.2 treats Pθ,q and Pθ,G as independent without justification; Sec. 3.2.2 states “we calculate the difference between original and masked outputs” but Eq. for Dq is a convex combination, not a difference; in Sec. 3.2.3, the filtering equation sets δ as 0/1 but z are logits (not probabilities), therefore setting δ({art,award})=0 at the logit level does not forbid tokens, potentially allowing probability mass leakage. \n3. Prior work on constrained decoding with FSAs/tries and KG-constrained generation should be thoroughly discussed.\n4. Compiling full KGs into NFAs (Sec. 3.2.1) could be computationally prohibitive for large-scale KGs like Wikidata, raising concerns about the approach's scalability. Complexity with respect to number of candidate paths, tokens per label, and beam size should be analyzed. \n5. The method performs SFT with 1/10 of training data from CWQ and WebQSP \"to teach the model correct path output format\" -- I wonder if this brings an unfair advantage over the agentic reasoning baselines that do not include SFT."}, "questions": {"value": "1. The paper cites \"constrained decoding\" in section 3.2.2, but it should be \"contrastive decoding.\"\n2. How is the sentence-transformer chosen and tuned for scoring NFA paths - why not use the LLM itself for consistency?\n3. How is MASK token handled in prompts— what exactly is masked (top-1 path only or top-K?), how long is the masked span, and how do you align time steps between original and masked runs?\n4. Logits strengthening should require two forward passes (original vs masked) per decoding step; yet Table 6 lists “1 LLM call per question.” Can you explain this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "30GdF6LIhb", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_nnUp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_nnUp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761515330963, "cdate": 1761515330963, "tmdate": 1762918854648, "mdate": 1762918854648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Logits-to-Logic, a framework to address Logic Drift in LLMs in the scenario of KGQA. The core innovation is targeting the logits distribution in LLMs’ autoregressive output process to align it with the logical constraints of KGs and question semantics. To achieve this goal, paths are used to filter tokens not in KG and keep consistent of the LLM logits with semantic and structure information."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is the first KGQA method that considers output-level control that corrects LLM outputs by manipulating logits.\n2. The results look promising in a few benchmarks. It adapts to different KGs and tasks (multi-hop QA, slot filling).\n3. The form of displaying results is good, where multiple different kinds of figures are used to show results."}, "weaknesses": {"value": "1. The information in Figure 1 is not clear. \"current approaches\" is very vague. I cannot get which methods and datasets are tested.\n2. The \"logic\" formulated in this paper mainly depends on paths, not true logics. Along with this problem, the novelty of this paper is a concern where there are many path-based methods like RoG (Luo et. al.). The authors should have a separate subsection in related works to discuss methods lie in this type.\n3. Based on the results in Figure 2, the main technique that works is $Z_f$, which serves as a filter that masks the logits of tokens that are not in the searched paths. So I wonder whether the NFA is still needed or just an approach for story telling.\n4. It seems that this method is quite expensive. For LLaMA3.1-8B model, it takes two A800 GPUs to compute in parallel for inference. The computing time is also not well compared.\n5. The layout of figures and tables in this paper is in chaos. Like Figure 2 is mentioned before  Figure 1. Table 4 lies in Section 4.6, which mainly discusses results in Figure 4.\n\nMinor issues:\n- The caption of Figure 3 is called \"overview of our framework\", while part (a) seems not the proposed method.\n- The concept of \"acceptable path\" is not well defined.\n- The range of $\\omega$ is not clear."}, "questions": {"value": "1. Please discuss the difference between logic drift and hallucination.\n2. In Table 4, why bigger model (Qwen2-1.5B) can be much weak than Qwen2-0.5B in WebQSP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EJuxHaU8A5", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_EXWb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_EXWb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620327771, "cdate": 1761620327771, "tmdate": 1762918854302, "mdate": 1762918854302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposes a novel framework, Logits-to-Logic, to enhance teh logical reasoning capabilities of LLM when applied to KGs. The main problem tackled by this manuscript is that LLM struggle with Logic Drift, where their reasoning paths often do not align with the logical structure of the KG, leading to errors in structured knowledge reasoning. \n\nThe authors propose Logits-to-Logic, a framework that directly operate on the logits output by the LLM during their autoregressive generation. Logits-to-Logic consists logic compiling, logits trenghthening, logits filtering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The manuscript addresses the issue of logic drift by directly intervening in the logits.\n+ Extensive experiments show significant improvements.\n+ The framework demonstrates significant computational efficiency"}, "weaknesses": {"value": "- Evaluation mainly focus on LLaMa and Qwen model. Other foundation models or larger models are not validated due to resource constraints. It would benefit analyzing how the framework scales with larger models.\n- Although the class-agnostic loss helps prevent overfitting to specific classes, the overall framework may stil struggle with class imbalance or biased training samples\n- The framework relies heavily on the predefined hyperparameters for the loss terms. While the paper show an empirical study on these values, further dynamic or adaptive tuning methodology may benefit the flexibility of the framework."}, "questions": {"value": "Please refer weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EefzjJxdev", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_nv8o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_nv8o"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761626859818, "cdate": 1761626859818, "tmdate": 1762918853970, "mdate": 1762918853970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a knowledge graph question answering method based on large language models (LLMs). When using LLMs to answer knowledge graph (KG) questions, they sometimes generate paths that do not exist in the KG or produce incorrect paths, leading to wrong answers. To address this, the authors propose aligning the logits of the LLM output with the logical structure of the knowledge graph to ensure the generated answers are faithful. Experimental results show that the proposed method outperforms existing state-of-the-art approaches.\n\nHowever, the paper is somewhat difficult to understand, particularly because it lacks an introductory section or preliminary knowledge, making it challenging for readers to assess its contributions. Moreover, the contribution appears somewhat incremental.\n\nI will try to review the paper again during the rebuttal period, so I hope the authors can provide sufficient information at that time."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The idea of aligning the logits of LLM outputs with knowledge graph logic to ensure that LLM outputs follow KG information is interesting. However, the idea is somewhat difficult to understand. LLM outputs are probability distributions over tokens, while in a KG, an entity name or relation may consist of multiple words. It is unclear how this mapping is performed.\n\nThe experimental results are promising, but in Table 1, only Hit@1 is reported; F1 scores are not provided. It would be better to include the F1 scores for all baseline methods for a more comprehensive comparison."}, "weaknesses": {"value": "The paper lacks an introduction to preliminary knowledge, which makes it difficult to understand and to assess the true contributions. Moreover, the contribution seems somewhat incremental.\n\nNo example is provided in the paper. It would be helpful to include a complete example that illustrates the entire process, from beginning to end, to facilitate understanding."}, "questions": {"value": "no"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "CtgdfIHuve", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_bu9C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_bu9C"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942843076, "cdate": 1761942843076, "tmdate": 1762918853674, "mdate": 1762918853674, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Official Comment by Authors"}, "comment": {"value": "# To all reviewers\n\nWe would like to express our sincere gratitude to all the reviewers for their thoughtful and constructive feedback on our submission. We genuinely appreciate the time and effort invested in helping us refine our work. We are also delighted that **our Logits-to-Logic approach is recognized for its interesting nature in aligning LLM logits with knowledge graph logic to ensure faithful answer generation** (reviewer bu9C), **novel approach to address logic drift through direct logits intervention with significant improvements and computational efficiency** (reviewer nv8o), being **the first KGQA method to consider output-level control through logits manipulation with promising results across multiple benchmarks and diverse tasks** (reviewer EXWb), and **clear motivation with model-agnostic nature that can be plugged into any decoder without retraining** (reviewer nnUp).\n\nWe believe Logits-to-Logic will make a highly impactful contribution to the KGQA field. Unlike existing methods that design complex agent-based workflows or prompt engineering to provide only input-level guidance, our framework addresses the fundamental Logic Drift problem from the output perspective by directly manipulating LLMs' last-layer logits. Our core innovation lies in identifying that Logic Drift stems from inconsistency between LLMs' output logits distributions and the logical distributions of structured KG and question intent. Through our two-stage approach—Logits Strengthening and Logits Filtering using Non-deterministic Finite Automaton (NFA)—we provide deeper insights into logic-consistent reasoning while maintaining excellent flexibility and transferability across different tasks and KGs without modifications.\n\nOur detailed responses address individual queries and suggestions from each reviewer, covering the following major categories of issues:\n\n**1.Background and Technical Clarification**: We provided comprehensive background on KGQA, detailed mathematical derivations with formal proofs (Reviewer bu9C, nnUp), clarified the necessity of NFA beyond narrative purposes, explained our logic concept encompassing both question semantic logic and KG structural logic (Reviewer EXWb), and thoroughly discussed existing path-based approaches and KG-constrained generation methods to better position our work in the literature (Reviewer EXWb, nnUp).\n\n**2.Experimental Validation and Scalability**: We supplemented F1 score comparisons alongside Hit@1 metrics (Reviewer bu9C), conducted experiments on additional model series including Microsoft, Mistralai, and Internlm with larger parameter models up to 14B (Reviewer nv8o), and provided comprehensive computational complexity analysis for large-scale KG compilation (Reviewer nnUp).\n\n**3.Methodological Robustness**: We clarified that our framework is training-free with only one hyperparameter $\\omega$, addressed concerns about class imbalance by explaining our SFT is only for output format learning without introducing prior knowledge (Reviewer nv8o), and demonstrated effectiveness through extensive ablation studies showing both Logits Strengthening and Filtering contribute significantly to performance (Reviewer EXWb).\n\n**4.Evaluation Comprehensiveness**: We addressed dataset currency concerns by demonstrating our evaluation covers the most extensive and commonly used KGQA benchmarks including both Freebase and Wikidata-based datasets (Reviewer nnUp), and provided detailed computational overhead comparisons showing substantial advantages in LLM API calls and costs compared to existing agentic methods (Reviewer EXWb).\n\n**5.Implementation Details and Efficiency**: We provided detailed analysis of computational overhead showing minimal additional GPU usage and running time (Reviewer EXWb), conducted comprehensive overhead analysis for NFA construction demonstrating feasibility on large-scale KGs (Reviewer nnUp), clarified the MASK token handling process and forward pass counting methodology (Reviewer nnUp), and corrected mathematical expressions and formatting issues throughout the paper.\n\nOnce again, we thank all reviewers for their invaluable suggestions and insights, which have significantly contributed to the improvement of our paper. Please feel free to reach out if further clarification is required to assist in the final assessment."}}, "id": "LtxVvPujzI", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Authors"], "number": 16, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763620108924, "cdate": 1763620108924, "tmdate": 1763620108924, "mdate": 1763620108924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}