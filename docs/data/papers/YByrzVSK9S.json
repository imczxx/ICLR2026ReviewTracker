{"id": "YByrzVSK9S", "number": 6465, "cdate": 1757985949717, "mdate": 1759897912750, "content": {"title": "Last Layer Logits to Logic: Empowering LLMs with Logic-Consistent Structured Knowledge Reasoning", "abstract": "Large Language Models (LLMs) achieve excellent performance in natural language reasoning tasks through pre-training on vast unstructured text, enabling them to understand the logic in natural language and generate logic-consistent responses. However, the representational differences between unstructured and structured knowledge make LLMs inherently struggle to maintain logic consistency, leading to *Logic Drift* challenges in structured knowledge reasoning tasks such as Knowledge Graph Question Answering (KGQA).\nExisting methods address this limitation by designing complex workflows embedded in prompts to guide LLM reasoning. Nevertheless, these approaches only provide input-level guidance and fail to fundamentally address the *Logic Drift* in LLM outputs. Additionally, their inflexible reasoning workflows cannot adapt to different tasks and knowledge graphs.\nTo enhance LLMs' logic consistency in structured knowledge reasoning, we specifically target the logits output from the autoregressive generation process. We propose the *Logits-to-Logic* framework, which incorporates logits strengthening and logits filtering as core modules to correct logical defects in LLM outputs. Extensive experiments show that our approach significantly improves LLMs' logic consistency in structured knowledge reasoning and achieves state-of-the-art performance on multiple KGQA benchmarks.", "tldr": "This paper presents Logits-to-Logic, a novel output-perspective approach addressing the Logic Drift of large language models (LLMs) in structured knowledge reasoning, with deeper insights into maintaining logic-consistent reasoning in LLMs.", "keywords": ["Large Language Models", "Structured Knowledge", "Logic Drift", "Logic-Consistent Reasoning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8ab85d88f95d38125b75f0b47011ab00924b7b51.pdf", "supplementary_material": "/attachment/1e6adf8efe90361b3e26731d1c8dda38b5549c17.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a decoding-time framework to reduce logic drift when LLMs reason over knowledge graphs. The framework includes multiple stages, like compiling legal KG paths into NFAs for ranking, and modifying the last-layer logits via \"strengthening\" and \"filtering\". Experiments report gains on several KBQA benchmarks across KGs and tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Presents a clear motivation and introduces an interesting approach to mitigate logical inconsistencies in LLM reasoning over structured KG on output-side logit corrections rather than only prompt-level guidance\n2. The proposed method is model-agnostic and can be plugged into any decoder without retraining\n3. The use of NFAs to model KG paths and constrain decoding is a clever way to improve path validity\n4. Extensive ablation studies and visualizations that help to illustrate the impact of core modules"}, "weaknesses": {"value": "1.The evaluation suite relies mostly on older KGQA datasets. This limits the external validity of the SOTA claim and may underrepresent contemporary KG schemas and LLM-era challenges. \n2. Several mathematical derivations need to be clarified: the overall objective in Sec. 3.2 treats Pθ,q and Pθ,G as independent without justification; Sec. 3.2.2 states “we calculate the difference between original and masked outputs” but Eq. for Dq is a convex combination, not a difference; in Sec. 3.2.3, the filtering equation sets δ as 0/1 but z are logits (not probabilities), therefore setting δ({art,award})=0 at the logit level does not forbid tokens, potentially allowing probability mass leakage. \n3. Prior work on constrained decoding with FSAs/tries and KG-constrained generation should be thoroughly discussed.\n4. Compiling full KGs into NFAs (Sec. 3.2.1) could be computationally prohibitive for large-scale KGs like Wikidata, raising concerns about the approach's scalability. Complexity with respect to number of candidate paths, tokens per label, and beam size should be analyzed. \n5. The method performs SFT with 1/10 of training data from CWQ and WebQSP \"to teach the model correct path output format\" -- I wonder if this brings an unfair advantage over the agentic reasoning baselines that do not include SFT."}, "questions": {"value": "1. The paper cites \"constrained decoding\" in section 3.2.2, but it should be \"contrastive decoding.\"\n2. How is the sentence-transformer chosen and tuned for scoring NFA paths - why not use the LLM itself for consistency?\n3. How is MASK token handled in prompts— what exactly is masked (top-1 path only or top-K?), how long is the masked span, and how do you align time steps between original and masked runs?\n4. Logits strengthening should require two forward passes (original vs masked) per decoding step; yet Table 6 lists “1 LLM call per question.” Can you explain this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "30GdF6LIhb", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_nnUp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_nnUp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761515330963, "cdate": 1761515330963, "tmdate": 1762918854648, "mdate": 1762918854648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Logits-to-Logic, a framework to address Logic Drift in LLMs in the scenario of KGQA. The core innovation is targeting the logits distribution in LLMs’ autoregressive output process to align it with the logical constraints of KGs and question semantics. To achieve this goal, paths are used to filter tokens not in KG and keep consistent of the LLM logits with semantic and structure information."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is the first KGQA method that considers output-level control that corrects LLM outputs by manipulating logits.\n2. The results look promising in a few benchmarks. It adapts to different KGs and tasks (multi-hop QA, slot filling).\n3. The form of displaying results is good, where multiple different kinds of figures are used to show results."}, "weaknesses": {"value": "1. The information in Figure 1 is not clear. \"current approaches\" is very vague. I cannot get which methods and datasets are tested.\n2. The \"logic\" formulated in this paper mainly depends on paths, not true logics. Along with this problem, the novelty of this paper is a concern where there are many path-based methods like RoG (Luo et. al.). The authors should have a separate subsection in related works to discuss methods lie in this type.\n3. Based on the results in Figure 2, the main technique that works is $Z_f$, which serves as a filter that masks the logits of tokens that are not in the searched paths. So I wonder whether the NFA is still needed or just an approach for story telling.\n4. It seems that this method is quite expensive. For LLaMA3.1-8B model, it takes two A800 GPUs to compute in parallel for inference. The computing time is also not well compared.\n5. The layout of figures and tables in this paper is in chaos. Like Figure 2 is mentioned before  Figure 1. Table 4 lies in Section 4.6, which mainly discusses results in Figure 4.\n\nMinor issues:\n- The caption of Figure 3 is called \"overview of our framework\", while part (a) seems not the proposed method.\n- The concept of \"acceptable path\" is not well defined.\n- The range of $\\omega$ is not clear."}, "questions": {"value": "1. Please discuss the difference between logic drift and hallucination.\n2. In Table 4, why bigger model (Qwen2-1.5B) can be much weak than Qwen2-0.5B in WebQSP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EJuxHaU8A5", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_EXWb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_EXWb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620327771, "cdate": 1761620327771, "tmdate": 1762918854302, "mdate": 1762918854302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposes a novel framework, Logits-to-Logic, to enhance teh logical reasoning capabilities of LLM when applied to KGs. The main problem tackled by this manuscript is that LLM struggle with Logic Drift, where their reasoning paths often do not align with the logical structure of the KG, leading to errors in structured knowledge reasoning. \n\nThe authors propose Logits-to-Logic, a framework that directly operate on the logits output by the LLM during their autoregressive generation. Logits-to-Logic consists logic compiling, logits trenghthening, logits filtering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The manuscript addresses the issue of logic drift by directly intervening in the logits.\n+ Extensive experiments show significant improvements.\n+ The framework demonstrates significant computational efficiency"}, "weaknesses": {"value": "- Evaluation mainly focus on LLaMa and Qwen model. Other foundation models or larger models are not validated due to resource constraints. It would benefit analyzing how the framework scales with larger models.\n- Although the class-agnostic loss helps prevent overfitting to specific classes, the overall framework may stil struggle with class imbalance or biased training samples\n- The framework relies heavily on the predefined hyperparameters for the loss terms. While the paper show an empirical study on these values, further dynamic or adaptive tuning methodology may benefit the flexibility of the framework."}, "questions": {"value": "Please refer weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EefzjJxdev", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_nv8o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_nv8o"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761626859818, "cdate": 1761626859818, "tmdate": 1762918853970, "mdate": 1762918853970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a knowledge graph question answering method based on large language models (LLMs). When using LLMs to answer knowledge graph (KG) questions, they sometimes generate paths that do not exist in the KG or produce incorrect paths, leading to wrong answers. To address this, the authors propose aligning the logits of the LLM output with the logical structure of the knowledge graph to ensure the generated answers are faithful. Experimental results show that the proposed method outperforms existing state-of-the-art approaches.\n\nHowever, the paper is somewhat difficult to understand, particularly because it lacks an introductory section or preliminary knowledge, making it challenging for readers to assess its contributions. Moreover, the contribution appears somewhat incremental.\n\nI will try to review the paper again during the rebuttal period, so I hope the authors can provide sufficient information at that time."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The idea of aligning the logits of LLM outputs with knowledge graph logic to ensure that LLM outputs follow KG information is interesting. However, the idea is somewhat difficult to understand. LLM outputs are probability distributions over tokens, while in a KG, an entity name or relation may consist of multiple words. It is unclear how this mapping is performed.\n\nThe experimental results are promising, but in Table 1, only Hit@1 is reported; F1 scores are not provided. It would be better to include the F1 scores for all baseline methods for a more comprehensive comparison."}, "weaknesses": {"value": "The paper lacks an introduction to preliminary knowledge, which makes it difficult to understand and to assess the true contributions. Moreover, the contribution seems somewhat incremental.\n\nNo example is provided in the paper. It would be helpful to include a complete example that illustrates the entire process, from beginning to end, to facilitate understanding."}, "questions": {"value": "no"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "CtgdfIHuve", "forum": "YByrzVSK9S", "replyto": "YByrzVSK9S", "signatures": ["ICLR.cc/2026/Conference/Submission6465/Reviewer_bu9C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6465/Reviewer_bu9C"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6465/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942843076, "cdate": 1761942843076, "tmdate": 1762918853674, "mdate": 1762918853674, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}