{"id": "OPZ2f3MnrQ", "number": 18933, "cdate": 1758292109218, "mdate": 1759897072166, "content": {"title": "Weight Clipping for Robust Conformal Inference under Unbounded Covariate Shifts", "abstract": "Conformal prediction (CP) provides powerful, distribution-free prediction sets, but its guarantees rely on the exchangeability of training and test data, which is often violated in practice due to covariate shifts. While weighted conformal prediction (WCP) is designed to handle such shifts, it can suffer from significant undercoverage when the density ratio between the distributions is unbounded and/or must be learned. This is because of both overfitting in learning the density ratio, and high variance in estimating the nonconformity score threshold. To address this, we introduce clipped least-squares importance fitting (CLISF) as a reduced-variance method for density ratio estimation. Specifically, we show that density ratios learned using CLISF, when plugged into WCP, have bounded expected undercoverage. Furthermore, we show that the undercoverage can be corrected by running WCP with a slightly inflated coverage target; crucially, we are able to estimate the required level of inflation from the data. We provide the first theoretical guarantees for weight clipping in conformal inference, achieving dataset-conditional coverage with a sample complexity that does not blow up with the higher moments of the true density ratio---a key limitation of prior work. We verify our results on real-world benchmarks and synthetic data.", "tldr": "", "keywords": ["conformal prediction", "covariate shift", "weight clipping", "uncertainty quantification", "importance weighting"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/480b0d57b2bb2a2c4824163e9aa545d08dcede8f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses a critical failure mode of WCP, which is used to provide valid prediction intervals under covariate shift.  WCP becomes unstable and can suffer from significant undercoverage  (but also overcoverage) when the true density ratio between the source and target distributions is unbounded or must be learned from data, leading to high-variance estimates. The authors propose Clipped Weighted Conformal Prediction (CWCP). The method consists of two main parts: 1) Clipped Least-Squares Importance Fitting (CLISF): Instead of learning an unbounded density ratio, they learn a ratio that is explicitly clipped at a threshold $B$, which introduces biases but reduces the variance of the estimator. 2) The authors provide a method to estimate the bias $\\Delta_B$ introduced by this clipping directly from the data. They then correct for this bias by running WCP with a slightly inflated coverage target $1 - \\alpha - \\Delta_B$. The key contribution is providing theoretical guarantees for this weight-clipping approach. They prove that CWCP achieves dataset-conditional coverage with a sample complexity that, crucially, does not depend on the higher moments of the true density ratio."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Addresses a Significant and Practical Problem:** The key contribution is providing theoretical guarantees for this weight-clipping approach. They prove that CWCP achieves dataset-conditional coverage with a sample complexity that, crucially, does not depend on the higher moments of the true density ratio.\n2. **Elegant Core Idea:** The idea of clipping weights is intuitive, and while it has been proposed already (implicitly or explicitly) in many WCP-related works, the paper's strength lies in formalizing it into a complete framework. The ability to estimate the clipping-induced bias and use it to correct the coverage level is a strong and elegant contribution, even if the underlying theory has limitations.\n3. **Novel Theoretical Analysis:** The core theoretical achievement is deriving PAC-style guarantees for a clipped importance weighting scheme that circumvents the dependence on the higher moments of the true density ratio. This directly addresses the primary failure mode of standard WCP."}, "weaknesses": {"value": "1. **Reliance on a Cascade of Unrealistic and Problematic Assumptions:** The paper's theoretical guarantees are built on a foundation of assumptions that are individually and collectively problematic for practical application.\n    1. **Unrealistic \"No Misspecification\" Assumption (Assumption 4):** The main theorems assume the true density ratio w* is perfectly contained within the chosen model class W $(\\Delta_R = 0)$. This \"realizability\" assumption is almost never true in practice, yet this primary source of error is assumed away for \"simplicity,\" making the final guarantees appear stronger than they would be in reality.\n    2. **Circular Logic and Arbitrary Constants in Bias Assumptions:** The theory requires the clipping bias $\\Delta_B \\leq 1/2$ (Assumption 3) and the learning error $\\epsilon \\leq 1/4$ (Theorem 3). These are presented as fixed preconditions, but both $\\Delta_B$ and $\\epsilon$ are unknown outcomes of the modeling process. This creates a circular dependency and relies on arbitrary constants, turning critical preconditions into unverifiable a posteriori checks.\n    3. **Comparison with dTV:** I’m asking myself, after all this complex theoretical machinery, have we actually gained anything practical over just using split conformal and accepting some degradation, or using a simpler correction based on a single assumption (which you don’t evaluate in your experiments)?\n2. **Insufficient and Potentially Misleading Experimental Evaluation:** The experiments fail to provide a complete picture of the method's practical utility.\n    1. **Unfair Baseline Comparisons:** The paper compares CWCP, which has stronger dataset-conditional (PAC) guarantees, against methods like standard WCP that only provide weaker marginal guarantees. This is an \"apples-to-pears\" comparison that makes CWCP appear more stable by design, without comparing it to other methods that offer similar PAC-style guarantees.\n    2. **Missing Critical Metrics:** The evaluation focuses exclusively on coverage, ignoring the \"efficiency\" of the prediction sets (i.e., their average size or width). Without this, it is impossible to know if the method achieves coverage by producing usefully tight intervals or trivially large ones. This is particularly concerning given the risk of over-correction.\n    3. **Incomplete Ablation Study:** The ablation study only varies the clipping parameter B, ignoring the many other critical (and difficult to set) modeling choices, such as the choice of the function class $W$.\n    4. **Suboptimal Visualization:** The empirical CDF plots used to show coverage distribution are difficult to interpret. Standard visualizations like box plots or violin plots would communicate the variance and central tendency of the coverage much more clearly.\n3. **Example 1:** I find it a bit weird that you say the problem is not that theoretical; however, you proceed with a highly artificial example to show that the generalization bound fails when the error has higher moments.\n4. **Practical Barriers to Implementation:** The combination of several challenges limits the method's off-the-shelf usability\n    1. the non-convex nature of the CLISF optimization problem;\n    2. the lack of a concrete, data-driven procedure for selecting the critical hyperparameter;\n    3. the assumption of a continuous score CDF, which is presented as standard but often fails to hold in practice;\n    4.  the risk that the bias correction term becomes so large that it results in trivially large, uninformative prediction sets."}, "questions": {"value": "- **Baselines & Fairness:** Why did you not compare against other methods that also provide dataset-conditional guarantees? Furthermore, what value of δ was used for your method's implementation in the experiments?\n- **Efficiency Metrics & Trivial Sets:** Could you provide results on the average prediction set size for all methods in your experiments? This is crucial for understanding whether CWCP provides meaningful, efficient prediction sets. Did you observe any instances in your experiments where the correction term $\\Delta_B + 5\\epsilon$ was large enough to cause the target quantile to exceed 1, leading to these uninformative sets?\n- **Ablation Studies:** Can you comment on the sensitivity of your method to the choice of the function class $W$? An ablation study showing the impact of model misspecification would significantly strengthen the paper's practical claims.\n- **Theoretical Assumptions:** Your main theorems assume no model misspecification $(\\Delta_R =0)$. Could you provide the full statement of Theorem 3 where the guarantee explicitly depends on $\\Delta_R $? The guarantee in Theorem 3 depends on several assumptions with fixed constants ($\\Delta_B \\leq 1/2, \\epsilon \\leq 1/4$), but these quantities are unknown in practice. Could you comment on the choice to use fixed constants rather than stating the bounds in terms of these error parameters directly?\n- **PAC-boundry:** maybe I missed it but could you state explicitly that you use PAC-boundry to enable training conditional coverage guarantes and that this is already worked out and formalized by Park et al. (2021) and Pournaderi and Xiang (2024) under coveriate shift.\n- Some minor remarks:\n    - line 046: “*First, unbounded ratios lead to high-variance estimates of the coverage threshold and reduce the “effective sample size” (Tibshirani et al., 2019).”*\n        - note that every deviation form the uniform weights will reduce the effective sample size\n    - line 964;: state maybe ERM in full first\n    - line 297: “*Our analysis relies on a standard assumption in conformal prediction, that the CDF of the nonconformity scores to be continuous.”* Is it really? I don’t think so."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9JqrUR1lZG", "forum": "OPZ2f3MnrQ", "replyto": "OPZ2f3MnrQ", "signatures": ["ICLR.cc/2026/Conference/Submission18933/Reviewer_wftD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18933/Reviewer_wftD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760537018437, "cdate": 1760537018437, "tmdate": 1762930922512, "mdate": 1762930922512, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address extreme density ratio weights in weighted conformal prediction (WCP), the authors proposed a weight clipping method by bounding the weight by a pre-specified constant $B$."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well-written. Formulas and notation are well-typed and shaped nicely. Experiments are designed well and the presentations are very clear."}, "weaknesses": {"value": "I acknowledge the theoretical investigations, efforts and contributions by the authors. This work is publishable given its **practical novelty.** However, at least at this time point, I don't think ICLR is a reasonable choice for this work, since I believe the novelty is not at a fundamental level that can bring much interest for future research. The contribution is instead minor for addressing an existing but less important issue. \n\nOverall, the impression of the paper to me is like modifying the implementation details of the density ratio weighting, instead of focusing on a novel setting or new problem. The techniques used in this paper are also not too novel. The clipping or stabilizing ideas are pretty common, such as propensity score trimming and truncation when addressing extreme inverse probability weights in treatment effect estimation (see [1--3]). \n\nFurthermore, while extreme weights may theoretically exist, I question whether the proposed method can fully address this issue. Consider a case where two populations are systematically different and share no overlap in their covariate or outcome distributions. In such a scenario, it is impossible to construct valid prediction intervals through density ratio weighting, as the true density ratio becomes infinite or extremely large. This raises the question of whether WCP remains meaningful under such circumstances. Moreover, clipping the weights inevitably introduces bias, since it imposes artificial bounds where the true weights are unbounded. I suspect some form of bounded weight or compact covariate support assumption must already be implicit in the validity of WCP, which makes it unclear why weight clipping is treated as a remedy rather than as a fundamental regularity condition.\n\nThat said, I encourage the authors to provide rebuttals to my comments, as there may be some misunderstandings on my part. If the authors believe they can provide a strong case about the following aspects of their work, I am open to change my score and assessment: (i) the high novelty on techniques they used for weight clipping; (ii) the wide applicability and potential impact of this work in ML and statistics community as well as social/medical/other applications; (iii) no bias is principally introduced by weight clipping. If you believe these can be well addressed, please also consider my below other comments in rebuttal. \n\n**Other comments**\n\n- In simulated experiment, it looks like the covariates shift only considered the mean shift by beta parameter, but the variance/covariance has no shift? It may not be necessary (if you can justify your choice) but could also be interesting to have some supplemental results on varying the covariance parameter as well. \n\n- The split conformal method does not account for covariate shift, so it is expected to perform poorly and produce biased results in your setting. I suggest emphasizing more clearly that its poor performance is expected rather than surprising. Although you briefly mention this point, it could be stated more explicitly. The reason I make this suggestion is that it may be somewhat unfair to treat this method as a direct competitor since it relies on stronger assumptions that are violated in your setup. However, it is still useful to include it for illustration (to demonstrate that methods ignoring covariate shift indeed fail in such scenarios). You just need to clarify that its inclusion is for illustrative purposes, not as a competing benchmark. As an analogy, in line 457 you wrote, “We did not evaluate LR-QR, as W was not compatible with the linear structed assumed in Joshi et al. (2025).” So you shouldn't be self-contracted by what you want and do not want to compare. (A side note: “structed” appears to be a typo and should be “structure.”)\n\n- A follow-up point for split-conformal: while it is biased, its prediction efficiency is really high from the SDs of emipircal coverage rates. Please discuss why and is there a bias-variance trade-off between your method and split-conformal. When covariates shift is moderate or small, would split-conformal actually be a better practical alternative? \n\n- Equation (4),  should the $\\delta$ actually be small? If it is not too small, it doesn't seem the coverage is guarantee at a high probability and it is not meaningful. \n\n- The statement of Assumption 3 may need some modification, \"The bias is not too large\" sounds vague and subjective. How large is large? \n\n- Are Assumptions 3 and 4 strong in practice, especially Assumption 4 which does not even allow misspecification? I understand such condition could even be necessary in this type of problems and it is okay, I don't expect you relax it for this work, but is there any sensitivity analysis type argument, quantification for the bias by the misspecification or plain language justifications? \n\n**References**\n\n[1] Crump, Richard K., et al. \"Moving the goalposts: Addressing limited overlap in the estimation of average treatment effects by changing the estimand.\" (2006).\n\n[2] Ma, Xinwei, and Jingshen Wang. \"Robust inference using inverse probability weighting.\" Journal of the American Statistical Association 115.532 (2020): 1851-1860.\n\n[3] Ju, Cheng, Joshua Schwab, and Mark J. van der Laan. \"On adaptive propensity score truncation in causal inference.\" Statistical methods in medical research 28.6 (2019): 1741-1760."}, "questions": {"value": "No additional question to add here. See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YVvfe5RCqc", "forum": "OPZ2f3MnrQ", "replyto": "OPZ2f3MnrQ", "signatures": ["ICLR.cc/2026/Conference/Submission18933/Reviewer_Nxh1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18933/Reviewer_Nxh1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760568582126, "cdate": 1760568582126, "tmdate": 1762930921339, "mdate": 1762930921339, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper is well-written, easy to read and follow the ideas.\n\nProblem context: Conformal prediction methods guarantee coverage under the assumption of exchangeability between training and test data. However, this assumption often fails under covariate shift. While Weighted Conformal Prediction (WCP) reweights calibration samples using estimated density ratios, it can perform poorly when these ratios are unbounded or inaccurately estimated, leading to high variance and under-coverage.\n\nProposal: The authors propose Clipped Least-Squares Importance Fitting (CLISF) and the corresponding Clipped Weighted Conformal Prediction (CWCP) framework. The main idea is to clip the learned density ratios at a threshold $B$ to reduce variance and stabilize conformal prediction under unbounded or heavy-tailed shifts. \n\nTheoretical results: The paper provides the finite-sample coverage guarantees for conformal prediction using clipped importance weights. Specifically, the authors derive (i) an $L_2$-generalization bound for the clipped density ratio estimator, (ii) a concentration result for estimating the clipping bias $\\Delta_B$, and (iii) dataset-conditional and expected coverage guarantees for CWCP with sample complexity.\n\nMethodology: The approach consists of three stages: (1) learning a clipped density ratio via CLISF over a bounded class $\\mathcal{W}_B$, (2) estimating the clipping bias $\\Delta_B$ from data, and (3) running weighted conformal prediction with a slightly inflated target coverage level $1 - \\alpha + \\widehat{\\Delta}_B$. Theoretical bounds rely on Rademacher complexity, weighted DKW inequalities, and standard uniform convergence tools.\n\n\nExperiment: Empirical results on synthetic and real-data settings validate the theoretical results.\n\nOverall, the paper makes a technically solid contribution by providing a principled theoretical foundation for weight clipping in conformal prediction. While the core idea is conceptually simple and based on existing heuristics, the analysis is rigorous and insightful."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, though mathematically dense, but the authors have taken care to elaborate on the key ideas underlying all theoretical results, making the technical content accessible.\n\n2. The problem paper tackles is of significant practical importance. It provides a rigorous theoretical treatment of the clipping heuristics commonly used for stabilizing importance weights in conformal prediction frameworks under distribution shift."}, "weaknesses": {"value": "1.  While the theoretical analysis elegantly characterizes the bias-variance trade-off governed by the clipping parameter $B$, and the paper may discuss strategies, the empirical validation appears to rely on evaluating $B$ over a fixed grid.\n\n2. The proposed Clipped Least-Squares Importance Fitting (CLISF) procedure is based on the $L_2$-optimal objective of the standard LSIF. The subsequent theoretical results, particularly the generalization bounds (e.g., Theorem 1 on $L_2$ error), inherently rely on the well-established properties of this objective and its connection to Rademacher complexity for the chosen function class $\\mathcal{W}$."}, "questions": {"value": "1. Do the paper's core finite-sample, dataset-conditional coverage guarantees rely specifically on the CLISF (i.e., the $L_2$-optimal) density ratio estimation procedure, or are the theoretical results (Theorem 2) general enough to accommodate other clipped density ratio estimators? Would it require a complete re-derivation of the generalization bounds based on the new objective function or perhaps with minor modifications?\n\n2. The paper reports coverage results. Beyond validity, how does the clipping parameter $B$ influence the expected size of the resulting prediction sets? Is there a principled way to select $B$ that balances the need for low clipping bias ($\\Delta_B$) with the desire for small prediction set size?\n\n3.  Can the authors empirically validate a practical procedure for selecting $B$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P3E7Hp7pFU", "forum": "OPZ2f3MnrQ", "replyto": "OPZ2f3MnrQ", "signatures": ["ICLR.cc/2026/Conference/Submission18933/Reviewer_QaPK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18933/Reviewer_QaPK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620815215, "cdate": 1761620815215, "tmdate": 1762930920065, "mdate": 1762930920065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes clipped least-squares importance fitting to address the issue of unbounded likelihood ratio in conformal prediction under covariate shift. Experiments on classification and regression demonstrate the effectiveness of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Extensive theoretical analysis is presented in section 3 to prove the resultant coverage guarantee by the proposed approach.\n\n2. Both classification and regression tasks prove the outperformance of the work.\n\n3. Discussion of choosing proper parameter B in Section 4.3 is insightful."}, "weaknesses": {"value": "1. 30 trials in Figure 1 seems insufficient with quite unsmooth CDFs.\n\n2. A figure presenting Example 1 can intuitively show the issue of unbounded ratio.\n\n3. Notations are used without introduction, such as \\hat{w} in Line 48."}, "questions": {"value": "1. Localized conformal prediction [1] aims to provide conditional coverage guarantee given X=x, and it also relies on density estimation. Can your work extend to that topic? 2. Can you explain in Line 179-180 the equation about \\triangle B when B =1.\n\n[1]Guan, Leying. \"Localized conformal prediction: A generalized inference framework for conformal prediction.\" Biometrika 110.1 (2023): 33-50."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "saiUneDBJ5", "forum": "OPZ2f3MnrQ", "replyto": "OPZ2f3MnrQ", "signatures": ["ICLR.cc/2026/Conference/Submission18933/Reviewer_888h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18933/Reviewer_888h"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096907862, "cdate": 1762096907862, "tmdate": 1762930919202, "mdate": 1762930919202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}