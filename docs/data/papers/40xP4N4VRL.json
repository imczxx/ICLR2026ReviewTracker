{"id": "40xP4N4VRL", "number": 21553, "cdate": 1758318895388, "mdate": 1761174013754, "content": {"title": "Causal Judge Evaluation (CJE): Auditable, Unbiased Off-Policy Metrics for LLM Systems via Design-by-Projection", "abstract": "**Causal Judge Evaluation (CJE)** recasts offline “LLM-as-judge” evaluation as calibrated off-policy estimation. For a candidate policy \\\\( \\\\pi' \\\\), the target is \\\\( V(\\\\pi') = E[Y(\\\\pi')] \\\\). From logs \\\\( (X,A,S) \\\\) under \\\\( \\\\pi_0 \\\\) we compute sequence-level ratios \\\\( W_{\\\\pi'} = \\\\pi'(A\\\\mid X)/\\\\pi_0(A\\\\mid X) \\\\) via teacher forcing. CJE applies one rule—**Design-by-Projection (DbP)**: encode justified knowledge as a closed convex set and project a valid object onto it: (i) calibrate rewards \\\\( R = f(S) \\\\) by a mean-preserving monotone map; (ii) stabilize ratios via a unit-mean, \\\\( S \\\\)-monotone projection (**SIMCal-W**); (iii) use nuisance-orthogonal estimating equations (OC-IPS / DR-CPO / TMLE-style targeting); and (iv) minimize variance by convex stacking in influence-function space. A **Knowledge–Riesz** result shows that intersecting the admissible IF class with justified convex knowledge preserves the estimand and weakly lowers the attainable variance; with cross-fitting, the resulting estimators attain the **surrogate information bound**. On Arena-derived logs (n = 4,989; five policies), SIMCal-W turns near-degenerate weights into stable ones (ESS: \\\\(0.6\\\\% \\\\to 94.6\\\\%\\\\)), calibrated DR recovers near-\\\\( \\\\sqrt{n} \\\\) scaling with well-calibrated CIs, and IF-stacking further improves ordering. CJE reports uncertainty that includes an oracle-slice jackknife and surfaces overlap/tail and judge-reliability diagnostics; when calibration support is limited, it returns rank-robust conclusions (REFUSE-LEVEL) rather than overconfident levels.", "tldr": "A turn-key, auditable OPE system for LLMs that calibrates judges and weights via projection, boosting ESS from near-zero to ~80–95% and delivering tight, honest CIs with stacked DR estimators.", "keywords": ["off-policy evaluation", "large language models", "teacher forcing", "isotonic calibration", "importance sampling", "doubly robust estimation", "causal inference", "evaluation methodology", "preference models", "RLHF/DPO", "projection onto convex sets", "diagnostics", "effective sample size"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/0e0797765046c103e9702d974220422052dbe2af.pdf", "supplementary_material": "/attachment/7968c7f7b9ffe9de9220140362b2d142f8df8179.zip"}, "replies": [{"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "Withdrawn due to bibliographic inaccuracies discovered post-deadline. A fully audited revision will appear elsewhere."}}, "id": "DawGG6MOQr", "forum": "40xP4N4VRL", "replyto": "40xP4N4VRL", "signatures": ["ICLR.cc/2026/Conference/Submission21553/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21553/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761174012203, "cdate": 1761174012203, "tmdate": 1761174012203, "mdate": 1761174012203, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}