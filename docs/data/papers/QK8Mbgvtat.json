{"id": "QK8Mbgvtat", "number": 17309, "cdate": 1758274564725, "mdate": 1763149658288, "content": {"title": "Cohort-Based Active Modality Acquisition", "abstract": "Real-world machine learning applications often involve data from multiple modalities that must be integrated effectively to make robust predictions. However, in many practical settings, not all modalities are available for every sample, and acquiring additional modalities can be costly. This raises the question: which samples should be prioritized for additional modality acquisition when resources are limited? While prior work has explored individual-level acquisition strategies and training-time active learning paradigms, test-time and cohort-based acquisition remain underexplored. We introduce Cohort-based Active Modality Acquisition (CAMA), a novel test-time setting to formalize the challenge of selecting which samples should receive additional modalities. We derive acquisition strategies that leverage a combination of generative imputation and discriminative modeling to estimate the expected benefit of acquiring missing modalities based on common evaluation metrics. We also introduce upper-bound heuristics that provide performance ceilings to benchmark acquisition strategies. Experiments on multimodal datasets with up to 15 modalities demonstrate that our proposed imputation-based strategies can more effectively guide the acquisition of additional modalities for selected samples compared with methods relying solely on unimodal information, entropy-based guidance, or random selection. We showcase the real-world relevance and scalability of our method by demonstrating its ability to effectively guide the costly acquisition of proteomics data for disease prediction in a large prospective cohort, the UK Biobank (UKBB). Our work provides an effective approach for optimizing modality acquisition at the cohort level, enabling more effective use of resources in constrained settings.", "tldr": "", "keywords": ["Machine Learning", "Active Learning", "Deep Learning"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9ca3d9e2984d2082791d9737a7dcc4dc8588342d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Cohort-based Active Modality Acquisition (CAMA), a novel problem setting that addresses the challenge of strategically acquiring costly additional data modalities for a subset of a cohort at test time, under a fixed budget. Unlike prior work focusing on individual samples or training-time acquisition, CAMA aims to maximize a global performance metric (e.g., AUROC) for the entire cohort. The core of the proposed solution is a family of \"imputation-based\" acquisition functions that use a generative model (like a DDPM) to predict counterfactual outcomes—simulating how a sample's prediction would change if the missing modality were acquired. By prioritizing samples with the largest expected predictive shift (quantified, for instance, by KL-Divergence), the method intelligently allocates the acquisition budget. Through comprehensive experiments on multiple real-world datasets, including the large-scale UK Biobank with up to 15 modalities, the paper demonstrates that these imputation-based strategies significantly outperform baseline methods like random selection or uncertainty-based sampling."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel and Practical Problem Formulation: The primary strength is the formalization of the CAMA setting. By shifting the focus from individual-level to cohort-level optimization and from training-time to test-time decisions, the paper addresses a highly practical and underexplored real-world problem. \n2. Comprehensive and Rigorous Evaluation: The experimental setup is exceptionally thorough. The authors evaluate their framework on four diverse, real-world multimodal datasets, including the large and complex UK Biobank, demonstrating scalability and generalizability.\n3. Principled and Effective Acquisition Strategy: The use of generative imputation to estimate counterfactuals is a powerful and theoretically grounded approach."}, "weaknesses": {"value": "1. High Architectural Complexity: The proposed solution requires jointly training a complex discriminative classifier and a sophisticated generative model (e.g., a Diffusion Transformer). \n\n2. Assumption of a Single Target Modality: The current framework is designed around the scenario of acquiring one specific, pre-determined \"target\" modality (e.g., proteomics in the UKBB example). \n\n3. Dependence on Generative Model Fidelity: The success of the imputation-based strategies is fundamentally tied to the quality of the counterfactuals generated by the imputation model (f_imp). If the generative model fails to produce plausible imputations, the acquisition decisions will be misguided."}, "questions": {"value": "1. High Architectural Complexity: The proposed solution requires jointly training a complex discriminative classifier and a sophisticated generative model (e.g., a Diffusion Transformer). \n\n2. Assumption of a Single Target Modality: The current framework is designed around the scenario of acquiring one specific, pre-determined \"target\" modality (e.g., proteomics in the UKBB example). \n\n3. Dependence on Generative Model Fidelity: The success of the imputation-based strategies is fundamentally tied to the quality of the counterfactuals generated by the imputation model (f_imp). If the generative model fails to produce plausible imputations, the acquisition decisions will be misguided."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "UtUIsciOmM", "forum": "QK8Mbgvtat", "replyto": "QK8Mbgvtat", "signatures": ["ICLR.cc/2026/Conference/Submission17309/Reviewer_zHE8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17309/Reviewer_zHE8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760495427489, "cdate": 1760495427489, "tmdate": 1762927244668, "mdate": 1762927244668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new active data acquisition setting called cohort-based active modality acquisition (CAMA), the goal of which is to choose for which samples from some population we should acquire the values of missing modalities in order to maximise some performance metric. The authors propose a set of acquisition functions designed for the CAMA setting that can allow to guide the acquisition. The authors define both oracle metrics, relying on unavailable quantities, and simple baselines such as random acquisition as baselines. To handle the missing modalities in the data during inference, the authors use an architecture based on late fusion models and denoising diffusion probabilities models (DDPMs). With these models in place, the proposed acquisition functions are compared and evaluated on a set of real-world multimodal datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Very clear and extensive related works.\n- The authors propose and discuss a comprehensive set of baseline acquisition functions (both oracle and random ones), which allow to put the performance of the proposed metrics in context.\n- The experiments are run on several datasets, and over multiple runs, making the results significant."}, "weaknesses": {"value": "**CAMA setting.**\n1. The objective in the CAMA setting is not clear to me. The authors mention that the purpose of CAMA is to `identify those samples for which the acquisition of an additional data modality would be most beneficial`. This is formalised through equation 4. However, it is not clear exactly what “beneficial” means in this context. After the acquisition, the models are not retrained on the newly acquired data (as in active learning). Further, ‘benefits’ are also not measured with respect to improving individual predictions at test time (as in active feature acquisition). Hence, it is not immediate to me what variable CAMA is aiming to gain information about (as it seems to be _neither_ the model parameters, as in AL, _nor_ the outcome variable $Y$, as in AFA). Rather than focusing on gaining information about a specific variable, it seems to me that the “benefits” are measured through improving the target performance metric (e.g. AUROC) on the train/test set $\\mathcal{D}$ itself (the distinction between the train and test set is blurry in the paper). While this is indeed a different setting than AL or AFA, I do not see how it translates to measurable gains in real-world settings. It would be great if the authors could clarify why considering such a setting might be of interest to any downstream application.\n2. What further makes the setting quite artificial is that the “budget” does not account for the fact that different samples $i$ might require different number of modality acquisitions or that some modalities might be more informative (and also more expensive) than others. Instead, the framework only considers the problem of acquiring _all_ missing modalities or none, making this setting quite simplified.\n\n**Acquisition Functions for CAMA.**\n1. The authors claim that their contribution in this work is to propose a “theoretical framework” for developing AFs within the CAMA setting. However, looking at the metrics introduced in Appendix C, it seems to me like the degree of novelty in the derived metrics is limited. In particular, the best performing “Maximum Expected Uncertainty Reduction” and “Expected KL Divergence” seem to be variations of the Expected Information Gain metric (this connection is not discussed in the paper). Meanwhile, some of the other metrics (e.g. Maximum Expected Probability or Expected Rank Change) seem quite arbitrary and not supported theoretically. As such, I do not see theoretical results or insights as a significant contribution of this work.\n\n**Architectures for CAMA.**\n1. There is limited formalism offered to help understand the exact design of the proposed architecture, making it more difficult to evaluate it and assess its contribution. In particular, it is unclear to me what are the exact components of the architectures, when each of them are used (training vs inference) and what loss functions are used (in particular, what are the loss functions used for the generative component $f_{imp}$?). Equation 6 does not allow to track how the inputs are processed by the architecture used by the authors. Further, what is meant by the “discriminative components” in l.094 and l. 306? Is “discriminative” used in the GAN sense here?\n2. The work seems to be heavily inspired by the architecture proposed in Wang et al. (2023). Compared to Wang et al. (2023), what changes did the authors propose or implement that allowed them to adapt this architecture to the CAMA setting specifically?\n3. The contribution sections of the paper mentions that the work establishes upper bounds for CAMA. It is unclear for me what this means, and how it is manifested in the proposed architectures."}, "questions": {"value": "1. During the evaluation in the CAMA setting, how does acquiring the additional modalities for one sample $i$ affect the performance/predictions for a different sample $j$? If there is no interaction between acquiring samples for $i$ and $j$, in what cases is the CAMA setting more interesting/beneficial than active feature acquisition? If there is interaction, how does it differ from active learning?\n2. What is a unimodal baseline (l.259)? I assume that this is the baseline with only a single modality for each sample. However, different modalities can have different level of “informativeness” for the outcome of interest, and as such which modality is chosen for the unimodal baseline is a crucial decision that will significantly affect the baseline value. Hence, it seems to me that the unimodal baseline is not well defined.\n3. Are the imputation based scores $\\{s_{I, k}^{imp}\\}$ obtained by taking samples from the generative model? If yes, what value of $K$ was used in the experiments, and how sensitive is the proposed framework to this hyperparameter?\n4. What do authors mean by “true scores $s_i^{full}$ and $s_i^{avail}$” (l.291) in the context of their data? I assume this corresponds to the logits (l. 376). If yes, how (if at all) are the “true” logits calculated? Are they used for training?\n5. In the evaluation process of their proposed models, I am assuming that the models are trained on the test set (in the cross-validation setting) and then the acquisition process is being run on the test set. Is that correct?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PIWH71mWJC", "forum": "QK8Mbgvtat", "replyto": "QK8Mbgvtat", "signatures": ["ICLR.cc/2026/Conference/Submission17309/Reviewer_rRxq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17309/Reviewer_rRxq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761647811088, "cdate": 1761647811088, "tmdate": 1762927244306, "mdate": 1762927244306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new active data acquisition setting called cohort-based active modality acquisition (CAMA), the goal of which is to choose for which samples from some population we should acquire the values of missing modalities in order to maximise some performance metric. The authors propose a set of acquisition functions designed for the CAMA setting that can allow to guide the acquisition. The authors define both oracle metrics, relying on unavailable quantities, and simple baselines such as random acquisition as baselines. To handle the missing modalities in the data during inference, the authors use an architecture based on late fusion models and denoising diffusion probabilities models (DDPMs). With these models in place, the proposed acquisition functions are compared and evaluated on a set of real-world multimodal datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Very clear and extensive related works.\n- The authors propose and discuss a comprehensive set of baseline acquisition functions (both oracle and random ones), which allow to put the performance of the proposed metrics in context.\n- The experiments are run on several datasets, and over multiple runs, making the results significant."}, "weaknesses": {"value": "**CAMA setting.**\n1. The objective in the CAMA setting is not clear to me. The authors mention that the purpose of CAMA is to `identify those samples for which the acquisition of an additional data modality would be most beneficial`. This is formalised through equation 4. However, it is not clear exactly what “beneficial” means in this context. After the acquisition, the models are not retrained on the newly acquired data (as in active learning). Further, ‘benefits’ are also not measured with respect to improving individual predictions at test time (as in active feature acquisition). Hence, it is not immediate to me what variable CAMA is aiming to gain information about (as it seems to be _neither_ the model parameters, as in AL, _nor_ the outcome variable $Y$, as in AFA). Rather than focusing on gaining information about a specific variable, it seems to me that the “benefits” are measured through improving the target performance metric (e.g. AUROC) on the train/test set $\\mathcal{D}$ itself (the distinction between the train and test set is blurry in the paper). While this is indeed a different setting than AL or AFA, I do not see how it translates to measurable gains in real-world settings. It would be great if the authors could clarify why considering such a setting might be of interest to any downstream application.\n2. What further makes the setting quite artificial is that the “budget” does not account for the fact that different samples $i$ might require different number of modality acquisitions or that some modalities might be more informative (and also more expensive) than others. Instead, the framework only considers the problem of acquiring _all_ missing modalities or none, making this setting quite simplified.\n\n**Acquisition Functions for CAMA.**\n1. The authors claim that their contribution in this work is to propose a “theoretical framework” for developing AFs within the CAMA setting. However, looking at the metrics introduced in Appendix C, it seems to me like the degree of novelty in the derived metrics is limited. In particular, the best performing “Maximum Expected Uncertainty Reduction” and “Expected KL Divergence” seem to be variations of the Expected Information Gain metric (this connection is not discussed in the paper). Meanwhile, some of the other metrics (e.g. Maximum Expected Probability or Expected Rank Change) seem quite arbitrary and not supported theoretically. As such, I do not see theoretical results or insights as a significant contribution of this work.\n\n**Architectures for CAMA.**\n1. There is limited formalism offered to help understand the exact design of the proposed architecture, making it more difficult to evaluate it and assess its contribution. In particular, it is unclear to me what are the exact components of the architectures, when each of them are used (training vs inference) and what loss functions are used (in particular, what are the loss functions used for the generative component $f_{imp}$?). Equation 6 does not allow to track how the inputs are processed by the architecture used by the authors. Further, what is meant by the “discriminative components” in l.094 and l. 306? Is “discriminative” used in the GAN sense here?\n2. The work seems to be heavily inspired by the architecture proposed in Wang et al. (2023). Compared to Wang et al. (2023), what changes did the authors propose or implement that allowed them to adapt this architecture to the CAMA setting specifically?\n3. The contribution sections of the paper mentions that the work establishes upper bounds for CAMA. It is unclear for me what this means, and how it is manifested in the proposed architectures."}, "questions": {"value": "1. During the evaluation in the CAMA setting, how does acquiring the additional modalities for one sample $i$ affect the performance/predictions for a different sample $j$? If there is no interaction between acquiring samples for $i$ and $j$, in what cases is the CAMA setting more interesting/beneficial than active feature acquisition? If there is interaction, how does it differ from active learning?\n2. What is a unimodal baseline (l.259)? I assume that this is the baseline with only a single modality for each sample. However, different modalities can have different level of “informativeness” for the outcome of interest, and as such which modality is chosen for the unimodal baseline is a crucial decision that will significantly affect the baseline value. Hence, it seems to me that the unimodal baseline is not well defined.\n3. Are the imputation based scores $\\{s_{I, k}^{imp}\\}$ obtained by taking samples from the generative model? If yes, what value of $K$ was used in the experiments, and how sensitive is the proposed framework to this hyperparameter?\n4. What do authors mean by “true scores $s_i^{full}$ and $s_i^{avail}$” (l.291) in the context of their data? I assume this corresponds to the logits (l. 376). If yes, how (if at all) are the “true” logits calculated? Are they used for training?\n5. In the evaluation process of their proposed models, I am assuming that the models are trained on the test set (in the cross-validation setting) and then the acquisition process is being run on the test set. Is that correct?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PIWH71mWJC", "forum": "QK8Mbgvtat", "replyto": "QK8Mbgvtat", "signatures": ["ICLR.cc/2026/Conference/Submission17309/Reviewer_rRxq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17309/Reviewer_rRxq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761647811088, "cdate": 1761647811088, "tmdate": 1763387223275, "mdate": 1763387223275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Cohort-based Active Modality Acquisition (CAMA), a test-time setting to formalize the challenge of selecting patients which require additional testing. The proposal uses a generative imputation model $f_{imp}$ to estimate counterfactual scores after acquiring the modality and then ranks samples via heuristics (e.g., KL divergence between current and imputed predictive distributions). The goal is to maximize a global test-time metric (e.g., AUROC) with the budget constraint."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The setting of test-time modality selection is quite important and needed, especially in clinical setting\n- The paper views the problem from the cohort point of view instead of individual patient point of view (since $\\beta$ is constraint on number of patients)"}, "weaknesses": {"value": "Weaknesses/Questions:\n- The setting, as they described is not novel. The paper doesn't cite [1] or [2] where the proposed test-time setting is identical to the setting in [1, section 3] and [2], and Eq (4) of CAMA is related to Lemma 3 in [1], where each modality selected is to maximize the accuracy. As far as I understand, [1] also uses foundation models as encoders, followed by a classification head to predict logit scores. While [1] approaches the issue from an RL perspective, the test-time modality acquisition seems identical since both are maximizing group metrics. The imputation approach mimics both [1] and [2] -- [1] uses the foundation model as generative, and [2] uses spline networks for imputation and uses that to score, however as a sequential RL control problem instead of cohort-level greedy ranking.\n- What doesn't make sense to me is eq (3), where if a sample is chosen, all modalities are acquired -- this basically doesn't give relevance to the setting under cost-constraints. Rather, it makes sense to have cost-constraints on the modalities itself, with a heterogenous cost vector $\\mathbf{c}$  and have it choose the modalities under constraint $\\beta$. This setting with only 1 modality not acquired boils down to the case of the paper. Moreover, the text of figure 1B says that the imputed score *estimates the counterfactual with only imputed modality added* - so is the logit score with all modalities or available + target?\n- DDPMs/VAEs have been used previously for missing modality imputation, and the paper seems to compare standard heuristics. Although it claims KL-div performs the best, tables in the appendix don't seem consistent. \n- What is the quality of the imputations? What modalities are acquired? What cost-profiles do we get with performance? Just the curves/tables under a single budget for the $G_\\bullet$ metric seems to lack a lot of important details. Cost-profiles for modalities and samples is much more important than inference time since the tasks at hand are not time-bounded. Are there correlations in patients requiring further screening? There are lot of lacking questions and ablations.\n\n[1] Jain, E., Wenckstern, J., von Querfurth, B., & Bunne, C. (2025, March). Test-time view selection for multi-modal decision making. In ICLR 2025 Workshop on Machine Learning for Genomics Explorations.\n\n[2] Li, Y., & Oliva, J. (2024). Towards Cost Sensitive Decision Making. arXiv preprint arXiv:2410.03892.\n\n\nI believe the paper lacks novelty, and is confusing to read. While the test-time setting is important, sample-wise all-modality acquisition seems less feasible in practice to just modality acquisition. In the current state I lean to reject the paper."}, "questions": {"value": "Mentioned along with Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "srUSrT290E", "forum": "QK8Mbgvtat", "replyto": "QK8Mbgvtat", "signatures": ["ICLR.cc/2026/Conference/Submission17309/Reviewer_fQ25"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17309/Reviewer_fQ25"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821334610, "cdate": 1761821334610, "tmdate": 1762927243867, "mdate": 1762927243867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Cohort-based Active Modality Acquisition (CAMA), a novel test-time setting for acquiring missing modalities. This setting focuses on ranking samples to determine which should receive additional, costly modalities in order to best achieve a global objective under a budget constraint. The authors further develop a family of imputation-based methods that combine generative imputation and discriminative modeling to estimate the expected benefit of acquiring missing modalities. Experiments on several multimodal datasets demonstrate that these imputation-based methods generally outperform baseline approaches that do not use imputation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and easy to follow. The motivation behind CAMA and the ideas underlying different acquisition strategies are clearly presented.\n2. The proposed evaluation metric for the CAMA setting is sound.\n3. Experiments are conducted on multiple multimodal datasets, providing comprehensive comparisons across acquisition strategies."}, "weaknesses": {"value": "1. According to Eqs. (3) and (4), the cost of acquiring missing modalities is assumed to be identical for all patients. This simplification may limit the practical applicability of the proposed setting and methods.\n2. Building on the previous point, trivial strategies, such as prioritizing patients with a greater number of missing modalities, might achieve competitive performance.\n3. Although the imputation-based methods generally outperform the baselines, their performance appears inconsistent across different evaluation criteria (e.g., KL-Divergence vs. probability metrics), particularly in Table 3. This variability raises uncertainty about which criterion should be preferred in practice."}, "questions": {"value": "Please see \"Weakness\""}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns"]}, "details_of_ethics_concerns": {"value": "The proposed setting and methods lead to a situation where certain selected patients receive additional acquired data and consequently achieve potentially better prediction scores. This may raise equity and fairness concerns, particularly when these prediction scores influence downstream decision-making processes. The authors also acknowledge this limitation in Appendix A."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "koUcIiL0q2", "forum": "QK8Mbgvtat", "replyto": "QK8Mbgvtat", "signatures": ["ICLR.cc/2026/Conference/Submission17309/Reviewer_RGpf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17309/Reviewer_RGpf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876102304, "cdate": 1761876102304, "tmdate": 1762927243391, "mdate": 1762927243391, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}