{"id": "CkOBcyntGd", "number": 5427, "cdate": 1757908541159, "mdate": 1759897976063, "content": {"title": "A Memory-Efficient Hierarchical Algorithm for Large-scale Optimal Transport Problems", "abstract": "In this paper we propose a memory-efficient hierarchical algorithm for solving large-scale optimal transport (OT) problems where the supports are in $\\mathbb{R}^2$ with squared Euclidean cost. \nThe key of our proposed approach is the combination of multiscale hierarchical representation of the OT problem and a GPU-implemented  Primal-Dual Hybrid Gradient (PDHG) method. Moreover, an active pruning technique is applied which can further reduce computational complexity. Theoretically, we establish a scale-independent iteration-complexity upper bound for the refinement phase, which is consistent with our numerical results. Numerically, extensive experiments on image dataset DOTmark demonstrate that the proposed algorithm effectively addresses the memory and scalability bottlenecks of existing solvers. \nFor images with resolution $1024\\times 1024$, our method achieves an $8.9\\times$ speedup and reduces GPU memory usage by $70.5$% compared to state-of-the-art baselines, under comparable accuracy.", "tldr": "", "keywords": ["optimal transport", "linear programming", "multiscale framework", "first-order methods"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c782a2423a43a7348560a7a221671557da3bd991.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces HALO, a hierarchical and memory-efficient algorithm for large-scale optimal\ntransport (OT) problems on 2D supports with squared Euclidean cost. The method combines a coarseto-\nfine multi-scale framework with a GPU-optimized PDHG (Primal-Dual Hybrid Gradient) solver\nand an active-pruning mechanism for sparsity. The authors prove a scale-independent iteration\ncomplexity bound for the refinement phase and show strong empirical results on the DOTmark\nbenchmark, achieving significant speedup and memory usage saving compared to methods such as\nHOT, ShortCut, and M3S."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Theorem 1 (scale-independent iteration complexity) provides a nontrivial and interpretable\nconvergence guarantee, addressing the gap in multi-scale OT methods (which often lack formal\ncomplexity bounds).\n2. HALO merges the hierarchical multi-scale structure with a GPU-based LP solver. This is a\nthoughtful contribution, given the growing interest in efficient OT solvers.\n3. The paper is clearly written and well-organized. Figures 1‚Äì3 effectively illustrate the hierarchical\nprocess and empirical trends. Proofs are included in the appendix and seem technically sound."}, "weaknesses": {"value": "1. HALO is currently limited to 2D support with squared Euclidean cost. The hierarchical design\nheavily relies on the specific problem (OT between two 2D images), while applications of OT\n(like in generative models) are on more general settings (Wasserstein GAN [1] and optimal flow\nmatching [2]) where the supports are high-dimensional. In this case, the HALO may not work well\nas in the image problems in DOTmark because the data locality property doesn't hold in these\nproblem. The limited problem setting is mentioned but not stated clearly in the introduction.\n\n2. Although the paper fairly acknowledges this, HALO‚Äôs performance heavily relies on a third-party\nGPU solver. A deeper analysis of how HALO interacts with other first-order solvers would make\nthe contribution more self-contained.\n\n3. The parameter beta in the dual-violation step appears to influence sparsity and runtime, but the\nsensitivity analyses are missing. Reporting how beta impacts convergence and memory would be\nvaluable.\n\n4. In DOTMark [3], there are various types of images. It would be interesting to see how HALO\nperforms on these classes of images respectively to have a clearer idea of the practicality of the\nassumptions and the influence of the data locality on the convergence of HALO.\n\nReferences:\n[1] Adler, Jonas, and Sebastian Lunz. \"Banach wasserstein gan.\" Advances in neural information\nprocessing systems 31 (2018).\n[2] Kornilov, Nikita, et al. \"Optimal flow matching: Learning straight trajectories in just one\nstep.\" Advances in Neural Information Processing Systems 37 (2024): 104180-104204.\n[3] Schrieber, J√∂rn, Dominic Schuhmacher, and Carsten Gottschlich. \"Dotmark‚Äìa benchmark for\ndiscrete optimal transport.\" IEEE Access 5 (2016): 271-282."}, "questions": {"value": "1. HALO is currently limited to 2D support with squared Euclidean cost. The hierarchical design\nheavily relies on the specific problem (OT between two 2D images), while applications of OT\n(like in generative models) are on more general settings (Wasserstein GAN [1] and optimal flow\nmatching [2]) where the supports are high-dimensional. In this case, the HALO may not work well\nas in the image problems in DOTmark because the data locality property doesn't hold in these\nproblem. The limited problem setting is mentioned but not stated clearly in the introduction.\n\n2. Although the paper fairly acknowledges this, HALO‚Äôs performance heavily relies on a third-party\nGPU solver. A deeper analysis of how HALO interacts with other first-order solvers would make\nthe contribution more self-contained.\n\n3. The parameter beta in the dual-violation step appears to influence sparsity and runtime, but the\nsensitivity analyses are missing. Reporting how beta impacts convergence and memory would be\nvaluable.\n\n4. In DOTMark [3], there are various types of images. It would be interesting to see how HALO\nperforms on these classes of images respectively to have a clearer idea of the practicality of the\nassumptions and the influence of the data locality on the convergence of HALO.\n\nReferences:\n[1] Adler, Jonas, and Sebastian Lunz. \"Banach wasserstein gan.\" Advances in neural information\nprocessing systems 31 (2018).\n[2] Kornilov, Nikita, et al. \"Optimal flow matching: Learning straight trajectories in just one\nstep.\" Advances in Neural Information Processing Systems 37 (2024): 104180-104204.\n[3] Schrieber, J√∂rn, Dominic Schuhmacher, and Carsten Gottschlich. \"Dotmark‚Äìa benchmark for\ndiscrete optimal transport.\" IEEE Access 5 (2016): 271-282."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YaMOrH01Ct", "forum": "CkOBcyntGd", "replyto": "CkOBcyntGd", "signatures": ["ICLR.cc/2026/Conference/Submission5427/Reviewer_Tm5V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5427/Reviewer_Tm5V"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824628211, "cdate": 1761824628211, "tmdate": 1762918055727, "mdate": 1762918055727, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a hierarchical algorithm to solve large-scare OT problems. By several techniques including hierarchical expansion, active support update, and GPU based PDHG. The algorithm justifies its efficiency by improving the state-of-the-art baselines and theoretical scale independent iteration complexity bound."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "By carefully tuning the three approaches in discrete OT techniques, the algorithm justify itself by testing on common data sets."}, "weaknesses": {"value": "1. A well known issue of the hierarchical approach, is the scalability to higher dimensions rather than 2D mesh like topology. The author shall consider a least a remark on extension to higher dimensions.\n2. Another issue of the manuscript is the theoretical justification relies on rather strong assumption (4,5), also as the authors mentioned. Since the complexity of HALO is only an upper bound under strong assumptions, the practical superiority of the HALO is not well-explained. The author may need further discuss the structural advantages comparing with other algorithm, for instance Multiscale-OT."}, "questions": {"value": "Beyond the weakness that requires the author to address.\n1. The active support in Def. 1 also appears in [1] and even earlier (see references in [1]), will such randomized method improve the HALO?\n2. In experiment, the ShortCut is only implemented on CPU, given its low memory cost and rather low runtime in lower resolution, is there theoretical barrier for ShortCut to implement on GPU and yield an even better result?\n\n[1] Xie, Yue, Zhongjian Wang, and Zhiwen Zhang. \"Randomized methods for computing optimal transport without regularization and their convergence analysis.\" Journal of Scientific Computing 100.2 (2024): 37."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tYB99mmhbp", "forum": "CkOBcyntGd", "replyto": "CkOBcyntGd", "signatures": ["ICLR.cc/2026/Conference/Submission5427/Reviewer_a2S6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5427/Reviewer_a2S6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842287510, "cdate": 1761842287510, "tmdate": 1762918055249, "mdate": 1762918055249, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HALO (Hierarchical Algorithm for Large-scale Optimal Transport), a GPU-based, memory-efficient method for solving large-scale optimal transport (OT) problems in the plane with squared Euclidean cost. HALO combines a multiscale hierarchical framework with a sparse, active-support refinement scheme and a primal‚Äìdual hybrid gradient (PDHG) solver to overcome the severe memory and scalability limitations of existing OT solvers. By solving coarser OT problems first and using their solutions to warm-start finer levels, HALO efficiently refines the transport plan while keeping memory usage to  ùëÇ(r^2), where r is the number of pixels per dimension.\n\nThe method also includes a dual-violation augmentation step that improves robustness, and the authors establish a scale-independent iteration bound, proving that each refinement level requires only ùëÇ(1) iterations. On the DOTmark benchmark, HALO outperforms state-of-the-art methods such as HOT, ShortCut, and M3S‚Äîachieving up to 8.9√ó speedup and 70% lower GPU memory use for 1024√ó1024 images, while maintaining comparable or superior accuracy. Overall, HALO demonstrates near-linear runtime scaling and high parallel efficiency, offering a theoretically grounded and practically scalable solution for large-scale OT computation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper‚Äôs main strengths lie in its combination of theoretical rigor and practical scalability. HALO introduces a hierarchical, GPU-friendly framework that reduces the memory requirement of large-scale optimal transport (OT) from ùëÇ(ùëü^4) to ùëÇ(ùëü^2), allowing it to handle very high-resolution problems that were previously infeasible. Its coarse-to-fine multiscale design and sparsity-based active support updates enable near-linear runtime scaling, while the factorization-free PDHG solver fully exploits GPU parallelism for efficient computation.\n\nEqually important, the paper provides strong theoretical guarantees and robust empirical validation. The authors prove a scale-independent iteration bound, ensuring that refinement at each level converges in a constant number of steps, and introduce dual-violation augmentation to improve robustness without sacrificing sparsity. Extensive experiments on the DOTmark benchmark confirm that HALO achieves up to 8.9√ó speedup and 70% memory savings compared to leading solvers, while maintaining high accuracy. Overall, the method is both theoretically elegant and practically impactful, setting a new benchmark for scalable OT computation."}, "weaknesses": {"value": "The main weaknesses of the paper lie in its limited generality and empirical scope. HALO is tailored for 2D optimal transport problems with squared Euclidean cost on regular grids, and both its theoretical guarantees and hierarchical design rely on this structure. As a result, the method‚Äôs applicability to higher-dimensional settings, irregular domains, or non-Euclidean costs remains unclear. Moreover, while the algorithm performs impressively on the DOTmark benchmark, its evaluation is confined to this dataset, leaving open questions about robustness and generalization to more diverse or real-world applications.\n\nAnother limitation is the dependence on heuristic components such as dual-violation augmentation and Top-K active-set selection, whose performance may vary with parameter choices not deeply analyzed in the paper. The implementation is also technically complex‚Äîcombining multiscale hierarchy, active-support refinement, and GPU-based PDHG‚Äîwhich could make reproduction or extension challenging for practitioners. Overall, while HALO is methodologically strong and achieves excellent performance, its restricted scope, heuristic tuning, and limited experimental diversity temper its broader applicability."}, "questions": {"value": "The following questions need to be addressed to further improve the quality:\n\n1. transportation cost: if the transportation cost is not the squared Euclidean distance, like L1 distance, will the method be applicable ?\n2. dimension : if the problem is not restricted on 2d, but general n dimensional Euclidean space, can the method work ?\n3. range: if the support of the target measure is not convex, but a concave Jordan domain, can the active-support refinement  algorithm still work ? In this situation, there will be complicated singularities in the domain, determining the singularity will be challenging.\n4. HALO is built on a first -order optimization framework, is it possible to use Newton's method ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PQYhkxCaN7", "forum": "CkOBcyntGd", "replyto": "CkOBcyntGd", "signatures": ["ICLR.cc/2026/Conference/Submission5427/Reviewer_u6SB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5427/Reviewer_u6SB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953444643, "cdate": 1761953444643, "tmdate": 1762918054820, "mdate": 1762918054820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The authors proposes HALO (Hierarchical Algorithm for Large-scale Optimal Transport), a novel GPU-friendly method for solving large discrete optimal transport (OT) problems efficiently. \n- The key idea is to build a coarse-to-fine multi-scale hierarchy and iteratively refine the transport plan while maintaining an active support set that captures potentially non-zero couplings. \n- Each refinement step solves a restricted OT problem via a primal-dual hybrid gradient (PDHG) method optimized for GPU computation.\n- Experiments on large-scale image OT tasks (DOTmark dataset) demonstrate significant speed and memory savings ove baselines like HOT, ShortCut, and M3S."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper successfully solves the scalability bottleneck of OT on high-resolution data with well-designed hierarchical + active-support framework and solid theoretical justification.\n- The experimental results are promising with great speed and memory advantage."}, "weaknesses": {"value": "- Currently limited to 2D grid supports with squared Euclidean cost.\n- The active-support update relies on heuristic parameters (e.g., Œ≤) without sensitivity analysis.\n-Experiments only cover image data; no test on non-grid or higher-dimensional problems. Does it work on other distributions?"}, "questions": {"value": "Please mainly see the above weakness part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0U7unVmYP1", "forum": "CkOBcyntGd", "replyto": "CkOBcyntGd", "signatures": ["ICLR.cc/2026/Conference/Submission5427/Reviewer_rnK4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5427/Reviewer_rnK4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762115937131, "cdate": 1762115937131, "tmdate": 1762918054581, "mdate": 1762918054581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}