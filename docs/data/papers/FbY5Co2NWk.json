{"id": "FbY5Co2NWk", "number": 20520, "cdate": 1758307007838, "mdate": 1763479132527, "content": {"title": "Unmute the Patch Tokens: Rethinking Probing in Multi-Label Audio Classification", "abstract": "Although probing frozen models has become a standard evaluation paradigm, self-supervised learning in audio defaults to fine-tuning when pursuing state-of-the-art on AudioSet. A key reason is that global pooling creates an information bottleneck causing linear probes to misrepresent the embedding quality: The $\\texttt{cls}$-token discards crucial token information about dispersed, localized events in multi-label audio. This weakness is rooted in the mismatch between the pretraining objective (operating globally) and the downstream task (localized events). Across a comprehensive benchmark of 13 datasets and 6 spectrogram-based encoders, we first investigate the global pooling bottleneck. We then introduce binarized prototypical probes: a lightweight and simple pooling method that learns prototypes to perform class-wise information aggregation. Despite its simplicity, our method notably outperforms linear and attentive probing. Our work establishes probing as a competitive and efficient paradigm for evaluating audio SSL models, challenging the reliance on costly fine-tuning.", "tldr": "This paper investigates the poor performance of probing in multi-label audio, attributing it to a pooling bottleneck rather than deficient features.", "keywords": ["audio self-supervised learning", "probing", "frozen embeddings", "bioacoustics"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/115e78f4e68bfeecb9fa1d1a5d8a67537935ba2d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the underperformance and underutilization of probing as an evaluation paradigm for self-supervised audio models, particularly in multi-label classification tasks. The authors hypothesize that the standard approach of using a linear probe on a globally pooled [cls] token creates an information bottleneck, discarding crucial information about localized sound events contained within the patch tokens. To address this, they introduce \"binarized prototypical probes\" (protobin), a lightweight and efficient pooling method that learns a set of per-class prototypes to aggregate information directly from the full token map. Through a comprehensive benchmark, the authors demonstrate that their proposed method significantly outperforms standard linear and attentive probing. The work makes a strong case for establishing prototypical probing as a more faithful and efficient evaluation standard in the audio SSL community."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Systematic and Insightful Problem Analysis: The paper's greatest strength is its methodical approach. Rather than just presenting a new method, it first provides a deep and convincing analysis of the existing problem—the \"pooling bottleneck\"—and validates this hypothesis with extensive empirical evidence.\n- Methodological Elegance and Efficiency: The proposed protobin method is simple to understand and implement, yet highly effective. It is parameter-efficient and, through binarization, memory-efficient, making it a practical tool for a wide range of applications, including on-device scenarios.\n- Comprehensive and Rigorous Benchmarking: The scale of the experimental study is a major strength. The evaluation across 13 datasets, 6 encoders (and their supervised variants), and 10 pooling methods provides a robust and generalizable foundation for the paper's claims. The structured presentation of results in response to explicit research questions is exemplary.\n- Clarity of Presentation: The writing is clear, and the high-quality visualizations (especially Figures 1, 2, and 5) are instrumental in conveying the paper's core ideas and findings effectively."}, "weaknesses": {"value": "- Fixed Number of Prototypes: The number of prototypes is set to 20 per class across all datasets, following a heuristic from a prior work. While this seems to work well, the paper would be slightly stronger with a brief sensitivity analysis or discussion on how this hyperparameter might be optimally chosen for datasets with different characteristics (e.g., number of classes, intra-class variance).\n- Trade-off of Binarization: The protobin method is compared to a float-based proto version, and while it performs competitively and often wins, it is not uniformly superior. A brief discussion on the specific trade-offs of binarization (e.g., in which scenarios might the precision of float-based prototypes be advantageous?) could add more nuance."}, "questions": {"value": "Please refer to the weaknesses above for the questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iVzThKMese", "forum": "FbY5Co2NWk", "replyto": "FbY5Co2NWk", "signatures": ["ICLR.cc/2026/Conference/Submission20520/Reviewer_HEBB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20520/Reviewer_HEBB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760774421938, "cdate": 1760774421938, "tmdate": 1762933941707, "mdate": 1762933941707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## Rethinking probing for Audio SSL models\n\n1. The paper proposes prototypical probing strategies for probing frozen Audio SSL models.\n2. Several pooling approaches have been evaluated across several audio SSL models with different pretext tasks for a holistic evaluation of the proposed pooling approaches.\n3. The empirical evaluation conducted in the paper is solid, and showcases that the proposed pooling approach works better than alternatives for pooling."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. For the most part, the paper is well written and well presented. Diagrams and illustrations aid in understanding the paper.\n2. The proposed binarised prototypical probing methods are well presented. \n3. The evaluation protocol is thorough, with a good selection of audio SSL models and several probing strategies.\n4. Results show that protobin probing works well, especially on 3 of the 5 evaluated tasks."}, "weaknesses": {"value": "## Weakness 1\n\na. The core argument/motivating principle, repeated several times in the paper, is that \"audio SSL works default to fine-tuning instead of probing\", but only a handful of papers that support the argument are cited throughout the paper. E.g.\n\nLines 52-53\n> Given probing’s apparent practicality and widespread adoption as an evaluation paradigm in computer vision (Oquab et al., 2024; Przewi˛e´zlikowski et al., 2025; Darcet et al., 2025), why does the audio SSL community still default to resource-intensive fine-tuning (Alex et al., 2025; Chen et al., 2024)?  \n\nLines 72-73\n> Therefore, the limited adoption of probing in audio SSL ....\n\nLines 214-215\n> Evaluation in audio SSL. While probes are widely used in computer vision (Oquab et al., 2024), audio SSL defaults to fine-tuning (Rauch et al., 2025b).\n\nStatements such as the above make it seem like the audio SSL domain is not doing probing-based evaluation on frozen encoders at all.  However, the paper only cites a handful of papers that support this notion, while ignoring the plethora of audio SSL works that evaluate frozen encoders using probing [1-15] (to mention a few). This includes Dasheng [8], the model you do cite in the paper and conduct experiments on.\n\n---\n\n## Weakness 2\n\n1. Further, the core motivation/hypothesis/guiding principle of the paper is that there is a \"pooling bottleneck\", and that standard single vector probes and [cls]-token only pooling under utilize token embeddings. However, several missing references listed in W1 are already aware of the drawbacks of conducting probing experiments only on [cls]-token or single vector representations obtained by pooling of information across all the patches.\n\n2. In MIM style SSL from spectrograms, every patch is a fragment in time and frequency. Thus, aggregation strategies that merge information across patches will inherently decimate frequency information. Niizumi et al. [02] were aware of this and proposed a simple strategy to aggregate temporal features while preserving frequency information.\n\n3. Thus, the <[cls]-linear probe> strategy is not representative of the entire audio SSL community's approach to evaluate audio SSL models, unlike what the paper in its current form makes it seem like.\n\n---\n\n## Weakness 3\n\nFrom lines 135-136\n> If the model exposes a last-layer....... If not, we can mean pool $\\tilde{z}_i$ by averaging all token positions.\n\nAs mentioned in Weakness 2, Point 2. This pooling strategy across token positions is suboptimal and puts plain linear probe at a disadvantage for the models that do not expose cls tokens. \n\n---\n\n## Weakness 4 \n\nIn several instances, the paper makes unjustified statements.\n\n> All current spectrogram-based audio SSL encoders apply MIM-style objectives, often coupled with student-teacher distillation (Chen et al., 2024; Alex et al., 2025).\n\nThese two papers are not representative of the entire audio SSL field. For e.g. [9, 13, 15] do not use a straightforward MIM style objective for learning audio representations through SSL.\n\n> While probes are widely used in computer vision (Oquab et al., 2024), audio SSL defaults to fine-tuning (Rauch et al., 2025b).\n\nHow does the paper on the BIRDNET dataset (Rauch et al., 2025b) justify that audio SSL defaults to using fine-tuning?\n\n---\n\n## REFERENCES\n\n01. Koutini et al., \"Learning General Audio Representations With Large-Scale Training of Patchout Audio Transformers\", 2022.  \n02. Niizumi et al., \"Masked spectrogram modeling using masked autoencoders for learning general-purpose audio representation\",   2022.  \n03. Anton et al., \"AUDIO BARLOW TWINS: SELF-SUPERVISED AUDIO REPRESENTATION LEARNING\", 2023.  \n04. Niizumi et al., \"BYOL for Audio: Exploring Pre-Trained General-Purpose Audio Representations\", 2023.  \n05. Niizumi et al., \"Masked Modeling Duo: Towards a Universal Audio Pre-Training Framework\", 2024.  \n06. Yadav et al., \"Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners\", 2024.  \n07. Yadav et al., \"Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations\", 2024.  \n08. Dinkel et al., \"Scaling up masked audio encoder learning for general audio classification\", 2024.  \n09. Li et al., \"Self-Supervised Audio Teacher-Student Transformer for Both Clip-Level and Frame-Level Tasks\", 2024.  \n10. Yadav et al., \"AxLSTMs: learning self-supervised audio representations with xLSTMs\", 2025.  \n11. Yuksel et al., \"GRAM: Spatial general-purpose audio representation models for real-world applications\", 2025.  \n12. Schmid et al., \"Effective Pre-Training of Audio Transformers for Sound Event Detection\", 2025.  \n13. Pepino et al., \"EnCodecMAE: leveraging neural codecs for universal audio representation learning\", 2025.  \n14. Niizumi et al., \"M2D-CLAP: Exploring General-Purpose Audio-Language Representations Beyond CLAP\", 2025.  \n15. Chang et al., \"USAD: Universal Speech and Audio Representation via Distillation\", 2025"}, "questions": {"value": "No specific questions. Please address the weaknesses stated above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3fWXvIiKQl", "forum": "FbY5Co2NWk", "replyto": "FbY5Co2NWk", "signatures": ["ICLR.cc/2026/Conference/Submission20520/Reviewer_FqWa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20520/Reviewer_FqWa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761749754648, "cdate": 1761749754648, "tmdate": 1762933941242, "mdate": 1762933941242, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper primarily investigates the limitations of the existing linear evaluation paradigm for audio encoders.  \n\nThe authors show that the use of [cls] tokens  for linear probing does not take into account the time-space localised representations contained in patch tokens, and this hurts downstream linear probing performance in audio encoders, especially given that most audio encoders employ reconstruction objectives where information is rich in the patch tokens.  \n\nThe paper runs an evaluation benchmark on a set of linear probing methods on multiple downstream tasks, evaluated over multiple pre-trained audio encoders, and show that [cls] based methods perform poorly as opposed to learned pooling methods. \n\nMotivated by this, the authors propose a pooling strategy (protobin) which adds to the existing method of prototype pooling by introducing binary constraints."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Clarity: The paper is well written and can be easily understood.  \n\nMotivation: The paper is well motivated, and the motivation is justified by the results in Appendix A, where [cls] tokens alone perform much worse than learned pooling methods. \n\nContribution 1: The paper presents a benchmark and evaluation of recent SSL methods under multiple pooling/aggregation strategies. Using this benchmark, SSL methods on audio data can be fairly evaluated without a bias towards the [cls] token, thereby nullifying the apparent advantage seen by discriminative-only based methods on linear probing performance. \n\nContribution 2: The results by using the binarized prototype tensor (protobin and proto combined) yield SoTA  linear probing performance across almost all tasks and pre-trained models. Therefore, prototype-based aggregation can act as a standard method for performing linear probing for multi-label audio classification."}, "weaknesses": {"value": "Significance: The fact that [cls] tokens alone perform worse than learned pooling mechanisms is already mentioned in literature [1]. Therefore, the same message being repeated for audio needs a stronger justification, with possible reasons as to why the message in [1] might or might not hold for audio data, thereby justifying the motivation for evaluation.  \n\nOriginality: The protobin aggregator is simply a binarization of the prototype tensor derived from Bird-MAE. Looking at Table 4 and 5, proto and protbin share similar overall performance, with protobin performing marginally better in more tasks than protobin (approximately 2/3), but not significantly enough to justify the addition of binarization as a contribution. The actual performance gain over other methods seems to be gained by the use of prototypes, as in Bird-MAE [2]. \n\nThe paper does not clearly explain why the cosine similarities between prototypes are mostly zero after training, despite the absence of any explicit mechanism to control the prototype distribution. It is unclear how the \\(\\pm{1}\\) constraint alone enforces this near-orthogonality or prevents different prototypes from converging to similar representations. \n\nMulti-label classification as a standalone downstream task: Although the extension towards other tasks is mentioned in future works, having multi-label classification alone as the evaluation framework does not provide a full picture on leveraging information from frozen features.  \n\nMinor: Some of the formatting seems to be too cluttered, for example the contributions and Q sections in results. It takes away from the clarity of the paper rather than adding to it. However, I acknowledge that this is subjective. \n\n \n\n[1] Przewięźlikowski, Marcin, et al. \"Beyond [cls]: Exploring the true potential of Masked Image Modeling representations.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2025. \n\n[2] Rauch, Lukas, et al. \"Can Masked Autoencoders Also Listen to Birds?.\" arXiv preprint arXiv:2504.12880 (2025)."}, "questions": {"value": "Control of prototype distributions: \nHow are the cosine similarities of prototypes mostly zero after training (Figure 4) if there is no explicit method to control the distribution?\nWhat is preventing two prototypes from learning the same thing? More specifically, why does the \\(\\pm{1}\\) constraint force near-0 similarity? It is not clear in the paper, and how this prototype-to-class contributions emerge is not explained in the results.  \n\nWhy exactly does the binarization work better in some tasks and not in others?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3WfoSNlZGW", "forum": "FbY5Co2NWk", "replyto": "FbY5Co2NWk", "signatures": ["ICLR.cc/2026/Conference/Submission20520/Reviewer_gW4z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20520/Reviewer_gW4z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924826176, "cdate": 1761924826176, "tmdate": 1762933940857, "mdate": 1762933940857, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}