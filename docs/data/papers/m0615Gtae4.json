{"id": "m0615Gtae4", "number": 9085, "cdate": 1758110037493, "mdate": 1759897744520, "content": {"title": "Adaptive Routing of Experts via Fuzzy Rule Interpolation for Efficient Multimodal Learning", "abstract": "Multimodal learning integrates heterogeneous data such as text, images, and audio, but existing Mixture of Experts (MoE) frameworks still face two critical limitations: (1) fixed skip rates that fail to adapt to task difficulty, and (2) inefficient expert selection guided by static priors. These issues hinder scalability and stability in large-scale scenarios with diverse semantic patterns.  To address these limitations, we propose a Fuzzy Router that incorporates fuzzy rule interpolation (FRI) into Routing of Experts (RoE) for adaptive and efficient expert selection. A sparse fuzzy rule base, derived from prior knowledge and expert experience, is expanded via interpolation to enable nuanced routing decisions based on task complexity. This design dynamically adjusts skip rates, reduces redundant computation, and maintains accuracy through adaptive refinement.  Experiments across multiple multimodal benchmarks demonstrate that our method reduces routing data and time by more than 68\\%, shortens overall training time by 16.7\\%, and preserves competitive performance. These results highlight FRI as a principled mechanism for adaptive resource allocation, advancing efficient and scalable multimodal MoE/RoE systems.\n Our code is open-sourced in the supplementary materials.", "tldr": "We use fuzzy logic to make AI routing decisions smarter—dynamically skipping computational layers based on task difficulty rather than using fixed skip rates, achieving 67% training efficiency gains while maintaining accuracy in multimodal AI models.", "keywords": ["Multimodal Learning", "Mixer-of-Experts", "Fuzzy Rule Interpolation"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c4128bc7911645c360db955516b0f859be2e1ee1.pdf", "supplementary_material": "/attachment/c3d0651da6416af5694ecd7f38b71bc0a261cf29.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes an improvement to Mixture-of-Experts architectures for multimodal large models, targeting their limits in dynamic inference. The authors point out two issues with current expert-routing methods: (1) fixed skip rates that fail to adapt to task difficulty, and (2) inefficient expert selection due to reliance on static priors. To address this, the paper introduces a Fuzzy Router that integrates Fuzzy Rule Interpolation, bringing fuzzy-control ideas into the Routing-of-Experts framework to enable task-dependent layer skipping and expert selection. Start with a small set of prior-knowledge rules and expand them via interpolation so routing decisions can vary finely with input uncertainty and cross-modal correlations, thereby deciding at each layer whether to run the full Transformer block or take a lightweight skip path. At inference time, the skip rate is inferred directly from the rule base to cut redundant computation; during training, the rule base can be automatically refined to track changes in task difficulty."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Introduce fuzzy control theory into expert routing by integrating a Fuzzy Rule Interpolation mechanism within the RoE framework. This uses a fuzzy rule base to directly infer each layer’s execution policy, enabling dynamic adjustment of skip rates and expert selection based on task complexity.\n\n2. Substantial efficiency gains: the routing stage can be trained with only about one-third of the data, routing overhead drops by roughly 68.4%, and overall training time is reduced by 16.7%."}, "weaknesses": {"value": "1. The description of the fuzzy membership functions and the partitioning of linguistic variables is too brief and leaves me confused. The authors mention $(x_1, x_2, x_3)$ as text uncertainty, image uncertainty, and cross-modal correlation, and say they use triangular membership functions to partition the fuzzy sets. But the paper does not provide the specific parameters of those membership functions or explain how the partition thresholds are chosen.\n\n2. Using the entropy of text and image features to label “low/medium/high” uncertainty directly can be misleading. Some images may have high entropy yet still fall into the low-uncertainty category. Treating “feature entropy” as uncertainty could misclassify “clearly solvable cases with high-frequency textures” as “high uncertainty.” How can this be addressed?\n\n3. How would different choices of the hyperparameter β in Sec. 4.2 affect accuracy and the skip rate? Also, if the “high-error” threshold in Sec. 3.1 were changed from 20% to other values, what differences would we see?\n\n4. How much influence do the initial rules have on performance? How much does the model rely on prior knowledge?\n\n5. In Section 4.1, the paper states: “The benchmarks used in this paper are five common vision-language and five recently proposed MLLM benchmarks.” However, the tables only report results for ScienceQA, GQA, MMB, and SEED. What are the other six benchmarks, and what are their results?\n\n6. In Section 3.6, the paper states: “$f_{\\text{opt}}(x)$ is the optimal skip rate (1 = skip layer via adapter, 0 = retain original layer) derived from human annotation or validation-set ground truth.” How exactly is this parameter determined?"}, "questions": {"value": "Please see the detailed information in the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "agiexqgi4R", "forum": "m0615Gtae4", "replyto": "m0615Gtae4", "signatures": ["ICLR.cc/2026/Conference/Submission9085/Reviewer_WqF6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9085/Reviewer_WqF6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761562828966, "cdate": 1761562828966, "tmdate": 1762920790962, "mdate": 1762920790962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paepr proposes an innovative \"Fuzzy Router\" that uses Fuzzy Rule Interpolation (FRI) to evaluate task complexity (by calculating text/image entropy and cross-modal similarity) and dynamically decide whether to skip a layer based on a self-learning rule base. The method successfully achieves true \"adaptive\" routing (more computation for hard tasks, less for easy ones), reducing router training data and time by over 68% and cutting total training time by 16.7%, while maintaining high accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Targeted Innovation: Integrates Fuzzy Rule Interpolation (FRI) into Routing of Experts (RoE) to directly address two core limitations of traditional MoE/Ro: fixed skip rates and inefficient static expert selectio, enabling task difficulty-adaptive routing, with strong alignment between innovation and problem definition.\n2. High Efficiency: The Router stage uses only 31.3%-34.3% of RoE's data but saves over 68% of time, requiring no additional annotation costs, balancing efficiency and practicality.\n3. Good Main Experiments: Covers 3 mainstream models and 4 benchmark datasets, verifying over 68% reduction in routing time/data, 16.7% shorter total training time, and stable accuracy, with comprehensive reasoning."}, "weaknesses": {"value": "1.  I'm not an expert in this area, so I was wondering if there are any references for the use of these three uncertainties, or perhaps an intuitive explanation? Why do these three factors determine whether to skip certain layers? Is the rationale that more difficult samples require more computation? Finally, have you explored other methods or baselines for determining sample difficulty to demonstrate the superiority of your proposed method? \n2. About Ablation Studies:  The paper only verifies the \"necessity of FRI\" through Table 4 (comparing \"Fuzzy (only)\" and \"Fuzzy-Router\") but does not decompose the independent contributions of \"fuzzy antecedent variables (x₁/x₂/x₃).\" For example: If \"cross-modal similarity (x₃)\" is removed, will using only text entropy + image entropy lead to bias in skip rate decisions? If text entropy (x₁) is replaced with other uncertainty indicators, will performance change? \n3. Regarding the comparison of model performance: In the main experiments, the paper’s results show only a modest improvement in Accuracy (Acc.) compared to the baseline, and this phenomenon is observed on the two benchmarks, GQA and SEED.\n4. The paper currently only supports the text-image bimodal scenario. If extended to audio, video, and other modalities in the future, what is the design idea for antecedent variables (x₁/x₂/x₃)? For example: Should the uncertainty of audio be quantified by \"spectral entropy\" or \"signal-to-noise ratio\"?"}, "questions": {"value": "see in weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o2kfdyeoKv", "forum": "m0615Gtae4", "replyto": "m0615Gtae4", "signatures": ["ICLR.cc/2026/Conference/Submission9085/Reviewer_Q6f6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9085/Reviewer_Q6f6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761671340426, "cdate": 1761671340426, "tmdate": 1762920790567, "mdate": 1762920790567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Fuzzy Router that integrates Fuzzy Rule Interpolation (FRI) into the Routing of Experts (RoE) framework to address two key limitations of existing Mixture of Experts (MoE) systems: Inflexible skip rates that do not adapt to task difficulty and inefficient expert selection based on static priors. The method dynamically adjusts routing decisions using a sparse fuzzy rule base, expanded via interpolation, and refined during training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Novelty: The integration of fuzzy logic and rule interpolation into dynamic routing is well-motivated.\n\nClarity: The paper is well-organized, with clear explanations of the fuzzy antecedent computation, interpolation mechanism, and training strategy.\n\nEmpirical Validation: Extensive experiments on multiple benchmarks (ScienceQA, GQA, MMB, SEED) and models (LLaVA, VILA, LLaVA-HR) demonstrate consistent improvements in speed and efficiency without sacrificing accuracy.\n\nAblation Studies: Table 4 effectively validates the contribution of key components (interpolation, sparse regularization).\n\nReproducibility: The paper includes a reproducibility statement, pseudo-code, and promises to release code and models."}, "weaknesses": {"value": "1. Limited improvement and lacking enough baselines: Table 1 shows limited advantages over RoE-20%. Also, while RoE baselines are included, comparisons to other adaptive routing or sparse recent MoE methods (e.g., Switch Transformer, HashLayer) could strengthen the claim of superiority. Hence, the advantages over existing works are not convincing enough. \n2. Comparison fairness: one of the disadvantage of the proposed method is its reliance on two-stage training. Hence, other two-stage training-based  MoE methods should be involved. Also, I wonder whether the comparison of training time contains the time in each stage. \n3. Some hyperparameters such as thresholds are important for its performance, which limits its adaptivity. \n4. Based on weakness 1 and 3, I hold doubts about its practical values, especailly for followers, maybe there is limited space for improvement as the intrinsic disadvantages in fuzzy control. I hope the authors could further clarify the advantages over other adaptive learning methods."}, "questions": {"value": "Refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BUsugCOnRX", "forum": "m0615Gtae4", "replyto": "m0615Gtae4", "signatures": ["ICLR.cc/2026/Conference/Submission9085/Reviewer_6yZm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9085/Reviewer_6yZm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883106876, "cdate": 1761883106876, "tmdate": 1762920790183, "mdate": 1762920790183, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a \"Fuzzy Router\" that integrates fuzzy logic and Fuzzy Rule Interpolation (FRI) into the Routing of Experts (RoE) framework for multimodal learning. The work aims to solve two primary limitations of existing Mixture-of-Experts (MoE) and RoE systems: 1) the use of fixed, static skip rates that cannot adapt to varying task or input difficulty, and 2) inefficient expert selection based on static priors.\n\nThe proposed Fuzzy Router makes dynamic routing decisions (i.e., whether to skip a transformer layer or execute it) based on three \"fuzzy antecedents\" computed from the input: text uncertainty (entropy), image uncertainty (entropy), and cross-modal relevance (cosine similarity). The system begins with a sparse, knowledge-based rule set. When an input's features do not match an existing rule, FRI is used to interpolate and generate an appropriate routing decision. This rule base is dynamically expanded and refined through a two-stage training process and a \"sparse region rule augmentation\" strategy.\n\nThe authors apply their Fuzzy Router to several MLLMs (LLaVA-1.5, LLaVA-HR, VILA). Experimental results demonstrate significant efficiency gains, all while maintaining competitive accuracy compared to baseline and fixed-rate RoE models. A key finding is that the router successfully learns to adapt its skip rate based on task difficulty."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel and Well-Motivated Approach: \n\n    The core idea of integrating fuzzy logic and FRI with expert routing is a novel and conceptually interesting contribution. It provides an elegant, interpretable, non-black-box mechanism for adaptive computation, addressing a well-known limitation in MoE/RoE systems.\n\n- Strong Empirical Efficiency Gains: \n\n    The reported efficiency improvements are a major practical strength. A 16.7% reduction in total training time is a significant and valuable contribution in the resource-intensive domain of MLLMs.\n\n- Demonstrated Adaptability: \n\n     The paper's primary claim of adaptive routing is well-supported by experimental evidence (Table 2). The results clearly show the Fuzzy Router intelligently allocates computational resources, using higher skip rates for easier tasks (e.g., ScienceQA) and lower skip rates for more complex ones (e.g., SEED). This is a clear advantage over fixed-rate RoE.\n\n- Maintained Performance: \n\n    Crucially, these significant efficiency gains are achieved without a corresponding loss in model accuracy. The Fuzzy-Router models consistently perform on par with, or even slightly better than, the baselines, demonstrating a superior efficiency-to-performance trade-off.\n\n- Interpretability: \n\n    The use of fuzzy logic grounds the routing decisions in interpretable, linguistic-style rules based on intuitive features (uncertainty, relevance), which is a valuable property."}, "weaknesses": {"value": "- Limited Baseline Comparisons: \n\n    This is a significant limitation. The paper only compares its method against the baseline MLLMs and the RoE framework. It fails to compare against other relevant work in dynamic and adaptive computation, such as other dynamic MoE routing mechanisms (e.g., Expert Choice) or token-skipping models (e.g., SkipGPT, DiffMoE). This makes it difficult to contextualize the full contribution.\n\n- Unclear Inference Overhead: \n\n    While the paper shows clear gains in training time and throughput (samples/sec) due to layer skipping, it fails to analyze the direct computational overhead (latency) of the Fuzzy Router itself. The fuzzy logic system (antecedent computation, rule matching, FRI) is significantly more complex than a standard RoE router (often a single linear layer). A direct analysis is needed to ensure the router itself is not a new inference bottleneck, especially for tokens that are not skipped.\n\n- Scalability Concerns: \n\n     The paper demonstrates the rule base growing from 3 to 27 rules in a 3-dimensional antecedent space. This raises serious questions about scalability. The \"curse of dimensionality\" is a well-known problem in fuzzy systems, and it is unclear how this approach would perform with a higher-dimensional antecedent space or on much larger-scale models.\n\n- Limited Ablation Studies: \n\n     The paper's ablations are not comprehensive enough. For instance, there is no justification for the specific choice of the three antecedents; the contribution of each is not ablated. Furthermore, the sensitivity to various new hyperparameters (e.g., $\\alpha$, $\\beta$, temperature) is not analyzed.\n\n- Lack of Theoretical Grounding: \n\n    The paper is almost entirely empirical. It does not provide a theoretical analysis of how the FRI mechanism (a symbolic method) interacts with gradient-based optimization in a deep learning context, nor does it offer any convergence guarantees for the adaptive rule-refinement process.\n\n- Typos\n\n   Figures 1 & 2: \"no mathing rules\" / \"mathing R\" should be \"no matching rules\" / \"matching R\"."}, "questions": {"value": "- Broader Baseline Comparison: \n\n     To strengthen the paper, it is advised to discuss and, if possible, compare their results against other state-of-the-art dynamic routing or adaptive computation methods, not just RoE.\n\n- Inference Latency Analysis: \n\n      It is advised to provide a direct analysis (e.g., in milliseconds per token) of the computational latency added by the Fuzzy Router's logic, separate from the gains achieved by skipping layers. This is essential for a complete efficiency analysis.\n\n- More Thorough Ablations: \n\n      It is advised to add ablation studies to justify their choice of antecedents (e.g., testing with only two or different uncertainty metrics) and to analyze the sensitivity of the model to key hyperparameters.\n\n- Scalability Discussion: \n\n     Even without new experiments, the paper would be improved by adding a discussion of the potential scalability limitations and how the FRI-based approach might be adapted or simplified for higher-dimensional feature spaces."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0xNJOlZi5p", "forum": "m0615Gtae4", "replyto": "m0615Gtae4", "signatures": ["ICLR.cc/2026/Conference/Submission9085/Reviewer_3tN6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9085/Reviewer_3tN6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762261360446, "cdate": 1762261360446, "tmdate": 1762920789869, "mdate": 1762920789869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}