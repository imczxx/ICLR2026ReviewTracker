{"id": "MWtm2f1tyG", "number": 19409, "cdate": 1758295997988, "mdate": 1759897040663, "content": {"title": "IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer", "abstract": "Industrial acoustic signals encode machine state, yet prevailing data-driven approaches are task-specific supervised pipelines that generalize poorly beyond their design conditions. Progress is further limited by the scarcity of large-scale datasets and pretrained models tailored to active shop floor audio. To address this, we introduce DINOS (Diverse INdustrial Operation Sounds), a dataset of 74,149 recordings totaling over 1,093 hours collected from active manufacturing lines across diverse processes and operating regimes. We also provide IMPACT(Industrial Machine Perception via Acoustic Cognitive Transformer), a reference model pretrained on DINOS to standardize evaluation. Our benchmark is structured in four machine-specific steps: (1) baseline discrimination, (2) moderate operational complexity, (3) scalability to unseen equipment, and (4) domain shift and sensor modality adaptation. Across tasks, models pretrained or fine-tuned on DINOS consistently outperform general-purpose audio models, demonstrating the value of domain-specific pretraining for industrial acoustic perception.", "tldr": "We introduce an industrial sound datasets and benchmarks with a reference pretrained model.", "keywords": ["Industrial sound dataset", "Machine monitoring", "Manufacturing", "Self-supervised learning", "Pretrainedmodel"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c666beb51193d3126bb1a445dcfa06facf8e07f2.pdf", "supplementary_material": "/attachment/20ab26429db55c21117de67ce1ecea9eaaeaca78.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a new dataset DINOS, consisting of 74149 acoustic samples collected from active manufacturing lines. The authors then proposed a pretraining method, IMPACT, which is conceptually similar to EAT. The authors evaluated its performance on 27 downstream tasks using DINOS."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The collection of DINOS is an earnest effort. DINOS consists of the signals collected from both a microphone and a stethoscope, and covers various types of equipment.\n2. The authors evaluated the performance of various off-the-shelf pretrained models on DINOS."}, "weaknesses": {"value": "1. The evaluation is critically insufficient and cannot show the superiority of IMPACT. The authors did not apply other pretraining methods (e.g., AudioMAE) on DINOS. They only evaluated the off-the-shelf pretrained models (e.g., a model pretrained using AudioMAE method on other acoustic datasets) on DINOS. Since IMPACT is a pretraining method, if the authors want to show the superiority of IMPACT, they need to **pretrain** IMPACT and other pretraining methods (e.g., AudioMAE) **on the same datasets**.\n2. The proposed pretraining method is conceptually not sufficiently novel. Its similarity to EAT is also acknowledged by the authors.\n3. Therefore, if the majority of the contributions lie in the introduction of DINOS, then this paper might be below the bar of ICLR. It might be more suitable to submit this paper to a venue specialized in industrial sensing or a venue offering dataset tracks.\n4. The presentation could be improved overall."}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "E23S76vTdl", "forum": "MWtm2f1tyG", "replyto": "MWtm2f1tyG", "signatures": ["ICLR.cc/2026/Conference/Submission19409/Reviewer_66g5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19409/Reviewer_66g5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19409/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760589443588, "cdate": 1760589443588, "tmdate": 1762931326412, "mdate": 1762931326412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## An open-access dataset of industrial operation sounds\n\n- Proposed DINOS, a dataset with over ~1000 hours of recordings from active manufacturing lines.\n- Proposes IMPACT, a reference baseline models trained on the DINOS dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Paper is well written (except some minor grammatical errors. Authors, please recheck for missing spaces and punctuation.)\n- A comprehensive benchmarking setup, with distinct pretraining and downstream benchmarking sets is provided.\n- Limited availability of public, large-scale corpora is a major pain point in manufacturing and floor monitoring, so the dataset could indeed prove invaluable to the community.\n- Evaluation, to the extent done in the paper, is good."}, "weaknesses": {"value": "- Based on the results alone, it is hard to say how useful the proposed dataset is over the publicly available DCASE2025 Challenge Task 2 dataset for pretraining."}, "questions": {"value": "1. Is there an overlap between the pretraining set for DINOS and DCASE2025 Challenge Task 2? \n2. Why is your paper titled after the model, and not the dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PojjjgQnnC", "forum": "MWtm2f1tyG", "replyto": "MWtm2f1tyG", "signatures": ["ICLR.cc/2026/Conference/Submission19409/Reviewer_erTN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19409/Reviewer_erTN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19409/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920676617, "cdate": 1761920676617, "tmdate": 1762931325911, "mdate": 1762931325911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DINOS (Diverse INdustrial Operation Sounds), a large-scale dataset for understanding Industrial acoustic signals at a large scale. The paper also trained a self-supervised baseline model on the data IMPACT (Industrial Machine Perception via Acoustic Cognitive Transformer)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is unique and interesting. The paper is written well and contains detailed experiments. The self-supervised model IMPACT, trained on the proposed data, achieves the best performance across the majority of the tasks."}, "weaknesses": {"value": "The paper has limited novelty. The primary contribution of the paper is the dataset; the IMPACT model is based on a well-known existing self-supervised model, EAT."}, "questions": {"value": "What is the number of parameters across various models in Table 4? Does the Impact model work better because it is a larger model, or due to pretraining on DINOS?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "kAEn5W4pw4", "forum": "MWtm2f1tyG", "replyto": "MWtm2f1tyG", "signatures": ["ICLR.cc/2026/Conference/Submission19409/Reviewer_US9t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19409/Reviewer_US9t"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19409/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962711750, "cdate": 1761962711750, "tmdate": 1762931325469, "mdate": 1762931325469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}