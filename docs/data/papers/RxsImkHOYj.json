{"id": "RxsImkHOYj", "number": 2731, "cdate": 1757226000439, "mdate": 1759898130766, "content": {"title": "DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation", "abstract": "Contact languages like English exhibit rich regional variations in the form of dialects, which are often used by dialect speakers interacting with generative models. However, can multimodal generative models effectively produce content given dialectal textual input? In this work, we study this question by constructing a new large-scale benchmark spanning six common English dialects. We work with dialect speakers to collect and verify over 4200 unique prompts and evaluate on 17 image and video generative models. Our automatic and human evaluation results show that current state-of-the-art multimodal generative models exhibit 32.26% to 48.17% performance degradation when a single dialect word is used in the prompt. Common mitigation methods such as fine-tuning and prompt rewriting can only improve dialect performance by small margins (< 7%), while potentially incurring significant performance degradation in Standard American English (SAE). To this end, we design a general encoder-based mitigation strategy for multimodal generative models. Our method teaches the model to recognize new dialect features while preserving SAE performance. Experiments on models such as Stable Diffusion 1.5 show that our method is able to simultaneously raise performance on five dialects to be on par with SAE (+34.4%), while incurring near zero cost to SAE performance.", "tldr": "DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation", "keywords": ["multimodality", "dialect", "text-to-image", "text-to-video", "robustness"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8ef9ef1ee0ec0e395c34efd2190b4e7f64d3fdfd.pdf", "supplementary_material": "/attachment/424caa05d0b27cff7f42e18c27a866c2504bb224.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces DialectGen, a benchmark evaluating dialect robustness in text-to-image and text-to-video generation. Moreover,  it proposes a method including three new loss functions to prevent significant dialect performance drops."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-written and easy to follow\n2. There is sufficient work related to benchmark construction and algorithm design."}, "weaknesses": {"value": "The biggest issue lies in the contribution/value of the paper. There are many unresolved challenges in text-to-image and text-to-video models, such as visual aesthetics and the ability to adhere to complex prompts. However, prompt alignment primarily reflects whether the generative model can accurately simulate the objects and scenes described in the prompt, it measures generative capability rather than understanding (as many current models already use LLMs as text encoders to pursue stronger text understanding). For dialect prompts, the greater difficulty lies in feature extraction by the text encoder due to the lack of high-quality dialect training data. Therefore, I believe the dialect evaluation topic is more meaningful for assessing the understanding ability of the text encoder rather than the generative capability of the model. Assuming the availability of high-quality dialect data that enables the text encoder to effectively learn dialect features, I think simple dialect mismatch issues would no longer exist in generative models.\n\nThus, I consider the contribution of the paper to be limited, as it does not address the critical challenges of generative models. Instead, the issue of dialect understanding and adherence should be more appropriately tackled within the realm of language models."}, "questions": {"value": "Please see Weakness. I hope these issues can be resolved, and I will reconsider my grading."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PH6CRlTB6J", "forum": "RxsImkHOYj", "replyto": "RxsImkHOYj", "signatures": ["ICLR.cc/2026/Conference/Submission2731/Reviewer_UK5K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2731/Reviewer_UK5K"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2731/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807542036, "cdate": 1761807542036, "tmdate": 1762916350507, "mdate": 1762916350507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper constructs DialectGen, a large-scale benchmark for multimodal generative models’ dialect robustness, covering 6 English dialects (e.g., SAE, AAE, InE) with 4,200 validated SAE-dialect prompt pairs. Evaluating 17 T2I/T2V models (e.g., Stable Diffusion, DALL-E), the authors find a single dialect lexical feature causes 32.26%–48.17% performance degradation, with T2V models like Wan 2.1 suffering the worst drops. Existing methods (e.g., UNet fine-tuning) only improve dialect performance by <7% and harm SAE results, so the authors propose an encoder-based strategy with three losses. This method raises 5 dialects’ performance to match SAE (+34.4% on average) with near-zero SAE loss (<1%) on Stable Diffusion 1.5/XL."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. DialectGen targets lexical variations (shown to drive >25% performance drops, vs. <2% for grammatical variations) and is built via authoritative regional dictionaries, filtering of derogatory/culture-unique terms, and validation by dialect speakers (35.9% of prompts rejected), ensuring high reliability.\n\n2. The authors assess 17 models across two prompt settings and three metrics (VQAScore, CLIPScore, human evaluation).\n\n3. The encoder-based strategy avoids the SAE performance loss of baselines. Ablation studies confirm each loss component’s value."}, "weaknesses": {"value": "1. DialectGen includes only 6 English dialects, omitting low-resource varieties (e.g., Caribbean English, Australian English) that are more vulnerable to allocational harms, limiting the benchmark’s global generalizability.\n\n2. While the paper notes Prompt Revision (e.g., GPT4.1 Prompt Translate) only improves dialect performance by up to 6.1%, it lacks detailed analysis of why this method fails—especially given that standalone LLM translation (e.g., GPT-4o translating dialect words to SAE) may appear effective in isolated tests. No failure cases or contextual constraints (e.g., concise prompts) are discussed.\n\n3. The proposed encoder-based method is only tested on Stable Diffusion 1.5 and SDXL (T2I models). T2V models (which suffer the worst performance drops) and proprietary/non-diffusion architectures (e.g., DALL-E 3, Open-Sora) are unaddressed, limiting the method’s real-world applicability. In contrast, Prompt Revision exhibits greater flexibility: it relies solely on general-purpose LLMs (e.g., GPT4.1, LLaMA 3) to rewrite or translate input prompts. This makes it easily applicable to proprietary models like DALL-E 3, as it does not depend on model developers providing fine-tuning interfaces or exposing internal architectural details."}, "questions": {"value": "1. You note Prompt Revision methods (e.g., GPT4.1 Prompt Translate) only improve dialect performance by up to 6.1%, yet standalone tests (e.g., using GPT-4o with “Translate this sentence into standard English”) can accurately replace dialect words with SAE equivalents. Could you explain why Prompt Revision underperforms in your experiments? Please provide specific failure cases (e.g., prompts where revision failed to replace dialect lexemes, or revised prompts still led to poor model generation) and analyze contextual factors.\n\n2. GPT4o was used to generate DialectGen’s prompts, which may introduce SAE-centric biases (e.g., overrepresenting Western contexts). Did you validate that these prompts reflect natural dialect usage (e.g., comparing to real-world dialect text from social media or regional corpora) or confirm with dialect speakers that prompts align with how they would naturally phrase the same scenes (e.g., for “carnal” in ChE)?\n\n3. Your KL Regularization uses MSCOCO, an SAE-centric image-caption dataset. Could this reinforce biases in dialect generations—for example, making “ang pow” (SgE) look more like Western “red packets” than culturally accurate Singaporean red envelopes? Have you tested region-specific datasets (e.g., Singaporean food/image corpora for SgE) for KL Regularization, and if so, how did performance and cultural alignment change?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GuBVeO56wp", "forum": "RxsImkHOYj", "replyto": "RxsImkHOYj", "signatures": ["ICLR.cc/2026/Conference/Submission2731/Reviewer_nKia"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2731/Reviewer_nKia"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2731/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898894025, "cdate": 1761898894025, "tmdate": 1762916350286, "mdate": 1762916350286, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a critical issue: generative models fail when users input dialectal English (like Singlish or AAE). The authors introduce \"DialectGen,\" a high-quality benchmark built with native speakers, to prove this performance drop (up to 48%). They also propose a smart encoder-tuning method that teaches models new dialect words (e.g., \"whip\" = \"car\") without making them forget the original meaning (\"whip\" = \"lash\") or hurting general performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Important Problem: This is a timely and crucial problem. As models go global, supporting all users, not just those speaking standard English, is essential.\n\nExcellent Benchmark: The \"DialectGen\" dataset is a significant contribution. Using native speakers for validation is the right way to do this, and the paired (SAE vs. Dialect) design is perfect for isolating the problem.\n\nWell-Designed Method: The mitigation strategy is clever. The three-part loss function (Dialect Learning, Polysemy Control, KL Reg) is an elegant way to add new knowledge while protecting existing abilities. The results (fixing dialect performance with <1% hit to SAE) are excellent."}, "weaknesses": {"value": "Video Models Untested: The fix was only applied to image models (SD 1.5, SDXL). The paper shows video models suffer even more from this problem, so it's a clear gap not to test the solution on them, even if it was just due to compute constraints.\n\nCompositionality: The benchmark tests single-word swaps. It's unclear how the models would handle prompts with multiple dialect words or even mixed dialects."}, "questions": {"value": "See the weakness. I found this task quite interesting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mNz0RKAK3E", "forum": "RxsImkHOYj", "replyto": "RxsImkHOYj", "signatures": ["ICLR.cc/2026/Conference/Submission2731/Reviewer_cLvx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2731/Reviewer_cLvx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2731/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932005435, "cdate": 1761932005435, "tmdate": 1762916349928, "mdate": 1762916349928, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce DialectGen, a benchmark for evaluating dialect robustness in multimodal generation across six english dialects."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- the analysis and modeling on english dialect data is rarely explored\n- the dataset is carefully designed with dialect speaker validation and semantic equivalence filtering\n- over 17 models are evaluated, using both automatic metrics and human judgement"}, "weaknesses": {"value": "-  the proposed mitigation approach is a combination of standard alignment objectives, lacking deeper theoretical or architectural innovation\n- only six dialects are included, which restricts generalizability and reduces potential community impact; it would be more convincing if extended to more dialects or other languages.\n- the main advance lies in dataset construction and fine-tuning; while valuable empirically, the contribution is incremental and limited"}, "questions": {"value": "Please refer to the weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uptkdschYO", "forum": "RxsImkHOYj", "replyto": "RxsImkHOYj", "signatures": ["ICLR.cc/2026/Conference/Submission2731/Reviewer_F7tQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2731/Reviewer_F7tQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2731/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997524695, "cdate": 1761997524695, "tmdate": 1762916349277, "mdate": 1762916349277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}