{"id": "SnIK1W2Fue", "number": 3017, "cdate": 1757316792061, "mdate": 1759898113301, "content": {"title": "MultiTune: Phase-Aware Multi-Objective Optimization for Diffusion Models", "abstract": "Diffusion models excel at basic text-to-image but struggle to align with specific objectives. While reinforcement learning offers a promising solution, single-reward setups often lead to overfitting. To this end, multi-objective optimization methods are proposed. However, such methods face challenges of goal conflicts, inflexible reward fusion, and low efficiency, hindering overall performance across diverse criteria.\nTo address these challenges, we propose MultiTune, a lightweight multi-objective framework tailored to the diffusion process. We decompose the optimization targets into Phase and Main objectives, where the former involves multiple phases of stepwise guidance and the latter ensures overall convergence.\nWe first introduce a phase-aware switching strategy that aligns with the structural-to-textural evolution in diffusion, enabling dynamic and decoupled scheduling of Phase Objectives. Then, we adaptively balance the Phase and Main Objectives based on variations in image quality for on-demand collaboration. \nExperiments demonstrate that MultiTune outperforms SOTA methods in aesthetics, semantics, details, and style, achieving leading performance across five quantitative metrics.", "tldr": "", "keywords": ["Diffusion Model；Text-to- Image"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ba86cdaa81aa6fea5f20cbf9f0f0013f3c30f074.pdf", "supplementary_material": "/attachment/ea20adfcb0ac5c3bdc411bfb0fc22f3fb0fa7dbb.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a novel multi-objective RL framework for text-to-image diffusion models by introducing an additional phase objective that gradually changes throughout the generation process. The proposed phase objective serve to mitigate the sparse reward problem, where the main reward can only be evaluated on the fully generated image. The authors conducted extensive experiments and demonstrated that the proposed method outperforms existing RL baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The presentation is clear and easy to understand. The Phase reward is well-motivated and different phases align with intuitive understanding about the diffusion generation process.\n2. The experiments are comprehensive, incorporating a wide range of metrics (CLIP, Pickscore) and base models (SDv1.5, SD2), demonstrating that the proposed method is universally applicable. The author also provided subjective evaluations using human and VLM judge, further strengthening their results.\n3. The author provided a thorough ablation studies on various design choices."}, "weaknesses": {"value": "1. The author experimented mostly on SD-series U-Net, it is unclear if the proposed method works for more recent DiT models based on rectified flow formulation, such as SD3, Sana, Flux, etc.\n2.  Given 1, the result in table 5 is especially concerning, as it raises the issue of the scalability of the proposed method. While SD-XL is a stronger base model, the performance after RL fine-tuning is actually worse than SDv1.4. The author should include a row of base model's performance in this table so it is easier to see the improvements. I imagine the improvements with respect to base model will be smaller? If that is the case, the author should provide additional discussion."}, "questions": {"value": "1. What  exactly are the phase reward models? In Appendix C, the author used ambiguous terms like \" introduce a reward function (e.g., CLIP)\", \"considering texture and aesthetic preferences (e.g., PickScore)\". Is the reward model just CLIP and PickScore? Are other models also used? The authors should provide more concrete details for better reproducibility\n2. What is \"see Section X.X \" in page 15 L 806\n3. Figure 13 on Page 19 appears to be broken in PDF"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "86cg4P7JOI", "forum": "SnIK1W2Fue", "replyto": "SnIK1W2Fue", "signatures": ["ICLR.cc/2026/Conference/Submission3017/Reviewer_zFFf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3017/Reviewer_zFFf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801056426, "cdate": 1761801056426, "tmdate": 1762916503694, "mdate": 1762916503694, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of fine-tuning text-to-image diffusion models to satisfy multiple objectives rather than optimizing a single reward. To this end, the authors propose MultiTune, which introduces three key components: a phase-aware switching strategy, adaptive coordination of objectives, and efficiency-aware training optimization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of decomposing the denoising process into intuitive phases and tying objectives to those phases is meaningful.\n2. The experimental evaluation is extensive, covering multiple model backbones."}, "weaknesses": {"value": "1. The paper employs the “Simple-animals” dataset (45 classes for training, 398 for testing). To better support claims of generality, it would be valuable to include larger and more diverse prompt sets—such as GenEval [1] or datasets spanning multiple domains.\n2. More details are needed on computational cost. Specifically, what is the additional overhead (in memory and compute) introduced by the phase-aware switching and dynamic balancing mechanisms compared to simpler baselines?"}, "questions": {"value": "1. How are the structural and textural scores in Figure 1 computed? What model architectures are used for these evaluations?\n2. How exactly is the denoising trajectory divided into $P_{Structural}$, $P_{Textural}$ and $P_{Marginal}$. How are the corresponding timesteps determined?\n3. There are a few textual inconsistencies—for example, line 806 references “Section X.X.” Could the authors clarify which section this refers to?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1Bbsz8PA5Q", "forum": "SnIK1W2Fue", "replyto": "SnIK1W2Fue", "signatures": ["ICLR.cc/2026/Conference/Submission3017/Reviewer_d9rJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3017/Reviewer_d9rJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849793142, "cdate": 1761849793142, "tmdate": 1762916503517, "mdate": 1762916503517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MultiTune, a reinforcement learning framework for text-to-image diffusion models that dynamically switches optimization objectives during the denoising process.\nThe model separates diffusion steps into three stages — structural, textural, and marginal — and adaptively balances intrinsic and extrinsic rewards.\nExperiments across Stable Diffusion backbones show improvements on metrics such as AES, CLIP, and PickScore."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focuses on the characteristics of the diffusion process  — namely, the generation proceeds from global structures to fine details — and proposes an efficient learning method for multi-objective preference optimization.\n\n2. It conducts comprehensive experiments using multiple baselines and evaluation metrics, demonstrating performance improvements across all metrics."}, "weaknesses": {"value": "1. It is unclear from the main text whether Equation (4) truly addresses a multi-objective task.\n\n2. The proposed method does not guarantee functionality under arbitrary combinations of preference objectives. In particular, the structure formation phase is fixed to use CLIP as the guiding signal. Therefore, in terms of exploring the trade-offs inherent to true multi-objective preference optimization, the contribution appears somewhat limited."}, "questions": {"value": "1. Could you tell me why CLIP and ES are used solely as feedback signals for exploration rather than being directly optimized? Equation (4) does not appear to represent multi-objective preference learning?\n\n2. Why did the authors choose to fix the extrinsic reward to AES instead of dynamically optimizing CLIP or ES depending on the phase change?\n\n3. Have the authors considered alternatives to using CLIP as the guiding signal during the structure formation phase?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uOyP7Qz1Mh", "forum": "SnIK1W2Fue", "replyto": "SnIK1W2Fue", "signatures": ["ICLR.cc/2026/Conference/Submission3017/Reviewer_LokY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3017/Reviewer_LokY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969825660, "cdate": 1761969825660, "tmdate": 1762916503318, "mdate": 1762916503318, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The author divides the diffusion process into two objectives dynamically: Phase and Main Objective. The author claimed it reached SOTA performance."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "## Presentation: ~5th percentile\nIt can be observed that the grammar and paragraph organisation are nearly flawless; however, anything beyond a single paragraph becomes nonsensical from the perspective of a reader (see below).\n\n## Soundness: 10th~50th percentile\nThe paper uses experimental results to support its method, but I find it challenging to verify the details (see below).\n\n## Contribution: 5~25th percentile\n\nThe divisions of denoising steps may seem arbitrary in theory, but they are reasonable in practice.\n\n## Note:\n\nI hope the AC is aware that the rating is calibrated using estimation of percentiles to reduce evaluation noise effectively.\nThe rating is simply the mean of the three aspects."}, "weaknesses": {"value": "Based on the writing, this paper should not be accepted. \n\n## Presentation\n\nThe writing is almost unintelligible. By the time I finished your methodology:\n\n1. I have a limited understanding of the Phase/Main objective beyond the term you coined, including how it is implemented and the rationale for choosing the key phase transition step $t$ (I assume it’s Eq (3) with 80% confidence, but see the issues below). I was misled by Figure 2 as the caption does not present the details of Figure 2.\n2. Is your approach an inference-time scaling method, or a training method with a different objective? I’m about 80% confident it’s the latter, but you shouldn't make me guess.\n3. Are you using DDIM/DDPM/score-based SDE to model the diffusion model? I assume it’s DDIM, based on $\\hat{x}_0(x_t)$ on Line 173 with 60% confidence. **This is a fundamental detail that should be presented to every reader.**\n\nThese details are either missing altogether or scattered across the text rather than presented coherently. As a result, the reading experience is terrible as I have to keep half-formed guesses in mind just to follow along.\n\n\n\n### Equation 3\n\nI believe Equation (3) defines the criterion for a phase transition, though it takes more effort to discern this compared to other papers. I still raise some issues.\n\n1. You should group this equation (on page 4) with Figure 1 (on page 2) if Figure 1 is the evidence of this choice of design. \n2. Why does the definition on Line 193 call variance (and why does it have no equation labelling?) What does the arrow mean in Equation (3)? What is the indicator for phase transition used for?\n\n\n\n\n\n## Contribution\n\n### Reproducibility\n\nA lot of important details are oversimplified, especially for those parameter settings. I don’t think a reader can reproduce your result by reading this paper.\n\n### Novelty\n\nThe observation that diffusion models denoising in a hierarchical manner is not new, especially since this has already been stated in several theoretical papers like score-based SDE (Yang et. al), EDM (Karras et. al.)\n\n## Soundness\n\nI want to evaluate the soundness based on the implementation details and the methodology. However, my limited understanding of the methodology made it difficult for me to make an accurate judgement, so I can only give my lower bound of my estimation. To be fair, I will lower my confidence to 3. Admittedly, the rather unpleasant experience I had while reading this paper may have influenced my assessment in this respect, although I recognise that I should have evaluated it independently.\n\n\n\nThe final rating was simply a linear transform of the average of the estimated percentile."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "E1R5Nnq4uf", "forum": "SnIK1W2Fue", "replyto": "SnIK1W2Fue", "signatures": ["ICLR.cc/2026/Conference/Submission3017/Reviewer_eoCG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3017/Reviewer_eoCG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986563303, "cdate": 1761986563303, "tmdate": 1762916503147, "mdate": 1762916503147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}