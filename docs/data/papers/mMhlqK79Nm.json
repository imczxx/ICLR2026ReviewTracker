{"id": "mMhlqK79Nm", "number": 17753, "cdate": 1758280144523, "mdate": 1759897155967, "content": {"title": "Learning Interpretable Representations Leads to Semantically Faithful EEG-to-Text Generation", "abstract": "Pretrained generative models have opened new frontiers in brain decoding by enabling the synthesis of realistic texts and images from non-invasive brain recordings. However, the reliability of such outputs remains questionable—whether they truly reflect semantic activation in the brain, or are merely hallucinated by the powerful generative models. In this paper, we focus on EEG-to-text decoding and address its hallucination issue through the lens of posterior collapse. Acknowledging the underlying mismatch in information capacity between EEG and text, we reframe the decoding task as semantic summarization of core meanings rather than previously verbatim reconstruction of stimulus texts. To this end, we propose the Generative Language Inspection Model (GLIM), which emphasizes learning informative and interpretable EEG representations to improve semantic grounding under heterogeneous and small-scale data conditions. Experiments on the public ZuCo dataset demonstrate that GLIM consistently generates fluent, EEG-grounded sentences without teacher forcing. More importantly, it supports more robust evaluation beyond text similarity, through EEG-text retrieval and zero-shot semantic classification across sentiment categories, relation types, and corpus topics. Together, our architecture and evaluation protocols lay the foundation for reliable and scalable benchmarking in generative brain decoding.", "tldr": "", "keywords": ["Brain decoding", "EEG-to-text", "Hallucination", "Posterior collapse", "Brain-computer interface", "Generative models", "Multimodal learning", "Language processing"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d1274ec0db40ae7da6ed513bc6082864149fb12e.pdf", "supplementary_material": "/attachment/e7ef3a2038530084e551a1f535fb43651ac67b49.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the hallucination problem in EEG-to-text generation by reframing it as a semantic summarization task rather than verbatim reconstruction. The authors identify posterior collapse as a core issue, where powerful language decoders ignore noisy EEG inputs and generate plausible but unfaithful text. To mitigate this, they propose GLIM (Generative Language Inspection Model), which learns interpretable EEG representations aligned with a frozen language model’s latent space.\n\nIn previous EEG-to-text work, even when the input contained noise, sentences with relatively high scores could still be generated. This \"illusion\" can be explained as posterior collapse. But my personal alternative explanation is that, for example, in the silent reading tasks represented by the Zuco dataset, the brain activity is relatively weak, which results in the semantic features being less prominent. Therefore, the original EEG data maintains a similar data distribution to the noise. Therefore, the original EEG data maintains a similar data distribution to the noise. This view can be verified by the loss curve. When inputting noise, the training curve exhibits a similar fluctuating trend to the input EEG.\n\nIn fact, MEG datasets that focus on auditory tasks (such as Libribrain [1], Armeni [2], etc.) are relatively more meaningful and are considered suitable for Brain-to-text applications.\n\n[1] Özdogan, M., Landau, G., Elvers, G., Jayalath, D., Somaiya, P., Mantegna, F., ... & Jones, O. P. (2025). LibriBrain: Over 50 Hours of Within-Subject MEG to Improve Speech Decoding Methods at Scale. arXiv preprint arXiv:2506.02098.\n\n[2] Armeni, K., Güçlü, U., van Gerven, M., & Schoffelen, J. M. (2022). A 10-hour within-participant magnetoencephalography narrative dataset to test models of language comprehension. Scientific Data, 9(1), 278."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Novel Problem Framing: Reframing EEG-to-text as semantic summarization is a key insight, aligning the task with the noisy and abstract nature of EEG signals.\n\nRobust Evaluation: Introduces zero-shot classification and EEG-text retrieval as complementary metrics, moving beyond surface-level text similarity.\n\nModular Design: The Q-aligner enables plug-and-play integration with any frozen LM, enhancing scalability.\n\nEmpirical Rigor: Ablation studies and the noise input test provide strong evidence for the model’s reliance on EEG signals.\n\nPractical Impact: Lays the groundwork for scalable EEG-to-text pretraining and non-invasive language BCIs."}, "weaknesses": {"value": "1.Limited Baseline Comparison: Only compares against EEG2Text and a random baseline. Recent models like DeWave or Brain2Text are not included, limiting claims of state-of-the-art performance.\n\n2.EEG Preprocessing Simplicity: The minimal preprocessing (downsampling, zero-padding) may overlook domain-specific EEG artifacts, potentially affecting generalizability.\n\n3.MTVs Trade-off: While multiple text variants improve robustness, they may dilute fine-grained lexical signals partially encoded in EEG, as acknowledged by the authors.\n\n4.Scalability Concerns: The model relies on frozen LMs (Flan-T5), which may limit adaptability to larger or more recent LMs (e.g., LLaMA 3).\n\n5.Limited Cross-Domain Analysis: While the model handles ZuCo’s heterogeneity, generalization to other EEG datasets (e.g., silent speech and listening task) remains untested."}, "questions": {"value": "1.Baseline Comparison: Why not compare with DeWave or Brain2Text? How would GLIM perform against these recent models?\n\n2.EEG Preprocessing: Have you explored artifact removal (e.g., ICA, filtering) or frequency-based features to improve signal quality?\n\n3.MTVs Impact: How do you ensure that paraphrased variants preserve subtle semantic nuances (e.g., negation, sarcasm) critical for sentiment?\n\n4.Scalability: Could GLIM be extended to larger LMs (e.g., LLaMA 3) or decoder-only models? What are the computational trade-offs?\n\n5.Cross-Domain Generalization: How would GLIM perform on silent speech EEG datasets (e.g., Nieto et al., 2022)? Would the semantic summarization framework still apply?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kPL4IACEpz", "forum": "mMhlqK79Nm", "replyto": "mMhlqK79Nm", "signatures": ["ICLR.cc/2026/Conference/Submission17753/Reviewer_pGpW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17753/Reviewer_pGpW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920927769, "cdate": 1761920927769, "tmdate": 1762927595043, "mdate": 1762927595043, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the posterior collapse in EEG-to-text decoding, i.e., mismatch between EEG signals and stimulus text. The authors proposed Generative Language Inspection Model (GLIM)—a framework to reframe the EEG-to-text decoding task as semantic summarization, rather than word-by-word reconstruction. \nThe authors address the posterior collapse issue with three technical components: (i) a contrastive-generative loss that aligns EEG embeddings to the frozen Flan-T5 latent space, (ii) multiple paraphrased text variants (MTV) per sentence to emphasise core semantics, and (iii) prompt-based domain adapters that cope with heterogeneous ZuCo recordings (different subjects, tasks, datasets). Extensive ablations show that the model produces fluent sentences, supports EEG-text retrieval, and achieves high zero-shot accuracy on sentiment/relation/corpus classification.\n\nDespite the rich ablation study, the most prominent weakness is the complete absence of comparison with any other EEG-to-text algorithm except the 2022 EEG2Text baseline. Without results from recent methods such as DeWave, STG-decoder, or the contrastive-augmented models published at ACL/NeurIPS 2023-24, it is impossible to judge whether GLIM’s numbers represent a real advance or simply a different pipeline on the same data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel problem framing: identifying posterior collapse as the root cause of hallucinations and recasting the task as semantic summarisation is original and interesting.\n2. Rich ablation study: combining contrastive alignment, MTV data augmentation, and lightweight prompt adapters yields consistent gains in ablations.\n3. Thorough self-diagnosis: the “noise-input” test and multi-view evaluation (generation, retrieval, zero-shot classification) demonstrate that the model actually listens to the EEG signal."}, "weaknesses": {"value": "1．Missing SOTA baselines. Only EEG2Text is reported. Please include recent systems (e.g., DeWave, STG-based decoders, contrastive/MAE models from ACL/NeurIPS 2023–24) under the same split, or justify non-applicability and adapt where feasible.\n\n2．Single-corpus evidence. All results are on ZuCo. Add cross-corpus tests (e.g., Natural Stories, UCLA Harry-Potter, Belt-2, ChineseEEG) to support generalization.\n\n3．EEG encoder underuses neural structure. Temporal cross-attention downsampling overlooks spatial topology and frequency content, likely leaving discriminative information unused.\n\n4．Retrieval is too easy. Top-1/Top-5 within 24-sentence batches inflates accuracy (even random vectors can exceed ~15% Top-1). No large-candidate retrieval (hundreds/thousands) or standard rank metrics (Median Rank, Recall@K, nDCG).\n\n5．Noise-input evidence is insufficient. The model outperforming EEG2Text under noise doesn’t, by itself, prove hallucination robustness. Stronger controls (shuffled alignment, subject swap, graded noise) and semantic-aware metrics are needed.\n\n6．Zero-shot comparisons feel inconclusive. Protocols do not clearly isolate semantic generalization attributable to GLIM vs. LM priors; make settings symmetric across models and report uncertainty.\n\n7．MTV quality control is underspecified. The appendix lists prompts/rules but lacks quality validation for paraphrases; unclear whether “more MTV” is always better or where benefits saturate."}, "questions": {"value": "suggestions\n1．Add recent baselines. Report at least two modern EEG-to-text models (e.g., DeWave, an STG-style decoder, a contrastive/MAE variant such as Wang et al., ACL 2024) on the same train/val/test split.\n\n2．Cross-corpus validation. Evaluate on Natural Stories, UCLA HP, Belt-2, ChineseEEG to test generalization.\n\n3．Stronger EEG encoders. Explore graph CNNs over electrodes and frequency-band features; consider controlled partial LM fine-tuning.\n\n4．Make MTV effects explicit. Vary the number/quality of paraphrases (0/1/3/5), show diminishing returns, and add BERTScore/BLEURT/MoverScore plus human ratings for semantic faithfulness/fluency.\n\n5．Harder retrieval & proper ranking. Use candidate pools of hundreds/thousands; report Median Rank, Recall@{1,5,10,50}, and nDCG with CIs.\n\n6．Robustness controls beyond one noise test. Add shuffled-pair, subject-swap, and graded-noise experiments; check for label/adapter leakage.\n\n7．Fair zero-shot protocol. Standardize prompts, freezes, and adapters across models; report confidence intervals and paired significance tests vs. strongest baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bzsax4869F", "forum": "mMhlqK79Nm", "replyto": "mMhlqK79Nm", "signatures": ["ICLR.cc/2026/Conference/Submission17753/Reviewer_QM1m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17753/Reviewer_QM1m"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960679277, "cdate": 1761960679277, "tmdate": 1762927594367, "mdate": 1762927594367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents GLIM, a generative model for EEG-to-text decoding that emphasizes semantic interpretability. The method introduces an intermediate “semantic subspace” to align EEG representations with textual embeddings via contrastive learning, followed by an autoregressive text generator that produces semantically faithful rather than word-by-word reconstructions of the original stimuli. Experiments on standard EEG-to-text datasets show moderate improvements in BLEU and embedding-based metrics, and the authors claim that GLIM captures interpretable linguistic features in its latent representations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper is exceptionally clear and well organized, making it easy to follow both the modeling approach and its neuroscientific motivation. It is a model example of strong writing and structure in the EEG decoding literature.\n2.\tThe shift in objective—from literal text reconstruction to capturing the core semantic content of EEG—is conceptually meaningful and addresses an important limitation in previous EEG-to-text work. The attempt to quantify “semantic faithfulness” through embedding-based evaluation is well motivated.\n3.\tThe authors support their claims with both decoding metrics and embedding analyses, and the correlation between latent representations and linguistic categories is an interesting exploratory result."}, "weaknesses": {"value": "1.\tThe methodological novelty is limited. The proposed “semantic subspace” and training objectives largely reuse existing alignment and generation strategies, and the paper introduces no fundamentally new algorithmic component. Its contribution lies primarily in combining these techniques into a coherent and well-presented EEG-to-text framework.\n2.\tThe distinction between literal decoding (“word-by-word reconstruction”) and semantic summarization is not fully explained. It is unclear how the model operationally achieves this shift—through multiple textual variants, specific loss weighting, or another mechanism. The two introduced losses (contrastive and generative) appear standard, and the results do not clearly demonstrate a qualitative difference in output type.\n3.\tPerformance improvements over prior work are limited. While interpretability is claimed as the main advance, the supporting analyses remain descriptive and lack rigorous quantitative validation. More systematic testing—e.g., human judgments or controlled semantic perturbations—would strengthen the argument."}, "questions": {"value": "1. The paper claims that GLIM shifts from literal reconstruction of the stimulus text to generating semantically faithful summaries. Could the authors clarify what concrete modeling choices or data settings enable this transition, and how this differs in practice from prior EEG-to-text approaches?\n2. How is the “semantic subspace” enforced to capture interpretable linguistic dimensions, rather than merely acting as a dimensionality bottleneck? Have you explored direct supervision (e.g., via linguistic features) or ablations on this design?\n3. Given the modest quantitative gains, what qualitative differences (e.g., in generated content or linguistic diversity) convince you that GLIM provides semantically richer decoding? Examples or human evaluation results would help make this case."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2xqcw8E7ZH", "forum": "mMhlqK79Nm", "replyto": "mMhlqK79Nm", "signatures": ["ICLR.cc/2026/Conference/Submission17753/Reviewer_g2vy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17753/Reviewer_g2vy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994204972, "cdate": 1761994204972, "tmdate": 1762927593525, "mdate": 1762927593525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses hallucination in EEG-to-text decoding by reframing the task as semantic summarization rather than verbatim reconstruction. The authors propose GLIM (Generative Language Inspection Model), which learns interpretable EEG representations aligned with a frozen pretrained language model's latent space. The framework combines: (1) a contrastive-generative training objective combining language modeling and cross-modal contrastive learning, (2) multiple paraphrased text variants to promote semantic robustness, and (3) domain-prompt injection for heterogeneous data handling. Evaluated on the ZuCo dataset, GLIM demonstrates performance improvements in EEG-text retrieval, zero-shot semantic classification across sentiment/relation/corpus categories, and fluent sentence generation without teacher forcing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The modular, plug-and-play architecture with minimal preprocessing enables scalability.\n2. Original problem reframing tied to a principled failure mode (posterior collapse) with a concrete mitigation (Sec. 2–3).\n3. The three-pronged evaluation (generation, retrieval, classification) provides much stronger validation than previous work relying solely on BLEU/ROUGE scores."}, "weaknesses": {"value": "1. Main results appear single-run; no confidence intervals/seed variance for Table 1. Authors should report mean+CI over ≥3 seeds for all metrics, including controls.\n2. The paper has limited technical novelty. Core components (Q-former-style alignment, contrastive learning, domain prompts) are borrowed from existing work. The contribution is primarily in their combination for this specific task.\n3. Semantic evaluation (zero-shot classification) relies on pretrained LM priors; unclear whether improvements reflect EEG alignment or LM bias. Maybe try label-agnostic MTV controls, shuffled/alternative label embeddings (or weaker/random LM encoders) to support the results.\n4. Insufficient baseline comparison. EEG2Text results are from Jo et al. (2024) using a different data split with potential train-test overlap (noted by †). This severely limits the validity of performance comparisons. The authors should reproduce EEG2Text on their split, and include additional brain decoding baselines for a fairer evaluation\n5. The notion of \"core semantics\" is not rigorously defined. The current evaluation captures only coarse categorical semantics and omits finer dimensions such as paraphrase quality, factual accuracy, and semantic similarity. The authors should include or discuss additional semantic evaluation metrics (e.g., BERTScore)"}, "questions": {"value": "1. Could you report per-subject or per-task variance to confirm statistical reliability?\n2. How do you ensure that MTV paraphrases do not leak information about sentiment/relation labels via LLM priors?\n3. Can you reproduce EEG2Text on your exact data split to enable fair comparison? The current comparison is inconclusive.\n4. Have you validated that the paraphrased variants actually preserve semantic content through human annotation? How do you ensure variants don't introduce systematic biases?\n5. Why these specific semantic categories (sentiment, relation, corpus)? Have you tested other categories like named entities?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EZnFq8kWsV", "forum": "mMhlqK79Nm", "replyto": "mMhlqK79Nm", "signatures": ["ICLR.cc/2026/Conference/Submission17753/Reviewer_JPgs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17753/Reviewer_JPgs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762073679096, "cdate": 1762073679096, "tmdate": 1762927592920, "mdate": 1762927592920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}