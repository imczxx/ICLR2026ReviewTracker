{"id": "l7EKvYs63z", "number": 16255, "cdate": 1758262385503, "mdate": 1759897251954, "content": {"title": "Effective Diffusion-free Score Matching for Exact Conditional Sampling", "abstract": "The success of score-based models largely stems from the idea of denoising a diffusion process given by a collection of time-indexed score fields. While diffusion-based models have achieved impressive results in sample generation, leveraging them for sound probabilistic inference—particularly for sampling from arbitrary conditionals of the approximate data distribution—remains challenging. Briefly, this difficulty arises because conditioning information is only observed for clean data and not available for higher noise levels, which would be required for generating exact conditional samples. In this paper, we introduce an effective approach to DIffusion-free SCOre matching (DISCO), which sidesteps the need for time-dependent score fields altogether. Our method is based on a principled objective that, while reminiscent of diffusion-based training, estimates only the score of the (slightly perturbed) data distribution. In our experiments, score models learned with DISCO are competitive with state-of-the-art diffusion models in terms of sample quality. More importantly, DISCO yields a more faithful representation of the underlying data distribution and—crucially—enables accurate sampling from arbitrary conditional distributions, outperforming standard heuristics samplers. This capability opens the door to sound and flexible probabilistic reasoning with score-based models.", "tldr": "We propose DISCO, a method for training score-based models without learning diffused data distributions, enabling asymptotically exact conditional sampling.", "keywords": ["Conditional Sampling", "Diffusion Models", "Score Matching", "Probabilistic Reasoning", "Tractability", "Energy-based Models", "Fisher Divergence"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/550b360c92c5ebae2374bceaf9394395e16de685.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a method for exact conditional sampling from diffusion models. The key contribution is the \"DISCO loss\", whose key properties are as follows:\n- The global minimizer is the score of the data distribution perturbed by a small amount of Gaussian noise, and\n- the score model is evaluated at all noise levels, so that the learned score is meaningful in practice away from the support of the data distribution.\n\nThe authors theoretically justify their method by showing that their DISCO loss' parameter gradients are identical to those of another loss whose minimizer is the score of the data distribution on the support of the training distribution. They show that their method significantly outperforms reasonable baselines on conditional inference from 2D toy distributions, and achieves acceptable, but generally not SOTA, performance on unconditional sampling and inpainting for image datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is generally well-written, and I was able to follow the main ideas without much trouble.\n- The theoretical results in this paper are correct to my knowledge.\n- The proposed method performs well at conditional sampling on 2D toy datasets."}, "weaknesses": {"value": "My primary critique of this work is that the experiments are somewhat misaligned with the paper's objectives. In the introduction, the authors claim that \"diffusion models fundamentally struggle as probabilistic reasoners\" and pose their central question as follows: \"Can we develop score-based models that serve as sound probabilistic reasoners, providing access to exact marginals and conditionals?\" To motivate this question, I would have liked to see experiments in which the authors use their method to solve a concrete probabilistic reasoning task that would otherwise be intractable. However, the authors only conclusively demonstrate their method's effectiveness for conditional sampling on 2D toy datasets; their method generally underperforms the \"EDM Masked\" baseline in their image experiments. I'm left with the impression that the method is currently a solution in search of a problem.\n\nIt also seems to me like the key observation is that one obtains the same solution to the score-matching problem if one takes the expectation of the $L_2$ loss over a proposal distribution whose support includes the support of the true target distribution. It is unclear to me that the proposal distribution $q(t,x,x_t)$ in the DISCO loss is better than other reasonable baselines. (e.g. what about the uniform distribution over a ball containing the support of the data distribution?) Is $q(t,x,x_t)$ a provably optimal proposal distribution? Does it outperform reasonable alternatives in practice?"}, "questions": {"value": "- Must one use $q(t,x,x_t)$ as the proposal distribution in the DISCO loss? Is it provably optimal in any reasonable sense? Does it outperform reasonable alternatives (e.g. the uniform distribution over a ball containing the support of the data distribution) in practice?\n- Do the authors have any concrete probabilistic reasoning tasks in mind that would be intractable without a time-independent diffusion model trained with the DISCO loss?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "G8ldrOTPnt", "forum": "l7EKvYs63z", "replyto": "l7EKvYs63z", "signatures": ["ICLR.cc/2026/Conference/Submission16255/Reviewer_VWDi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16255/Reviewer_VWDi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16255/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760992703541, "cdate": 1760992703541, "tmdate": 1762926408378, "mdate": 1762926408378, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method to learn the score of a target distribution using only samples from it. The approach minimizes a weighted mixture of Fisher divergences, extending the principle of denoising score matching (DSM). Instead of using a single noise level as in classical DSM, the method averages over multiple perturbed distributions with varying noise magnitudes. This ensures accurate score estimation both in high-probability regions (captured by small-noise perturbations) and in low-probability regions (captured by larger noise levels). The approach is validated on 2D toy distributions and image modeling tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The paper addresses an important and timely problem.\n* The work demonstrates careful attention to detail, notably in the treatment of posterior sampling, a subtle and technically challenging aspect often overlooked in prior studies."}, "weaknesses": {"value": "* The paper is poorly written and often difficult to follow.\n* Although the paper mentions training energy-based models, such experiments are never actually conducted. This omission is critical, as estimating the Fisher divergence in low-probability regions lies at the heart of the score-matching blindness problem, which affects many applications (see [1,2,3]). Moreover, the proposed approach is closely related to existing methods that attempt to address this issue (see [2] and, more recently, [4]). This connection should be emphasized, and comparisons with these approaches would substantially strengthen the paper.\n* The work clearly aims to address the limitations of MDSM, yet this motivation appears only briefly in the related work section and Appendix A.2. The discussion in Appendix A.2 should be brought into the main text to better justify the proposed method and clarify the role of the posterior sampling component, which is currently difficult to understand.\n* As acknowledged by the reviewers in Appendix B, the empirical approximation of the data distribution in posterior sampling poses significant computational and statistical challenges.\n* A major weakness lies in the choice of the weighting function $\\lambda(t)$. While averaging over multiple noise levels is conceptually appealing, the variance of the objectives can differ greatly across values of $\\sigma(t)$, making optimization unstable and difficult.\n\n[1] Wenliang, L., & Kanagawa, H.. (2021). Blindness of score-based methods to isolated components and mixing proportions.\n\n[2] Zhang, M., Key, O., Hayes, P., Barber, D., Paige, B., & Briol, F.X. (2022). Towards Healing the Blindness of Score Matching. In NeurIPS 2022 Workshop on Score-Based Methods.\n\n[3] Shi, Z., Yu, L., Xie, T., & Zhang, C.. (2024). Diffusion-PINN Sampler.\n\n[4] Tobias Schröder, Zĳing Ou, Jen Ning Lim, Yingzhen Li, Sebastian Josef Vollmer, & Andrew Duncan (2023). Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. In Thirty-seventh Conference on Neural Information Processing Systems."}, "questions": {"value": "* Could you reproduce Fig. 2 (and, more generally, Section 5.1) using an energy-based parametrization? Visualizing the learned log-probability would make Fig. 2 much clearer and easier to interpret.\n* Would it be possible to include experiments on synthetic Gaussian mixtures (ideally with unequal mode weights) to demonstrate whether the proposed method alleviates the score-matching blindness issue? This setup would also be fully tractable.\n* Out-of-distribution detection seems like a natural application of this work, have you considered evaluating it in that context?\n* It would be valuable to strengthen the connection with the energy-based modeling community, which addresses closely related problems [A,B,C,D,E]. For instance, [C] also integrates diffusion-based ideas in that setting.\n* I had difficulty understanding the image experiments: how do you perform sampling with the EDM Heun sampler without a time-dependent denoiser? Do you simply ignore the time dependence during sampling?\n\n[A] Nijkamp, E., Hill, M., Han, T., Zhu, S.C., & Wu, Y. (2020). On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based Models. Proceedings of the AAAI Conference on Artificial Intelligence, 34(04), 5272–5280.\n\n[B] Gao, R., Nijkamp, E., Kingma, D., Xu, Z., Dai, A., & Wu, Y. (2020). Flow Contrastive Estimation of Energy-Based Models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).\n\n[C] Ruiqi Gao, Yang Song, Ben Poole, Ying Nian Wu, & Diederik P Kingma (2021). Learning Energy-Based Models by Diffusion Recovery Likelihood. In International Conference on Learning Representations.\n\n[D] Nijkamp, E., Gao, R., Sountsov, P., Vasudevan, S., Pang, B., Zhu, S.C., & Wu, Y. (2022). MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC. In International Conference on Learning Representations.\n\n[E] Grenioux, L., Moulines, E., & Gabrie, M. (2023). Balanced Training of Energy-Based Models with Adaptive Flow Sampling. In ICML 2023 Workshop on Structured Probabilistic Inference & Generative Modeling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SGIBRMcth0", "forum": "l7EKvYs63z", "replyto": "l7EKvYs63z", "signatures": ["ICLR.cc/2026/Conference/Submission16255/Reviewer_Qg4t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16255/Reviewer_Qg4t"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16255/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761387846668, "cdate": 1761387846668, "tmdate": 1762926407875, "mdate": 1762926407875, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\n\nThe goal is to draw samples from *conditional* distributions of data, having sample-access to the *joint* distribution of data. The authors do so in three steps:\n\n**Step 1**. Estimate the score vector of the *joint* distribution\n\n**Step 2**. Deduce the score vector of the *conditional* distribution (discard the vector entries you condition on, Eq. 5)\n\n**Step 3**. Plug that score into a Sequential Monte Carlo *sampler*\n\nThe authors' contribution is in step 1: they propose a new loss function for estimating the score, called DISCO."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "### **Original Problem Statement**\n\nThe original score-matching loss measures the squared error between the true and model scores *in-distribution*, that is, averaged over samples drawn from the *data* distribution. Much of the prior literature has focused on reformulating this loss into computationally tractable forms [1, 2].\n\nIn contrast, the authors propose to evaluate the squared error between the true and model scores *out-of-distribution*, that is, averaged over samples drawn from *other* distributions. In practice, these distributions are “flattened” versions of the data density, simulated by adding Gaussian noise to data samples.\n\nOut-of-distribution estimation of the data score is an important topic and the authors' formulation is interesting. For example, sampling from the product of two distributions can be done by adding their scores [3].  In such a case, the scores are typically trained using samples from individual distributions rather than their product, which can lead to inaccuracies when evaluated on samples from the product. The authors’ approach could address this mismatch.\n\n[1] Hyvärinen, Estimation of Non-Normalized Statistical Models by Score Matching, JMLR 2005.\n\n[2] Vincent, A Connection Between Score Matching and Denoising Autoencoders, Technical Report 2010.\n\n[3] Du et al., Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC, ICML 2023."}, "weaknesses": {"value": "## 1. Motivation for the DISCO Loss\n\nWhat is the motivation for the DISCO loss (Eq. 6), which estimates the data score *out-of-distribution*?\n\nThe only reason I can think of is that the authors anticipate the SMC sampler will query the score function *outside* the data distribution, and therefore the authors would like the score to be accurately estimated in these areas. If this is indeed the motivation, it should be stated explicitly, since it is the starting point of the entire contribution. \n\n## 2. Concern with the Loss Function\n\nThe main technical contribution is the DISCO loss (Eq. 13) for estimating the score of the joint distribution. However, evaluating this loss requires sampling from the distribution of clean data given noisy data, also called denoising posterior (see the “DISCO Training” paragraph).\n\nThis is a difficult problem in itself! Sampling from the denoising posterior is exactly what one-step generative models (*e.g.* consistency and flow-map models) try to do. If we could sample accurately from the denoising posterior, we would essentially have solved the data generation problem.\n\nI understand that the authors suggest that sampling from an approximation of the denoising posterior is sufficient, but this should be further discussed, especially as it raises questions about both feasibility of the training objective.\n\n## 3. Concern with the Evaluation Procedure\n\nAs stated in the summary, the authors use a three-step process for conditional sampling:\n\n**1-** Estimate the score of the joint distribution.\n\n**2-** Derive the conditional score.\n\n**3-** Plug this conditional score into an SMC sampler\n\nThere are two main sources of error in this pipeline:\n- The estimation error of the score\n- The sampling error from the SMC sampler\n\nThe paper’s contribution concerns the first part: improving score estimation. Therefore, the natural evaluation would be to compare different score estimators using the **same** SMC sampler. Instead, the experiments pair different estimators with **different samplers** (e.g., DISCO + SMC vs. DSM + diffusion guidance). This confounds the interpretation: improvements could very well be due to the choice of sampler rather than from better score estimation. In fact, I suspect this is the case: previous work explicitly compares SMC (Annealed Langevin Dynamics specifically) and diffusion guidance, and showed drastic difference in results that highlight that SMC is an unbiased sampler while diffusion guidance is a biased sampler [2]. \n\nMoreover, the SMC sampler is barely described in the main text: it is mentioned only once on page 3 and once on page 8. Given that it is the main sampling algorithm the authors use to generate samples from conditional distributions, it definitely deserves a more detailed explanation (e.g. choice of schedule, of initialization). \n\nLastly, Figure 2, which visualizes joint scores estimated by different methods, does not seem very useful. The differences between DISCO and other score estimators are not visually striking, but more importantly, the authors care that the conditional scores are correct which is not obvious to visualize on a plot that shows the joint scores. \n\n[2] Du et al. Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. ICML 2023.\n\n## 4. Clarity in the Writing\n\nWhile the paper is overall clear, some passages are quite confusing. \n\n**Introduction**\n> “This objective, albeit reminiscent of diffusion training, only fits the (slightly perturbed) data distribution rather than a full diffusion process, while taking care that the score field is also fit outside the data manifold. This approach makes conditioning de-facto trivial: one simply fixes observed variables in the learned score field and samples only the unobserved variables—enabling asymptotically exact probabilistic inference.”\n\n\n**Masked DISCO Training**\n> “During conditional sampling, the model must have learned the score at points $(\\mathbf{x}^u, \\mathbf{x}^c)$ where $\\mathbf{x}^c$ is ‘clean’, and $\\mathbf{x}^u$ is ‘noisy’. While in theory, minimizing $\\mathcal{L}_{\\text{DISCO}}$ learns the true score also at these points, we observe that in high dimensions, the model does not learn accurate scores at these points.”\n\nIt is not clear to me that the model \"must\" have learned the noisy score for conditional sampling. While diffusion-based samplers use the noisy conditional scores, an SMC sampler only requires the clean conditional score.\n\n**DISCO Training and Masked DISCO Training**\nThese paragraphs are hard to read.\n\n## 5. Clarifying the Related Work\n\nThe paper refers to gradient guidance (Ho et al., 2022), the replacement heuristic (Song et al., 2020), and the Twisted Diffusion Sampler (Wu et al., 2023).\n\nHowever, I could not find the term “replacement heuristic” in the cited Song et al. (2020) papers. If this terminology is introduced by the authors, it should be clearly stated, and the relevant passage in the original work cited precisely.\n\nThe authors state that the Twisted Diffusion Sampler offers “only asymptotic guarantees.” Asymptotic in what sense—in the number of particles, iterations of SMC, or samples? I would note that the authors’ method is also correct only asymptotically! Exact sampling from the conditional distributions would require perfect score estimation (infinite data) and convergence of SMC (infinite iterations). \n\nAlso, the authors claims that diffusion guidance lacks theoretical guarantees. It would be relevant to cite recent theoretical analysis of guidance [1]. \n\n[1] Chidambaram et al. What Does Guidance Do? A Fine-Grained Analysis in a Simple Setting. NeurIPS 2025.\n\n## 6. Missing Related Work\n\nThe authors ommitted a relevant and recent line of work, which uses diffusion and flow models to do unbiased sampling of conditional distributions [1–3]. In particular, (3) clearly explain how this works: one can amortize the score (or velocity) estimation across denoising schedules. To sample from $p(x^1 \\mid x^2)$, one first denoises $x^1$ and then denoises $x^2$. The first part effectively samples from the conditional.\n\n[1] Chen et al. Diffusion Forcing: Next-Token Prediction Meets Full-Sequence Diffusion. NeurIPS 2024.\n\n[2] Song et al. History-Guided Video Diffusion. ICML 2025.\n\n[3] Wewer et al. SRM: Spatial Reasoning with Denoising Models. ICML 2025."}, "questions": {"value": "Can the authors address the six concerns I have detailed in the Weaknesses section? \n\nMy foremost concern is that successful sampling from the conditional distribution is attributable to the choice of sampler (SMC vs. diffusion guidance) rather than the score estimation (DISCO vs. DSM at multiple noise levels). Because the authors' main contribution is the score estimation, this deserves special attention. Can the authors comment on this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9p9cH5Ieph", "forum": "l7EKvYs63z", "replyto": "l7EKvYs63z", "signatures": ["ICLR.cc/2026/Conference/Submission16255/Reviewer_oy6K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16255/Reviewer_oy6K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16255/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761407876610, "cdate": 1761407876610, "tmdate": 1762926407559, "mdate": 1762926407559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel training paradigm to perform conditional sampling via diffusion models. The authors argue that existing methods for conditional sampling based on diffusion models are largely *heuristic*, where the objective functions being used do not correspond to well-defined minimizers, etc. To circumvent this issue, they propose DISCO, a diffusion-free score-matching objective based which learns a time-independent score function which they can use to perform conditional sampling in a principled manner. While the authors do still incorporate a notion of \"noising process\" at various amounts of noise, the end-goal of their approach is to only learn the score very close to the data distribution i.e., when the noise is essentially zero. The objective function being used is related to the relative Fisher information between the two distributions, as well as an additional \"masking\" loss. The authors compare their method with heuristic approaches on a suite of examples."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "I appreciate the level of rigor that the authors want to bring to the challenging task of conditional sampling, and the detailed background of different existing methods based on diffusion models. The use of a new objective function (the reweighted Fisher divergence) also appears to be new. I also think the presentation for the experiments was well put together."}, "weaknesses": {"value": "- Lack of discussion/comparison or citation of other methods for conditional simulation: There is a swath of literature on this topic based on optimal transport, GANs, or Schrödinger bridges, that deserves a mention or citation; see below for examples and the references therein.\n\n- Presentation style: There are too many distributions named $p$ but correspond to different things. For example, there is $p(t)$ as well as $p(\\textbf{m})$, and it is a bit confusing. The naming convention for the loss $\\mathcal{L}_{\\rm DISCO}^{\\rm mask}$ and the version when the super and subscript are swapped might be worth revisiting.\n\n- The method claims to be principled but I am not entirely sure I understand that it is beyond the loss-minimization aspect. The use of a new object (reweighted FI) is interesting, but the fact that the objective function itself requires conditional sampling of some kind (this is my understanding between likes 240 and 243). It is entirely possible I misunderstood something, but this does seem to be a limitation. \n\n- I appreciate the use of Inference Quality as a metric, but the comparison seems like it could be improved. For instance, would it not be better to perform MC estimation of \n$$ \\mathbb{E}_{p'_d(x_1)}[ W_1( p_d(x_2|x_1) , p^\\theta(x_2|x_1)], $$\nwhere the first argument is the ground-truth conditional distribution? This can be done in the case of Gaussian distributions or other simple 2D settings (see the references below for examples).\n\n-  The use of 10^5 examples in 2D is a bit high, given that this many samples does not even exist for CIFAR10 or MNIST. \n\nSome references:\n\n@article{kerrigan2024dynamic,\n  title={Dynamic conditional optimal transport through simulation-free flows},\n  author={Kerrigan, Gavin and Migliorini, Giosue and Smyth, Padhraic},\n  journal={Advances in Neural Information Processing Systems},\n  volume={37},\n  pages={93602--93642},\n  year={2024}\n}\n\n@article{baptista2024conditional,\n  title={Conditional simulation via entropic optimal transport: Toward non-parametric estimation of conditional Brenier maps},\n  author={Baptista, Ricardo and Pooladian, Aram-Alexandre and Brennan, Michael and Marzouk, Youssef and Niles-Weed, Jonathan},\n  journal={arXiv preprint arXiv:2411.07154},\n  year={2024}\n}\n\n@inproceedings{shi2022conditional,\n  title={Conditional simulation using diffusion Schr{\\\"o}dinger bridges},\n  author={Shi, Yuyang and De Bortoli, Valentin and Deligiannidis, George and Doucet, Arnaud},\n  booktitle={Uncertainty in Artificial Intelligence},\n  pages={1792--1802},\n  year={2022},\n  organization={PMLR}\n}"}, "questions": {"value": "Why is having a family of proposal distributions a good idea as opposed to one fixed choice? This is a central question that I was not able to understand."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ONVxjDSJSY", "forum": "l7EKvYs63z", "replyto": "l7EKvYs63z", "signatures": ["ICLR.cc/2026/Conference/Submission16255/Reviewer_Q8EJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16255/Reviewer_Q8EJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16255/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762110513515, "cdate": 1762110513515, "tmdate": 1762926407177, "mdate": 1762926407177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}