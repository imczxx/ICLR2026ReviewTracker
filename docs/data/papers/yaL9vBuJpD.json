{"id": "yaL9vBuJpD", "number": 8587, "cdate": 1758091914718, "mdate": 1759897774804, "content": {"title": "A11YN: Aligning LLMs for Accessible Web UI Code Generation", "abstract": "Large language models (LLMs) have recently demonstrated strong capabilities in generating functional and aesthetic web interfaces directly from instructions. However, these models often replicate accessibility flaws from their training data, resulting in interfaces that exclude users with diverse needs and contexts. To address this gap, we introduce A11yn, the first method that aligns code-generating LLMs to reliably produce accessibility-compliant web UIs. A11yn optimizes a novel reward function that penalizes violations of the Web Content Accessibility Guidelines (WCAG), with penalties scaled to the severity of each violation as identified by an accessibility testing engine. To support training, we construct UIReq-6.8K, a dataset of 6,800 diverse instructions for web UI generation. For evaluation, we introduce RealUIReq-300, a benchmark of 300 real-world web UI requests grounded and manually curated from public web pages, spanning a broad range of use cases. Empirical results show that A11yn significantly outperforms strong baselines, lowering the Inaccessibility Rate by 60% over the base model while preserving semantic fidelity and visual quality of generated UIs. These findings demonstrate that accessibility can be systematically optimized within LLMs, showing the feasibility of aligning code generation for accessibility.", "tldr": "We introduce A11YN, the first framework for post-training code-generating LLMs to produce accessibility-compliant web UIs.", "keywords": ["AI for Accessibility", "UI generation", "Post-Training Alignment"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b4153668da9678c8cfc7cb73d617bb5302285b28.pdf", "supplementary_material": "/attachment/d17e8422a37bb85f1b9d038bad98550476fd4de4.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces A11YN, an approach to align large language models for generating more accessible web UI code. The method integrates accessibility evaluation (via Axe-core) into a GRPO-based reinforcement learning framework and fine-tunes an open-source code model using synthetic accessibility-focused datasets (UIReq-6.8K and RealUIReq-300). Experiments show reduced violation rates and improved accessibility scores compared with baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Socially meaningful objective. Addressing accessibility in code generation is an important and underexplored direction that broadens the scope of model alignment beyond general coding accuracy.\n\n+ Clear pipeline design. The integration of automatic accessibility evaluation into a reinforcement learning loop is well described and straightforward to reproduce.\n\n+ Comprehensive baseline coverage. The experiments include multiple strong models (e.g., GPT-4, CodeLlama, DeepSeek-Coder), providing a fair empirical comparison within the same evaluation setup."}, "weaknesses": {"value": "- Limited methodological novelty.  The paper mainly applies an existing RL-based alignment framework (GRPO) to web accessibility without introducing new algorithmic ideas or training mechanisms. While the topic is valuable, the technical contribution is largely an adaptation rather than a conceptual advance.\n\n\n- Synthetic and weakly validated data.  Both the training dataset (UIReq-6.8K) and the benchmark (RealUIReq-300) rely heavily on GPT-generated instructions and code. This raises concerns about data authenticity and generalization, as the method is essentially evaluated on distributions created by the same type of model.\n\n\n- Evaluation lacks robustness.  The reported improvements mainly rely on Axe-core–based automatic scores. There is no human or cross-tool validation, nor analysis of code correctness or executability after alignment. The gains therefore reflect optimization toward the reward function rather than clear practical improvements in accessibility."}, "questions": {"value": "1. How well does the proposed method generalize to real-world accessibility requests beyond GPT-generated synthetic data?\n\n\n2. Can the authors provide human or cross-tool evaluations to confirm that the observed improvements go beyond optimizing for the Axe-core reward?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SJJYMtwX34", "forum": "yaL9vBuJpD", "replyto": "yaL9vBuJpD", "signatures": ["ICLR.cc/2026/Conference/Submission8587/Reviewer_pBvL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8587/Reviewer_pBvL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011244891, "cdate": 1762011244891, "tmdate": 1762920433453, "mdate": 1762920433453, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes to train website coding LLM with a reward function that comes directly from an automated WCAG auditor (axe‑core), which measures the violations of accessibility defects in HTML/CSS. For training prompts, the authors synthesize UI requests with GPT‑4o‑mini to form UIReq‑6.8K spanning 68 application categories. For evaluation, they collect screenshots of public webpages, extract structured metadata, and prompt another GPT model to generate user requests from the metadata. The LLM coder is GRPO‑tuned against the accessibility reward. The models are scored by WCAG violations and the appearance of the generated website. The results show that the proposed method improves accessibility without degrading visual/semantic quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work presents a novel application of GRPO for improving accessibility of generated websites.\n\n2. The newly curated dataset may be useful for future work on website coding.\n\n3. The proposed approach is simple and effective."}, "weaknesses": {"value": "1. The technical depth is limited: Although the application of GRPO for improving accessibility of website coding is straightforward but somewhat incremental, training LLMs with hand‑engineered rewards is already well explored.\n\n2. Using only one testset leaves generalization to unseen domains and request styles, especially those not represented during training, unclear.\n\n3. Both training and eval prompts are GPT‑generated, and it's unclear that the synthesized requests are realistic. As seen in Figure 4, the many remain high‑level and omit concrete functional elements (e.g., dropdowns, buttons)."}, "questions": {"value": "1. Whether the RL training decreases the diversity of website generation? The code LLM may learn a specific UI style, which is a safe solution."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b0VUuiGlct", "forum": "yaL9vBuJpD", "replyto": "yaL9vBuJpD", "signatures": ["ICLR.cc/2026/Conference/Submission8587/Reviewer_Zw7A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8587/Reviewer_Zw7A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762060127166, "cdate": 1762060127166, "tmdate": 1762920432978, "mdate": 1762920432978, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new method to align code generation LLMs to produce accessibility-compliant web UIs. The approach augments existing LLMs with a new reinforcement learning reward. The reward takes into account violations of accessibility as negative rewards and trains the LLM using GRPO. To evaluate the performance, the authors also curated a new benchmark consisting 300 real-world web UIs. Results show that the propose method outperforms the baselines including Claude Sonnet 4, reducing the inaccessibility rate by 60% over the base model, while preserving semantic fidelity and visual quality of generated UIs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper concerns accessibility as a new metric for text-to-UI generation, which is an important research aspect. \n2.\tThe paper is generally well-structured. The motivation, methodology, and results are easy to follow. \n3.\tThe authors provide a new benchmark, RealUIReq-300, containing realistic web UI requests curated from 300 real-world web pages, which can be useful for future evaluation."}, "weaknesses": {"value": "1.\tThe core methodological novelty is modest. The proposed method merely augments GRPO with a custom accessibility reward. While practically useful, this design does not introduce fundamentally new RL methodology or optimization mechanisms, making the novelty borderline for ICLR standards.\n2.\tThe qualitative study in 6.2 is rather shallow. It provides only a single qualitative example (color contrast). A deeper case analysis, covering diverse violation types (e.g., ARIA roles, landmark semantics, keyboard navigation), would strengthen the narrative.\n3.\tThe paper evaluates accessibility solely via automated tools (Axe-core). Given the human-centered nature of accessibility, even a small-scale user or expert study would greatly enhance credibility. \n4.\tThere is no ablation showing the contribution of different reward components or GRPO hyperparameters. It is unclear how sensitive the results are to the weighting scheme, the base score B, or the severity mapping.\n5.\tThe work focuses narrowly on HTML-based UIs. The paper could discuss whether the proposed alignment strategy generalizes to other UI platforms (e.g., React, Flutter, mobile UIs) or broader code-generation tasks.\n6.  There are also some recent related work on Web UI code generation, which can be discussed. For example:\n\nUICopilot: Automating UI Synthesis via Hierarchical Code Generation from Webpage Designs, https://arxiv.org/abs/2505.09904\n\nUnlocking the conversion of web screenshots into html code with the websight dataset. 2024. URL https://api.semanticscholar.org/CorpusID:268385510.\n\nVISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs, https://arxiv.org/abs/2404.06369v1, April 2024."}, "questions": {"value": "- Did you perform a user or expert study on accessibility? \n- Any ablation study showing the contribution of different reward components?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IaO1HrZNNi", "forum": "yaL9vBuJpD", "replyto": "yaL9vBuJpD", "signatures": ["ICLR.cc/2026/Conference/Submission8587/Reviewer_sosE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8587/Reviewer_sosE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762084063032, "cdate": 1762084063032, "tmdate": 1762920432656, "mdate": 1762920432656, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}