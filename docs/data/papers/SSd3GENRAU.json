{"id": "SSd3GENRAU", "number": 15916, "cdate": 1758257086494, "mdate": 1763696967943, "content": {"title": "Low-pass Personalized Subgraph Federated Recommendation", "abstract": "Federated Recommender Systems (FRS) preserve privacy by training decentralized models on client-specific user-item subgraphs without sharing raw data. However, FRS faces a unique challenge: subgraph structural imbalance, where drastic variations in subgraph scale (user/item counts) and connectivity (item degree) misalign client representations, making it challenging to train a robust model that respects each client’s unique structural characteristics. \n\nTo address this, we propose a Low-pass Personalized Subgraph Federated recommender system (LPSFed). LPSFed leverages graph Fourier transforms and low-pass spectral filtering to extract low-frequency structural signals that remain stable across subgraphs of varying size and degree, allowing robust personalized parameter updates guided by similarity to a neutral structural anchor. Additionally, we leverage a localized popularity bias-aware margin that captures item-degree imbalance within each subgraph and incorporates it into a personalized bias correction term to mitigate recommendation bias. Supported by theoretical analysis and validated on five real-world datasets, LPSFed achieves superior recommendation accuracy and enhances model robustness.", "tldr": "LPSFed addresses subgraph structural imbalance in federated recommendation via low-pass spectral filtering and a localized bias-aware loss, enabling robust personalized updates that enhance both accuracy and diversity across diverse client subgraphs.", "keywords": ["Federated Learning", "Recommender Systems", "Graph Neural Networks"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f56b8b2b81596b5c5318d6502fccbd3c5edf8cac.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper, the authors introduce Low-Pass Personalized Subgraph Federated Recommendation (LPSFed) for personalized federated recommendation systems. LPSFed could address the challenge of subgraph structure imbalance and local popularity deviation. LPSFed uses low-pass spectral filtering on heterogeneous subgraphs to extract low-frequency structural signals. These signals are used to calculate the personalized structural similarity between each client and the global model. LPSFed also uses a local popularity bias-aware margin to capture the imbalance of item degrees in each subgraph and incorporates it into the personalized bias correction term to mitigate recommendation bias. Extensive results on multiple datasets demonstrate the effectiveness of the approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is easy to follow and generally well presented.\n\n2. It is a timely topic and a very interesting area to explore.\n\n3. The theoretical analysis is solid."}, "weaknesses": {"value": "1. The authors acknowledge in the Appendix and Limitations that spectral calculations are performed in the preprocessing stage. If the eigenvectors of the entire graph (or subgraph) are directly calculated on a very large graph (such as Tmall), it may not be feasible in terms of memory/time.\n\n2. The author averages the local margins of all (u,i) of each client into a scalar $M^c$ and uploads it to the server. A single average value cannot reflect the skewness (such as long tail) or multimodal distribution within the client; the average value is sensitive to outliers and will mask important information.\n\n\n3. Figure 1 shows a 15-client partition for Amazon-Book; however, D.2 in the main experiment states, \"In the main experiment, we partitioned the full graph into four subgraphs.\" The paper does not clearly explain the correspondence between the different experimental settings and the reasons behind them."}, "questions": {"value": "See in weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "CkD5y5Bn0U", "forum": "SSd3GENRAU", "replyto": "SSd3GENRAU", "signatures": ["ICLR.cc/2026/Conference/Submission15916/Reviewer_wXeM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15916/Reviewer_wXeM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761423747661, "cdate": 1761423747661, "tmdate": 1762926136286, "mdate": 1762926136286, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces LPSFed, a federated recommendation framework designed to handle structural imbalance across user–item subgraphs of different clients. This imbalance arises from variations in subgraph density and connectivity, which often lead to inconsistent representation learning when applying traditional GNN-based federated models. To address this issue, LPSFed employs low-pass spectral filtering to capture smooth, low-frequency graph signals, enhancing representation stability under heterogeneous structures. In addition, a popularity-aware contrastive loss is introduced to balance recommendations and reduce local popularity bias. Experiments on several datasets show consistent improvements over baseline federated models, and theoretical results provide further support for the effectiveness of the proposed spectral regularization strategy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper offers a novel perspective by applying low-pass spectral filtering to mitigate structural imbalance in federated recommendation. The combination of spectral graph modeling and bias-aware optimization is original and novel.\n\n2. The approach is conceptually clear. The appendix adds useful details on complexity analysis and spectral properties, improving transparency and reproducibility.\n\n3. The study investigates an important but relatively underexplored problem in federated recommendation, namely the structural imbalance among decentralized user–item subgraphs. This imbalance is caused by variations in graph density and connectivity across clients. It can negatively influence the stability and fairness of model training in practical applications. By introducing spectral filtering and bias-aware optimization to address this issue, the paper provides a fresh perspective on improving structural consistency in federated recommender systems. The proposed direction may encourage further research on combining structure-aware learning with privacy-preserving mechanisms to develop more robust and equitable personalized recommendation models."}, "weaknesses": {"value": "1. The core method of the paper is not sufficiently explained. The authors propose decomposing the embedding layer to generate a low-pass convolution kernel distribution k, which is then used for similarity comparison. However, the paper does not clarify why this specific k is chosen or why it is appropriate for measuring similarity. A more thorough discussion of both the theoretical and empirical reasoning behind this design would help readers understand its advantages over alternative approaches.\n\n2. While the paper claims innovation in \"structural imbalance,\" the uniqueness of the method compared to existing spectral federation methods (such as FedSSP) can be explained more clearly. \n\n3. Although the description of the main method is relatively clear, the workflow diagram(Figure 2) appears somewhat cluttered, which makes it harder to fully understand the overall process."}, "questions": {"value": "1.  Please provide a detailed explanation of the motivation behind the core method, specifically the similarity comparison based on the low-pass convolution kernel distribution k. The authors should clarify why this kernel distribution is chosen for measuring similarity and discuss its advantages over other possible approaches from both theoretical and empirical perspectives.\n\n2. The model uses spectral domain filtering (Graph Fourier Transform + low-pass filtering) to remove high-frequency noise while preserving low-frequency structural information. Why is it better to retain the low-frequency signal for similarity comparison?\n\n3. While the goal of federated learning is to preserve user privacy, the paper does not discuss whether the client-uploaded information (such as statistical features, spectral kernel distributions, or structural similarity scores) might pose a risk of indirectly revealing the underlying graph structure. A discussion or analysis of potential privacy implications would enhance the completeness of the work and align better with the core principles of federated learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lqbvuZ8x6P", "forum": "SSd3GENRAU", "replyto": "SSd3GENRAU", "signatures": ["ICLR.cc/2026/Conference/Submission15916/Reviewer_7AW4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15916/Reviewer_7AW4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886103862, "cdate": 1761886103862, "tmdate": 1762926135389, "mdate": 1762926135389, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets the challenge of subgraph structural imbalance in FRS. The authors propose LPSFed which uses graph Fourier transform and low-pass spectral filtering to extract stable structural signals, measures structural similarity to guide personalization, and introduce a popularity-bias-aware margin to mitigate feedback loops. Experiments across five datasets show advantages supported by theoretical analysis."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The authors provide a well-motivated spectral view and lots of theoretical analysis. The qualitative tests show advantageous performance with discussions on robustness, completed by the ablation study of model components and hyperparameter analysis. The limitation of reliance on spectral computations is acknowledged."}, "weaknesses": {"value": "1. Although the motivation of selected algorithms and theories are well motivated, the work seems to be a nice combination of existing proposals applied to this specific challenge, i.e., subgraph structural imbalance. This is not to undermine the effort and importance of such combination, but the novelty by itself is thus unavoidably limited. \n2. As acknowledged by the authors in the appendix, the reliance on spectral computations raises the computation burden, I'd like to see if authors can provide some thoughts on how that could be alleviated. \n3. It seems only one baseline is from the spectral FL family, please include more baselines from this direction, or otherwise explain the reason. The same applies to bias performance tests, which didn't compare with sufficient fairness-aware FRS works. \n4. The cut-off frequency may have a considerable impact on system performance, yet the authors seem skip the discussion on the frequency value choice.  This also applies to the neutral structural anchor.\n5. There seem to be quite some places in the math reasoning that are either vague or too idealized. For example, C1 and C2 only have vague description (actually only C1 has) without specifying how to determine their values; it idealizes the client graphs as having clear k-block community structures, which is quite rare in reality I'm afraid."}, "questions": {"value": "Could the authors elaborate on the novelty besides combining existing algorithms and methods?\nCould the authors provide some discussion on how the computation burden caused by spectral computation may be alleviated?\nCan the authors include more fair comparisons with peering baselines such as spectral FRS and fairness-aware FRS?\nCould the authors discuss more about the cut-off frequency and structural anchor determination and their impact and sensitivity?\nCould the authors relax the idealization in math assumptions and give more specifics on value choices for example for C1 and C2 etc. ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hEdECZiidB", "forum": "SSd3GENRAU", "replyto": "SSd3GENRAU", "signatures": ["ICLR.cc/2026/Conference/Submission15916/Reviewer_rJvg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15916/Reviewer_rJvg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945347494, "cdate": 1761945347494, "tmdate": 1762926134914, "mdate": 1762926134914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LPSFed, a federated recommender framework designed to handle subgraph structural imbalance and popularity bias across clients. It applies low-pass spectral filtering to extract stable, low-frequency structural signals and computes a structural similarity between each client and a server-generated reference graph for personalized aggregation. Additionally, it introduces a bias-aware margin loss that mitigates popularity bias by adjusting item ranking based on local degree distributions. Theoretical analysis justifies the stability and regularization of low-pass filtering, and experiments on five real-world datasets demonstrate consistent improvements in recall, NDCG, and robustness over multiple baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear and coherent framework integrating personalization and debiasing.\n\n- Sound theoretical motivation for spectral similarity and low-pass regularization.\n\n- Strong empirical results across multiple datasets and settings.\n\n- Effective ablation studies confirming each module’s contribution."}, "weaknesses": {"value": "- Novelty is incremental; relies heavily on previous spectral FL ideas.\n\n- Theoretical assumptions may not align with real-world bipartite graphs.\n\n- Ambiguity in privacy handling (what information the server receives).\n\n- Sensitivity to anchor graph design and data partitioning not deeply analyzed."}, "questions": {"value": "1 Can similarity computation be done entirely on clients to ensure privacy?\n\n2 How sensitive is performance to the reference graph’s design or randomness?\n\n3 Do empirical eigengaps correlate with observed improvements?\n\n4 Can the bias-aware margin adapt automatically rather than be fixed?\n\n5 Has the model been tested under naturally partitioned (non-synthetic) clients?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tzsDaRQ4Fq", "forum": "SSd3GENRAU", "replyto": "SSd3GENRAU", "signatures": ["ICLR.cc/2026/Conference/Submission15916/Reviewer_SL1j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15916/Reviewer_SL1j"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15916/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105948401, "cdate": 1762105948401, "tmdate": 1762926134153, "mdate": 1762926134153, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}