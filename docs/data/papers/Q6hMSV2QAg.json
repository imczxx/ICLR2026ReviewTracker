{"id": "Q6hMSV2QAg", "number": 13148, "cdate": 1758214102989, "mdate": 1759897460828, "content": {"title": "Compute-efficient Evaluation of LLM Voting Accuracy", "abstract": "Test-time scaling methods, such as voting, have emerged as a powerful paradigm to dramatically improve the performance of large language models (LLMs).  Majority voting is often useful however to estimate the tradeoff between task performance (e.g., accuracy) and computational cost, as we vary the size of ensemble used in voting, denoted $M$; or as we vary hyperparameters, such as Temperature, in pursuit of a more favorable tradeoff. In the literature, evaluating voting accuracy performance is done using a purely empirical approach that requires many LLM evaluations and is highly computationally intensive. In this work we propose two methods to estimate the voting accuracy of an LLM with substantially less computational cost than current methods. Using a popular public benchmark datasets of LLM problems (MATH) we demonstrate that our two estimation approaches can closely approximate the true ensemble accuracy, with substantially less computational cost than current methods less computation than a purely empirical approach, especially as the number of votes grows larger.", "tldr": "Metrics for efficiently and rapidly evaluating LLM performance.", "keywords": ["large language models", "evaluations", "Gaussian approximation", "Monte-Carlo simulation", "efficient", "rapid"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e4f14446d310d480e1df93e8ecfcf7e992f7d0e5.pdf", "supplementary_material": "/attachment/fa4dd99a504b52242d25f812a4721c07d2ed3674.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes two computationally efficient methods to accurately estimate the voting accuracy of Large Language Models (LLMs)."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The research topic is important."}, "weaknesses": {"value": "- The proposed methods suffer from significant technical flaws that undermine the paper's contributions. \n\n  1. The first proposed method is simply an application of the parametric **bootstrap**. The method first estimates the parameters of the underlying categorical distribution, and then uses this estimated distribution to run Monte-Carlo simulations. This is a well-known, textbook procedure. The methodological novelty here is therefore minimal.\n\n  2. The second proposed method is based on a **fundamentally flawed assumption**. Specifically, Eq. (10) is based on the assumption that $V_M(y^*,x)$ and $V_M(y,x)$ are all independent. This assumption is false. They are, in fact, negatively correlated: a higher count for correct solutions necessarily implies a lower total count for all other candidates. The correct way is to apply the *multivariate* central limit theorem to the vector $C_M(\\cdot, x)$ and approximate it with a multivariate normal distribution. This distribution would have a non-diagonal covariance matrix that captures the negative dependencies between the counts. A correct (consistent) estimation should take the covariance into account.\n\n- The paper also has many presentation issues, detracting from the paper's professionalism.\n  1. Line 15: I don't think $M$ should be defined in the abstract.\n  2. Line 32: Incorrect quotation marks.\n  3. The paper uses \"majority voting\", \"plurality voting\", and \"plurality ensembles\" interchangeably. I recommend the authors to make this consistent and stick to the most commonly-used \"majority voting\".\n  4. Eq, (4): Why is $1/M$ needed here?\n  5. The paper is inconsistent in its presentation of the \"temperature\" hyperparameter. It appears variously as \"Temperature\" (capitalized), \"temperature\" (lowercase), and at times is _italicized_.\n  6. Line 221: $<< \\to \\ll$ (`\\ll` in latex)."}, "questions": {"value": "- In Table 1, do the TFLOPS results of the proposed method include the cost for sampling $G$ solutions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mpIomU8As0", "forum": "Q6hMSV2QAg", "replyto": "Q6hMSV2QAg", "signatures": ["ICLR.cc/2026/Conference/Submission13148/Reviewer_Ccxh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13148/Reviewer_Ccxh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13148/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761367906028, "cdate": 1761367906028, "tmdate": 1762923864703, "mdate": 1762923864703, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method to estimate the accuracy of **test-time voting** for LLMs using only a small number of samples. Instead of running many generations to measure majority-vote accuracy empirically, the method samples $G$ outputs per question, estimates the output distribution, and uses Monte Carlo simulation to predict accuracy under a larger vote size $M$.\n\nExperiments on the **MATH dataset** with **GPT-4o-mini** and **Llama-3.2 1B Instruct** compare predicted and empirical accuracies across different sampling temperatures and vote sizes. The results suggest that the proposed estimator can approximate full-sampling accuracy using significantly fewer model queries."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The motivation, reducing the cost of majority-vote inference while maintaining accuracy estimates, is easy to understand and potentially useful if the method worked reliably.\n- Despite a limited scope, the experiments (especially in Figure 2) illustrate how accuracy saturates with the number of samples."}, "weaknesses": {"value": "- The paper assumes that the empirical distribution of LLM outputs can be reliably estimated with a very small number of samples (e.g., $G = 5$ or $10$).\nThis assumption is not justified either theoretically or empirically. In practice, LLM output distributions are often highly multimodal and long-tailed.\n- Although the paper claims low approximation error, its “ground truth” accuracy is itself obtained from Monte Carlo simulations rather than actual LLM ensemble runs, making the validation self-consistent but not empirically independent. (Line 316, 335-336).\n- Table 1 underestimates the computation for the Monte-Carlo and Gaussian methods by excluding the FLOPs of the required $G$ LLM queries (see Sec. 4.1), while the empirical baseline includes LLM inference FLOPs. Using the paper’s own 12,300 TFLOPs/query, $G$ queries would add ~$12,300G$ TFLOPs to Monte-Carlo, which is orders of magnitude larger than the values reported.\n- The errors in Figure 8 are already substantial, and the inclusion of $T = 2$ and $T = 8$, temperatures that are effectively nonsense in practical LLM inference, further undermines the credibility of the analysis. The authors should focus on realistic temperature ranges (e.g., $T \\in [0, 1.5]$) and discuss why their estimator’s performance deteriorates outside that regime.\n- The curves are not clear enough in Figures 2 and 5.\n- The experimental validation is extremely narrow. The authors only test their method on **two models** (GPT-4o-mini and Llama-3.2 1B-Instruct) and a **single dataset (MATH)**. This limited scope raises concerns about the generality of the proposed estimator.\n- Terminology:\n    - (Line 32-33) Actually, TTV is not a well-known acronym in LLM inference literature, and I prefer to use the full name (test-time voting), answer aggregation, etc.\n    - (Line 33-34) In the most recent LLM literature (e.g., [1][2][3]), *“majority voting”* is used colloquially to mean selecting the **most frequent** answer among sampled generations, without requiring the winner to exceed 50% of votes. The distinction from *“plurality voting”* is rarely enforced and may confuse the reader.\n\n[1]. Wang, Xuezhi, et al. \"Self-consistency improves chain of thought reasoning in language models.\" *arXiv preprint arXiv:2203.11171* (2022).\n\n[2]. Brown, Bradley, et al. \"Large language monkeys: Scaling inference compute with repeated sampling.\" *arXiv preprint arXiv:2407.21787* (2024).\n\n[3]. Du, Weihua, Yiming Yang, and Sean Welleck. \"Optimizing temperature for language models with multi-sample inference.\" *arXiv preprint arXiv:2502.05234* (2025)."}, "questions": {"value": "- See Weaknesses\n- For weakness 1, could the authors provide some theoretical proof about why $5-10$ samples are enough?\n- Can the methodology be applied to other test-time voting methods, like weighted majority voting and best-of-N?\n- Even if the proposed estimator can accurately predict the accuracy curve of majority voting as a function of the number of samples $M$, is there any principled way to determine a *suitable* or *optimal* number of samples in practice? Without such guidance, it is unclear how this estimator informs real-world inference-time decisions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w73HgAzMtp", "forum": "Q6hMSV2QAg", "replyto": "Q6hMSV2QAg", "signatures": ["ICLR.cc/2026/Conference/Submission13148/Reviewer_fSjZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13148/Reviewer_fSjZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13148/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761438109629, "cdate": 1761438109629, "tmdate": 1762923863934, "mdate": 1762923863934, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims at improving computational efficiency of majority-voting techniques used to improve LLM accuracy. The main contribution is to compute a first estimate of the LLM's output distribution and then to simulate majority-voting without an LLM."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well-written and the plots are readable."}, "weaknesses": {"value": "The contributions of this paper are very limited. \n\nThe paper argues that if we know a good estimate of the categorical distribution $p(x)$ over output sequences of an LLM then we can speed up the majority-vote sampling process by sampling from a categorical distribution instead of the LLM. I think one could even directly compute the expected majority vote instead of simulating sampling M times from a categorical distribution (as in 4.1), provided we have a good-enough $p(x)$. Either way, the challenge is rather to estimate $p(x)$ in the first place (from my perspective).\n\nIn addition to the weak contribution, the experimental analysis does not clearly demonstrate that this simple approach is significantly better than majority-voting approaches in the literature. The current empirical evidence is very limited since (1) the approach is evaluated on just a single dataset, and (2) a detailed comparison to baselines is missing:\n\nFirst, the paper argues that the computational effort is too high to extend the analysis to more datasets. The problem of the current evaluation is, however, rather that it remains unclear if this dataset is reasonable and sufficient to study the problem. Second, (and more important), it might be the case that a small number of samples is also sufficient for the baselines to obtain a good performance estimate. The paper is missing a detailed comparison with computational effort / FLOPS directly compared against method performance in estimating accuracy. In particular, the paper is missing a comparison of a small number of samples (KM) in previous approaches against the small number of samples used for this approach (G). This baseline comparison would be critical to correctly assess the contribution of this paper.\n\nOverall, this paper does not have significant contributions, insights and empirical evidence to recommend it for acceptance."}, "questions": {"value": "What does \"ground truth\" refer to exactly in Figure 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Lz4s56vkdO", "forum": "Q6hMSV2QAg", "replyto": "Q6hMSV2QAg", "signatures": ["ICLR.cc/2026/Conference/Submission13148/Reviewer_rj8o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13148/Reviewer_rj8o"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13148/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761472688830, "cdate": 1761472688830, "tmdate": 1762923863494, "mdate": 1762923863494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method to estimate the accuracy of the self-consistency method during \"test-time scaling\" (i.e., how the ensemble accuracy changes with respect to the number of samples)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The research problem addressed in this paper—i.e., the accuracy estimation for self-consistency method—is meaningful.\n2) The introduction section is clear and easy to follow."}, "weaknesses": {"value": "1) At the end of the paper, in Appendix D, the authors mention that, \"we used a LLM, GPT-4o, to assist in retrieval and discovery of related works\".   \nBased on this, the related work section provided in the paper is too brief, and the description of the most relevant literature—i.e., the literature on \"estimating the accuracy of self-consistency method during scaling\"—is lacking. The authors note in the related work section that this research problem has been proposed by prior works, but they do not provide an introduction to the methodologies proposed by the prior works.\n2) In the experiments, the authors only use one dataset for evaluation. It is recommended that the authors use more datasets and cover different types of tasks, rather than focusing solely on math.\n\nSome other concerns:    \nIt is recommended that the authors add references the first time \"test-time voting (TTV)\" is mentioned in the Introduction. Additionally, it seems that this term is not frequently used by researchers in the field of test-time scaling."}, "questions": {"value": "None."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pdwC3rNH9W", "forum": "Q6hMSV2QAg", "replyto": "Q6hMSV2QAg", "signatures": ["ICLR.cc/2026/Conference/Submission13148/Reviewer_J8aT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13148/Reviewer_J8aT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13148/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761770401813, "cdate": 1761770401813, "tmdate": 1762923863120, "mdate": 1762923863120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}