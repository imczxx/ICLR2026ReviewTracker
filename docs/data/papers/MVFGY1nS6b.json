{"id": "MVFGY1nS6b", "number": 24487, "cdate": 1758357328941, "mdate": 1763480190180, "content": {"title": "Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking", "abstract": "Large Language Model (LLM)-based agents have emerged as a transformative approach for open-ended problem solving, with information seeking (IS) being a core capability that enables autonomous reasoning and decision-making.  While prior research has largely focused on improving retrieval depth, we observe that current IS agents often suffer from \\textit{low search efficiency}, which in turn constrains overall performance. A key factor underlying this inefficiency is the sparsity of target entities in training tasks, which limits opportunities for agents to learn and generalize efficient search behaviors. To address these challenges, we propose WebLeaper, a framework for constructing high-coverage IS tasks and generating efficient solution trajectories. We formulate IS as a tree-structured reasoning problem, enabling a substantially larger set of target entities to be embedded within a constrained context. Leveraging curated Wikipedia tables, we propose three variants for synthesizing IS tasks—Basic, Union, and Reverse-Union—to systematically increase both IS efficiency and effectiveness. Finally, we curate training trajectories by retaining only those that are simultaneously accurate and efficient, ensuring that the model is optimized for both correctness and search performance. Extensive experiments conducted on five IS benchmarks—BrowserComp, GAIA, Seal-0, WideSearch, and xbench-DeepSearch—demonstrate that our method consistently achieves improvements in both effectiveness and efficiency over strong baselines.", "tldr": "", "keywords": ["agent", "information seeking", "data synthesis", "llm"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/101dca6ffeec2b15061be48deb62874d07bb4761.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper targets long-horizon information-seeking tasks, where excessive tool calls, noisy retrieval, and growing context length lead to inefficiency and unstable search trajectories. The authors propose a lightweight agent framework that limits retrieval scope, reduces unnecessary webpage reading, and periodically summarizes the trajectory to maintain shorter contexts while achieving competitive final performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation with practical relevance. Long-horizon efficiency is indeed a real challenge for multi-step search agents, and the paper aims at a meaningful problem.\n\n- Pipeline is simple and reproducible. The method does not rely on additional models or training, making it easy to implement in real systems.\n\n- Experiments show stable behavior. Results demonstrate that cost can be reduced without a dramatic drop in final accuracy, which may have engineering value in low-budget agent scenarios."}, "weaknesses": {"value": "- Innovation is limited and overlaps with existing efficiency-oriented agents. Prior works such as Search-O1, SimpleDeepSearcher, InfoGENT, memory-based agents already adopt context compression, selective reading, or memory management. The proposed approach reads more like an engineering pipeline than a new methodology, and a direct comparison to these closest baselines is missing.\n\n- Efficiency gains follow from a one-size-fits-all reduction strategy. The method shortens trajectories “by default,” which may harm performance on inherently hard tasks that require long reasoning chains (e.g., math/IMO-style problems). In contrast, systems such as DeepSeek-R1 adapt chain length to task difficulty. The paper does not analyze this trade-off or justify when aggressive compression is safe.\n\n- Lack of deeper insight. The paper does not explain why the approach works—whether it improves planning, reduces noise, or merely limits input size. The contribution remains on the level of engineering heuristics, without providing methodological takeaway or generalizable design principles."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "byrXPV7Y4q", "forum": "MVFGY1nS6b", "replyto": "MVFGY1nS6b", "signatures": ["ICLR.cc/2026/Conference/Submission24487/Reviewer_vV8B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24487/Reviewer_vV8B"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760966760117, "cdate": 1760966760117, "tmdate": 1762943100603, "mdate": 1762943100603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **WebLeaper**, a framework to enhance **efficiency and efficacy** of LLM-based information-seeking (IS) agents. It reformulates IS as a **tree-structured reasoning** task, addressing entity sparsity in existing datasets. Three task variants—**Basic**, **Union**, and **Reverse-Union**—progressively increase reasoning depth and realism.\nTo ensure learning from high-quality data, trajectories are filtered via **Information-Seeking Rate (ISR)** and **Information-Seeking Efficiency (ISE)** metrics, balancing correctness and search economy.\nExperiments on **BrowserComp, GAIA, Seal-0, WideSearch, and xbench-DeepSearch** demonstrate consistent improvements in both accuracy and efficiency ."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* Addresses a neglected but critical dimension—efficiency;\n* Clear theoretical justification and measurable impact;\n* Well-designed ablation studies and visualization;\n* Comprehensive benchmark evaluation with strong improvements;\n* Highly reproducible (data construction and algorithmic details disclosed)."}, "weaknesses": {"value": "* Lack of hyperparameter sensitivity analysis for α and β;\n* Dataset bias (Wikipedia-only) not discussed;\n* No multilingual or real-world deployment tests;\n* Missing analysis on computational training overhead."}, "questions": {"value": "* Can ISR/ISE thresholds adapt dynamically during training?\n* Does Reverse-Union risk overfitting due to fuzzy clue anchoring?\n* Could integration with knowledge graphs further enhance reasoning coverage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cmmE92cQ7D", "forum": "MVFGY1nS6b", "replyto": "MVFGY1nS6b", "signatures": ["ICLR.cc/2026/Conference/Submission24487/Reviewer_ZRih"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24487/Reviewer_ZRih"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761781088326, "cdate": 1761781088326, "tmdate": 1762943100378, "mdate": 1762943100378, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents WebLeaper, a framework aimed at enhancing the efficiency and effectiveness of information-seeking (IS) agents based on large language models (LLMs). The authors identify the problem of low search efficiency in current IS agents, attributing it to the sparsity of target entities in training tasks. To address this issue, they propose a novel approach that constructs high-coverage IS tasks using a tree-structured reasoning model, allowing for a greater number of target entities within a limited context. The framework includes three dataset variants—Basic, Union, and Reverse-Union—to systematically increase task complexity. Additionally, the authors curate training trajectories based on the Information-Seeking Rate (ISR) and Information-Seeking Efficiency (ISE) to ensure that the model is optimized for both accuracy and efficiency. Extensive experiments on five IS benchmarks demonstrate that WebLeaper consistently outperforms strong baselines, validating the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an important issue in most current LLM-based information-seeking agents, specifically the problem of low search efficiency. The focus on efficiency is a valuable contribution to the field, as it complements existing efforts that primarily target search depth.\n- The proposed tree-structured reasoning framework can support more comprehensive IS tasks through more structured trajectories, which may lead to better learning of search strategies.\n- The use of ISR and ISE metrics to curate training trajectories is a valuable contribution that ensures the model is trained on high-quality data."}, "weaknesses": {"value": "- The paper claims to present an information-seeking agent; however, the agent mainly focuses on finding target entities via web search given artificially constructed complex questions. This is more akin to entity mining tasks rather than general information-seeking tasks. The authors should better clarify the definition of an information-seeking agent in this work and discuss the limitations of the proposed method in broader information-seeking scenarios—particularly, how the three proposed dataset variants can help the agent seek information beyond entity finding.\n- The proposed tree-structured reasoning framework is interesting, but the paper lacks a detailed analysis of how this structure is advantageous compared to other possible structures, such as graphs. The authors also overlook the potential limitations of tree structures in capturing complex relationships among entities.\n- Since the proposed method mainly focuses on synthetic dataset construction and trajectory filtering, it may not generalize well to real-world applications. For example, web content is often noisy, and retrieved documents may lack crucial clues or entities. This suggests that the proposed method might not perform well in practical scenarios. The authors should discuss these limitations in more depth and provide analyses or experiments to verify the robustness of their method under more realistic conditions."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "G2qaIeRn9L", "forum": "MVFGY1nS6b", "replyto": "MVFGY1nS6b", "signatures": ["ICLR.cc/2026/Conference/Submission24487/Reviewer_cPZV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24487/Reviewer_cPZV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991964619, "cdate": 1761991964619, "tmdate": 1762943100147, "mdate": 1762943100147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical inefficiency of IS agents, identifying \"entity sparsity\" as a key bottleneck. It proposes two metrics ISE and ISR to quantify the IS efficiency, and also shows that the variance of ISE is negative correlated to target entities. The authors propose WebLeaper  to automatically synthesize entity intensive training tasks from wiki tables. It models IS as a tree-structured reasoning problem. The framework increases task complexity through three variants: basic, union and reserse-union. WebLeaper also generates solution trajectories and curates them using ISE and ISR to ensure efficiency. Experiments over challenging QA tasks demonstrate that WebLeaper-trained agents significantly outperform open source baselines, achieving both higher accuracy and greater efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper highlights the low efficiency of the current IS agents, providing evidence that most of actions are often invalid. It formally defines two metrics, ISR and ISE to quantify this problem. The authors provide Proposition 1 that the variance of the ISE metric decreases as the number of target entities n grows.\n2. The paper proposes an innovative tree-based pipeline, WebLeaper, to generate entity-intensive training data from Wiki tables. This method systematically increases task complexity through three variants (Basic, Union, and Reverse-Union). The framework also curates solution trajectories by filtering for high ISR and ISE, ensuring the agent learns from optimal, efficient examples.\n3. WebLeaper demonstrate better performance in challenging QA tasks comparing to the open source IS agents."}, "weaknesses": {"value": "1. The WebLeaper is finetuned on a single base model (Qwen3-30B-A3B-Thinking-2507). The observations may change with a different base model.\n2. The ablation study could include the analysis of how the average action rounds change with different data sources (similar to table 2)."}, "questions": {"value": "It would be helpful to run the experiments mentioned in weakness part. \n1. finetune over a different base model\n2. enrich ablation study"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TZ2v3owCdT", "forum": "MVFGY1nS6b", "replyto": "MVFGY1nS6b", "signatures": ["ICLR.cc/2026/Conference/Submission24487/Reviewer_GntM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24487/Reviewer_GntM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24487/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999274844, "cdate": 1761999274844, "tmdate": 1762943099746, "mdate": 1762943099746, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes WebLeaper, a data-centric framework for improving the efficiency of web-based information-seeking agents. The authors construct dense, entity-rich tasks from Wikipedia tables (Basic, Union, Reverse-Union), generate ReAct trajectories using a strong model, and filter these trajectories with two empirically motivated metrics: Information Seeking Rate (ISR) and Information Seeking Efficiency (ISE). The filtered trajectories are used for supervised fine-tuning. Experiments on five benchmarks show solid and consistent improvements in both accuracy and efficiency, supported by ablations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel task synthesis channel using structured Wikipedia tables to create dense, multi-entity information-seeking tasks.\n2. Empirically grounded filtering strategy (ISR/ISE) that directly addresses observed inefficiencies in existing agents.\n3. Strong empirical results across five benchmarks, with clear gains and well-supported ablations."}, "weaknesses": {"value": "1. Limited insight into the underlying mechanism of why the efficiency-oriented filtering leads to such large improvements; the explanation remains at an engineering level.\n2. The claim that long trajectories are inefficient conflicts with recent RL-based reasoning advances, where longer, adaptive chains often improve quality.\n3. The ISE filtering may be too rigid, potentially suppressing necessary complex or difficulty-adaptive reasoning (e.g., long-form CoT or AIME-like tasks)."}, "questions": {"value": "1. Why does efficiency-based filtering have such a large impact?\nIt is unclear whether the gains come from richer sub-queries, reduced long-context degradation, or other behavioral shifts (eg, more focused planning).\n2. How does this reconcile with RL models that benefit from long chains?\nIf shorter, cleaner trajectories are key here, why do math/reasoning systems still require RL-driven long CoT (eg, AIME-style problems)?\n3. Is strict efficiency optimal for tasks requiring exploration?\nThe ISE constraint may suppress necessary divergent reasoning (eg, adaptive exploration), and it is unclear whether the model loses performance on complex tasks such as AIME24/25.\n\nI would be happy to engage with the authors during the rebuttal phase regarding these concerns, and I am open to revising my score should the responses address them satisfactorily."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aIl6k2JLYM", "forum": "MVFGY1nS6b", "replyto": "MVFGY1nS6b", "signatures": ["ICLR.cc/2026/Conference/Submission24487/Reviewer_vV8B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24487/Reviewer_vV8B"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission24487/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763049126721, "cdate": 1763049126721, "tmdate": 1763049126721, "mdate": 1763049126721, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "We thank all reviewers for their time. We are encouraged that the reviewers found our work to be novel, empirically grounded, and effective.\n\nWe have summarized the strengths and categorized their concerns below, followed by an overview of how we have addressed them.\n\n**Strengths**\n\nThe reviewers have affirmed the novelty, the theoretical grounding of metrics, and the strength of empirical results:\n\n- **Methodology & Novelty:**\n  - \"Novel task synthesis channel using structured Wikipedia tables ... multi-entity information-seeking tasks.\" (**vV8B**)\n  - \"Proposes an innovative tree-based pipeline, ... systematically increases task complexity.\"1 (**GntM**)\n  - \"Addresses a neglected but critical dimension—efficiency.\" (**ZRih**)\n  - \"The proposed tree-structured reasoning framework can support more comprehensive IS tasks.\" (**cPZV**)\n- **Metrics (ISR & ISE):**\n  - \"Empirically grounded filtering strategy (ISR/ISE) that directly addresses observed inefficiencies.\" (**vV8B**)\n  - \"Clear theoretical justification and measurable impact.\" (**ZRih**)\n  - \"The use of ISR and ISE metrics to curate training trajectories is a valuable contribution.\" (**cPZV**)\n- **Evaluation & Results:**\n  - \"Strong empirical results across five benchmarks, with clear gains and well-supported ablations.\" (**vV8B**)\n  - \"Significantly outperform open source baselines, achieving both higher accuracy and greater efficiency.\"2 (**GntM**)\n  - \"Highly reproducible (data construction and algorithmic details disclosed).\" (**ZRih**)\n\n**Concerns and Our Improvements**\n\nThe reviewers expressed concerns regarding the mechanism of efficiency gains, the relationship between our method and RL-based reasoning, the definition of the task scope, and requests for additional ablation studies and model generalizations.\n\n**1. Mechanism, Efficiency vs. Reasoning, and RL Integration**\n\n- **Concerns:**\n  - \"Limited insight into the underlying mechanism of why the efficiency-oriented filtering leads to such large improvements.\" (**vV8B**)\n  - \"The claim that long trajectories are inefficient conflicts with recent RL-based reasoning advances.\" (**vV8B**)\n  - \"The ISE filtering may be too rigid, potentially suppressing necessary complex or difficulty-adaptive reasoning.\" (**vV8B**)\n- **Response:**\n  - **Clarification:** We clarified the distinction between **Information Seeking** (where \"length\" often implies redundant actions/noise, making shortness desirable) and **Logical Reasoning** (where \"length\" implies depth, making shortness risky).\n  - **New Experiments** We implemented GRPO on top of our SFT model. The results show that our method is compatible with RL. Crucially, the agent learned to improve performance *without* increasing the number of steps, confirming that for IS tasks, \"smarter\" is better than \"longer.\"\n\n**2. Generalization (Models, Real-World, & Language)**\n\n- **Concerns:**\n  - \"Finetuned on a single base model (Qwen3-30B)... observations may change with a different base model.\" (**GntM**)\n  - \"May not generalize well to real-world applications... web content is often noisy.\" (**cPZV**)\n  - \"No multilingual or real-world deployment tests.\" (**ZRih**)\n  - \"Dataset bias (Wikipedia-only) not discussed.\" (**ZRih**)\n- **Response:**\n  - **New Experiments**  We conducted experiments using **Qwen3-4B**. The results confirm consistent improvements, proving our method works across model sizes.\n  - **Analysis:** We highlighted that our benchmarks (GAIA, BrowseComp, WideSearch) are constituted of noisy, real-world, and multilingual (Chinese/English) data, directly validating robustness beyond Wikipedia.\n\n**3. Task Definition & Structure**\n\n- **Concerns:**\n  - \"Agent mainly focuses on finding target entities... akin to entity mining tasks rather than general information-seeking tasks.\" (**cPZV**)\n  - \"Lacks a detailed analysis of how this structure [Tree] is advantageous compared to other possible structures, such as graphs.\" (**cPZV**)\n- **Response:**\n  - **Clarification:** We justified the **entity-centric** definition as a widely adopted foundation for complex reasoning (supported by references like WebResearcher/DeepDive).\n  - **Justification:** We explained that the **Tree structure** was chosen specifically to maximize entity density and synthesis scalability, which are the primary bottlenecks we aim to solve.\n\n**4. Ablations & Hyperparameters**\n\n- **Concerns:**\n  - \"Ablation study could include the analysis of how the average action rounds change.\" (**GntM**)\n  - \"Lack of hyperparameter sensitivity analysis for $\\alpha$ and $\\beta$.\" (**ZRih**)\n- **Response:**\n  - **New Analysis:** We added a sensitivity analysis for ISR and ISE thresholds, identifying the \"sweet spot\" for data quality vs. quantity.\n  - **Clarification:** We pointed to Figure 4 analysis which explicitly plots Effectiveness vs. Efficiency (action rounds).\n\nFor further details on these experiments and clarifications, we kindly refer the reviewers to our specific responses below."}}, "id": "fHV1UA6WWM", "forum": "MVFGY1nS6b", "replyto": "MVFGY1nS6b", "signatures": ["ICLR.cc/2026/Conference/Submission24487/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24487/Authors"], "number": 26, "invitations": ["ICLR.cc/2026/Conference/Submission24487/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763716909385, "cdate": 1763716909385, "tmdate": 1763716909385, "mdate": 1763716909385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}