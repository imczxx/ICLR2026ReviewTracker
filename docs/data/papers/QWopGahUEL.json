{"id": "QWopGahUEL", "number": 25452, "cdate": 1758368225042, "mdate": 1760347142719, "content": {"title": "Games for AI Control: Models of Safety Evaluations of AI Deployment Protocols", "abstract": "To evaluate the safety and usefulness of deployment protocols for untrusted AIs, AI Control uses a red-teaming exercise played between a protocol designer and an adversary. This paper introduces AI-Control Games, a formal decision-making model of the red-teaming exercise as a multi-objective, partially observable, stochastic game. We also introduce reductions from AI-Control Games to a special case of zero-sum partially observable stochastic games that allow us to leverage existing algorithms to find Pareto-optimal protocols.\nWe apply our formalism to model, evaluate and synthesise protocols for deploying untrusted language models as programming assistants, focusing on Trusted Monitoring protocols, which use weaker language models and limited human assistance.\nFinally, we demonstrate the utility of our formalism by showcasing improvements over empirical studies in existing settings, evaluating protocols in new settings, and analysing how modelling assumptions affect the safety and usefulness of protocols.", "tldr": "We introduce a game-theoretic framework for modelling AI Control evaluations, and synthesising protocols.", "keywords": ["Partially Observable Stochastic Games", "AI Control", "AI Evaluations", "Safeguards", "Game theory"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/7c6bf24da5832b676ea37c1f217c451e5d09b73a.pdf", "supplementary_material": "/attachment/2ecbbd78b6374b506c760f201ef667c983b87fa8.zip"}, "replies": [], "withdrawn": true}