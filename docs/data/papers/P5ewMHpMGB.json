{"id": "P5ewMHpMGB", "number": 1209, "cdate": 1756864913121, "mdate": 1759898221171, "content": {"title": "Tri-Agent Driving: Learning to Coordinate Agents via Scenario Complexity Representation for Efficient Autonomous Driving", "abstract": "We present Tri-Agent Driving (TAD), a novel learning framework that dynamically coordinates multiple autonomous agents by learning lightweight scenario complexity representation directly from sensor inputs. This learned representation serves as a routing signal to enable real-time activation of the optimal agent, balancing computational efficiency and reasoning depth on demand. TAD integrates three complementary agents: a Fast Agent optimized for low-complexity and routine scenarios, a Smart Agent for medium-complexity scenes and a Deep Thinking Agent enhanced with Chain-of-Thought (CoT) reasoning for high-complexity corner cases. The core of TAD lies in the trainable Agent Coordination module, which proactively predicts scenario complexity and triggers agent switching without human intervention. On a challenging hybrid test set spanning diverse traffic conditions, TAD achieves state-of-the-art trajectory prediction, while reducing average inference latency by 26\\% (4.2s vs. 5.7s) and GPU memory consumption by 30\\% (15.4 GB vs. 22 GB) compared to the strongest VLM-based model. This ``fast when possible, deep when necessary” paradigm establishes a new standard for efficient, robust, and adaptive end-to-end autonomous driving.", "tldr": "", "keywords": ["Scenario Complexity-Aware", "Vision-Language Models", "Autonomous Driving"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/629197bf9df196cffec9b9fdf515f707e95398a1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a Mix-of-Experts–like planning framework for autonomous driving. In simple scenarios, a faster end-to-end model is used for trajectory planning, while in medium and complex scenarios, a VLM-based large model is employed for scene understanding and planning. The authors introduce a data-driven method for defining scene complexity that does not rely on manually set thresholds, and they design a ViT-based module to assess scene complexity during inference. Experiments conducted on a hybrid dataset fused from multiple open-source datasets demonstrate that the proposed approach achieves consistent advantages over previous strategies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed TAD framework presents an intuitive idea: by adopting a Mixture-of-Experts–like approach, it allows the system to use a faster end-to-end model for trajectory planning in most common and simple scenarios, thereby significantly reducing computational cost.\n2. The narrative is clear, and the figures and tables are intuitive, making it easy for readers to understand the authors’ methodology and main ideas."}, "weaknesses": {"value": "1. The comparison with Senna in Table 4 is not entirely appropriate, as Senna is a sequential model combining VLM and end-to-end approaches. Its final trajectory is produced by the end-to-end module, rather than being directly generated by the VLM as in the proposed method.\n2. The relative definition of scene complexity has certain limitations. For example, in the nuScenes dataset, straight-driving scenarios account for a large portion, so some cases categorized as “complex” may not actually be hard cases. Conversely, if a dataset primarily contains complex scenes, forcing a split into “simple” cases may also be inappropriate.\n3. Although the proposed method improves average latency and memory, this metric has limited practical significance, since what matters in real-world applications is the real-time latency.\n4. The paper lacks sufficient training details. Specifically, for each agent, is the training performed only on data corresponding to its assigned scene complexity, or on the entire dataset? If it is the former, then misclassification of a complex scene as a simple one could severely degrade performance, as the fast agent may not have been trained on such complex cases.\n5. In Table 3, there is a significant performance gap between the fast agent and the other two agents. If this is the case, then regardless of scene complexity, a fully VLM-based model (e.g., Impromptu-3B) should theoretically achieve the best results. However, as shown in Table 4, the proposed hybrid model performs better. Authors should clarify why this is the case."}, "questions": {"value": "1. It is unclear how “Unseen Cases” are labeled and identified. Is this information, such as Unconventional Obstacles, labeled in the dataset?\n2. For the scene complexity annotation, were the datasets annotated separately before merging, or was the annotation conducted after merging all original datasets (nuScenes, Impromptu VLA, ...)?\n3. Line 357 mentions that the authors further annotated CoT reasoning data. If these annotations were produced using a large model, this should also be explicitly stated in Line 632, where the use of large models is discussed.\n4. There seems to be a practical contradiction: complex and safety-critical scenarios, where deep and accurate reasoning is most needed, are often the ones requiring the fastest inference speed.\n5. It is recommended to use vector-based PDF figures, as the current rasterized images become blurry when zoomed in."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "IWxnyeV1xl", "forum": "P5ewMHpMGB", "replyto": "P5ewMHpMGB", "signatures": ["ICLR.cc/2026/Conference/Submission1209/Reviewer_c1Uy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1209/Reviewer_c1Uy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760605289360, "cdate": 1760605289360, "tmdate": 1762915707973, "mdate": 1762915707973, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Tri-Agent Driving (TAD), a hierarchical autonomous driving framework with three agents, that handle scenes of increasing complexity.\nA complexity-based routing module classifies each scene into easy, normal, or hard levels to decide which agent plans the trajectory.\nTAD aims to balance accuracy, latency, and computational cost, achieving comparable planning performance with lower delay and memory than single-agent or VLM baselines.\nThe main contributions are the complexity-driven routing strategy, and analysis showing improved efficiency trade-offs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The TAD architecture cleanly decomposes tasks by scene complexity, making the system easy to reason about and extend.\n2. Complexity-based routing allocates compute where needed, yielding better latency/memory trade-offs than a single heavy model.\n3. The paper is well organized and written in a clear, easy-to-follow manner."}, "weaknesses": {"value": "1. Lack of empirical analysis of existing hybrid systems. Although the authors claim in the related work section that pipeline of DriveVLM & Senna (treating VLM outputs as fixed auxiliary inputs to downstream modules) is suboptimal, this limitation is not empirically validated. Presenting comparative experiments to demonstrate such drawbacks would make the motivation for introducing TAD much more convincing.\n2. Questionable validity of complexity labels. The complexity labels used to decide which agent handles planning are defined purely from a scene-modeling perspective and are hard-coded using the $<Q1$ and $>Q3$ thresholds. This approach seems arbitrary, lacking empirical analysis.\n3. Limited scenario complexity in the dataset. The dataset used does not appear to include highly challenging or diverse driving scenes, which restricts the evaluation of the proposed system’s robustness and scalability.\n4. Absence of closed-loop evaluation. The results are primarily based on open-loop metrics such as L2 trajectory error. Without closed-loop testing, it is difficult to assess performance, especially the paper aims to address some complex scenarios."}, "questions": {"value": "1. Does the system include any mechanism to estimate uncertainty or fallback when the complexity classifier is uncertain or misclassifies a scene? This could be critical for safety in deployment.\n2. You mention that existing hybrid systems (DriveVLM & Senna), where VLM outputs are treated as fixed auxiliary inputs, have notable limitations. Could you provide empirical evidence or ablation studies demonstrating this weakness to strengthen your motivation for TAD?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X4PLkx0oSG", "forum": "P5ewMHpMGB", "replyto": "P5ewMHpMGB", "signatures": ["ICLR.cc/2026/Conference/Submission1209/Reviewer_uWbS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1209/Reviewer_uWbS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761574173401, "cdate": 1761574173401, "tmdate": 1762915707528, "mdate": 1762915707528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript introduces Tri-Agent Driving, a framework that dynamically routes multi-view sensor inputs to one of three agents: a lightweight Fast Agent, a medium-capacity Smart Agent, and a CoT-enhanced Deep Thinking Agent,  based on a learned scenario-complexity signal (ScpViT). The idea of adaptive, on-demand activation of differently sized reasoning modules is compelling and addresses an important deployment trade-off: conserve compute in routine cases while invoking heavier reasoning for long-tail corner cases."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles an important topic: how to allocate computation adaptively in end-to-end autonomous driving systems. The high-level idea of dynamic routing among multiple reasoning agents is appealing, and the motivation to balance efficiency and robustness is timely and relevant to practical deployment"}, "weaknesses": {"value": "However, in its current form, the paper has substantial methodological and empirical weaknesses that limit confidence in its claims.\n\nAbstract:\nThe abstract does not clearly communicate what problem is being solved or why it matters. Even after reading it several times, I still could not pinpoint the exact task or contribution. The writing feels vague and overly general, lacking concrete details that help readers understand the core objective and novelty.\n\nIntro:\nThe introduction never explicitly defines the research problem. It repeatedly emphasizes “trade-offs” between computation and reasoning, but does not specify for which task or under what setting. I only realized on the second page that the paper targets end-to-end autonomous driving, which should have been stated up front.\n\nAdditionally, the mention of \"long-tail\" scenarios (line 84) requires further justification. What constitutes a long-tail scenario in the context of autonomous driving? How is it formally defined, and what is the data distribution used in the experiments? The introduction also relies on overly vague and promotional phrasing, which should be revised for clarity and focus.\n\nFinally, the claimed contribution regarding speed improvement lacks essential experimental details, such as the hardware setup or computational environment, making it difficult to assess its validity.\n\nMethodology：\nThe methodological presentation suffers from a lack of logical flow. If the goal is to address an end-to-end task, the section should begin with a clear problem definition and necessary preliminaries. Instead, the authors jump directly into the model architecture, leaving readers confused about the overall setup.\n\nI have serious concerns regarding the proposed scene complexity computation. How are factors such as “Environment,” “Entities,” and “unseen cases” actually derived? Are they obtained from front-view images or historical agent states? The process for identifying elements like “ambiguous traffic signs” or “moderate pedestrian density” from limited input data remains unexplained. The inputs and outputs of the model are not clearly defined, making the entire pipeline difficult to follow.\n\nMoreover, the manual assignment of values and complexity indices for different factors appears arbitrary. The authors do not justify how these values were chosen or whether they generalize across different scenarios. The criteria for complexity level划分 also lack theoretical or empirical support.\n\nThe core contribution appears to be ScpViT, but the design of the complexity computation seems relatively straightforward and lacks clear innovation. The remaining components (e.g., VLA and CoT modules) are adapted from existing works, which further diminishes the novelty of the approach. More importantly, the implementation details of these modules are not sufficiently elaborated.\n\nExperiments：\nThe experimental section has several critical shortcomings. The custom dataset appears to be filtered according to the model’s own complexity classification, which introduces potential bias and raises concerns about circular evaluation.\n\nThe experiments are conducted only on this custom dataset without validation on established public benchmarks, which limits the credibility of the reported results. Furthermore, the selected baselines are outdated—mostly from two or three years ago—and do not reflect the current state of the art. The number of baselines is also limited, weakening the comparative analysis.\n\nMost tests are performed in open-loop settings, which are insufficient for validating model effectiveness in real-world driving. Closed-loop evaluation following standard protocols would be more appropriate. The inclusion of trajectory prediction metrics also seems inconsistent with the initial end-to-end framing; if trajectory prediction is a focus, relevant baselines and comprehensive metrics from that subfield should be included.\n\nAs someone familiar with this area, I believe the authors should deepen their understanding of autonomous driving tasks and evaluation methodologies before revising. In its current form, the manuscript contains substantial flaws in motivation, method design, and experimental validation, and I do not believe it meets the bar for publication at ICLR."}, "questions": {"value": "See the content in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "pM9foNFmeY", "forum": "P5ewMHpMGB", "replyto": "P5ewMHpMGB", "signatures": ["ICLR.cc/2026/Conference/Submission1209/Reviewer_VAfo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1209/Reviewer_VAfo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920656409, "cdate": 1761920656409, "tmdate": 1762915707403, "mdate": 1762915707403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Tri-Agent Driving (TAD), an autonomous driving framework that switches between three types of driving prediction models depending on how difficult a situation is. A lightweight vision transformer (ScpViT) looks at camera inputs and decides whether the current scene is simple, moderately complex, or very complex. For simple cases, a fast and efficient model is used. For medium complexity, a vision-language model with semantic understanding (\"smart agent\") takes over. For difficult cases, a slower reasoning model with chain-of-thought logic is used. The goal of the approach is to let the system be fast most of the time but think deeply when needed, in order to achieve similar or better accuracy than large vision-language models while using less time and GPU memory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-organized and easy to read, with illustrative figures and tables. The proposed tri-agent approach with a learned complexity-based routing is interesting and appears to address the efficiency-accuracy trade-off, as it appears to increase prediction accuracy while having lower latency and memory consumption than compared-to baselines. The benchmarks use real-world scenes over a wide range of traffic conditions."}, "weaknesses": {"value": "The accuracy of the ScpViT model is trained on and evaluated against scenario complexity derived by authors, so the comparison to other models might not be fully representative. THe paper could also benefit from showing example trajectories to better illustrate the prediction accuracy of the three agents, and where the simpler agents might fail. Some ablations comparing different routing methods would be interesting."}, "questions": {"value": "- I would be curious to know how the 3 models perform individually on the hybrid test set in Table 4, both in terms of accuracy and efficiency. Did the authors compute this? \n- Table 2: Should Params (MB) be Params (M)? And what is the memory consumption of these complexity prediciton models?\n- The inference latency (>4s) seems unsuitable for real-time AV control. What is the practical applicability of this work?\n- The tables mention t=1s/2s/3s. Is the error measured at the final time step t, or over times 0 to t? If the latter, what is the step frequency dt, and could transitioning between agents lead to non-smooth control actions? \n- In table 3, why is the deep thinking agent performing worse than the smaller smart agent on low complexity scenarios? \n- How are scenarios categorized as training vs test?\n- How do the authors think their approach would compare to a complexity router directly outputting a model, rather than a score which is then converted to a model based on percentiles? Also the authors mention \"The Deep Thinking Agent is designed to handle extreme corner cases that demand sophisticated reasoning\". However this models is assigned 25% of cases, which may appear to be overkill?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9FwKtFnAoO", "forum": "P5ewMHpMGB", "replyto": "P5ewMHpMGB", "signatures": ["ICLR.cc/2026/Conference/Submission1209/Reviewer_Yavs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1209/Reviewer_Yavs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984640286, "cdate": 1761984640286, "tmdate": 1762915707302, "mdate": 1762915707302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}