{"id": "Z0wK97A4WY", "number": 14703, "cdate": 1758242088862, "mdate": 1759897354076, "content": {"title": "Context Attribution with Multi-Armed Bandit Optimization", "abstract": "Understanding which parts of the retrieved context contribute to a large language model’s generated answer is essential for building interpretable and trustworthy generative QA systems. We propose a novel framework that formulates context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each context segment is treated as a bandit arm, and we employ Combinatorial Thompson Sampling (CTS) to efficiently explore the exponentially large space of context subsets under a limited query budget. Our method defines a reward function based on normalized token likelihoods, capturing how well a subset of segments supports the original model response. Unlike traditional perturbation-based attribution methods (e.g., SHAP), which sample subsets uniformly and incur high computational costs, our approach adaptively balances exploration and exploitation by leveraging posterior estimates of segment relevance. This leads to substantially improved query efficiency while maintaining high attribution fidelity. Extensive experiments on diverse datasets and LLMs demonstrate that our method achieves competitive attribution quality with fewer model queries.", "tldr": "The paper introduces CAMAB, a bandit-based framework that efficiently identifies which context segments support LLM outputs, achieving high attribution fidelity with far fewer queries than traditional perturbation methods", "keywords": ["Large language model", "attribution method", "explainable machine learning", "reinforcement learning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d0cda274383f15a7de3c42671f0a57cf33094379.pdf", "supplementary_material": "/attachment/3770964b9c462dd34ba0bc083bc1ed16f196fe17.zip"}, "replies": [{"content": {"summary": {"value": "The paper studies the problem of segment-level context attribution. The authors formulate attribution as a multi-armed bandit problem, where each segment is an arm and an action corresponds to selecting a subset of segments. The reward is defined as the change in token log-likelihood of the original answer when conditioning on a subset versus the full context. The objective is to find high-reward subsets under a limited query budget. The proposed method CAMAB uses Combinatorial Thompson Sampling with Gaussian posteriors per segment. At each round, it samples per-segment utilities, selects the top-p subset, queries the LLM to obtain the reward, and updates the posteriors using a linear semi-bandit observation model. The authors compare CAMAB with baselines such as ContextCite, Leave-One-Out, and SHAP. Experiments are conducted on 3 different tasks using 3 different LLMs of varying sizes."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Context attribution is an important problem for RAG applications.\n\n\n* The experiments include both token-level and sentence-level attribution."}, "weaknesses": {"value": "* The main motivation of this work is to improve efficiency compared to perturbation-based methods such as LIME and SHAP. However, there already exist efficient variants such as TreeSHAP that mitigate the extensive sampling problem. The authors should discuss and include comparisons with these variants. Moreover, none of the datasets used in the paper involves long-context scenarios, which somewhat weakens the motivation.\n* I am not fully convinced by the MAB framing. What is exploration and exploitation in the context attribution setting?\n* There is more recent work on context attribution that the authors neither discuss nor compare against [1, 2, 3].\n* The results in Tables 1–3 do not clearly show the advantages of CAMAB as the improvements are marginal. The authors should report standard deviations and/or conduct statistical significance tests.\n\n[1] Cohen-Wang, Benjamin, Yung-Sung Chuang, and Aleksander Madry. \"Learning to Attribute with Attention.\" arXiv preprint arXiv:2504.13752 (2025).\n\n[2] Liu, Fengyuan, Nikhil Kandpal, and Colin Raffel. \"AttriBoT: A Bag of Tricks for Efficiently Approximating Leave-One-Out Context Attribution.\" ICLR 2025.\n\n[3] Xiao, Yingtai, et al. \"TokenShapley: Token Level Context Attribution with Shapley Value.\" arXiv preprint arXiv:2507.05261 (2025)."}, "questions": {"value": "* Could the paper report runtime comparisons between CAMAB and other baselines?\n* Since the Leave-One-Out baseline removes one segment at a time and measures the effect on the model's output likelihood, shouldn't it serve as an upper bound performance when $k = 1$? Could the authors clarify why CAMAB performs better than this baseline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "14Ybc7nrSr", "forum": "Z0wK97A4WY", "replyto": "Z0wK97A4WY", "signatures": ["ICLR.cc/2026/Conference/Submission14703/Reviewer_YBij"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14703/Reviewer_YBij"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876722438, "cdate": 1761876722438, "tmdate": 1762925068603, "mdate": 1762925068603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CAMAB, a new framework for context attribution in retrieval-augmented generation (RAG) systems with large language models (LLMs). By formulating the attribution task as a combinatorial multi-armed bandit (CMAB) problem and leveraging Combinatorial Thompson Sampling (CTS), the method aims to efficiently identify which context segments most support a model’s generated answer. The approach is evaluated on three datasets (SST2, HotpotQA, CNN/DailyMail) and three LLMs (LLaMA3-8B, Qwen3-8B, SmolLM-1.7B), showing competitive or slightly superior attribution quality with fewer model queries compared to established baselines like SHAP and ContextCite."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Novel Formulation: The CMAB framing for context attribution is original and addresses the inefficiency of traditional perturbation-based methods.\nPrincipled Algorithm: The use of Combinatorial Thompson Sampling for adaptive exploration/exploitation is well-motivated and theoretically grounded.\nEmpirical Evaluation: The experiments are thorough, spanning multiple datasets and models, and use both log-probability drop and BERTScore metrics.\nPractical Relevance: Query efficiency is a real concern for LLM applications, and the method is designed with this in mind.\nClear Baseline Comparisons: The paper benchmarks against strong baselines and explores performance under varying query budgets."}, "weaknesses": {"value": "Marginal Empirical Gains: The improvements over existing baselines are generally small, and in some cases, CAMAB is only comparable rather than clearly superior—even under limited query budgets. This raises questions about the practical impact and significance of the contribution."}, "questions": {"value": "Given the marginal improvement over existing prior works, what is key value add to attribution with the proposed approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "raSKyyh989", "forum": "Z0wK97A4WY", "replyto": "Z0wK97A4WY", "signatures": ["ICLR.cc/2026/Conference/Submission14703/Reviewer_3iHs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14703/Reviewer_3iHs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993839410, "cdate": 1761993839410, "tmdate": 1762925068238, "mdate": 1762925068238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CAMAB, a framework for context attribution that identifies which retrieved segments most influence an LLM's output. It formulates the attribution task as a CMAB problem, where each context segment is treated as an arm, and uses combinatorial Thompson sampling to efficiently explore the exponentially large space of possible context subsets under limited query budgets. A reward function based on normalized token-likelihood differences measures how well a subset of segments supports the model's original answer. By maintaining Bayesian posteriors over each segment’s latent importance and sampling from these distributions to choose subsets, CAMAB adaptively balances exploration and exploitation, focusing model queries on the most informative context portions. This approach achieves attribution fidelity comparable to or better than traditional perturbation-based methods like SHAP or LIME, while requiring far fewer model evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The authors address an important problem of contextual attribution\n* The experimental sections design demonstrates generality across different levels of compositionality and context length.\nIt also supports the claim that CAMAB is versatile across diverse generative settings."}, "weaknesses": {"value": "* The combinatorial MAB framing is elegant in theory but effectively reduced to an additive approximation that ignores segment interactions. While CTS provides tractable sampling, it does not truly explore the exponentially large action space; it merely assumes away the combinatorial complexity through a linear independence assumption. \n* Although presented as a Bayesian bandit innovation, the algorithm effectively performs an online approximation of SHAP-like marginal attribution. The independence and additivity assumptions make it efficient but at the cost of fidelity: segment dependencies, negations, or redundancy are not properly captured. \n* Results in Tables 1–3 show that CAMAB’s advantage is not consistent. The authors evaluate only 500 samples per dataset, randomly drawn from validation sets.\n* A more principled alternative would be to frame attribution as a contextual MAB problem, where each context segment's expected reward depends on features derived from the question, retrieval context, and model generation. Such a formulation would allow attribution to adapt dynamically to query-specific semantics, capture complementarity and redundancy between segments, and leverage shared structure for improved sample efficiency. Such modelling would also help to propose different reward-schemes that do not mimic SHAP. For e.g., reward based on semantic alignment between a segment and the generated answer, pproximate influence using gradients etc."}, "questions": {"value": "Kindly refer to weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1hAubG59eY", "forum": "Z0wK97A4WY", "replyto": "Z0wK97A4WY", "signatures": ["ICLR.cc/2026/Conference/Submission14703/Reviewer_sFGw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14703/Reviewer_sFGw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997546184, "cdate": 1761997546184, "tmdate": 1762925067846, "mdate": 1762925067846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for interpreting generative QA models by identifying context segments that influence a large language model’s responses. The proposed method formulates context attribution as a combinatorial multi-armed bandit problem and applies Combinatorial Thompson Sampling to efficiently explore context subsets under limited queries. A reward function based on normalized token likelihoods quantifies each segment’s contribution. Unlike perturbation-based methods adaptively balances exploration and exploitation through posterior relevance estimates, achieving high attribution fidelity with significantly fewer model queries."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors reformulate segment-level context attribution as a combinatorial multi-armed bandit problem."}, "weaknesses": {"value": "The proposed context attribution method does not fundamentally differ from perturbation- or mask-based approaches; it mainly introduces improvements in sampling or subset partitioning. Moreover, as acknowledged by the authors, traditional methods can achieve better performance when computational resources are sufficient. Hence, the theoretical guarantees and advantages of the proposed method require further clarification.\nIn the experimental section, the dataset used by the authors appears to be small, which limits the ability to accurately assess the model’s performance and relevance to current benchmarks.\nAs a reminder, that many formulas are difficult to follow and lack adequate annotations or explanations, making it challenging for readers to fully understand the theoretical derivations."}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kC5XY16kRb", "forum": "Z0wK97A4WY", "replyto": "Z0wK97A4WY", "signatures": ["ICLR.cc/2026/Conference/Submission14703/Reviewer_sEzR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14703/Reviewer_sEzR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762187865385, "cdate": 1762187865385, "tmdate": 1762925067362, "mdate": 1762925067362, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}