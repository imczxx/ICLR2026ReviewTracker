{"id": "sC9gjsv7p7", "number": 24860, "cdate": 1758361245262, "mdate": 1759896745049, "content": {"title": "A2A: Mechanistic Analysis for Efficient Layer Selection in Activation Steering", "abstract": "Activation steering has emerged as an effective and economical technique for behavior control in large language models (LLMs). Despite growing interest, existing methods typically rely on exhaustive layer-wise interventions to identify effective steering locations. This process is computationally expensive and lacks interpretability. To mitigate this problem, we propose Attribution-to-Action (A2A), an efficient layer selection framework that leverages mechanistic interpretability to identify layers where steering is most impactful. Specifically, A2A first constructs an attribution graph that traces how internal pathways contribute to model outputs, guided by a small set of contrastive behavior data. Subsequently, edge-level attribution weights are aggregated at the node level and then combined within each layer to derive an importance ranking. Steering vectors are applied only to the top-ranked layers, effectively reducing the search space. Experiments on behavior control tasks such as personality conditioning and model jailbreaking demonstrate that A2A achieves performance comparable to exhaustive search while requiring significantly fewer interventions and offering improved interpretability.", "tldr": "", "keywords": ["Mechanistic Interpretability", "Activation Steering", "Attribution Graph", "Large Language Models", "Efficient Intervention"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e6e8d1cad6c03926acf0fe8def819265ea30a825.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work highlights that precise layer localization is crucial for activation-engineering-based steering of LLM behavior. The authors address this gap from a mechanistic interpretability perspective by introducing Edge Attribution Patching with Integrated Gradients (EAP-IG). They evaluate their proposed A2A method on two tasks: personality steering (PersonalityEdit) and alignment hacking (SafeEdit). The results show that A2A achieves performance comparable to an exhaustive grid search over layers."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed layer localization method A2A is technically sound. Analylize layer importance via the attribution graph upon input embeddings, output unembeddings, attention heads and MLP blocks is resonalble and to my knowledge is the first try in activation module  selection LLM behavior steering.\n- A2A is evalualate on LLMs from two family, LLaMA2 and Qwen2.5.\n- The authors provide experimental results to demonstrate the consistency on layer seletion, task accrucy and ablation on top layer number K and attribution dataset size."}, "weaknesses": {"value": "- The presentation needs significant improvemnt. For example, the captions for Figures 2 and 3 are identical; each figure should have a distinct, informative caption.\n- The paper repeatedly claims to evaluate A2A on LLaMA 2 and Qwen 2.5, but Tables 1–3 do not specify the exact model variants. Please clarify this in the experimental setup and/or table captions.\n- A2A provides four metrics for layer ranking. Please explain how the metric is chosen in practice, justify the choice used in your main results, and, if possible, include a comparison to show sensitivity to the metric.\n- The module-selection baselines appear incomplete. In particular, linear probing used in ITI is missing. Please include this baseline or provide a clear justification for its exclusion.\n\n* [1] Li et al., Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. In NeurIPS 2023."}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "f59ZK0SQwK", "forum": "sC9gjsv7p7", "replyto": "sC9gjsv7p7", "signatures": ["ICLR.cc/2026/Conference/Submission24860/Reviewer_TZh4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24860/Reviewer_TZh4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24860/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761401517404, "cdate": 1761401517404, "tmdate": 1762943223828, "mdate": 1762943223828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed A2A, a framework for efficiently identifying which layers in a LLM are most effective for activation steering. It constructs an attribution graph using EAP-IG to trace how internal activations contribute to specific behaviors, based on contrastive data pairs. Then aggregates edge level attributions into layer level importance scores to rank layers by influence, enabling interventions only at the top-k most impactful layers."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper reframes identifying important layers as an interpretable problem by leveraging attribution graphs, providing a principled explanation for why certain layers are effective instead of relying on empirical heuristics. And the introduction of multiple aggregation metrics (In, Out, Total, Ratio) reveals different perspectives on layer influence.\n2. A2A replaces exhaustive layer wise grid search with a targeted, attribution based ranking method that reduces computation."}, "weaknesses": {"value": "1. The experiment section lacks clarity. It is not clear which representation steering method was applied to the identified layers, nor what specific evaluation metrics were used to assess steering effectiveness. The paper would benefit from reporting quantitative measures of steering accuracy and from comparing the performance of steering only the selected layers versus steering all layers.\n2. It is unclear how the attribution in Equation (1) is computed. Providing a detailed explanation of the attribution mechanism, along with intuition for its design would greatly improve it."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RrFFY32RSA", "forum": "sC9gjsv7p7", "replyto": "sC9gjsv7p7", "signatures": ["ICLR.cc/2026/Conference/Submission24860/Reviewer_A5Zq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24860/Reviewer_A5Zq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24860/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761432404563, "cdate": 1761432404563, "tmdate": 1762943223628, "mdate": 1762943223628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a way to select the most efficient layers in a transformer model using attribution patching + integrated gradients, and compare the performance gains and computational efficiency to grid-search based approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe authors propose patching techniques instead of a grid search as the most efficient way to identify important layers for steering.\n-\tThe authors test out their approach on multiple models and task settings, and show empirical generalization.\n-\tNice complexity analysis."}, "weaknesses": {"value": "-\tThe motivation is very weak, since the findings in the paper are already well known. Essentially the authors suggest that identifying important layers using causal mediation analysis is useful for steering. This is a rehashing of results from existing literature, but done in a set of specific task settings. Sadly, I didn’t really learn anything new from this paper. \n-\tWhat’s NDCG? How is it different from nDCG?\n-\tThe authors seem unaware of the literature in causal mediation analysis, or at least don’t cite it. The framework the authors propose is essentially causal mediation analysis and it has been used in several seminal works, and shown to be both performant and computationally effective. The steering setting is not sufficiently different from these other settings – steering is essentially a “how to steer” approach once a “where to steer” site has been identified.\n- No comparisons with other causal intervention approaches"}, "questions": {"value": "- The authors test out attribution patching + IG. How does this compare to activation patching, Knockout layers, adding a small perturbation to the layer in the style of the ROME paper [1]?\n- How is this different from traditional causal mediation analysis approaches, besides the fact that we use CMA + steering rather than CMA + mean ablations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ryEUfVXwCO", "forum": "sC9gjsv7p7", "replyto": "sC9gjsv7p7", "signatures": ["ICLR.cc/2026/Conference/Submission24860/Reviewer_d1dy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24860/Reviewer_d1dy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24860/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925766681, "cdate": 1761925766681, "tmdate": 1762943223334, "mdate": 1762943223334, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Attribution-to-Action (A2A), a computationally efficient and interpretable framework for selecting steering layers in LLMs. Instead of exhaustive layer-wise search, A2A builds attribution graphs from contrastive examples to rank layers by importance. Experiments on behavior control tasks (e.g., personality editing, jailbreak) show A2A achieves near-optimal performance with significantly fewer interventions across multiple models (LLama 2 7/13B, Qwen 2.5 7B)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Addresses a practical challenge in activation steering: selecting the most effective layers for intervention.\n- Well-grounded in mechanistic interpretability; the use of attribution graphs per layer is intuitive and well-motivated.\n- Method is clearly presented with intuitive visualizations, thoughtful design choices, and empirical justifications.\n- Simple, easy-to-understand approach that is significantly more efficient than exhaustive search; includes computational cost analysis.\n- Offers comprehensive hyperparameter analysis (e.g., top-k selection, dataset size), with useful insights into efficient steering vector computation."}, "weaknesses": {"value": "See Questions"}, "questions": {"value": "- Prior work [1,2,3,4] has shown that steering across all layers is effective. The paper should compare against steering on all layers as well as on top-k layers selected by A2A.\n- Minor: (Line 123) duplicate citation of Hanna et al.\n- Line 164–165: Why use the sum of incoming and outgoing attributions rather than the difference? Intuitively, $Out(l) - In(l)$ may better reflect layer $l$'s contribution. This is supported by the insight in lines 342–343, where A2A-In performs the worst.\n- The method is only applied to activation addition (Eq. 3). The authors should also evaluate with other steering operators, such as the one used in [2].\n- It's unclear how the attribution of a single layer compares to attribution aggregated across all layers. The paper should define a metric to quantify this.\n- Table 4 should be moved from the appendix to the main text.\n\n**Additional suggestions:**\n- Evaluate on smaller (e.g., 2–3B) and larger (e.g., 13–14B) models, and include other model families such as Gemma to strengthen claims of generality.\n- Explore the use of top-p for selecting layers.\n- Consider more recent steering formulation such as [4,5].\n\n**References:**\n\n[1] The Hydra Effect: Emergent Self-repair in Language Model Computations  \n[2] Refusal in Language Models Is Mediated by a Single Direction  \n[3] Beyond Linear Steering: Unified Multi-Attribute Control for Language Models  \n[4] Angular Steering: Behavior Control via Rotation in Activation Space  \n[5] Controlling Language and Diffusion Models by Transporting Activations"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ygjDsVCr0W", "forum": "sC9gjsv7p7", "replyto": "sC9gjsv7p7", "signatures": ["ICLR.cc/2026/Conference/Submission24860/Reviewer_BnWL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24860/Reviewer_BnWL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24860/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994044131, "cdate": 1761994044131, "tmdate": 1762943223119, "mdate": 1762943223119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}