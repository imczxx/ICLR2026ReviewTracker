{"id": "CokvXd3dCE", "number": 22332, "cdate": 1758329716862, "mdate": 1763112451858, "content": {"title": "Three Forms of Stochastic Injection for Improved Distribution-to-Distribution Generative Modeling", "abstract": "Modeling transformations between arbitrary data distributions is a fundamental scientific challenge, arising in applications like drug discovery and evolutionary simulation. While flow matching offers a natural framework for this task, its use has thus far primarily focused on the noise-to-data setting, while its application in the general distribution-to-distribution setting is underexplored. We find that in the latter case, where the source is also a data distribution to be learned from limited samples, standard flow matching fails due to sparse supervision. To address this, we propose a simple and computationally efficient method that injects stochasticity into the training process by perturbing source samples and flow interpolants. On five diverse imaging tasks spanning biology, radiology, and astronomy, our method significantly improves generation quality, outperforming existing baselines by an average of 9 FID points. Our approach also reduces the transport cost between input and generated samples to better highlight the true effect of the transformation, making flow matching a more practical tool for simulating the diverse distribution transformations that arise in science.", "tldr": "we identify that flow matching in the distribution-to-distribution setting is sparsity-challenged and address this with stochastic injections", "keywords": ["flow matching", "generative modeling", "AI for science", "distribution learning", "image translation"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/996cb227dedafcb94716d3a068c1b0bfe72cc7af.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a simple and computationally efficient three-stage method that injects stochasticity into the training process by perturbing source samples and flow interpolants. \nExtensive experiment is performed to verify the effectiveness of the proposed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe proposed method is practical in real world with sparse supervision. \n\n2.\tThe method is intuitionally by the demonstration of toy experiments."}, "weaknesses": {"value": "1. The two-stage learning is a kind of transfer learning, while perturbing the source distribution is a form of data augmentation, and path interpolation perturbation has been explored in prior work. The novelty the paper is unclearly and please clarify the main contribution.\n\n2. The current evaluation methodology lacks persuasiveness. To strengthen the validation, the model could be trained on unpaired datasets and then tested on paired datasets (e.g., the SynthRAD medical image paired dataset), reporting more convincing quantitative metrics such as SSIM and PSNR.  \n\n    \n3. To demonstrate the generality of random injection, experiments are needed to validate its effectiveness in flow matching based method, such as RF and OT-CFM.\n\n\n\n4. Please provide comparisons with more advanced unpaired baselines, such as OT-CFM for Unpaired Data Translation, Bi-DPM for partially paired data.\n\n    \n5. Why does perturbing the source distribution not have a hyperparameter for perturbation magnitude. Dose the impact of the perturb is negligible? The authors acknowledge that the perturbation magnitude is a parameter requiring fine-tuning.\nAblation study for the two perturbation magnitudes is necessary\n\n[1] Alexander Tong and Kilian FATRAS and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Guy Wolf and Yoshua Bengio. Improving and generalizing flow-based generative models with minibatch optimal transport. Transactions on Machine Learning Research, 2835-8856, 2024\n[2] he Xiong and Qiaoqiao Ding and Xiaoqun Zhang, Bi-modality medical images synthesis by a bi-directional discrete process matching method. https://openreview.net/forum?id=GqsepTIXWy, 2025."}, "questions": {"value": "In the left of Figure3(a), why does the blue curve first decrease and then increase?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JLU3S8YdZt", "forum": "CokvXd3dCE", "replyto": "CokvXd3dCE", "signatures": ["ICLR.cc/2026/Conference/Submission22332/Reviewer_osuf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22332/Reviewer_osuf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22332/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962113747, "cdate": 1761962113747, "tmdate": 1762942172912, "mdate": 1762942172912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "bndsWtRse4", "forum": "CokvXd3dCE", "replyto": "CokvXd3dCE", "signatures": ["ICLR.cc/2026/Conference/Submission22332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22332/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763112450882, "cdate": 1763112450882, "tmdate": 1763112450882, "mdate": 1763112450882, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces three distinct noise-injection mechanisms designed to improve distribution learning. The proposed methods are accompanied by theoretical analysis and validated through numerical experiments."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The proposed noise-injection techniques are both simple and broadly applicable. Moreover, the paper provides a thorough and rigorous theoretical analysis that explains why these methods are effective. This combination of practical simplicity and strong theoretical grounding gives the work both immediate applicability and a solid conceptual foundation. Furthermore, the inclusion of numerical experiments to support the theoretical claims strengthens the paper, as it demonstrates that the methods perform well in practice."}, "weaknesses": {"value": "One potential weakness or concern is that many of the noise-injection techniques proposed in the paper are not entirely new, even though the authors present them as novel contributions. I recommend that the authors provide a clear and fair survey of existing methods in the literature and emphasize the theoretical contributions of their work, which I believe offer the most significant novelty in this work."}, "questions": {"value": "Could the authors include toy examples to illustrate the benefits of these techniques, particularly the second one, where Lemma 1 appears especially interesting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VgtQOQnly4", "forum": "CokvXd3dCE", "replyto": "CokvXd3dCE", "signatures": ["ICLR.cc/2026/Conference/Submission22332/Reviewer_SZP1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22332/Reviewer_SZP1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22332/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981218585, "cdate": 1761981218585, "tmdate": 1762942172723, "mdate": 1762942172723, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed  three forms of stochastic injection to improve flow matching for distribution-to-distribution generative modeling. The method introduces randomness in transfer learning, source perturbation, and interpolant perturbation to address data sparsity and improve generalization. Experiments on five datasets show consistent FID improvements compared to standard flow matching and prior baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.The proposed stochastic injections (transfer pretraining, source perturbation, and interpolant noise) are conceptually intuitive and easy to integrate into existing flow matching pipelines. Numerical result show that empirical improvements across multiple datasets  in terms of FID.\n2.Experiments span five datasets showing consistent improvements in FID and qualitative fidelity."}, "weaknesses": {"value": "1.Although the method is stated as stochastic injection into flow matching method with three types of randomness, the  proposed method is a combination of three known techniques: transfer learning (training from gaussian-target), data augmentation (perturbation) and combining  with diffusion method training ( perturbing the interpolant).  Thus it is not surprising that it improves upon the basic flow matching method.  Also the motivation of the paper is to deal with generative ability from few examples, however this aspect is not explored how the proposed model deal with the scarce of data, not even empirical study how the model improves for different level of data.\n\n2.The experimental comparisons in the paper is not very convincing. Not only some recent flow matching models such as CFM, Rectified are not included, and the image quality criteria with FID is not sufficient  for real image translation applications  The effectiveness of image translation method should be evaluated  either with image quality assessment (PSNR, SSIM) or with downstream task performance.   The paper also lacks runtime analysis, leaving uncertainty about the methodâ€™s efficiency in practice.\n\n3. Overall the paper is poorly written with many flaws. For example,  in the beginning it is mentioned that the method is used with few samples with concentric examples, however the quantity of samples are not well present. Also what does it mean by standard flow matching method, as there is no specific reference?"}, "questions": {"value": "IN addition to the questions mentioned in the weakness, there are two more:\n1.While the paper briefly examines the noise schedule and scale parameter aaa on the BBBC dataset, it remains unclear how sensitive the overall performance is to these hyperparameters. Could the authors provide a broader sensitivity analysis across datasets?\n2.Can the stochastic injection strategy generalize to non-image modalities?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "weWZYKVuIF", "forum": "CokvXd3dCE", "replyto": "CokvXd3dCE", "signatures": ["ICLR.cc/2026/Conference/Submission22332/Reviewer_htau"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22332/Reviewer_htau"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22332/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991401315, "cdate": 1761991401315, "tmdate": 1762942172463, "mdate": 1762942172463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}