{"id": "VafxuFOb3f", "number": 3754, "cdate": 1757513096921, "mdate": 1763702224895, "content": {"title": "Hugging Carbon: Quantifying the Training Carbon Emissions of AI Models at Scale", "abstract": "The scaling-law era has propelled artificial intelligence (AI) from research into a global industry, but its rapid growth raises concerns over energy demand, carbon emissions, and environmental sustainability. Unlike traditional sectors, AI still lacks systematic methodologies for comprehensive carbon accounting, leaving open the questions of how large the problem is today and how large it might be in the near future. We propose a FLOPs-based framework to estimate training emissions of open-source models on Hugging Face, introducing a tiered approach to handle uneven disclosure quality. Compute is converted to energy using hardware efficiency characteristics and then to emissions using the carbon intensity of the relevant grid, which we summarize as an AI Training Carbon Intensity (ATCI, emissions per compute) and for which we report an empirical reference value to enable quick model-level estimates. Our results show that training the most popular 5,234 models (with over 5,000 downloads) emitted approximately 5,8000 tons of carbon emissions. These findings provide the comprehensive industry-scale estimate of AI’s training footprint and a practical methodology to guide future standards and sustainability strategies.", "tldr": "", "keywords": ["machine learning", "artificial intelligence", "language model", "large language models", "environmental impact", "carbon emissions"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/51cd451a99742ba1d437e4478fe76897842320b0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents an interesting FLOPs-based framework to estimate training emissions of open-source AI models on the Hugging Face Hub. They convert compute to energy based on hardware efficiency characteristics and then to emissions using readily available carbon intensity data -- they call this the AI Training Carbon Intensity and compute it for the most popular 2,097 models on the Hugging Face Hub."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The methodology used by the authors is interesting and relevant:\nThe three-tier strategy for estimating missing values makes sense given the amount of missing data and the lack of transparency in the field.\n\nThey also report novel results, for instance:\n- [CV & multimodal exhibit higher training emission intensity than NLP] -- this is consistent with previous work on different modalities\n- [Instruction-tuned models show higher median model-level emissions than base models] -- this is coherent with the fact that instruction tuning often happens iteratively, compared to base model training\n- [The geographical bias of model training] - which is concentrated in the Global North (coherent with Abdalla et al.'s results)"}, "weaknesses": {"value": "There are quite a few assumptions that are made by authors that are not necessarily supported by empirical evidence, namely:\n\n- The fact that models were trained at the geographical location of their authors -- many/most authors will use cloud compute in regions other than their own\n\n- That \"ATCI provides a meaningful measure for understanding not only the absolute environmental burden of AI training\" -- since it is based on multiple estimations, the fact that it is \"absolute\" seems far-fetched to me.\n\n- That authors provide a \"comprehensive carbon accounting in AI\" - when in fact they only estimate the emissions of training, and no other steps of the AI lifecycle.\n\nOverall, I would suggest for the authors to use less superlative claims and focus on their concrete contribution and its strengths and weaknesses."}, "questions": {"value": "The following statements are unclear to me:\n\n- \"instruction-tuned models show higher median model-level emissions than base models\" -- do you mean for each model (summing together all the instruction tuning done for that model)? Otherwise I find it strange that base emissions are lower.\n\n- What are the \"architecture-specific heuristics\" you apply to computer vision (CV) and multimodal models? how do you define them?\n\n- What about smolLM architectures and others that don't follow the scaling-law approximation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "e1utEs16bp", "forum": "VafxuFOb3f", "replyto": "VafxuFOb3f", "signatures": ["ICLR.cc/2026/Conference/Submission3754/Reviewer_PKst"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3754/Reviewer_PKst"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761571663694, "cdate": 1761571663694, "tmdate": 1762916967715, "mdate": 1762916967715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method and reproducible framework to estimate the carbon emissions due to training for many machine learning models (over two thousand open-source models from Hugging Face).  This framework leverages an approximation of the FLOPS (floating point operations) used to train the model, and translates a given number of FLOPS to an estimate of carbon emissions based on the GPUs likely used during training, the carbon intensity of the electric grid in which the model was likely trained, and the size of the model.  The latter translation is done using a metric of AI Training Carbon Intensity (ATCI) that the authors propose as a general metric for estimating the carbon emissions of AI models.  The authors conducted this analysis and reported estimates for many open-source models on Hugging Face, present top-level results in the paper, and will publish a data set and code to reproduce their analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "A key strength of this study is the scale of the results, providing carbon emissions estimates for thousands of commonly used open source models on Hugging Face.\n\nResults give some nice evidence that NVIDIA H-series accelerators are more carbon efficient than A-series.  Furthermore, there is value in the ATCI metric for comparing model training pipelines — as the authors point out, ATCI provides a normalized metric to compare across modalities and training paradigms.\n\nThis work provides strong reason to advocate for better carbon disclosure quality of all widely-adopted AI models, as better disclosure of simple factors such as training GPU type, GPU-hours, and regions would greatly improve these estimates."}, "weaknesses": {"value": "The paper states that “there is a lack of a dedicated set of measurement practices” — this statement strikes me as tenuous.  There is an established notion of Software Carbon Intensity published by the Green Software Foundation whose definition is exactly the AI Training Carbon Intensity defined in this paper, where the “functional unit” is scaled to a FLOP [1]\n\nSection 3.1’s statement that models are classified into base and instruct models seems to imply that the models considered in this paper are LLMs, but as far as I can tell this is not explicitly stated.  Furthermore, Section 3.3 suggests the opposite, namely that the models considered include LLMs but also include e.g., Vision Transformers.\n\nAssumptions are made throughout the analysis that are reasonable in the sense that they may be necessary due to the lack of data, but they are quite coarse-grained and thus they simplify the analysis a lot.  \nFor example, in applying the scaling law approximation for transformers, a ratio c is set to capture the ratio between attention and feed-forward operations.  The authors select a uniform value of 6 in most of the analysis (sensitivity analysis is conducted in the Appendix, but this also seems like a single value c is applied to all models). Similarly, when estimating GPU power, it is assumed that the GPU operates at maximum TDP — recent papers have shown that LLM training (in particular) actually induces large fluctuations in GPU power [2], making this a simplification as well.\n\nIn my opinion, the main weakness of this paper is that the estimation model seems to heavily rely on these assumptions that are applied more or less uniformly to all models, so the final analysis is effectively a sophisticated unit conversion between model characteristics (e.g., size) and a very coarse estimate of emissions from public data.\n\nI am generally happy to see a serious treatment of this estimation problem, since this paper does provide the first (to my knowledge) estimate of per-model training emissions — however, at the current stage, I do not see this as a sufficient contribution over existing guidelines and public data for ICLR.  I am happy to discuss further if I have misunderstood some key contributions of the paper.\n\n1. https://sci.greensoftware.foundation\n2. https://arxiv.org/abs/2508.14318"}, "questions": {"value": "How does the scaling law approximation (line 259) capture training time?  If I have two identical models, where one is trained for a month and the other is trained for 2 months, I would expect the latter model to have a carbon footprint twice as big.  Is that captured in this approximation?  If not, how is it captured in your analysis when GPU-hours are not reported?\n\nYour estimate states 240 tCO2/e for Llama 3 / 3.1, but the Llama 3 repo on Hugging Face [3] states 2,290 tCO2/e.  This discrepancy could be because the paper is only considering a single model out of the Llama family, but this should be clarified.\n\nTable 2 lists the disclosed emissions for some model series, but doesn’t include the estimations?\n\nThe types of accelerator families considered are not explicitly defined anywhere that I can find in the paper — the caption of Figure 2 suggests that NVIDIA A100/A800 and NVIDIA H100/H800 GPUs are considered.  How exactly are jobs assigned to one of these families?  For the Tier 1 data it sounds like this data is provided, but for Tier 2 it must be imputed, and even for Tier 1 data, a choice must be made if the model was trained using a different family of accelerator (e.g., AMD, Google TPU).  How is this handled?\n\nMinor comment — it may make sense to report CO2e/FLOP in a differently-scaled metric such as grams of CO2e/FLOP, since reporting in tons gives small values that are difficult to conceptualize (e.g., 10^{-22} on line 309).\n\nHow is the grid region for carbon intensity chosen for each model?  Is it purely based on the country of the model’s origin?  Even within a single country, there can be a massive difference in the carbon intensity of the grid(s) — the US is a good example of this (e.g., compare California with Missouri).\n\n3. https://huggingface.co/meta-llama/Meta-Llama-3-70B"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fQhMYvtLDR", "forum": "VafxuFOb3f", "replyto": "VafxuFOb3f", "signatures": ["ICLR.cc/2026/Conference/Submission3754/Reviewer_yezs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3754/Reviewer_yezs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761776030079, "cdate": 1761776030079, "tmdate": 1762916966561, "mdate": 1762916966561, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a first step to quantify carbon emissions of open-weight models available on the Huggingface platform, based on their FLOPS consumed to train a released model checkpoint.  The calculation per model includes a conventional and fairly standard set of factors:  hardware (GPU family used to train) × efficiency × computation × system amplification × infrastructure × environment (regional energy efficiency information).  What’s novel in this paper is (1) aiming to account for a wide collection of models (moving beyond case studies on a single model or family, as in previous related work), starting with those that disclose the most information and with the most downloads, and expanding out; separating out the FLOPS (computation) used to train a model from all other factors, which are rolled into “ATCI” and empirically validated.  The paper culminates in numerical estimates for three tiers of Huggingface-available models, based on the amount of information for CO2 estimation that was disclosed, with Tier 1 models being used to calibrate and validate their estimates, while Tier 3 has most variables inferred (with downloads above 5K, 1K, and 100).   They also find how different model training routines (base or instruct models) and modalities (CV, NLP, and multimodal) impact the general CO2 training emission."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written and motivated. As the authors say, “AI lacks a dedicated set of measurement practices, disclosure standards, and systematic methodologies for embodied carbon emissions.”  The paper is a first step toward a broadly (though not universally) applicable tool for estimating the footprint of AI.  It aims to help the field move from speculations and empty statements about environmental impact and actually measure it at scale. \n\nAuthors provide an empirical reference of the ATCI (AI training carbon intensity) metric, which allows for estimation of carbon emissions in past (and future?) training runs. The metric takes into account both hardware and regional energy characteristics and is the first to give us a general estimate of the impacts of model training on carbon emissions and contextualize it within other CO2-emitting human activities.\n\nThe authors seem to provide most of the necessary information/simplifications used to build the metric. Authors provide  explanations on how the data was collected, validated, and processed, as well as are committed to releasing it and their codebase so the community can build upon it."}, "weaknesses": {"value": "The use of LMs with agents to extract information from repositories to fill in the details for all the models is interesting but hardly discussed.  Will these tools also be made publicly available so the process can be improved?\n\nAlthough the comparison of CO2 emissions provided around line 87 helps, it would also be useful to have a ceiling for some of those comparisons, i.e., 2k model trainings were equivalent to around 7k cars annual emissions, but how many cars do we currently have in a country? And how long does it take to have 2097 new models on HuggingFace? Some of this information is in Figure 3 later in the text, but I feel I still don’t have a clear picture of how bad for the environment training is compared to other everyday activities and industries.\n\nThe estimation approach does not account at all for uncertainty propagation.  Each factor is simply estimated and they are multiplied together.  There’s not even an attempt to follow significant digit rules – e.g., Table 1a has 7 significant digits in the rightmost column.\n\nThe methodology for confirming that the estimates are valid is not detailed in the main paper.  I was unable to confirm that the approach was sound.  I’m actually unclear of whether I should view the differences within rows of Table 2 (estimation vs. disclosed) as error in the method or error in what’s disclosed or perhaps both.  The paper should be more clear about this.  On line 426, the authors mention that “estimation errors remain within an acceptable range” without actually determining what an acceptable range of error is and how different their estimates were from disclosed emissions in the text. The latter information can be inferred from Table 2, but it would be helpful to report aggregate values so we are more easily aware of how far off from the empirical values the estimate is. In addition, the authors make use of a lot of unified/aggregate values for the parameters in the metric, and it is not clear to me how much the errors would compound.\n\nThe stated assumption that the compute used to train a model comes from the same region as the author who uploaded the model seems very hard to support when estimating a regional electricity carbon intensity for each model.  Organizations that train models often use compute clusters in distant locales, driven by a concerns about price and environmental impact.\n\nThe models studied were trained at different times across five years.  Apart from specific hardware, there is no discussion of whether the factors needed to estimate ATCI are time-sensitive.  Perhaps cooling technology has become more efficient, for example.  It would be good to discuss this.\n\nAn undiscussed caveat with these estimates is that they consider (as far as I understand it) only the final model that is released.  But organizations that train models – especially those that do pretraining – carry out extensive experiments to choose hyperparameters, architecture details, data mixes, etc.  The final model is likely only a small fraction of the total compute used in the process.  I suspect that taking this into account would change the conclusion that “instruction models accumulate higher per-checkpoint emissions.”\n\nAnother concern I have that was addressed by the authors in the Limitations section is that models might emit much more carbon during their inference lifetime. Since the paper is concerned mostly with models with more than 5000 downloads, it is reasonable to expect that such models will have a high inference carbon emission. It would be interesting to have a rough estimate of how inference CO2 emissions would scale with usage, although I understand that measuring this is a challenging problem on its own.\n\nIt is acknowledged as a limitation that proprietary models are not included here.  From Table 2, where four non-HF models with disclosed emissions (not included in this paper’s estimates), we see that the footprint of training those models is likely orders of magnitude greater than what can be estimated through this paper’s methodology.  The models that can be accounted for, it seems, are contributing a tiny fraction to the real problem.\n\n\nTypos:\nSome citations are not in the correct format (lines 51, 106)\nExtra “.” on line 106"}, "questions": {"value": "On line 38, the authors say that concerns about the environmental impact of AI remain conceptual. Later, on line 53, the authors place their contributions as a “conceptual estimate of its overall impact”. The term “conceptual” seems to mean loaded as it means different things in these two sentences. Is the proposed methodology also conceptual? A question that came up is: how often would the empirical parameters used in the ATCI have to be revisited?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GcWR3m8SYw", "forum": "VafxuFOb3f", "replyto": "VafxuFOb3f", "signatures": ["ICLR.cc/2026/Conference/Submission3754/Reviewer_bz5z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3754/Reviewer_bz5z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932454577, "cdate": 1761932454577, "tmdate": 1762916966180, "mdate": 1762916966180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This is a FLOPs-based carbon emission estimation framework for LLM training by approximating the emissions of open source models on Huggingface. The key idea is to first approximate the total computational cost in FLOPs required to train a given model.\nThis quantity is then converted into energy consumption based on the efficiency characteristics of the hardware likely used for training and finally into carbon emissions by applying the carbon intensity of electricity in the relevant region. This conversion can be interpreted as assigning a training carbon intensity (ATCI), which means training emissions per FLOP, which reflects both hardware energy efficiency and regional energy mix.\n\nTraining emissions can be calculated by hardware × efficiency × computation × system amplification × infrastructure × environment. The authors adopt a three-tier framework to include models having less/more training information in documentation. the models having rich disclosure (gpu hrs, hardware types, flops), partial (flops), minimal info (parameters).\nResults show mainly that CV and multimodal exhibit higher training emission intensity than NLP.  Instruction-tuned models show higher median model-level emissions than pretrained models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper addresses an important and timely problem: quantifying AI’s environmental cost at scale.\n\nIntroduces the ATCI (AI Training Carbon Intensity) metric, a practical abstraction for emissions per FLOP.\n\nThe three-tier framework is systematic and allows estimation even when disclosure quality varies.\n\nProvides an industry-scale analysis of thousands of models, revealing useful cross-domain insights (e.g., CV vs NLP, base vs instruction-tuned)."}, "weaknesses": {"value": "1. Paper focuses only on the training related carbon emissions and omit the inference related emissions. But it is important to model the inference emissions. Can this framework be used for inference estimates? I acknowledge that the authors mentioned this in limitations and future work.\n2. Also while basing off these experiments only on HF models is good, we don't have an estimate of emissions of proprietary models. They have a three-tier framework in which only parameter count is considered in third tier, given that can we estimate emissions for propretary LMs?\n3. Mainly two results are derived. One of which is: Instruction-tuned models show higher median model-level emissions than base pretrained models. Can we draw comparison across different LLM families?\n4. How their approach is better/compare to [1] This paper also does flops based end-to-end carbon emission modeling.\n5. Can this framework be used to model fine-tuning carbon emissions? Because once the models are trained and released on HF, fine-tuning and inference is done most often, so these emissions should be accounted for as well.\n\n[1] Faiz, A., Kaneda, S., Wang, R., Osi, R., Sharma, P., Chen, F. and Jiang, L., 2023. Llmcarbon: Modeling the end-to-end carbon footprint of large language models. arXiv preprint arXiv:2309.14393."}, "questions": {"value": "1.\tWhat is the uncertainty or error margin of the reported totals (e.g., 33,446 t CO₂e)? Can they provide confidence intervals or upper/lower bounds?\n\t2.\tIn Tier 2 and 3, what representative hardware assumptions (GPU type, utilization, PUE) were used? How sensitive are results to those?\n\t3.\tHow were training regions determined for each model? If based on author affiliation, this may misrepresent actual data-center locations.\n\t4.\tFor Tier 3 regression (parameter-only), how accurate is the fit when tested on known cases?\n\t5.\tSince the work relies heavily on imputed data, can the authors release their dataset and code for transparency and reproducibility?\n\t6.\tThe related work section omits LLMCarbon (Faiz et al., 2023) and other recent carbon-accounting tools (CodeCarbon, CarbonTracker). How does this framework differ from or improve upon them?\n\t7.\tCan the ATCI metric be extended to inference or fine-tuning phases, and what would change in the estimation equation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "y7WwSsAF1g", "forum": "VafxuFOb3f", "replyto": "VafxuFOb3f", "signatures": ["ICLR.cc/2026/Conference/Submission3754/Reviewer_VGTc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3754/Reviewer_VGTc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949594325, "cdate": 1761949594325, "tmdate": 1762916965965, "mdate": 1762916965965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper develops a structured approach to estimate the training carbon emissions of open-source AI models on Hugging Face. To address the current lack of consistent accounting standards in AI, the authors design a FLOPs-based estimation framework that links model training compute to carbon output through hardware efficiency and regional electricity carbon intensity. They introduce the AI Training Carbon Intensity (ATCI) metric—measuring CO₂-equivalent emissions per FLOP—to provide a practical and comparable way to estimate emissions when complete training data are unavailable. To handle uneven metadata quality, the study applies a three-tier classification system (Tier 1: detailed; Tier 2: partial; Tier 3: minimal) and combines automated LLM-assisted metadata extraction with manual cross-checking for verification."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The introduction of the FLOPs-based estimation framework combined with the AI Training Carbon Intensity (ATCI) metric offers a practical, scalable approach to estimate emissions—even when disclosure is incomplete or absent.\n- In contrast to earlier research centered on a few individual models, this study examines open-source Hugging Face models at an industry-wide scale. The extensive coverage enables a comprehensive estimate of the cumulative training emissions within the open-source AI ecosystem, offering a broader and more representative view than case-specific analyses.\n- This paper presents comprehensive experimental results and systematically compares NLP, CV, and multimodal models. The analysis shows that vision workloads exhibit higher ATCI values, largely due to data-processing and pipeline overhead. It also differentiates between base pretraining and instruction tuning, revealing the often-overlooked cumulative carbon cost associated with repeated fine-tuning and alignment cycles.\n- The paper is well written, with clear organization and logical flow throughout. In particular, the results are effectively visualized—figures and tables are well designed, easy to interpret, and enhance the overall clarity and impact of the presentation."}, "weaknesses": {"value": "- The novelty of this paper is not enough. Even this papers mentation this is the first systematic accounting of training related carbon emissions for mainstream models hosted on Hugging Face. But the core methodology (FLOPs × carbon intensity) is not new—it has been previously proposed in works such as [1]-[5]. The novelty is primarily scale and aggregation, not conceptual framework.\n- As the paper notes, its analysis focuses solely on training-related emissions while excluding other important sources such as inference, research, and full lifecycle impacts. This limitation reduces the completeness of the overall environmental assessment. It would be valuable for future work to extend the framework to include inference and other downstream processes, providing a more holistic view of AI’s total carbon footprint.\n- It is a thoughtful approach that the paper classifies models into three tiers based on disclosure completeness. However, for Tier 2 and Tier 3 models, where key information is missing, the heavy reliance on estimation and regression methods—though practical—introduces considerable uncertainty into the results and may affect the precision of the overall emission estimates.\n- In the Training FLOPs Estimation section, the study relies on heuristic approximations for different model architectures. Since model structures and training configurations vary widely, this approach may lead to estimation biases. It would strengthen the work to validate these approximation formulas using available disclosed training logs or verified benchmarks where possible, thereby improving the accuracy and credibility of the computed FLOPs values.\n- The study provides limited ground-truth validation, relying on comparisons with only a small number of disclosed models (e.g., BLOOM, LLaMA) as shown in Table 2. While these examples demonstrate reasonable consistency, the validation set is too narrow to thoroughly evaluate the accuracy and robustness of the proposed estimation framework. Future work could expand the validation dataset by incorporating more models with partial disclosures, such as reported FLOPs or runtime statistics. Additionally, collaborating with model developers to access authentic training logs would provide stronger empirical grounding and improve the reliability of the framework’s estimates.\n\n## References\n**[1]** Strubell, Emma, Ananya Ganesh, and Andrew McCallum. \"Energy and policy considerations for modern deep learning research.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 09. 2020.\n\n**[2]** Patterson, David, et al. \"Carbon emissions and large neural network training.\" arXiv preprint arXiv:2104.10350 (2021).\n\n**[3]** Anthony, Lasse F. Wolff, Benjamin Kanding, and Raghavendra Selvan. \"Carbontracker: Tracking and predicting the carbon footprint of training deep learning models.\" arXiv preprint arXiv:2007.03051 (2020).\n\n**[4]** Lacoste, Alexandre, et al. \"Quantifying the carbon emissions of machine learning.\" arXiv preprint arXiv:1910.09700 (2019).\n\n**[5]** Luccioni, Alexandra Sasha, Sylvain Viguier, and Anne-Laure Ligozat. \"Estimating the carbon footprint of bloom, a 176b parameter language model.\" Journal of machine learning research 24.253 (2023): 1-15."}, "questions": {"value": "- Table 2 lists a few models that disclose their training emissions. Could the authors provide more detailed comparison data—such as the disclosed FLOPs, GPU-hours, or runtime statistics—for these models? Additionally, would it be possible to calculate and report the relative errors between the disclosed emissions and the framework’s predicted values to better assess the accuracy of the estimation method?\n- Could the authors provide a quantitative breakdown of the overall emissions uncertainty, distinguishing the respective contributions from FLOPs estimation, hardware efficiency assumptions, and regional grid carbon intensity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jOAY3HEYi0", "forum": "VafxuFOb3f", "replyto": "VafxuFOb3f", "signatures": ["ICLR.cc/2026/Conference/Submission3754/Reviewer_cMNg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3754/Reviewer_cMNg"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission3754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978423166, "cdate": 1761978423166, "tmdate": 1762916965738, "mdate": 1762916965738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper develops a structured approach to estimate the training carbon emissions of open-source AI models on Hugging Face. To address the current lack of consistent accounting standards in AI, the authors design a FLOPs-based estimation framework that links model training compute to carbon output through hardware efficiency and regional electricity carbon intensity. They introduce the AI Training Carbon Intensity (ATCI) metric—measuring CO₂-equivalent emissions per FLOP—to provide a practical and comparable way to estimate emissions when complete training data are unavailable. To handle uneven metadata quality, the study applies a three-tier classification system (Tier 1: detailed; Tier 2: partial; Tier 3: minimal) and combines automated LLM-assisted metadata extraction with manual cross-checking for verification."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The introduction of the FLOPs-based estimation framework combined with the AI Training Carbon Intensity (ATCI) metric offers a practical, scalable approach to estimate emissions—even when disclosure is incomplete or absent.\n- In contrast to earlier research centered on a few individual models, this study examines open-source Hugging Face models at an industry-wide scale. The extensive coverage enables a comprehensive estimate of the cumulative training emissions within the open-source AI ecosystem, offering a broader and more representative view than case-specific analyses.\n- This paper presents comprehensive experimental results and systematically compares NLP, CV, and multimodal models. The analysis shows that vision workloads exhibit higher ATCI values, largely due to data-processing and pipeline overhead. It also differentiates between base pretraining and instruction tuning, revealing the often-overlooked cumulative carbon cost associated with repeated fine-tuning and alignment cycles.\n- The paper is well written, with clear organization and logical flow throughout. In particular, the results are effectively visualized—figures and tables are well designed, easy to interpret, and enhance the overall clarity and impact of the presentation."}, "weaknesses": {"value": "- The novelty of this paper is not enough. Even this papers mentation this is the first systematic accounting of training related carbon emissions for mainstream models hosted on Hugging Face. But the core methodology (FLOPs × carbon intensity) is not new—it has been previously proposed in works such as [1]-[5]. The novelty is primarily scale and aggregation, not conceptual framework.\n- As the paper notes, its analysis focuses solely on training-related emissions while excluding other important sources such as inference, research, and full lifecycle impacts. This limitation reduces the completeness of the overall environmental assessment. It would be valuable for future work to extend the framework to include inference and other downstream processes, providing a more holistic view of AI’s total carbon footprint.\n- It is a thoughtful approach that the paper classifies models into three tiers based on disclosure completeness. However, for Tier 2 and Tier 3 models, where key information is missing, the heavy reliance on estimation and regression methods—though practical—introduces considerable uncertainty into the results and may affect the precision of the overall emission estimates.\n- In the Training FLOPs Estimation section, the study relies on heuristic approximations for different model architectures. Since model structures and training configurations vary widely, this approach may lead to estimation biases. It would strengthen the work to validate these approximation formulas using available disclosed training logs or verified benchmarks where possible, thereby improving the accuracy and credibility of the computed FLOPs values.\n- The study provides limited ground-truth validation, relying on comparisons with only a small number of disclosed models (e.g., BLOOM, LLaMA) as shown in Table 2. While these examples demonstrate reasonable consistency, the validation set is too narrow to thoroughly evaluate the accuracy and robustness of the proposed estimation framework. Future work could expand the validation dataset by incorporating more models with partial disclosures, such as reported FLOPs or runtime statistics. Additionally, collaborating with model developers to access authentic training logs would provide stronger empirical grounding and improve the reliability of the framework’s estimates.\n\n***Disclose the use of LLMs:*** *I used LLM for light writing assistance, including grammar refinement and phrasing suggestions. All substantive assessments, judgments, and technical evaluations in this review are my own. If the authors resolve the concerns and questions I raised, I would be willing to improve my score.*\n\n## References\n**[1]** Strubell, Emma, Ananya Ganesh, and Andrew McCallum. \"Energy and policy considerations for modern deep learning research.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 09. 2020.\n\n**[2]** Patterson, David, et al. \"Carbon emissions and large neural network training.\" arXiv preprint arXiv:2104.10350 (2021).\n\n**[3]** Anthony, Lasse F. Wolff, Benjamin Kanding, and Raghavendra Selvan. \"Carbontracker: Tracking and predicting the carbon footprint of training deep learning models.\" arXiv preprint arXiv:2007.03051 (2020).\n\n**[4]** Lacoste, Alexandre, et al. \"Quantifying the carbon emissions of machine learning.\" arXiv preprint arXiv:1910.09700 (2019).\n\n**[5]** Luccioni, Alexandra Sasha, Sylvain Viguier, and Anne-Laure Ligozat. \"Estimating the carbon footprint of bloom, a 176b parameter language model.\" Journal of machine learning research 24.253 (2023): 1-15."}, "questions": {"value": "- Table 2 lists a few models that disclose their training emissions. Could the authors provide more detailed comparison data—such as the disclosed FLOPs, GPU-hours, or runtime statistics—for these models? Additionally, would it be possible to calculate and report the relative errors between the disclosed emissions and the framework’s predicted values to better assess the accuracy of the estimation method?\n- Could the authors provide a quantitative breakdown of the overall emissions uncertainty, distinguishing the respective contributions from FLOPs estimation, hardware efficiency assumptions, and regional grid carbon intensity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jOAY3HEYi0", "forum": "VafxuFOb3f", "replyto": "VafxuFOb3f", "signatures": ["ICLR.cc/2026/Conference/Submission3754/Reviewer_cMNg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3754/Reviewer_cMNg"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission3754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978423166, "cdate": 1761978423166, "tmdate": 1763663906273, "mdate": 1763663906273, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}