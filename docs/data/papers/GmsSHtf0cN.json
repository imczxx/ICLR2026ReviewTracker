{"id": "GmsSHtf0cN", "number": 5347, "cdate": 1757903126606, "mdate": 1759897980373, "content": {"title": "RDDM: Practicing RAW Domain Diffusion Model for Real-world Image Restoration", "abstract": "We present the RAW domain diffusion model (RDDM), an end-to-end diffusion model that restores photo-realistic images directly from the sensor RAW data. While recent sRGB-domain diffusion methods achieve impressive results, they are caught in a dilemma between high fidelity and realistic generation. As these models process lossy sRGB inputs and neglect the accessibility of the sensor RAW images in many scenarios, e.g., in image and video capturing in edge devices, resulting in sub-optimal performance. RDDM obviates this limitation by directly restoring images in the RAW domain, replacing the conventional two-stage image signal processing (ISP)$\\rightarrow$Image Restoration (IR) pipeline. However, a simple adaptation of pre-trained diffusion models to the RAW domain confronts the out-of-distribution (OOD) issues. To this end, we propose: (1) a RAW-domain VAE (RVAE), encoding sensor RAW and decoding it into an enhanced linear domain image, (2) a configurable multi-bayer (CMB) LoRA module, adapting diverse RAW Bayer patterns such as RGGB, BGGR, etc. To compensate for the deficiency in the dataset, we develop a scalable data synthesis pipeline synthesizing RAW LQ-HQ pairs from existing sRGB datasets for large-scale training. Extensive experiments demonstrate RDDM's superiority over state-of-the-art sRGB diffusion methods, yielding higher fidelity results with fewer artifacts.", "tldr": "", "keywords": ["Low Level Vision", "Diffusion", "RAW Processing", "Image Restoration"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aa9ea50ac8696e61a6777bc193e5a97c91220150.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces RDDM, a diffusion model that restores images directly from sensor RAW data, avoiding the lossy ISP→sRGB process. It employs a RAW Variational Autoencoder (RVAE) for RAW–linear mapping, a Configurable Multi-Bayer LoRA for different sensor patterns, and a RAW data synthesis pipeline for training. With a dual-domain loss combining RAW and sRGB supervision, RDDM achieves higher fidelity and perceptual quality than state-of-the-art methods, establishing a new paradigm for RAW-domain image restoration."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is highly original in proposing the first RAW-domain diffusion model (RDDM) for real-world image restoration. Unlike prior works limited to the sRGB domain, it innovatively leverages unprocessed sensor RAW data, capturing richer signal information and eliminating dependence on handcrafted ISP pipelines. The integration of diffusion priors into the RAW domain represents a clear conceptual advance.\n2. The technical design is solid and well-justified. The introduction of the RAW Variational Autoencoder (RVAE), Configurable Multi-Bayer LoRA, and RAW data synthesis pipeline effectively addresses domain gap and data scarcity issues. Comprehensive experiments on multiple benchmarks confirm the method’s superiority in both fidelity and perceptual quality, supported by strong quantitative and visual evidence.\nSignificance: \n3. This work establishes a new paradigm for real-world image restoration by moving from the conventional sRGB domain to the sensor RAW domain. Its framework and data synthesis approach are broadly applicable to other low-level vision tasks and could significantly influence future research on RAW-domain generative modeling and camera imaging pipelines."}, "weaknesses": {"value": "1. While RDDM shows strong results on several benchmarks, the experiments mainly focus on synthetic or semi-synthetic datasets derived from sRGB sources. The paper would be stronger with more evaluation on diverse real RAW datasets captured by different sensors and under varied lighting conditions to verify cross-camera robustness.\n2. The proposed RAW data synthesis pipeline is creative but may not fully capture real-world sensor noise characteristics or color responses. The paper lacks quantitative analysis on how well the synthetic RAW data matches real RAW distributions, which could affect the model’s practical reliability.\n3. The ablation study, while detailed, could include comparisons with simpler RAW-based baselines (e.g., RAW-ISP pipelines using modern neural ISPs) to better quantify the advantage of diffusion-based modeling in the RAW domain."}, "questions": {"value": "1. Could the authors provide quantitative or visual comparisons between results trained on real RAW data (if available) and synthetic RAW data generated by their pipeline? This would help assess how well the synthetic data distribution aligns with real-world sensor characteristics.\n2. How does RDDM perform when applied to RAW data from cameras with unseen Bayer patterns or sensor characteristics (e.g., mobile vs. DSLR sensors)? Have the authors tested the adaptability of the CMB-LoRA module in truly cross-device scenarios?\n3. The dual-domain loss design is interesting. Could the authors clarify the relative contributions of RAW-domain and sRGB-domain supervision? For instance, what happens when each component’s weight (( \\lambda_1, \\lambda_2 )) is varied, or when the loss is applied asymmetrically?\n4. Failure Cases and Visual Artifacts:\nCould the authors show examples where RDDM fails or produces artifacts, and analyze the causes (e.g., misdemosaicing, over-smoothing, or hallucinated textures)? This would give a clearer picture of its limitations and possible improvement directions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uJzQz33Uzf", "forum": "GmsSHtf0cN", "replyto": "GmsSHtf0cN", "signatures": ["ICLR.cc/2026/Conference/Submission5347/Reviewer_NuQu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5347/Reviewer_NuQu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894342968, "cdate": 1761894342968, "tmdate": 1762918017454, "mdate": 1762918017454, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes RDDM, a diffusion model that performs image restoration in the RAW domain rather than sRGB space. Directly adapting diffusion models to the RAW space presents out-of-distribution (OOD) issues. To overcome this issue, the authors propose a RAW domain VAE and a scalable data synthesis pipeline to create RAW images from existing sRGB data. The method achieves better perceptual quality and higher fidelity than state-of-the-art methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed idea of using latent diffusion models for RAW domain restoration is interesting.\n2. The qualitative results have more detail and higher fidelity than existing methods."}, "weaknesses": {"value": "1. Hard to understand: The flow and explanation of the methodology section is very difficult to follow (see questions).\n2. Unclear motivation: From my understanding, the paper proposes a method that restores a LQ RAW image ($X_L^\\text{RAW}$) to its HQ counterpart in RGB space ($X_H^\\text{rgb}$). Existing methods directly perform restoration on the LQ image in RGB space. The methodology in the paper depends on converting the LQ image from RGB space to the RAW space and then performing restoration (both in training and inference). However, isn’t this inverse mapping not perfect as RAW to RGB mapping is lossy? Then, the performance of the entire method depends on how well this inverse mapping is learnt right? There are no experiments validating the effectiveness of the inverse mapping, which makes it unclear as to why the proposed methodology is working.\n3. No experiments validating the effectiveness of the data synthesis pipeline."}, "questions": {"value": "1. What is the difference between linear domain and RAW domain? There is no mention of this in Sec. 3.1.\n2. How are $\\mathcal{F}_\\text{DD}$ and $\\mathcal{F}_\\text{PTP}$ trained? Sec. 3.1 assumes the presence of data pairs $(X_L^\\text{RAW}, X_H^\\text{lin}$, but there is no such available data right (only HQ RAW and RGB images are available?)?\n3. What is the dataset used to train the VAE?\n4. Most degradations in LQ RGB images are caused by compression, blur, noise, etc. These degradations are prevalent in RGB post-processing techniques (for instance JPEG compression) and would be absent in RAW sensor data. So, is it fair to consider the RAW input image as an equivalent LQ in RGB space, which existing SOTA approaches work on?\n5. How are $\\mathcal{F}^{-1}_\\text{DD}$ and $\\mathcal{F}^{-1}_\\text{PTP}$ trained?\n6. Can the authors provide examples of synthesized data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1gf0pjjbKg", "forum": "GmsSHtf0cN", "replyto": "GmsSHtf0cN", "signatures": ["ICLR.cc/2026/Conference/Submission5347/Reviewer_BPDr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5347/Reviewer_BPDr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940482812, "cdate": 1761940482812, "tmdate": 1762918017168, "mdate": 1762918017168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the RAW Domain Diffusion Model (RDDM), a novel approach for image restoration that operates directly on sensor RAW data, bypassing the conventional two-stage ISP-then-restoration pipeline.  The technical solutions (RVAE, CMB-LoRA) appear to directly address the core challenges of OOD and pattern diversity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Sufficient presentation of objective metrics and subjective visualization results in the experiments:\n2. Clear description of the methodology and contributions:"}, "weaknesses": {"value": "1. As shown in Table 1, many results in the comparison with SOTA methods are suboptimal. Does this imply that the current solution still has limitations, and that more relevant analysis and experiments should be provided?\n2. It is important to note that a VAE's optimal reconstruction results are not indicative of superior generation capability, given the frequent trade-off between these two objectives. Therefore, in addition to the reconstruction performance presented in Table 3, an evaluation of the generation performance is necessary to conclusively determine a better VAE structure.\n3. As shown in Figure 4, different input modes require LoRAs with different parameters, which reduces overall practicality. Could a unified LoRA be considered to achieve this functionality without switching?"}, "questions": {"value": "1. Some information across the tables appears inconsistent, such as the method names in Figure 1 and the configuration codes in Figure 9. More complete information should be provided in the captions to facilitate reading.\n2. Several minor errors in the text need correction to improve readability, such as the garbled characters appearing in line 466."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ON1YegjHkG", "forum": "GmsSHtf0cN", "replyto": "GmsSHtf0cN", "signatures": ["ICLR.cc/2026/Conference/Submission5347/Reviewer_VdBX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5347/Reviewer_VdBX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968183598, "cdate": 1761968183598, "tmdate": 1762918016956, "mdate": 1762918016956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper “RDDM: Practicing RAW Domain Diffusion Model for Real-World Image Restoration” presents an end-to-end diffusion framework that directly restores high-quality RGB images from sensor RAW data, bypassing traditional ISP (image signal processing) pipelines. The method introduces several components: a RAW-domain VAE (RVAE) for encoding mosaicked signals, a configurable multi-Bayer (CMB) LoRA for different sensor patterns, a dual-domain (RAW + sRGB) loss, and a RAW data synthesis pipeline for training data creation. Experiments on multiple benchmarks (DIV2K, RealSR, DRealSR, DND) demonstrate competitive results, suggesting advantages in both fidelity and perceptual quality compared to sRGB-domain diffusion and ISP-based two-stage baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "+ The combination of RAW-domain VAE, LoRA-based Bayer adaptation, and dual-domain supervision reflects careful engineering to handle distribution gaps and data diversity in sensor formats.\n+ The authors provide a broad set of quantitative, qualitative, and user studies, covering both synthetic and in-the-wild datasets, and analyze component effectiveness through ablations on losses, VAE variants, and prompt extractors."}, "weaknesses": {"value": "- Overly complicated and fragmented pipeline. The proposed system consists of multiple coupled modules. The overall architecture is highly procedural and difficult to apply or reason about conceptually. Much of the technical novelty lies in stitching existing components together rather than introducing a coherent or elegant new formulation.\n\n- Limited conceptual novelty. The work mainly transfers existing ideas (latent diffusion, LoRA, ISP simulation, prompt-based conditioning) into the RAW domain. While this is a meaningful application, it is not a fundamental algorithmic advance in diffusion modeling or image restoration. The contributions are more empirical and system-engineering in nature than theoretical or methodological.\n\n- Ambiguity in causal effectiveness and dependence on pretrained modules. It remains unclear how much of the reported improvement stems from genuine RAW-domain learning versus strong pretrained priors. Moreover, the dual-domain supervision appears heuristic and lacks deeper justification.\n\n- There are too many typos in the paper, which significantly lowers the presentation and clarity of this work. For example, Line-093:  “enahnced linear domain image” → enhanced linear domain image; Line-268: \"to obtain degraed RAW images” → degraded RAW images; Line-466: \"as shown in Table ??.\"; Line-473: “Fig. 11 demonstrate the visual performance.” → “Fig. 11 demonstrates the visual performance.”, Line-484: “Although generating more realistic details, Its fidelity …” → “Although generating more realistic details, its fidelity …”, etc."}, "questions": {"value": "How robust is RDDM to variations in real sensor calibration, non-Bayer mosaics, or camera-specific noise models that differ from the synthesized RAW data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1TiL8tsOHO", "forum": "GmsSHtf0cN", "replyto": "GmsSHtf0cN", "signatures": ["ICLR.cc/2026/Conference/Submission5347/Reviewer_z4Nw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5347/Reviewer_z4Nw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5347/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979378909, "cdate": 1761979378909, "tmdate": 1762918016736, "mdate": 1762918016736, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}