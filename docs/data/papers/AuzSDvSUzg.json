{"id": "AuzSDvSUzg", "number": 16637, "cdate": 1758267082032, "mdate": 1762940595943, "content": {"title": "Human Aligned Compression for Robust Models", "abstract": "Adversarial attacks on image models threaten system robustness by introducing imperceptible perturbations that cause incorrect predictions. \n    We investigate human-aligned learned lossy compression as a defense mechanism, comparing two learned models (HiFiC and ELIC) against traditional JPEG across various quality levels. \n    Our experiments on ImageNet subsets demonstrate that learned compression methods outperform JPEG, particularly for Vision Transformer architectures, by preserving semantically meaningful content while removing adversarial noise. \n    Even in white-box settings where attackers can access the defense, these methods maintain substantial effectiveness. \n    We also show that sequential compression—applying rounds of compression/decompression—significantly enhances defense efficacy while maintaining classification performance. \n    Our findings reveal that human-aligned compression provides an effective, computationally efficient defense that protects the image features most relevant to human and machine understanding.", "tldr": "", "keywords": ["Compression", "adversarial purification", "realism in compression", "adversarial defense", "adversarial attacks"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/2d0ed1eada36896ca4d7d2d78f50a1aeb0eeab7f.pdf", "supplementary_material": "/attachment/f70e9719451da74d18732e6d2bd21ca972e55e00.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates the feasibility of using learnable lossy compression models as a defense mechanism against adversarial examples. The experiments demonstrate that HiFiC and ELIC algorithms offer significant advantages over JPEG, showing that even under low BPP (bits per pixel) conditions, they do not drastically degrade the baseline classification accuracy of image models. The paper also highlights the limitations of such defense mechanisms in white-box settings. Furthermore, it is pointed out that multi-round compression techniques can significantly enhance defense effectiveness, with JPEG demonstrating the best balance between robustness and image quality across multiple iterations."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The experiments are relatively systematic, involving a comparison of the representative learnable compression methods HiFiC and ELIC with the traditional JPEG method. These experiments confirm that the former provides better defense efficacy, offering insights for researchers aiming to improve adversarial robustness through data preprocessing techniques.\n2. The discovery of the \"multi-round compression\" approach, though simple, provides valuable ideas for lightweight defense strategies."}, "weaknesses": {"value": "1. The paper lacks substantial innovation. A similar systematic study was conducted by Dziugaite et al.[1], which already explored this area in depth. This paper merely replaces JPEG with HiFiC/ELIC without offering any significant new contributions. Additionally, there is a lack of theoretical analysis explaining why \"human perception-aligned compression\" improves model robustness.\n2. The scope of the models and datasets used is too narrow. The study only considers two models—ResNet50 and ViT—and primarily utilizes the ImageNet dataset. Other classic models, such as VGG, Inception, and AlexNet, are missing from the analysis.\n3. While the paper compares the performance of traditional JPEG and learnable compression methods (HiFiC and ELIC) in defense tasks, as well as the effects of multi-round compression strategies, it lacks a mechanistic explanation. The approach seems more empirical and lacks a convincing theoretical foundation to support its findings.\n\n[1]Dziugaite G K, Ghahramani Z, Roy D M. A study of the effect of jpg compression on adversarial images[J]. arXiv preprint arXiv:1608.00853, 2016."}, "questions": {"value": "1. How is \"human perception alignment\" specifically defined and measured in the context of this study?\n2. I believe the choice of models in the experimental section may be insufficient. Could you explain why only ResNet50 and ViT were selected?\n3. What is the underlying mechanism behind the improvement brought by multi-round compression? Can it be explained from an information entropy perspective?\n4. In comparing traditional methods with the current learnable compression techniques, are there more innovative methods to address the limitations observed in both?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "foBgDN8Ecm", "forum": "AuzSDvSUzg", "replyto": "AuzSDvSUzg", "signatures": ["ICLR.cc/2026/Conference/Submission16637/Reviewer_W3pH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16637/Reviewer_W3pH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16637/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794902195, "cdate": 1761794902195, "tmdate": 1762926702920, "mdate": 1762926702920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "ozTLftf1eG", "forum": "AuzSDvSUzg", "replyto": "AuzSDvSUzg", "signatures": ["ICLR.cc/2026/Conference/Submission16637/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16637/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762937415195, "cdate": 1762937415195, "tmdate": 1762937415195, "mdate": 1762937415195, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates human-aligned learned lossy compression as a defense against adversarial attacks for image models. The authors experimentally demonstrate that learned compressions outperform traditional JPEG and can remain effective even in a challenging white-box setting. Moreover, sequentially applying multiple rounds of compression can further enhance the efficacy of the defense."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors explored learned image compression models for both single-pass and sequential defense, and conducted a thorough investigation on the relationship between defense efficacy and the number of iterations through the compression module."}, "weaknesses": {"value": "- One major concern is the effectiveness against adaptive attacks. The experiments only considered a simple “white-box” attack where the gradients are backpropagated through the image compression module. This approach may lead to an overestimation of defense efficacy due to potential gradient obfuscation rather than true robustness [1]. The paper would benefit significantly from considering stronger adaptive attacks, which are the recognized standard for evaluating adversarial defenses within the community [2,3].\n\n- The authors claim that the learned image compression defense maintains \"substantial effectiveness\" even when the adversary has access to the defense. However, this claim appears to conflict with experimental results in later sections, where both ELIC and HiFiC failed to resist iFGSM attacks for ResNet50 and ViT in the white-box setting. Furthermore, the effectiveness of sequentially composed defenses is difficult to ascertain without proper evaluation against adaptive attacks.\n\n- The paper mainly discusses early defense mechanisms such as defensive distillation and JPEG compression (both from 2016). A comprehensive comparison with more recent and advanced defenses (e.g., adversarial purification [4,5]) is absent, limiting the paper's contribution to the current state of research.\n\n- Existing research [6,7] indicates that neural image compression models themselves can be vulnerable to adversarial attacks. Introducing these models as a pre-processing defense module may thus create new attack surfaces, which the current paper does not address.\n\n\n[1] Athalye, Anish, Nicholas Carlini, and David Wagner. \"Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples.\" International conference on machine learning. PMLR, 2018.\n[2] Tramer, Florian, et al. \"On adaptive attacks to adversarial example defenses.\" Advances in neural information processing systems 33 (2020): 1633-1645.\n[3] Croce, Francesco, and Matthias Hein. \"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.\" International conference on machine learning. PMLR, 2020.\n[4] Yoon, Jongmin, Sung Ju Hwang, and Juho Lee. \"Adversarial purification with score-based generative models.\" International Conference on Machine Learning. PMLR, 2021.\n[5] Nie, Weili, et al. \"Diffusion Models for Adversarial Purification.\" International Conference on Machine Learning. PMLR, 2022.\n[6] Sui, Yang, et al. \"Reconstruction distortion of learned image compression with imperceptible perturbations.\" arXiv preprint arXiv:2306.01125 (2023).\n[7] Wu, Chenhao, et al. \"On the Adversarial Robustness of Learning-based Image Compression Against Rate-Distortion Attacks.\" arXiv preprint arXiv:2405.07717 (2024)."}, "questions": {"value": "Please refer to the weaknesses listed above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tBmpuWCjcq", "forum": "AuzSDvSUzg", "replyto": "AuzSDvSUzg", "signatures": ["ICLR.cc/2026/Conference/Submission16637/Reviewer_hfuX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16637/Reviewer_hfuX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16637/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795911082, "cdate": 1761795911082, "tmdate": 1762926702463, "mdate": 1762926702463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the feasibility of using learnable lossy compression models as a defense mechanism against adversarial examples. The experiments demonstrate that HiFiC and ELIC algorithms offer significant advantages over JPEG, showing that even under low BPP (bits per pixel) conditions, they do not drastically degrade the baseline classification accuracy of image models. The paper also highlights the limitations of such defense mechanisms in white-box settings. Furthermore, it is pointed out that multi-round compression techniques can significantly enhance defense effectiveness, with JPEG demonstrating the best balance between robustness and image quality across multiple iterations."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The experiments are relatively systematic, involving a comparison of the representative learnable compression methods HiFiC and ELIC with the traditional JPEG method. These experiments confirm that the former provides better defense efficacy, offering insights for researchers aiming to improve adversarial robustness through data preprocessing techniques.\n2. The discovery of the \"multi-round compression\" approach, though simple, provides valuable ideas for lightweight defense strategies."}, "weaknesses": {"value": "1. The paper lacks substantial innovation. A similar systematic study was conducted by Dziugaite et al.[1], which already explored this area in depth. This paper merely replaces JPEG with HiFiC/ELIC without offering any significant new contributions. Additionally, there is a lack of theoretical analysis explaining why \"human perception-aligned compression\" improves model robustness.\n2. The scope of the models and datasets used is too narrow. The study only considers two models—ResNet50 and ViT—and primarily utilizes the ImageNet dataset. Other classic models, such as VGG, Inception, and AlexNet, are missing from the analysis.\n3. While the paper compares the performance of traditional JPEG and learnable compression methods (HiFiC and ELIC) in defense tasks, as well as the effects of multi-round compression strategies, it lacks a mechanistic explanation. The approach seems more empirical and lacks a convincing theoretical foundation to support its findings.\n[1]Dziugaite G K, Ghahramani Z, Roy D M. A study of the effect of jpg compression on adversarial images[J]. arXiv preprint arXiv:1608.00853, 2016."}, "questions": {"value": "1. How is \"human perception alignment\" specifically defined and measured in the context of this study?\n2. I believe the choice of models in the experimental section may be insufficient. Could you explain why only ResNet50 and ViT were selected?\n3. What is the underlying mechanism behind the improvement brought by multi-round compression? Can it be explained from an information entropy perspective?\n4. In comparing traditional methods with the current learnable compression techniques, are there more innovative methods to address the limitations observed in both?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zlaasankug", "forum": "AuzSDvSUzg", "replyto": "AuzSDvSUzg", "signatures": ["ICLR.cc/2026/Conference/Submission16637/Reviewer_VPbr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16637/Reviewer_VPbr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16637/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882072549, "cdate": 1761882072549, "tmdate": 1762926701886, "mdate": 1762926701886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscinvestigate humanaligned learned lossy compression as a defense mechanism, comparing two learned\nmodels (HiFiC and ELIC) against traditional JPEG across various quality levels."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This manuscript systematically compares the impact of different types of image compression codecs on the robustness of image classification models, providing some ideas for experimental settings in this direction of research."}, "weaknesses": {"value": "The technological innovation of the current version is limited:\n1) The main contribution of the entire manuscript is the exploratory experiments conducted on image classification tasks using different image compression codecs. There are some new discoveries in the article, but no new solutions are proposed.\n2) The title of the manuscript covers a wide range, but the range of evaluation tasks of the experimental setting is limited. The current version is only for image classification tasks and lacks testing for other more complex tasks.\n3) The idea of this manuscript is interesting, but it gives the reviewer the impression that it has not been completed yet. The current version is more like a stage baseline testing report rather than a complete academic research paper."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xw0duOEUZ1", "forum": "AuzSDvSUzg", "replyto": "AuzSDvSUzg", "signatures": ["ICLR.cc/2026/Conference/Submission16637/Reviewer_G1bP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16637/Reviewer_G1bP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16637/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989331845, "cdate": 1761989331845, "tmdate": 1762926701431, "mdate": 1762926701431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}