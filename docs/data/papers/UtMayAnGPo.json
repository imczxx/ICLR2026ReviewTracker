{"id": "UtMayAnGPo", "number": 19995, "cdate": 1758301281363, "mdate": 1759897007579, "content": {"title": "CAReDiO: Enhancing Cultural Alignment of LLM via Representativeness and Distinctiveness Guided Data Optimization", "abstract": "As Large Language Models (LLMs) more deeply integrate into human life across various regions, aligning them with pluralistic cultures is crucial for improving user engagement and mitigating cultural conflicts. For this purpose, recently, different culture-specific corpora have been carefully curated, either synthesized or manually annotated. Nevertheless, inspired by culture theories, we identify two key challenges faced by these datasets: (1) Representativeness: These corpora fail to fully capture the target culture's core characteristics, causing insufficient cultural coverage with redundancy; (2) Distinctiveness: They struggle to distinguish the unique nuances of a given culture from shared patterns across other relevant ones, hindering precise cultural modelling. To handle these challenges, we introduce CAReDiO, a novel data optimization framework, which alternatively refines culture-sensitive questions and responses according to information-theoretic objectives in an in-context optimization manner, enhancing the cultural informativeness and distinguishability of constructed data. Extensive experiments on 15 distinct cultures demonstrate that CAReDiO can create high-quality data with richer cultural information and enable efficient alignment of small open-source or large proprietary LLMs with as few as 200 training samples, consistently outperforming previous datasets in both multi-choice and open-ended cultural benchmarks.", "tldr": "", "keywords": ["large language model", "cultural alignment", "data optimization"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9020c8022ad4e9ae81a118bdd3070965d6c01285.pdf", "supplementary_material": "/attachment/884d5d7f503d37f4f8bf9f569049314387bbea5e.zip"}, "replies": [{"content": {"summary": {"value": "The authors present a method for generating a dataset for cultural alignment. The algorithm proceeds as follows: \n1. start with an initial set of seed prompts; \n2. generate model responses for those prompts;\n3. score the prompt-response pairs based on a combination of A. how relevant they are to a given culture (via an LLM judge) and B. how distinct the response is to responses associated with other cultures (measured by embedding similarity);\n4. use an LLM to refine each question given the response.\n\nThe paper creates a dataset using this method. The paper also offers the theoretical insights supporting the relevance and distinctiveness ideas core to the prompting-based approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles an important problem and offers a helpful conceptual framework to think about what is desirable in a dataset for cultural alignment. \n2. The paper formalizes these concepts mathematically, to add theoretical weight to the intuition.\n3. The figures are well-done, and the results include human evaluation."}, "weaknesses": {"value": "1. Theory-aside, the paper offers a prompting-based method for generating a dataset. In that regard, it is not quite clear to me what this method does that’s more than / justifies better performance than other methods. Making this distinction in the practical implementation clear would be helpful. \n2. If I understand correctly, there seem to be slight discrepancies between the mathematical objectives, algorithm box, and actual implementation based on prompting in the appendix. Making these more explicit would help with reader understanding. For instance, lines 247-254 seem to suggest inner loop optimization of the responses whereas the algorithm simply generates a response without additional optimization. And the notation for lines 4 and 5 in the algorithm box were a bit confusing as well as I could not find their precise definitions (e.g., with vs. without the subscript). \n3. While the authors have various results to measure \"cultural alignment,\" some more clarity on the precise experimental setups (and how they differ) would help. For instance, what is the difference between Figure 4b and Table 3, e.g. GPT-4.1 on CB-Hard?"}, "questions": {"value": "1. Focusing on the prompting method itself, what makes the proposed method better than some of the others that generated previous datasets? For instance, how do we know that the performance gap is actually attributable to the central ideas on representativeness + distinctiveness in a generalizable way and not just better models, longer prompts, more iterations, etc.?\n2. I noticed the results in main would using CardSet whereas the appendix used CaReDiO. Is there some significant difference in the experimental setup? I had originally thought that the comparison was of fixed datasets.\n3. What were the seed questions?\n4. Could the authors add more context around each of the different results / figures? Namely, how each is set up and measured?\n5. Could authors clean up theorem 1 and the proof? It seems pretty informal as it currently stands.\n\nIf the authors could address these questions and concerns, I would be willing to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t6Uf8f7JDf", "forum": "UtMayAnGPo", "replyto": "UtMayAnGPo", "signatures": ["ICLR.cc/2026/Conference/Submission19995/Reviewer_ai47"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19995/Reviewer_ai47"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19995/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883882524, "cdate": 1761883882524, "tmdate": 1762932899090, "mdate": 1762932899090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of cultural bias in LLMs and argue that existing cultural alignment datasets are insufficient because they fail on two key dimensions, which they ground in established culture theories: (1) Representativeness, or the failure to capture the consensus characteristics of a culture (the \"emic\" view) , and (2) Distinctiveness, or the failure to capture the unique nuances that differentiate a culture from other, similar ones (the \"etic\" view). To solve this, the paper proposes CAREDIO, a data optimization framework. CAREDIO is an in-context, LLM-driven process for generating and refining high-quality, culture-specific training data. It formalizes the two dimensions as information-theoretic objectives. The authors then use the approach to generate a new dataset, covering 15 cultures. Their experiments show that fine-tuning both small and large LLMs on as few as 200 samples from the dataset outperforms models trained on existing, often larger, cultural datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is grounded in clear mathematical formalisations, derived directly from information-theoretic quantities and supported with detailed proofs. The formulations for mutual information-driven sample selection and Jensen-Shannon-based culture divergence are actionable.\n2. The quantitative dataset analysis is thorough. Table 2 compares diversity, information content, and similarity metrics across datasets, supporting the claim that proposed dataset is both more informative and more diverse. \n3. Human evaluation demonstrates the practical significance and that the approach moves beyond benchmark overfitting.\n4. The proposed approach needs fewer than 200 training samples for strong performance. Figure 5 shows early high-value data boosts alignment more per sample, which highlights the method's efficiency claims."}, "weaknesses": {"value": "1. The paper's core premise lies in the two dimensions, but the introduction does not clearly articulate them. Figure 1 is also unclear, leaving the reader with a poor intuition for what \"representativeness\" means independently of distinctiveness.\n2. In Section 3.2, the “distinctiveness” objective (Eq. 4) relies on φ(y, x) as a probability that responses are not from other cultures, implemented via a “clustering-based distance measurement”. This is left quite vague: how is this classifier trained, what architectures/embeddings are used, and how sensitive are results to this choice? This is described only briefly.\n3. Results demonstrate that the proposed approach is better, but no analysis shows how much each dimension (representativeness / distinctiveness) contributes to final model performance. \n4. Theoretically, the distinctiveness objective is vital for closely related cultures (e.g., Japan/Korea/China). However, Table 5–9 largely report aggregate or per-country results, with only sparse discussion of confusion between “neighbour” cultures. It would be informative to see confusion matrices or analysis on these closely related pairs, does CAREDIO really outperform baselines in making fine distinctions?"}, "questions": {"value": "1. See Weaknesses for some questions. \n2. Can you report results (or discuss limitations) for adapting the proposed approach to “zero-shot” or unseen cultures? What changes are needed to ensure transferability and avoid overfitting to the 15 present cultures?\n3. How do you control for or report on annotator disagreement in human evaluations? Do any particular cultures or question types show especially high variance, and does that impact major conclusions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TuYMFVbWYE", "forum": "UtMayAnGPo", "replyto": "UtMayAnGPo", "signatures": ["ICLR.cc/2026/Conference/Submission19995/Reviewer_HCb7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19995/Reviewer_HCb7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19995/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941610791, "cdate": 1761941610791, "tmdate": 1762932898610, "mdate": 1762932898610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CAReDiO, an in-context data optimization framework for cultural alignment. It alternates between generating and refining culture-sensitive questions and answers with two information-theoretic objectives: an information-gain objective (representativeness) and a culture-divergence objective (distinctiveness). Using CAReDiO, the authors build CARDSet for 15 cultures and report that small-scale fine-tuning can improve cultural benchmarks across multiple backbones. The framework itself comprises 1) information gain to reduce a model’s cultural uncertainty, 2) divergence to separate target from non-target cultures, and 3) an iterative refinement loop on data questions and responses. The paper evaluates on GlobalOpinionQA and WVS-style setups among others, and compares across a range of cultural benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The authors present a clear problem framing with two concrete challenges. The paper explicitly separates data quality into representativeness and distinctiveness and ties each to a learning objective, which is conceptually helpful.\n\nS2. The defined objectives are grounded well with theory. Representativeness is operationalized as mutual information and distinctiveness is linked to maximizing a lower bound on generalized Jensen-Shannon divergence across cultures under classifier accuracy and non-overconfidence assumptions. The use of JS echoes prior robustness work employing multi-distribution JS for consistency. \n\nS3. CAREDIO is itself a practical, model-agnostic pipeline. The alternating refinement loop is simple to implement with existing LLMs and can leverage either the target backbone or a larger assistant model to synthesize data. \n\nS4. The new method is evaluated well across a breadth of baselines and benchmarks. The paper situates results against multiple cultural datasets (CB/Prism/GOQA/WVS) covering a range of tasks (multiple choice/survey/open-ended) and methods (CultureX, Role-Play).\n\nS5. There are some risks of circularity due to the use of LLMs as judges. Both objectives estimate culture labels or divergences using LLM-based classifiers, which can encode the same cultural priors the method hopes to correct. Without strong human-grounded calibration, the approach risks amplifying pre-existing biases in the assisting model. The authors mostly mitigate this risk through the use of existing well-developed human preference datasets like PRISM and global value surveys like WVS and the further human evaluations on the final outputs of the CARDSet dataset and the final alignment step showing strong validation of the methods."}, "weaknesses": {"value": "W1. Distinctiveness theory depends on strong, partly unverifiable conditions. Proposition 2 connects the learning objective to a lower bound on GJS only if a culture-membership classifier is sufficiently accurate and not over-confident. The paper does not clearly demonstrate these premises hold across cultures or provide diagnostics of the error bounds in practice.\n\nW2. The benchmark construction offers some leakage concerns. Several compared datasets are built or augmented from WVS or related sources, and the evaluation also uses WVS/GlobalOpinionQA. This creates potential data leakage or style overlap that can inflate gains; the paper mentions the datasets but does not rigorously audit overlap or de-duplication. Durmus et al (2024) show how easy it is for LLMs to overfit survey-style probing.\n\nW3. Another weakness of this work is that the technical novelty relative to prior synthetic pipelines is incremental. CulturePark also uses multi-agent LLMs to generate cross-cultural dialogues, CultureLLM uses WVS to seed augmentation, and PRISM and CulturalBench collect diverse human feedback to ground value statements. CAReDiO’s main novelty is the particular objective pairing, which is interesting but not obviously transformative without stronger ablations."}, "questions": {"value": "Q1. Could the authors provide more details on how the role-playing baseline is developed. In section 3 a number of different types of role-playing are described but it is not clear how they are developed or what the final approach is.\n\nQ2. Did the authors consider ablations on the independent optimization objectives of representativeness and distinctiveness?\n\nQ3. The paper mentions that the english-dominant nature of training corpuses can bias a model towards western cultures. Was any investigation done into the impact of language improving cultural alignment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0ILUUZVtYP", "forum": "UtMayAnGPo", "replyto": "UtMayAnGPo", "signatures": ["ICLR.cc/2026/Conference/Submission19995/Reviewer_g389"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19995/Reviewer_g389"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19995/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148534433, "cdate": 1762148534433, "tmdate": 1762932898068, "mdate": 1762932898068, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for dataset construction for cultural alignment, where it aims to optimize for two objectives (representativeness and distinctiveness). The framework entails generating cultural QA pairs, scored for whether the QA pair is representative of that culture through consensus of multiple LLMs and whether it is distinct from other cultural QA pairs by measuring JS divergence between the answer distributions. The authors theoretically ground their objective in cultural theories and create a dataset for 15 cultures, showing that fine-tuning on data generated using the proposed framework leads to better performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Both objectives seem sound, are well motivated, and grounded in theory\n- The proposed approach shows moderate improvements compared to the baselines\n- The writing is clear\n- In depth details and fine-grained results are provided in the Appendix"}, "weaknesses": {"value": "- For the representativeness optimization objective, a fundamental assumption behind the consensus elicitation approach is that multiple LLMs with the right conditioning can simulate a group of individuals from a target culture c. This isn’t obvious to me and would be something that needs empirical experiments to prove its efficacy, persona based prompting for survey simulation is still a research field. Thus, repeatedly using the Cultural Consensus theory for grounding seems a bit of a stretch. \n- The weaknesses or limitations of the paper are not discussed in sufficient detail. For instance, since all parts of the pipeline depend on LLMs already knowing or inferring something about the culture, a fundamental limitation would be the approach not working for cultures not well represented in current LLMs. This is a core limitation that should be discussed in the paper. \n- Presentation could be improved\n  - A lot of the space in the paper is given to outlining the framework and grounding it in theory. I appreciate the effort the authors put into grounding the approach but this results in framework becoming concrete much later in the paper, which is worse for readability. \n  - Several important details necessary for understanding the paper in depth are in the Appendix.\n  - Figure 2 is not visually representative of the framework, the reader isn’t walked through the Figure in text. Clear examples or a better figure would aid the reader in clearly understanding the iterative data generation and optimization process."}, "questions": {"value": "- Minor:\n  - WVS is cited with multiple references in different parts of the paper (Xu et al., AlKhamessi et al., Tao et al.), none of which correspond to the actual reference: Haerpfer et al. (2022).\n- Suggestion:\n  - Could shorten the framework introduction and current motivation, propositions which are quite verbose, make the framework concrete earlier in the paper with the dataset, add a discussion section at the end."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M6xAtPRDzk", "forum": "UtMayAnGPo", "replyto": "UtMayAnGPo", "signatures": ["ICLR.cc/2026/Conference/Submission19995/Reviewer_UgnK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19995/Reviewer_UgnK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19995/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762251705374, "cdate": 1762251705374, "tmdate": 1762932897468, "mdate": 1762932897468, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}