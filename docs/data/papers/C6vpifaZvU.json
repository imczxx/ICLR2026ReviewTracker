{"id": "C6vpifaZvU", "number": 5573, "cdate": 1757920685223, "mdate": 1759897967251, "content": {"title": "Graph Representational Learning: When Does More Expressivity Hurt Generalization?", "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning on structured data, yet the relationship between their expressivity and predictive performance remains unclear. We introduce a family of pseudometrics that capture different degrees of structural similarity between graphs and relate these similarities to generalization, and consequently, the performance of expressive GNNs. By considering a setting where graph labels are correlated with structural features, we derive generalization bounds that depend on the distance between training and test graphs, model complexity, and training set size.  These bounds reveal that more expressive GNNs may generalize worse unless their increased complexity is balanced by a sufficiently large training set or reduced distance between training and test graphs.  Our findings relate expressivity and generalization, offering theoretical insights supported by empirical results.", "tldr": "We introduce a family of pseudometrics that capture different degrees of structural similarity between graphs and relate these similarities to generalization and performance of expressive GNNs.", "keywords": ["Graph Neural Networks", "Generalization", "Expressivity", "PAC-Bayes"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7b20bbe2f12c4d92cc8fe3738193ef379d0eceb4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper conducts an theoretical analysis on the tradeoffs between model expressiveness in the graph neural network context and empirical performance (seen through the lens of generalization). To this end, the paper studies the generalization of GNNs vis-a-vis their expressiveness by introducing and basing their theoretical analysis on variants of a tree-movers distance, which indicates correlations between structural features learnable / detectable by models and the ultimate classification output. The paper introduces the necessary concepts early in the paper, and explains how expressiveness affects TMDs (with more expressive models increasing them, potentially harmfully to performance), and them produces a bound combining model complexity and structural similarity.\n\nFrom this bound, the authors produce a simplified version that more accessibly explains the main contributors to worse generalization between training and testing. In particular, the paper highlights model complexity as a negative factor, relating this to overfitting, as well as worsening similarity between training and testing sets and worsening TMDs, which decreases model alignment. \n\nFinally, the paper conducts an empirical analysis of GNNs of varying expressiveness against both synthetic and real-world baselines, showing empirically that expressiveness indeed offers a \"sweet spot\", in which too little expressiveness can undermine performance, but excessive, uncorrelated expressiveness can lead to overfitting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper's methodology is sound and its arguments and experiments are well-designed. \n- The exposition of the paper is balanced, despite the highly involved nature of the proofs and of the subject matter as a whole.\n- The authors do well in extracting key insights from the paper and maintaining a high-level narrative despite the high technicality of the work."}, "weaknesses": {"value": "- The results derived in this paper need significant contextualization and connection to practical phenomena to become more beneficial to the community. Naturally, I appreciate the derivations and constructions behind the theorems being proven in this paper. However, the connection, say, between $\\zeta$-TMDs as a theoretical construct and the choices of datasets and synthetic targets in the paper are not clear. I fully recognize that this is not a simple concept or connection to make, but I feel it is essential to better understand the underlying mechanics that are qualitatively being presented. It would also substantially strengthen the takeaway message of the paper.\n\n- At a high level, the insights drawn in this paper align with intuition, but, in keeping with my point above, lack accompanying guidance or support to be more widely applicable. For instance, $\\zeta$-TMDs and structural similarity are reasonable and plausible (if not perfectly quantifiable) metrics to want to estimate when selecting a model for a graph representation learning task, but it's not clear where to start. This may be a somewhat trivial exercise compared to the theoretical derivations themselves, but I feel that more curated examples with concrete choices for the pseudometrics and guidance on identifying appropriate choices more broadly would substantially increase the appeal of this work, and take it from being a theoretical result confirming widely held intuitions to the start of a framework or heuristic that informs model selection, much like algorithmic alignment [1]\n\n- Speaking of algorithmic alignment, I feel that that nuance is missing in this work. This is not a fundamental limitation, as the work in itself is already substantial, but I do still think that a comparison with intuitive alignment arguments would be beneficial for grounding your intuitions and conclusions, and would add good color. Most prominently, adding features that align with the task being learned, e.g., cycle counting, is well explained as a performance improvement through algorithmic alignment, and is compatible with your results. However, alignment captures a complementary subtlely, namely that being able to learn cycles as an expressive model is typically worse for generalization versus having explicit cycling representations. This also lines up with your work: A more expressive model capturing cycles among other cycles would weaken the correlation with the target signal, worsening generalization, whereas an aligned cycle-only model wouldn't. I would add some discussion on this as a minor improvement to the nuance of your analysis.\n\n[1] Xu et al., What Can Neural Networks Reason About? ICLR 2020."}, "questions": {"value": "None, please see weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0f33uNioZT", "forum": "C6vpifaZvU", "replyto": "C6vpifaZvU", "signatures": ["ICLR.cc/2026/Conference/Submission5573/Reviewer_iyDd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5573/Reviewer_iyDd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761489491409, "cdate": 1761489491409, "tmdate": 1762918143409, "mdate": 1762918143409, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies when higher expressivity in Graph Neural Networks improves or harms generalization performance. It introduces a family of pseudometrics called ζ Tree Mover Distances that quantify structural similarity between graphs at varying expressive levels, and uses these metrics to model structure–label correlation. The authors derive data dependent generalization bounds that decompose into a model capacity term and a structural similarity term, showing that increased expressivity can worsen generalization when it does not align with task relevant structure. Empirically, they demonstrate that moderately expressive GNNs outperform both vanilla MPNNs and highly expressive higher order GNNs on synthetic and real datasets when label signals correlate with specific structural features. Their results show that accuracy decreases as test graphs become structurally farther from the training graphs under the relevant pseudometric, matching the theoretical predictions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles a central open problem in graph learning: understanding when increased GNN expressivity improves versus harms generalization. This is a core theoretical theme highlighted in recent GNN survey and workshop discussions, and the paper makes progress on a topic with clear community interest.\n- The ζ-TMD construction formalizes the intuition that model expressivity should match task relevant structural signals. By connecting GNN expressivity to pseudometrics that capture structural similarity, the paper provides a structured way to reason about alignment between graph structure and supervision.\n- The paper demonstrates cases where moderately expressive models outperform both simpler and more expressive architectures, consistent with the theory. The experiments, though modest in scale, validate the predicted trade-off between expressivity and structure–label alignment and show trends consistent with the generalization bounds."}, "weaknesses": {"value": "- Although the paper proposes a ζ-TMD framework, the incremental contribution over closely related analyses of structure label alignment and robustness in recent literature (for example Ma et al., 2021; Li et al., 2024; Vasileiou et al., 2024) is not entirely explicit. The manuscript would benefit from a sharper articulation of what new theoretical insight is enabled beyond these frameworks, particularly given that alignment based perspectives have been explored previously.\n- The approach assumes access to an appropriate ζ that correlates with label structure. However, identifying such a metric in practice is nontrivial, and the paper does not provide a principled procedure to select or estimate it. This limits practical applicability, especially when the relevant structural signal is unknown.\n- Experiments are conducted primarily on synthetic tasks and small scale TU datasets. These benchmarks do not fully stress the claimed benefits, and are not representative of modern large scale or heterophilic graph learning settings. Validation on more challenging datasets such as OGB or heterophilic graphs would strengthen empirical support.\n- The generalization bounds are informative but rely on constants and assumptions that are difficult to estimate or control, which limits actionable guidance for model selection in practice. The paper frames the results as qualitative, but clearer direction on how practitioners should use the theory would increase impact.\n- The narrative focuses on expressivity alignment, but does not explicitly connect to orthogonal failure modes such as over-smoothing, over-squashing, and information bottlenecks in deep GNNs. Clarifying how the proposed theory relates to or differs from these phenomena would improve conceptual clarity."}, "questions": {"value": "- In practice, how should one determine the correct pseudometric ζ for a given task? Does the proposed theory offer any algorithmic method or diagnostic criteria to identify such a metric when the relevant structural signal is not known a priori?\n- Why are the empirical evaluations limited to synthetic tasks and relatively small TU datasets? Can the authors provide results on larger and more challenging graph benchmarks such as OGB or heterophilic datasets to demonstrate generality and real world relevance?\n- How does this framework relate to other established causes of generalization failure in GNNs, such as over smoothing, over squashing, and information bottlenecks? Are these phenomena orthogonal to the expressivity alignment perspective, or can the proposed theory explain or incorporate them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gLZKhgvnwv", "forum": "C6vpifaZvU", "replyto": "C6vpifaZvU", "signatures": ["ICLR.cc/2026/Conference/Submission5573/Reviewer_wMWG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5573/Reviewer_wMWG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893955603, "cdate": 1761893955603, "tmdate": 1762918143168, "mdate": 1762918143168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies when increased GNN expressivity helps or hurts generalization by introducing ζ-Tree Mover Distances (ζ-TMDs), task-aligned pseudometrics built via strong simulation of color refinement algorithms. It proves ζ-MPNNs are Lipschitz w.r.t. ζ-TMD, then derives PAC-Bayes bounds that decompose into a capacity term and a structural similarity term (distance between train/test under ζ-TMD). The analysis shows that expressivity improves generalization only when it enhances structure–label alignment; otherwise, it can worsen the bound. Empirically, synthetic and TU datasets support the theory and illustrate tighter (though still loose) bounds than standard PAC-Bayes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clear metric → stability → generalization pipeline with non-trivial derivations. he paper defines task-aligned pseudometrics ζ-TMDs (Def. 3.1; Prop. 3.2–3.3), proves Lipschitz stability of ζ-MPNNs with respect to ζ-TMD (Theorem 3.4; e.g., “∥h(G) − h(H)∥ ≤ L · ζ-TMDT+1(G, H)”), and derives PAC-Bayes generalization bounds that separate a capacity term from a structural-similarity term (Theorem 4.1 and its simplified Eq. (4)). These steps connect distance between graphs → Lipschitz robustness → generalization in a coherent chain and require several technical lemmas (Appendix E, e.g., Lemmas E.2–E.5). The framework extends beyond standard MPNNs via strong simulation (Appendix B), covering F-MPNNs (Cor. 3.5) and k-GNNs (Cor. C.9).\n\nζ-TMD extends the TMD framework to strongly simulatable color refinements, sharpening the bounds via task-aligned structure–label correlation. The ζ-TMD pseudometrics let the bound depend on structure–label alignment, not just model capacity: “generalization improves when the model maps structurally similar graphs (with respect to the ζ-TMD that correlates with the labels) to similar representations while keeping model capacity in check” (Sec. 4; Eq. (4)). This is a principled and flexible way to encode task-relevant structure.\n\nWhen more expressivity helps vs. hurts is theoretically clarified and empirically supported. heorem 5.1 shows that moving from an under-expressive F′-MPNN to a task-aligned F-MPNN preserves the bound, whereas going beyond the task (to F˜-MPNN) can worsen the structural term since ξF˜ ≥ ξF (Lemma G.1), yielding a looser bound. This matches the experiments (Fig. 1 left; Table 1), where overly expressive models overfit. The paper even articulates the design principle: “the optimal GNN is precisely as expressive as required… no more, no less” (Sec. 5). Tighter-than-standard PAC-Bayes: the authors report their bounds are “significantly tighter,” often orders of magnitude smaller than standard PAC-Bayes bounds (e.g., 10^16 vs. 10^4; Sec. 6). To be precise, this is an orders-of-magnitude improvement (not necessarily “exponential” in a formal sense)."}, "weaknesses": {"value": "Choosing ζ is nontrivial and can be the bottleneck; once ζ is fixed, several proofs become mechanical.  The main benefit hinges on picking a ζ that actually aligns with labels. The authors acknowledge this: “the relevant pseudometric is often unknown and possibly expensive to compute” (Limitations), and Rζ can inflate size/degree/features (Eq. (4) discussion: “model complexity may increase if the graph transformation Rζ enlarges…”). Since many results follow from strong simulation plus known Lipschitz/OT arguments, the conceptual challenge is predominantly in selecting/designing ζ.  \n\nThe “increasing expressivity hurts generalization” conclusion rests on upper bounds and monotone dependence on ξ, not a tight characterization.  Theorem 5.1 compares upper bounds; it shows that a more expressive model can have a larger ξ term (ξF˜ ≥ ξF), hence a looser bound, but this is not a lower-bound or necessity result. Comparing two upper bounds does not prove a performance drop must occur—only that it may, given ξ and capacity growth. A converse or data-dependent lower bound (or a matching rate) would strengthen the claim.\n\nBound tightness and trend-shape mismatch in the empirical validation; limited breadth of alternatives. Fig. 3 shows the bound tracks trends but is very loose in scale (theoretical curves on the order of 10^4 vs. empirical errors below 1—i.e., ~4 orders of magnitude gap). Moreover, as TMD-to-train grows, empirical error often saturates/plateaus, whereas the bound’s dependence on ξζ is monotone and cannot capture this flattening. The paper notes the bounds are “qualitative guidelines rather than precise estimates” (Limitations), but some calibration (e.g., data-dependent Lipschitz constants, local smoothness, or normalized structural terms) would help. The empirical scope, while decent (synthetic + six TU datasets), is still limited relative to alternatives: few large-scale graphs, no runtime/compute study for ζ-TMD, and limited comparison to other distance-based theories (e.g., graphon cut metrics, Gromov–Wasserstein) or strong baselines beyond the selected GNN family variants. Ablations on the choice of ζ (how sensitive are results to different CRAs?) would also strengthen the evidence. Practitioner guidance is limited because the bounds are quite loose (often several orders of magnitude above empirical error). Adding one or two strong, actionable experiments—e.g., a ζ-selection/augmentation protocol that measurably improves test accuracy by reducing ξζ, or a procedure to choose model expressivity based on estimated ζ-TMD alignment—would better demonstrate practical utility."}, "questions": {"value": "Please refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2JwJEOHbev", "forum": "C6vpifaZvU", "replyto": "C6vpifaZvU", "signatures": ["ICLR.cc/2026/Conference/Submission5573/Reviewer_uzRa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5573/Reviewer_uzRa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983699970, "cdate": 1761983699970, "tmdate": 1762918142867, "mdate": 1762918142867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the complex relationship between the expressivity of Graph Neural Networks (GNNs) and their generalisation. It suggests that generalisation depends on model capacity and the alignment between task labels and graph similarity. To capture this, the authors introduce a family of pseudometrics called ζ-Tree Mover Distances (ζ-TMDs), which extend the Tree Mover’s Distance by using “strongly simulatable” colour refinement algorithms to transform graphs before distance computation.\n\nTheoretical results show that ζ-MPNNs (MPNNs consistent with a given CRA ζ) are Lipschitz with respect to ζ-TMD and yield PAC-Bayes based generalisation bounds. The test loss decomposes into a capacity term involving layer widths, spectral norms, and graph degree, and a structural similarity term that measures the distance between the training and test sets under ζ-TMD.\n\nThe paper emphasises that “more expressivity” can have both positive and negative effects. Increased expressivity improves performance if it reduces structural similarity term (i.e., better label-structure alignment), but it can degrade otherwise due to added capacity without alignment gains. The paper supports this through synthetic cycle-counting tasks and several TUDatasets, showing that moderately expressive, task-aligned models (e.g., F4-MPNN) generalise best, and empirical errors increase with the TMD distance from the training graphs, tracking the bound’s qualitative trend."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of task-aligned pseudometrics for graphs, formalized as ζ-TMDs, is novel and compelling. Extending TMD through strong simulation of CRAs unifies diverse expressive GNNs (k-GNNs, subgraph models, motif-augmented MPNNs) under a single stability/robustness lens.\n\n- Proofs are extensive and careful, showing Lipschitz continuity of ζ-MPNNs and deriving PAC-Bayes style bounds where the generalization gap depends on $\\xi_\\zeta$. The synthetic and real-world experiments are well targeted to the claims (memorization under label noise, alignment-driven generalization, expressivity vs. overfitting).\n\n- Definitions of CRAs, strong simulation, and ζ-TMD are clearly laid out. The decomposition of the bound into “capacity” and “structural similarity” terms makes the trade-offs intuitive. The paper situates itself well among WL-expressivity, graphon bounds, and robustness literature."}, "weaknesses": {"value": "- Identifying the right ζ (task-aligned pseudometric) can be hard:\nThe framework presumes labels are “strongly correlated” with a chosen $\\zeta-TMD$. In practice, discovering the right ζ is nontrivial and can be expensive (e.g., motif counts, product graphs).\n\n- The paper assumes the CRA to be strongly simulatable, but did not mention under what condition is a CRA strongly simulatable, some examples would be good. \n\n- Bound looseness and constants:\nThe PAC-Bayes bound involves many constants (widths, spectral norms, degrees) and uses assumptions (e.g., Assumption D.1) that can be stringent. The bound is qualitative and not tight.\n\n- Computational overhead of ζ-TMD and strong simulation:\nMany expressive CRAs require transformations (e.g., k-tuple product graphs) that scale poorly, and computing TMD itself is nontrivial. This, together with the looseness of the bound, greatly hinders the practicality of the results.\n\n- Experimental scope:\n The authors empirically shows the bound demonstrates similar trend as empirical error in Fig 3, but this is not quantitative. If possible, I would like to see the correlation between the bound and empirical error on a wider range of datasets.\n\n- Presentation polish:\nSome minor issues (placeholder captions, typographical glitches, compressed figure axes) impact readability, e.g. \n  * missing caption is Fig 10\n  * P in L157 is not defined.\n  * L165-167 \"We say that a graph invariant ζ is more expressive than another graph invariant θ if ζ(G) = ζ(H) implies θ(G) = θ(H) for all G, H ∈ G.\" This doesn't feel right, if ζ and θ have the same expressivity, then ζ(G) = ζ(H) implies θ(G) = θ(H), according to this definition, ζ is more expressive than θ?"}, "questions": {"value": "1. How would you recommend practitioners choose ζ in real tasks?\n\n2. What is the complexity of computing ζ-TMD at depth T for the CRAs considered? Can you provide scalable approximations (e.g., subsampling rooted trees, contrastive encoders trained to approximate TMD distances)?\n\n3. Assumption and robustness:\nHow sensitive are your bounds and empirical trends to violations of $y \\sim \\zeta-TMD^{T+1}$ and Assumption D.1? Could you adopt alternative robustness frameworks to relax or complement D.1?\n\n4. Does your Lipschitz analysis extend to attention-based graph transformers or alternative poolings (e.g., mean/max, Set2Set)? What constraints would be required?\n\n5. Empirical alignment tests:\nCould you add a diagnostic that measures the correlation between label distributions and ζ-TMD distances to training graphs, to operationalize “alignment” before model design?\n\n6. Experiments: in Fig 2 and 3, the accuracy/empirical error increases/stabilises after certain TMD, can you think of any reasons?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uIp968cHYs", "forum": "C6vpifaZvU", "replyto": "C6vpifaZvU", "signatures": ["ICLR.cc/2026/Conference/Submission5573/Reviewer_cYcW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5573/Reviewer_cYcW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762081330398, "cdate": 1762081330398, "tmdate": 1762918142607, "mdate": 1762918142607, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}