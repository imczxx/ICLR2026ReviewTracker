{"id": "eue8OGzkxI", "number": 24598, "cdate": 1758358343133, "mdate": 1759896758801, "content": {"title": "HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation", "abstract": "Electroencephalography (EEG) is an essential technique for neuroscience research and brain-computer interface (BCI) applications. Recently, large-scale EEG foundation models have been developed, exhibiting robust generalization capabilities across diverse tasks and subjects. However, the heterogeneity of EEG devices not only hinders the widespread adoption of these models but also poses significant challenges to their further scaling and development. In this paper, we introduce HEAR, the first EEG foundation model explicitly designed to support heterogeneous EEG devices, accommodating varying electrode layouts and electrode counts. HEAR employs a learnable, coordinate-based spatial embedding to map electrodes with diverse layouts and varying counts into a unified representational space. This unified spatial representation is then processed by a novel spatially-guided transformer, which effectively captures spatiotemporal dependencies across electrodes. To support the development of HEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data collected from over 150 distinct electrode layouts with up to 1,132 electrodes. Experimental results demonstrate that HEAR substantially outperforms existing EEG foundation models in supporting heterogeneous EEG devices and generalizing across diverse cognitive tasks and subjects.", "tldr": "", "keywords": ["Electroencephalography", "EEG foundation model", "Heterogeneous layouts", "Spatial embedding"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dade6f828a3f86511b4067bb51cc26131f821e8e.pdf", "supplementary_material": "/attachment/5122923863c617dd7f47eca6d7852b5145b6c28e.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes HEAR as a robust foundation model toward varying electrode layouts and count. Using a learnable spatial coordinate based encoding this paper demonstrates strength in robustness, a pressing issue in a generalizable applicability of modern EEG models. Spatially-Guided Transformer module is novel. Extensive evaluations on five downstream datasets reveal that it may outperform state of the model with a relatively small parameter size."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- Well motivated, implemented, presented and visualized. \n- Judging by the heterogeneity of the datasets, engineering and open-sourcing an additional dataset for the community is valuable.\n- Complete documentation including the supplemental materials.\n- Small model to outperform larger models show the efficiency of the method."}, "weaknesses": {"value": "- Limited scalability of the model: the difference between base and tiny models are not statistically significant.\n- Small model coupled with a transfer learning approach: closer to \"pretraining\" approach rather than \"foundation\" model. A foundation model is conventionally characterized by a large model where only the feature is extracted and used on a relatively light adapter modules. All experiments in this paper seem to be based on transfer learning, without linear probing or feature interpretation."}, "questions": {"value": "- Have you considered other methods, like fourier features or NeRF, continuous positional encoding, etc instead of a simple MLP? \n- Both tiny and base models are pretty small. Have you tried one size larger model to see whether scalable performance still meet?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pxi41yxucu", "forum": "eue8OGzkxI", "replyto": "eue8OGzkxI", "signatures": ["ICLR.cc/2026/Conference/Submission24598/Reviewer_3xmU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24598/Reviewer_3xmU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791726442, "cdate": 1761791726442, "tmdate": 1762943133020, "mdate": 1762943133020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HEAR, an EEG foundation model designed to handle heterogeneous EEG devices with varying electrode counts and layouts. The authors propose a learnable coordinate-based spatial embedding and a spatially-guided transformer to map diverse electrode configurations into a unified representational space. Experiments show that HEAR achieves strong generalization across tasks, subjects, and unseen electrode configurations, outperforming existing EEG foundation models that typically rely on fixed-channel subsets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The authors introduce the HEAR dataset, which aggregates data from 20 existing datasets encompassing diverse electrode configurations.\n\n2. The authors propose a general-purpose electrode encoding scheme capable of handling inputs with varying electrode configurations.\n\n3. The supplementary material includes detailed descriptions of the electrode layouts across the constituent datasets."}, "weaknesses": {"value": "1. The paper’s organization is suboptimal for a foundation model study: critical details regarding pretraining procedures and the optimization objective are absent from the main text and relegated to Appendix E.1. These should be moved to the main body to ensure clarity and completeness.\n\n2. The set of baselines appears outdated. Notably, the most recent baseline is EEGPT (NeurIPS 2024). The author should compare with more recent foundation models such as  CbraMod and CSBrain. Moreover, the evaluation is limited to a small number of downstream tasks, and the reported performance gains are modest, weakening the empirical support for the proposed approach.\n\n3. In my view, the core technical contribution lies in the unified electrode positional encoding. However, given that standard tools like MNE can automatically derive 3D coordinates for any electrode layout, the novelty of this component is limited—it essentially amounts to taking the union of existing layouts and exporting their coordinates. Furthermore, the handling of electrodes absent from the global dictionary (i.e., excluded them) contradicts the claim of “unified channel mapping” illustrated in Figure 1a and stated in the text.\n\n4. The assertion that “HEAR is the first EEG foundation model capable of accommodating heterogeneous EEG devices with varying electrode layouts and counts” is not well supported. Several existing foundation models already support heterogeneous electrode configurations to varying degrees, making this “first” claim inaccurate.\n\n5. The paper should report performance under a linear probing evaluation protocol and include a discussion on whether the proposed universal electrode encoding translates into improved performance in such settings. Demonstrating such gains would strengthen the justification for the method design. However, the current experiments (e.g., Sections 5.5 and 5.6) do not provide sufficient evidence to support this aspect of the contribution.\n\n6. The title of Section 5.6, “zero-shot generalization,” is potentially misleading. Strictly speaking, fine-tuning on one set of channels and evaluating on another constitutes channel-wise zero-shot transfer, not zero-shot in the conventional sense. Moreover, this experimental setup appears to have limited practical relevance, as real-world scenarios rarely involve the same EEG device being used with disjoint channel subsets for training and testing."}, "questions": {"value": "see in weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HLNgnJFizU", "forum": "eue8OGzkxI", "replyto": "eue8OGzkxI", "signatures": ["ICLR.cc/2026/Conference/Submission24598/Reviewer_PpMP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24598/Reviewer_PpMP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887061936, "cdate": 1761887061936, "tmdate": 1762943132678, "mdate": 1762943132678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HEAR (Heterogeneous Electrode Adaptive Representation), an EEG foundation model designed to handle heterogeneous electrode montages without subject-specific calibration. The work addresses electrode heterogeneity using coordinate-based spatio-temporal embeddings and spatially-guided transformer architecture, pre-trained on 8,782 hours of EEG data. However, the synthesis of expert human review and AI calibrated review reveals fundamental issues: the novelty claim of being \"first\" to support unseen layouts is demonstrably false given prior work (PopT, CBraMod, Brant), missing essential baselines (CBraMod, PopT, LaBraM) prevent validation of the core contribution, and architectural components closely resemble prior work without clear innovation. For ICLR's rigorous standards, these fundamental issues—particularly the inaccurate novelty claim and missing competitive baselines—position this as a rejection despite addressing a real problem."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses a genuine practical problem of electrode heterogeneity in EEG, which is a deployment barrier for BCI applications\n- Dataset contribution: HEAR Dataset with 8,782 hours of EEG data represents a valuable community resource\n- Good presentation quality: paper is generally well-structured and clearly written\n- Evaluation includes diverse datasets spanning motor imagery and sleep staging tasks"}, "weaknesses": {"value": "- Factually inaccurate novelty claim: The assertion of being \"first EEG foundation model capable of supporting unseen layout\" is demonstrably false. PopT (Song et al., 2024) explicitly supports \"arbitrary channel configurations\" using 3D coordinates, CBraMod (Wang et al., 2024) handles varying montages, and Brant (Jiang et al., 2024) demonstrates zero-shot transfer across electrode setups. This violates scientific integrity standards.\n- Missing essential baselines: CBraMod, PopT, and LaBraM are the directly comparable montage-agnostic models that would validate whether HEAR provides improvements beyond existing solutions. Without these comparisons, the core contribution cannot be validated. All current comparisons are against non-montage-agnostic baselines, which doesn't validate a montage-agnostic contribution.\n- Lack of architectural novelty: Component-by-component analysis shows each element has clear precedent in recent prior work: Global Channel Dictionary resembles LaBRaM's channel embedding framework, Coordinate-based Spatio-Temporal Embedding resembles PopT's 3D coordinates, Temporal Slice Channel Attention resembles CSBrain/CBraMod factorized attention, and Spatially Guided Transformer has precedent in Li et al., 2022. The work represents engineering reconfiguration rather than algorithmic innovation.\n- Ambiguity in core technical capability: Unclear whether HEAR supports truly unseen channels (e.g., C5, C6, P5, P6 not in 10-20 system) or only unseen configurations of pre-training channels. This fundamental ambiguity prevents proper evaluation of the claimed contribution.\n- Incomplete ablation studies: Critical design choices lack systematic justification—Spatial MLP block not ablated, coordinate encoding scheme alternatives not compared, channel dictionary size not analyzed. This undermines reproducibility.\n- Limited downstream task diversity: Only evaluated on motor imagery and sleep staging. For a \"foundation model\", evaluation should span emotion recognition, cognitive load assessment, error-related potential detection to demonstrate generalizability.\n- Limited scaling exploration: Only tiny (3.1M) and base (6.0M) models evaluated. Foundation models should demonstrate scaling properties at 10M, 50M, 100M+ parameters.\n- Small dataset size relative to baselines: HEAR uses 8,782 hours vs. CBraMod's 27,062 hours (3.1x more). Unclear whether performance differences might be due to dataset scale rather than architectural innovation.\n- Missing dataset distribution analysis: No details on types of EEG paradigms (resting-state, task-based, clinical), distribution of channel counts, or potential biases in pre-training data.\n- No computational cost analysis: Missing training time, computational requirements, inference latency, and memory footprint compared to baselines—important for practical deployment."}, "questions": {"value": "How does HEAR compare against CBraMod, PopT, and LaBraM on the same downstream tasks? These are the essential montage-agnostic baselines needed to validate the core contribution.\n\nCan HEAR handle completely unseen channels (e.g., channels not in the 10-20 system like C5, C6, P5, P6) or only unseen configurations of pre-training channels? Please clarify this fundamental technical capability.\n\nWhat is the computational cost (training time, memory, inference latency) compared to montage-agnostic baselines like CBraMod and PopT?\n\nHave you evaluated HEAR on additional downstream tasks beyond motor imagery and sleep staging, such as emotion recognition (SEED, DEAP datasets), cognitive load assessment, or error-related potential detection?\n\nHow does performance scale with model size beyond the base model? Please provide results for 10M, 50M, 100M parameter models to demonstrate foundation model scaling properties.\n\nWhy was the spatial MLP block not included in the ablation study? What is its contribution to performance?\n\nWhat specific architectural innovations does HEAR provide over prior montage-agnostic models like PopT (which uses similar coordinate-based embeddings) and CBraMod (which uses channel-wise transformations)? Please clarify the novel contribution beyond existing techniques."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Kq4mba3B1Q", "forum": "eue8OGzkxI", "replyto": "eue8OGzkxI", "signatures": ["ICLR.cc/2026/Conference/Submission24598/Reviewer_TjNs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24598/Reviewer_TjNs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989047437, "cdate": 1761989047437, "tmdate": 1762943132512, "mdate": 1762943132512, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HEAR, a foundation model designed to handle heterogeneous EEG electrode layouts and varying channel counts by (1) building a global channel dictionary and mapping dataset-specific channel sets into it, (2) learning a coordinate-based spatial embedding (spatial MLP) that is broadcast across temporal patches, (3) applying a temporal-slice channel attention module and a spatially-guided Transformer that injects pairwise spatial bias into attention, and (4) pretraining on a large heterogeneous corpus followed by fine-tuning on downstream tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tDevice heterogeneity is a genuine barrier to deploying EEG foundation models; addressing layout variability is valuable for real-world BCI and clinical use.\n2.\tThe HEAR dataset is a notable engineering contribution that supports cross-layout learning and gives the paper strong empirical grounding.\n3.\tThe coordinate MLP + pairwise spatial bias in attention is a straightforward, interpretable way to provide layout-awareness to transformers.\n4.\tResults are shown on multiple public tasks/datasets with zero-shot experiments and detailed visualization of attention."}, "weaknesses": {"value": "1.\tThe core components (coordinate embeddings, spatial bias as attention bias) are conceptually straightforward and similar to spatial-bias techniques used in vision. The main novelty is the combination of those pieces at scale with a large heterogeneous pretraining corpus rather than a fundamentally new modeling or theoretical contribution.\n2.\tHEAR does not explicitly address the integration of derived channels or bipolar/Laplacian montages commonly used in clinical EEG. Although the appendix mentions selecting the first channel in dual EEG channel setups, this effectively discards the structured spatial information inherent in bipolar derivations. Ignoring this large, clinically relevant class of heterogeneity is a significant practical limitation.\n3.\tThe model uses Euclidean 3-D coordinates projected by an MLP and pairwise difference embeddings as attention bias, but there is no analysis of (a) sensitivity to coordinate noise or mis-registration across datasets, (b) whether Cartesian coordinates are superior to spherical/head-surface coordinates, or (c) whether the MLP learns meaningful invariances vs. implicitly memorizing layout statistics. Ablations (coordinate representation, MLP capacity) are missing.\n4.\tThe attention heatmaps are interesting but do not prove causal reliance on spatial priors; more rigorous analyses (e.g., lesioning channels, saliency analyses, or intervention studies that remove/shift channels) would substantiate claims that spatial embeddings are the causal driver of robustness.\n5.\tThe provided ablation studies remove modules (spatial embedding, temporal-slice attention, full transformer) but do not test: (a) alternative spatial encodings (spherical coords, normalized positions), (b) coordinate perturbation robustness, (c) varying MLP capacity or codebook variants in quantization.\n6.\tAcross most datasets, the performance gap between HEAR-tiny and HEAR-base is marginal—often within one standard deviation. This raises questions about whether the model capacity or architecture scaling meaningfully contributes to improvement.\n7.\tLack of statistical significance testing.\n8.\tWhile the paper compares against several EEG foundation models, it omits more recent and competitive approaches such as CBraMod (2024) and CSBrain (2025), which are regarded as current SOTA for heterogeneous EEG representation."}, "questions": {"value": "Please refer to the Weaknesses section for detailed questions and suggestions to the authors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YjxlgKtkCX", "forum": "eue8OGzkxI", "replyto": "eue8OGzkxI", "signatures": ["ICLR.cc/2026/Conference/Submission24598/Reviewer_35sd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24598/Reviewer_35sd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24598/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995153623, "cdate": 1761995153623, "tmdate": 1762943132336, "mdate": 1762943132336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}