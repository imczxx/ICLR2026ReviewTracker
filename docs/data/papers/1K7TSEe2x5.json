{"id": "1K7TSEe2x5", "number": 6156, "cdate": 1757955129269, "mdate": 1759897932544, "content": {"title": "Achieving Subcategorical Erasure in Text-to-Image Models", "abstract": "The emergence of large-scale text-to-image diffusion (T2ID) models has led to significant advancements in generating high-quality visual content from textual prompts. However, these powerful capabilities have also raised growing concerns about the generation of harmful and copyrighted material. While existing concept erasure techniques can effectively block the production of specific unwanted concepts from prompts, they often fall short when it comes to erasing an entire category (including subcategories) and are typically limited to handling only a few concepts at a time. In this paper, we introduce Subcategorical Unlearning via Regularized Erasure (SURE), a novel method for removing entire subcategories from text-to-image diffusion models using only a single parent category as the target. Unlike prior approaches, SURE does not rely on sets of synonyms. Instead, it employs concept space to discover and eliminate the target category while preserving the model's overall utility. To further enhance erasure, SURE incorporates Lipschitz regularization, which encourages smoother model responses to perturbations around the target category. Specifically, the regularization promotes consistent behavior in the model’s latent space when exposed to slight variations of the category to be forgotten. This smoothness constraint aids in erasure while maintaining the model’s ability to generate unrelated content. Extensive experiments conducted across three tasks—object removal, suppression of explicit content, and elimination of artistic styles demonstrate that SURE achieves balanced performance in both effective category erasure and preservation of non-target concepts.", "tldr": "A novel method for removing entire sub categories from text-to-image diffusion models", "keywords": ["Text-to-Image Diffusion-based Foundation Models", "Erasing Concepts", "Generative model"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0aa2f9edf54bc4d55c2e9668a0cd20dad76f7a0e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method to remove broad categories (and all their subcategories) from text-to-image diffusion models. It builds on existing concept-removal techniques such as ESD (Gandikota et al., 2023), and introduces an adversarial approach to automatically identify related subcategories for erasure. Additionally, it proposes a Lipschitz regularization loss to encourage smooth model outputs in the ε-neighborhood of the target concept as proposed in Foster et al. 2024."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n1. Addressing category-level removal that includes subcategories is a practical and relevant problem for real-world model safety.\n2. The adversarial concept-search formulation is a sound idea to generalize erasure beyond explicitly listed tokens."}, "weaknesses": {"value": "Weaknesses:\n1. The method section writing can be improved. For example, it would be great to have the definition of the concept space C in Section 4.2, instead of in the Appendix. Further, it’s currently defined using a discrete CLIP vocabulary with only 100 words, which may miss fine-grained or semantically close subcategories. An analysis of coverage (e.g., recall of known hyponyms) or ablation over the size of C would strengthen this part. Also, the objective seeks concepts most different from the neutral prompt, but this can lead to the selection of entirely unrelated concepts to the target concept. Does the concept space C only consist of possibly relevant related sub-categories?  \n2. It is unclear how the Lipschitz loss in Section 4.3 contributes to unlearning. The loss is computed in VAE-encoded space, which will update the VAE encoder, instead of the diffusion UNet? Since only the VAE decoder is used at inference, updating the encoder seems irrelevant. If the goal is smoothness in the diffusion feature space, the paper should explicitly clarify where gradients flow and justify this design. \n3. Regularizing the model output on a single “neutral” prompt may not reliably preserve semantically close but non-target concepts (e.g., “plate” when erasing “knife”). Evaluation should include such near-neighbor categories rather than random CIFAR-10 classes. \n4. A short algorithm block summarizing the steps would be really helpful. The min–max setup in Equations 3 and 7 is missing the outer min that enforces the mapping of the related sub-categories to the neutral concept.  \n5. Evaluation:   \n– To measure locality, the evaluation setup should select the closest non-target concept instead of random classes from CIFAR-10, e.g., “plates” when removing “knives”, which might be closer in the concept space of kitchen utensils.  \n  – Tests are limited to SD-1.4; extending to newer architectures (e.g., SD3, or FLUX) would show broader applicability.   \n – Additional evaluation on adversarial prompts (e.g., Ring-A-Bell (Tsai et al., 2023)) would help evaluate robustness."}, "questions": {"value": "please look at the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cpaJBXFu3r", "forum": "1K7TSEe2x5", "replyto": "1K7TSEe2x5", "signatures": ["ICLR.cc/2026/Conference/Submission6156/Reviewer_jzz5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6156/Reviewer_jzz5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761526858464, "cdate": 1761526858464, "tmdate": 1762918506977, "mdate": 1762918506977, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SURE (Subcategorical Unlearning via Regularized Erasure), a framework for removing high-level semantic categories and their implicit subcategories from large text-to-image diffusion models such as Stable Diffusion. Unlike previous concept-erasure approaches (e.g., ESD, ACE, UCE), which require explicit lists of target words or fine-grained concepts, SURE aims to achieve category-wide erasure by training only on a single parent-class label (e.g., “gun”), while automatically discovering and forgetting related subcategories (e.g., “rifle”, “pistol”, “shotgun”). Experiments on object categories, NSFW content, and artistic styles show that SURE outperforms prior methods in removing entire semantic families while maintaining high image fidelity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of subcategorical erasure extends beyond traditional “single concept” forgetting, addressing a realistic and underexplored safety problem in text-to-image models.\n2. The use of Gumbel-Softmax for differentiable selection over a restricted CLIP concept space is elegant, allowing the model to approximate hard max search while remaining trainable. This is a technically sound compromise between efficiency and adversarial robustness."}, "weaknesses": {"value": "1. Limited Theoretical Depth for Subcategory Discovery: While L₃ is designed to “automatically discover” related subcategories, the paper lacks a formal analysis or quantitative validation (e.g., retrieval accuracy or coverage metrics). The reliance on pre-filtered 100 CLIP candidates suggests partial supervision rather than full autonomy.\n2. Ablation Insufficiency: Key design choices—such as using max vs. top-k or soft-average formulations in L₃—are not empirically justified. Similarly, the sensitivity to the Lipschitz regularization weight (λₗᵢₚ) is unexplored, even though it directly affects stability.\n3. Ambiguity in Neutral Concept Definition: The “neutral concept” is not clearly defined. Is it a fixed token (“object” or “thing”) or dynamically learned? The lack of explanation weakens the reproducibility and interpretability of results.\n4. Previous work [1] also explores the removal of semantically related sub-concepts and the preservation of neutral sub-concepts in text-to-image diffusion models. It would strengthen the paper to discuss this work in more detail.\n\n[1] Erasing Concept Combination from Text-to-Image Diffusion Model, ICLR 2025"}, "questions": {"value": "1. How sensitive is SURE to the choice of the 100 pre-filtered CLIP concepts? Have you tried expanding to 200 or 500 candidates, and does performance saturate or degrade?\n2. Why was hard max used instead of top-k or entropy-regularized averaging? Would averaging gradients over several high-loss subcategories improve convergence stability?\n3. Have you observed cases where SURE over-erases or inadvertently affects unrelated categories? For example, when erasing “guns”, do “camera” or “drill” images degrade due to visual similarity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jUxNLlu2Su", "forum": "1K7TSEe2x5", "replyto": "1K7TSEe2x5", "signatures": ["ICLR.cc/2026/Conference/Submission6156/Reviewer_TvHz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6156/Reviewer_TvHz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761666055039, "cdate": 1761666055039, "tmdate": 1762918506542, "mdate": 1762918506542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SURE, a novel method for removing entire subcategories from text-to-image (T2I) diffusion models using only a single parent-category prompt as the target. The key idea is to generalize from one parent concept to its many subcategories without explicitly naming or training on each one. To achieve this, the method applies Lipschitz regularization, which encourages smoother model behavior and helps erase concept clusters in a more controlled way. SURE is designed to be scalable and generalizable, aiming to erase broad semantic groups while preserving the generation quality of unrelated content. The method is evaluated across multiple erasure tasks and shows state-of-the-art performance in many of them."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A key strength of SURE is its ability to erase an entire set of semantically related subcategories by providing only a single parent-category prompt.\n\n2. The introduction of Lipschitz regularization is novel in this context and helps enforce smooth transitions in the model’s representations. This appears to contribute to more stable and effective erasure, especially when trying to remove broad or abstract concepts.\n\n3. The method achieves state-of-the-art results in several concept erasure benchmarks."}, "weaknesses": {"value": "1. While the paper shows that Lipschitz regularization is effective, it does not provide a clear theoretical rationale for how or why it improves forgetting dynamics.\n\n2. Most experiments focus on semantically or visually similar subcategories. It remains unclear how the method performs when the parent category covers diverse or loosely related subcategories.\n\n3. The link between Lipschitz regularization and subcategory erasure is not well articulated. The motivation behind applying this specific type of regularization to the erasure task could be explained more clearly, both intuitively and mathematically.\n\n4. Missing important related works:\n\n[1] Eraseanything: Enabling concept erasure in rectified flow transformers\n\n[2] Dark miner: Defend against unsafe generation for text-to-image diffusion models\n\n[3] One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework\n\n[4] Erasing More Than Intended? How Concept Erasure Degrades the Generation of Non-Target Concepts"}, "questions": {"value": "1. The current ablation experiments do not clearly isolate the effect of each component in the method. Could you conduct more fine-grained ablations, such as removing Lipschitz regularization alone or varying the sample size used during optimization, to better understand each component’s contribution?\n2. You mention that performance peaks when the number of training samples is n = 5, but then declines as n increases. Could you provide a theoretical or empirical explanation for this behavior? Why does adding more samples hurt performance?\n3. How does SURE perform when the parent category and its subcategories are semantically or visually distant (e.g., abstract parent terms or diverse visual instances)?\n4. In the object-related erasure tasks, SURE significantly outperforms baseline methods. Could you explain which part of the method contributes most to this improvement? Is it due to regularization, training strategy, or the parent-subcategory setup?\n5. While the paper critiques using word sets to erase subcategories, it would still be valuable to include a word-set baseline for comparison. This helps quantify the advantage of your approach, even if word sets are not ideal.\n\nIf the authors can solve the questions, I will consider raising my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VcGqpFrDHK", "forum": "1K7TSEe2x5", "replyto": "1K7TSEe2x5", "signatures": ["ICLR.cc/2026/Conference/Submission6156/Reviewer_QZ8U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6156/Reviewer_QZ8U"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880065785, "cdate": 1761880065785, "tmdate": 1762918506080, "mdate": 1762918506080, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Subcategorical Unlearning via Regularized Erasure (SURE), a method for removing entire subcategories (e.g., SMG, revolvers, pistols, rifles, shotguns) from text-to-image diffusion models using only a single parent category (e.g., guns) as the unlearning target.\n\nThe problem setting the paper aims to address is that existing concept unlearning methods are typically limited to erasing either a single concept (e.g., pistol) or a small set of closely related ones (e.g., revolver, rifle, shotgun), and struggle to eliminate a complete category and all its subcategories.\n\nThe core design builds upon extending Lipschitz continuity to the latent space, encouraging smooth generative behaviour around the to-be-erased categorial. More specifically, given $f(x)$ is the latent representation of input image $x$ (via VAE encoder in the Latent Diffusion Models), the authors propose to minimize the different between $f(x)$ and $f(x + \\xi_i)$ where $\\xi_i$ is the $i$-th perturbation sample over $N$ total perturbations, i.e., $\\| f(x) – f(x+\\xi_i) \\| / \\| \\xi_i \\| $, reduce memorization of that target category."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "•  The paper tackles an important problem in machine unlearning—removing undesirable concepts from generative models.\n\n•  The specific subproblem of subcategorical unlearning is novel and practically relevant, though it raises potential concerns about over-unlearning, i.e., unintentionally erasing related but desirable concepts.\n\n•  The idea of using Lipschitz regularization to encourage smoother latent behavior is interesting and intuitively appealing.\n\nHowever, the effectiveness of this approach appears to depend heavily on the choice of the sample x, which may significantly affect performance"}, "weaknesses": {"value": "The writing and presentation reduce the perceived novelty of the work. The optimization objective comprises four components, three of which are directly borrowed from prior work, with only the Lipschitz regularization term being newly proposed. \n\nThe paper does not provide sufficient justification or analysis of why Lipschitz regularization is effective in preventing subcategorical memorization. The motivation currently appears intuitive rather than empirically grounded.\n\nThe authors should focus more on analyzing and justifying the contribution of the Lipschitz regularization term—e.g., through ablation studies, visualization of latent trajectories, or quantitative metrics.\n\nInstead of positioning SURE as a standalone unlearning framework, the authors might consider integrating the Lipschitz regularization term into existing unlearning methods (such as MACE or ACE) to demonstrate broader utility.\n\nOverall, the technical contribution in its current form seems insufficient for ICLR-level significance, as the novelty is limited and the empirical justification is incomplete"}, "questions": {"value": "-\tHow is the sample $x$ chosen for the Lipschitz regularization? \n-\tHow does the proposed term interact with or affect other unlearning methods such as MACE, ACE or recent approaches when combined with them?\n-\tCan the authors provide a more detailed analysis of the effect of perturbation strength on both unlearning and generation quality?\n-\tHow is the concept space $C$ defined and how sensitive is the performance to the choice of this space?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ybNS6v9KCX", "forum": "1K7TSEe2x5", "replyto": "1K7TSEe2x5", "signatures": ["ICLR.cc/2026/Conference/Submission6156/Reviewer_PSKP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6156/Reviewer_PSKP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762057487431, "cdate": 1762057487431, "tmdate": 1762918505683, "mdate": 1762918505683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}