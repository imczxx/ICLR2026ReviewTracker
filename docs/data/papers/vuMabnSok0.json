{"id": "vuMabnSok0", "number": 1102, "cdate": 1756840917706, "mdate": 1759898227974, "content": {"title": "Early Stopping Chain-of-thoughts in Large Language Models", "abstract": "Reasoning large language models (LLMs) have demonstrated superior capacities in solving complicated problems by generating long chain-of-thoughts (CoT), but such a lengthy CoT incurs high inference costs. In this study, we introduce ES-CoT, an inference-time method that shortens CoT generation by detecting answer convergence and stopping early with minimal performance loss. At the end of each reasoning step, we prompt the LLM to output its current final answer, denoted as a step answer. We then track the run length of consecutive identical step answers as a measure of answer convergence. Once the run length exhibits a sharp increase and exceeds a minimum threshold, the generation is terminated. We provide both empirical and theoretical support for this heuristic: step answers steadily converge to the final answer, and large run-length jumps reliably mark this convergence. Experiments on five reasoning datasets across three LLMs show that ES-CoT reduces the number of inference tokens by about 41% on average while maintaining accuracy comparable to standard CoT. Further, ES-CoT integrates seamlessly with self-consistency prompting and remains robust across hyperparameter choices, highlighting it as a practical and effective approach for efficient reasoning. Implementation codes of this study are available online (hidden for peer review).", "tldr": "We propose ES-CoT, an inference-time method that reduces inference cost by stopping the CoT generation at an early step.", "keywords": ["large language model", "reasoning", "early stop"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/86785fe265828105b0c5d447ef3a1bf5aa840b45.pdf", "supplementary_material": "/attachment/b4efdfb1f350c1e970ad0173cb463941613003f2.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes ES-CoT, an inference-time method that reduces CoT length by detecting answer convergence and stopping generation early. By monitoring repeated step answers, the method terminates once convergence stabilizes, cutting inference tokens. Experiments on multiple datasets and LLMs show ES-secondo me CoT’s efficiency, robustness, and compatibility with self-consistency prompting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Overall, the paper is well-written.\n- Efficiency in LLMs is an important and valid research challenge."}, "weaknesses": {"value": "- Several related works on concise reasoning and CoT compression are missing from the discussion and experiments. The authors should compare or at least discuss their approach. Some of them (for example):\n- Xu et al. – Chain of Draft: Thinking Faster by Writing Less\n- Aytes et al. – Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching\n- Zhang et al. – LightThinker: Thinking Step-by-Step Compression\n- Fatemi et al. – Concise Reasoning via Reinforcement Learning\n- Lee et al. – How Well Do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach\n- Nayab et al. - Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost\n\nAlthough the proposed method reduces long CoT generation, it still requires multiple-step answers. The authors should clarify how these results lead to a significant reduction in inference cost.\n\nThe mathematical framework appears somewhat isolated. The authors should better explain their technical contribution and how it supports or strengthens the experimental findings."}, "questions": {"value": "Please address computational cost and theoretical issues indicated in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5VCNEgxsUX", "forum": "vuMabnSok0", "replyto": "vuMabnSok0", "signatures": ["ICLR.cc/2026/Conference/Submission1102/Reviewer_kr89"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1102/Reviewer_kr89"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1102/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761567904540, "cdate": 1761567904540, "tmdate": 1762915678489, "mdate": 1762915678489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ES-CoT, an inference-time method to reduce chain-of-thought (CoT) reasoning length in large language models (LLMs) by stopping generation early when answer convergence is detected. ES-CoT monitors the consecutive run length of identical 'step answers' (the model's current statements of its answer at each reasoning step) and halts generation using a run-jump test—triggered when the run length makes a statistically significant increase, exceeding a minimum threshold. The paper justifies this heuristic empirically and theoretically, demonstrating that step answers typically stabilize before completion. Experiments on five reasoning datasets and three LLMs show ES-CoT reduces token usage by about 41% on average with minimal loss in accuracy, and is robust across hyperparameter settings and compatible."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1)The paper provides a quantitative and visual analysis of answer convergence in LLM reasoning (see Figure 2 and Figure 3), demonstrating that step answers indeed tend to stabilize toward the end of reasoning trajectories. The convex jump in run length (Figure 3) offers a clear, observable signal for potential early stopping.\n(2)The ES-CoT mechanism is straightforward to implement at inference, requiring only minor modifications (adding a 'final answer' prompt per step), and does not require retraining, parallel decoding, or auxiliary models.\n(3)The method is evaluated across three competitive LLMs and five well-established reasoning benchmarks, showing substantial savings in average tokens (see Table 1) while maintaining comparable or sometimes even better accuracy."}, "weaknesses": {"value": "(1):The paper does not provide head-to-head results with Speculative Rejection (Sun et al., 2024) or Early Stop Self-Consistency (ESC, Li et al., 2024), which also propose output-side early stopping methods for CoT. These missing baselines are critical for evaluating the genuine advantage of ES-CoT. Without this, it is unclear if the proposed method achieves better cost-quality tradeoffs or simply offers a simpler alternative.\n(2) There is no systematic examination of what types of questions or failure modes lead to suboptimal early stopping (incorrect halts, divergence from the true answer, etc.). A deeper dive into breakdowns by problem type or error case is warranted for practical adoption.\n(3) ES-CoT assumes the 'step answer' extraction at each reasoning step can be done reliably. In real-world settings, especially with less structured or conversational prompts, it may be challenging to parse step-wise answers automatically, limiting applicability to domains outside structured problem-solving."}, "questions": {"value": "(1):How would ES-CoT perform or adapt in tasks where answer uncertainty remains high, or where step answers do not stabilize (violation of Assumption 1)? Can the authors provide breakdowns or error analysis for such cases?\n(2):Is the t-test actually an appropriate statistical test on the run difference sequence $D$? Have the authors considered non-parametric or more tailored sequential change-detection approaches?\n(3):How robust is the step-answer extraction in less-structured CoT outputs, e.g., open-domain QA or conversation? Can ES-CoT be reasonably applied in those settings?\n(4):For the token counting, are the per-step answer prompts included in both ES-CoT and baseline methods? How does ES-CoT’s overhead affect the true token savings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gb5G7zadNd", "forum": "vuMabnSok0", "replyto": "vuMabnSok0", "signatures": ["ICLR.cc/2026/Conference/Submission1102/Reviewer_oxFa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1102/Reviewer_oxFa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1102/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761702465492, "cdate": 1761702465492, "tmdate": 1762915678199, "mdate": 1762915678199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes early-stopping CoT (ES-CoT), an inference-time method that aims to reduce reasoning length by producing a final answer at every reasoning step. The authors introduce the concept of run length, which is the number of consecutive steps yielding the same final answer, and use it to detect answer convergence. Both empirical and theoretical analyses are provided to justify run length as a reliable convergence signal. Experiments on five mathematical reasoning datasets show that ES-CoT significantly reduces the number of inference tokens."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is easy to read.\n- Based on empirical findings, authors make two assumptions: 1) final answers are deterministic, 2) the probability of an intermediate answer being the same as the final answer monotonically increases as the reasoning progresses. Based on the two assumptions, the authors provide a theoretical justification of the run length based early stopping CoT method, which is sound.\n- Authors provide sensitivity and robustness analysis of their method."}, "weaknesses": {"value": "- Experiments focus on mathematical (or formal logic) reasoning datasets.\nThe generalizability of the method is unclear since the core assumptions (e.g., deterministic final answers) may not hold in other domains such as commonsense or open-ended reasoning.\n- Accuracy is not preserved. In Table 1, ES-CoT outperforms the CoT baseline in only 4 out of 20 cases, with 3 of those improvements observed on the larger QwQ 32B model. The method performs poorly on smaller models. While token usage is reduced, this often comes at a substantial cost to accuracy (e.g., on AIME with Qwen3, accuracy drops from 0.73 to 0.50).\n- Even when combined with self-consistency prompting, ES-CoT underperforms the baseline (CoT + SC) in nearly all cases.\n- The method introduces an additional hyperparameter—the difference threshold between run lengths—yet the paper provides no clear guidance on how to select this parameter. The performance seems to vary a lot depending on this parameter."}, "questions": {"value": "In Figure 2-(a), why is the probability that step answers match the final answer so low across all models, even at 100% reasoning progress?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ay7CD38mIg", "forum": "vuMabnSok0", "replyto": "vuMabnSok0", "signatures": ["ICLR.cc/2026/Conference/Submission1102/Reviewer_r9Q5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1102/Reviewer_r9Q5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1102/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906708973, "cdate": 1761906708973, "tmdate": 1762915677974, "mdate": 1762915677974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ES-CoT (Early-Stop CoT), an inference-time method that lets a LLM quit early while it is still doing CoT reasoning. At every step the authors force the model to output its current final answer (step answer). If that answer repeats for a suddenly longer run than before, the process stops and returns that answer. No extra training, reward model, or parallel runs are needed. Tests on 5 math/logic datasets (AIME, GPQA, MATH, Minerva and Olympiad) and 3 LLMs (QwQ 32B, Qwen3 8B, DeepSeek-R1-Distill-Llama 8B) show 41 % fewer generated tokens on average while the accuracy is close to that of standard CoT. Theory and ablations are supplied and the code is promised."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. ES-CoT needs no re-training or extra GPUs, so it's convenient to reproduce the results with LLMs.  \n2. The stopping signal (the \"jump\" in the run-length of identical step-answers) is statistically testable, giving experiments a clear, theory-backed criterion.  \n3. Across 5 mathematical/logical datasets and 5 LLMs the method reduces 41% of generated tokens on average, and in several cases even raises accuracy by preventing over-thinking.  \n4. When paired with self-consistency, decoding ES-CoT keeps most of its token saving and sometimes yields extra accuracy, showing that the method of Early-Stop is useful to some extent.  \n5. Extensive ablation on thresholds and p-value shows stable behaviour, and the failure risk is low and controllable."}, "weaknesses": {"value": "1. Every reasoning step is interrupted with the manually inserted prompt \"The final answer is\", which increases prompt tokens and may make some models toward stopping reasoning too early.\n2. The datasets used in this paper have deterministic final answers and open-ended, creative tasks are excluded, which may lead to insufficient validation of ES-CoT's universal applicability. \n3. Since no comparison is made against distilled, same-scale short-CoT LLMs that were explicitly trained for shorter reasoning, it remains unclear how much of the 41% token savings is simply due to weak baselines.\n4. ES-CoT does not achieve higher reasoning accuracy than standard CoT in most experiments, so despite its efficiency in token usage, there is limited evidence for its substantive effectiveness in reasoning.\n5. The high temperature (0.6) may introduce excessive randomness, and the limited model scales tested (only 32B and 8B) restrict the generalizability of the findings. These factors weaken the reliability and applicability of the conclusions.\n6. The tables are poorly formatted. For instance, in Tables 3 and 4, the word \"DeepSeek\" is split across rows, and there are no annotations to draw attention to significant data differences."}, "questions": {"value": "See the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jOEVNPrkNe", "forum": "vuMabnSok0", "replyto": "vuMabnSok0", "signatures": ["ICLR.cc/2026/Conference/Submission1102/Reviewer_JTng"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1102/Reviewer_JTng"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1102/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916798055, "cdate": 1761916798055, "tmdate": 1762915677662, "mdate": 1762915677662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}