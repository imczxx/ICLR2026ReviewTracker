{"id": "1s1OqbPnBG", "number": 15346, "cdate": 1758250427157, "mdate": 1759897312580, "content": {"title": "Learning Chemical Knowledge from Large-Scale Unlabeled Molecular Data for Retrosynthesis", "abstract": "Retrosynthesis, the process of predicting reactants from products, remains a critical challenge in computational chemistry and drug discovery. While recent deep learning methods have shown strong performance, they remain overly reliant on reaction datasets, which are limited in availability and quality. Large-scale unlabeled molecular data encode rich structural patterns that can be leveraged to learn transferable chemical knowledge, but remain largely unexplored. In this work, we propose KnowRetro (Knowledge-Guided Retrosynthesis Prediction), a chemically-aware framework that learns chemical knowledge from large-scale unlabeled molecules to enhance the accuracy and diversity of retrosynthesis prediction. Specifically, KnowRetro first builds a hierarchical knowledge graph from millions of unlabeled molecules, which captures transformation-relevant relationships among molecules, substructures, and functional groups. It then employs chemically guided pre-training based on substructure decomposition to encourage the model to capture fundamental reaction patterns, followed by fine-tuning with a KG adapter designed to inject task-relevant knowledge into reactant generation. Extensive experiments demonstrate that KnowRetro achieves high accuracy with improved robustness and diversity in reactant generation.", "tldr": "", "keywords": ["Retrosynthesis", "Chemical Knowledge"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e6cdeab1622841cdaf0f5cb0f69043789bc1dc5a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper leverages large-scale unlabeled molecules to improve the accuracy and diversity of retrosynthesis. It first builds a hierarchical chemical knowledge graph via BRICS decomposition to capture relationships among molecules, substructures, and functional groups. Two layers of R-GCN are then pre-trained on this graph. A task-relevant knowledge adapter extracts effective task-specific KG embeddings, while the retrosynthesis encoder–decoder is pre-trained on a molecule→substructures objective. Finally, the task-relevant KG embeddings are integrated into the pretrained encoder–decoder for end-to-end retrosynthesis training."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper effectively injects chemical knowledge into a hierarchical BRICS-based knowledge graph, explicitly encoding molecule–substructure–functional group relations. Pre-training a two-layer R-GCN on this graph yields stronger, transferable embeddings that provide a better initialization for downstream tasks. A task-relevant adapter further aligns these embeddings with retrosynthesis objectives. In parallel, molecule→substructures pre-training for the encoder–decoder supplies fine-grained supervision, boosting downstream retrosynthesis performance.\n\n2. As shown in Table 1, the approach achieves state-of-the-art performance; Table 3 further demonstrates that every component contributes meaningfully."}, "weaknesses": {"value": "1. Given that the proposed pre-training effectively boosts downstream performance, why restrict the evaluation to single-step retrosynthesis? It would be valuable to report results on multi-step retrosynthesis as well. The approach should also extend naturally to single-step forward reaction prediction and molecular property prediction.\n\n2. The interdependencies between modules are insufficiently articulated, giving the impression of a composite system lacking a unifying design rationale."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BuRYUhvSBd", "forum": "1s1OqbPnBG", "replyto": "1s1OqbPnBG", "signatures": ["ICLR.cc/2026/Conference/Submission15346/Reviewer_2rUs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15346/Reviewer_2rUs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761446574098, "cdate": 1761446574098, "tmdate": 1762925635642, "mdate": 1762925635642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces KnowRetro, which constructs a chemical knowledge graph (KG), pretrains using a reaction-aware task (SMILES to BRICS fragments), and injects task-relevant knowledge via a KG adapter for one-step retrosynthesis. It reports SOTA performance on the USPTO-50K dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work leverages unlabeled data to construct a hierarchical chemical KG and uses it to guide the generation process.\n\n2. It employs fragment-aware pretraining to enhance performance on the retrosynthesis task.\n\n3. The paper includes detailed ablation experiments."}, "weaknesses": {"value": "1. Negative KG sampling distinguishes between “not in KG” and truly chemically infeasible reactions, which may limit the model’s ability to avoid invalid chemistry.\n\n2. There is a heavy reliance on BRICS/SMARTS rules; the limited coverage and inherent bias of rule-based fragments/functional groups may restrict generalization."}, "questions": {"value": "- Since products are cut into BRICS fragments via predefined rules, could this introduce unintended overlap with ground-truth reactants? Could you quantify any potential leakage by reporting the exact/partial hit rates of main reactants (fragment set vs. ground-truth reactant set) on the test split?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "N6w43lWTZI", "forum": "1s1OqbPnBG", "replyto": "1s1OqbPnBG", "signatures": ["ICLR.cc/2026/Conference/Submission15346/Reviewer_HJdF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15346/Reviewer_HJdF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809636311, "cdate": 1761809636311, "tmdate": 1762925635268, "mdate": 1762925635268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work investigates inorganic retrosynthesis by constructing a hierarchical knowledge graph (KG) that incorporates fine-grained substructures and functional groups. The authors further apply the Information Bottleneck (IB) principle to capture task-relevant knowledge. Various experiments are conducted to demonstrate the superiority of the proposed method, KnowRetro."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Compared to previous methods that only model KG relationships between reactants and products, this work builds a hierarchical KG leveraging more fine-grained information at the substructure and functional-group levels, and demonstrates its effectiveness through diverse experiments including ablation studies.\n- Extensive experiments, including a theoretical analysis, are provided."}, "weaknesses": {"value": "- The overall structure of the paper does not clearly and systemically explain how all components of the method connect to each other.\nBeyond the theoretical analysis, further explanation and experimental validation are needed to justify the necessity and effectiveness of the Task-Relevant Knowledge Adapter.\nIt remains unclear whether the model actually achieves significant information gain for retrosynthesis compared to directly using the raw KG.  \n- In Equation (9), the process of penalizing “excessive dependence” on e_product needs more clarification — what exactly constitutes “excessive dependence”?\nIn retrosynthesis, the input embeddings arguably contain the most critical information, so it is unclear why penalizing their dependence would be beneficial.\n- It would also strengthen the paper to include a specific example showing how the Information Bottleneck filtering removes noisy or irrelevant information from the original KG.\n- While the Reliability of KnowRetro on Noisy KGs experiment is valuable, it only covers artificially induced noise; showing examples of real-world KG noise and how the filtering mitigates it would be more convincing.\nAdditionally, comparisons against baselines on other datasets such as Pistachio or ORD would improve the completeness of the evaluation.\n- Although an anonymized GitHub link is provided, the code could not be accessed."}, "questions": {"value": "See Weakness section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DzjYbNmBBd", "forum": "1s1OqbPnBG", "replyto": "1s1OqbPnBG", "signatures": ["ICLR.cc/2026/Conference/Submission15346/Reviewer_8eRW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15346/Reviewer_8eRW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882734147, "cdate": 1761882734147, "tmdate": 1762925634643, "mdate": 1762925634643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}