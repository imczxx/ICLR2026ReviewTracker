{"id": "CPxZClPMiy", "number": 24910, "cdate": 1758361811498, "mdate": 1759896742739, "content": {"title": "Aria: an Agent for Retrieval and Iterative Auto-Formalization via Dependency Graph", "abstract": "Accurate auto-formalization of theorem statements is essential for advancing automated discovery and verification of research-level mathematics, yet remains a major bottleneck for LLMs due to hallucinations, semantic mismatches, and their inability to synthesize new definitions.\nTo tackle these issues, we present Aria (**A**gent for **R**etrieval and **I**terative **A**utoformalization), a system for conjecture-level formalization in Lean that emulates human expert reasoning via a two-phase Graph-of-Thought process: recursively decomposing statements into a dependency graph and then constructing formalizations from grounded concepts. To ensure semantic correctness, we introduce **AriaScorer**, a checker that retrieves definitions from Mathlib for term-level grounding, enabling rigorous and reliable verification.\nWe evaluate Aria on diverse benchmarks. On ProofNet, it achieves 91.6\\% compilation success rate and 68.5\\% final accuracy, surpassing previous methods. On FATE-X, a suite of challenging algebra problems from research literature, it outperforms the best baseline with 44.0\\% vs. 24.0\\% final accuracy. On a dataset of homological conjectures, Aria reaches 42.9\\% final accuracy while all other models score 0\\%.", "tldr": "", "keywords": ["Lean 4", "Autoformalization", "LLM", "Graph-of-Thought", "Retrieval Augmented Generation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e212662185b551e06441435260d5f375f2bc6aec.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Aria, a comprehensive agent-based autoformalization pipeline designed to emulate human reasoning for research-level mathematics. The system first performs graph-of-thought decomposition, transforming natural language statements into dependency graphs and grounding the identified concepts in mathlib when possible. For ungrounded concepts, it employs graph-of-thought synthesis to generate Lean representations through a self-reflective loop.\n\nThe authors further introduce AriaScorer, which decomposes informal statements into atomic assumptions and conclusions, then aligns them with formal clauses retrieved from Lean’s library and their corresponding natural language versions to compute an aggregated correctness score.\n\nExperimental results demonstrate that Aria significantly outperforms existing LLM-based autoformalization baselines on the ProofNet, FATE benchmarks, and real-world conjectures. Moreover, AriaScorer achieves more accurate verification of formalization correctness compared to other evaluation methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is well-written and well-motivated. Its focus on research-level mathematical autoformalization is interesting.  \n* The proposed Aria and AriaScorer frameworks are novel, integrating several intuitively and carefully designed components into a cohesive pipeline.  \n* Experimental results demonstrate that both Aria and AriaScorer are effective, outperforming existing methods by a substantial and consistent margin.  \n* The key insights underlying AriaScorer are also inspiring, offering a new perspective on evaluating the correctness of autoformalization."}, "weaknesses": {"value": "There is no human evaluation in the main results, which makes the reported performance less reliable. Moreover, since AriaScorer uses Gemini for both generation and evaluation, the results may be biased toward its own generated responses, especially when compared to other baselines such as Goedel-Autoformalizer."}, "questions": {"value": "* Could you include some manual evaluation on the main experiments to better assess the quality and reliability of the autoformalized results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VdhhWq4b0n", "forum": "CPxZClPMiy", "replyto": "CPxZClPMiy", "signatures": ["ICLR.cc/2026/Conference/Submission24910/Reviewer_dKZk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24910/Reviewer_dKZk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761621543221, "cdate": 1761621543221, "tmdate": 1762943242144, "mdate": 1762943242144, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Aria, a system designed to perform autoformalization of high-level mathematical statements into Lean 4 syntax. Aria emulates human reasoning via a two-phase Graph-of-Thought (GoT) process: (1) recursively decomposing a conjecture into a dependency graph of definitions and sub-statements, and (2) constructing Lean-formalized statements using retrieved definitions from Mathlib. To enforce semantic precision, it employs AriaScorer, a retrieval-based verifier that grounds terms and checks logical consistency.\nThe model combines retrieval-augmented generation, graph reasoning, and self-reflection for improved correctness. On three benchmarks (ProofNet, FATE-X, and Homological Conjectures) Aria achieves strong improvements. The paper claims Aria is the first system to synthesize novel definitions during autoformalization, addressing a key bottleneck in automated mathematical reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The combination of retrieval, graph-of-thought reasoning, and verification is well-motivated and logically coherent. Autoformalization of research-level statements is a frontier problem, and this paper is impactful both for Lean and general symbolic reasoning research.\n\n2. Performance is satisfactory. The system achieves SOTA results across diverse benchmarks, especially on difficult tasks where all prior models can't do well.\n\n3. It tackles hallucination and definition synthesis, the two well-known weaknesses of current formalization LLMs.\n\n4. The use of term-level retrieval (AriaScorer) for semantic grounding is a technically meaningful contribution that enhances reliability."}, "weaknesses": {"value": "1. More ablation study can make it even better. The contribution of each submodule (retrieval, GoT reasoning, reflection, AriaScorer) is not quantified in detail; ablation or controlled comparison would strengthen claims.\n\n2. Some discussion on Aria's generality to other systems (e.g., Coq, Isabelle, Lean 3) will make it more impactful.\n\n3. While promising, the \"first to synthesize novel definitions\" claim may need stronger empirical evidence (e.g., human evaluation verifying novelty and correctness).\n\n4. More detailed discussion on computational cost or efficiency will be very beneficial for assessing scalability."}, "questions": {"value": "Addressing the points I mentioned in weakness part should be enough."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wauGuEbAEY", "forum": "CPxZClPMiy", "replyto": "CPxZClPMiy", "signatures": ["ICLR.cc/2026/Conference/Submission24910/Reviewer_tTzy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24910/Reviewer_tTzy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882124836, "cdate": 1761882124836, "tmdate": 1762943241897, "mdate": 1762943241897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Aria, an agent system for auto-formalizing mathematical statements through a two-phase Graph-of-Thought (GoT) process: recursively decomposing statements into conceptual dependency graphs anchored to Mathlib via RAG, then bottom-up construction of formalizations synthesizing new definitions through compiler-in-the-loop reflection. The paper also introduces AriaScorer, a semantic checker achieving term-level grounding by retrieving actual definitions of Lean terms. Experiments demonstrate that Aria achieves 44.0% accuracy on FATE-X (baseline: 24.0%) and 42.9% on Homological Conjectures (all baselines: 0%), significantly outperforming existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Effective system architecture**: The paper successfully integrates GoT planning, RAG, and compiler-in-the-loop reflection to address the critical failure point of prior models in synthesizing new definitions. Ablation studies in Table 3 validate the necessity of each component: removing RAG or reflection causes accuracy to collapse from 42.9% to 0% on the Conjectures dataset.\n\n- **Innovative contribution of AriaScorer**: This checker transcends text similarity limitations by employing the static analyzer jixia to retrieve actual definitions of Lean terms. Table 2 validates that this term-level grounding step is crucial for improving accuracy.\n\n- **Breakthrough experimental results**: The system achieves 42.9% success rate on the Homological Conjectures benchmark where all baseline models completely fail (scoring 0%), demonstrating the unique capability and practical value of this compound approach for conjecture-level formalization."}, "weaknesses": {"value": "- **Compound propagation risk of semantic errors**: The paper explicitly states that the GoT synthesis phase ensures only syntactic correctness and \"cannot preclude correctly-typed but semantically wrong translations,\" while AriaScorer's semantic checking is described as a final step (Figure 1(C)). This creates a critical logical gap: if a base concept (e.g., \"Cohen-Macaulay Module\" in Figure 1) is semantically incorrect during synthesis, it will serve as a syntactically valid but semantically flawed premise for synthesizing all dependent parent nodes, invalidating entire dependency branches. The paper lacks crucial discussion or experimental validation on whether AriaScorer should be iteratively applied to each node during the synthesis phase to prevent this issue.\n\n- **Insufficient explanation of contradictory phenomena in GoT ablation**: Table 5 shows that removing GoT paradoxically increases compilation rate (89%→95%) while decreasing final accuracy (71%→54%) on FATE-H. Although Section C.2 mentions this leads to \"synthesis failure\" and \"interface hallucination\" failure modes, it inadequately explains why a simpler monolithic approach systematically produces more syntactically simple (thus easier to compile) but semantically incorrect code. The fundamental mechanism of this \"high compilation, low accuracy\" failure mode remains unclear, weakening understanding of GoT's core value."}, "questions": {"value": "1. **Regarding semantic error propagation mechanism**: Is AriaScorer's semantic checking iteratively applied to each newly synthesized node during the GoT synthesis phase (Figure 1(B)), or only performed once at the end? If not iteratively applied, how does the system prevent or recover from compound semantic errors caused by intermediate definitions that are \"correctly-typed but semantically wrong\"? Is there experimental data quantifying the impact and system robustness under such error scenarios?\n\n2. **Regarding the deep mechanism of Table 5's anomaly**: Removing GoT increases compilation rate (89.0%→95.0%) but decreases accuracy (71.0%→54.0%) on FATE-H. Does this suggest that the non-GoT monolithic approach tends to produce syntactically simpler (thus easier to compile) but semantically incorrect formalizations? Can you provide concrete cases for in-depth analysis of the root cause of this \"high compilation, low accuracy\" failure mode? What does this reveal about GoT's core value (enforcing semantic structure vs. syntactic simplification)?\n\n3. **Regarding reliability of critical decision points in GoT decomposition**: This process relies on an LLM reasoner to judge whether retrieved Mathlib candidates are \"suitable matches\" and decide whether to use candidates or trigger synthesis of new concepts. Overall pipeline performance critically depends on this decision's accuracy. How is this LLM reasoner's accuracy evaluated? Is there data showing the specific impact of its erroneous decisions (e.g., deciding to synthesize an existing concept or incorrectly matching an irrelevant concept) on end-to-end performance?\n\n4. **Regarding robustness boundaries of AriaScorer**: This checker's term-level grounding depends on retrieving term information from the Herald dataset. What are AriaScorer's failure modes if Lean terms used in formalized statements are not included in this dataset, or if informal descriptions of terms in the dataset are inaccurate or ambiguous? Does the paper experimentally quantify the checker's robustness to incomplete grounding datasets? How does this affect the method's generalization capability to new domains or rapidly evolving Mathlib versions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nhWmu3I6pF", "forum": "CPxZClPMiy", "replyto": "CPxZClPMiy", "signatures": ["ICLR.cc/2026/Conference/Submission24910/Reviewer_Tkra"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24910/Reviewer_Tkra"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920069863, "cdate": 1761920069863, "tmdate": 1762943241628, "mdate": 1762943241628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents ARIA, an agent for auto-formalization of mathematical statements in Lean 4. ARIA integrates Retrieval-Augmented Generation (RAG), a Graph-of-Thought (GoT) planning mechanism, and a reflection loop guided by the Lean compiler. It also introduces AriaScorer, a semantic checker that retrieves term definitions from Mathlib for grounding-based verification. Experiments show improvements over prior baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly motivates improving statement-level formalization before theorem proving by introducing ARIA, an agent designed to convert natural language mathematical statements into Lean 4 formalizations.\n\n2. It presents a well-structured and competently engineered system that integrates Retrieval-Augmented Generation (RAG), a Graph-of-Thought (GoT) planning mechanism, and a reflection loop guided by the Lean compiler, alongside AriaScorer, a semantic checker leveraging Mathlib for grounding-based verification.\n\n3.It evaluates the model on various benchmarks, including conjecture-level tasks."}, "weaknesses": {"value": "1. The paper claims novelty by integrating RAG, GoT, and the reflection loop guided by the Lean compiler. However, each of these components already exists in prior work. ARIA merely combines these elements without introducing a new algorithmic principle or theoretical insight. This makes the paper engineering incremental rather than conceptually innovative\n2. The core metric is defined using AriaScorer, a tool introduced in the same paper, which introduces a potential self-evaluation bias: the observed performance gains may reflect alignment with the metric rather than genuine capability. Furthermore, only the Conjectures dataset has been human-verified, leaving the main benchmarks unchecked. Alternative metrics for autoformalizers, such as typecheck and BEq [1], exist, and reporting results under these metrics would provide a more robust and credible evaluation.\n3. Table 1 compares ARIA with Goedel-V2, although most results reported are for pass@1. However, “pass@k” sampling is not equivalent to multi-stage agentic reasoning. Additionally, regarding the Conjectures dataset, I would like to ask why ARIA exhibits such a significant advantage on this data. It seems likely that other models may not have encountered this type of data during training, resulting in 0% accuracy for those models.\n\n[1] Qi Liu, Xinhao Zheng, Xudong Lu, Qinxiang Cao, Junchi Yan. Rethinking and Improving Autoformalization: Towards a Faithful Metric and a Dependency Retrieval-based Approach"}, "questions": {"value": "Please refer to the Weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ipyjYzPCnw", "forum": "CPxZClPMiy", "replyto": "CPxZClPMiy", "signatures": ["ICLR.cc/2026/Conference/Submission24910/Reviewer_ZfvQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24910/Reviewer_ZfvQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926755623, "cdate": 1761926755623, "tmdate": 1762943241404, "mdate": 1762943241404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **ARIA**, an agent for translating informal mathematical statements into Lean code through **Graph-of-Thought (GoT)** reasoning, **retrieval-augmented generation (RAG)** from Mathlib, and a **compiler-in-the-loop** feedback mechanism. It also introduces **AriaScorer**, a term-grounded semantic checker ensuring meaning consistency between informal and formal statements. Experiments on **ProofNet**, **FATE**, and real conjectures show **state-of-the-art** performance, demonstrating ARIA’s ability to handle complex, research-level formalization tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Introduces a **dependency-graph (GoT)** framework that mirrors human reasoning, enabling structured decomposition and synthesis of unseen mathematical concepts.\n- Combines **RAG grounding**, **GoT planning**, and **compiler reflection** into a robust, self-correcting pipeline, with solid ablation evidence.\n- Well-structured and clearly illustrated; figures and examples effectively explain the dependency graph process.\n- Achieves **research-level formalization** beyond prior methods and improves semantic reliability through **term-level grounding** (AriaScorer)."}, "weaknesses": {"value": "- The paper does not provide the detailed prompts used in the key stages—decomposition, grounding, synthesis, and reflection. Since the entire pipeline relies on prompt-driven reasoning, the absence of these examples makes it difficult to reproduce the workflow or evaluate design choices. Including representative prompts or templates would significantly improve clarity and reproducibility.  \n\n- All experiments are conducted on datasets from algebra and commutative algebra, limiting the demonstrated generality of ARIA. It remains unclear whether the dependency-graph and grounding strategies would perform equally well in other mathematical domains such as analysis, topology, or geometry. Broader testing or discussion on domain adaptation would strengthen the paper’s scope and impact.\n\n- The LeanSearch component relies on a locally indexed Mathlib database, which introduces significant computational and storage overhead. A discussion of indexing efficiency, caching, or alternative lightweight retrieval strategies would make the system more practical for large-scale or real-time deployment."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VjfafqkG0l", "forum": "CPxZClPMiy", "replyto": "CPxZClPMiy", "signatures": ["ICLR.cc/2026/Conference/Submission24910/Reviewer_vbY2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24910/Reviewer_vbY2"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission24910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928525325, "cdate": 1761928525325, "tmdate": 1762943241201, "mdate": 1762943241201, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce two contributions, Aria, an autoformalization method/pipeline which decomposes and grounds an informal statement in Mathlib to ensure correctness, and AriaScore, a new metric which improves upon other alignment scorers such as LeanScore and back-translation. The authors conduct experiments to demonstrate the effectiveness of their contributions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "Both AriaScore and Aria are significant contributions to the community. The authors conduct experiments and error analyses to show that AriaScore performs better at measuring alignment than previous metrics. The authors also show that each of their three components in Aria are important to high performance as shown by an ablation study. Overall, the authors do a good job supporting their claims and have a strong contribution."}, "weaknesses": {"value": "I think it's worth distinguishing this approach from papers such as (Liu et al, 2025), which also do RAG autoformalization.\n\nAn error analysis of the components of Aria would be very useful to understanding how this method improves. The authors make a claim (~L361) that hallucination of incorrect interfaces is the main source of error. However, why does a single-retrieval RAG system not accomplish a similar improvement in that case? Or perhaps it does, but just not to the same degree? Your ablation study answers this to some extent. But I believe an error analysis would be most beneficial."}, "questions": {"value": "How does your system know the **informal** definitions of things it can't find in Mathlib, e.g., Cohen-Macaulay Module? My understanding is that this would be necessary information to be able to continue breaking down the definition into grounded terms, but I'm not clear on how this works.\n\nWhile it's not in autoformalization, a similar technique as your \"reflection\" module has been used in similar fields such as automated theorem proving (see: COPRA from Thakur et al. 2024) among others. Maybe worth mentioning in related works."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zLsFtcrOTI", "forum": "CPxZClPMiy", "replyto": "CPxZClPMiy", "signatures": ["ICLR.cc/2026/Conference/Submission24910/Reviewer_YbKa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24910/Reviewer_YbKa"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission24910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762039724981, "cdate": 1762039724981, "tmdate": 1762943240867, "mdate": 1762943240867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}