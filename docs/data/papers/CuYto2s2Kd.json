{"id": "CuYto2s2Kd", "number": 5256, "cdate": 1757879387599, "mdate": 1759897984835, "content": {"title": "Automating Structural Engineering Workflows with Large Language Model Agents", "abstract": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows. Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size. Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization—capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities. We present a proof-of-concept showing that most real-world structural engineering workflows can be fully automated through a training-free LLM-based multi-agent system. MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios.", "tldr": "", "keywords": ["Large Language Models", "Multi-Agent Systems", "Structural Engineering"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b89bbca7cef61e41d40e8de4db585181058cca2f.pdf", "supplementary_material": "/attachment/8c20df9c5121384d8a4d7738868a8e644113ec5e.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces MASSE, a multi-agent LLM system designed to automate complex structural engineering workflows. It addresses the observed failure of single-agent LLMs on long-horizon, multi-tool tasks by decomposing the problem. MASSE mimics a real-world engineering firm, structuring agents into \"Analyst,\" \"Engineer,\" and \"Management\" teams to handle data extraction, FEM analysis, and final safety verification."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a high-value problem in a traditionally inefficient industry. The 98% reduction in expert workload is a massive and compelling result that clearly demonstrates the system's practical value.\n2. The multi-agent architecture, which mirrors a real-world organizational structure (Analyst, Engineer, Manager), is an intelligent solution for decomposing a complex task that single agents fail to solve."}, "weaknesses": {"value": "1. The entire system and its impressive results are demonstrated on a single, specific task: \"racking system design\". Claims that the framework is \"plug-and-play\"  for other, more complex structural engineering tasks are unsubstantiated.\n2. The system appears highly reliant on a pre-defined set of tools and specific Python scripts. This \"brittleness\" may mean it cannot adapt to new problems or different engineering software without significant manual re-engineering.\n3. The LLM agents often seem to act as \"controllers\" that primarily call pre-defined functions and pass structured JSON data. This raises questions about how much novel engineering reasoning is being done by the AI versus how much it is simply executing a very well-defined, pre-scripted workflow."}, "questions": {"value": "How would the system's runtime and token consumption scale to a more complex, 3D structural problem with hundreds of elements and multiple load combinations, as opposed to the 2D frame analyzed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AvfnavCaRL", "forum": "CuYto2s2Kd", "replyto": "CuYto2s2Kd", "signatures": ["ICLR.cc/2026/Conference/Submission5256/Reviewer_W7cr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5256/Reviewer_W7cr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635344163, "cdate": 1761635344163, "tmdate": 1762917976134, "mdate": 1762917976134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MASSE (Multi-Agent System for Structural Engineering), a training-free LLM-based framework designed to automate structural engineering workflows. The system employs specialized agents organized into three teams (Analyst, Engineer, and Management) that coordinate to perform tasks including code interpretation, load calculations, FEM analysis, and structural verification. The authors evaluate MASSE on 100 racking system design cases and report 98% time reduction compared to human engineers (from ~2 hours to ~2 minutes)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Structural engineering is a high-stakes, traditionally manual field where automation could deliver substantial societal benefit. The motivation for applying AI to this domain is compelling.\n2. The three-team architecture (Analyst, Engineer, Management) with 9+ specialized agents demonstrates thoughtful decomposition of complex engineering workflows into manageable subtasks.\n3. The human evaluation with 11 experienced engineers provides meaningful evidence of practical utility, showing dramatic efficiency improvements.\n4. The focus on structured communication (JSON), logging, and explainability aligns well with engineering practice requirements for verification and accountability.\n5. Integration of OpenSeesPy for FEM analysis and RAG for building code retrieval shows proper engagement with domain-specific requirements."}, "weaknesses": {"value": "1. Evaluation focuses exclusively on racking system design. Claims about broader applicability to structural engineering (bridges, buildings, etc.) are unsupported. \n3. Real structural engineering involves many tasks not demonstrated: irregular geometries, nonlinear analysis, soil-structure interaction, construction sequencing, cost optimization.\n3. 100 cases from one geographic region (British Columbia) with reorganized/anonymized data limits reproducibility and generalization assessment.\n4. Commercial structural engineering software (SAP2000, ETABS). Other AutoML or AI-assisted engineering tools. Simpler single-agent approaches with stronger models (o1-preview, Claude Sonnet 4)\n5. Verification gaps: The \"Verification Engineer\" agent checks only basic limit states. Real engineering requires: 1) Progressive collapse analysis. 2) Connection design. 3) Fatigue assessment. 4) Serviceability checks beyond what's mentioned.\n6. Temperature settings vary across models (0 for some, 1 for o4-mini) without justification\nAgent communication rounds limited to 4 without exploration of optimal values\nNo ablation on number of agents or team composition\n7. Figure 1 analogy oversimplifies the human-AI collaboration complexity. Figure 3 is dense and difficult to parse quickly. Appendices are extensive (26 pages) but critical details scattered throughout.\n8. JSON communication protocol (Section 4.2): While structured formats help, the paper doesn't address: 1) Schema validation failures. 2) Version compatibility across agents. 4) Recovery from malformed JSON.\n9. The paper mentions other systems use \"expensive large models\" but doesn't compare against these directly on the same tasks. Failure mode analysis: Figure 2 shows single-agent failures (formatting 20%, dependency 50%, logic 30%) but: 1) lacks analysis of multi-agent failure modes. 2) lacks discussion of cascading errors. 3) lacks quantification of error propagation."}, "questions": {"value": "1. How does MASSE handle non-standard structural systems that don't fit the predefined agent workflows?\n2. What happens when the Safety Manager declares a structure inadequate? Is there an iterative redesign capability?\n3. Can you provide evidence that GPT-5's evaluation judgments align with human expert assessments?\n4. What is the false negative rate for safety assessments on a validation set with known failures?\n5. How would MASSE extend to 3D structural analysis, nonlinear behavior, or composite structures?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AVFV64PTgK", "forum": "CuYto2s2Kd", "replyto": "CuYto2s2Kd", "signatures": ["ICLR.cc/2026/Conference/Submission5256/Reviewer_VVfQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5256/Reviewer_VVfQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773509105, "cdate": 1761773509105, "tmdate": 1762917975082, "mdate": 1762917975082, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MASSE, a Multi-Agent System for Structural Engineering, designed to automate real-world engineering workflows using LLM-based agents. The system mimics professional practice by assigning specialized roles (Analyst, Engineer, Manager) and coordinating their collaboration through structured communication protocols (JSON I/O, shared memory). MASSE integrates finite element (FEM) tools, building codes, and reasoning LLMs like GPT-4o and o4-mini.\n\nThe authors evaluate MASSE on realistic racking-system design tasks, benchmarking across four custom datasets (SAAB, SDAB, LAB, MASEB). An ablation study confirms the benefit of structured memory and JSON-based I/O. Overall, MASSE demonstrates that multi-agent LLM frameworks can automate tool-driven, safety-critical workflows in structural engineering without additional training."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "MASSE represents the first systematic attempt to model structural-engineering workflows through role-specialized LLM agents. Prior work focuses on isolated subtasks (e.g., load calculation, text-to-code), whereas MASSE unifies the full workflow from data extraction to final safety verification.\n\nThe system design is clear and well-engineered, featuring persistent structured memory, JSON schemas for inter-agent communication, and integration with FEM solvers. The ablation study convincingly shows why these components matter."}, "weaknesses": {"value": "No quantitative validation: MASSE’s outputs aren’t compared to ground-truth engineering calculations; accuracy claims lack numerical error metrics.\n\nBenchmarks are internal: SAAB/SDAB/LAB/MASEB are self-defined and not externally verified, limiting reproducibility.\n\nNarrow scope: Experiments focus only on racking systems; generalization to broader structural types is untested.\n\nMissing failure analysis: The paper reports only successful runs; reliability or error-rate data are absent.\n\nWeak human study: The 98% time-saving result measures speed, not correctness or safety, with no control group.\n\n\nAblation limited: Only memory and JSON are tested; other design choices (role hierarchy, safety logic) remain unexplained."}, "questions": {"value": "How does MASSE handle ambiguous or contradictory information in building codes (e.g., conflicting load provisions across regions)?\n\nDid you test MASSE on non-racking tasks such as reinforced-concrete beam design to assess generality?\n\nHow are errors detected and recovered when agents produce inconsistent JSON outputs?\n\nWhat mechanisms prevent “hallucinated” code or unsafe load assumptions when no ground truth is available?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w42oNluQH0", "forum": "CuYto2s2Kd", "replyto": "CuYto2s2Kd", "signatures": ["ICLR.cc/2026/Conference/Submission5256/Reviewer_3mAS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5256/Reviewer_3mAS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916238844, "cdate": 1761916238844, "tmdate": 1762917974820, "mdate": 1762917974820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MASSE, a pioneering multi-agent system that automates structural engineering workflows by leveraging large language models (LLMs). The authors highlight that traditional structural engineering processes are manual, inefficient, and resistant to digital transformation, motivating the need for automation. MASSE addresses this by orchestrating specialized LLM agents into analyst, engineer, and management teams, each handling data extraction, modeling, analysis, and decision validation via structured communication protocols. The system is evaluated using newly proposed benchmarks and a real-world racking system dataset, showing that MASSE dramatically reduces expert workload and operating time by about 98% while maintaining or improving reliability and accuracy compared to human engineers and other LLM configurations. Detailed ablation studies demonstrate the critical impact of memory and structured communication on performance, and runtime analysis reveals a trade-off between communication rounds and efficiency. The discussion emphasizes MASSE’s transparency, safety integration, and potential for real-world impact by reallocating human expertise to higher-level oversight, and concludes that such agent-based automation could reshape engineering and related industries. Future directions include adapting MASSE for practical deployment, refining agent specializations, and enabling real-time feedback for self-improvement."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- MASSE is, to the best of current knowledge, the first comprehensive LLM-based multi-agent orchestration for structural engineering. The design closely mirrors real-world engineering team structures, introducing a novel mapping of professional roles to AI agents, and uses structured communication (JSON formats) and memory for stable, auditable automation.\n  \n- The empirical validation is thorough: the system is benchmarked against key structural engineering tasks with domain-specific metrics. Performance, efficiency, and scalability (runtime, cost) are analyzed, and ablation studies robustly demonstrate the value of system design choices (agent memory, structured I/O). The human expert comparison demonstrates a 98%+ reduction in manual effort.\n\n- The paper’s problem motivation and potential impact are well articulated. The workflow mapping, modular agent roles, and methodological pipeline are described with clarity, aided by diagrams. The structure targets both AI and engineering audiences.\n\n- Given the global economic and safety relevance of structural engineering, demonstrating that LLM-based agents can match or exceed human reliability on real tasks is an important step for trust in AI in high-stakes domains. The modular architecture and benchmarks may enable rapid transfer to other engineering or procedural professions."}, "weaknesses": {"value": "- Major implementation and experimental details are often relegated to appendices (e.g., agent instructions, simulation setups, dataset specification), making full independent assessment and reproduction difficult from the main text alone.\n\n- It is not clearly stated if or when the anonymized dataset or code will be released. Without public access or a reproducible evaluation protocol, the community may struggle to verify results or build upon the work.\n\n- While single-agent and multi-agent comparisons are made, broader benchmarks against existing automation systems (either commercial or recent LLM-powered research/industry pipelines) are lacking. The practical superiority of the multi-agent breakdown over optimized single-agent setups is not thoroughly quantified (e.g., via cost/failure mode analyses).\n\n- Little qualitative or quantitative error analysis is presented (failure cases, confusion matrices, or limitation scenarios), and statistical reporting of variance or confidence for metrics is sparse except for runtime.\n\n- The structure and blinding of human comparison tasks are not fully described, making it hard to judge the fairness and rigor of the manual vs. MASSE efficiency claims.\n\n- The claim that MASSE generalizes to other engineering/procedural domains remains speculative, with no experimental demonstration. The paper also does not deeply explore real-world adoption barriers (regulatory, integration with legacy tools, practitioner trust)."}, "questions": {"value": "- Can the authors clarify whether the anonymized dataset and code used for MASSE’s evaluation will be available to the community? The paper mentions privacy constraints and anonymization but does not specify plans for public release, which affects reproducibility and future research.\n\n- Beyond privacy constraints, could the authors clarify the nature and distribution of their case dataset (e.g., problem diversity, real vs. synthetic split, and any accessible subset for benchmarking)? Without sufficient visibility into data diversity, coverage, and public access, it will be difficult for others to fairly reproduce, benchmark, or extend your evaluation.\n\n- Can the authors provide more description/comparison to strong single-agent or non-agentic LLM baselines, including any relevant complexity (latency/memory/cost) metrics, and justify the multi-agent breakdown over these plausible alternatives? For fair assessment, it is crucial to compare multi-agent systems to optimized single-agent approaches or prior automation pipelines, reporting key trade-offs in complexity and failure modes.\n\n- Could you clarify whether the new dataset and its corresponding ground-truth solutions will be made publicly available, and if not, what measures are in place to ensure reproducibility? Reproducibility of the experimental results hinges on access to the evaluation data; limited or undisclosed data sets may impede this.\n\n- Can you provide more specifics on the structure of the human evaluation—were the 11 engineers working independently on the same instances, what were the precise tasks, and how was their output objectively compared to MASSE results? Understanding the setup, task uniformity, blinding, and scoring criteria is necessary to assess the fairness and rigor of the human vs. MASSE comparison.\n\n- Could you report more granular statistical analyses on the main benchmarks (e.g., standard deviations, confidence intervals, significance testing), not only for runtime but also for the accuracy/score metrics in Table 1? Reporting the variance and conducting statistical significance checks are critical for assessing the reliability and practical impact of performance differences between methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z7oojoEFPz", "forum": "CuYto2s2Kd", "replyto": "CuYto2s2Kd", "signatures": ["ICLR.cc/2026/Conference/Submission5256/Reviewer_EQx6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5256/Reviewer_EQx6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5256/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989376397, "cdate": 1761989376397, "tmdate": 1762917974588, "mdate": 1762917974588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}