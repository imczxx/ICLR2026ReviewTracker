{"id": "vBEbUTS81u", "number": 22384, "cdate": 1758330348413, "mdate": 1759896869339, "content": {"title": "Explainable Mixture Models through Differentiable Rule Learning", "abstract": "Mixture models excel at decomposing complex, multi-modal distributions into simpler probabilistic components, but provide no insight into the conditions under which these components arise. We introduce explainable mixture models (EMM), a framework that pairs each mixture component with a human-interpretable rule over descriptive features. This enables mixtures that are not only statistically expressive but also transparently grounded in the underlying data. We formally examine the conditions under which an EMM exactly captures a target distribution and propose a scalable, differentiable learning procedure for discovering sets of rules. Experiments on synthetic and real-world datasets demonstrate that our method discovers interesting sub-populations in both univariate and multivariate settings, offering interpretable insights into the structure of complex distributions.", "tldr": "We introduce explainable mixture models, a framework that pairs each mixture component with a human-interpretable rule over descriptive features.", "keywords": ["Mixture modeling", "Interpretability", "Conditional Density Estimation"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b6feec882b8fab1c177b7720f0583a269562be88.pdf", "supplementary_material": "/attachment/170bcdc102c298489ede2a0a8d9ad6d30fa91f60.zip"}, "replies": [{"content": {"summary": {"value": "They propose a method for explainable mixture models. The explanations created are a conjunctions of different features. The mixture model created can fit the model well and able to generate logical rules to explain the mixtures created."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Well written paper.\n* Good exploration with synthetic dataset to showcase the capability of the models.\n* Approach also fairly robust based on the synthetic dataset noise."}, "weaknesses": {"value": "* The motivation of the problem with application can be improved.\n* Many variants of their method is being introduced and it is a bit unclear on what the conclusion is between them. While they say that over NLL on real dataset is best for EMM-GMM, i am not sure how accurate it would be to claim that to be the best, as different datasets yielded different best model.\n* Some human evaluation for some real-world dataset would have been good to evaluate the goodness of the explainability.\n\nNOTE: i did not read the appendix section and my comments are purely based on main text."}, "questions": {"value": "* Are the definitions in section 3 part of contribution or is it background?? It is a bit unclear. if it is background, then it is good to add ref. for them.\n* What kind of noise is added in the robustness experiments and how much??\n* In synthetic dataset will the performance change if the data is generated from a random distribution rather than a gaussian and uniform?\n* Given the rules are logical statements can the features be continuous or do they have to be discrete/categorical for the approach to work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "bjt1mxWVkT", "forum": "vBEbUTS81u", "replyto": "vBEbUTS81u", "signatures": ["ICLR.cc/2026/Conference/Submission22384/Reviewer_utZR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22384/Reviewer_utZR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935677898, "cdate": 1761935677898, "tmdate": 1762942193392, "mdate": 1762942193392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper maximizes the conditional likelihood, where the conditional likelihood is parameterized using a mixture model, and adds a regularizer to the objective to encourage each data point to follow a unique path within the mixture. The authors design the mixture model as a rule function, providing explainability, and learnt by gradient descent."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces a novel objective function that maximizes conditional density estimation in mixture-models."}, "weaknesses": {"value": "How is this different from Mixture of Experts (MoE)?\nMoEs use a gating function to decide which expert/block to activate, and are typically trained under a maximum likelihood objective for generative modeling. I see EMMs as a special case of MoEs where the gating logic is determined by learned rules. There are many possible gating mechanisms that can yield explainability, for example by restricting the gating function to be simple. Calling these models “EMMs” and not acknowledging them as a special case of MoEs is, in my view, misleading.\n\nDefinitions are not complete\nHow do you define “human-interpretable explanation”? This is subjective. You need to either define it explicitly or give application-specific criteria before introducing Definition 1 (Marginal-EMM). Otherwise, you cannot really call it a “definition.”\n\nAlso, from Definition 1, any tree-based method would qualify as an EMM if you take the path to the node as, $e_i$. Does that mean all tree-based models are EMMs?\n\nComparison to [1]\nThis paper modifies the objective proposed in [1] for conditional density estimation. Can you provide a direct comparison with [1]? The only clear difference I see is that your objective removes the entropy term. But [1] can still be used to compute a conditional density. How does the current method compare to [1] in terms of (a) explainability and (b) test-set likelihood?\n\nI also disagree with the claim that tree-based approaches are “prone to overfitting.” Any machine learning method, deep learning models, are prone to overfitting.\n\nFinally, in Eq. (6), since $w_i$ is constrained to be positive, why do you need to square it?\n\n[1] Sascha Xu, Nils Philipp Walter, Janis Kalofolias, and Jilles Vreeken. “Learning Exceptional Subgroups by End-to-End Maximizing KL-Divergence.” ICML, 2024."}, "questions": {"value": "Can you perform an ablation on $\\lambda$, and also explain how increasing the number of mixtures affects the conditional likelihood?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cQ7aWbNHF0", "forum": "vBEbUTS81u", "replyto": "vBEbUTS81u", "signatures": ["ICLR.cc/2026/Conference/Submission22384/Reviewer_2m51"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22384/Reviewer_2m51"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965755121, "cdate": 1761965755121, "tmdate": 1762942193094, "mdate": 1762942193094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes EMM, explainable mixture model, a principled learning procedure that discovers each mixture component with a human-interpretable rule over descriptive features. Experiments on synthetic and real-world datasets demonstrate the effectiveness of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed approach is based on a principled machine learning procedure."}, "weaknesses": {"value": "The experiments are restricted to mixture models, and don't reflect the paradigm shift in the era of deep learning. The experiments should include the results that compare with deep learning models such as VAE, and whether the proposed can be extended deep learning models; the data sets are UCI which are too small, don't support the claim that the proposed method is scalable and applicable to more complex, multi-model distributions."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MYoIGNo1BL", "forum": "vBEbUTS81u", "replyto": "vBEbUTS81u", "signatures": ["ICLR.cc/2026/Conference/Submission22384/Reviewer_LLHS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22384/Reviewer_LLHS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762037795545, "cdate": 1762037795545, "tmdate": 1762942192813, "mdate": 1762942192813, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Given a set of data-value pairs $(x_i,y_i)$, where the covariates $x_i \\in \\mathbb{R}^d$, the paper proposes an explainable mixture model (EMM) approximation of the conditional density $p(y|x)$. The mixture model is conceptually proposed as follows:\n- first, the $p(y|x)$ is approximated by a weighted mixture of $k$ components\n- each component ideally represented as a box (intersection of intervals) in $\\mathbb{R}^d$ or in a lower dimension. The authors show that if the components are supported on a partition of $\\mathbb{R}^d$, then there is no error in the approximation\n- In order to apply standard optimisation to learn the parameters, each component is approximated by a  smoothed \"box\" (equation 10)\n- the mixture model parameters are learned by minimising a regularised negative log likelihood\n- some further pruning is done to reduce the number of rules learned\n\nThe authors demonstrate that the proposed EMM model provides good fit of data, while providing fewer learning rules for the explainable model.\n\nThe authors show"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The overall EMM model uses a combination of simple ideas, but learns an explainable rule-based model that consistently has fewer rules.\nThe experiments look convincing (with the caveat that I not an expert in this specific problem)"}, "weaknesses": {"value": "The paper's theoretical contribution is limited. A simple result is provided in the case where the supports of the components form a partition. However, there are no guarantees regarding the severity of the approximation error in the general case.\nI was tempted to give a low score due to this, but it turns out that this is not a concern in relevant literature (papers like CADET, CDTree).  \n\nI found parts of the papers a bit difficult to follow, which could be because I am not familiar with this line of work (and generally, less familiar with explainability literature)."}, "questions": {"value": "Could the authors explain how to read the explanation plots (for example, right hand side of Fig 7)? What do the bars and colours mean?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "9BCkgeX5E1", "forum": "vBEbUTS81u", "replyto": "vBEbUTS81u", "signatures": ["ICLR.cc/2026/Conference/Submission22384/Reviewer_ZarE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22384/Reviewer_ZarE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762215652179, "cdate": 1762215652179, "tmdate": 1762942192621, "mdate": 1762942192621, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}