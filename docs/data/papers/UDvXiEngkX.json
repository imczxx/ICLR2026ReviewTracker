{"id": "UDvXiEngkX", "number": 21805, "cdate": 1758322104920, "mdate": 1759896902187, "content": {"title": "From Noise to Signal: Enabling Foundation-Model Pretraining on Noisy, Real-World Corpora via Quality-Aware Tokenization", "abstract": "Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present *QA-Token (Quality-Aware Tokenization)*, which incorporates data reliability directly into vocabulary construction. Our framework introduces three technical contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance (proven NP-hard), (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization.\n\nWe show that QA-Token achieves information-theoretic optimality under noisy conditions, with convergence guarantees for both policy and parameter learning. Experiments demonstrate consistent improvements: *genomics* (8.9% absolute F1 gain in variant calling, Hedges' *g*=8.2), *finance* (30% Sharpe ratio improvement). At foundation scale, re-tokenizing METAGENE-1's 1.7 trillion base-pair corpus achieves state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. A 1.2B parameter financial model trained with QA-Token shows 12-27% improvements across forecasting tasks. These results demonstrate that quality-aware tokenization enables effective training on noisy corpora that standard methods cannot handle.", "tldr": "QA-Token enables foundation-model pretraining on noisy corpora by learning quality-aware vocabularies.", "keywords": ["Tokenization", "Adaptive Learning", "Reinforcement Learning", "Hyperparameter Optimization", "Genomics", "Quantitative Finance", "Natural Language Processing", "Foundation Models"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1639d13d067123686b8f3930b43c30e22ecdfcc8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces QA-Token, a quality-aware tokenization framework designed to incorporate domain-specific data reliability signals into the token merging process. The work frames tokenization as a bilevel optimization problem and employs reinforcement learning with Gumbel-Softmax to adaptively construct token vocabularies that are robust to noise. The method is evaluated on genomics and high-frequency financial domains, where the authors claim substantial gains over conventional tokenizers and character/byte-level baselines. The paper argues that this approach improves robustness and downstream task performance in naturally noisy domains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Timely and relevant motivation — modeling data quality during tokenization is a meaningful direction, especially for high-noise domains such as genomics or financial microstructure data.\n\n- Novel perspective — explicitly incorporating quality signals into the tokenizer construction process is underexplored, and the bilevel formulation is conceptually innovative.\n\n- Strong empirical gains reported — especially in genomics variant calling and financial forecasting; claims are accompanied by multiple downstream tasks and some statistical testing.\n\n- No additional inference-time cost — the added complexity is isolated to tokenizer construction, which is attractive from a practical standpoint."}, "weaknesses": {"value": "1. Baseline comparison appears incomplete and potentially unfair.\nAlthough the paper emphasizes noise robustness as the core motivation, all experimental baselines are standard tokenizers (BPE, WordPiece, SentencePiece, etc.). There is no comparison against data denoising / filtering / quality-weighted sampling / robust preprocessing pipelines, which are widely used in both genomics and financial modeling. Since the paper positions itself as addressing noise, not purely tokenization, this omission leaves the evaluation incomplete.\n\n2. The method does not appear truly “general” or domain-agnostic as claimed.\nThe framework requires explicit per-domain manual design of quality functions (e.g., Phred-based scoring for genomics vs. MI/volatility-based metrics for finance), and these formulations differ substantially. This suggests a domain-tailored architecture rather than a general-purpose quality-aware tokenizer. The current framing may be somewhat overstated relative to its actual scope.\n\n3. Clarity and reproducibility are not yet at publishable standard.\n- No code or implementation is currently released, so reproducibility cannot be assessed.\n- The presentation lacks an early and clear articulation of the exact research question and evaluation setup. Benchmarks and baseline selection logic are spread across sections rather than systematically introduced.\n- It is occasionally difficult to trace how the proposed tokenizer concretely integrates into pipelines like BWA-MEM → GATK in genomics, which do not typically depend on tokenization.\n\n4. Potential risk of information leakage in the financial evaluation.\nThe mutual-information-based quality metric appears to condition on future returns. Unless the authors enforce strict causal rolling windows with no lookahead during tokenizer training, the reported financial results may be artificially inflated."}, "questions": {"value": "1. Can you confirm whether q_info in the financial domain is computed using strictly causal, horizon-appropriate rolling windows without access to future returns at tokenizer construction time?\n\n2. Why are noise-removal or robust data filtering baselines not included, given that noise handling is the central motivation of this work?\n\n3. Would you agree that the current method is domain-tailored rather than universal? If so, would revising the framing away from a “general-purpose” claim be more accurate?\n\n4. Could you clarify how the tokenizer interacts with the genomics variant-calling pipeline, which typically does not tokenize sequences? A schematic would be helpful.\n\n5. Will code and tokenizer configs be released to ensure reproducibility, as strongly expected by ICLR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dVyqwSlC4L", "forum": "UDvXiEngkX", "replyto": "UDvXiEngkX", "signatures": ["ICLR.cc/2026/Conference/Submission21805/Reviewer_nZxw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21805/Reviewer_nZxw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21805/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753735136, "cdate": 1761753735136, "tmdate": 1762941936933, "mdate": 1762941936933, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces QA-Token, a quality-aware tokenizer designed for learning robust tokenization under noisy data conditions (e.g., genomics, finance, and social text. The authors formalize tokenization as a bilevel optimization problem balancing downstream model likelihood, vocabulary complexity, and a reliability reward Q(V,Z).\nAnd the paper proposed a reinforcement learning algorithm to solve this bilevel optimization problem approximately, with convergence guarantee. \nThey also use Gumbel-Softmax relaxation to achieve end to end learning of quality sensitivity parameters.\nExperiments on genomics, finance, and text corpora show consistent gains and reduced token length."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper targets an underexplored but practically important problem: tokenization under measurement noise, which is crucial in many domains.\n2. The bilevel formulation, NP-hardness proof, and derivation of the quality-aware merge score are mathematically sound and well integrated.\n3. Propose a clear reinforcement learning algorithm to implement.\n4. The experiment showstrong and consistent improvements across multiple noisy domains"}, "weaknesses": {"value": "1. No significant weakness. just one minor: The approach assumes availability of per-symbol quality (e.g., Phred scores), which may not generalize to other kind noised data."}, "questions": {"value": "1. Can you find more fields with noised data and we can easily get quality score q_t? Can we also apply this tokenizer technique to such fields?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "qGaqEmtenF", "forum": "UDvXiEngkX", "replyto": "UDvXiEngkX", "signatures": ["ICLR.cc/2026/Conference/Submission21805/Reviewer_AJ7S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21805/Reviewer_AJ7S"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21805/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860693337, "cdate": 1761860693337, "tmdate": 1762941936549, "mdate": 1762941936549, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces QA-Token, a novel tokenization framework that uses reinforcement learning to construct vocabularies based on data quality. The authors verify the effectiveness of the method on multiple domains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The core idea of making tokenization \"quality-aware\" is an important research direction.\n2. The paper is very ambitious in its scope. It proposes a general framework and applies it to multiple domains.\n3. The paper reports performance gains over the baselines it compares against"}, "weaknesses": {"value": "1. The proposed method is very complex and expensive compared to standard tokenizers:\n\n(a) The authors report using 50-60 GPU-hours on a A100 for tokenization, which is just a preprocessing step. This cost is very expensive for a preprocessing step, especially compared to other tokenization methods. Moreover, the network trained for RL policy is very small. It is unclear why so much time is needed for training such a tiny network.\n\n(b) The method uses heavy reinforcement learning and optimization techniques to solve problems that don't need it. For example: in genomics, it \"rediscovers\" codons as meaningful tokens. Codons have been known for a long time as the fundamental units of genetic code. You could have actually baked this information from the start into the tokenizer [1].\n\nUltimately, the framework feels like a solution in search of a problem. The authors have built a computationally intensive and over-engineered system that in the genomics case rediscovers established domain knowledge.\n\n2. Ambiguity in experimental setup: the paper is not fully explicit about the training process for the foundation models. While the context implies training from scratch, this should be clearly stated. \n\n3. While the paper does the evaluation across multiple domains, I believe each of these domains warrant a more personalized solution given their unique characteristics and complexity. It would have been better if the authors focused on a single domain, instead of pursuing the universality. For instance in genomics recently there were proposed several interesting biologically-informed architectures [2, 3]. \n\n4. Evaluation lacks depth and insight. Beyond the choice of baselines, the paper's evaluation on multiple domains prevents a deep and comprehensive evaluation within any single field. A more focused study would have allowed for a much richer and conclusive analysis whether the method is useful or not.\n\n5. The paper's central premise is that its framework can unlock the value in noisy datasets. However, it doesn't adequately compare its approach against a good data curation baseline. It would be interesting to see an experiment where a standard tokenizer like BPE is trained only on a high-quality subset of the data.\n\n6. Paper has **18** !!! missing references (highlighted by ?? in PDF file).\n\n7. No code for experiments is provided in supplementary material.\n\n[1] BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models, 2025 Medvedev et. al.\n\n[2] A DNA language model based on multispecies alignment predicts the effects of genome-wide variants, 2025 Benegas et. al.\n\n[3] A Phylogenetic Approach to Genomic Language Modeling, 2025 Albors et. al."}, "questions": {"value": "1. Could you please confirm whether the METAGENE-1 and the 1.2B financial foundation models were trained from scratch using your new tokenizers?\n2. Have you considered comparing your method in the genomics domain to a simpler knowledge-driven tokenizer that directly encodes known biological motifs like codons such as [1] referenced above? \n3. The training time of 50-60 GPU-hours for the RL policy seems exceptionally high for what is described as a small network. Could you provide a breakdown of where this computational time is spent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3JYKZI95pq", "forum": "UDvXiEngkX", "replyto": "UDvXiEngkX", "signatures": ["ICLR.cc/2026/Conference/Submission21805/Reviewer_b3bG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21805/Reviewer_b3bG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21805/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939291131, "cdate": 1761939291131, "tmdate": 1762941936243, "mdate": 1762941936243, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper argues that tokenization should account for data quality when corpora are noisy, and proposes QA-Token, a framework that builds vocabularies with explicit quality signals. The method formalizes tokenization as a bilevel objective balancing downstream LM performance, vocabulary complexity, and reliability, derives a quality-aware merge score, uses an RL policy to pick merges under a multi-objective reward, and then learns quality-sensitivity parameters with a Gumbel-Softmax relaxation. Domain instantiations for genomics and quantitative finance show sizable gains. On simulated and real genomics tasks, QA-BPE-seq improves variant calling and related benchmarks, in finance, QAT-QF improves predictive and trading metrics; and at foundation scale, re-tokenizing a 7B metagenomic model lifts pathogen detection while reducing tokens. \n\nThe claim is that once the vocabulary is built, there is no extra inference-time cost, so the one-off training overhead amortizes over large deployments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper presents a coherent end-to-end story linking a well-motivated problem to concrete algorithmic choices and convincing empirical payoffs. Theoretical framing (bilevel objective, NP-hardness, approximation via RL, and two-timescale adaptive learning) provides a principled backbone and clarifies why frequency-only tokenization is brittle under heterogeneous noise. \n\nThe derived merge score usefully factors association strength with a concave quality aggregator and domain constraints, aligning the math with the intuition that high-quality regions should be merged more aggressively. \n\nEmpirically, the genomics section is notably strong. Improvements are consistent across diverse tasks and the foundation-scale experiment demonstrates that retokenization can both reduce the token budget and improve accuracy.\n\nThe finance instantiation is also thoughtfully engineered, with a clear slate of baselines and a broad metric suite, and the paper is upfront about compute and runtime characteristics, including that inference speed matches standard BPE once the vocab is fixed."}, "weaknesses": {"value": "The finance setup risks information leakage because one of the quality components directly uses mutual information with future returns, unless those statistics are computed strictly within the training window and never refreshed with validation/test periods, the tokenizer could be indirectly exposed to test labels. The paper should make this protocol airtight and quantify the impact of removing this component. Beyond leakage, the finance validation is concentrated on BTC/USD for a single quarter; results may be regime- or asset-specific, and the broader coverage hinted at in appendices would be more convincing in the main paper. While the theory is well-developed, many assumptions (stability, boundedness, adaptive submodularity conditions) sit in the appendices; surfacing the practical scope and likely failure modes would help readers understand when guarantees apply. Finally, sensitivity and cost–benefit analyses feel underplayed given the extra training overhead. Readers would benefit from explicit curves showing performance vs. quality-sensitivity parameters, batch size, and vocabulary size, and from a clearer return-on-investment picture that relates RL/adaptive hours to downstream gains at different scales."}, "questions": {"value": "- How do you guarantee no look-ahead when computing the “information quality” term in finance, which depends on mutual information with future returns? A strict train-only estimation and a “no-MI” ablation would de-risk leakage and clarify how much this component drives gains. \n\n- Can you promote the cross-asset and out-of-sample extensions now in the appendix (e.g., AAPL) into the main text and add rolling-window results? This would demonstrate robustness beyond a single asset/regime. \n\n- Could you provide sensitivity curves for the learned quality exponent and other adaptive parameters, as well as batch size and vocabulary size? This would help practitioners tune QA-Token and understand stability.\n\n- Which core assumptions behind the approximation and convergence guarantees are most likely to be violated in practice, and how should users detect and mitigate those cases? A brief “when guarantees fail” section in the main text would increase trust."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nyQPHMQXjr", "forum": "UDvXiEngkX", "replyto": "UDvXiEngkX", "signatures": ["ICLR.cc/2026/Conference/Submission21805/Reviewer_G2mF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21805/Reviewer_G2mF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21805/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987756782, "cdate": 1761987756782, "tmdate": 1762941935911, "mdate": 1762941935911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}