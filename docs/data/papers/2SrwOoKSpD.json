{"id": "2SrwOoKSpD", "number": 11188, "cdate": 1758192600544, "mdate": 1763001268571, "content": {"title": "Quasi-Orthogonal Model Merging for Continual Learning", "abstract": "Continual learning (CL) seeks to enable models to acquire new tasks sequentially without overwriting prior knowledge. Recently, model merging has emerged as a promising paradigm, where task vectors, i.e., parameter updates induced by fine-tuning, are combined across tasks. However, naive sequential merging often suffers from interference when task vectors overlap in conflicting directions. We introduce Quasi-Orthogonal Model Merging (QOMM), a unified framework that mitigates such interference through two complementary strategies. First, QOMM employs Singular Value Decomposition (SVD) to extract the dominant subspace of previously merged task vectors, and projects each new vector onto its approximate orthogonal complement. This Quasi-Orthogonal Projection (QOP) filters out conflicting directions, reducing interference. Second, QOMM integrates Attention-Exclusive Fine-Tuning (AEFT), which restricts updates to Transformer attention layers. This yields task vectors that are naturally more orthogonal, enhancing the effectiveness of QOP. By combining orthogonality-aware merging with attention-exclusive fine-tuning, QOMM achieves a better balance between stability (retaining past knowledge) and plasticity (adapting to new tasks). Experiments on standard CL benchmarks demonstrate that QOMM consistently outperforms prior methods. Our code will be released.", "tldr": "", "keywords": ["Continual Learning", "Model Merging"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/c808f54abd4719491ba1c053cf0197a9fbc85b25.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Quasi-Orthogonal Model Merging (QOMM) for merging-based continual learning. Specifically, Quasi-Orthogonal Projection (QOP) is introduced to mitigate conflicts when merging task vectors, and Attention-Exclusive Fine-Tuning (AEFT) is utilized to enhance the orthogonality among task vectors."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation of the proposed method is clear. Parameter optimization in an orthogonal space is a well-recognized and effective approach in continual learning.\n2. The paper is clearly written and easy to follow."}, "weaknesses": {"value": "1. My major concern lies in the absence of evaluation metrics. In continual learning, it is important to assess the trade-off between stability and plasticity using both average accuracy and backward transfer (BWT). Neglecting the BWT metric undermines the credibility of the experimental results. Moreover, the experiments are not repeated with different seeds, nor are the mean and variance reported. As the randomness of dataset partition and model training can significantly affect the continual learning process, this omission raises concerns about the robustness of the proposed method's performance.\n2. In the setting of domain-incremental learning (DIL), the proposed method does not achieve better performance compared to pervious works. Notably, EWC was introduced as early as 2017, yet the authors provide no analysis or discussion to explain why their method fails to surpass such earlier baselines.\n3. Several existing works in continual learning adopt similar ideas of model merging (often referred to as interpolation, ensembling, etc.), but none of these are included in the experimental comparison. The authors are strongly encouraged to include a more comprehensive discussion on the relationship between QOMM and these prior works, as many relevant studies are currently omitted.\n\n[1]  Stojanovski, Z., Roth, K., and Akata, Z. Momentum-based weight interpolation of strong zero-shot models for con tinual learning. In NeurIPS Workshop, 2022.\n\n[2]  Simon, C., Faraki, M., Tsai, Y.-H., Yu, X., Schulter, S., Suh, Y., Harandi, M., and Chandraker, M. On generalizing beyond domains in cross-domain continual learning. In CVPR, 2022.\n\n[3]  Lee, J., Joo, D., Hong, H. G., and Kim, J. Residual continual learning. In AAAI, 2020.\n\n[4]  Lin, G., Chu, H., and Lai, H. Towards better plasticity stability trade-off in incremental learning: A simple linear connector. In CVPR, 2022.\n\n[5]  Marouf, I. E., Roy, S., Tartaglione, E., and Lathuili`ere, S. Weighted ensemble models are strong continual learners. In ECCV, 2024.\n\n[6] Li, M., Lu, Y., Dai, Q., Huang, S., Ding, Y., Lu, H., BECAME: Bayesian Continual Learning with Adaptive Model Merging. In ICML, 2025."}, "questions": {"value": "1. In the ablation study and Table 3, a naive baseline, i.e., a variant without QOP, should be added to more clearly demonstrate the contribution of QOP to overall performance.\n2. The model used in experiments is a pre-trained CLIP. Considering the datasets used in experiments are relatively simple for this powerful model, I am wondering if the proposed method can attain consistent performance when using different models, such as ViT model from scratch, or smaller models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HVC1BD04ue", "forum": "2SrwOoKSpD", "replyto": "2SrwOoKSpD", "signatures": ["ICLR.cc/2026/Conference/Submission11188/Reviewer_MYPy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11188/Reviewer_MYPy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641581076, "cdate": 1761641581076, "tmdate": 1762922342373, "mdate": 1762922342373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "DrSohDIgwm", "forum": "2SrwOoKSpD", "replyto": "2SrwOoKSpD", "signatures": ["ICLR.cc/2026/Conference/Submission11188/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11188/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763001267541, "cdate": 1763001267541, "tmdate": 1763001267541, "mdate": 1763001267541, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a continual learning method based on model merging. To mitigate the interference caused by sequential merging, it proposes the Quasi-Orthogonal Model Merging method (QOMM) that projects the new task vectors to the basis of previously merged task vectors, and filters out components parallel to previous task vectors. To encourage orthogonality of task vectors, the paper restricts updates only to Transformer attention layers. The paper conducts experiments over regularization-based CL methods and model merging methods. Results show that the proposed method achieves better performance in CIL."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Applying model merging methods to CL is an emerging topic and has potential to reduce forgetting for large scale models. \n\n2. The experiments are conducted over both CIL and DIL settings, with comparison to many existing models. The ablation study is included."}, "weaknesses": {"value": "1. It is unclear why Quasi-Orthogonal projection (QOP) achieves a better balance between stability and plasticity. \n- Filtering new task vector components that are in the same directions of previous task vectors is a strong regularization, which may harm the model’s plasticity. In addition, scaling the parameter updates to be close to the pre-trained model may intensify the problem. \n- In experiments Table 3, using QOP only underperforms EWC when the number of data subsets is more than 20.   \n\n2. The hypothesis ‘constraining fine-tuning to attention-related linear layers yields more orthogonal task vectors’ is interesting. However, to support the hypothesis, some details of figure 3 are missing. \n- What are the settings of FMFT and AEFT training? Do FMFT and AEFT share the same learning rates and training epochs? Since the cosine similarity ranges in [-1,1], should the $M^{diff}$ be computed over absolute $M^{FMFT}$ and $M^{AEFT}$?\n\n3. The experiments only compare with regularization based CL baselines (LwF and EWC) besides model merging methods. It could be helpful to see how QOMM performs compared to more recent CL methods."}, "questions": {"value": "1. In experimental result Table 3, using QOP only has a large performance gap compared to  QOP + AEFT.  Does that mean the improvement of QOMM only comes from AEFT? Will adding AEFT to other methods like EWC, MAGMAX achieve better performance than QOP + AEFT (QOMM)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lKnKDTRm72", "forum": "2SrwOoKSpD", "replyto": "2SrwOoKSpD", "signatures": ["ICLR.cc/2026/Conference/Submission11188/Reviewer_RVGH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11188/Reviewer_RVGH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978109459, "cdate": 1761978109459, "tmdate": 1762922341935, "mdate": 1762922341935, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Quasi-Orthogonal Model Merging (QOMM), a continual learning framework that aims to mitigate task interference when merging task-specific models. The approach operates in two stages: first, it performs Quasi-Orthogonal Projection (QOP) by identifying the dominant singular subspace of previously merged task vectors and projecting each new task vector onto its approximate orthogonal complement, thereby filtering out conflicting directions. Second, it applies Attention-Exclusive Fine-Tuning (AEFT), which restricts parameter updates to Transformer attention layers to promote greater orthogonality among task vectors. The authors argue that this combination allows for a better balance between stability and plasticity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well written and presents a clear and coherent formulation of the proposed method. The motivation for addressing task interference in merging-based continual learning is relevant, especially as model merging continues to gain traction as an alternative to replay- or regularization-based CL. The authors present the mathematical formulation of their projection mechanism in detail, and the integration of an orthogonality-aware update rule with attention-exclusive fine-tuning is articulated clearly."}, "weaknesses": {"value": "Despite its good presentation, the paper’s conceptual contribution is limited. Orthogonal updates have been extensively studied in continual learning and model merging, and the notion of constraining new updates to the orthogonal complement of previously learned subspaces has appeared in various forms (e.g., OWM, OGD, SGP, O-LoRA, and others). The proposed Quasi-Orthogonal Projection mainly rephrases this idea in the context of task-vector merging and employs a low-rank approximation via SVD, which is not a fundamentally novel insight. Similarly, restricting fine-tuning to attention layers (AEFT) has been explored previously, including in recent studies like InfLoRA [1] and O-LoRA, where adapters or low-rank components are made orthogonal across tasks, a formulation that is very close to QOMM but more computationally efficient since it updates only low-rank modules instead of full-rank weight matrices. These prior works, along with others like SD-LoRA [2] and DualPrompt [3] or CODA-Prompt [4] for continual transformers, are not discussed, even though they offer directly comparable or superior trade-offs between efficiency and orthogonality.\n\nFrom a methodological standpoint, the work does not provide new theoretical insights into why quasi-orthogonal projections at the model-merging level should outperform standard orthogonal or subspace-constrained methods. The low-rank approximation and scaling factor are introduced heuristically, without analysis of stability, convergence, or computational complexity. Although the authors highlight memory efficiency, they do not quantify the computational overhead of repeated SVD operations or compare it against lighter-weight alternatives like LoRA-based orthogonalization.\n\nIn the experiments, results are limited to CL benchmarks using CLIP/ViT-B16 backbones, and while performance improvements over MagMax are consistent, they are relatively modest considering the additional computational cost. The related work section would benefit from a deeper integration of recent literature on parameter-efficient continual adaptation, especially orthogonal low-rank methods and prompt-based tuning, to better contextualize the contribution. Overall, the work feels incremental rather than offering a significant conceptual or empirical advance.\n\n[1] Liang, Y.S. and Li, W.J., 2024. Inflora: Interference-free low-rank adaptation for continual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 23638-23647).\n\n[2] Wu, Y., Piao, H., Huang, L.K., Wang, R., Li, W., Pfister, H., Meng, D., Ma, K. and Wei, Y., SD-LoRA: Scalable Decoupled Low-Rank Adaptation for Class Incremental Learning. In The Thirteenth International Conference on Learning Representations.\n\n[3] Wang, Z., Zhang, Z., Ebrahimi, S., Sun, R., Zhang, H., Lee, C.Y., Ren, X., Su, G., Perot, V., Dy, J. and Pfister, T., 2022, October. Dualprompt: Complementary prompting for rehearsal-free continual learning. In European conference on computer vision (pp. 631-648). Cham: Springer Nature Switzerland.\n\n[4] Smith, J.S., Karlinsky, L., Gutta, V., Cascante-Bonilla, P., Kim, D., Arbelle, A., Panda, R., Feris, R. and Kira, Z., 2023. Coda-prompt: Continual decomposed attention-based prompting for rehearsal-free continual learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 11909-11919)."}, "questions": {"value": "•  How does QOMM compare empirically and computationally (in terms of FLOPs, runtime, and memory footprint) with low-rank orthogonal methods such as InfLoRA or O-LoRA, which also enforce task-wise orthogonality but in a parameter-efficient manner?\n\n•  Since AEFT restricts updates to a small subset of parameters, to what extent could the observed gains arise from the reduced update capacity rather than from increased task-vector orthogonality itself?\n\n•  The proposed approach appears conceptually related to InfLoRA, which designs LoRA adapters that are orthogonal across tasks. Could the authors clarify in concrete terms how QOMM differs from or improves upon InfLoRA both algorithmically and computationally?\n\n•  How does QOMM perform relative to prompt-based continual learning approaches such as DualPrompt, CODA-Prompt, or L2P, which also aim to achieve modular, interference-resistant adaptation in Transformers?\n\n•  Finally, could the authors clearly articulate the main novelty of their contribution compared to existing orthogonal or merging-based continual learning methods, beyond combining quasi-orthogonal projection with attention-exclusive fine-tuning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T97aSTX8nQ", "forum": "2SrwOoKSpD", "replyto": "2SrwOoKSpD", "signatures": ["ICLR.cc/2026/Conference/Submission11188/Reviewer_fCmW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11188/Reviewer_fCmW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154006541, "cdate": 1762154006541, "tmdate": 1762922341343, "mdate": 1762922341343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}