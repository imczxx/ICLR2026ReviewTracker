{"id": "m2MeiYOJED", "number": 17107, "cdate": 1758272251639, "mdate": 1759897197007, "content": {"title": "PRISM: Partial-label Relational Inference with Spatial and Spectral Cues", "abstract": "In many real-world scenarios, precisely labeling graph data is costly or impractical, especially in domains like molecular biology or social networks, where annotation requires expert effort. This challenge motivates partial-label graph learning, where each graph is weakly annotated with a candidate label set containing the true label. However, such ambiguous supervision makes it hard to extract reliable semantics and increases the risk of overfitting to noisy candidates. To address these challenges, we propose PRISM, a unified framework that performs relational inference with spatial and spectral cues to resolve label ambiguity. PRISM captures discriminative spatial cues by aligning prototype-guided substructures across graphs and extracts global spectral cues by decomposing graph signals into multiple frequency bands with attention, preserving frequency-specific semantics. These complementary views are integrated into a hybrid relational graph, which supports confidence-aware label propagation under candidate constraints. A closed-loop refinement mechanism further stabilizes supervision via masked updates and momentum-based confidence estimation. Extensive experiments across diverse benchmarks demonstrate that PRISM consistently outperforms strong baselines under various noise settings, establishing a new paradigm for weakly supervised graph classification.", "tldr": "", "keywords": ["Weak Supervised Learning", "Graph Neural Networks", "Relational Inference"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b02a7a63d31428b26dd176c0a38d5a8c4bd0884b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes PRISM, a framework for Partial-Label Graph Learning (PLGL). It resolves label ambiguity by integrating local spatial cues (substructure matching) with global spectral cues (frequency analysis). These views are used to construct a relational graph that guides an iterative label propagation process. Experiments show PRISM achieves state-of-the-art results, demonstrating strong robustness to label noise."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The manuscript tackles an important, practical task: learning from graphs that only provide a candidate label set, and it states the setup clearly for real applications.\n2. It shows strong results with noticeable margins on several benchmarks and stays stable as label noise increases, which points to solid robustness.\n3. The pipeline is modular and easy to adapt and swap encoders or spectrum modules without redesigning the whole method."}, "weaknesses": {"value": "1. The theory relies on very strong assumptions and does not explain how the model actually learns under noisy supervision; it mostly describes behavior at an ideal fixed point.\n2. The paper does not convincingly show that the two views truly help each other; ablations suggest the label-propagation step may account for most gains, not the new encoders, so the claimed synergy remains unclear.\n3. Some key implementation details are missing, such as how confidence-based filtering is done, and the complexity claim skips the likely quadratic cost of cross-graph similarity and Top-k selection, which can mislead readers about scalability."}, "questions": {"value": "1. Theorems 1/2 assume the GNN already maps samples near the correct prototypes and the classifier recognizes them perfectly; they describe an ideal fixed point rather than how the model reaches it under noisy supervision, offering little insight into the core challenge.\n2. Is the claim that the model's complexity is O(|E| d) reasonable? Finding the top-k neighbors for all graphs in a batch seems like it would be at least an O(N^2) operation, which can be very slow. The paper doesn't seem to have accounted for this cost.\n3. The paper claims the spatial and spectral views are complementary, but neither the theory nor the experiments really show how they help each other. Is there an example where one view gets it wrong, but the other one corrects it? Otherwise, it looks more like a simple combination of two methods.\n4. Looking at your ablation study (Table 2), removing the \"Relational Inference\" step causes the biggest performance drop. This makes me wonder: is the final label propagation step the real key to the performance boost? It might mean that the spatial and spectral encoders you focus on are not the main reason for the model's great results.\n5. In Section 3.1, you mentioned a key step called \"confidence-based filtering\" for updating the prototypes, but it's never explained how it works. Without it, it's hard to fully understand your method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oglSf5EO7R", "forum": "m2MeiYOJED", "replyto": "m2MeiYOJED", "signatures": ["ICLR.cc/2026/Conference/Submission17107/Reviewer_Nyo7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17107/Reviewer_Nyo7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761692617241, "cdate": 1761692617241, "tmdate": 1762927109327, "mdate": 1762927109327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the practical and underexplored problem of Partial-label Graph Learning (PLGL), which reflects real-world situations where graph labels are incomplete or uncertain. The proposed method PRISM integrates three complementary components, i.e., prototype-guided substructure alignment, spectral modeling, and hybrid relational graph propagation, to address label ambiguity from spatial, spectral, and relational perspectives."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The approach is conceptually coherent and well-motivated, combining local structural cues with global spectral information for more reliable supervision. Experimental results on multiple benchmarks demonstrate clear performance improvements over existing weakly supervised and graph learning methods, supporting the effectiveness of the proposed framework."}, "weaknesses": {"value": "1. Graphs differ significantly in size and structure, making cross-graph substructure alignment both conceptually unclear and potentially computationally expensive. The paper does not explain how this process is implemented or efficiently approximated, and when dealing with large graphs with many nodes and edges, it could still lead to severe computational bottlenecks.\n\n2. Each graph has its own Laplacian basis, making frequency bands difficult to compare across graphs. The paper does not explain how spectral features are aligned or normalized, and when the structural differences between graphs are large, ensuring that their spectral representations are meaningfully aligned remains a significant challenge.\n\n3. The theory assumes a perfectly trained classifier with one-hot outputs. In practice, momentum updates and label propagation interact, so this assumption may not hold.\n\n4. Limited robustness evaluation. The work does not systematically evaluate different candidate set sizes, nor does it examine performance under varying noise levels or open-set scenarios."}, "questions": {"value": "1. How is the cross-graph substructure alignment implemented in practice? Can the authors show that this step does not cause extra computational cost?\n2. Since each graph has its own Laplacian basis, how does the method handle spectral inconsistency when using multi-band features?\n3. The convergence proof assumes a well-trained classifier with correct one-hot outputs. What happens if this assumption does not hold? Any discussion or experiments?\n4. Could the authors test the model under different candidate set sizes, noise levels, or open-set cases (where true labels are missing)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fAvWhvpOlt", "forum": "m2MeiYOJED", "replyto": "m2MeiYOJED", "signatures": ["ICLR.cc/2026/Conference/Submission17107/Reviewer_Qmcu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17107/Reviewer_Qmcu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761793942415, "cdate": 1761793942415, "tmdate": 1762927108095, "mdate": 1762927108095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel graph classification method in partial-label setting, which captures relations between graphs from both spatial and spectral views."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed method designs a novel way to compute spatial and spectral relations between graphs.\n- The method's training complexity is linear in the number of edges and consistent with standard GNN-based methods.\n- The method applies a binary mask to enable partial supervision."}, "weaknesses": {"value": "- The equations lack explanations. Why do you design the spatial relations by Eq.(5), which consists of two components. Why do you use Eq.(7)  to compute X^(p) . What is the deeper meaning behind these equations.\n- How to decide the binary mask M, as it desides how many data are used for supervision. Does this method sensitive to M and the ratio of supervised data."}, "questions": {"value": "- I am not quite understand Figure 3, please provide more explanations.\n- For Eq.16 and Eq. 17, which one is the final loss function?\n- Why using different q for different datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Aq6it6soZv", "forum": "m2MeiYOJED", "replyto": "m2MeiYOJED", "signatures": ["ICLR.cc/2026/Conference/Submission17107/Reviewer_Nemd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17107/Reviewer_Nemd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761827454273, "cdate": 1761827454273, "tmdate": 1762927107794, "mdate": 1762927107794, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to solve a novel graph classification problem known as partial label graph learning where labels of each graph are ambiguous with a set of labels provided but not precise label. The paper proposed a novel framework that aims to establish both graph-graph relation from spatial view and spectral view and denoise the label set from the established graph pair relations. For spatial view, the author proposed to align subgraph structure with the clustered class-centered substructure prototype and for spectral view, the author aims to build band-frequency based alignment. Empirical results suggest a clear improvement of proposed method compared with various baselines from graph neural network based models and partial label learning from computer vision fields. Ablation results suggest each component's effectiveness. The author also show theoretical analysis on the convergence of the label confidence matrix and training loss."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper discusses a novel problem called partial label graph learning problem which would be practical in real application setting where labels are ambiguous for actual datasets.  \n2. A novel framework is proposed that absorbs both spatial and spectral information for each graph to effectively capture useful information for denoise the noisy soft labels and train the classifier.\n3. The theoretical analysis looks sound and comprehensive.\n4. Empirical results suggest a clear improvements for proposed method compared with baselines from Graph neural network side and partial label learning benchmarks."}, "weaknesses": {"value": "1. I think when it involves with the eigenvalue computation, especially for the dense and large-scale graph, the computation cost becomes expensive and prohibitive. This makes the spectral part of the framework not scalable. In the computation efficiency analysis, the author failed to discuss this important question and in my opinion falsely conclude the computation efficiency is comparable to standard GNN. For a dense and large-scale graph, the computation of eigenvalue and eigenvectors could be approaching O(n^2).\n2. I find some parts of the paper lacks explanation of the symbols. For example, in the spectrum part, k seems to be an index, yet, in the computation analysis, k becomes the number of eigenvalues. M is referred to as the binary mask, but there is no definition on how it should be computed, which makes the paper hard to follow at some points."}, "questions": {"value": "Please see weakness. I would like to know how the author considers their runtime on spectrum part and also how M is computed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6LYdQ89Fld", "forum": "m2MeiYOJED", "replyto": "m2MeiYOJED", "signatures": ["ICLR.cc/2026/Conference/Submission17107/Reviewer_kgnv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17107/Reviewer_kgnv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950591100, "cdate": 1761950591100, "tmdate": 1762927107552, "mdate": 1762927107552, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}