{"id": "02mBAZjFzp", "number": 19416, "cdate": 1758296070926, "mdate": 1763752072623, "content": {"title": "VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems", "abstract": "Designing high-performing heuristics for vehicle routing problems (VRPs) is a complex task that requires both intuition and deep domain knowledge. Large language model (LLM)-based code generation has recently shown promise across many domains, but it still falls short of producing heuristics that rival those crafted by human experts. In this paper, we propose VRPAgent, a framework that integrates LLM-generated components into a metaheuristic and refines them through a novel genetic search. By using the LLM to generate problem-specific operators, embedded within a generic metaheuristic framework, VRPAgent keeps tasks manageable, guarantees correctness, and still enables the discovery of novel and powerful strategies. Across multiple problems, including the capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our method discovers heuristic operators that outperform handcrafted methods and recent learning-based approaches while requiring only a single CPU core. To our knowledge, VRPAgent is among the first LLM-based paradigms to advance the state-of-the-art in VRPs, highlighting a promising future for automated heuristics discovery.", "tldr": "We introduce VRPAgent, a framework that leverages LLMs and evolutionary search to discover novel heuristic operators for vehicle routing problems, achieving state-of-the-art performance across multiple VRP variants.", "keywords": ["automated algorithm design", "evolutionary search", "vehicle routing problem", "LLM agent", "heuristic discovery"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0633c4d756ab3fce71d49567912ad35b725f14e1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces VRPAGENT, a framework for discovering heuristic operators for Vehicle Routing Problems (VRPs) using large language models (LLMs). The method combines LLM-generated “destroy” and “order” operators with a Large Neighborhood Search (LNS) metaheuristic, leveraging genetic algorithms (GAs) to iteratively evolve improved operators. Although the research motivation and validation results seem feasible, the approach is almost identical to existing LLM-guided heuristic frameworks, which weakens the overall contribution of the paper."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The approach is clear, and the LLM-guided evolutionary framework has discovered operators that go beyond expert-designed ones.\n2. The authors have conducted a certain level of analysis on the generated heuristic operators."}, "weaknesses": {"value": "1.\t**Incrementa novelty** — The evolutionary framework of VRPAgent is similar to existing heuristic evolutionary frameworks (such as Heuristics evolution based on LLM, e.g., EoH [1]), and the proposed \"code length penalty\" is also negligible.\n2.\t**Empirical overclaiming** — The experimental results of VRPAGENT show only minor improvements compared to existing methods. There is a lack of comparison with LLM-empowered LNS approaches, such as LLM-LNS [2]. It is also unclear how it performs compared to adaptive LNS methods like PPO-ALNS [3].\n3.\t**Fairness of experiments** — It is not clearly stated whether the comparison methods based on LLM heuristic generation have a similar number of API calls.\n4.\t**Incomplete experimental analysis** — The study lacks an analysis of aspects such as the convergence of the genetic algorithm or the probability of code correctness.\n\n[1] Evolution of heuristics: Towards efficient automatic algorithm design using large language model. ICML 2024.\n\n[2] Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems. ICML 2025.\n\n[3] Reinforcement learning-guided adaptive large neighborhood search for vehicle routing problem with time windows. Journal of Combinatorial Optimization, 2025."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uG0zaS46hU", "forum": "02mBAZjFzp", "replyto": "02mBAZjFzp", "signatures": ["ICLR.cc/2026/Conference/Submission19416/Reviewer_Z5wY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19416/Reviewer_Z5wY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19416/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761640544072, "cdate": 1761640544072, "tmdate": 1762931332135, "mdate": 1762931332135, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for automated heuristic discovery in VRPs using LLMs called VRPAgent. VRPAgent integrates LLM-generated problem-specific operators within a Large Neighborhood Search (LNS) metaheuristic and refines them through a genetic algorithm that employs elitism, biased crossover, and code-length penalty mechanisms.​\n\nKey features include generating problem-specific destroy and insert heuristics via LLMs, and evolving these operators over multiple generations to maximize solution quality while controlling code complexity. The method is evaluated across standard VRPs (capacitated, time windows, prize-collecting), consistently discovering heuristics that outperform handcrafted and previous LLM/learning-based methods on large benchmark instances using only CPU resources.​\n\nThe approach offers interpretability, practical efficiency, and a reproducible pipeline for discovering and improving heuristics for combinatorial optimization, highlighting a new path for LLM-driven algorithmic design in operations research.​\n\nThe contributions include:\n1. A hybrid metaheuristic framework (LLM-in-the-loop LNS) for VRPs where LLMs generate, mutate, and combine code for local operators.\n2. A genetic algorithm with code-length penalties to evolve and select the best LLM-generated operators.\n3. Demonstrating state-of-the-art or superior performance compared to both expert-designed heuristic solvers and recent neural/LLM solutions on several large VRP benchmarks, with superior interpretability and scalability"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed VRPAgent leverages LLMs to generate and evolve problem-specific destroy/insert heuristics for VRPs, significantly reducing the need for expert-written code and enabling discovery of novel strategies.​\n\n2. The framework combines LLM-generated operators with a genetic algorithm using elitism, biased crossover, and code-length penalties, leading to efficient search and interpretable code that is competitive with and sometimes superior to handcrafted heuristics.​\n\n3. VRPAgent consistently outperforms or matches best-in-class expert and neural approaches on benchmark VRPs (CVRP, VRPTW, PCVRP), working efficiently on CPU and scaling to large instances.​\n\n4. The approach maintains strong performance across multiple VRP classes without requiring expensive hardware. By modularizing heuristic generation and search refinement, it allows for adaptation to different problem types and operator ensembles.​\n\n5. By focusing LLM synthesis on manageable code components within a robust metaheuristic shell, VRPAgent strikes a balance between automated innovation and guarantees of feasibility and quality"}, "weaknesses": {"value": "1. Many LLM-generated heuristics discovered by VRPAgent are ensembles or recombinations of standard strategies from the literature (e.g., SISRs-like removal, weighted greedy criteria for sorting). The framework excels at combining known components but provides little evidence of discovering fundamentally new algorithms that would advance state-of-the-art theory for VRPs.​\n\n2. While the code is readable to experts, it is often overly redundant, deeply nested, and filled with hard-to-tune random parameters and magic numbers. Several domain experts in the study noted that a human would write more succinct, interpretable, and maintainable code. The logic behind some probabilistic choices is especially convoluted, making ablation studies and performance analysis difficult.​\n\n3. The performance improvements are attributed to complex ensembles and parameterized strategies, but the paper lacks detailed ablation studies pinpointing which components are truly responsible for gains. This makes it hard to generalize findings beyond the benchmarked VRP instances.​\n\n4. Many key parameters affecting the algorithms' behavior are scattered, sometimes hard-coded and sometimes embedded within random logic, increasing risk of inadvertent misconfiguration. This could hinder code modification, adaptation, or debugging in practice.​\n\n5. The experiments focus on classic VRPs and well-known benchmark formats. There is no evaluation of the heuristics' robustness under noisy, dynamic, or highly custom problem constraints, which are common in operational logistics scenarios.​\n\n6. Although some level of interpretability is claimed, true transparency into how and why the LLM-generated code behaves well is lacking. For many users and practitioners, relying on black-box or stochastic mixtures of heuristics without clear guidance or analysis may be risky.​\n\n7. The framework does not address risks inherent in LLM-generated code, such as silent propagation of bugs, accidental feasibility violations, or malicious prompt engineering in operational settings. This could be critical for industrial deployment.​\n\n8. Claims of extensibility to other combinatorial domains (packing, scheduling) are made, but without any experimental or theoretical evidence."}, "questions": {"value": "1. How sensitive is the genetic search to the initialization of random heuristics and the specific code-length penalty functions? Can you provide detailed ablation studies quantifying how different parameter choices impact final solution quality and code interpretability, particularly for non-benchmark VRP variants or logistics settings outside the training corpus?​​\n\n2. Given that several domain experts found the final heuristic code verbose, redundant, or over-complicated, what mechanisms (besides code-length penalty) do you propose to systematically regularize the structure, improve succinctness, and enhance human interpretability for large LLM-generated operator populations?​​\n\n3. What validation and error-checking processes are in place to guarantee that newly synthesized operators do not introduce infeasibility, silent bugs, or performance degradation, especially as code complexity increases over generations and as operators interact in ensembles? Is there any theoretical or empirical guarantee that VRPAgent will not produce brittle or unsafe solutions on realistic, highly constrained, or adversarial VRP instances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "D0O7X821Fg", "forum": "02mBAZjFzp", "replyto": "02mBAZjFzp", "signatures": ["ICLR.cc/2026/Conference/Submission19416/Reviewer_fYZd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19416/Reviewer_fYZd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19416/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761650118693, "cdate": 1761650118693, "tmdate": 1762931331541, "mdate": 1762931331541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Designing effective heuristics for VRP problems based on the Large Neighborhood Search (LNS) algorithm typically requires extensive human expertise and trial-and-error. To address this issue, the paper proposes using large language models (LLMs) to automatically design heuristic operators. Building on the concept of genetic algorithms, the LLM generates diverse heuristic candidates, retains the best-performing ones according to the solution results, and performs heuristic modifications and explorations to further improve performance. The proposed method is validated on multiple types of VRP problems, demonstrating a significant overall performance advantage compared with other AI-enhanced LNS approaches."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The work presented in this paper is solid and substantial, with comprehensive comparisons against many methods published in top-tier conferences, demonstrating strong overall performance.\n\nThe manuscript is well-written, logically organized, and carefully proofread.\n\nThe proposed method also shows promising potential for extension and application to other problem domains."}, "weaknesses": {"value": "The proposed framework exhibits general applicability; however, the experimental cases are limited to the VRP domain.\n\nThe effectiveness of the proposed method still requires further investigation, as it has not been compared with widely used commercial solvers. Moreover, the results do not show a significant improvement in either computational speed or solution quality compared with existing approaches."}, "questions": {"value": "1. In Fig. 2, why does the curve without mutation decrease faster in the early iterations, yet later perform worse than the one with mutation? It seems that 20 iterations are insufficient for convergence. It is recommended to extend the number of iterations to show a more complete convergence process.\n\n2. The analysis of Fig. 5 (a) and (b) is inadequate. The discussion merely restates the numerical results without providing insight into the underlying reasons or the conclusions that can be drawn from them.\n\n3. The paper claims that the proposed framework has strong transferability. Therefore, the results and implementation should be made open-source to enable further verification and application by other researchers across different problems and domains.\n\n4. All test cases in the paper are limited to VRP-related problems, yet the method itself does not incorporate any VRP-specific structural design or analysis. Moreover, the generated heuristics are not analyzed, leaving the algorithm’s interpretability and physical rationale unclear.\n\n5. As mentioned in Comment 4, since the algorithm is not specifically tailored to VRP, it is suggested to include additional results on other mixed-integer programming benchmarks (e.g., general MILP instances) in the appendix to demonstrate the generality and effectiveness of the proposed approach.\n\n6. Although the paper compares with many deep learning–based methods, it does not include comparisons with classical solvers such as Gurobi or CPLEX, which are widely used in practice. Without such baselines, the practical applicability of the proposed method to real-world VRP problems remains unclear. It is recommended to supplement results comparing with Gurobi and/or CPLEX."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jD0850R4NE", "forum": "02mBAZjFzp", "replyto": "02mBAZjFzp", "signatures": ["ICLR.cc/2026/Conference/Submission19416/Reviewer_fmXs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19416/Reviewer_fmXs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19416/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761736893795, "cdate": 1761736893795, "tmdate": 1762931331171, "mdate": 1762931331171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents VRPAGENT, a framework that uses Large Language Models (LLMs) to automatically discover heuristic operators for Vehicle Routing Problems (VRPs). The approach embeds LLM-generated problem-specific operators within a Large Neighborhood Search (LNS) metaheuristic and refines them through a genetic algorithm with elitism and biased crossover. The authors evaluate their method on three VRP variants (CVRP, VRPTW, PCVRP) and demonstrate state-of-the-art performance using only a single CPU core at test time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel and Practical Framework: The approach of generating only problem-specific operators within a fixed metaheuristic is well-motivated. This \"keeping AI agents on a leash\" philosophy addresses key limitations of prior LLM-based approaches by ensuring correctness and manageability while still enabling discovery of novel strategies.\n2. Strong Empirical Results: VRPAgent achieves impressive performance improvements over both traditional OR solvers and recent learning-based methods, with negative gaps (around -0.30%) relative to state-of-the-art SISRs on larger instances. The consistency across multiple problem variants and instance sizes is particularly compelling.\n3. Computational Efficiency: The single CPU core requirement at test time is a significant practical advantage over GPU-dependent NCO methods, making deployment more accessible.\n4. Thorough Experimental Analysis: The paper includes comprehensive ablation studies demonstrating the importance of biased crossover and mutation, analysis across different LLMs (showing that open-source gpt-oss achieves near-SOTA performance at low cost), and sensitivity analyses on GA hyperparameters.\n5. Expert Analysis: The inclusion of expert evaluation of generated heuristics (Appendix C) provides valuable qualitative insights into readability, coherence, and novelty, adding credibility beyond pure performance metrics."}, "weaknesses": {"value": "**Major issues**\n\n1. Interpretability Concerns: The expert analysis consistently notes that discovered heuristics are difficult to interpret due to complex logic, nested conditionals, and convoluted use of random numbers. This limits practical adoption where transparency is important. The paper acknowledges this but doesn't propose concrete solutions.\n2. Limited Generalization Analysis:\n- Training is conducted only on 500-customer instances, yet the approach generalizes well to 1000 and 2000 customers. More analysis on why this generalization occurs would strengthen the paper.\n- The operators are discovered separately for each problem variant. Can operators transfer across problems or be adapted more efficiently?\n3. LLM Dependency:\n- Best results require Gemini 2.5 Flash at ~$19 per run, which may limit accessibility\n- While gpt-oss performs well, the reliance on specific LLM characteristics raises questions about reproducibility and long-term viability\n4. GA Design Choices:\n- The strong bias toward exploitation (80% elite in crossover, mutation only on elites) is unusual. While ablations show it works, more analysis on why exploitation is so beneficial in this search space would be valuable.\n- Limited exploration of other GA hyperparameters (e.g., initial population diversity, selection mechanisms)\n5. Comparison Limitations:\n- Some baselines use different time budgets or hardware configurations, making direct comparison slightly less clear\n- The paper compares against construction-based LLM methods (EoH, ReEvo) that don't benefit from search budgets, but limited comparison with other LLM-based improvement heuristics\n6. Novelty of Discovered Heuristics: While the expert analysis confirms novelty, it also notes that heuristics are primarily \"recombinations of existing ideas.\" The paper could better discuss what fundamentally new concepts (if any) were discovered.\n\n**Minor Issues**\n1. The abstract mentions \"VRPAGENT is the first LLM-based paradigm to advance the state-of-the-art in VRPs,\" which is a strong claim. While the results support this, it might be beneficial to briefly acknowledge the ongoing rapid advancements in LLM-based optimization to provide full context, perhaps by rephrasing slightly to \"among the first\" or \"a pioneering LLM-based paradigm.\"\n2. Notation Consistency: In Algorithm 2, line 4 uses NE (non-elite) which could be confused with the elite size parameter also denoted $N_E$. Consider using different notation. In Algorithm 2, line 7 uses $RANDOM(Е)$ and line 8 uses $RANDOM(NE)$. It would be clearer to explicitly state what $E$ and $NE$ represent in this context (e.g., a list of elite individuals, a list of non-elite individuals) to avoid ambiguity for readers unfamiliar with the specific GA implementation.\n3. Missing Details: The paper mentions that full prompts will be provided in the \"final code release\" but only shows CVRP-specific prompts in the appendix. For reproducibility, all prompts should be included.\n4. Statistical Significance: Results lack error bars or significance tests, though the consistent improvements across problems suggest robustness.\n5. Figure Quality: Figure 1 is informative but quite busy. Consider simplifying or providing a higher-level conceptual diagram first."}, "questions": {"value": "1. Have you considered incorporating interpretability metrics into the fitness function to encourage more transparent heuristics without sacrificing performance?\n2. Can you provide more insight into why strong exploitation (biased crossover, elite-only mutation) works so well? Is there something specific about the LLM-generated operator search space that makes this effective?\n3. How sensitive is the approach to the choice of metaheuristic framework? Would similar results be achievable with other frameworks beyond LNS?\n4. The expert analysis mentions ensemble approaches in all discovered heuristics. Is this a fundamental property of effective operators, or an artifact of the LLM's training or the prompt design?\n5. Have you investigated whether operators discovered for one problem (e.g., CVRP) can be adapted or fine-tuned for related problems (e.g., VRPTW) more efficiently than starting from scratch?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ODFKpFC7tV", "forum": "02mBAZjFzp", "replyto": "02mBAZjFzp", "signatures": ["ICLR.cc/2026/Conference/Submission19416/Reviewer_7uJY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19416/Reviewer_7uJY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19416/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988169721, "cdate": 1761988169721, "tmdate": 1762931330768, "mdate": 1762931330768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}