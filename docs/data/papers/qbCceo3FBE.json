{"id": "qbCceo3FBE", "number": 119, "cdate": 1756728929009, "mdate": 1763725095002, "content": {"title": "GOLDILOCS: GENERAL OBJECT-LEVEL DETECTION AND LABELING OF CHANGES IN SCENES", "abstract": "We propose GOLDILOCS: a novel zero-shot, pose-agnostic method for object-level semantic change detection in the wild. While supervised Scene Change Detection (SCD) methods achieve impressive results on curated datasets, these models do not generalize and performance drops on out-of-domain data. Recent Zero-Shot SCD methods introduced a more robust approach with foundational models as backbone, yet they neglect the 3D aspect of the task and remain constrained to the image-pair setting. Conversely, 3D-centric SCD methods based on 3D Gaussian Splatting (3DGS) or NeRFs require multi-view inputs, but cannot operate on an image pair. Our key insight is that SCD can be reformulated as a 3D reconstruction problem over time, where geometric inconsistencies naturally indicate change. Although previous work considered viewpoint difference a challenge, we recognize the additional geometric information as an advantage. GOLDILOCS uses dense stereo reconstruction to estimate camera parameters and generate a pointmap of the commonalities between input images by filtering geometric inconsistencies. Rendering the canonical scene representation from multiple viewpoints yields reference images that exclude changed or occluded content. Rigid object changes are then detected through mask tracking, while nonrigid transformations are identified using SSIM heatmaps. We evaluate our method on a variety of datasets, covering both pairwise and multi-view cases in binary and multi-class settings, and demonstrate superior performance over prior work, including supervised methods.", "tldr": "", "keywords": ["Change detection", "scene change detection", "semantic change detection"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab9f9bc9f66feb9de3c047531a72ea73f8e20214.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes GOLDILOCS, a zero-shot, 3D-aware framework for object-level scene change detection (SCD) from image pairs or multi-view image sets. The method reformulates SCD as a combination of stereo 3D reconstruction, semantic segmentation, mask tracking, and non-rigid change detection via SSIM-based comparison. It leverages foundational models (MASt3R for 3D reconstruction and SAM2 for segmentation) without additional training and introduces a standardized object-level change taxonomy including Removed, Added, Moved, and Warped. Experiments on both synthetic and real datasets (ChangeSim, VL-CMU-CD, 3DGS-CD, NeRFCD) demonstrate strong zero-shot performance, especially in IoU and F1 metrics, while avoiding expensive multi-view reconstruction at test time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Zero-shot object-level change detection with 3D geometric reasoning.\n\n2. Modular pipeline leveraging stereo reconstruction and segmentation models.\n\n3. Introduces a clear object-level change taxonomy (Removed, Added, Moved, Warped).\n\n4. Faster inference compared to traditional 3D reconstruction pipelines.\n\n5. Comprehensive experiments across multiple datasets."}, "weaknesses": {"value": "Ⅰ. Parameter Sensitivity:\n\nSSIM Thresholds: The thresholds used for non-rigid change detection significantly affect results. A threshold set too high may miss subtle deformations, while a threshold too low may falsely classify static objects as changed.\n\nLabel Priority Ordering: The per-pixel prediction relies on the priority order (Warped > Moved > Removed > Added). This can affect nested or overlapping object changes; for example, small objects inside a larger moved object may be suppressed and misclassified.\n\nⅡ. Limited Ablation:\n\nAblation experiments mainly focus on stereo reconstruction and novel view synthesis, but the contribution of non-rigid change detection and mask propagation is not thoroughly analyzed.\n\nThe effects of individual components such as depth filtering, cross-view voting, and mask propagation on each change type (added, removed, moved, warped) are not quantified.\n\nⅢ. Data Limitations:\n\nThe evaluation datasets lack extreme real-world scenarios, including large occlusions, fast-moving objects, or highly dynamic scenes, which may cause 3D reconstruction or mask tracking failures."}, "questions": {"value": "1. How sensitive is GOLDILOCS to SSIM thresholds and mask tracking parameters across datasets?\n\n2. How does it handle partially occluded or highly dynamic objects?\n\n3. Could hierarchical segmentation improve detection for nested objects?\n\n4. Would longer temporal sequences improve detection robustness?\n\n5. Any plans for evaluation in real-world dynamic scenes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dnjltU8wW0", "forum": "qbCceo3FBE", "replyto": "qbCceo3FBE", "signatures": ["ICLR.cc/2026/Conference/Submission119/Reviewer_14W9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission119/Reviewer_14W9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission119/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912182194, "cdate": 1761912182194, "tmdate": 1762915455802, "mdate": 1762915455802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GOLDILOCS, a zero-shot and pose-agnostic approach for object-level semantic change detection (SCD). The key idea is utilizing  3D geometric inconsistencies to detect changes. With the estimated pointmaps by dense stereo reconstruction models , the method generates reference images of clean point clouds. Changes are then identified via mask tracking for rigid objects and SSIM heatmaps for non-rigid ones. Evaluations on various datasets show better performance over baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- With the help of SAM2, the proposed method is zero-shot.\n- The idea to utilize SAM and MASt3R to SCD problem is practical.\n- The proposed method achieved best overall performance in most settings."}, "weaknesses": {"value": "- The proposed method depends on two large foundation models, which demands large computations and may limit its applications.\n- Lack of implementation details/runtime comparisons to show the extra cost of the proposed pipeline.\n- The peromance improvement is marginal (e.g, resutls in Tab.4.)"}, "questions": {"value": "- Is there analysis of how the performance/generality of 3D reconstruction model affect the result of SCD results? Are there any visualization of reconstructed results?\n- The “conflict resolution” in Sec. 4.2 is confusing, what does it mean?\n- Is the method end-to-end? Or they are rule-based after getting the segmentation/reconstruction by existing models.\n- Citation of 3DGS-CD of Tab.1 differs from that of Tab. 2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "098Jj66CH8", "forum": "qbCceo3FBE", "replyto": "qbCceo3FBE", "signatures": ["ICLR.cc/2026/Conference/Submission119/Reviewer_x35Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission119/Reviewer_x35Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission119/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009434684, "cdate": 1762009434684, "tmdate": 1762915455590, "mdate": 1762915455590, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce GOLDILOCS, a framework that establishes a standardized taxonomy for object-level change labeling in 3D scenes. The approach is grounded in geometric reconstruction and visibility reasoning, where an object is defined as any visually identifiable entity ranging from volumetric elements like boxes or furniture to planar textures such as ink stains on paper.\n\nGOLDILOCS reconstructs the 3D geometry of a scene and employs novel-view rendering, segmentation, and temporal tracking of object masks to detect both rigid and  non-rigid transformations over time. The framework is evaluated across multiple datasets, demonstrating consistent and satisfactory improvements over state-of-the-art methods in object-level change detection and labeling."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces a well-defined and systematic taxonomy for object-level change labeling in 3D scenes, addressing the lack of standardization in existing approaches.\n\nThe authors adopt an inclusive definition of object, covering both volumetric entities (e.g., furniture) and planar or texture-based elements (e.g., ink blotches), which enhances the framework’s generality and applicability.\n\nThe integration of 3D geometric reconstruction and visibility-based reasoning allows for more precise understanding of scene changes compared to purely 2D or image-based methods.\n\nThe use of segmentation and mask tracking across time ensures consistent identification of objects and their transformations, including non-rigid changes.\n\nThe pipeline’s inclusion of novel-view rendering improves the robustness of change detection under different viewpoints and occlusions.\n\nThe model has been tested on multiple datasets, demonstrating strong generalization and satisfactory improvements over state-of-the-art methods.\n\nBy combining geometry, visibility, and temporal reasoning, GOLDILOCS can be extended to practical domains like robotics, AR/VR scene updates, and autonomous navigation."}, "weaknesses": {"value": "The proposed framework is computationally heavy, as it integrates conventional segmentation and 3D stereo reconstruction modules, making it less efficient for real-time or large-scale applications.\nThe 3D stereo reconstruction component appears to rely on existing methods with minimal innovation, reducing the novelty of that part of the pipeline.\nThe paper lacks clear technical details about the underlying 3D reconstruction model its architecture, parameters, and optimization strategy are not adequately discussed.\nThe motivation for selecting specific existing models for segmentation and reconstruction is not well justified. The rationale behind these design choices should have been elaborated to strengthen the methodological clarity.\nThe computational complexity, including FLOPs, memory requirements, and inference time, is not reported. Such analysis would be valuable for early reference and comparative evaluation.\nGiven its reliance on multiple integrated modules, the pipeline may face scalability and deployment challenges in dynamic or resource-limited environments."}, "questions": {"value": "The proposed framework is computationally heavy, as it integrates conventional segmentation and 3D stereo reconstruction modules, making it less efficient for real-time or large-scale applications.\nThe 3D stereo reconstruction component appears to rely on existing methods with minimal innovation, reducing the novelty of that part of the pipeline.\nThe paper lacks clear technical details about the underlying 3D reconstruction model its architecture, parameters, and optimization strategy are not adequately discussed.\nThe motivation for selecting specific existing models for segmentation and reconstruction is not well justified. The rationale behind these design choices should have been elaborated to strengthen the methodological clarity.\nThe computational complexity, including FLOPs, memory requirements, and inference time, is not reported. Such analysis would be valuable for early reference and comparative evaluation.\nGiven its reliance on multiple integrated modules, the pipeline may face scalability and deployment challenges in dynamic or resource-limited environments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pHt5o4j8EB", "forum": "qbCceo3FBE", "replyto": "qbCceo3FBE", "signatures": ["ICLR.cc/2026/Conference/Submission119/Reviewer_rCUL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission119/Reviewer_rCUL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission119/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762224914237, "cdate": 1762224914237, "tmdate": 1762915454886, "mdate": 1762915454886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new method for scene change detection. The new method, entitled GODILOCS, offers an alternative for zero-shot, class-agnostic object-level change detection, leveraging recent advances in foundation models. The method is 3D geometry aware, firstly by calculating the 3D geometry of the scene using Mast3R. The created point-maps are filtered for inconsistent regions (likely corresponding to changes in the scene) and then images are rendered using the same viewpoints such that the images can be compared. Discrepancies between the rendered and initial images help identify object-level changes, with the help of object-level masks created by SAM2. A foundation model for tracking is the afterwards deployed to differentiate between rigid and non-rigid changes. The presented method achieves state-of-the-art results compared with a set of relevant baselines both on synthetic and real-world dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an interesting topic: scene change detection. Especially, it also helps sub-categorize the change into added, removed, or moved objects (rigid and non-rigid changes). Scene change detection is an understudied and interesting topic. \n\nThe paper leverages the latest trends in foundation models, offering a class-agnostic, zero-shot method for scene change detection. More specifically, using Mast3R, the proposed method creates a 3D reconstruction of the scene to have a 3D geometry-aware 3D change detection, and then uses a class-agnostic instance segmentation model (SAM2) to identify objects in the scene and track them using DEVA].\n\nThe paper achieves SoTA results, compared to other baselines, validating the motivation of having a 3D geometry aware change detection methods when just images of a scene are given.\n\nThe paper is well-motivated, and well-written. The methodology is thoroughly explained."}, "weaknesses": {"value": "The novelty of the paper is limited. The paper is mainly extending the work of [1] that uses Mast3R towards creating a geometry aware-scene change detection method. Mast3r offers the 3D reconstruction of the scene, along with the poses and the calibration matrices of the views. Through that, the proposed method can then compare depth maps and render novel views, using the same viewpoints. On the rendered views, the methodologies applied in [1] are then deployed.\n\nMore baselines should be included, including CYWS-3D (Sachdeva & Zisserman, 2023b). Even though the paper offers bounding boxes as changing regions, SAM could be deployed to get the mask for the bounding boxes. Moreover, since the method does not categorize into the different types of changes, the authors could present comparative metrics on all changes and not specific categories.\n\nMost importantly, methods that reason in 3D such as (Taneja et al., 2011), [Adam et al., Objects can move: 3d change detection by geometric transformation consistency, ECCV 2022], [Palazzolo and Stachniss, Fast image-based geometric change detection given a\n3d model, ICRA 2018] are not included in the experimental evaluation and are mostly not discussed in the related work. Such methods could be easily adopted to the given use case by using Mast3r to obtain the 3D models they reason on, which could result in strong baselines. Right now, the presented baselines do not integrate any kind of knowledge about the 3D scene.\n\n[1] Kannan, Shyam Sundar, and Byung-Cheol Min. \"Zeroscd: Zero-shot street scene change detection.\" 2025 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2025."}, "questions": {"value": "Is the integration of Mast3R really necessary? Given that posed, calibrated images were used, using a simpler and more lightweight SfM method, wouldn’t the traditional render and compare lead to similar results? That would be an interesting experiment that would explore the trade-off between computational resource needed for the method and the success of the method.\n\nSince the proposed method reasons in 3D, why are its results not also evaluated in 3D? Using an appropriate dataset, e.g., 3RScan [1] and extending the method by back-projecting the highlighted changes into 3D would also give interesting insights on the success of the method in the 3D environment.\n\n[1] Wald, Johanna, et al. \"Rio: 3d object instance re-localization in changing indoor environments.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TodFqFwmxt", "forum": "qbCceo3FBE", "replyto": "qbCceo3FBE", "signatures": ["ICLR.cc/2026/Conference/Submission119/Reviewer_KMk1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission119/Reviewer_KMk1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission119/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762326456478, "cdate": 1762326456478, "tmdate": 1762915454295, "mdate": 1762915454295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}