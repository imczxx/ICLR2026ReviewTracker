{"id": "maYDrS6TvM", "number": 10803, "cdate": 1758182208515, "mdate": 1759897627576, "content": {"title": "DeTaCH: Decoupling Tasks and Control via a Meta-Gradient Hypernetwork", "abstract": "Current language-conditioned robotic policies suffer from a fundamental architectural bottleneck: when language instructions and visual observations are processed through shared representations, networks cannot distinguish between task specification and state perception, leading to policies that exploit spurious visual correlations rather than grounded language semantics. We identify this phenomenon as modality confounding, where gradient interference and entangled representations prevent proper decomposition of task knowledge from perceptual processing. To address this limitation, we propose DeTaCH, which reconceptualizes language not as an input to be fused with vision (state), but as a meta-specification that generates parameters of task-specific visuomotor policies. Through a two-stage hypernetwork architecture combining semantic initialization with iterative neural gradient estimation, DeTaCH achieves explicit decoupling between language understanding and visual control. Experiments across 90 language-conditioned tasks in LIBERO and 45 tasks in Meta-World demonstrate that DeTaCH improves success rates to 51.4\\% and 92.2\\%, respectively, with particularly strong gains on complex, long-horizon tasks where modality confounding is most severe. The generated parameter manifold also exhibits semantic structure, enabling 25\\% better few-shot adaptation than baselines with only three demonstrations. Our results suggest that explicit architectural separation of heterogeneous modalities may be essential for the generalization of multi-task manipulation policies.", "tldr": "", "keywords": ["Language-Conditioned Policy Learning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d67df3d54a2639575823f462cbb81cdab47bed30.pdf", "supplementary_material": "/attachment/02f1dd43b66d3ec4d7aaf7a12da006daad869c06.zip"}, "replies": [{"content": {"summary": {"value": "The work outlines the issue of modality confounding in Vision-Language Models, where the language specification of the task and the visual information become entangled with harms to performance and generalization capabilities. The proposed solution, DeTaCH, consists in configuring the task specification as a meta-parameter selection problem, with the visual policy optimization occurring at a lower level. In simulation results on 2 benchmarks (LIBERO and Meta-World) show improvements in success rate over other pipelines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "From a conceptual point of view, I appreciate the notion that not mixing both text specifications and visual cues into a single feature vector could be something desirable. The decoupling seems to be a logical and sound approach which the authors make a case for.\n\nThe presentation is overall clean and the solution pipeline designed is sensible and easy to follow.\n\nThe results are consistently better than the competitors considered to benchmark the approach, showcasing a real performance advantage."}, "weaknesses": {"value": "**Task-State Entanglement motivation**\n- The problem at the heart of the necessity for DeTaCH is not sufficiently well presented and documented.\n- The authors provide a short explanation  (lines 185-191)  \"backed up\" by Figure 1, that poses more questions than answers. (Appendix A.9,1 and Figure 5 appear to be more repetitive than complementary is assessing this)\n- Indeed first and foremost, there is no definition of the attention map technique used, what it represents exactly (there is a whole zoo of those techniques, most of which have been shown to be very unreliable). Are they patchwise or pixel wise. A lot of details lack here.\n- The authors state that attention (in general) should be on the target object, without any justification as to why this is the desirable modus operandi of VLAs. The definition of how \"relevant visual entities\" should theoretically and consistently relate to some attention map requires attending to. To the best of my knowledge there is no clean convincing mathematical way of establishing such a relationship. If the authors agree, they should discuss such limitations and present this section as a general intuitive motivation for decoupling. Should they disagree they should provide the clear reasoning. Either way this part of the manuscript is too hand-wavy.\n\n**More on Attention Heatmaps**\n- If entanglement is so bad and the heatmaps for attention confirm that, how come an architecture such as Octo still performs so competitively. The link between the quality of heatmaps and performance is only used as vague motivation and not shown to really hold in practice. One would be more convinced if for example Octo's attention was shown to be on objects while DiT for example shows a more entangled vision. \n- Furthermore, the authors aim to solve the modality confounding issue, illustrated by poor attention, then after presenting the solution, fail to provide post fix attention maps to show attention on objects as was the conjecture for a sane policy.\nEnough on that\n\n**Policy selection**\n- There is a big gap in performance between the different VLAs considered as benchmarks. With some perhaps more popular architectures omitted (pi_0 family). The establishment of the list is a bit confusing with no clear apples to apples comparison of a policy say with the same underlying architecture and number of layers/ parameters trained with one shot concatenated visual input and language task specs, vs a DeTaCH version. It is this not clear how to decipher the relative merits of each approach.\n- Thus, the claim in the abstract and conclusion that DeTaCH achieves 51.4% and 92.2% on the benchmarks is also very vague as the reader has no reference as to how good/bad this is in the absolute but also relative to other policies.\n\n**Lack of real-world deployment**\n- This is a robotics application paper. It is standard to expect real world transfer of the pipeline on hardware. This can constitute a lot off additional work but is crucial to showcase how well this can be applied beyond simulation benchmarks. (again given the authors can also circle back to their claims on attention and decoupling)\n\n**Superficial analysis**\n- The meta-parameter training shows interesting clusters that the authors illustrate in Figure 3 as well as in the appendix (figure font is too small by the way and could do with some improvements of presentation). \n- Yet there is little but vacuous conclusions drawn from the clustering of the same tasks close to each other. There are many things to analyze here, namely how clusters are formed by task and not by objects and the relationship between the two (as most instruction are usually a pair task+object). Also how different tasks relate, e.g. what in the positioning of \"pick up a book\" vs \"pick up a butter\" vs \"put book down\". The idea being of really looking into the task vs object break down and combinations (maybe 2D t-SNE not rich enough)\n\n**Cost of bi-level optimization**\n- There is no presentation of the extra computational cost incurred by running a bi-level iterative optimization compared to a vanilla single policy optimization, this makes it difficult to establish the cost to advantage ratio."}, "questions": {"value": "A lot of the questions are incorporated in detail into the weakness section, a little breakdown of specific information missing.\n\n- What is the cost of computing the meta-update steps?\n\n- What is the attention map mechanism considered? Why is it the best/right one?\n\n- Why is performance quite close to Octo which does not decouple?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0TpADHzfEd", "forum": "maYDrS6TvM", "replyto": "maYDrS6TvM", "signatures": ["ICLR.cc/2026/Conference/Submission10803/Reviewer_ggga"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10803/Reviewer_ggga"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760991657050, "cdate": 1760991657050, "tmdate": 1762922016962, "mdate": 1762922016962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses modality confounding in language-conditioned robot policies,  the interference that occurs when visual observations and language instructions are processed through shared representations. The authors propose DeTaCH, a two-stage hypernetwork that generates task-specific visuomotor policy parameters from language, thereby explicitly separating task specification from state observation.\nDeTaCH first uses a Weight Initialization Network (WIN) to produce a coarse, semantically informed parameter set and then applies Iterative Refinement via learned neural gradients to yield optimized task policies.\nExperiments on LIBERO-90 (90 tasks) and Meta-World ML45 (45 tasks) show strong results, 51.4% and 92.2% success respectively, outperforming six baselines (Octo, VQ-BeT, Diffusion Policy, DiT, HyPoGen, HyperZero). The method also demonstrates improved robustness to paraphrased language and better few-shot adaptation, with t-SNE visualizations showing semantically structured policy manifolds."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Strong motivation and clear problem framing: The notion of modality confounding is intuitive and experimentally supported with attention/gradient analysis.\n\n- Architectural innovation: The meta-gradient hypernetwork approach introduces a principled decoupling of task and state representations.\n\n- Comprehensive evaluation: The paper benchmarks on both LIBERO and Meta-World with multiple baselines, ablations, and robustness tests.\n\n- Few-shot adaptation: Demonstrates emergent meta-learning capability without specialized training, showing real practical promise.\n\n- Interpretability: The parameter manifold visualization nicely links the method’s inductive bias to its generalization behavior."}, "weaknesses": {"value": "- Over-complex framing: Some sections (especially in the refinement module) are dense and could benefit from simplified exposition or pseudocode.\n\n- Lack of real-world experiments: Results are limited to simulation (LIBERO, Meta-World), leaving uncertainty about real-robot deployment and efficiency.\n\n- Comparative novelty: While the architecture is elegant, the conceptual leap from existing hypernetworks (e.g., HyPoGen) is somewhat incremental; justification for calling this a “meta-gradient” hypernetwork could be strengthened.\n\n- Computation and scalability: The cost of generating full policy parameters per task is not quantified and real-time feasibility remains unclear."}, "questions": {"value": "- How computationally expensive is DeTaCH at inference time compared to Octo or HyPoGen?\n\n- Does the learned hypernetwork generalize to unseen language distributions beyond paraphrasing (e.g., out-of-vocabulary verbs)?\n\n- How sensitive is the performance to the choice of frozen language encoder (T5-small)?\n\n- Could the refinement process be interpreted as approximating gradient descent? If so, how stable is it during training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0MEoaatnW1", "forum": "maYDrS6TvM", "replyto": "maYDrS6TvM", "signatures": ["ICLR.cc/2026/Conference/Submission10803/Reviewer_hYUZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10803/Reviewer_hYUZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761513498518, "cdate": 1761513498518, "tmdate": 1762922016543, "mdate": 1762922016543, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel modeling approach for language-conditioned robotic policy learning. Unlike conventional methods that treat language instructions as model inputs at the same level as visual observations, this work interprets language as a meta-specification of the task. To realize this idea, the authors design a meta-hypernetwork conditioned on language, which generates the parameters of task-specific visuomotor policies. The hypernetwork is trained under a meta-learning paradigm using behavior cloning loss, and the overall method is termed DeTaCH. The key motivation is that explicitly disentangling language and visual inputs encourages the model to achieve proper language grounding and visual understanding while avoiding modality confounding. Experiments are conducted on two simulation benchmarks—Libero and Meta-World. DeTaCH attains a 51.4% success rate on Libero and a 92.2% success rate on Meta-World, demonstrating that a meta-learning framework can be effectively applied to robotic manipulation tasks for the first time."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper addresses an essential problem in language-conditioned robotic policy learning—namely, that the conventional behavior cloning paradigm forces the model to simultaneously learn both task (language) grounding and visual understanding through end-to-end training. However, it is difficult to assess the model’s capability in task grounding and visual understanding during the learning process of such a large multimodal \"black box.\" As mentioned in the paper, a widely observed issue is that language understanding is often overshadowed due to limited linguistic diversity and sparse supervision. The overall writing of the paper is clear and the motivation is well presented and meaningful.\n\n2. Incorporating meta-learning methods into language-conditioned policy learning for robotics is an underexplored but promising direction. I agree with the authors’ view that purely end-to-end training is unlikely to be the ultimate solution for robotic learning, as robotics inherently involves integrating multiple modalities—each with differing levels of supervision, diversity, and semantic abstraction.\n\n3. Training a meta-learning framework is generally challenging due to stability concerns, and the paper demonstrates a successful application of this approach to robotic learning. This represents a valuable practical contribution and a meaningful step forward in the field."}, "weaknesses": {"value": "The main concern with this paper lies in the insufficiency of experimental analysis, which is reflected in several aspects:\n\n1. The proposed method is compared only with relatively outdated baselines such as Octo, VQ-BET, and DP. More recent and advanced models, such as Pi-0 and OpenVLA-OFT, should be included for a fair and meaningful comparison. Moreover, a critical baseline is missing—the one that trains task-specific visuomotor policies without the meta-learning paradigm. Such a baseline would provide valuable insight, as it incurs significantly lower computational cost. Demonstrating performance improvement over this baseline is essential to justify the effectiveness and necessity of the proposed meta-learning approach.\n\n2. Low Performance on the Libero Benchmark. The reported results on Libero-90 are substantially lower than current state-of-the-art methods. In fact, it has been widely observed that even a simple DP model can achieve around 70% success rate on Libero-90 with proper training and evaluation setup. While the high computational cost of meta-learning might necessitate using a smaller model or simplified pipeline, the reported metrics are too low to serve as a strong empirical reference.\n\n3. Limited Analysis on Task and Language Diversity. In my opinion, the number of tasks and the diversity of language instructions are key factors affecting hypernetwork learning. Although the paper includes an analysis of robustness under augmented language settings, a more thorough investigation into how performance changes with increasing task or language diversity is crucial. Such an analysis would help determine whether the hypernetwork truly learns to capture common-sense knowledge across tasks and languages, and whether it can efficiently generate parameters for downstream policies.\n\n4. Absence of Computational Cost Analysis. A well-known drawback of meta-learning frameworks is their high computational cost. However, the paper lacks any analysis or comparison of training efficiency or resource consumption across methods. This omission weakens the overall evaluation, as computational efficiency is a central concern for deploying such approaches in robotics.\n\n5. Missing Ablation on Inner-Loop Steps. The number of inner-loop steps is a critical hyperparameter in meta-learning, directly affecting both model performance and training cost. The paper does not include any ablation study or sensitivity analysis on this parameter, which is essential for understanding the stability and efficiency of the proposed framework.\n\n\n### Minor weakness\n\n1. The introduction should include more references or preliminary empirical evidence to substantiate the claim regarding “modality confounding.”"}, "questions": {"value": "1. As mentioned above, the meta-learning training process is often unstable due to conflicts that can arise in the outer-loop optimization. It is unclear how the proposed DeTaCH framework addresses this challenge. The paper should provide more details on how training stability is ensured—specifically, what mechanisms or regularization techniques are applied to mitigate outer-loop instability.\n\n2. It would be valuable to clarify the task and language sampling strategy used during training. Since the choice of sampling strategy can significantly affect both stability and generalization, describing how tasks and language instructions are selected or balanced across iterations would greatly enhance the paper’s methodological transparency and reproducibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rpS5K1ypqK", "forum": "maYDrS6TvM", "replyto": "maYDrS6TvM", "signatures": ["ICLR.cc/2026/Conference/Submission10803/Reviewer_TqGM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10803/Reviewer_TqGM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761744137012, "cdate": 1761744137012, "tmdate": 1762922016198, "mdate": 1762922016198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses a crucial problem of modality confounding in language-conditioned robot policy learning. The authors propose DeTaCH, an architecture that decouples language and vision through a two-stage hypernetwork. The paper exhibits results for multi-task learning on 2 simulated benchmarks and highlights the ability of the proposed framework for few-shot adaptation. The paper also includes additional analysis and ablations to study specific properties of the proposed framework."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper studies an important problem of modality confounding in language-conditioned robot policy learning.\n- DeTaCH’s two-stage hypernetwork design enables tractable and effective generation of task-specialized policy parameters from language embeddings. This explicit decoupling is fundamentally new compared to commonly fused transformer or diffusion-based architectures.\n- The authors compare DeTaCH with prior works on 2 simulated benchmarks and exhibit superior results for language-conditioned multi-task learning on these benchmarks.\n- The structured architecture design in DeTaCH enables rapid adaptation to new tasks with minimal demonstrations, outperforming both task-state entangled and prior hypernetwork-based approaches in adaptation settings. \n- The paper includes detailed ablation and qualitative analyses to study specific aspects of the proposed framework."}, "weaknesses": {"value": "Including both weaknesses as well as questions tied to the weaknesses below.\n- The paper does not include a limitations section.\n- The results in Table 1 seem to reach a performance of 50-70% on the libero benchmark. This is considerably low when compared to prior works such as BAKU[1] which exhibit >90% performance on LIBERO-90. More recent results from VLAs reported in MolmoAct [2] (Table 2 in the paper) also report  much superior performance (>80%) on LIBERO-90. This hints towards implementation issues in the benchmarks as well as in DeTaCH.\n- In Table 3, the final success rate on LIBERO-90 (18%) and Meta-World (34%) seems very low to draw reasonable conclusions. Why not increase the number of demonstrations to more than 3 demonstrations in this setting?\n- Similar to Table 3, Table 4 only shows 2-3% improvement over Octo, with low success rates (<40% on LIBERO-90). Such a low final performance might not be enough to draw reasonable conclusion, especially when prior works have reported much superior performances on the same benchmarks [1,2].\n\n[1]  Haldar, Siddhant, Zhuoran Peng, and Lerrel Pinto. \"Baku: An efficient transformer for multi-task policy learning.\" Advances in Neural Information Processing Systems 37 (2024): 141208-141239.\n[2] Lee, Jason, et al. \"Molmoact: Action reasoning models that can reason in space.\" arXiv preprint arXiv:2508.07917 (2025)."}, "questions": {"value": "It would be great if the authors could address concerns listed in the weaknesses section. I am willing to increase my score once the concerns have been addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MK17Iyhk3h", "forum": "maYDrS6TvM", "replyto": "maYDrS6TvM", "signatures": ["ICLR.cc/2026/Conference/Submission10803/Reviewer_Ed7r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10803/Reviewer_Ed7r"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849864550, "cdate": 1761849864550, "tmdate": 1762922015788, "mdate": 1762922015788, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}