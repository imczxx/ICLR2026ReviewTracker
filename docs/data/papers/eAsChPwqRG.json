{"id": "eAsChPwqRG", "number": 22874, "cdate": 1758336570815, "mdate": 1759896841718, "content": {"title": "Deep Hashing Based on the von Mises-Fisher Distribution for Fast Large-Scale Image Retrieval", "abstract": "Deep hashing has become a pivotal technology in image retrieval, benefiting from advancements in deep learning and the computational advantages of hashing methods. Existing methods either rely on Euclidean distance, ignoring directional similarity and leading to retrieval errors in high-dimensional scenarios, or use deterministic spherical projections that neglect feature probability distributions, making them susceptible to noise interference. To address these challenges, we propose von Mises-Fisher Deep Hashing (vMF-DH), which introduces the von Mises-Fisher (vMF) distribution to map features onto the unit hypersphere. This approach models directional distributions (cosine similarity) instead of relying on Euclidean distances, leveraging the maximum entropy property of the vMF distribution to enhance both adaptability and robustness. Additionally, we design the vMF-Hash loss function, which regulates feature clustering through the vMF concentration parameter. This ensures the generation of binary hash codes that are compact within classes, well-separated across classes, and highly discriminative. Extensive results on multiple benchmark datasets show that vMF-DH outperforms current state-of-the-art deep hashing methods, demonstrating superior performance in terms of retrieval accuracy and robustness.", "tldr": "", "keywords": ["Image retrieval", "deep hashing", "von Mishes-Fisher distribution", "vMF-Hash loss"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/90defa980b9ccbac9f188462c634cc159f9c2adb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes vMF-DH, a  deep hashing method that addresses limitations of Euclidean-based and deterministic spherical hashing. By modeling features with von Mises-Fisher distributions on the unit hypersphere, it effectively captures directional similarity while enhancing noise robustness through maximum entropy properties. The designed vMF-Hash loss ensures compact intra-class and separable inter-class binary codes. Comprehensive experiments demonstrate state-of-the-art retrieval performance across multiple benchmarks, validating the method's effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The use of the von Mises-Fisher distribution is new to deep hashing. It leverages its maximum entropy property on the hypersphere for handling high-dimensional directional data.\n\n- The authors present the experimental evaluation on several benchmark datasets including MIRFLICKR-25K, NUS-WIDE, MS COCO, using several evaluation metrics including mAP, NDCG@1000, P@H≤2. The proposed vMF-DH method shows superior performance across different bit lengths and datasets."}, "weaknesses": {"value": "- The novelty of this work seems limited. The authors adapt a probabilistic vMF model for hash code learning without proper citation specifically in Section 3.2.\nThe paper does not adequately distinguish its contribution from prior work that also leverages cosine similarity or spherical embeddings (e.g., CSQ, CenterHash). The specific advantage of a probabilistic vMF model over these alternatives is not deeply discussed or empirically verified.\n\n- The core methodology is described in a confusing and insufficiently detailed manner. It is required to detail technical parts.\n\n- The deep analysis on empirical results why this work is better than the baselines is not given. The empirical studies should better verify the theoretical claims.\n\n- The computational complexity is not discussed.\n\n- The claim that vMF provides better \"adaptability\" and \"robustness to noise\" requires verification.\n\n- The writing requires further improvement. The writing contains repetitive phrases and convoluted sentences, especially in the Methodology and Loss Function sections."}, "questions": {"value": "Pls see the comments in Section Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xXYOMYIOBc", "forum": "eAsChPwqRG", "replyto": "eAsChPwqRG", "signatures": ["ICLR.cc/2026/Conference/Submission22874/Reviewer_cey4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22874/Reviewer_cey4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761618775956, "cdate": 1761618775956, "tmdate": 1762942422233, "mdate": 1762942422233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies deep hashing, and uses of the von Mises-Fisher distribution to model the directional similarity of high-dimensional features on a unit hypersphere. Experiments are conducted on three datasets and ResNet50 is used as backbone. Comparisons show boosted performance of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method works well as shown in experiments. \n2. This paper is well motivated and reasonable in methodolgy."}, "weaknesses": {"value": "1. The presentation should be improved. The figure 1 is not effective in showing the intuition of the proposed method. The loss function in eq. 3 is complicated. Fig.7 is informative enough, and should be moved to appendix. \n2. The proposed method does not always show best performance in comparison with existing works. Some improvements are marginal in some settings. \n3. The experiments are not quite convincing enough. Only one backbone is tested. ResNet50 is an outdated backbone. The study of hyperparameters should also be provided. \n4. The complexity and computational cost of the proposed method should also be discussed and evaluated. \n5. The proposed method relies on triplets as training samples, which could be sensitive to triplet sampling strategy, and leads to degraded training efficiency."}, "questions": {"value": "1. The authors should conducted more extensive experiments by using more recent backbones. \n2. The generalization capability of tuned hyperparameter across datasets should be evaluated. \n3. The training efficiency should be discussed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gjgqzd7ceu", "forum": "eAsChPwqRG", "replyto": "eAsChPwqRG", "signatures": ["ICLR.cc/2026/Conference/Submission22874/Reviewer_KL9L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22874/Reviewer_KL9L"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811502370, "cdate": 1761811502370, "tmdate": 1762942421974, "mdate": 1762942421974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on addressing limitations of existing deep hashing methods in large-scale image retrieval and proposes a novel solution called von Mises-Fisher Deep Hashing (vMF-DH). It points out that current methods either depend on Euclidean distance (ignoring directional similarity and causing retrieval errors in high-dimensional scenarios) or use deterministic spherical projections (neglecting feature probability distributions and being vulnerable to noise). To solve these issues, the paper introduces the von Mises-Fisher (vMF) distribution to map features onto the unit hypersphere, modeling directional distributions (cosine similarity) and leveraging the vMF distribution’s maximum entropy property to boost adaptability and robustness. It also designs the vMF-Hash loss function, which uses the vMF concentration parameter to regulate feature clustering, ensuring generated binary hash codes are compact within classes, well-separated across classes, and highly discriminative. Extensive experiments on multiple benchmark datasets verify that vMF-DH outperforms state-of-the-art deep hashing methods in retrieval accuracy and robustness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s strengths lay a solid foundation for its weak acceptance: it astutely targets two core flaws in existing deep hashing methods—overdependence on Euclidean distance and disregard for feature probability distributions, addressing a pressing need in large-scale image retrieval. \nIts integration of the von Mises-Fisher (vMF) distribution to model directional features and leverage its maximum entropy property is a theoretically innovative choice, while the custom vMF-Hash loss function effectively ensures hash codes are class-compact and inter-class separated, a key requirement for retrieval performance. Additionally, rigorous experiments across multiple benchmarks provide clear empirical proof that vMF-DH outperforms state-of-the-art methods, confirming its practical utility."}, "weaknesses": {"value": "The paper lacks a systematic analysis of how the vMF concentration parameter’s magnitude influences model behavior, leaving a gap in understanding the method’s internal dynamics; it also does not compare vMF-DH’s memory footprint with baselines nor test its performance on datasets with highly imbalanced class distributions, which limits confidence in its generalizability and deployment potential."}, "questions": {"value": "The paper uses the vMF concentration parameter in the vMF-Hash loss function to regulate feature clustering, but it does not elaborate on the selection strategy of this parameter. Could you explain how you determined the optimal range or initial value of the vMF concentration parameter in experiments, and whether there is an adaptive adjustment mechanism that can dynamically optimize this parameter according to different dataset characteristics?\nThe paper mentions that vMF-DH outperforms state-of-the-art methods in retrieval accuracy, but large-scale image retrieval also requires high computational efficiency. Can you provide specific experimental data (such as hash code generation time, query response time) to compare the computational efficiency of vMF-DH with baseline methods, and explain whether the introduction of the vMF distribution increases model complexity or inference latency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Pej9GLdRPg", "forum": "eAsChPwqRG", "replyto": "eAsChPwqRG", "signatures": ["ICLR.cc/2026/Conference/Submission22874/Reviewer_Y35N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22874/Reviewer_Y35N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000067966, "cdate": 1762000067966, "tmdate": 1762942421723, "mdate": 1762942421723, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a deep hashing method (vMF-DH) that maps features onto the unit hypersphere using the von Mises–Fisher (vMF) distribution, aiming to model directional similarity rather than Euclidean distance. A new loss function is introduced to control feature concentration and encourage compact within-class and separated across-class hash codes. Experiments on standard image retrieval benchmarks (MIRFLICKR-25K, NUS-WIDE, MS-COCO) are reported to show improvements over prior deep hashing methods."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1) Empirical results seem to show good results relative to prior work.\n2) The idea of using the von Mises-Fisher Distribution to model unit normalized embedded data seems to be a good approach to take."}, "weaknesses": {"value": "1) The paper is not written well at all, in many respects, as I will specify next. Therefore, I find it far from ICLR standards in its current form.\n2) The main motivation of the paper is unclear - What exactly is the problem with prior approaches and how does the current one deal with them. The reasoning is based on sentences like \"High-dimensional data inherently\nexhibits spherical distribution characteristics\" (line 121) and \" the directional clustering properties of high-dimensional features\" (line 157), which are not generally true. Neither is any empirical evidence provided.\n3) The main Figures (1 and 2) are very confusing and do not assist in understanding the principles behind the method. For example, Figure 2 contains quite a few color inconsistencies, notations that appear nowhere and part that are not refered to.\n4) Method description is incomplete and unclear, including unclear and missing notations. E.g. what is C_d(.)? What are exp_{p_y} and exp_z?\n5) Results might be strong, but they are not presented in an understandable manner - Relevant dataset details a mostly missing, measures not explained, etc'."}, "questions": {"value": "."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mREjDO2GF5", "forum": "eAsChPwqRG", "replyto": "eAsChPwqRG", "signatures": ["ICLR.cc/2026/Conference/Submission22874/Reviewer_G89N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22874/Reviewer_G89N"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762028669030, "cdate": 1762028669030, "tmdate": 1762942421495, "mdate": 1762942421495, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}