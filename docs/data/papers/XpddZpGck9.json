{"id": "XpddZpGck9", "number": 5211, "cdate": 1757866888272, "mdate": 1763570668064, "content": {"title": "UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking", "abstract": "We present UniTrack, a plug-and-play graph-theoretic loss function designed to significantly enhance multi-object tracking (MOT) performance by directly optimizing tracking-specific objectives through unified differentiable learning. Unlike prior graph-based MOT methods that redesign tracking architectures, UniTrack provides a universal training objective that integrates detection accuracy, identity preservation, and spatiotemporal consistency into a single end-to-end trainable loss function, enabling seamless integration with existing MOT systems without architectural modifications. Through differentiable graph representation learning, UniTrack enables networks to learn holistic representations of motion continuity and identity relationships across frames. We validate UniTrack across diverse tracking models and multiple challenging benchmarks, demonstrating consistent improvements across all tested architectures and datasets including Trackformer, MOTR, FairMOT, ByteTrack, GTR,  and MOTE. Extensive evaluations show up to 53\\% reduction in identity switches and 12\\% IDF1 improvements across challenging benchmarks, with GTR achieving peak performance gains of 9.7\\% MOTA on SportsMOT.", "tldr": "UniTrack is a differentiable graph representation learning framework that unifies detection, identity preservation, and temporal consistency for improved multi-object tracking.", "keywords": ["Multi-object tracking", "graph representation learning", "differentiable optimization", "end-to-end learning", "identity preservation", "spatio-temporal modeling", "flow networks", "unified loss functions", "video understanding", "deep learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c095d1f25939fc641a79dd4b0cfd0f48b60e7682.pdf", "supplementary_material": "/attachment/dae56fc21439a5c33c44f9c24756dede824b175c.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces UniTrack, a differentiable graph representation learning framework designed to unify detection accuracy, identity preservation, and spatio-temporal consistency for multi-object tracking (MOT). Instead of relying on separate detection and association modules, UniTrack formulates tracking as a graph flow optimization problem and introduces a unified loss composed of three parts‚Äîflow, spatial, and temporal‚Äîoptimized in an end-to-end differentiable manner. The framework includes an adaptive Laplacian-based weighting mechanism and can be integrated into existing trackers (e.g., MOTR, TrackFormer, ByteTrack, FairMOT, GTR) without architectural modifications. Experiments across MOT17, MOT20, SportsMOT, and DanceTrack show consistent gains (up to +9.7% MOTA, +12.3% IDF1) and reduced identity switches, highlighting the effectiveness and generality of the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. UniTrack combines detection, identity, and temporal consistency into a single differentiable loss.\n2. UniTrack can be applied to tracking architectures without network modification, demonstrating practical flexibility.\n3. Experiments across MOT17, MOT20, SportsMOT, and DanceTrack show consistent gains (up to +9.7% MOTA, +12.3% IDF1) and reduced identity switches, highlighting the effectiveness and generality of the proposed framework."}, "weaknesses": {"value": "1. The method introduces more training complexity and memory overhead; scalability to large scenes or dense MOT scenarios remains a concern.\n2. The authors are suggested to add more ablation studies on the adaptive Laplacian weighting.\n3. The ablation section focuses mainly on component removal but could include more fine-grained analysis of hyperparameters (e.g., Œªs, Œªt updates, thresholding strategies).\n4. It is recommended that the authors compare UniTrack with more recent MOT approaches, especially those that incorporate memory-based mechanisms such as MOTRv2, MeMOTR, and MOTIP, to better show the advantages of the proposed framework."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oT2WO7hmix", "forum": "XpddZpGck9", "replyto": "XpddZpGck9", "signatures": ["ICLR.cc/2026/Conference/Submission5211/Reviewer_3Pqh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5211/Reviewer_3Pqh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5211/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619665210, "cdate": 1761619665210, "tmdate": 1762917949070, "mdate": 1762917949070, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a new loss for multi-object tracking. This loss is based on graph theory, which integrates detection accuracy, identity preservation, and spatiotemporal consistency. Convergence and consistency of the loss are theoretically validated. Experiments on multiple trackers and multiple benchmarks demonstrate the effectiveness of the proposed loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of using a plug-and-ply graph-based loss makes sense.\n2. The implementation of the graph-based loss is suitable for the MOT task.\n3. The analysis of the loss is reasonable.\n4. The loss is effective with different trackers on multiple benchmarks, which shows the universality of the proposed loss.\n\nOverall, this work develops a loss which has both solid theoretic foundation and obvious improvement in practice. I believe this work will benefit the community."}, "weaknesses": {"value": "The weights of spatial and temporal loss are adaptive to the graph connectivity. It is encouraged to compare with other solutions, like adaptive parameters directly learned by the network, and fixed parameters."}, "questions": {"value": "Will the code be made publicly available to help re-implement and apply this work? It would further benefit people in this field."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ij8LxwoZFC", "forum": "XpddZpGck9", "replyto": "XpddZpGck9", "signatures": ["ICLR.cc/2026/Conference/Submission5211/Reviewer_m6K5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5211/Reviewer_m6K5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5211/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973142688, "cdate": 1761973142688, "tmdate": 1762917948726, "mdate": 1762917948726, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "UniTrack introduces a training-only loss that couples three differentiable terms: flow, spatial, and temporal inside a graph, over a sliding-window graph with flow conservation and adaptive ùúÜ. Œª chosen by Laplacian connectivity; it is added to TrackFormer/MOTR/FairMOT/ByteTrack/GTR/MOTE without inference overhead. Reported gains across several mot benchmarks including mot 17/20."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. One of the biggest advantages is that the proposed method is architecture‚Äëagnostic: it demonstrates improvements when plugged into diverse families (end-to-end transformers, joint detection-tracking, tracking-by-detection, global transformers).\n\n2. The proposed unified objective makes sense as it merges detection quality and identity preservation, and benefit the end-to-end MOT training.\n\n3. The authors show Clear ablation on error types (Table‚ÄØ3), clearly presenting which term combats which failure mode; qualitative figures are convincing."}, "weaknesses": {"value": "1. The details of the differentiability of the flow term are not clearly conveyed. The loss scales by factors that depend on false positives/false negatives, but the paper does not define a differentiable surrogate for those counts. As far as i understand that derivation treats the FP/FN counts inside the loss as if they were constants and never explains how those counts are made differentiable with respect to the model outputs. In practice, FP/FN are discrete functions of predictions (they jump when a score crosses a threshold.\n\n2. Inconsistent definitions: the paper has defined Œªs and Œªt ((Eq. 8), as they are deterministic functions of graph connectivity (via Laplacian eigenvalues). Then, in eq.10, the Œªs and Œªt are treated as learnable parameters that can be updated by backprop. \n\n3. The paper includes frame-rate analysis and normalizes by the frame interval, which is good. Still, some ablations suggest removing the temporal term can improve certain metrics. eg MOTA by 2.1.\n\n4. Prior work already models inter-object relations and global data association with differentiable mechanisms [1]\n\n[1] SLAck: Semantic, Location, and Appearance Aware Open-Vocabulary Tracking"}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Dx1AxEMGU1", "forum": "XpddZpGck9", "replyto": "XpddZpGck9", "signatures": ["ICLR.cc/2026/Conference/Submission5211/Reviewer_fpzX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5211/Reviewer_fpzX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5211/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762115559299, "cdate": 1762115559299, "tmdate": 1762917948327, "mdate": 1762917948327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}