{"id": "Iio6islT2Z", "number": 14177, "cdate": 1758229757135, "mdate": 1759897386008, "content": {"title": "Improving Protein Sequence Design through Designability Preference Optimization", "abstract": "Protein sequence design methods have demonstrated strong performance in sequence generation for de novo protein design. However, as the training objective was sequence recovery, it does not guarantee designability--the likelihood that a designed sequence folds into the desired structure. To bridge this gap, we redefine the training objective by steering sequence generation toward high designability. To do this, we integrate Direct Preference Optimization (DPO), using AlphaFold pLDDT scores as the preference signal, which significantly improves the in silico design success rate. To further refine sequence generation at a finer, residue-level granularity, we introduce Residue-level Designability Preference Optimization (ResiDPO), which applies residue-level structural rewards and decouples optimization across residues. This enables direct improvement in designability while preserving regions that already perform well. Using a curated dataset with residue-level annotations, we fine-tune LigandMPNN with ResiDPO to obtain EnhancedMPNN, which achieves a nearly 3-fold increase in in silico design success rate (from 6.56% to 17.57%) on a challenging enzyme design benchmark.", "tldr": "This paper tackles the critical designability gap in protein sequence design by decoupling DPO at the residue-level using AlphaFold pLDDT scores, achieving a nearly 3-fold increase in in silico design success.", "keywords": ["de novo protein design", "protein design", "inverse folding", "sequence optimization"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0896707464a0b033e7ce64aa7ea1b7dfb7079b00.pdf", "supplementary_material": "/attachment/891b0ad3d545e3ecb064902979933bb5b159b47e.zip"}, "replies": [{"content": {"summary": {"value": "The paper applies DPO to protein sequence design by using residue-level pLDDT scores from AlphaFold2 as rewards. They split the loss into two parts - one optimizes low-pLDDT residues (preference learning), one preserves high-pLDDT residues (KL regularization). This gives \"EnhancedMPNN\" which improves enzyme design success from 6.56% to 17.57%."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem is well-motivated - sequence recovery doesn't equal designability, and framing this as an alignment problem makes sense.\n\nThe threefold improvement on enzyme benchmarks looks good (Fig 2a). The method also generalizes decently to binder design.\n\nDecoupling the DPO loss at residue level is intuitive and seems to help based on the ablations.\n\nThe dataset with residue-level pLDDT labels could be useful."}, "weaknesses": {"value": "The core contribution is pretty incremental. It's basically DPO with residue-level splitting instead of sequence-level. Section 3.3 makes it sound complicated but the idea is simple if I got it right: apply preference loss where pLDDT is low, apply KL where it's high. This isn't a major conceptual advance, more of a good engineering. The paper oversells it as \"novel alignment algorithm.\"\n\nCircular evaluation. You train using AF2 pLDDT and evaluate using AF2 predictions. How do we know this actually improves real designability vs just learning to game AlphaFold's confidence? Sure, pLDDT correlates with structure accuracy, but the correlation isn't perfect. Would be nice to see at least some validation on structures not from PDB - like actually designed proteins with known experimental outcomes.\n\nPreference pair generation seems questionable. \"Relative sampling\" creates pairs from any sequences with pLDDT difference >10, even if both are mediocre (like 50 vs 60). The model is learning preferences from comparing bad sequences to slightly-less-bad sequences. The \"application sampling\" approach (high vs low quality) makes more sense but they reject it due to insufficient data. Quality-quantity tradeoff that isn't well justified.\n\nToo many hyperparameters. The authors claim \"comprehensive grid search\" but don't show the full search space or give clear guidance for new applications. For someone wanting to use this on a different protein design task, what values should they use? The method seems tuned specifically to their benchmarks.\n\nModest improvements over standard DPO. Table 1 shows 66.08% vs 62.11% pLDDT accuracy - that's a 4 percentage point improvement. Is all the added complexity worth it? No error bars or significance tests provided. And standard DPO already gives a decent boost over baseline (57.71% to 62.11%), so DPO itself works pretty well.\n\nThe mechanism isn't well understood. Section 4.5 shows EnhancedMPNN uses more charged residues and less Alanine. The explanation about \"reducing ambiguity\" is vague. Why do these specific changes improve designability? Is this a general principle or an artifact of the training data? Without further insight it's hard to know if this will generalize to other design problems.\n\nSome results look cherry-picked. Main text shows 5 enzymes, but they mention \"expanding to 41 enzymes\" buried in the appendix. Why not show all 41 in the main results? Makes you wonder why?"}, "questions": {"value": "How does this compare to other recent inverse folding methods like those in ProteinBench (https://proteinbench.github.io)?\n\nThe success rate is still only 17.57% - what about the 82% that fail? Any analysis of failure modes?\n\nWith α=10 for pLDDT margin, how sensitive is this? \n\nCan you show the full hyperparameter grid search results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nQGE8UJmGG", "forum": "Iio6islT2Z", "replyto": "Iio6islT2Z", "signatures": ["ICLR.cc/2026/Conference/Submission14177/Reviewer_eyxe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14177/Reviewer_eyxe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761846678704, "cdate": 1761846678704, "tmdate": 1762924634294, "mdate": 1762924634294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ResiDPO, a residue-level variant of Direct Preference Optimization (DPO) for protein sequence design. The goal is to improve designability rather than sequence recovery. Using AlphaFold2 pLDDT as a quantitative preference signal, the authors decompose DPO into residue-level preference and constraint terms. Fine-tuning LigandMPNN with this method (EnhancedMPNN) leads to a 3× increase in in-silico success rate on enzyme benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe residue-level optimization idea is well-motivated and fits naturally with protein structure design, where local regions can be evaluated independently and conserved regions should remain stable.\n2.\tThe method is conceptually sound and mathematically well-formulated, with clear derivations and intuitive design choices."}, "weaknesses": {"value": "1.\tThe evaluation is limited and entirely in silico. All preference signals and success metrics rely on AlphaFold2 (AF2), raising concerns that the model may simply exploit AF2’s scoring patterns rather than genuinely improving folding or stability. No cross-validation with other structure predictors (e.g., ESMFold, RoseTTAFold) or experimental validation is provided.\n2.\tThe set of baselines is rather limited, lacking comparisons with other sequence design methods such as ESM-IF, PiFold, or KW-Design. Including results on standard protein design benchmarks (e.g., CATH) would better demonstrate the generality of the proposed method.\n3.\tSome references and formatting look unpolished (e.g., wrong citation format, wrong bolding in Table 1), which hurts readability."}, "questions": {"value": "1.\tAs noted in Weakness 1, could you verify whether ResiDPO-trained models generalize to structure predictors beyond AF2, such as ESMFold or RoseTTAFold?\n2.\tWhat is the computational cost of generating preference pairs with AF2, and how feasible is this pipeline for larger datasets?\n3.\tHow well does ResiDPO transfer to other architectures (e.g., ProteinMPNN, PiFold, LM-Design) on general protein design benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0wjefHjoe6", "forum": "Iio6islT2Z", "replyto": "Iio6islT2Z", "signatures": ["ICLR.cc/2026/Conference/Submission14177/Reviewer_Tc3D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14177/Reviewer_Tc3D"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912000225, "cdate": 1761912000225, "tmdate": 1762924633838, "mdate": 1762924633838, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ResiDPO (Residue-level Direct Preference Optimization), a fine-tuning framework for protein sequence design that aims to align model objectives with designability rather than sequence recovery. The method uses AlphaFold2 pLDDT scores as a proxy for foldability and constructs residue-level preference pairs to encourage the model to favor sequences that are more likely to fold into the target backbone. The resulting model, called EnhancedMPNN, is evaluated on enzyme and binder benchmarks, showing an improvement in in silico design success rate compared with LigandMPNN and standard DPO fine-tuning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The misalignment between sequence-recovery training and true designability is well motivated and clearly articulated.\n2. Introducing residue-level decomposition (RPL + RCL) is a technically neat way to balance preference learning and knowledge retention, avoiding catastrophic forgetting.\n3. Experiments on enzyme and binder benchmarks show consistent in silico improvements in design success rate and reasonable ablations."}, "weaknesses": {"value": "1. ResiDPO is explicitly trained to generate sequences that yield higher AlphaFold2 pLDDT scores and is then evaluated using the same metric, creating a self-consistency bias that may inflate the reported gains in design success.\nMoreover, pLDDT measures local confidence within AlphaFold2 rather than true physical or thermodynamic stability.\nUsing it as the sole optimization constraint is therefore too weak to capture real designability and may encourage the model to exploit AlphaFold2’s scoring patterns instead of learning generalizable folding principles.\nValidation with alternative predictors (e.g., ESMFold, RoseTTAFold) or complementary metrics such as PAE, energy-based stability would provide stronger evidence of genuine foldability improvement.\n\n2. Although ResiDPO is presented as improving “designability,” the paper offers little analysis of what changes in the designed sequences drive improvement. For example, which residue types or structural motifs are favored after training, and do these align with known biophysical intuitions?   Although EnhancedMPNN shows shifts in amino-acid usage, the paper does not analyze whether these changes correspond to physically meaningful improvements or merely exploit AF2 preferences.\n\n3. The benchmarks (enzymes and binders) are both relatively small and structurally homogeneous. It remains unclear whether ResiDPO generalizes to larger or more complex backbones (e.g., multi-domain proteins, transmembrane proteins). The absence of cross-domain evaluation weakens the claim that the method enhances \"overall designability\".\n\n4. The proposed PDB-D dataset consists mainly of AF2-derived per-residue pLDDT labels. Its novelty and added value over existing resources are not clearly demonstrated."}, "questions": {"value": "1. Given that AlphaFold3 now offers more accurate modeling of complexes, ligands, and residue-level confidence, why did the authors choose to rely solely on AlphaFold2 for both preference generation and evaluation?\nWould adopting AF3 or combining AF2 and AF3 predictions alter the designability signal or improve validation reliability?\n\n2. Could the authors quantify the additional computational cost of applying DPO at the residue level compared with standard sequence-level DPO, and clarify whether the reported improvements in designability justify this overhead? \n\n3. Do performance gains distribute uniformly across different secondary-structure elements (α-helices, β-sheets, loops), or are improvements concentrated in specific regions?\n\n4. Can the residue-level preference framework (RPL/RCL) be applied to other sequence-design models or diffusion-based models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MgZMviQoLW", "forum": "Iio6islT2Z", "replyto": "Iio6islT2Z", "signatures": ["ICLR.cc/2026/Conference/Submission14177/Reviewer_3uHx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14177/Reviewer_3uHx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762747659289, "cdate": 1762747659289, "tmdate": 1762924633176, "mdate": 1762924633176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the gap between sequence recovery and design success (designability) in protein sequence design. It introduces Direct Preference Optimization (DPO) guided by AlphaFold pLDDT as an objective signal to bias generation toward sequences that are more likely to fold to a target backbone. To improve granularity and stability, the authors propose Residue-level DPO (ResiDPO), which applies preference rewards to residues. They fine-tune LigandMPNN with ResiDPO to create EnhancedMPNN, reporting a near 3× increase in in silico design success on an enzyme benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The work is well-motivated.  The work targets a well-identified objective mismatch in protein sequence design—optimizing for sequence recovery rather than designability.\n\n2. The presentation is clear and easy to follow."}, "weaknesses": {"value": "1. The methodological novelty appears limited. The work reads primarily as a straightforward application of DPO to protein sequence design.\n\n2. Results should be broken down by secondary-structure class (all-α, all-β, α/β, α+β). All-α targets are typically easier to design than all-β, so aggregate reporting can mask meaningful differences. Please report the fold-class composition of the evaluation sets and stratified metrics to ensure fair comparisons.\n\n3. The paper relies heavily on pLDDT Accuracy for ablations but presents no empirical validation that this proxy tracks the final design success metric. At minimum, provide a correlation/ rank-correlation analysis (and calibration plots) between pLDDT Accuracy and AF2-based success on a smaller held-out subset with rigorous statistical testing. \n\n4. Evidence for data efficiency should be on validation, with overfitting controls. In Section 4.6 and Figure 5, the data-efficiency comparison (ResiDPO vs. DPO with varying sample sizes) should be evaluated on a validation set, not the training set, to support generalization claims. \n\n5. Missing related work. Important DPO-based protein design papers are not cited or discussed in Section 2. Line 141 mentions peptide design. Please include antibody-design applications that use DPO, such as AbDPO and AbNovo. In particular, AbDPO also introduces a residue-level DPO variant and reports effectiveness/efficiency gains over vanilla DPO. \n\n6. Writing and formatting issues requiring proofreading.\n\n   a. Mathematical expressions contain unreadable or stray symbols (e.g., Lines 198, 199, 372). \n\n   b. Line 51: “…in large language models (LLMs) Lla;” — “Lla” appears to be a typo or placeholder; clarify or remove."}, "questions": {"value": "Please address the questions in the Weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jVgLuWMrU2", "forum": "Iio6islT2Z", "replyto": "Iio6islT2Z", "signatures": ["ICLR.cc/2026/Conference/Submission14177/Reviewer_q5bv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14177/Reviewer_q5bv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762843480664, "cdate": 1762843480664, "tmdate": 1762924632792, "mdate": 1762924632792, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}