{"id": "bU8tRjuanU", "number": 18061, "cdate": 1758283376742, "mdate": 1759897135611, "content": {"title": "Low-Rank Attention and Contrastive Alignment for Deep Multi-View Clustering", "abstract": "Recent years have witnessed significant advancements in deep multi-view clustering (MVC). However, prevailing methods exhibit three critical limitations: (1) poor scalability for large-scale datasets, (2) neglect of anchor semantic consistency in feature alignment, and (3) inability to capture high-order feature interactions. To overcome these challenges, we propose a Low-Rank Attention and Contrastive Alignment framework (LRACA). Unlike conventional approaches that align sample-level features in shared subspaces, LRACA employs a category-aware anchor generation module to directly align high-level semantic prototypes (i.e., category centers) across views, explicitly enforcing clustering semantic consistency. Furthermore, we devise a dynamic low-rank attention mechanism to enhance feature discriminability, where entropy regularization constrains attention weight distributions to derive clustering pseudo-labels. Finally, a pseudo-label-guided cluster-level contrastive learning module maximizes cross-view mutual information through a feed-forward optimization paradigm. Extensive experiments on six large-scale multi-view datasets demonstrate that LRACA significantly outperforms state-of-the-art methods.", "tldr": "", "keywords": ["Multi-view clustering", "Low-rank attention", "Contrastive learning", "Deep clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7ce28095641fd207921397e8ba36ebee101806e7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the three major bottlenecks of deep multi-view clustering (MVC) on large-scale data—poor scalability, inconsistent semantic anchors, and inability to model high-order feature interactions—by proposing an end-to-end framework called LRACA (Low-Rank Attention and Contrastive Alignment). Its core concept is to achieve efficient and consistent cross-view alignment at both the feature and semantic levels. First, a category-aware anchor sampling module is used to generate cross-view semantic prototypes, which are then weighted by a low-rank self-attention module to enhance discriminability. Subsequently, a pseudo-label-based cluster-level contrastive learning mechanism is employed to maximize cross-view mutual information under the guidance of an anchor graph, thereby simultaneously optimizing both intra-view discriminability and inter-view consistency. The algorithm training consists of two stages: pre-training (reconstruction and anchor alignment) and contrastive fine-tuning. The overall loss consists of a reconstruction loss, entropy regularization, and a contrastive loss."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. RACA combines low-rank attention with an anchor guidance mechanism to achieve a linear approximation of the traditional quadratic complexity self-attention (O(Nk)). At the same time, by replacing the fixed JL projection with a dynamic learnable projection matrix Θ, the low-rank space can adapt to the data distribution, balancing expressiveness and efficiency.\n2. Through category-aware anchor generation and cross-view anchor alignment loss (L_align-anchor), the center consistency of different views is constrained at the cluster semantic level, avoiding the semantic drift of randomly sampled anchors.\n3. Cluster probability vectors are used instead of instance features for comparison, which effectively reduces pseudo-label noise and improves inter-cluster distinguishability, achieving cross-view semantic alignment under maximum mutual information."}, "weaknesses": {"value": "1. The anchor generation and pseudo-label refinement are mutually dependent, which may cause semantic drift and unstable convergence under noisy initialization.\n2. The low-rank attention projection matrix lacks orthogonality constraints, leading to potential subspace redundancy and degraded discriminability.\n3The cluster-level contrastive loss and entropy regularization are not theoretically well-grounded, weakening the mutual-information interpretation and optimization stability.\n4. The experimental validation is incomplete and partly inconsistent, with abnormal baseline results, missing variance analysis, and insufficient evaluation on smaller or incomplete multi-view scenarios."}, "questions": {"value": "1. In Section 3.1 of the algorithm, pseudo labels are generated on the fusion feature Z_fusion through K-means and then reversely guide the anchor update. Z_fusion relies on the encoding of each view and the anchor features. This bootstrap dependence may lead to semantic drift and unstable convergence. In particular, when the initial clustering deviation is large, the model may fall into local consistent misalignment. How should the author consider this problem?\n2. The projection matrix Θ constructed by softmax(AW_c) in Equation (9) lacks orthogonal constraints, and its rows may be highly correlated, resulting in feature redundancy and subspace collapse during multi-head attention fusion. In addition, the calculation forms of K̃ and Ṽ in Equations (10)–(11) are exactly the same, which may cause semantic information duplication at the implementation level and weaken the complementary effect of Key/Value.\n3. What is the purpose of summing all a_ij in Equation (12)? This may lead to excessive gradient smoothing, making it impossible for attention to fully focus on the discriminative anchor in the early stage. Will sample normalization or relative entropy constraints be used instead of pure Shannon entropy to enhance sparse discrimination?\n4. Although sensitivity analysis of λ_c and λ_ent was performed, only partial surface plots were presented, lacking quantitative trends and statistical variances, and no explanation was given of how α balances the reconstruction and comparison terms in Equation (16).\n5. Some sentences are repeated (e.g., \"we propose we propose\"), capitalization is mixed (Multi-View vs. multi-view), and punctuation and spacing errors are frequent; the layout of Equation (11) is misaligned; \"PmLR\" in the literature citation should be \"PMLR\"; and the reference format is inconsistent (some include doi, some do not have page numbers)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DxPMU9tNGe", "forum": "bU8tRjuanU", "replyto": "bU8tRjuanU", "signatures": ["ICLR.cc/2026/Conference/Submission18061/Reviewer_TEUL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18061/Reviewer_TEUL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18061/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761281636843, "cdate": 1761281636843, "tmdate": 1762927849724, "mdate": 1762927849724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LRACA, a deep multi-view clustering framework designed to overcome key limitations in scalability, semantic alignment, and high-order feature interaction. The method employs a category-aware anchor generation module to align high-level semantic prototypes across views, a dynamic low-rank attention mechanism with entropy regularization to reduce computational complexity while enhancing feature discriminability, and a pseudo-label-guided cluster-level contrastive learning module to maximize cross-view mutual information. Extensive experiments on six large-scale multi-view benchmarks demonstrate that LRACA significantly outperforms state-of-the-art methods in clustering performance and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed LRACA are tested on multiple large-scale datasets, demonstrating its good scalability."}, "weaknesses": {"value": "1. The introduction about the proposed LRACA is not clear, it’s difficult to follow it. For example, Eq. 4 is confusing and what’s the meaning of g_(ϕ_v ).\n2. There are many grammatical errors and typos, such as “we propose we propose a Low-Rank” in the Introduction.\n3. The authors claimed that the proposed LRACA improves the running efficiency, but it lacks the comparison about running time.\n4. From the experimental results, the proposed algorithm introduces many modules, but the improvement it brings is very limited, which makes people doubt its significance."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "u2A3KarbiG", "forum": "bU8tRjuanU", "replyto": "bU8tRjuanU", "signatures": ["ICLR.cc/2026/Conference/Submission18061/Reviewer_o5mJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18061/Reviewer_o5mJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18061/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761310318156, "cdate": 1761310318156, "tmdate": 1762927849283, "mdate": 1762927849283, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on three critical limitations in existing deep multi-view clustering (MVC) methods, and proposes a Low-Rank Attention and Contrastive Alignment framework (LRACA) model to deal with them. LRACA integrates a category-aware anchor generation strategy, a dynamic low-rank attention mechanism, and a cluster-level contrastive learning scheme to improve semantic consistency and feature discriminability across datasets. Additionally, LRACA reduces attention complexity to approximately linear form and aligns cluster prototypes across multiple views using pseudo-labels. Experiments on six large-scale datasets demonstrate that LRACA significantly outperforms state-of-the-art methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Low-rank attention reduces computation costs when compared to full attention, which makes LRACA more applicable in large-scale datasets.\n2. The structural organization of this paper is appropriate.\n3. Extensive experiments show that the proposed model is comparable with existing MVC methods."}, "weaknesses": {"value": "1. The writing needs improvement. The authors need to tell how they address three critical limitations.\n2. The novelty is insufficient. The efficiency of the proposed method lies in the low-rank attention mechanism and the cluster-level contrastive learning, but there has been a lot of research in these directions. \n3. Many expressions are confusing. For example, “aggressive low-rank approximation” and “fine-grained calculations on the entire sample”. Why is the low-rank approximation aggressive? Why are the calculations on the entire sample fine-grained?\n4. Some symbols are not unified or wrong, such as $y_{pseudo, i}$ and the symbol in Line 148. And what is $\\mathcal{S}_c^{(v)}$?"}, "questions": {"value": "1. The limitations of MVC are confusing. What are the “high-order feature interactions”? Why can’t the MVC methods capture the interactions? Additionally, the related work has provided many methods to address the large-scale MVC problem.\n2. This paper focuses on multi-view clustering. Why don’t the authors apply cross-attention among view features but self-attention?\n3. What is “C’s SVD principal component”? “C” is a scalar in the paper.\n4. How does Eq. 12 encourage sparsity for discriminative features while maintaining diversity?\n5. Why does the traditional contrastive learning suffer from “sample-level noise”? What is “sample-level noise”?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RIKJBdCcA7", "forum": "bU8tRjuanU", "replyto": "bU8tRjuanU", "signatures": ["ICLR.cc/2026/Conference/Submission18061/Reviewer_6JPQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18061/Reviewer_6JPQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18061/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761383933157, "cdate": 1761383933157, "tmdate": 1762927848727, "mdate": 1762927848727, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a deep multi-view clustering algorithm equipped with an anchor-based attention mechanism and cluster-based contrastive learning, which achieves good performance, but has many problems, as detailed in the weaknesses section."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes a deep multi-view clustering algorithm equipped with an anchor-based attention mechanism and cluster-based contrastive learning, which achieves good performance."}, "weaknesses": {"value": "1. The variables in the title of Figure 2 and in lines 230 and 232 are not bolded. Please check other places yourself.\n\n2. The parentheses in line 148 are incorrect.\n\n3. Equation 4 is missing a \"|\" separator.\n\n4. Lines 168-172, please clarify the meanings of $ \\mathcal{S}_{k}^{(c)} $,   $ \\mathcal{S}^{(v)}_c $, and $\\mathbf{S}^{(v)}_c$; their usage is inconsistent.\n\n5. Line 175, the decoder g is inconsistent with D in Equation 1. Furthermore, this process should be placed in or near Equation 8.\n\n6. Line 146, $\\mathbf{X} \\in \\mathbb{R}^{d_v \\times N}$, line 200, $\\mathbf{X} \\in \\mathbb{R}^{N \\times d}$? From lines 200 to 234, as I understand it, $\\mathbf{X}^{v}$ should be corrected to $\\mathbf{X}$, and $\\mathbf{X}$ should be specified as the concatenation of the original features.\n\n7. Line 203, please use matrix concatenation notation, such as [A1, A2] or [A1; A2]. A symbol cannot represent both a set and a matrix, and their corresponding operators cannot be mixed.\n\n8. The comma in line 205 needs to be moved after formula 8.\n\n9. The superscript of the variable for the $v$-th viewpoint is sometimes $v$ and sometimes $(v)$.\n\n10. It's $\\mathbf{W}_c$ in formula 9, but $\\mathbf{W}_A$ in Figure 1.\n\n11. Some words are missing spaces, for example, lines 210, 227, 379, and 251.\n\n12. In line 208, if $\\mathbf{A} \\in \\mathbb{R}^{M \\times d}$, $\\mathbf{W}_c \\in \\mathbb{R}^{d \\times k}$, then $\\mathbf{\\Theta} \\in \\mathbb{R}^{M \\times k}$. Since $\\mathbf{X} \\in R^{N \\times d}$, the calculations in formulas 10 and 11 are problematic.\n\n13. In line 209, the projection matrix is $​​\\mathbf{W}_c$, not $\\mathbf{\\Theta}$.\n\n14. In line 211, \"C's SVD principal component\"?\n\n15. In line 227, is $\\mathbf{W}_{Q}$ the query matrix? Shouldn't $\\mathbf{Q}$ be the query matrix?\n\n16. Line 231, i and j are not in mathematical format.\n\n17. Line 249, $head_{i}$ is not well described; it is neither shown in Figure 1 nor given a formula or source.\n\n18. Line 275, network weights are matrices and should be in uppercase and bold.\n\n19. The loss function is a scalar and does not need to be bolded.\n\n20. Lines 280, 281, and 285: Formula format is incorrect.\n\n21. There are some errors in the bold and underline in Table 2.\n\n22. Table 3: Is it LC or CL? Furthermore, the \"w/o L\" mentioned in the title does not appear in the table.\n\n23. This paper is poorly organized and written, especially Section 3. Combined with the above errors, this makes the rough paper unconvincing.\n\n24. PUR is a relatively weak metric, usually not lower than ACC; therefore, ARI and F1-Score are more recommended.\n\n25. The comparison algorithms mainly consist of early and traditional algorithms, which lacks rationality.\n\n26. The main contributions of this paper are the anchor-based attention mechanism and cluster-based contrastive learning. However, these two ideas are not original, although there are subtle differences between different works. Therefore, this paper should clearly explain why these two methods are used, how their specific designs or formulas are derived, their similarities and differences with other works, their advantages and disadvantages, and the final results achieved.\n\n27. The abstract mentions the scalability problem of existing models, but since deep clustering uses batch training and online learning, it is inherently scalable. The use of anchors and projections further enhances its scalability. Furthermore, the solution presented in this paper is still anchors and projections.\n\n28. The purpose of scalability is to save memory and computational overhead, and the authors emphasize \"efficient\" in their contributions; however, the paper lacks an analysis of space complexity and does not provide a comparison of memory and runtime in the experiments.\n\n29. The abstract also mentions the problem of anchor misalignment, but not all anchor-based methods require alignment; it depends on whether there are cross-view interactions at the anchor level in the specific architecture design. When alignment is required, the corresponding methods all perform alignment operations, and Equation 6 is just the simplest one.\n\n30. The abstract also mentions the lack of higher-order feature interactions. In fact, low-dimensional embeddings based on neural networks and various graph-based learning methods are all high-order features.\n\n31. Considering the three points above, the authors should be more careful in their motivations.\n\n32. In the ablation experiments, $\\mathcal{L}_{ent}$ is merely an entropy regularization; w/o $\\mathcal{L}\\_{ent}$ does not mean the cancellation of low-rank projection. The differences between no projection, JL projection, SVD projection, and dynamic projection should be observed.\n\n33. While the model claims to be end-to-end, it seems that each iteration requires calling $k$-means to generate pseudo-labels and applying them to the final output $\\mathbf{Z}_{o}$ to obtain the final cluster assignment. I believe that only a seamless architecture can be strictly called end-to-end; otherwise, all models are end-to-end. Furthermore, repeated calls to k-means should significantly increase runtime. If $k$-means runs on the CPU, it also involves I/O between the CPU and GPU. If $k$-means runs on the GPU, it poses a challenge to GPU memory."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KDQiP7Yv6s", "forum": "bU8tRjuanU", "replyto": "bU8tRjuanU", "signatures": ["ICLR.cc/2026/Conference/Submission18061/Reviewer_rrG4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18061/Reviewer_rrG4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18061/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845267957, "cdate": 1761845267957, "tmdate": 1762927848389, "mdate": 1762927848389, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Low-Rank Attention and Contrastive Alignment (LRACA) framework to address three critical limitations in deep multi-view clustering: limited scalability on large-scale datasets, inconsistent anchor semantics, and an inability to model high-order feature interactions. LRACA aligns cross-view semantic prototypes through category-aware anchor generation, reduces computational complexity and improves feature discriminability via dynamic low-rank attention, and maximizes cross-view mutual information using pseudo-label-guided cluster-level contrastive learning. Experimental results demonstrate the effectiveness of the proposed framework."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The combination of efficiency and robust cross-view alignment addresses an important practical challenge in large-scale multi-view clustering.\n\n2. Using category-aware anchors as a semantic bottleneck and deriving a dynamic low-rank projection from them provides a principled way to maintain attention that is both computationally efficient and semantically meaningful.\n\n3. The paper is well organized and presents the method with clarity."}, "weaknesses": {"value": "1. The category-aware anchor generation relies on $K$-means clustering of fused latent features to produce initial pseudo-labels.\n\n2. The paper exhibits a critical weakness in its overall performance on benchmark datasets.\n\n3. The paper compares LRACA with nine baselines, but omits several recent state-of-the-art methods (e.g., from 2024 onward) for large-scale multi-view clustering.\n\n4. Generalization to non-image multi-view data is untested, as all six datasets used are image-centric."}, "questions": {"value": "1. The authors should provide an analysis of the mixed results on NUS-WIDE-OBJ, Fashion, YouTubeFace50, and CIFAR10, including an investigation of failure modes and dataset-specific factors.\n\n2. It would be valuable to evaluate LRACA on non-image multi-view datasets and analyze its performance in such settings.\n\n3. The paper should include additional comparisons between LRACA and recent state-of-the-art methods (e.g., published in 2024 or early 2025) for large-scale multi-view clustering.\n\n4. Table 2 shows that some methods have missing results on certain datasets without explanation. Table 3 fails to isolate the contribution of the cluster-level contrastive learning (LC) module. Moreover, no efficiency metrics for the compared methods are reported to empirically substantiate the claimed linear complexity.\n\n5. The dynamic low-rank attention in LRACA constructs a projection matrix $\\Theta$ through multi-view anchor fusion, achieving linear complexity $O(Nk)$ and enhancing cross-view alignment. However, since anchors from different modalities exhibit distinct distributions, directly merging them without distribution alignment may bias $\\Theta$ toward dominant views and compromise cross-view alignment consistency."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aPS3Rf3sKO", "forum": "bU8tRjuanU", "replyto": "bU8tRjuanU", "signatures": ["ICLR.cc/2026/Conference/Submission18061/Reviewer_uoVW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18061/Reviewer_uoVW"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18061/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993685268, "cdate": 1761993685268, "tmdate": 1762927847804, "mdate": 1762927847804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}