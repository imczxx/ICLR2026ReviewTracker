{"id": "9ckLDyDUI6", "number": 13521, "cdate": 1758218859564, "mdate": 1763655564521, "content": {"title": "SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection", "abstract": "The goal of coreset selection is to identify representative subsets of datasets for efficient model training. Yet, existing approaches paradoxically require expensive training-based signals, e.g., gradients, decision boundary estimates or forgetting counts, computed over the entire dataset prior to pruning, which undermines their very purpose by requiring training on samples they aim to avoid. We introduce SubZeroCore, a novel, training-free coreset selection method that integrates submodular coverage and density into a single, unified objective. To achieve this, we introduce a sampling strategy based on a closed-form solution to optimally balance these objectives, guided by a single hyperparameter that explicitly controls the desired coverage for local density measures. Despite no training, extensive evaluations show that SubZeroCore matches training-based baselines and significantly outperforms them at high pruning rates, while dramatically reducing computational overhead. SubZeroCore also demonstrates superior robustness to label noise, highlighting its practical effectiveness and scalability for real-world scenarios.", "tldr": "SubZeroCore is a fast, training-free coreset selection method that combines coverage and density into a single submodular objective, outperforming training-based baselines under high pruning while needing only one hyperparameter.", "keywords": ["Coreset Selection", "Zero-Shot", "Importance Sampling", "Deep Learning", "Dataset Pruning", "Submodularity"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e791fa328e06b73e4668b27df0ca04c49e8b5cb4.pdf", "supplementary_material": "/attachment/b468aa8e1632916fc21d08d986d8f340c83522da.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes SubZeroCore, a training-free coreset selection framework that formulates data summarization as a submodular optimization problem combining coverage and density. The method introduces a closed-form expectation-based coverage estimator to determine the K-nearest neighbor parameter and uses a greedy facility-location algorithm to construct the subset. Experiments on CIFAR-10 and ImageNet-1K show improved performance at very high pruning ratios compared to existing baselines such as CAL and GradMatch."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a你interesting problem of efficient coreset selection without model training, which is practically relevant in large-scale data settings.\n\n- Integrating coverage and density in a unified submodular framework is conceptually elegant and computationally efficient.\n\n- The method’s simplicity and \"zero-training\" property make it easy to implement and scalable to moderate-sized datasets."}, "weaknesses": {"value": "- The proposed weighted facility location function cannot distinguish dense noise clusters from genuine high-density regions. For example, if outliers form small local clusters, their $r_i$ values become small, giving them large $s_i$ scores, and thus they are preferentially selected due to the requirement of coverage. The experimental results in Figure 5 also show that their method cannot beat the SOTA algorithm like CAL.\n- In Section 3.3, the authors compute the neighborhood size $K$ by inverting a coverage target. This equation in line 285 implicitly assumes that samples are independently and uniformly drawn from the dataset, and that the underlying data distribution is homogeneous.\nHowever, for real-world data domain (i.e., embeddings of figures or text), these assumptions almost never hold.\n- The method’s reliance on pairwise similarity and static density weighting fundamentally limits transferability. For vision data, embedding similarity roughly preserves semantic structure, making submodular coverage meaningful. But for textual or cross-lingual data, embedding metrics are unreliable, and semantically equivalent samples in different languages can be distant. These limitations suggest that SubZeroCore cannot generalize beyond image tasks.\n- In modern large-model settings, coreset selection is primarily motivated by improving data efficiency while maintaining downstream performance. That means the true metric is not reconstruction similarity but the performance of a retrained model on held-out or shifted data. By optimizing only for embedding-space similarity, SubZeroCore completely ignores this goal."}, "questions": {"value": "How are the embeddings obtained? If I understand correctly, they should either use a pretrained embedding model or train one themselves."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LqLtA730nS", "forum": "9ckLDyDUI6", "replyto": "9ckLDyDUI6", "signatures": ["ICLR.cc/2026/Conference/Submission13521/Reviewer_4G5k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13521/Reviewer_4G5k"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893960695, "cdate": 1761893960695, "tmdate": 1762924127569, "mdate": 1762924127569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SubZeroCore, a training-free coreset selection method that avoids the computational overhead of traditional approaches requiring gradient or model-based signals. The method unifies submodular coverage and data density into a single objective, and derives a closed-form sampling strategy that balances these components via a single hyperparameter controlling the trade-off between global coverage and local density. Without any model training, SubZeroCore achieves performance comparable to or better than training-dependent baselines, particularly at high pruning rates, while being significantly more efficient. It also exhibits strong robustness to label noise."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a well-motivated and practically important problem in coreset selection. The proposed approach is clearly articulated, and the integration of coverage and density through geometric tools such as NNk distance and volume-based measures is intuitive and well justified. The exposition is clear, with strong motivation for why a training-free alternative is desirable. The experimental results show consistent and positive gains, and the authors provide good intuition and analysis to support their design choices."}, "weaknesses": {"value": "- The experimental analysis is limited to a few small-scale image datasets. It remains unclear whether the proposed findings generalize to other modalities such as text or to large-scale models, where gradient-based signals may play a more significant role. A broader evaluation or discussion on cross-modal applicability would strengthen the paper’s empirical claims.\n\n- The paper does not discuss several recent training-free subset selection approaches such as CCS, D2Pruning, and InfoMax. These methods share similar motivations—efficient data or feature subset selection without model retraining—but differ in formulation and theoretical grounding. It would strengthen the work if the authors clarified how their method relates to or improves upon these approaches. In particular, a discussion highlighting the applicability gaps, scalability trade-offs, or assumptions distinguishing their approach would be helpful.\n\n   - CCS: Coverage-centric Coreset Selection for High Pruning Rates. ICLR-2023\n   - D2Pruning: D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning. ICLR-2024.\n   - InfoMax: Data Pruning by Information Maximization. ICLR-2025.\n\n- The paper would benefit from direct comparisons with other monotone submodular objectives such as GraphCut, Disparity-Min, and FLMI (Facility Location Mutual Information) to better contextualize the proposed coverage–density formulation.\n\n- The overall contribution feels somewhat limited, as the method primarily relies on predefined measures like K-nearest neighbor distance and volume from Morgan (2016). The theoretical analysis is also rather minimal, offering no substantial new insights or results."}, "questions": {"value": "- In Fig. 4, the bar chart comparing selection time is unclear regarding what contributes to the higher cost for GradNd and GradNorm. Is the majority of this time due to gradient computation? It would be helpful to separate the gradient computation time from the subset selection time to make the comparison more informative.\n\n- Model-based signals often provide richer information than embedding-space measures alone. It would be interesting to see whether the reported gains persist for larger models or fine-tuning scenarios, such as with SLMs, rather than being limited to smaller architectures like ResNets. Additionally, do the improvements translate to other modalities, for instance in text or large-scale training settings?\n\n- For noisy outliers, the normalized scores across the radii distribution appear to favor dense clusters while penalizing dense outliers. Empirically, it would be helpful to know how this trade-off behaves with higher levels of label noise (e.g., >10%) and whether the authors observed a Pareto-style curve illustrating the balance between coverage and robustness.\n\n- The use of the K-NN metric may be sensitive to noisy data and outliers, which could affect the reliability of the evaluation, although authors argue the robustness to 10% label noise. A systematic ablation or analysis showing how the proposed normalized scores mitigate this sensitivity would help clarify the robustness of the method and strengthen the empirical claims.\n\n- Since the method essentially reduces to a weighted Facility Location problem, it can be seen as a K-medoids variant. How does it compare to other clustering algorithms, both theoretically and empirically, such as BanditPAM and BanditPAM++?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Auizi1miyJ", "forum": "9ckLDyDUI6", "replyto": "9ckLDyDUI6", "signatures": ["ICLR.cc/2026/Conference/Submission13521/Reviewer_2CD1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13521/Reviewer_2CD1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978965725, "cdate": 1761978965725, "tmdate": 1762924127216, "mdate": 1762924127216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SubZeroCore presents a training-free coreset selection method that optimally balances submodular coverage and density via a closed-form solution controlled by a single hyperparameter. Training-free coreset selection is desirable; many recent methods are reliant on training-based signals (e.g., gradients, forgetting scores). Empirical results show SubZeroCore matches or exceeds the performance of training-based and geometry-driven baselines on CIFAR-10 and ImageNet-1K, particularly at high pruning rates and in some settings with label noise."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The method described is interesting and unifies competing goals into a single formulation. The ability to control the tradeoff between coverage and density by one hyperparameter is also compelling.\n\n- The method derivation based on density-weighted to systematically downweighting potential noisy examples seems to lead to increased robustness to noise. \n  \n- The speed of the method is attractive.\n\n- The results demonstrating strong performance at high prune rates are strong."}, "weaknesses": {"value": "- Coreset selection is challenging whether or not one uses training signals. Interestingly, reports (e.g., Griffin et al. https://arxiv.org/pdf/2411.15349) have shown that uniform sampling is a very competitive baseline.  This paper has no such analysis against the competitive baseline.  EG. Looking at the prune rate of 70% for CIFAR10 in that paper and this paper (both using ResNet18 as the downstream detector), the uniform sampler performs within variance to this paper 90.61 +- .44 (AND the uniform sampler uses no class labels and no training).\n\n- The paper defines the problem to be fully supervised setup with labels for all samples (tacitly described in Sec 2).  This differs from the original coreset definition Sener and Savarese 2017 active learning framework, where only some labels are available and the goal is to select the next subset to label. However, the actual method does not seem to use the class labels (although this is not clear because the notation shifts to only using a $\\mathbf{X}$ to subsume the class labels.  So it is not clear whether or not the later derivations are performed per class or agnostic to class.  (While this shift is more common in recent coreset literature, it is problematic because it abandons the core motivation of Sener and Savarese: reducing labeling costs for large datasets.)\n\n- Competitive methods are missing from the results.  e.g., Temporal Dual-Depth Scoring Zhang et al. CVPR 2024.  This example may use training, but it is still quite relevant. e.g.2: ELFS by Zheng et al. ICLR 2025 which does not use ANY labels.  No comparative result in the tables exist for papers after 2021?  This is concerning.  Furthermore, increasing the number of datasets used in the analysis would help the reader understand the method's behavior; datasets that have different comparative properties than just size like the two used here, such as gross class imbalance.\n\n- Although the method is interesting, it seems like it may struggle for imbalanced scenarios.  Similarly, the paper suggests superior robustness to label noise, but this is only minimally analyzed in Fig. 5.  One expects more thorough analysis for a core property."}, "questions": {"value": "- Clarify if and how the class labels are actually used in the method.  If they are not used the paper should more clearly state that.  EG one can have class labels but not use training.\n- Why are no competitive results included from the recent literature? This is a significant weakness of the paper.\n- How does the method perform under higher noise rates?  \n- HOw does the method perform under class imbalance?"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "Probably this is not a true ethics concern.  But, it is very clear to me that 13521 and 2361 were contributed by the same authors.  The problem statements are the same, chunks of text are common, and the results have the same limitations.  The methods seem to be sufficiently different (although in the end all they are really doing is fitting local densities to data-samples and the sampling from those densities)."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VsaoWpi6j0", "forum": "9ckLDyDUI6", "replyto": "9ckLDyDUI6", "signatures": ["ICLR.cc/2026/Conference/Submission13521/Reviewer_CYjx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13521/Reviewer_CYjx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762183429366, "cdate": 1762183429366, "tmdate": 1762924126729, "mdate": 1762924126729, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}