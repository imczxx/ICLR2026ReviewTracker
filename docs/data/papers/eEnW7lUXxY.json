{"id": "eEnW7lUXxY", "number": 9239, "cdate": 1758116035185, "mdate": 1763564541088, "content": {"title": "CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding", "abstract": "Multimodal large language models (MLLMs) have recently achieved remarkable progress in radiology by integrating visual perception with natural language understanding. However, they often generate clinically unsupported descriptions, known as medical hallucinations, which pose serious risks in medical applications that demand accuracy and image-grounded outputs. Through empirical analysis, we find that prompt-induced hallucinations remain prevalent in radiology MLLMs, largely due to over-sensitivity to clinical sections. To address this, we introduce **C**linical **C**ontrastive **D**ecoding (**CCD**), a *training-free* and *retrieval-free* inference framework that integrates structured clinical signals from task‑specific radiology expert models. CCD introduces a dual-stage contrastive mechanism to refine token-level logits during generation, thereby enhancing clinical fidelity without modifying the base MLLM. Experiments on three datasets and multiple models demonstrate that CCD consistently improves overall performance on radiology report generation (RRG). On the MIMIC-CXR dataset, it yields up to a **2.78** absolute improvement in RadGraph-F1 when applied to state-of-the-art RRG models. Our approach provides a lightweight solution for mitigating medical hallucinations, effectively bridging expert models and MLLMs in radiology.", "tldr": "We propose Clinical Contrastive Decoding, a training-free and retrieval-free inference strategy that mitigates medical hallucinations in radiology MLLMs by integrating task-specific expert model guidance through a dual-stage contrastive mechanism.", "keywords": ["Radiology AI", "Chest X-ray", "Multimodal Large Language Models", "Hallucination Mitigation", "Decoding Strategy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f9247d6e4c2804ae69a57bf4b5ef7cf0c2b8e90d.pdf", "supplementary_material": "/attachment/297956d125cffa5d8bdba98626ff301dbcd6ef48.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a contrastive decoding approach tailored to radiology report generation (RRG) called. clinical contrastive decoding (CCD). The CCD framework adjusts the token logits of a pretrained multimodal large language model (MLLM) using the outputs of a pretrained image classifier, enabling a training-free method to enhance the generations of the MLLM. The authors additionally conduct an analysis on a potential source of hallucination in the generations of the MLLM within the context of RRG."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "●\t Interesting idea to understand the potential to utilize a pretrained classifier to enhance model generation without retraining the LLM. Interesting approach to modify the token logits backed by context provided evidence of a domain “expert” image model.\n\n●\t Valuable analysis to try to quantify the impact of potentially misleading information in the model prompt. Empirical results do demonstrate differences, though perhaps still an open question as to why those differences exist.\n\n●\t The manuscript is well prepared with generally clear writing, equations, figures, and tables."}, "weaknesses": {"value": "●\tThe authors’ claim on the impracticality of retrieval doesn’t seem well founded, it’s  poorly cited and in reality, computing similarities over precomputed embeddings of images or text should be relatively cheap compared to the LLM inference that the system needs to do anyways.\n\n●\tWhile section 3 and table 1 provide interesting empirical evidence that the generations are sensitive to the prompts, the conclusions stated by the authors are more conjecture than evidence-based claims. For example, lines 216-217 claim clinical terminology and standardized phrasing is more prevalent in the history or technique sections, yet it is easy to observe similar standardized clinical phrasing in the other note sections exemplified in figure 1a. Additionally, in the paragraph on lines 222-231, the authors claim certain findings are more prevalent in different note sections. The authors fail to discuss the general increase in performance for cardiomegaly, consolidation, and edema when including all note sections in the prompt. Further the claims that are made by the authors, in terms of why atelectasis and pleural effusion do worse, should be quantified rather than relying on citing a review article from 1996 that only reviews atelectasis. It would seem that there is a lack of clinical background and context for the authors to make broad claims about clinical practice.\n\n●\tIt is confusing how the CCD framework is using the expert model predicted probabilities in the ECD arm of the method. Equation 5 shows the clipped bias for a single $\\tilde{l}_i$ being “uniformly added to the token logits”; how is the symptom label “selected” (line 337)? Does the label change depending on the step t? Figure 2 seems to present the use of all labels for every step t, so it seems further clarification on this fundamental component of the method is warranted.\n\n●\tRelatedly, given the use of the 14 CheXpert labels as the grounding source of information, why should CCD mitigate hallucinations such as the example “AP and lateral” vs “single frontal” provided in Figure 1a or help the model determine the type of atelectasis in Figure 1b? It is additionally unclear based on the presented results and methodology whether the authors actually evaluated whether CCD could mitigate these hallucinations in the context of the varying prompt information. See related question below on table 2 vs table 1 results.\n\n●\tThe presentation of relative change in performance overstates results and should be tempered. The absolute change in F1RadGraph is ~2.8%. Additionally, while this work aims to demonstrate the relative gain of CCD over its baseline model, it would still be beneficial to understand the magnitude of the gain relative to the more complex approaches the authors aim to beat. Some of these results are presented in Appendix Table 6, however these results demonstrate much weaker results for generalizability of CCD."}, "questions": {"value": "●\tIn your experiments in section 3 on prompt-induced hallucination, was the type of clinical context provided in the prompt? I.e. was the note section header given as part of the clinical context? This would help the model better understand the information it was given, otherwise the results of section 3 may be confounded by the lack of contextualization.\n\n●\tFigure 2 seems to show the CheXpert labels are single tokens, is that the case? I would suspect not, given then the need to retrain the tokenizer and model, perhaps this should be clarified.\n\n●\tLines 344-345 mention the use of different decoding components in the logits processor, yet line 378/9 state the use of greedy decoding. This should be clarified as the decoding strategies used in the logits processor are not the same as the final decoding approach, yet it still has an impact on the output logits.\n\n●\tIt is unclear if the radiology report generation results presented in Table 2 includes any of the context prompts that were assayed in Table 1. It would be a stronger result to understand how CCD has mitigated those hallucinations in the presence of potentially counterfactual information."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l7l44yy7HR", "forum": "eEnW7lUXxY", "replyto": "eEnW7lUXxY", "signatures": ["ICLR.cc/2026/Conference/Submission9239/Reviewer_aSHU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9239/Reviewer_aSHU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761765465908, "cdate": 1761765465908, "tmdate": 1762920892431, "mdate": 1762920892431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Clinical Contrastive Decoding (CCD), a training-free, retrieval-free inference method to reduce medical hallucinations in radiology MLLMs. CCD plugs in a task-specific expert classifier (e.g., CheXpert-style DenseNet) and uses its predicted labels and probabilities to (1) inject a “clinical anchor” into the prompt (SCD) and (2) bias token logits with calibrated logit offsets (ECD). Evaluated on MIMIC-CXR, IU-Xray, and CheXpert Plus across RRG and CXR-VQA, CCD improves several clinical metrics (e.g., up to +17% RadGraph-F1 on MIMIC-CXR) without retraining the base MLLM."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-motivated. Instead of just proposing a new method, the authors first dedicate Section 3 to diagnosing a specific, tangible problem: MLLMs \"overreact to clinical context\" , and the clinical sections in reports \"are not always reliable sources of guidance\". This empirical analysis provides a strong justification for their solution.\n2. The proposed CCD framework is both training-free and retrieval-free. This is a significant advantage in the medical domain, as it avoids the cost, privacy concerns, and complexity associated with retraining models or maintaining large retrieval databases."}, "weaknesses": {"value": "1. The empirical motivation in Table 1, while interesting, is not as compelling as it could be. The authors demonstrate that adding noisy or counterfactual context (like \"comparison\" or \"technique\" sections) degrades performance. This is somewhat expected, as the model is not given the prior images needed for comparison, confusing its generation task.\nA stronger motivation for CCD would be to complete this analysis by showing the opposite:\nFirst, demonstrate that feeding the model clean, structured labels (like those from an expert classifier) as prompt context actually improves performance over the baseline in Table 1.\nThen, contrast this with the performance degradation when using the noisy, original report sections.\n\nThis would more forcefully prove the central hypothesis: MLLMs are harmed by bad context but benefit from good context, thereby providing a stronger justification for the CCD framework.\n\n2. The framework's performance is fundamentally coupled to the quality and design of the expert model, which introduces several limitations:\na. The framework's effectiveness is capped by the expert model's accuracy. As the authors' own ablations suggest, a stronger expert yields better results. Conversely, a weak or systematically biased expert model could, in principle, steer the MLLM to replicate its own errors, potentially propagating biases.\n\nb.  The use of a simple > 0.5 probability threshold to select expert labels for the anchor prompt is suboptimal, especially for highly imbalanced medical datasets where clinically important findings are often rare. More sophisticated, data-driven thresholding techniques (e.g., maximizing F1-score) would be better suited to calibrate the expert guidance.\n[1] The limits of fair medical imaging AI in real-world generalization. Nature Medicine.\n[2] Algorithmic encoding of protected characteristics in chest X-ray disease detection models. Lancet\n\nc. The CheXpert ontology’s 14 pathologies provide limited morphological and positional detail (e.g., scarring, lesion location), which explains the observed performance dips in VQA categories like Location and Type.\nThis reflects an inherent ceiling for CCD’s guidance. The authors could extend their framework by incorporating expert findings for anatomical regions and observation types (using RADGRAPH), inspired by:\n[1] Anatomy-Guided Weakly-Supervised Abnormality Localization in Chest X-rays. MICCAI 2022\n[2] Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat. ICML 2023\n[3] Distilling blackbox to interpretable models for efficient transfer learning. MICCAI 2023\n\n3. The evaluation could be expanded to include LLM-as-a-Judge metrics, particularly the recently proposed GREEN framework (EMNLP 2024, “Generative Radiology Report Evaluation and Error Notation”). Such metrics capture clinically nuanced correctness and could provide complementary insights beyond traditional lexical or structured metrics.\n\n4. The paper positions itself as a solution to prompt-induced hallucinations, as identified in Table 1 where \"comparison\" sections cause errors. However, it is unclear how the proposed CCD framework—which guides the MLLM based on findings in the current image—would explicitly prevent the model from spontaneously hallucinating references to past exams. This common and problematic type of hallucination seems unaddressed by the current mechanism.\n\n\n5. The paper currently lacks consistent figure references and variable definitions.\nFigure 2 is cited as having panels (a) and (b), but no such markings are visible.\nThe variable c in line 298 is undefined; it appears to refer to the structured labels from the expert model, which should be explicitly stated.\nImproving figure annotations and notational clarity will make the methodology easier to follow."}, "questions": {"value": "1. Since the framework’s success depends heavily on the expert classifier, how sensitive is CCD to expert calibration and label-imbalance effects?\n\n2. Given that the 14 CheXpert labels lack morphological or positional coverage, do the authors plan to incorporate anatomical and observation-level findings (e.g., from RADGRAPH or anatomy-guided classifiers) as additional expert concepts?\nHow might CCD generalize to these richer ontologies, which could address the VQA “Location/Type” performance dips?\n\n3. Have the authors considered evaluating with LLM-as-a-Judge metrics such as GREEN (EMNLP 2024)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UXHKYLfswe", "forum": "eEnW7lUXxY", "replyto": "eEnW7lUXxY", "signatures": ["ICLR.cc/2026/Conference/Submission9239/Reviewer_H2Rc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9239/Reviewer_H2Rc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970311730, "cdate": 1761970311730, "tmdate": 1762920892053, "mdate": 1762920892053, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Clinical Contrastive Decoding (CCD), a training-free, retrieval-free inference-time framework designed to mitigate medical hallucinations in radiology MLLMs. CCD integrates structured signals from task-specific expert models through a dual-stage contrastive mechanism, refining generation towards clinical fidelity without altering model parameters."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The dual-stage framework is clearly presented, relying on structured, interpretable expert signals, and mathematically grounded.\n\n2. CCD is a plug-and-play inference-time approach, applicable across architectures and tasks without retraining or specialized data."}, "weaknesses": {"value": "1. The methodology design mainly builds on prior work, with no clear methodological innovation beyond adapting it to the cxr-related domain. Also, the discussion on hallucination overlaps heavily with the well-studied topic of prompt injection attacks, which are not a new finding. This is not sufficient for ICLR acceptance.\n\n2. for the motivation part ( section 3), about the medical hallucination experiments, i find the experimental design unconvincing. llava-med is trained on data from public text sources (pubmed), not on clinical cxr datasets such as mimic-cxr or chexpert, so describing it as a \"radiology mllm\" seems overstated. Moreover, the experiments focus on cxr report generation, which is confusing given that there are established rrg models like maira-2 (which the authors also use in the main experiments). it’s unclear why those models weren’t used to analyze the hallucination issue instead. the logic behind this setup is weak.\n\n3. The evaluation scope is too limited, especially in model selection. for cxr vqa, there are domain-specific models like chexagent, yet they are not included. since the title focuses on radiology mllms, the experiments should evaluate at least two to three radiology-specific models for both vqa and report generation to make the claims convincing.\n\n4. The report generation results also seem questionable. I've used maira-2 myself and see the paper's results, and the reported metrics, especially radgraph and chexbert scores, are much lower than what i observed. It’s unclear whether any specific preprocessing was applied to the evaluation data. In addition, If the evaluation uses only single frontal-view cxrs, the authors should clarify whether information from the reports that depends on lateral views or longitudinal records has been filtered out."}, "questions": {"value": "I suggest not using relative improvement percentages, since they make it hard to see the actual, absolute gains. For a more solid comparison, the authors should include significance testing to clearly demonstrate the advantages of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "N5VaMHjOLF", "forum": "eEnW7lUXxY", "replyto": "eEnW7lUXxY", "signatures": ["ICLR.cc/2026/Conference/Submission9239/Reviewer_zXA8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9239/Reviewer_zXA8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762063470464, "cdate": 1762063470464, "tmdate": 1762920891699, "mdate": 1762920891699, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Clinical Contrastive Decoding (CCD), a training-free, retrieval-free, inference-time method to curb medical hallucinations in radiology multimodal LLMs. CCD plugs in a task-specific expert model (e.g., a CheXpert-style chest-x-ray classifier) and applies a two-stage, token-logit adjustment during decoding:\n\n* Symptom-grounded Contrastive Decoding (SCD): adds expert-predicted labels as a concise “clinical anchor” prompt and blends anchor-conditioned logits with the base logits to reduce false negatives.\n\n* Expert-informed Contrastive Decoding (ECD): converts expert probabilities into clipped logit biases (bounded by a likelihood-ratio cap) to suppress false positives."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* CCD requires no retraining and only an external expert classifier, making it easy to add to existing radiology MLLMs while directly optimizing clinical fidelity at decode time.\n\n* Improvements hold across datasets, metrics (RadGraph-F1, RaTE, Temporal-F1, CheXbert), and tasks (RRG, VQA), with clear ablations (remove SCD/ECD, vary α/β, swap experts) supporting the mechanism."}, "weaknesses": {"value": "* Guidance is limited by the 14 CheXpert labels; categories like Location/Type in VQA degrade slightly, suggesting missed morphology/topography signals and potential brittleness outside the expert’s ontology.  \n\n* Core knobs (α, β, γ) are fixed across tasks/models; there’s no adaptive controller tied to uncertainty or prompt/model state, leaving performance-vs-fluency trade-offs hand-tuned. \n\n* While multi-metric, the paper reports limited variance/seed statistics, human evaluation, or calibration/uncertainty analysis; compute/latency overhead of running the expert online is only qualitatively discussed. \n\n* Experiments focus on CXR single-view RRG/VQA; generalization to CT/MRI/US, multi-series exams, or longitudinal/report-level reasoning is unproven."}, "questions": {"value": "* How would CCD scale beyond CheXpert-14—e.g., to morphology (size/shape), location, devices, lines/tubes, or temporal comparisons—without re-training the expert?\n\n* How sensitive is CCD to expert miscalibration or domain shift (different scanners/hospitals, pediatric vs. adult)? Any safeguards (e.g., temperature scaling, conformal thresholds) to avoid propagating expert errors?\n\n* What is the end-to-end overhead (ms/image, GPU memory) of running the expert and logit processors at decode time, and how does it compare to training-time mitigation (e.g., COMT/RAG-style methods)?\n\n* Beyond automated metrics, have you performed radiologist blind reads or error-taxonomy audits to verify reductions in harmful hallucinations (e.g., false effusion/pneumothorax claims)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5EsGqRYweD", "forum": "eEnW7lUXxY", "replyto": "eEnW7lUXxY", "signatures": ["ICLR.cc/2026/Conference/Submission9239/Reviewer_pv1x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9239/Reviewer_pv1x"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762084190145, "cdate": 1762084190145, "tmdate": 1762920891356, "mdate": 1762920891356, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Rebuttal Response & Thank You!"}, "comment": {"value": "Thank you to all reviewers and the AC for your service in making ICLR possible. We sincerely appreciate the thoughtful and constructive feedback, which has helped strengthen the clarity and quality of our work. \n\nIn response, we have carefully revised the manuscript and clarified our contributions. The main updates are summarised below and highlighted in red in the revised version.\n\n***\n\n# Changes to the manuscript:\n\n1. Improved the readability of Figure 2 by increasing font size and bolding key elements in the caption. **[H2Rc]**\n    \n2. Revised the description of the LogitsProcessor() module in Section 4.2 (Line 344) to clarify its role within our framework. **[aSHU]**\n\n3. Updated Table 2 (Section 5.2) to report relative rather than absolute score improvements. **[zXA8, aSHU]**\n\n4. Added clarifications regarding the prompt settings used for MAIRA-2, including modifications to the chat template, in Appendix C.1 to ensure reproducibility. **[zXA8]**\n\n5. Incorporated LLM-as-a-judge evaluation (GREEN score) in Appendix D.1. **[H2Rc]**\n\n6. Added evaluation results for the CheXAgent-8B model on the VQA task in Appendix D.3 (Table 7), together with a detailed discussion. **[zXA8]**\n\n7. Included a clarification on online latency in Appendix G (Line 1512). **[pv1x]** \n\n8. Added a discussion of adaptive hyperparameter selection in Appendix G (Line 1515). **[pv1x, aSHU]**\n\n9. Expanded the discussion of other imaging modalities (e.g., CT, MRI) in Appendix G (Line 1552). **[pv1x]**\n\n10. In the Abstract, we reported absolute (not relative) improvements and removed the generalisation claim. **[zXA8, aSHU]**\n\nWe have also included a Special Acknowledgements section in **Appendix I** to convey our sincere appreciation for the valuable feedback from all reviewers. As a substantial portion of reviewer comments at ICLR 2026 were AI-generated, we are especially grateful for the time and thoughtful insights provided by the human reviewers. Such genuine and constructive feedback is of great importance to us. Regardless of the final decision, we hope that future readers will find the OpenReview discussions helpful and gain a deeper understanding of our work.\n\n\n***\n\n\n# Thank you!\n\nIf you still need any clarification or have any other concerns, please feel free to contact us, and we are happy to continue communicating with you.\n\nBest regards,\n\nAuthors"}}, "id": "vOrYcIdZ7W", "forum": "eEnW7lUXxY", "replyto": "eEnW7lUXxY", "signatures": ["ICLR.cc/2026/Conference/Submission9239/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9239/Authors"], "number": 14, "invitations": ["ICLR.cc/2026/Conference/Submission9239/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763564168107, "cdate": 1763564168107, "tmdate": 1763564168107, "mdate": 1763564168107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}