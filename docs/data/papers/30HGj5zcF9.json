{"id": "30HGj5zcF9", "number": 4973, "cdate": 1757823115657, "mdate": 1759898002080, "content": {"title": "GenDrugCLIP: A Generation-Augmented Framework for ContrastiveDrug-Target Representation Learning", "abstract": "Virtual screening (VS) has become an indispensable component of early drug discovery, aiming to identify potential ligands for a given protein target. While CLIP-style methods (e.g., DrugCLIP) have emerged as a powerful solution by enabling efficient compound retrieval through drug-target representation alignment, current models face two fundamental challenges: (1) the scarcity of true binding data for training limits coverage of diverse binding modes, and (2) the use of trivial negatives—molecules binding to other pockets—leads to a significant train-test domain gap. To address these challenges, we introduce GenDrugCLIP, a novel generation-augmented framework that repositions structure-based drug design (SBDD) models as controllable data engines. GenDrugCLIP implements a Generate-Filter-Score-Select pipeline to construct target-aware pseudo positives and hard negatives for triplet contrastive learning. Our approach not only expands the chemical space but also prevents the model from relying solely on trivial negatives. Extensive experiments on three benchmarks demonstrate that GenDrugCLIP achieves state-of-the-art performance, outperforming DrugCLIP by +7.66% in BEDROC and +7.45 in early enrichment on the DUD-E benchmark. Our work highlights the untapped potential of SBDD models as powerful data engines for representation learning, opening a new paradigm for data-efficient drug discovery.", "tldr": "GenDrugCLIP leverages SBDD to generate pseudo positives and hard negatives, significantly improving virtual screening performance by addressing the scarce binding data and trivial negatives in drug-traget CLIP methods.", "keywords": ["AI for Science", "Drug Virtual Screen", "Hard Negative Mining", "Data Augmentation", "Contrastive Learning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/35bde5e0d9becde5f1f5a145a82e4aae66244051.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces GenDrugCLIP, an extension of DrugCLIP, which incorporates a structure-based drug design (SBDD) model, MolCRAFT, to generate molecule samples conditioned on the target. These generated samples are then filtered and used as pseudo positives and negatives for data augmentation, aiming to enhance the training of DrugCLIP. While the method is conceptually reasonable, it achieves only marginal improvements on virtual screening benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of using a generative model to create pseudo hard negative samples for virtual screening is both interesting and conceptually sound. \n2. The filtering strategy is thoughtfully designed and appears to be well-justified.\n3. The proposed method leads to some kind of improvements over baselines.\n4. The improvement over the “with trivial negatives” setting in the ablation study is encouraging, suggesting that generating negatives via a generative model is more effective than using random samples, although more details should be included."}, "weaknesses": {"value": "1. The major concern of this paper is the relatively limited overall performance improvement. Both the enrichment factor and BEDROC show less than 10% gain, which may not be sufficient to convincingly demonstrate the effectiveness of the proposed method.\n2. The overall techniqual depth and contribution of this paper is limited. It is based on an existing model for virtual screening, and use an existing  SBDD model for data augmentation. \n3. The paper currently explores only one SBDD model: MolCRAFT. It is better to try more generative models and compare the performance.\n4. The ablation study should be more detailed and thorough. For example, It is unclear whether the “trivial negatives” were also passed through the same filtering process, which may be a key factor behind the method’s success. If the random negatives were not filtered similarly, the comparison could be misleading. Clarifying this would strengthen the credibility of the analysis.\n5. While the inclusion of visualizations is appreciated, Figure 3b provides limited insight. It only shows one case where GenDrugCLIP outperforms the original DrugCLIP on a specific target, without offering any analysis of the underlying causes. Although cherry-picking cases can illustrate potential improvements, a deeper explanation of why the improvement occurs is needed to enhance the informativeness of the result."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1UpmZvuanu", "forum": "30HGj5zcF9", "replyto": "30HGj5zcF9", "signatures": ["ICLR.cc/2026/Conference/Submission4973/Reviewer_8bmZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4973/Reviewer_8bmZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4973/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761567911490, "cdate": 1761567911490, "tmdate": 1762917801758, "mdate": 1762917801758, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a generation augmented contrastive learning framework tGenDrugCLIP, to address two key limitations of CLIP-style virtual screening: (1) sparse true binding data and (2) reliance on trivial negatives. By repurposing SBDD models as controllable data engines, it introduces a Generate-Filter-Score-Select pipeline to create target-aware pseudo positives and hard negatives for triplet contrastive learning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This study successfully applies Structure-Based Drug Design (SBDD) to new practical scenarios(Virtual Screening), yielding positive effects.\n\n2. The paper is well structured and easy to follow.\n\n3. The paper evaluates on three benchmarks: DUD-E, DEKOIS 2.0, and LIT-PCBA. On DUD-E, GenDrugCLIPVina achieves 45.42 % BEDROC (+7.66 % over DrugCLIP) and EF0.5 % of 35.63 (+7.45 over DrugCLIP). It also sets new state-of-the-art on DEKOIS 2.0 (BEDROC 49.12 % ) and improves over DrugCLIP on the challenging LIT-PCBA dataset (BEDROC 5.51 % vs. 3.78 %)."}, "weaknesses": {"value": "Concerns:  \n\n1. AutoDock Vina’s known biases (e.g., molecular-weight preference) may propagate into the pseudo-labels and cap generalization.  \n\n2. The paper employs two scoring schemes DrugCLIP similarity and Vina affinity, but provides insufficient analysis of why, in different settings, DC performs better (DEKOIS 2.0) while Vina prevails (LIT-PCBA).\n\n3. The optimal mixing ratio of generated data must be carefully tuned—more is not always better, limiting the overall gain.  \n\n4. SBDD model choice is limited to MolCRAFT; no ablation on alternatives (DiffSBDD, Pocket2Mol, etc.) or sensitivity analysis is provided. \n \n5. Core contribution is standard data-augmentation via generation, with incremental novelty."}, "questions": {"value": "Refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JXBNWYjXyI", "forum": "30HGj5zcF9", "replyto": "30HGj5zcF9", "signatures": ["ICLR.cc/2026/Conference/Submission4973/Reviewer_we3Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4973/Reviewer_we3Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4973/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653016414, "cdate": 1761653016414, "tmdate": 1762917801326, "mdate": 1762917801326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a data augmentation method for protein pocket-small molecule contrastive learning called GenDrugCLIP, using the generative ability of SBDD models like MolCRAFT. The method addresses challenges such as the scarcity of true binding data and the use of trivial negative samples by generating target-aware pseudo positives and hard negatives. Experimental results show that GenDrugCLIP outperforms DrugCLIP on multiple benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of using generated model to generated synthetic data for VS task is a great idea, as the real data is hard to get because of the expense of wet lab exps.\n2. This paper mentioned a important problem is that the negative sample need to be hard to push the model learn the really important pricinples."}, "weaknesses": {"value": "The main contribution of this paper is focused on the Data Augmentation method, which may not be a very broad topic, and whether it is sufficient for publication at ICLR might be worth discussing. However, I think it’s still quite ok, as data augmentation methods are currently much needed in this field.\n\nFor others, see the questions."}, "questions": {"value": "1.\tIn your motivation, you mentioned that a key challenge is the limited number of true active ligands for each target. Why is this considered a critical issue when modeling pocket-ligand interactions?\n2.Have you experimented with combining both the DC score and Vina score filters? If applied simultaneously, do you think this would improve the results?\n\n3.\tThe baseline results on DUD-E seem to differ from those reported in previous papers, such as DrugCLIP. Is this due to dataset deduplication based on UniProt IDs or another factor?\n4.\tMolCRAFT is trained using CrossDocked, which is not deduplicated from the test sets. Could using MolCRAFT to generate training data result in data leakage?\n5.\tIt’s not clear how much useful information is provided by MolCRAFT versus the multiple filters. I recommend adding an ablation study where random molecules are first sampled (with or without matching ligand atom numbers to the reference ligand), then subjected to Vina docking to get their poses. Afterward, apply the same property and DC or Vina score filters to select the synthetic data. Would this approach potentially enhance DrugCLIP’s performance?\n6.\tThe distribution of the generated molecules differs from that of real molecules. Could this pose a problem for your approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sNAMuBy9SW", "forum": "30HGj5zcF9", "replyto": "30HGj5zcF9", "signatures": ["ICLR.cc/2026/Conference/Submission4973/Reviewer_XyZo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4973/Reviewer_XyZo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4973/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761827770074, "cdate": 1761827770074, "tmdate": 1762917800908, "mdate": 1762917800908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GenDrugCLIP, a generation-augmented framework for contrastive drug–target representation learning. The key idea is to repurpose structure-based drug design models as controllable data engines that can generate target-aware molecules. GenDrugCLIP employs a Generate–Filter–Score–Select pipeline to produce pseudo positives (high-scoring molecules) and hard negatives (low-scoring molecules) for triplet-based contrastive learning. Experiments on three benchmarks show that GenDrugCLIP outperforms existing methods such as DrugCLIP."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Creative reuse of SBDD models as generative data engines, bridging generative modeling and contrastive learning.  \n- Demonstrated strong empirical gains over DrugCLIP across multiple benchmarks.  \n- Conceptually broadens the role of generative models in drug discovery from candidate generation to data augmentation for representation learning."}, "weaknesses": {"value": "- Compared to DrugCLIP, the methodological novelty is limited. The main contribution appears to be the generation of an augmented dataset rather than a fundamentally new learning framework.  \n- Only one SBDD method is used for data augmentation, and it is unclear why this specific method was chosen or how robust the approach would be if alternative SBDD generators were applied.  \n- ground truth positive compounds might not even pass a strict filter like the one the authors implemented here, potentially introducing a data distribution shift between the augmented and original datasets.  \n- The paper does not discuss how sensitive or robust the model is to imperfect or less curated filtering procedures, which could affect generalization in practical scenarios."}, "questions": {"value": "- GenDrugCLIP consistently outperforms both DrugCLIP and EquiScore across most metrics, but the differences in AUROC are relatively small. Does this indicate that GenDrugCLIP primarily improves early enrichment rather than overall ranking performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bu6f9daHTA", "forum": "30HGj5zcF9", "replyto": "30HGj5zcF9", "signatures": ["ICLR.cc/2026/Conference/Submission4973/Reviewer_oY5n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4973/Reviewer_oY5n"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4973/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762238028270, "cdate": 1762238028270, "tmdate": 1762917800389, "mdate": 1762917800389, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}