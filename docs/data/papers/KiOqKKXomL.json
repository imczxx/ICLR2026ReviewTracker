{"id": "KiOqKKXomL", "number": 21652, "cdate": 1758320129358, "mdate": 1759896910527, "content": {"title": "ASIDE: Adaptive and Separable Interventional Dynamics  via Progressive Meta-Learning", "abstract": "To inform decisions about changing the future trajectories of a dynamics system, it is important to predict not only the intrinsic dynamics of the system but also its response to external interventions. While notable progress has been made in learning intervention effects over time, existing research has prioritized the challenge of time-varying confounding in observational data. Significant challenges however remain in aspects related to the modeling and inference of latent dynamics.  A first and foremost challenge lies in the need to separate, from a composite observation, the natural temporal evolution of intrinsic dynamics from its response to external interventions. This challenge is further exacerbated by the need to integrate rich history information into these latent dynamics. In this paper, we present a novel framework of adaptive and separable interventional dynamics (ASIDE) to overcome these challenges. First, we leverage inductive bias and progressive learning to allow separable modeling and inference of the intrinsic dynamics and its responses to external interventions at the latent space. This is in contrast to existing approaches that model and infer the composite dynamics as a black box. Second, we leverage meta-learning to enable these latent dynamics to adapt to context examples in past history, addressing both inter- and intra-subject variabilities. This is in contrast to existing approaches that use history only to initialize a $\\textit{one-size-fit-all}$ forecasting function. On synthetic and real benchmarks, we demonstrate the advantage of ASIDE in improving forecasting accuracy for both intrinsic and interventional dynamics, in settings with or without time-varying confounding.", "tldr": "", "keywords": ["forecasting", "dynamics", "intervention modelling"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/63eb851ede4bbfac2f12b95f3936835c7ce66f33.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses time‑series forecasting under external interventions. It proposes ASIDE, which decomposes predictions into baseline (intrinsic) and response (intervention‑driven) components implemented by separate networks whose outputs are combined additively. Each network takes a context embedding of the history as input, and the model is optimized for future predictive accuracy. Training proceeds in three stages: (i) intrinsic dynamics only, (ii) intervention dynamics only, and (iii) joint training. Evaluation is conducted on a synthetic dataset aligned with the method’s assumptions and on the MIMIC dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* The paper targets an important problem in the healthcare domain: estimating treatment effects in medical time-series.\n* On the synthetic experiment, the method substantially outperforms the baselines, however, the scenario is not realistic (see Weaknesses)."}, "weaknesses": {"value": "The paper should be rejected due to (i) limited novelty, (ii) unclear conceptual differences from prior work, (iii) focus on a special‑case problem with no clear real‑world use case, and (iv) issues with the empirical evaluation.\n\n**(i) Limited Novelty**\n\nThe method comprises: (a) an additive decomposition with separate networks for baseline and response dynamics; (b) conditioning of these networks on history via a context embedding, and (c) a three‑stage training procedure. Here, components (a) and (b) are not novel ideas, which limits the originality of the contribution.\n\n**(ii) Conceptual differences with prior work**\n\nThe paper does not discuss prior work relevant to (c) the three‑stage adaptive training, making it impossible to assess novelty. \n\nIn addition, several claims reference prior literature without citations, e.g.:\n* Ln. 97-98: All existing intervention-effect models … - no reference.\n* Ln. 99-101: … typically achieved in a two-stage encoding-decoding framework… - no reference\n* Ln. 184-185: While different adaptation mechanisms exist, … - no reference\n* Ln. 186-187: … differ from existing works … - no reference\n* Ln. 192-194: …, existing works mostly focus on … - no reference\n\n**(iii) Special‑case problem with no clear real‑world connection**\n\nThe paper models intervention effects without addressing time‑varying confounding, thereby tackling a special case of counterfactual outcome estimation studied in prior work [Bica+20; Melnychuk+22]. In real medical time‑series, interventions are typically assigned based on patient history. Additionally, the manuscript does not connect its restricted setting to a concrete real‑world use case.\n\n**(iv) Issues with empirical results**\n\nBecause the method only estimates treatment effects in the absence of time‑varying confounding, the synthetic experiment uses randomly assigned treatments. This setup is unrealistic and limits the significance of the observed gains. In the real‑world MIMIC experiment, the method does not show substantial improvements over the main baseline, the causal transformer (CT) [Melnychuk+22].\n\n**Minor comments**\n* Figures and captions are not yet polished and could be improved.\n* Several repeatedly used phrases are unclear and should be defined at first use:\n  * “one-size-fit-all” forecasting function\n  * leverage inductive bias"}, "questions": {"value": "There are several points missing in the main text:\n\n* The training prediction horizon for the proposed method and each baseline is not reported. Please clarify the horizon used for each method in each experiment.\n* Parameter counts for ASIDE and for all baselines are not provided. Please report them.\n* What is the training‑time overhead of the three‑stage procedure relative to single‑stage training? Is it $3 \\times$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lBltH7YqLQ", "forum": "KiOqKKXomL", "replyto": "KiOqKKXomL", "signatures": ["ICLR.cc/2026/Conference/Submission21652/Reviewer_V4z1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21652/Reviewer_V4z1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761672234952, "cdate": 1761672234952, "tmdate": 1762941872069, "mdate": 1762941872069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ASIDE (Adaptive and Separable Interventional Dynamics), a framework that disentangles latent intrinsic dynamics from interventional responses in time-series data. The method leverages (1) explicit decomposition of latent ODE components into intrinsic (with own dynamic) and intervention-dependent (influenced by action) (2) a progressive meta-learning scheme that first learns intrinsic dynamics from intervention-free segments, then adapts interventional components via counterfactual generation. Context embeddings extracted from past history enable adaptation to inter- and intra-subject heterogeneity. Experiments on synthetic and real world dataset show improved forecasting accuracy over RMSN, CRN, and CT baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The explicit separation of intrinsic and interventional dynamics is intuitive and provides interpretability benefits over existing black-box time-series models.\n\n2. The two staged optimization that first learns intrinsic and then interventional dynamics is a neat idea that mitigates entanglement issues common in neural ODE frameworks. (although not sure why this is framed as meta- learning but okay)\n\n3. Both synthetic and real-world data are evaluated, with ablation studies that show each component’s contribution. In general, the empirical results are fare."}, "weaknesses": {"value": "1. The paper is dense and difficult to follow. Key intuitions behind the meta-learning and counterfactual embedding extraction could be explained more clearly, intuitively and visually. Can you try to add more explanations?\n\n2. While the work uses causal terminology and very much close to causal literature, it does not formally define or justify causal assumptions (especially around identifiability). Can you provide some justification or insight here?\n\n3. Maybe some baselines are missing, e.g. causal time series models, or recent counterfactual CDE or transformer-ODE baselines. Maybe there are some other baselines to compare to?\n\n4. Not sure how much novelty this idea have, decomposable models for time series separate default condition and conditions with intervention is not new. The literature should not just limited to neural ODE?"}, "questions": {"value": "Please see my weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R3DNME5JD4", "forum": "KiOqKKXomL", "replyto": "KiOqKKXomL", "signatures": ["ICLR.cc/2026/Conference/Submission21652/Reviewer_mjx5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21652/Reviewer_mjx5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761677443553, "cdate": 1761677443553, "tmdate": 1762941871710, "mdate": 1762941871710, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new framework, ASIDE, for modeling time-series data under external interventions. ASIDE is designed to explicitly separate the intrinsic system dynamics and responses to external interventions at the latent space. To address inter- and intra-subject variability, ASIDE leverages a meta-learning approach, extracting context embeddings from historical data to adapt both the intrinsic and intervention dynamics. This design allows the model to handle heterogeneity across and within subjects, thereby improving forecasting accuracy, especially over longer prediction horizons and with increasing heterogeneity. The framework is evaluated on both synthetic and real-world datasets to demonstrate its effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivations for disentangling and adapting the intrinsic and intervention-driven dynamics in time-series data are clearly described, and corresponding solutions are proposed.\n2. Experiments on both synthetic and real-world datasets, including ablation studies, are conducted to demonstrate ASIDE’s advantages.\n3. The paper is generally well-written and easy to follow."}, "weaknesses": {"value": "1. The baselines are too few (only three) and outdated (the newest is from 2022). The authors should consider more advanced baselines. In addition, classical non-neural-network-based models are lacking.\n2. The proposed model appears to require more computational complexity due to its more complicated structure and training process. A complexity comparison should be provided and discussed.\n3. While the model is claimed to be more interpretable, the paper does not provide qualitative or quantitative analyses of interpretability benefits."}, "questions": {"value": "Same as the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LdocyDDlxp", "forum": "KiOqKKXomL", "replyto": "KiOqKKXomL", "signatures": ["ICLR.cc/2026/Conference/Submission21652/Reviewer_yo1o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21652/Reviewer_yo1o"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884635312, "cdate": 1761884635312, "tmdate": 1762941871279, "mdate": 1762941871279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a framework called Adaptive and Separable Interventional Dynamics (ASIDE) to address challenges in modeling dynamic systems and time series forecasting. Using both synthetic and real-world benchmarks, they demonstrate that ASIDE improves forecasting accuracy for both intrinsic and interventional dynamics, under settings with or without time-varying confounders."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written, and the proposed method is conceptually clear and easy to follow.\nThe authors conduct experiments on both synthetic and real-world datasets, providing empirical evidence for the effectiveness of ASIDE."}, "weaknesses": {"value": "Several concerns should be addressed to strengthen the paper:\n\na. Outdated baselines:\nMost baseline methods used for comparison are from before 2022. More recent baselines, such as [1] and [2], should be included to better demonstrate the advantages of ASIDE.\n\nb. Lack of theoretical justification:\nThe theoretical support for the method is insufficient. The authors should provide a more rigorous theoretical analysis or justification to explain why ASIDE can outperform existing methods.\n\nc. Limited datasets:\nOnly two datasets are used in the experiments. Additional datasets, especially those focused on out-of-distribution (OOD) forecasting, should be included to provide a more comprehensive evaluation.\n\nd. Minor contribution of meta-learning:\nThe discussion of meta-learning in the paper appears somewhat trivial and should not be emphasized as a major contribution. This component represents a natural approach for representation learning in time series forecasting rather than a novel idea.\n\nReferences\n\n[1] Liu, Haoxin, et al. \"Time-series forecasting for out-of-distribution generalization using invariant learning.\" arXiv preprint arXiv:2406.09130 (2024).\n\n[2] Wang, Yuxuan, et al. \"Timexer: Empowering transformers for time series forecasting with exogenous variables.\" Advances in Neural Information Processing Systems 37 (2024): 469–498."}, "questions": {"value": "Please refer to the weaknesses above. Addressing these issues would significantly strengthen the paper and clarify the contribution of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8HsBJSGbK8", "forum": "KiOqKKXomL", "replyto": "KiOqKKXomL", "signatures": ["ICLR.cc/2026/Conference/Submission21652/Reviewer_XZKz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21652/Reviewer_XZKz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762111198451, "cdate": 1762111198451, "tmdate": 1762941870902, "mdate": 1762941870902, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}