{"id": "E9hSdtsAG0", "number": 14086, "cdate": 1758228271477, "mdate": 1763641785431, "content": {"title": "Drax: Speech Recognition with Discrete Flow Matching", "abstract": "Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, a discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as a promising direction for advancing NAR ASR.", "tldr": "A discrete flow matching approach for speech recognition", "keywords": ["Speech Recognition", "Discrete Flow Matching"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c550770606aa5651a6a8e11b35f824cc7669476c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes DRAX, an ASR system trained with Discrete Flow Matching (DFM). It introduces a tri-mixture training path that adds an audio-conditioned intermediate distribution between noise and the target transcript, aiming to better guide the flow during training while keeping non-autoregressive, parallel decoding. Advantages include low latency, a configurable accuracy–latency trade-off via the number of flow steps, support for ensemble/candidate sampling. The authors present results on standard benchmarks and motivate the approach with an occupancy-based generalization bound."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces a training only tri mixture path with an audio conditioned middle distribution, which (as far as I can tell) has not been used in DFM based ASR or in other DFM applications. The choice is theoretically motivated and appears extendable beyond ASR to other DFM style discrete token tasks.\n\nNon autoregressive, fully parallel decoding with a tunable  number of NFE and the candidate ensemble size  provides a clear accuracy versus latency trade off. However, this advantage stems from the general DFM/NAR framework, not from this paper’s specific path design.\n\nBecause the middle distribution is used only during training, the inference pipeline is unchanged with no additional test-time cost. Training overhead is modest, and performance remains comparable over a broad temperature range (Table 8), underlining ease of use in real-world applications"}, "weaknesses": {"value": "While the theory is nice, in practice there is no demonstrated link between the theory and the chosen middle path. The theory motivates reducing a training and inference occupancy gap, but there is limited tangible evidence (analytic or empirical) that this specific audio conditioned middle reduces that gap; at best, the paper offers intuition.\n\nI also feel there is a lack of ablations to support the central claim. Given the weak link between the design choice and the theory, the paper should lean on stronger empirics. In particular, there is no version of the main models trained without the middle distribution; only a small, single dataset ablation appears at the end. A extra row in the main tables (1 and/or 2) for the two mixture (no middle) reference would materially strengthen the claim. In particular, since the rationale and modeling presented here seem applicable beyond ASR, a more complete set of experiments (at least within ASR),  including the no middle baseline across multiple datasets, should be the minimum to substantiate the contribution.\n\nUnclear attribution and uneven comparisons within the DFM family. DRAX leverages ensemble prediction, while competing DFM baselines do not appear to be evaluated under the same ensemble regime (correct me if i'm wrong). As a result, improvements may be due to ensembling prediction rather than the proposed method. A comparison with identical numbers of flow steps and fixed candidate counts is needed to fairly attribute gains to the middle path, which again could be achieved by simply running the model without the middle path for the main experiments of the paper."}, "questions": {"value": "Did you try weighting the middle path term (for example, total loss = CDFM loss plus lambda times the middle path loss (equation 9))? Any insights on the impact of such parameter on the results ?\n\nI would suggest to increase figure font sizes; there is enough space to do it and several labels are hard to read."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1fXu3DqwGa", "forum": "E9hSdtsAG0", "replyto": "E9hSdtsAG0", "signatures": ["ICLR.cc/2026/Conference/Submission14086/Reviewer_pZNh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14086/Reviewer_pZNh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761138855363, "cdate": 1761138855363, "tmdate": 1762924563756, "mdate": 1762924563756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a discrete Flow Match approach for non-autoregressive (NAR) speech recognition, utilizing a tri-mixture probability path with an audio-conditioned middle distribution. \nExperimental results across eight language benchmarks demonstrate competitive accuracy compared to various baselines, offering an effective balance between accuracy and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The successful integration of discrete Flow Match into NAR Automatic Speech Recognition yields good performance in terms of both accuracy and computational efficiency.\n\nIntroduce probability path design within DFW, supported by comprehensive experimental studies and theoretical analysis."}, "weaknesses": {"value": "The approach has not yet been validated on larger scale tasks, nor thoroughly tested for robustness in noisy environments.\n\nThere is still insufficient analysis of how to optimize the probability path in ASR, including selecting improved intermediate distributions that can better approximate actual inference dynamics."}, "questions": {"value": "As the Flow Match model can condition on either continuous audio latents or discrete audio tokens, a comparative study examining accuracy, generalisation, and training efficiency would be valuable.\n\nIt is advisable to include an analysis of the three error types (Insertion/Deletion/Substitution).\n\nDetailed proofreading is recommended—for example, correcting minor errors such as the duplicate reference observed on line 189."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JtipksdvQX", "forum": "E9hSdtsAG0", "replyto": "E9hSdtsAG0", "signatures": ["ICLR.cc/2026/Conference/Submission14086/Reviewer_QEcG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14086/Reviewer_QEcG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761292428616, "cdate": 1761292428616, "tmdate": 1762924563267, "mdate": 1762924563267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel ASR framework, Drax, based on discrete flow matching. To address the transitions mismatch between training and inference, the audio-conditioned middle distribution is introduced to augment the probability paths. This is motivated by the provided theoretical analysis, which shows the flow matching generalization is controlled by the divergence between training and inference occupancies. Experimental results show that Drax suppasses standard discrete flow matching, and achieves competitive performance with other large scale ASR models, while offering better accuracy-efficiency trade-offs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The motivation of this paper is simple and reasonable: standard flow matching only learns transitions from pure noise to target, while ASR inference meets acoustically plausible but imperfect intermediate states, like substitutions, insertions, and deletions. Therefore, the authors improve path designs by augmenting the probability path with the audio-conditioned middle distribution. They also provide theoretical analysis to support that the training-inference path mismatch in flow matching affects generalization ability. \n2) The proposed Drax model achieves ASR performance comparable to SOTA large-scale models, while offering improved accuracy-efficiency trade-offs. \n3) Good writing, professional academic presentation, and detailed analysis."}, "weaknesses": {"value": "1) As the Drax encoder is a pretrained Whisper (large-v3) model, the authors should also compare to combining a simpler decoder module, such as CTC or AED or Transducer, which is more standard choice in ASR, on the same training data, and see if the proposed method can still get both better accuracy-efficiency trade-offs than these simple methods. I am concerned that, directly comparing to the released Whisper model might not be fair, since it is not trained on the used training data (Appendix C.2). The authors can also finetune the Whisper decoder on these training data for comparison.  \n2) In Table 1, on Hugging Face Open ASR result, though many popular large-scale models are included, it seems that there are other models achieving better results that Table 1 on https://huggingface.co/spaces/hf-audio/open_asr_leaderboard. It would be better to include a few of them if possible."}, "questions": {"value": "1) In L232-235, \"Thus, at test time we are interested in generating directly from the model without relying on the auxiliary component pmid. Concretely, we therefore setαmid ≡ 0 and sample using the same procedure as in the two-way mixture case\". I am interested in the results when including the audio-conditioned middle distribution in inference, which should also be reasonable because it align better with the training strategy?\n2) In L208-210, \"The middle distribution pmid(· | a) is parameterized by an auxiliary network rψ that takes the encoder representation φa as input and outputs per-token categorical distributions.\" The speech encoder output sequence and target text sequence typically have different lengths. How do the authors handle this? I assume p_mid has the same length of  text sequence.   \n3) How do the authors determine the target text length in decoding? By EOS tokens or other ways?\n4) In Section 5.4, what does \"uniform middle\" means? If the training paths are only from \"audio-conditioned source\", is the inference starting from the \"audio-conditioned source\", or uniform noise source?\n5) How about the results if MBR or Whisper-guided scoring are used in standard discrete flow matching model? Would the gain from the audio-conditioned middle distribution disappear?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hUN1odTpHF", "forum": "E9hSdtsAG0", "replyto": "E9hSdtsAG0", "signatures": ["ICLR.cc/2026/Conference/Submission14086/Reviewer_rrjF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14086/Reviewer_rrjF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14086/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833591597, "cdate": 1761833591597, "tmdate": 1762924562705, "mdate": 1762924562705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "We thank all reviewers for their time, careful reading, and constructive feedback. We are encouraged that reviewers found the paper well written and professionally presented (rrjF, pZNh) and appreciated the clarity of motivation and design of the proposed approach (rrjF). Reviewers highlighted the novelty of introducing an audio-conditioned middle distribution within discrete flow matching (rrjF, QEcG, pZNh), noting its simplicity, intuitive grounding, and potential applicability beyond ASR (pZNh). The reviewers acknowledged the strength of the theoretical analysis, particularly the occupancy-based generalization perspective (rrjF, QEcG). They also highlighted the strong empirical results, including competitive ASR accuracy, a favorable accuracy-efficiency trade-off, and the advantages of non-autoregressive, fully parallel decoding (rrjF, QEcG, pZNh). Reviewers also noted the breadth of experiments across eight benchmarks (QEcG) and the detailed analysis in the empirical section (rrjF).\n\nBelow, we provide detailed, point-by-point responses to each reviewer’s questions and concerns. We also uploaded a revised version of the paper, with modifications marked in red for ease of reference."}}, "id": "Fz9E9wLf7b", "forum": "E9hSdtsAG0", "replyto": "E9hSdtsAG0", "signatures": ["ICLR.cc/2026/Conference/Submission14086/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14086/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14086/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763638417857, "cdate": 1763638417857, "tmdate": 1763638417857, "mdate": 1763638417857, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "We thank the reviewers for their time, careful reading, and constructive feedback. We are encouraged that the reviewers found the paper well written and professionally presented (rrjF, pZNh) and appreciated the clarity of motivation and design of the proposed approach (rrjF). Reviewers highlighted the novelty of introducing an audio-conditioned middle distribution within discrete flow matching (rrjF, QEcG, pZNh), noting its simplicity, intuitive grounding, and potential applicability beyond ASR (pZNh). The reviewers acknowledged the strength of the theoretical analysis, particularly the occupancy-based generalization perspective (rrjF, QEcG). They also highlighted the strong empirical results, including competitive ASR accuracy, a favorable accuracy-efficiency trade-off, and the advantages of non-autoregressive, fully parallel decoding (rrjF, QEcG, pZNh). Reviewers also noted the breadth of experiments across eight benchmarks (QEcG) and the detailed analysis in the empirical section (rrjF).\n\nBelow, we provide detailed, point-by-point responses to each reviewer’s questions and concerns. We also uploaded a revised version of the paper, with modifications marked in red for ease of reference."}}, "id": "Fz9E9wLf7b", "forum": "E9hSdtsAG0", "replyto": "E9hSdtsAG0", "signatures": ["ICLR.cc/2026/Conference/Submission14086/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14086/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14086/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763638417857, "cdate": 1763638417857, "tmdate": 1763714298200, "mdate": 1763714298200, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}