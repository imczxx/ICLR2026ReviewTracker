{"id": "hFiNgXOT8p", "number": 17549, "cdate": 1758277422791, "mdate": 1759897167867, "content": {"title": "Real-Time Text-Conditioned World Models for Interactive Prototyping", "abstract": "State-of-the-art world models have been used to produce sequences of gameplay that accord with provided user-input actions, with the suggestion that such models could have creative applications such as quick prototyping of game ideas. However, high quality, consistent gameplay generation often comes at the cost of inference speed, making real-time interactive play challenging. Models are also limited in their ability to generate new content that deviates from original gameplay, particularly when trained on data from a single environment. In this work we demonstrate two major steps towards enabling interactive, real-time ideation. Building on an autoregressive world model capable of generating highly consistent and complex sequences over minutes (Kanervisto et al., 2025), we enable substantial model speed-up with minimal deterioration in output quality. This is done by replacing the next-token prediction paradigm with discrete diffusion, introducing a lightweight refinement transformer which carries out iterative masked predictions. Subsequently, we explore how new game behaviours can be learned and triggered at inference time in a controlled manner. To this end, we introduce text to control the game environment generated by the model, and curate the BodySwap dataset which simulates a character swapping mechanism allowing to change the playable character using a text prompt. Our results highlight the potential of world models as real-time prototyping tools, enabled by intentional curation of small datasets and efficient fine-tuning.", "tldr": "", "keywords": ["World models", "autoregressive models", "real time"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ae429833fe3ac2afef42f1cdff6694aaf2736032.pdf", "supplementary_material": "/attachment/9c2e2009741d54b8d9d497a47078024488336e87.zip"}, "replies": [{"content": {"summary": {"value": "The authors present a new video world-model trained on the game Bleeding Edge which is capable of generating simulated frames in approximately real time (~17 FPS) while maintaining coherence over a moderate time horizon (5 minutes). The authors also introduce a version of the world model which is fine-tuned to swap the in-game character in response to text input. The models are evaluated according to both a variety of automated image quality metrics as well as a human preference study."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The technical contribution of this paper seems quite impressive -- an action-conditioned world model which runs efficiently enough to permit real-time play is a real accomplishment and paves the way for future advances in that direction. The architecture appears well motivated and the quantitative results are thorough enough to motivate other researchers to build off of the ideas. The paper is also clearly written and well-explained."}, "weaknesses": {"value": "While I very much appreciate the motivation to begin exploring prototyping and adaptation to novel mechanics with the BodySwap dataset and model, I do also feel that it is the weaker aspect of the paper. The stated motivation is to facilitate prototyping, but the BodySwap model does not simulate any mechanics which have not already been implemented in the existing game environment. That is, while mid-game character swapping does not appear in Bleeding Edge, each of the characters obviously already do. It’s not totally clear that training a world model would be more efficient than implementing the relevant mechanic for the purpose of prototyping. The main upside of a world model in this context (zero- or few-shot simulation of an unimplemented game mechanic) doesn’t seem like it’s fully being realized with the BodySwap example. Even if the results would be less impressive, I think the paper would be strengthened by an exploration of adaptation to truly novel game mechanics (e.g. “swapping” to a character that doesn’t exist)."}, "questions": {"value": "- How important is the size of the original WHAM training dataset to the performance of WHAM-RT and BodySwap? This seems like one of the main barriers to wider adoption of the general technique.\n- Appendix E only says that “N” human raters were recruited -- what’s the value of N?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BzaElPV76w", "forum": "hFiNgXOT8p", "replyto": "hFiNgXOT8p", "signatures": ["ICLR.cc/2026/Conference/Submission17549/Reviewer_8EMq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17549/Reviewer_8EMq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791426278, "cdate": 1761791426278, "tmdate": 1762927421045, "mdate": 1762927421045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper made some acceleration improvements to WHAM and then collected a BodySwap dataset to fine-tune the model with text control."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The proposed method seems reasonable and indeed effective in terms of acceleration."}, "weaknesses": {"value": "- (1) The title of the paper is overly ambitious, as the authors aim to achieve \"Interactive Prototyping,\" but the techniques discussed in the paper are not sufficient to support this goal. Key issues such as the model's generative capabilities, understanding, and memory were not addressed, all of which are crucial for achieving interactive prototyping.\n- (2) The acceleration and text control fine-tuning methods proposed in the paper lack significant novelty; they are merely common techniques applied to next-token-prediction models.\n- (3) The paper's qualitative results are poorly presented. It is difficult to assess the quality of the generated gameplay videos directly from the figures shown by the authors. The specific relationships between interactive controls and corresponding video frames are hard to identify, and it's unclear whether the text control was successful. Additionally, the number of qualitative results shown is very limited. This greatly weakens the contribution of the paper and raises doubts about the effectiveness of the proposed method."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yWfMUMhBAn", "forum": "hFiNgXOT8p", "replyto": "hFiNgXOT8p", "signatures": ["ICLR.cc/2026/Conference/Submission17549/Reviewer_mqCL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17549/Reviewer_mqCL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837280269, "cdate": 1761837280269, "tmdate": 1762927420392, "mdate": 1762927420392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents WHAM-RT, a real-time extension of the WHAM world model for interactive gameplay prototyping, achieving up to 17 FPS (≈7000% speed-up) through a discrete diffusion-style refinement that replaces next-token autoregression while preserving visual fidelity. To enhance controllability, the authors introduce the BodySwap dataset, simulating character-swapping in the Bleeding Edge game and enabling text-based prompts to trigger new gameplay behaviours. Experiments show that novel mechanics can be efficiently learned from small curated datasets via lightweight finetuning methods (Full, LoRA, DoRA), with quantitative (FVD, FVMD, JEDI) and human evaluations confirming a strong balance between generation speed and quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper introduces WHAM-RT, a real-time variant of the WHAM world model, aimed at enabling interactive gameplay prototyping through efficient video generation and text-conditioned control.\n\nThe authors replace the original next-token autoregressive prediction with a discrete diffusion-style refinement process, achieving up to 17 FPS (≈ 7000 % speed-up) over WHAM with minimal loss in visual fidelity.\n\nTo further expand controllability, the authors curate the BodySwap dataset, simulating character-swapping behaviour in the Bleeding Edge game, and integrate text-based prompts to trigger new gameplay mechanics."}, "weaknesses": {"value": "The architectural modification largely adapts known ideas from MaskGit / MAGVIT; the conceptual leap from diffusion-based image refinement to world-model token generation is incremental.\n\nAll experiments rely on the single Bleeding Edge environment; no evidence is given for cross-environment generalisation. The author can provide more game scenes, more diverse combinations of objects and characters to verify the generalization and robustness of the method.\n\nWhile numerical metrics are extensive, visual comparisons (e.g., temporal coherence heatmaps or failure cases) are scarce. The visual results presented in the paper are not convincing enough; more and higher-quality visualizations should be provided.\n\nThe use of proprietary gameplay footage (Bleeding Edge) raises unresolved issues around licensing and dataset release.The description of the dataset in the article is rather vague. Could there be more fine-grained dataset analysis and statistics, as well as more visualizations of the dataset and prompts? This would make it more convenient to evaluate the model's performance based on the training dataset.\n\nThe paper is poorly written, with many sections that are difficult to follow. There are numerous typos throughout—for example, in Figure 2, both “tokenizer” and “modeling” are misspelled."}, "questions": {"value": "I believe the current version of the paper does not meet the quality required for acceptance. I recommend that the authors address the identified weaknesses and revise the paper for submission to a future conference."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yFSHffnPmK", "forum": "hFiNgXOT8p", "replyto": "hFiNgXOT8p", "signatures": ["ICLR.cc/2026/Conference/Submission17549/Reviewer_XsJT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17549/Reviewer_XsJT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917626417, "cdate": 1761917626417, "tmdate": 1762927419823, "mdate": 1762927419823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}