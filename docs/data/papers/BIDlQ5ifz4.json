{"id": "BIDlQ5ifz4", "number": 18705, "cdate": 1758290299220, "mdate": 1759897086383, "content": {"title": "FALCON-S: Fixed-wing Aerodynamics and Learning Control Suite", "abstract": "We introduce FALCON-S, a modular and high-fidelity framework for learning and control of fixed-wing aerial vehicles operating in ground effect. In contrast to existing aerial platforms with simplified dynamics, FALCON-S incorporates full 6DoF simulation alongside detailed modeling of ground-effect aerodynamics, actuator dynamics, and environmental disturbances. It offers a level of physical fidelity and modular component design that enables fine-grained manipulation and systematic analysis of low-altitude flight phenomena, capabilities rarely found in open-source or state-of-the-art simulation platforms. The framework includes both CPU and GPU simulation backends via Python and NVIDIA Warp, supporting high-throughput simulation across up to millions of parallel environments, which makes it suitable for reinforcement learning, sampling-based control algorithms, and large-scale evaluation. FALCON-S features a flexible architecture with interchangeable controllers, supporting optimal control, model-free and model-based RL, as well as a suite of flight control tasks such as altitude regulation and trajectory tracking. We include optional interfaces for validation and comparison through MATLAB/Simulink and XPlane, making it compatible with both engineering workflows and commercial simulators. The framework is released as open-source to facilitate reproducibility and enable controlled benchmarking in realistic flight scenarios.", "tldr": "FALCON is a high-fidelity, GPU-accelerated simulation benchmark for fixed-wing aircraft in ground effect, supporting both RL and classical control with modular physics, scalable training, and detailed flight control analysis.", "keywords": ["Flight Control", "Optimal Control", "Reinforcement Learning", "ground-effect aerodynamics"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e65afba62b3944fac459019981b6606c83396819.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces FALCON-S, a new, open-source simulation framework for developing and bench-marking control algorithms for fixed-wing aerial vehicles. The main contribution is a simulator unlike previous work that provides :- \n\n(1) High fidelity Physics - 6 DoF dynamics model that includes components for Aerodynamics, first or second order actuator dynamics, environmental dynamics and sensor models \n(2) High throughput scalability - Dual backend architecture for CPU/GPU based pipelines with the GPU backend being able to simulate \"up to millions of parallel environments\" wit ha single step time.\n(3) Modularity - The framework supports both reinforcement learning and optimal control methods with a gym api being exposed for RL methods\n(4) Cross platform validation interfaces - Validation capabilities for both MATLAB/Simulink and X Plane.\n\nThe paper is motivated by the need to bridge sim-2-real gap as existing simulators are either high-fidelity but too slow for RL (JSBSim, FlightGear, and X-Plane) or high-throughput but lack the necessary physical realism (Flightmare, NeuralPlane)"}, "soundness": {"value": 1}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "1. Originality - It correctly identifies and addresses an important gap in the existing landscape of aerial vehicle simulators - either they are slow or too oversimplified and lack physics realism. Its the mix of both that is available in FALCON-S that pushes it for the win\n2. Quality -  The quality of engineering work presented in this paper is absolutely amazing. The physics model that includes interconnected components for - Aerodynamics, Actuators, Environmental Effects and Sensors- is a significant strength with the dual backend architecture for high throughput simulation\n3. Clarity - Absolutely perfect technical clarity with the writing and well structured, making it easy to follow. The figures and tables are also very effective with the appendices providing deep technical clarity\n4. Significance - This work is highly significant as an open source community resource as it provides a strong instrument for the robotics, aerospace, and RL communities."}, "weaknesses": {"value": "1. The paper's primary motivation -bridging the \"sim-to-real gap\"  - is left entirely unsubstantiated. There is no experiments done on real world hardware.\n2. 75% of the experimental results use a classical LQR and just 1 experiment using Dreamer V3. The paper thus provides zero insights about learning and just is flexing the simulator features. And it DreamerV3 is just tested in isolation for some reason. \n3. It is stated - \"Our experiments are designed to highlight the flexibility and realism of the FALCON-S framework, rather than to optimize or compare specific learning or control algorithms\" - this probably goes against the necessity for a learning based conference."}, "questions": {"value": "1. Could the authors provide more experimental results for learning based algorithms ? As we are only relying on a non-learning controller for the main results\n2. The MPPI controller failures seem to be omitted from main text and are pushed to the appendix (Appendix B2 (Table 9)). What was the reasoning behind LQR passing and MPPI failing in such scenarios ? \n3. Why should the ICLR community accept the fact that this framework helps bridge the gap when there are no real world experiments ? \n4. Why did you use a classical LQR controller for all the key physics tests (like sensor noise, ground effect, and delays)? Since this is a learning conference, shouldn't these experiments have used a learning agent like PPO or DreamerV3 to show how these realistic physics impact the learning process itself ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sF04ZGcemT", "forum": "BIDlQ5ifz4", "replyto": "BIDlQ5ifz4", "signatures": ["ICLR.cc/2026/Conference/Submission18705/Reviewer_K936"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18705/Reviewer_K936"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971413165, "cdate": 1761971413165, "tmdate": 1762928408405, "mdate": 1762928408405, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FALCON-S, a modular, high-fidelity simulation framework designed for learning and control of fixed-wing unmanned aerial vehicles (UAVs) operating in ground effect. The simulator integrates full 6DoF rigid-body dynamics, advanced aerodynamic modeling, including semi-empirical ground effect corrections—and realistic actuator and sensor dynamics. It supports GPU-accelerated simulation via NVIDIA Warp, enabling high-throughput training across millions of parallel environments. The framework is highly extensible, with support for both classical (e.g., LQR, MPPI) and modern deep reinforcement learning (e.g., PPO, DreamerV3) controllers. It also includes interfaces for cross-validation with MATLAB/Simulink and X-Plane. The authors demonstrate the platform’s utility through illustrative experiments on multi-task generalization, cross-aircraft evaluation, and robustness to environmental disturbances."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **High Fidelity and Realism:**\nFALCON-S stands out for its realistic modeling of ground effect, aerodynamic coefficients, actuator dynamics, and sensor imperfections—features often missing or oversimplified in existing simulators like QPlane or NeuralPlane.\n\n2. **Scalable, GPU-Accelerated Simulation:**\nThe use of NVIDIA Warp enables a single-step simulation time of 0.0022 seconds across 1 million parallel environments - i.e., a 100× speed-up over state-of-the-art. This is a major technical achievement and crucial for efficient RL training.\n\n3. **Modular and Extensible Architecture:**\nThe framework is well-organized into agent and environment modules, with clean separation of concerns. The ability to toggle physical models (e.g., ground effect, turbulence) and swap controllers (classical vs. learning-based) enables rigorous ablation studies.\n\n4. **Strong Validation and Interoperability:**\nThe inclusion of X-Plane and MATLAB/Simulink interfaces is a significant asset for cross-platform validation, sim-to-real transfer, and integration with industry-standard workflows.\n\n5. **Open-Source and Reproducible Research:**\nThe code is released under an open-source license (via anonymous 4open.science), promoting reproducibility, benchmarking, and community adoption."}, "weaknesses": {"value": "1. **Limited Quantitative Benchmarking:**\nWhile the paper presents several illustrative experiments, it lacks comprehensive, quantitative benchmarks comparing FALCON-S against existing platforms (e.g., NeuralPlane, QPlane) on standard control tasks. A formal benchmarking study would strengthen the claim of superiority.\n\n2. **Lack of Hardware Integration or Real-World Deployment:**\nThe paper focuses on simulation and learning, but there is no discussion of hardware-in-the-loop (HIL) testing, flight testing, or sim-to-real transfer in practice. This limits the paper’s impact on real-world deployment.\n\n3. **Insufficient Discussion of Computational Overhead and Memory Usage:**\nWhile speed is emphasized, the paper lacks detailed analysis of memory footprint, GPU memory usage, and scalability limits (e.g., how many agents can be simulated before performance degrades). This is critical for practical deployment.\n\n4. **Limited Explanation of Ground Effect Model Parameters:**\nThe ground effect model is based on empirical corrections (Phillips & Hunsaker, 2013), but the paper does not clearly explain how parameters (e.g., h/b ratio, aspect ratio) are estimated or tuned for different aircraft. This reduces transparency."}, "questions": {"value": "1. How does FALCON-S compare to existing platforms (e.g., NeuralPlane, QPlane) in terms of simulation accuracy and computational efficiency across a wide range of tasks?\n2. Could the authors provide a detailed breakdown of the memory and GPU usage during large-scale parallel simulations (e.g., 1M environments)?\n3. How are the ground effect model parameters (e.g., µL, µD) calibrated for different aircraft types in FALCON-S? Is this process automated or manual?\n4. Are there plans to include more complex flight dynamics (e.g., post-stall aerodynamics, vortex shedding) in future versions?\n5. Has FALCON-S been tested in hardware-in-the-loop (HIL) setups or actual flight tests? If so, please provide details.\n6. How does the framework handle non-ideal environmental conditions such as crosswinds, gusts, or sudden atmospheric pressure changes beyond the Dryden turbulence model?\n7. Is the framework compatible with reinforcement learning baselines beyond SB3 and DreamerV3 (e.g., SAC, TD3, PPO with attention)?\nWhat is the expected time and computational cost to train a single controller (e.g., DreamerV3) on a standard task using FALCON-S?\n8. How does the framework ensure numerical stability and convergence when simulating high-dimensional, nonlinear dynamics over long horizons?\n9. Are there plans to support real-time rendering and visualization (e.g., via Unity or Unreal) in addition to X-Plane?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6ikIc4bMBa", "forum": "BIDlQ5ifz4", "replyto": "BIDlQ5ifz4", "signatures": ["ICLR.cc/2026/Conference/Submission18705/Reviewer_5ovJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18705/Reviewer_5ovJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974583722, "cdate": 1761974583722, "tmdate": 1762928407790, "mdate": 1762928407790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a software package for GPU-accelerated realistic simulation of a fixed-wing aircraft.\nThe package targets applications in reinforcement learning and sampling-based model-predictive control. The package simulates basic rigid-body dynamics, fixed-wing aerodynamic forces, actuator delays, wind, pressure, ground effect, and sensor delays/noise.\nSeveral reward functions for different tasks are provided.\nThe package exposes an OpenAI Gym interface and supports both GPU and CPU backends.\nIt has a bridge to X-Plane to compare the simulation against a realistic industry standard.\n\nThe experiments:\n- Demonstrate that DreamerV3, a model-based RL algorithm, can learn an altitude-keeping policy.\n- Evaluate a LQR controller on different tasks.\n- Show that a LQR controller synthesized for one aircraft does not transfer to others.\n- Show the impact of different physical and sensor disturbances on the LQR controller.\nThere is also a MPPI experiment in the appendix, but its results are not discussed in the main body."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed simulator appears to fill a gap in the landscape of fixed-wing flight simulators: the realistic ones are not amenable to parallel single-stepping for learning, and the other GPU-parallel one is not realistic (if we take the authors' word for it).\n- The package seems well-designed, and the GPU acceleration is highly relevant for RL.\n- The description of the simulator architectures and features has a good detail level - for a practitioner trying to decide which simulator to use, the paper should have all the information they need.\n- Fixed-wing control, especially in scenarios far from straight and level flight, is relatively under-explored by the learning+control community compared to the (arguably less interesting) quadrotors."}, "weaknesses": {"value": "- Numerous plots are illegible in the text labels and/or plots themselves: Figure 2, bottom row of Figure 4, second row of Figure 5.\n- Given the emphasis on supporting a range of control architectures, the paper seems to be missing an obvious experiment: compare the performance of DreamerV3, MPPI, and LQR on the same set of tasks. Some of this information already exists in comparing Table 3 and Table 9, but Table 9 is relegated to the appendix, and it will be easy to make errors looking back and forth.\n- Going further, other candidates like model-free RL and optimization-based (deterministic) MPC could make the comparison even more interesting.\n- Ground effect modeling is stated as a key improvement relative to other simulators, but only one small experiment in the appendix includes it.\n- There is a feature table comparing to other simulators, but there is no quantitative comparison e.g. on framerate, accuracy, etc.\n- Lines 302-304 claim that the experiment will analyze ground effect and actuator delay, but the experiment does not actually include those phenomena.\n- Table 7 in the appendix is never discussed in the appendix text.\n\nOverall, the software presented in this paper is a solid contribution to the aerial robotics and learning+control research communities. The paper does a good job describing the features and architecture of the software. However, the experiments seem more like basic validation tests; they do not really provide any new information. For a datasets/benchmarks paper in ICLR, I would expect the experiments to do at least one of:\n\n1) shed light on some important phenomenon in the application of learning+control algorithms to fixed-wing aircraft that was not well-known before, or\n2) show very convincing evidence that the simulator is an improvement on previous available simulators.\n\nI do not think this paper has met that standard. However, it seems within reach with a bit more effort, and I encourage the authors to keep refining this project."}, "questions": {"value": "- In Table 1, the authors claim that their simulator is \"more realistic\" than NeuralPlane in an unspecified way. However, since it is the most closely related work, there should be more detail. In what way exactly is NeuralPlane less realistic?\n- The authors claim the package includes \"visualization tools\", but these are never discussed, and I did not see any screenshots. What are they?\n- Line 065: In the intro, it is not clear exactly what \"validation capabilities\" means.\n- Line 090: What do you mean by \"3DoF models\"? It seems implausible that any flight simulator would not use a 6DoF SE(3) configuration as the foundation.\n- Line 161-162: Is there any reference to justify that first- and second-order actuator response models are \"realistic\", e.g. from the aerospace controls literature?\n- Line 203: What does it mean for the agent module to \"support\" a control model? Most robotics simulators can be used with any control architecture with no special effort.\n- Line 272: Typo \"luck-up table\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0nodm5Nssr", "forum": "BIDlQ5ifz4", "replyto": "BIDlQ5ifz4", "signatures": ["ICLR.cc/2026/Conference/Submission18705/Reviewer_rS4i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18705/Reviewer_rS4i"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984307982, "cdate": 1761984307982, "tmdate": 1762928407236, "mdate": 1762928407236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}