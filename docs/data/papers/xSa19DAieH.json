{"id": "xSa19DAieH", "number": 17392, "cdate": 1758275410026, "mdate": 1759897177804, "content": {"title": "Stable-LoRA: Stabilizing Feature Learning of Low-Rank Adaption", "abstract": "Low-Rank Adaption (LoRA) is a widely adopted parameter-efficient method for fine-tuning Large Langauge Models. The weight matrix is updated as $W=W_0+sBA$, where $W_0$ is the original frozen weight, $s$ is a scaling factor and $A$,$B$ are trainable low-rank matrices. In this paper, we first theoretically show that, LoRA can naturally achieve and sustain stable feature learning (i.e., can be self-stabilized) given appropriate hyper-parameters and initializations of $A$ and $B$. However, we also claim that the non-zero initialization of $A$ could potentially compromise self-stability. To address this issue, we propose Stable-LoRA, a weight-shrinkage optimization strategy that enhances stability of LoRA feature learning. By progressively shrinking $A$ in the earliest training steps, Stable-LoRA is theoretically proved and empirically verified to prevent potential instability of LoRA while preserving the benefits of the non-zero start. With only 3 lines of code modification, Stable-LoRA consistently outperforms classical LoRA and other baselines in accuracies across various tasks, with no extra memory usage and negligible additional computation costs.", "tldr": "This paper proposes Stable-LoRA, a weight-shrinkage optimization strategy that enhances stability of LoRA feature learning.", "keywords": ["Large Language Models", "parameter-efficient fine tuning", "low-rank adaption"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d4d5eebfff0ca80a854d69b5ebc54f73d4575518.pdf", "supplementary_material": "/attachment/2c308e9cfce07c393aac63e6043c06bca544df2d.zip"}, "replies": [{"content": {"summary": {"value": "This paper provides a theoretical analysis of LoRA’s fine-tuning dynamics and argues that LoRA can achieve self-stabilization under proper initialization and hyperparameter choices. The authors further propose *Stable-LoRA*, a simple weight-shrinkage strategy applied to the A matrix during early training to mitigate instability. Experimental results show consistent improvements across several reasoning and QA benchmarks, demonstrating the method’s effectiveness and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper offers a clear theoretical perspective on the stability of LoRA fine-tuning, supported by a consistent use of the γ-function framework to characterize scaling behavior. The derivations are mathematically well-structured and connect intuitively to optimization dynamics. The proposed Stable-LoRA method is simple yet effective, introducing negligible computational overhead while improving training stability across tasks. The work also contributes conceptually by bridging theoretical analysis and practical optimization design within the PEFT paradigm."}, "weaknesses": {"value": "1. About Assumption 1: \n\n   If the activation $Z$ is normalized under a fan-in scaling scheme  (i.e., each input element scaled by $1/\\sqrt{n}$, which is common in linear layers or attention projections),  then each component of $Z$ becomes $\\Theta(n^{-1/2})$.  \n\n   Consequently, the product $g_A^t Z$ involves a summation over $n$ such terms,  resulting in an overall magnitude of $\\Theta(\\sqrt{n})$.  This implies that $\\gamma[g_A^t Z] = \\tfrac{1}{2}$ rather than $1$.  Could the authors clarify whether Assumption 1 still holds under common fan-in scaling conventions?  In particular, does the assumed normalization (e.g., layer normalization, residual connections, or other schemes)  preserve the activations at the $\\Theta(1)$ scale?\n\n2. In Section 3.2, the authors assume that $\\gamma[A_0 Z] \\le \\gamma[\\eta] + 1 \\Rightarrow \\gamma[A_t Z] = \\gamma[\\eta] + 1.$ However, “≤” only provides an upper bound and does not guarantee equality during training. This step effectively assumes convergence of the recursive relation $\\gamma[A_t Z] = \\max(\\gamma[A_{t-1}Z], \\gamma[\\eta] + 1),$ without proving that the sequence will reach equality. Could the authors provide a justification (analytical or empirical) showing that the recursion indeed converges to $\\gamma[A_t Z] = \\gamma[\\eta] + 1$ rather than remaining strictly below that bound?\n\n3. The paper claims that when only one condition in Eq. (5) holds, $\\gamma[A_t Z] = \\gamma[B_t] + 1 \\Rightarrow \\gamma[\\delta_1] = \\gamma[\\delta_2],$ which is said to be “undesirable.” However, δ₁ and δ₂ represent the contributions of matrices A and B to the output update ΔYₜ. Having the same γ-scale simply implies that both pathways contribute symmetrically, which is not necessarily detrimental to learning stability. Could the authors clarify why $\\gamma[\\delta_1] = \\gamma[\\delta_2]$ must be considered suboptimal? Is there theoretical or empirical evidence that symmetric scaling between A and B leads to instability?\n\n### Cons\n\n1. The baselines considered in Table 1 are too limited. Recent PEFT methods such as DoRA[1] and AdaLoRA  also address optimization stability and efficiency. Including these methods would provide a fairer and more comprehensive comparison.\n\n2.  The backbones used are relatively small (≤ 3B parameters). To substantiate the claim of general stability, experiments on larger or more recent architectures (e.g., Llama-3.2-8B, Mistral-7B, or Mixtral-8×7B) are necessary. This would also help assess scalability and compatibility with modern large-model training dynamics.\n\n   [1] Liu, X., Li, Y., Zhou, T., Wang, K., & Qiu, X. (2024). *DoRA: Weight-Decomposed Low-Rank Adaptation*. arXiv preprint arXiv:2402.09353.\n\n   [2] Zhang, R., Xu, H., Cui, Y., Liu, T., & Zhang, Y. (2023). *AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning*. arXiv preprint arXiv:2303.10512.\n\n## Typos\n\n1. Lines 101: There is a dot(.) at the begining of 101 lines. Maybe its should be placed on the end of Eq. (1). \n\n2. Lines 202: The same issue as in line 101 — punctuation should not appear at the beginning of a new line."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iga8GuzJHa", "forum": "xSa19DAieH", "replyto": "xSa19DAieH", "signatures": ["ICLR.cc/2026/Conference/Submission17392/Reviewer_iYHY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17392/Reviewer_iYHY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922400596, "cdate": 1761922400596, "tmdate": 1762927298886, "mdate": 1762927298886, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Stable-LoRA, a novel optimization strategy that enhances the training stability of LoRA. The authors first theoretically demonstrate that LoRA possesses self-stabilizing properties under appropriate hyperparameters and initialization, but commonly used non-zero initialization often undermines this stability. To address this, Stable-LoRA dynamically shrinks matrix A during the early training phase. Experimental results demonstrate the effectiveness of Stable-LoRA and with negligible additional computational or memory overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* This paper is solid in its theoretical contribution. The motivation and concepts are well illustrated, making the work easy to follow. The algorithm design is simple yet elegant, and the stability stopping criterion is theoretically justified.\n\n* Empirical results demonstrate both the effectiveness and stability of the proposed method. Moreover, it is computationally efficient, introducing only a minor additional runtime overhead. The approach is also compatible with existing LoRA setups without requiring any architectural modifications."}, "weaknesses": {"value": "* The experimental settings and details are somewhat limited and unclear. First, how are the experiments on the QA datasets conducted? Is the model fine-tuned on a mixed training dataset and then evaluated on several benchmarks, or is it fine-tuned on one QA dataset and tested accordingly? If it is the latter case, I would suggest conducting additional experiments on general language understanding and dialogue datasets such as WizardLM to better assess the model’s generalization ability. Moreover, the experimental settings for the reasoning tasks are also limited.\n\n* How many steps does Stable-LoRA require to reach its stable mode? I think the shrinkage of the LoRA matrix $A$ shares a similar intuition with the weight decay mechanism in AdamW. How about comparing Stable-LoRA with AdamW using a relatively large weight decay parameter when the model shows instability?\n\n* Finally, Stable-LoRA should also be applicable to other LoRA variants, such as AdaLoRA. Have the authors tried this? If the method generalizes well to other setups, it would be quite interesting."}, "questions": {"value": "See details in the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ew5Wo6HWvg", "forum": "xSa19DAieH", "replyto": "xSa19DAieH", "signatures": ["ICLR.cc/2026/Conference/Submission17392/Reviewer_S7AS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17392/Reviewer_S7AS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947660867, "cdate": 1761947660867, "tmdate": 1762927297955, "mdate": 1762927297955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates whether LoRA can achieve and sustain stable feature learning. By introducing a $\\gamma$-function as the main analytical tool, the authors prove that stable feature learning is attainable under specific hyperparameter settings and when $A = B = 0$. However, in practices, $A$ and $B$ cannot be set to 0 at the same time. To mitigate this issue, the paper proposes a progressive shrinkage strategy that gradually reduces $A$ during the early training stages. Extensive experiments suggest that the proposed Stable-LoRA method consistently outperforms baseline models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper introduces the $\\gamma$-function as a novel analytical construct for understanding LoRA’s stability behavior.\n* Theoretical analysis yields an interpretable condition—$A=B=0$—under which stable feature learning can be achieved.\n* The proposed progressive-shrink mechanism is a practical solution to approximate the ideal condition $A=B=0$ and address the constratins that in practices, we cannot set both $A$ and $B$ to 0."}, "weaknesses": {"value": "* Definition 1 lacks rigorous justification. While it aligns with prior empirical observations, it represents only one possible stability condition. The framework built upon it may have limited generalizability, which can only be supported by broader empirical studies.\n* The definition of the $\\gamma$-function appears mathematically infeasible. Although it seems inspired by logarithmic properties (e.g., \n$\\log(x) + \\log(y) = \\log(x \\times y)$ and $\\log(x + y)$ is dominated by $\\max(\\log(x), \\log(y)$). The equation $\\gamma[v + v'] = \\max(\\gamma[v], \\gamma[v'])$ may not always hold, even with a hidden constant in the $\\Theta(\\cdot)$. Thus, the $\\gamma$-function may be valid for qualitative reasoning, but not for formal proof.\n* Empirical results (e.g., Table 1) show only moderate improvements without reporting standard deviations or confidence intervals. It is therefore difficult to determine whether the observed gains are statistically significant or within expected variance.\n* The writing quality could be improved. Several sections are hard to parse and would benefit from clearer exposition and more precise mathematical notation."}, "questions": {"value": "1. Line 47: Should the asymptotic complexity be $O(n)$ instead of $O(n^0)$,  if this is \"with respect to model width $n$\" as stated in line 46.\n2. Line 131: The definition of $r[v]$ by $v=\\Theta(n^{\\gamma[v]})$ is kind of informal. Written in this way, it implicitly invites a proof of existence.\n3. Line 132: $\\gamma[\\overrightarrow{v}]:=\\max(v_i, 0 < i < k)$. Should it be $0\\le i$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "G59yKgcar8", "forum": "xSa19DAieH", "replyto": "xSa19DAieH", "signatures": ["ICLR.cc/2026/Conference/Submission17392/Reviewer_1UrF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17392/Reviewer_1UrF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958067613, "cdate": 1761958067613, "tmdate": 1762927297499, "mdate": 1762927297499, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LoRA is the method that is the most commonly use to finetune LLMs. However it does have some training challenges. This study looks at those problems and proposes a clear analysis, especially around the initialization of LoRA--and propose a novel solution. Empirical results are provided to support the claim.\n\n** Strength **\n- very important problem in the world of LLM and post-training especially\n- the experiments are quite sound to validate the study\n- the interpretation of LoRA is interesting albeit hard to grasp for readers not familiar with the field\n\n** Weakness **\n- enormous typo (e.g. one right in the title, adaption, or in the abstract, Langauge) which makes the entire script feel quite odd\n- could the author discuss a possible link with https://arxiv.org/pdf/2410.09692? who also checked at initialization and training dynamics?\n- lacking some geometric/visual intuition that would help reader better grasp the results\n- needs better scoping of limitation and future work"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Please see summary"}, "weaknesses": {"value": "Please see summary"}, "questions": {"value": "Please see summary"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "v3njdn2OIe", "forum": "xSa19DAieH", "replyto": "xSa19DAieH", "signatures": ["ICLR.cc/2026/Conference/Submission17392/Reviewer_33Pn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17392/Reviewer_33Pn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970834779, "cdate": 1761970834779, "tmdate": 1762927296946, "mdate": 1762927296946, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}