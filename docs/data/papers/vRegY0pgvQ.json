{"id": "vRegY0pgvQ", "number": 336, "cdate": 1756735897023, "mdate": 1759898267139, "content": {"title": "Mobile-GS: Real-time Gaussian Splatting for Mobile Devices", "abstract": "3D Gaussian Splatting (3DGS) has emerged as a powerful representation for high-quality rendering across a wide range of applications.\n    However, its high computational demands and large storage costs pose significant challenges for deployment on mobile devices. \n    In this work, we propose a mobile-tailored real-time Gaussian Splatting method, dubbed Mobile-GS, enabling efficient inference of Gaussian Splatting on edge devices.\n    Specifically, we first identify alpha blending as the primary computational bottleneck, since it relies on the time-consuming Gaussian depth sorting process. \n    To solve this issue, we propose a depth-aware order-independent rendering scheme that eliminates the need for sorting, thereby substantially accelerating rendering.\n    Although this order-independent rendering improves rendering speed, it may introduce transparency artifacts in regions with overlapping geometry due to the scarcity of rendering order. \n    To address this problem, we propose a neural view-dependent enhancement strategy, enabling more accurate modeling of view-dependent effects conditioned on viewing direction, 3D Gaussian geometry, and appearance attributes. \n    In this way, Mobile-GS can achieve both high-quality and real-time rendering.\n        Furthermore, to facilitate deployment on memory-constrained mobile platforms, we propose first-degree spherical harmonics distillation, a neural vector quantization technique, and a contribution-based pruning strategy to reduce the number of Gaussian primitives and compress the 3D Gaussian representation with the assistance of neural networks. \n    Extensive experiments demonstrate that our proposed Mobile-GS achieves real-time rendering and compact model size while preserving high visual quality, making it well-suited for mobile applications.", "tldr": "", "keywords": ["3D Vision"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab34fbec956bdce8d1b6732cbe5839dc9be4046d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper aims to run 3D Gaussian Splatting representations on mobile devices. To this end, the authors first identified that sorting consumes a large portion of the computational cost. Therefore, the paper proposes a sort-free algorithm with lower computational costs compared to other existing sort-free methods. This is combined with view-dependent features to mitigate artifacts. To make the representation even more lightweight, the authors introduce color distillation, vector quantization, and pruning. The experiments cover both desktop GPUs and mobile devices, evaluated with both numerical metrics and user preference studies. With all these components, the results suggest that the proposed method increases FPS and decreases storage and peak memory, all while maintaining representation quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Strong performance. The proposed method shows strong performance over baselines and is well-evaluated on mobile devices. In addition, it provides thorough ablation studies that help the reader understand the role and effect of each component.\n- The paper provides a runtime analysis that identifies how expensive certain operations are, which operations are bottlenecks, and how these can be reduced for mobile devices. It also shows the resulting share of operations after removing sorting.\n- Beyond numerical metrics, the inclusion of a user study strengthens the performance claims from a user's perspective."}, "weaknesses": {"value": "- The sort-free method seems to be a core part of this paper's novelty. However, a critical equation for the weighting term (Eq. 3) is not supported by or provided with an ample description of its underlying idea or theoretical grounding. The paper would also benefit from a direct comparison of the equations from different sort-free methods. Although there are descriptive paragraphs in the supplementary, the relationship between existing methods is not clearly shown at the equation level.\n- Although distillation is an important part of this method, the necessity of a teacher model is not fully justified, nor is the setup adequately explained. It's unclear why this method requires distillation unlike other methods. Since it requires much longer training, it would be helpful if the paper explained why the current comparison (directly comparing \"from scratch\" methods with the proposed method that additionally requires a teacher model) is fair."}, "questions": {"value": "- **Weighting term (Eq. 3)**: Could the authors provide the theoretical motivation or intuition behind the weighting term in Eq. 3? Including comparisons at the equation level would help readers better understand the context and the novelty of this component.\n- **Necessity of distillation**: Is the distillation step truly necessary for achieving strong performance? Since the proposed depth-aware, order-independent rendering pipeline could, in principle, be trained from scratch, it is unclear why the method depends on distillation rather than following the same training approach as the baselines.\n\nIf these points are adequately addressed, I would be willing to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "16wMmJPhT1", "forum": "vRegY0pgvQ", "replyto": "vRegY0pgvQ", "signatures": ["ICLR.cc/2026/Conference/Submission336/Reviewer_JkAA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission336/Reviewer_JkAA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761510254773, "cdate": 1761510254773, "tmdate": 1762915496658, "mdate": 1762915496658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel method called Mobile-GS, which enables the deployment of the Gaussian Splatting (GS) method on mobile devices and achieves real-time rendering performance. The authors analyze the limitations of GS rendering and identify alpha blending as the main bottleneck. To address this issue, they propose a depth-aware, order-independent rendering scheme that eliminates the need for sorting. In addition, they introduce a neural view-dependent enhancement strategy to mitigate rendering artifacts. Post-processing techniques such as distillation and quantization are also employed to achieve efficient rendering on mobile devices."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors provide deep insights into the rendering strategy of 3DGS and effectively analyze its bottlenecks.\n2. The proposed depth-aware order-independent rendering approach is interesting and appears novel.\n3. The use of quantization and pruning methods successfully enables the deployment of 3DGS on mobile devices."}, "weaknesses": {"value": "1. Do the authors analyze the precision or deviation of the depth-aware rendering theoretically? It would be helpful if they could provide a mathematical analysis or proof, along with additional exploratory experiments.\n2. The reviewer would like to know whether neural vector quantization and pruning affect rendering quality. Could the authors provide evaluation results rendered on mobile devices and compare them with other methods?\n3. What is the time cost of the proposed approach? It would strengthen the paper if the authors could provide this metric and compare it with existing methods."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BU6BMgscGx", "forum": "vRegY0pgvQ", "replyto": "vRegY0pgvQ", "signatures": ["ICLR.cc/2026/Conference/Submission336/Reviewer_xVP3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission336/Reviewer_xVP3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706968099, "cdate": 1761706968099, "tmdate": 1762915496306, "mdate": 1762915496306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Mobile-GS introduces the first real-time 3D Gaussian Splatting framework optimized for mobile GPUs by eliminating costly depth-sorting through a depth-aware, order-independent rendering scheme.\nCompared with the prior sorting-free Gaussian representation (SortFreeGS), Mobile-GS models view-dependent opacity and rendering weights in an implicit and lightweight manner, reducing the per-Gaussian parameter footprint. It further integrates spherical-harmonics distillation, neural vector quantization, and contribution-based pruning to enhance compactness and efficiency.\nThe method achieves ~125 FPS on a Snapdragon 8 Gen 3 device with only 4â€“5 MB of storage, while preserving visual fidelity comparable to full 3DGS."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Real-time mobile performance: Demonstrates the first 3D Gaussian Splatting system achieving real-time rendering on mobile GPUs such as Snapdragon 8 Gen 3.\n2. Order-independent efficiency: The proposed depth-aware order-independent rendering removes the costly sorting step, significantly improving runtime without significant quality loss.\n3. Implicit view modeling: Replaces explicit per-Gaussian weights and opacity with a shared lightweight MLP, enabling stable training and reduced parameters compared with SortFreeGS.\n4. Compact design: Through spherical-harmonics distillation, neural vector quantization, and contribution-based pruning, the model compresses storage from hundreds of MB to only ~4â€“5 MB while maintaining comparable visual fidelity to 3DGS."}, "weaknesses": {"value": "1. Extended training time: The use of a pre-trained teacher model for spherical-harmonics distillation doubles the overall training iterations, increasing computational cost.\n\n2. Complex weighting formulation: The depth-aware weighting term (Eq. 3) appears empirically designed and lacks clear theoretical justification or ablation on its components.\n\n3. Missing key baseline: The paper does not include a direct quantitative comparison with SortFreeGS in Table 2, which should serve as the most relevant baseline for this work.\n\n4. Incomplete dataset coverage (minor): Several Mip-NeRF 360 scenes are missing from the evaluation; including them would strengthen the completeness and reliability of the results."}, "questions": {"value": "1. Pruning mechanism:\n This paper evaluates the contribution of each Gaussian primitive using scale and opacity, while prior works often rely on gradient-based importance or learnable pruning masks. Could the authors discuss the advantages and disadvantages of their design compared to these alternatives, particularly in terms of stability, computational efficiency, and adaptivity during training?\n2. Choice of teacher model:\n The framework employs a pre-trained teacher model for spherical-harmonics distillation. Could the authors clarify the motivation behind this choice and whether alternative teacher configurations (e.g., vanilla 3DGS) would impact performance or training cost?\n3. Potential use of the teacher model for initialization:\n Since the framework already depends on a teacher model, could this model also be leveraged to provide better Gaussian initialization or coverage, potentially reducing training time?\n4. Initialization source:\n Are the initial Gaussian primitives derived from COLMAP point clouds or the teacher modelâ€™s reconstructed points?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lAsXiCjLlg", "forum": "vRegY0pgvQ", "replyto": "vRegY0pgvQ", "signatures": ["ICLR.cc/2026/Conference/Submission336/Reviewer_sRjw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission336/Reviewer_sRjw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811633618, "cdate": 1761811633618, "tmdate": 1762915496158, "mdate": 1762915496158, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a mobile-friendly 3D Gaussian Splatting pipeline that removes depth sorting via depth-aware order-independent rendering, then recovers quality with a lightweight, view-dependent enhancement MLP. It further compresses the representation using first-degree SH distillation, neural vector quantization, and contribution-based pruning to cut storage to a few MB while keeping fidelity. Experiments report >100 FPS on Snapdragon 8 Gen 3 and >1k FPS on RTX 3090 with competitive quality versus 3DGS and recent lightweight baselines."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- This paper claims per-tile sorting as the dominant bottleneck and introduces a simple, parallelizable order-independent blending scheme to remove it.\n- A small view-conditioned MLP effectively suppresses transparency/occlusion artifacts that arise from sorting-free compositing.\n- The compression stack (first-degree SH distillation + neural vector quantization + contribution-based pruning) is complementary and yields strong storage reductions with limited quality loss.\n- The evaluation is extensive, includes ablations/runtime breakdowns, and demonstrates impressive reported throughput on Snapdragon 8 Gen 3."}, "weaknesses": {"value": "- The novelty relative to contemporary sorting-free methods (e.g., SortFreeGS, stochastic/OIT-style splatting) is incremental and would benefit from a deeper theoretical or empirical comparison.\n-  Some hyperparameters, such as pruning thresholds/schedules, codebook sizes and SH-order trade-offs need further analysis.\n- The related works on network design and pruning should be added."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b9aOIuGYEC", "forum": "vRegY0pgvQ", "replyto": "vRegY0pgvQ", "signatures": ["ICLR.cc/2026/Conference/Submission336/Reviewer_Jsav"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission336/Reviewer_Jsav"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929306538, "cdate": 1761929306538, "tmdate": 1762915496008, "mdate": 1762915496008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Mobileâ€‘GS, a 3D Gaussian Splatting pipeline designed for realâ€‘time rendering on mobile devices. The key contributions include: \n\n1) Depthâ€‘aware orderâ€‘independent rendering (OIR) that removes nearâ€‘toâ€‘far sorting by blending all Gaussians affecting a pixel with a depth/scaleâ€‘modulated weight; the weight includes an MLPâ€‘predicted, viewâ€‘dependent factor Ï•. A small neural viewâ€‘dependent opacity/weighting module combats transparency artifacts that arise from dropping strict alpha compositing.\n\n2) Compression for mobile: (i) firstâ€‘degree SH distillation from a teacher (Miniâ€‘Splatting) to reduce color parameters, (ii) neural vector quantization using subâ€‘codebooks plus tiny decoders for diffuse/viewâ€‘dependent SH components, and (iii) contributionâ€‘based pruning guided by opacity and maximum scale.\n\n3) Implementation & results: a Vulkan implementation on a Snapdragon 8 Gen 3 device; the method achieves 116â€“127 FPS at mobile resolutions with ~4â€“5â€¯MB perâ€‘scene storage, and >1,100 FPS on an RTX 3090 with similar or better quality than lightweight baselines. The paper identifies sorting as the desktop bottleneck and provides runtime breakdowns showing the MLP overhead is modest."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "++ The paper starts from a concrete performance study showing that nearâ€‘toâ€‘far sorting dominates 3DGS inference time. It then replaces sorting with a depthâ€‘aware, orderâ€‘independent blend: perâ€‘pixel colors are computed by normalizing a weighted sum over all contributing Gaussians, where the weights increase with proximity and scale and are modulated by a small learned, viewâ€‘dependent factor. \n\n++ Orderâ€‘independent blending can cause depthâ€‘ambiguity/â€œseeâ€‘throughâ€ artifacts; the authors respond with a tiny opacity/weighting MLP that conditions on Gaussian geometry, SH appearance and view direction to predict ğœ™ and a viewâ€‘conditioned opacity. The ablation in Tableâ€¯3 shows that removing this module causes a notable quality drop (e.g., PSNR from 28.45 â†’ 28.06 on Mipâ€‘NeRF360) while the runtime overhead is small.\n\n++ Three componentsâ€”firstâ€‘degree SH distillation, neural vector quantization (NVQ) with subâ€‘codebooks and tiny decoders, and contributionâ€‘based pruningâ€”work together to shrink the footprint while keeping quality."}, "weaknesses": {"value": "-- Eq.â€¯(2) uses a global transmittance ğ‘‡, then defines ğ‘‡, which is orderâ€‘dependent and indexâ€‘ambiguous under OIR; this needs a precise approximation/implementation \n\n-- Fig.â€¯3 claims tileâ€‘based rasterization is removed and â€œall Gaussians associated with a pixelâ€ are blended, but the paper doesnâ€™t detail how perâ€‘pixel lists are built/cached on GPU (desktop or mobile).\n\n-- The proposed weight ğ‘¤_i (Eq.â€¯(3), pp.â€¯4â€“5) blends squared, inverseâ€‘squared and exponential terms whose dynamic ranges can differ by orders of magnitude. The paper shows an ablation for turning OIR on/off (Tableâ€¯3), but not a componentâ€‘level analysis, nor a discussion of clipping/normalization. Without this, itâ€™s hard to assess numerical stability, generalization to thin structures, and the sensitivity to scene scale."}, "questions": {"value": "1. Please clarify the exact computation of T in Eq.â€¯(2). If it is not the product in the definition (which requires sorting), what approximation is actually used and how is it implemented? Is it related to weighted blended OIT (e.g., a transmittance proxy from aggregated Î±)? A small derivation or pseudocode would help.\n\n2. What data structure replaces tile binning? Are you using screenâ€‘space bounding ellipses with perâ€‘pixel lists, hierarchical culling, or computeâ€‘shader binning? Please quantify the cost of building these lists, especially on mobile.\n\n3. What ranges are enforced for ğ‘‘_ğ‘– and ğ‘ _max? Are terms clamped or normalized perâ€‘tile/view? Could you share an ablation removing each term? \n\n4. What exact resolution(s) and camera path were used for Tableâ€¯2? How long were runs and what was the steadyâ€‘state FPS after 5â€“10â€¯minutes? Any power draw measurements?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4XMLFPjqDQ", "forum": "vRegY0pgvQ", "replyto": "vRegY0pgvQ", "signatures": ["ICLR.cc/2026/Conference/Submission336/Reviewer_JUSS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission336/Reviewer_JUSS"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762103875249, "cdate": 1762103875249, "tmdate": 1762915495801, "mdate": 1762915495801, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}