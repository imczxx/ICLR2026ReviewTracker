{"id": "uJCGMBO6Qx", "number": 14813, "cdate": 1758244276316, "mdate": 1763689943353, "content": {"title": "When Is Diversity Rewarded in Cooperative Multi-Agent Learning?", "abstract": "The success of teams in robotics, nature, and society often depends on the division of labor among diverse specialists; however, a principled explanation for when such diversity surpasses a homogeneous team is still missing. Focusing on multi-agent task allocation problems, we study this question from the perspective of reward design: what kinds of objectives are best suited for heterogeneous teams? We first consider an instantaneous, non-spatial setting where the global reward is built by two generalized aggregation operators: an inner operator that maps the N agents’ effort allocations on individual tasks to a task score, and an outer operator that merges the M task scores into the global team reward. We prove that the curvature of these operators determines whether heterogeneity can increase reward, and that for broad reward families this collapses to a simple convexity test. Next, we ask what incentivizes heterogeneity to emerge when embodied, time-extended agents must learn an effort allocation policy. To study heterogeneity in such settings, we use multi-agent reinforcement learning (MARL) as our computational paradigm, and introduce Heterogeneity Gain Parameter Search (HetGPS), a gradient-based algorithm that optimizes the parameter space of underspecified MARL environments to find scenarios where heterogeneity is advantageous.  Across different environments, we show that HetGPS rediscovers the reward regimes predicted by our theory to maximize the advantage of heterogeneity, both validating HetGPS and connecting our theoretical insights to reward design in MARL. Together, these results help us understand when behavioral diversity delivers a measurable benefit.", "tldr": "", "keywords": ["multi-agent systems", "heterogeneity", "multi-agent reinforcement learning", "co-design"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fc1b677c6cc5e7f6eb80f5d34689f29a2e5ab9b6.pdf", "supplementary_material": "/attachment/fed14d8546d47c67c753aa68086f2d046f7ff62d.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a principled framework for understanding when and why behavioral diversity among cooperative agents leads to improved collective performance. The authors introduce the notion of heterogeneity gain, defined as the performance difference between heterogeneous and homogeneous teams, and formally analyze it within a general two-level reward aggregation model. Using majorization theory and Schur-convexity analysis, they prove that the curvature of the inner and outer aggregation functions determines whether diversity enhances or hinders performance — specifically, concave-outer and convex-inner structures favor heterogeneity. Building on this theoretical foundation, the paper proposes HetGPS (Heterogeneity Gain Parameter Search), a differentiable environment co-design algorithm that discovers reward parameterizations maximizing or minimizing heterogeneity gain through bilevel optimization. Empirical studies across analytic matrix games and embodied MARL tasks (multi-goal capture, tag, and football) validate the theory, showing that HetGPS consistently rediscovers curvature conditions predicted to reward diverse behaviors. The work provides a unifying explanation for when diversity benefits cooperative learning and establishes a new paradigm linking reward curvature, environment design, and emergent specialization in multi-agent systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a mathematically precise metric $\\Delta R = R_{\\text{het}} - R_{\\text{hom}}$​ to quantify when heterogeneous (specialized) teams outperform homogeneous (identical) teams. It proves that the sign of ΔR depends solely on the Schur-convexity or concavity of the inner and outer reward aggregators: (1) Schur-convex inner operator leads to heterogeneity gain; (2) Schur-concave inner operator leads to no gain; (3) Schur-convex outer operator (under constant-sum normalization) leads to no gain. This gives a simple convexity test for when diversity helps — a clear theoretical advance over heuristic assumptions in prior MARL work.\n2. This paper provides closed-form and bounded results for Softmax, Power-Sum, and {min, mean, max} families, creating a general mathematical map of reward structures that promote or suppress diversity.\n3. A new gradient-based environment co-design algorithm that directly optimizes environment parameters to maximize or minimize $\\Delta R$: (1) It operates via differentiable simulators (back-propagates through environment); (2) It avoids inefficiencies and instability of RL-based environment design (e.g., PAIRED); (3) It can either promote or suppress heterogeneity by switching gradient ascent/descent. The algorithm alternates MARL policy training and environment updates efficiently — roughly 25 % overhead — and robustly rediscovering the theoretical curvature configurations.\n4. Tests across (i) analytical matrix games, (ii) embodied long-horizon MARL tasks (Multi-Goal Capture, 2v2 Tag, Football). All experiments confirm theoretical predictions: **concave-outer + convex-inner** reward structures yield the largest heterogeneity gains. The algorithm autonomously learns the same curvature conditions predicted by theory (inner convex, outer concave) for both Softmax and Power-Sum parameterizations — a strong consistency check.\n5. This paper links convex analysis and majorization theory to concrete MARL reward design, turning diversity from a heuristic into a controllable design variable. Also, it provides a principled answer to an open question in cooperative MARL — under what reward structures does behavioral diversity outperform homogeneity?\n6. The contribution of this paper is applicable beyond RL to any cooperative optimization setting expressible as nested aggregations (e.g., task allocation, team composition, distributed robotics).\n7. Complete code and YAML configurations provided; all mathematical proofs and assumptions detailed in appendices. Figures (e.g., Fig. 2–5) clearly demonstrate the alignment between theoretical curvature analysis and empirical $\\Delta R$ outcomes. Writing is logically structured, connecting intuition, theory, and experiment in a coherent flow."}, "weaknesses": {"value": "1. While elegant, the use of Schur-convexity assumes symmetric and differentiable reward functions. Many practical rewards in MARL are asymmetric, piecewise, or sparse — outside the smooth function classes covered by majorization theory.\n2. Though claimed to be “25% higher,” the method still requires dual policy training (heterogeneous vs homogeneous teams) and outer-loop environment gradient updates. The bilevel optimization may become prohibitively expensive for large-scale, high-dimensional MARL tasks.\n3. Empirical validation is confined to simple matrix games and small-scale MARL benchmarks (Multi-goal Capture, 2v2 Tag, Football mini-games). There are no large-scale or high-dimensional tasks (e.g., SMACv2, MPE with >10 agents, or real robotic control) to demonstrate robustness."}, "questions": {"value": "> Please answer the following questions:\n\n1. The theory presumes identical agents differing only in behavior (i.e., “behavioral heterogeneity”). What if agents differ in capacity, observation space, or action bounds? Would Schur-convexity still capture heterogeneity gain?\n2. The method performs bilevel optimization: inner MARL loop + outer gradient update of environment parameters. Does the paper analyze or guarantee convergence, or could gradient coupling cause oscillations?\n3. HetGPS successfully rediscovers concave-outer/convex-inner curvature. Would it also succeed if reward functions were implemented via neural networks instead of analytic forms?\n\n> The possible suggestions:\n\nA prior work [1] also found that the reward structure (even encoding the same goal) in a real-world problem could impact the performance of MARL algorithms a lot, though it does not consider the multi-task scenarios. This can be used as an example to motivate the research goal of this paper.\n\n[1] Wang, Jianhong, Wangkun Xu, Yunjie Gu, Wenbin Song, and Tim C. Green. \"Multi-agent reinforcement learning for active voltage control on power distribution networks.\" _Advances in neural information processing systems_ 34 (2021): 3271-3284.\n\nThe global reward structure that aggregates reward functions embedding different subtasks/roles is highly relevant to payoff allocations/credit assignment. Especially, in prior work MARL algorithms with Shapley values [2] also demonstrate that agents with heterogenous behaviors is corresponding to different payoffs assigned by Shapley values. This paper aims to automatically search for a design of local rewards which is an reverse process against the prior work, that design local rewards inspired by cooperative game theory leading to heterogeneous behaviors. Thus, this relevant prior work is encouraged to be discussed in related work.\n\n[2] Wang, Jianhong, Yuan Zhang, Tae-Kyun Kim, and Yunjie Gu. \"Shapley Q-value: A local reward approach to solve global reward games.\" In _Proceedings of the AAAI conference on artificial intelligence_, vol. 34, no. 05, pp. 7285-7292. 2020."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "93BV9i4O4n", "forum": "uJCGMBO6Qx", "replyto": "uJCGMBO6Qx", "signatures": ["ICLR.cc/2026/Conference/Submission14813/Reviewer_icAF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14813/Reviewer_icAF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761319250413, "cdate": 1761319250413, "tmdate": 1762925161994, "mdate": 1762925161994, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank the reviewers for their insightful comments and constructive feedback. We are encouraged that the reviewers found our theoretical framework to be a \"rigorous, formal theory\" (M2TT) and a \"clear theoretical advance\" (icAF), providing \"clean\" theorems (j8eg) that move diversity \"from ad-hoc heuristics to a principled design dimension\" (M2TT). We are also glad reviewers found our analysis \"very clear and well explained\" (JKoM) and that our proposed algorithm, HetGPS, is a \"significant algorithmic contribution\" (M2TT) demonstrating a \"strong consistency check\" (icAF) with the theory.\n\nIn response to the (very helpful!) feedback, we have made several updates to the manuscript, which has now been uploaded:\n\n*   **Clarified assumptions:** We expanded **Appendix R** to discuss the scope and applicability of our theoretical assumptions (symmetry, monotonicity), clarifying when they apply and emphasizing that the constant-sum assumption is specific only to Theorem 3.3.\n*   **Expanded experiments (Scalability):** We added new experiments with a larger number of agents (**11 agents** in 8v3 Tag and Matrix Games, Appendix J and L) to further validate the scalability of our theoretical predictions.\n*   **Improved figure clarity:** We added tables summarizing the final heterogeneity gain values for Figure 4 (**Tables 10, 11**) and referenced them in the captions to improve the readability of the plots.\n*   **Expanded Related Work:** We updated **Section 1.1** to include suggested literature on reward design and credit assignment, providing further context for our work.\n*  **Clarified the notation:** We implemented the suggestions regarding making our notations clearer (e.g., minimizing the use of the $\\bigoplus$ notation in favor of $T$ and $U$) in the revised paper.\n\n\nWe address specific comments below and welcome further discussion."}}, "id": "HuJSaVae2p", "forum": "uJCGMBO6Qx", "replyto": "uJCGMBO6Qx", "signatures": ["ICLR.cc/2026/Conference/Submission14813/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14813/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14813/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763688967493, "cdate": 1763688967493, "tmdate": 1763690638277, "mdate": 1763690638277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical and previously unresolved question of when behavioral heterogeneity is inherently beneficial in cooperative multi-agent task allocation problems. The authors provide a principled theoretical answer by demonstrating that the potential advantage of specialized policies is determined by the curvature of the global reward function, which is modeled as a double aggregation of agent efforts. Specifically, positive heterogeneity gain is predicted when the inner, task-level aggregator is Schur-convex and the outer, team-level aggregator is Schur-concave. To validate and extend these insights to complex, time-extended environments, the paper introduces HetGPS (Heterogeneity Gain Parameter Search), a gradient-based bilevel optimization algorithm. HetGPS efficiently searches the parameter space of rewards and successfully rediscovers the theoretically optimal reward regimes in various MARL settings, thereby connecting the abstract theoretical predictions directly to reward design in practical environments5. The results ultimately offer clear criteria for diagnosing and designing missions where agent diversity is essential for maximizing team performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is well-written and easy to follow. The author provide sufficient supplementary material, making the conclusions of this paper clearer and more convincing.\n2. This paper provides a rigorous, formal theory for predicting when behavioral heterogeneity is advantageous in multi-agent task allocation problems. This theoretical framework, based on the curvature of reward aggregation operators (Schur-convexity/concavity), moves the selection of diversity from ad-hoc heuristics to a principled design dimension.\n3. The introduction of Heterogeneity Gain Parameter Search (HetGPS) is a significant algorithmic contribution. This gradient-based bilevel optimization method efficiently searches the reward parameter space to find configurations that maximize or minimize the empirical heterogeneity gain.\n4. The extensive experiments, ranging from abstract matrix games to complex embodied MARL scenarios (Multi-goal-capture, Tag, Football), successfully demonstrate that the theoretical predictions derived from reward curvature reliably transfer to long-horizon settings. HetGPS further validates the theory by automatically discovering the predicted optimal reward regimes."}, "weaknesses": {"value": "1. The core theoretical criterion for heterogeneity gain is based solely on the curvature of the reward function (Schur-convexity/concavity). This analysis is inherently restricted to the reward structure and does not formally integrate the complexity of environment dynamics.\n2. The high efficiency and tractability of the HetGPS algorithm fundamentally rely on the assumption of an end-to-end differentiable simulator. This is required to compute the exact environment gradients via backpropagation."}, "questions": {"value": "1. The two issues mentioned in the Weaknesses section.\n2. The curves in Figure 4 overlap significantly, making them difficult to distinguish clearly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "n3HF8UxQAd", "forum": "uJCGMBO6Qx", "replyto": "uJCGMBO6Qx", "signatures": ["ICLR.cc/2026/Conference/Submission14813/Reviewer_M2TT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14813/Reviewer_M2TT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860990338, "cdate": 1761860990338, "tmdate": 1762925161133, "mdate": 1762925161133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a theoretical analysis of the heterogeneous vs homogeneous credit assignment in MARL, which provides insights for the reward shaping problem in different MAS tasks. It presents HetGPS to optimize the parameter space of an underspecified MARL environment. The experiments showcase that it can discover new reward regimes to maximize the advantage of heterogeneity."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "It is novel to formulate diverse reward allocation choices to a mathematical curvature question via Schur-convex/concave tools. The theorems/constructive counter-examples are clean with explicit assumptions. The algorithm description and experiment analysis are clearly presented. This work has significance in influencing environment/reward design and architecture choices in MARL."}, "weaknesses": {"value": "1. Results hinge on symmetry/coordinate-wise monotonicity and near constant-sum task scores. It would be good to tabulate common benchmarks that violate these assumptions and provide bounds or heuristics for the reward difference when constant-sum fails.\n2. Longer-horizon Dec-POMDP dynamics may interact with curvature in nontrivial ways; more systematic ablations or counterexamples would strengthen the claim\n3. Figures all consist of 9 cases, making it difficult to distinguish the lines"}, "questions": {"value": "1. What are the conservative bounds $\\Delta R$ when constant-sum is violated?\n2. Will there be any cases where curvature is only a part of the total reward yet remains predictive?\n3. In non-differentiable simulators, how do sample complexity and final performance compare when using score-function/ES estimators?\n4. For non-symmetric or non-monotone aggregators (e.g., capacity/bottleneck constraints), will the results admit first-order approximations or sharp counter-examples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pEnzIGOBMH", "forum": "uJCGMBO6Qx", "replyto": "uJCGMBO6Qx", "signatures": ["ICLR.cc/2026/Conference/Submission14813/Reviewer_j8eg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14813/Reviewer_j8eg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980605324, "cdate": 1761980605324, "tmdate": 1762925160801, "mdate": 1762925160801, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates aggregation functions in a multi-task/multi-objective multi-agent RL setting, particularly answering the question of for which aggregations heterogeneous behavior is advantageous over homogeneous behavior.\nA theoretical analysis shows that this is connected to the schur-convexity of the aggregation functions.\nExperiments confirm the theoretical analysis.\nFurther, a method to optimize environment parameters such that they favor heterogenity is proposed and validated."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The problem setting is interesting and relevant. The question of whether or not to share parameters in Multi-Agent RL is relevant and the analysis of aggregation functions in this paper provides a useful step towards answering it.\n * The theoretical analysis and its presentation are very clear and well explained\n * The experiments nicely confirm the theoretical predictions."}, "weaknesses": {"value": "Minor points:\n * The assumption of normalized inner aggregators could be justified better. It's not entirely clear to me whether this is justified in practice"}, "questions": {"value": "*  See question about assumption in weaknesses\n * In HetGPS, it is not entirely clear to me why an approach that alternates between policy and environment improvement was chosen. Intuitively, it could be posed as an entirely bi-level process, in which the policies are trained from scratch for each environment configuration\n\n\nNitpicks:\n * L71 It may be better to introduce the symbols T and U for agent-wise and team-wise aggregation here already, on a first read the two addition symbols are a bit unclear.\n * L172 Similar issue, the abuse of notation is initially confusing and (in my opinion) unnecessary\n * L177 Introducing the allocations under the close simplex, i.e. allowing for sum < 1, and then excluding this case in L207 seems unnecessary\n * L351 \"continues to be and informative\"\n\nOverall I really enjoyed reading this paper, great work!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rNtkhc12nm", "forum": "uJCGMBO6Qx", "replyto": "uJCGMBO6Qx", "signatures": ["ICLR.cc/2026/Conference/Submission14813/Reviewer_JKoM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14813/Reviewer_JKoM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762067490664, "cdate": 1762067490664, "tmdate": 1762925160471, "mdate": 1762925160471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}