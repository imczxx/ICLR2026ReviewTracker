{"id": "XcnD27hE15", "number": 20830, "cdate": 1758310657517, "mdate": 1759896956395, "content": {"title": "Evaluation of the accuracy of pattern recognition by a neural network with various filters in the receptor layer of the retinal simulation module", "abstract": "The purpose of this work is to evaluate the effect of the location of receptors in the first layer of the retinal simulation module on the ability of a neural network to recognize images. The retinal simulation module serves as a means for preprocessing images. The retinal simulation module is described and compared with existing popular preprocessing methods. The module processes the image using three layers. The object of this study is the first layer of the module, which simulates the receptor layer of the real retina of the human eye. The experiments were conducted on a fully connected neural network. The retinal simulation module preprocessed a sample of fruit images photographed from different angles, which was then fed to the input of the neural network. In the process, ninety-four experiments were performed with different module settings. In each of the experiments, the settings of the fully connected neural network remained unchanged. The results of image recognition by a neural network are presented. Recommendations are given for configuring the receptor layer of the retinal simulation module to improve the accuracy of pattern recognition.", "tldr": "", "keywords": ["Pattern recognition", "classification", "neural networks", "retina", "fully connected neural networks", "supervised learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ee2a2a44ad3ac60f92cba45755c3490c8f7f8646.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper explores the impact of receptor-layer filter arrangements in a bio-inspired retinal simulation module on neural network recognition accuracy. The authors construct a three-layer retinal simulator and test 94 filter configurations on a fruit image recognition task. The key finding is that diagonal red-blue alternating filter patterns boost fully-connected neural network (FCNN) accuracy to 92%, significantly outperforming traditional preprocessing methods. The authors attribute this phenomenon to the spatial distribution of retinal ON cells, proposing a biologically-inspired approach to image preprocessing."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tTesting 94 filter configurations far exceeds prior work in bio-inspired vision preprocessing, providing the first systematic analysis of spatial topology effects. \n2.\tON/OFF cell modeling is well-founded in retinal neuroscience, and the link between diagonal patterns and ON-cell responses offers a plausible mechanism.. \n3.\tThe \"red-blue diagonal alternation\" principle  directly informs sensor design, with a +14% accuracy gain over baselines.."}, "weaknesses": {"value": "1.\tConclusions rely solely on FCNN – an obsolete architecture for vision tasks.  The critical absence of CNN/Transformer validation (e.g., ResNet, ViT) leaves open whether results generalize to modern models.\n2.\tDespite citing hexagonal lattices in biological retinas, all filters use rectangular grids.  This mismatch undermines the claimed bio-inspiration.\n3.\tThe ON-cell distribution hypothesis lacks computational/biological support.  The conclusion section fails to restate this hypothesis, weakening theoretical contributions.\n4.\tResults on fruit images may overfit diagonal textures.  Tests on standard datasets (CIFAR/ImageNet) and comparisons with neuromorphic models (e.g., Spiking CNNs) are missing."}, "questions": {"value": "1.\tWhy use FCNN instead of CNNs?  Can the conclusions hold for mainstream vision architectures?\n2.\tHow does the rectangular grid assumption align with biological hexagonal lattices?  Will hexagonal filters alter the diagonal pattern effect?\n3.\tHave you tested generalization beyond fruit images (e.g., on CIFAR-10/100 or ImageNet subsets)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5ZZsLRFAES", "forum": "XcnD27hE15", "replyto": "XcnD27hE15", "signatures": ["ICLR.cc/2026/Conference/Submission20830/Reviewer_rMAN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20830/Reviewer_rMAN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815466510, "cdate": 1761815466510, "tmdate": 1762936325251, "mdate": 1762936325251, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel set of preprocessing filters specifically tailored for image classification. These filters are inspired by the structure of the human retina and are used to simulate the distribution of photoreceptor cells. By applying these biologically motivated filters before feeding images into a neural network, the model can achieve improved feature extraction and higher recognition accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper provides new insights inspired by the visual processing mechanisms of the human eye, offering biologically motivated ideas for improving artificial vision systems."}, "weaknesses": {"value": "The experiments presented in the paper are not sufficient to fully support the main proposal. In particular, the evaluation lacks comparative analysis with other existing models and architectures. To strengthen the validity of the findings, the authors should include experiments that compare their method against a wider range of baseline models and state-of-the-art approaches in image preprocessing and classification."}, "questions": {"value": "Why did the authors use only a fruit image dataset for the experiments? This limited choice makes it difficult to evaluate the generality of the proposed method. Testing on additional and more diverse datasets would strengthen the validity of the results.\n\nCould the authors clarify whether the retinal simulation module operates as a fixed preprocessing layer or if it is trainable (end-to-end with the network)?\n\nHow robust are the results to network architecture changes—e.g., CNNs or ResNets?\n\nHow does the module perform on standard benchmarks (e.g., CIFAR-10, ImageNet subsets)?\n\nAre the “color alternation” effects observed consistent across multiple datasets and lighting conditions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "Why did the authors use only a fruit image dataset for the experiments? This limited choice makes it difficult to evaluate the generality of the proposed method."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U8q8R58L32", "forum": "XcnD27hE15", "replyto": "XcnD27hE15", "signatures": ["ICLR.cc/2026/Conference/Submission20830/Reviewer_vQiy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20830/Reviewer_vQiy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982535871, "cdate": 1761982535871, "tmdate": 1762936324633, "mdate": 1762936324633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript presents a three-layer retinal simulation module consisting of photoreceptors, bipolar cells, and ganglion cells, which is used solely as an image pre-processor. It investigates how different photoreceptor mosaics - drawing inspiration from Bayer, RGBW, X-Trans, and custom-designed patterns—impact classification accuracy on a 39-class fruit dataset with images sized at 100×100 pixels. A total of ninety-four module configurations are evaluated, keeping a fully connected classifier constant. The results, averaged over ten training sessions, indicate that the proposed module outperforms several classical pre-processing baselines. Additionally, qualitative observations reveal certain “rules” regarding colour alternation along the diagonals."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. A clear and modular description of a biologically motivated pre-processor.\n2. A systematic examination of various photoreceptor mosaics (total of 94 settings) with the classifier held constant, isolating the effect of pre-processing."}, "weaknesses": {"value": "1. The idea is intriguing, and the empirical pattern regarding colour alternation shows promise. However, the current evaluation lacks robust baselines, generalisation tests, and thorough statistical analysis. Addressing these points would significantly strengthen the paper.\n2. The abstract states the objective but would benefit from a concise research question. Moreover, the manuscript fails to discuss the prior work in relation to the current work in the discussion section. No limitation is mentioned either."}, "questions": {"value": "1. The current classifier is a fully connected network that operates on raw pixel data. No convolutional baseline has been reported. This raises concerns about its practical utility, as modern vision systems typically utilise CNNs or ViTs, which are adept at learning colour and centre-surround structures. I recommend adding at least one small CNN (for example, a 3–5 layer convolutional network) and a lightweight ResNet-18 baseline, both with and without your proposed module. Please maintain the same training protocol as your current setup (SGD with Nesterov momentum, for 10 epochs, and repeated over 10 runs) to ensure fairness in comparison.\n2. The details regarding the \"fruit\" dataset, including its source, licensing, and class list, are currently missing.\n3. Please provide per-class accuracy, confusion matrices, calibration, and robustness against common corruptions. Additionally, show learning curves to determine whether the module accelerates convergence or merely shifts final accuracy.\n4. This manuscript lacks an ablation experiment, which should include the following scenarios: (a) removing the ganglion stage; (b) using only the ON pathways or only the OFF pathways; (c) varying the receptive field radii; and (d) swapping the colour-channel assignments between L/M/S and RGB. Please report the contribution of each stage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pTCSWrUUeW", "forum": "XcnD27hE15", "replyto": "XcnD27hE15", "signatures": ["ICLR.cc/2026/Conference/Submission20830/Reviewer_oKn4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20830/Reviewer_oKn4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762018119829, "cdate": 1762018119829, "tmdate": 1762936322687, "mdate": 1762936322687, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates how different retinal receptor layouts, inspired by biological vision systems, affect image classification accuracy. The authors design a retinal simulation module that mimics the photoreceptor, bipolar, and ganglion layers of the human eye, using fixed filters to model center-surround receptive fields. Several receptor configurations are tested as preprocessing steps before a simple fully connected neural network trained on a 39-class fruit dataset. Results show that certain color arrangements, particularly alternating red and blue patterns, improve classification accuracy compared to standard preprocessing methods (grayscale, LoG, DoG). The article concludes with design guidelines for effective receptor layouts and suggests that biologically inspired mosaics can modestly enhance recognition performance."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper’s strength lies in its original, biologically inspired framing, which models retinal receptor mosaics as a preprocessing mechanism for image classification. It is methodically thorough, testing 94 receptor layouts under consistent training conditions, and presents precise, reproducible results. The idea offers a cross-disciplinary perspective linking computational vision and neurobiology, and the paper’s structure and visualizations make the findings reasonably clear."}, "weaknesses": {"value": "The paper’s main weaknesses lie in its limited methodological rigor and narrow experimental scope. Relying on a single small dataset (fruit images, 100×100 pixels) and a simple fully connected network prevents meaningful generalization. There is no evaluation on standard benchmarks such as CIFAR or ImageNet, nor with modern architectures like ResNet, ConvNeXt, or Vision Transformers, so the reported improvements lack credibility and broader validation. The retinal simulation module also contains white or blank patches in the receptor layout, elements that do not exist in real Bayer filters or biological retinas—making the model optically and biologically implausible. These “white cells” distort spatial sampling density and frequency response, undermining fair comparison with true color filter arrays. Figure 6 should more clearly illustrate the proposed architecture. Its current presentation is sloppy and confusing, lacking structure and visual clarity. The authors are encouraged to redraw it using standard diagramming tools to produce a cleaner, more professional visualization of the model. The paper further suffers from weak theoretical grounding and the absence of statistical analysis; no uncertainty estimates, variance measures, or significance tests are provided. The discussion remains purely descriptive, offering unvalidated hypotheses without analytical support. To improve, the authors should strengthen the biological and optical modeling, expand experimental validation to diverse datasets and modern networks, and provide rigorous statistical and theoretical analysis."}, "questions": {"value": "1.\tHave you evaluated the proposed retinal simulation module on other datasets or architectures, such as ResNet, ConvNeXt, or Vision Transformers? Results on a single small fruit dataset limit the generalizability of your conclusions.\n\n\t2.\tThe receptor layout includes white or blank cells, which are not present in real Bayer filters or biological retinas. What is the rationale behind this design choice, and how does it affect the model’s optical and biological validity?\n\n\t3.\tThe reported accuracy differences are not supported by statistical analysis. Could you include standard deviations, confidence intervals, or significance tests across the ten runs to show that these differences are meaningful?\n\n\t4.\tFigure 6 does not clearly illustrate the proposed architecture. Can you provide a higher-quality, properly labeled diagram showing the module structure, layer arrangement, and data flow?\n\n\t5.\tCould you better relate your work to previous computational and biologically inspired vision models, such as color filter array optimization or neuromorphic vision front ends? This would clarify the novelty of your approach.\n\n\t6.\tThe observed performance trends (for example, alternating red and blue patterns) are only described heuristically. Can you provide an analytical or theoretical explanation for why these arrangements improve accuracy?\n\n\t7.\tYou mention that the algorithm for the bipolar layer has a time complexity of O(n⁴). Could you quantify its computational cost relative to standard convolutional preprocessing or CNN feature extraction?\n\n\t8.\tWill you make your code and receptor configurations publicly available? Providing access to your implementation would help others replicate and verify your results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "clibuuwRu9", "forum": "XcnD27hE15", "replyto": "XcnD27hE15", "signatures": ["ICLR.cc/2026/Conference/Submission20830/Reviewer_n3ZM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20830/Reviewer_n3ZM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762025957176, "cdate": 1762025957176, "tmdate": 1762936310730, "mdate": 1762936310730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}