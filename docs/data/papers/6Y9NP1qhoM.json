{"id": "6Y9NP1qhoM", "number": 2607, "cdate": 1757162996834, "mdate": 1759898137854, "content": {"title": "Goal-Aware Identification and Rectification of Misinformation in Multi-Agent Systems", "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have demonstrated strong advantages in addressing complex real-world tasks. However, due to the introduction of additional attack surfaces, MASs are particularly vulnerable to misinformation injection. To facilitate a deeper understanding of misinformation propagation dynamics within these systems, we introduce **MisinfoTask**, a novel dataset featuring complex, realistic tasks designed to evaluate MAS robustness against such threats. Building upon this, we propose **ARGUS**, a two-stage, training-free defense framework leveraging goal-aware reasoning for precise misinformation rectification within information flows. Our experiments demonstrate that in challenging misinformation scenarios, ARGUS exhibits significant efficacy across various injection attacks, achieving an average reduction in misinformation toxicity of approximately 28.17% and improving task success rates under attack by approximately 10.33%.", "tldr": "We introduce MisinfoTask, a dataset to assess the impact of misinformation injection on Multi-Agent Systems, and ARGUS, a universal and adaptive framework designed to defend against this threat.", "keywords": ["LLM-based Agent", "Multi-agent System", "Misinformation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/07c238abc364d46971620003fb9eee59e7db0d27.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper makes two primary contributions. First, they introduce MISINFOTASK, a new benchmark dataset comprising 108 tasks designed specifically to evaluate MAS robustness against covert misinformation. The dataset includes plausible but fallacious arguments for each task, along with ground truth information. Second, they propose ARGUS, a training-free, two-stage defense framework."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.  This paper evaluates the robustness of MAS against misinformation using  Tool Injection, Prompt Injection and RAG Injection.\n\n2.  This paper builds a corrective agent to guard the misinformation in MAS."}, "weaknesses": {"value": "1. The initial localization phase relies exclusively on Edge Betweenness Centrality, a purely topological metric, to identify critical channels. This strategy assumes that misinformation will travel along the most central paths. However, a sophisticated adversary could easily evade this initial detection by injecting misinformation through less central, seemingly unimportant edges, allowing it to propagate for at least one full round before content-aware mechanisms are activated.\n\n2. The effectiveness of the adaptive re-localization hinges entirely on the corrective agent's ability to accurately infer the misinformation's intent-driven goal $g_{mis}$. If this inference is flawed or inaccurate, the subsequent calculation of information relevance $Score_{rel}$ will be based on an incorrect premise.\n\n3. The entire defense rests on the strong assumption that the corrective agent's internal, parameterized knowledge is factually superior to the incoming information.\n\n4. The comprehensive score for channel importance is calculated using fixed weights (α=0.2, β=0.2, γ=0.6). These static values may not be optimal across different MAS topologies, task types, or evolving adversarial strategies.\n\n5. The paper states that the dataset underwent a rigorous manual review process after AI generation. However, the methodology lacks transparency. Crucial details are omitted, such as the qualifications of the human experts, the number of reviewers per entry, the specific guidelines for filtering content, and any inter-annotator agreement metrics. This makes it difficult to independently assess the quality, consistency, and objectivity of the final dataset.\n\n6. The dataset's size of 108 entries is relatively small for a benchmark intended to test broad generalization. Furthermore, since the initial data was generated by a single LLM (GPT-4o), there is a risk that the misinformation is inadvertently tailored to the specific failure modes of that model family.\n\n7. The dataset generation prompt explicitly targets misinformation that contradicts well-established facts likely learned during pre-training. This approach overlooks the challenge of dynamic misinformation related to recent events, evolving topics, or time-sensitive data that falls outside an LLM's static knowledge base. This limits the dataset's applicability to real-world scenarios where misinformation is often timely and ephemeral."}, "questions": {"value": "1. The number of monitored channels was set to k=M-1, meaning nearly every channel was monitored. This implies significant computational and financial costs. Have you considered or experimented with more efficient implementations, such as a sampling strategy for monitoring or a lightweight initial check to triage messages before triggering the full, resource-intensive CoT analysis?\n\n2. The corrective agent's rectification strategy relies on a CoT prompting method guided by heuristic principles like \"root cause analysis\" and \"cognitive reframing\". Could you discuss the generalizability of this prompting strategy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gSZKNT9HdJ", "forum": "6Y9NP1qhoM", "replyto": "6Y9NP1qhoM", "signatures": ["ICLR.cc/2026/Conference/Submission2607/Reviewer_9fCa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2607/Reviewer_9fCa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2607/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760609646415, "cdate": 1760609646415, "tmdate": 1762916301985, "mdate": 1762916301985, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduced MISINFOTASK, a novel dataset  featuring complex, realistic tasks designed to evaluate MAS robustness against such threats. In addtion, they proposed ARGUS, a two-stage, training-free defense framework leveraging goal-aware reasoning for precise misinformation rectification within information flows. Experiment results show that ARGUS exhibits significant efficacy across various injection attacks for misinformation alleviation and task success rate improvement."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a novel and practical dataset that enables rigorous evaluation of misinformation robustness in multi-agent systems.\n2. The proposed ARGUS framework effectively mitigates misinformation without additional training and improves task completion.\n3. The work addresses an important and timely problem of misinformation security that has been largely overlooked in prior MAS research.\n4. The paper is clearly written, well organized, and supported by comprehensive experimental validation."}, "weaknesses": {"value": "1. It is recommended that the authors revise the structure of Table 1 so that the model names appear in the first column and the defense types in the second column, making the table layout clearer and improving comparability across models.\n\n2. The paper would benefit from a clearer specification of the threat model, detailing attacker goals, capabilities, and assumptions, which would help strengthen the discussion on the security significance of misinformation propagation in MAS.\n\n3. In MAS, various intelligent agents have different motivations, or mindsets. They have competitive, compromising, and accommodating personalities to achieve their goals. Therefore, how does this information and misinformation spread? In addition, how can the spread of illusions and misinformation be distinguished?\n\n4. The contribution and self-containment of the paper could be improved if the authors provided a more detailed description of the structure and content of MISINFOTASK. In particular, including concrete examples or a summary of task types and misinformation patterns would help readers better understand the dataset’s design and relevance.\n\n5. In the experimental analysis section, it is recommended that the authors add a discussion on the MAS topology\n\n6. How does ARGUS resist the attack of Misinformation in existing MAS? \n\n7. it is recommended that the author reflect the results and discussion of the Appendix in the main text."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rcYMRB8pKT", "forum": "6Y9NP1qhoM", "replyto": "6Y9NP1qhoM", "signatures": ["ICLR.cc/2026/Conference/Submission2607/Reviewer_A4Ps"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2607/Reviewer_A4Ps"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2607/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761109527204, "cdate": 1761109527204, "tmdate": 1762916301779, "mdate": 1762916301779, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how LLM-based MAS are vulnerable to hidden misinformation attacks. It introduces MISINFOTASK, a dataset with 108 complex tasks used to test the robustness of MAS. It also presents ARGUS, a defense framework that does not need extra training.\n\nIn the first stage, called Adaptive Localization, ARGUS finds the key communication channels. In the second stage, called Goal-aware Persuasive Rectification, it places a corrective agent on these channels. The agent uses chain-of-thought reasoning to break down messages, detect suspicious claims, compare them with its own knowledge, and create persuasive corrections.\n\nTests show that ARGUS lowers misinformation toxicity by 28.17% on average and raises the TSR by 10.33% compared to systems without defense."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-  The design is original. The synthesis of static topological analysis with dynamic, semantic re-localization based on an inferred misinformation goal is a clever and novel approach. Furthermore, the concept of a \"persuasive\" corrective agent using CoT reasoning is more advanced than simple fact-checking or edge-pruning defenses. \n\n- The MISINFOTASK dataset is a useful contribution. \n\n- Experiments are thorough. This paper tests across multiple LLM families, multiple modern attack vectors and defense baselines. The analysis is detailed. \n\n- The paper is written with clarity. \n\n- Code is attached. Seems well\n\n- This work addresses a challenge to the adoption of MAS."}, "weaknesses": {"value": "- The paper acknowledges the limit of computational overhead & cost but does not quantify the overhead.\n\n- The initial localization step relies on Edge Betweenness Centrality, which is computationally expensive ($O(V \\cdot E)$) and does not scale well to large graphs. This would be a bottleneck for MAS with tens or hundreds of agents.\n\n- The paper's definition of misinformation is \"content that contradicts the factual knowledge implicitly stored in the parameters of an LLM.\" Thus \"Internal Knowledge Resonance\" relies on this. This makes ARGUS vulnerable to misinformation about dynamic, time-sensitive information pre-training data. \n\n- The choice of $k=M-1$ seems to be a brute-force approach to ensure all critical channels are covered, but it maximizes the cost. How performance degrades with a more sparse and realistic $k$."}, "questions": {"value": "1. See weakness\n\n2. How sensitive is the adaptive re-localization mechanism to the weights $\\alpha=0.2, \\beta=0.2, \\gamma=0.6$? Was a sensitivity analysis or sweep performed to arrive at these values?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cTuS0lGRC5", "forum": "6Y9NP1qhoM", "replyto": "6Y9NP1qhoM", "signatures": ["ICLR.cc/2026/Conference/Submission2607/Reviewer_Er5U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2607/Reviewer_Er5U"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2607/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761581797034, "cdate": 1761581797034, "tmdate": 1762916301421, "mdate": 1762916301421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how misinformation affects Multi-Agent Systems. Specifically, the paper introduces MISINFOTASK which evaluates how MAS defends against misinformation injection. It also proposes ARGUS, a training free defense that (i) locates the most critical communication channels where misinformation is likely flowing, then (ii) performs “goal-aware” persuasive rectification using CoT-style reasoning to counter and correct it."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is studying a meaningful question that how misinformation propagate within MAS after information injection attacks.\n2. The paper builds a complete benchmark including the dataset, setup and evaluation, and also propose a method to tackle such problem."}, "weaknesses": {"value": "1. The paper first uses LLM to generate tasks, and then manually filter out tasks. However, it is unclear whether these tasks align with real-world tasks and whether they are diverse enough to be used, since the same prompt is being used to generate tasks over and over.\n2. The dataset only contains 108 tasks, which is small, especially the main content is crafted by LLM.\n3. The evaluation employs an LLM judge. Although LLM judge could be useful, the paper doesn't have any sanity check of it, for example, compare it with manual scores.\n4. While the paper states that one limit of ARGUS is efficiency and cost, there is no such measurement of its cost compared to other methods. This call into question whether such method is practical, that it could be trading massive resource for performance boost."}, "questions": {"value": "The questions below correspond to each point of the weakness.\n\n1. Can you explain how you ensure diversity and real-world utility of these tasks?\n2. (Please see weakness)\n3. Do you have any analysis of the LLM judge (human agreement)? \n4. Can you provide how much additional cost of the proposed method compared to other methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ucqloRpoJZ", "forum": "6Y9NP1qhoM", "replyto": "6Y9NP1qhoM", "signatures": ["ICLR.cc/2026/Conference/Submission2607/Reviewer_TzYe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2607/Reviewer_TzYe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2607/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944218171, "cdate": 1761944218171, "tmdate": 1762916301160, "mdate": 1762916301160, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}