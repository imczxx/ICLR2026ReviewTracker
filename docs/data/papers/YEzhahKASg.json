{"id": "YEzhahKASg", "number": 20617, "cdate": 1758308247723, "mdate": 1759896967798, "content": {"title": "SpheriQ: Probabilistic Hyperbolic Reasoning for Interpretable Recommendation", "abstract": "Recommendation models are increasingly used in settings where ambiguity and transparency matter, yet many approaches are deterministic or poorly calibrated. We present SpheriQ, a geometric framework that embeds users, items, and tags as probabilistic regions in hyperbolic space. The center encodes the semantic position while the radii capture the predictive uncertainty; a Gaussian semantic kernel on the manifold enables a calibrated, transitive composition along the user--tag--item paths. This bridges symbolic and distance-based paradigms, providing concept-level traces and confidence estimates with the efficiency of lightweight embeddings. We instantiate SpheriQ with automatic tag construction and Riemannian optimisation, and evaluate it on news, books, and commonsense reasoning benchmarks. Across datasets, our model pairs strong ranking performance with improved calibration and semantic diversity, while remaining training efficient. These results indicate that probabilistic geometry combined with concept-level reasoning is a practical route to trustworthy recommendation.", "tldr": "SpheriQ models users, items, and tags as probabilistic spheres in hyperbolic space, enabling calibrated, interpretable, and semantically diverse recommendations", "keywords": ["Probabilistic recommendation", "Hyperbolic embeddings", "Uncertainty calibration", "Explainable recommendation", "Semantic reasoning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/19a80f379937c4e1e3d76ae6ea9bab9643e00333.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes SPHERIQ, a probabilistic hyperbolic embedding framework for recommendation. Users, items, and tags are represented as probabilistic spheres in the Poincaré ball, where centers capture semantic positions and radii encode predictive uncertainty. A semantic Gaussian kernel enables transitive reasoning through user–tag–item paths, providing calibrated similarity scores and concept-aligned rationales. Evaluations on four datasets demonstrate improvements in ranking accuracy, calibration, and semantic diversity, while explanations remain faithful due to their intrinsic role in scoring."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed probabilistic sphere representation is elegant and principled. It generalizes traditional hyperbolic embeddings by adding uncertainty modeling, enabling both semantic expressiveness and confidence estimation.\n2. The user → tag → item transitive reasoning provides explicit explanation chains, which are inherently interpretable rather than post-hoc. This is a meaningful step toward explainable recommendation.\n3. The experimental section is thorough, covering multiple paradigms (collaborative, graph, causal, geometric, tag-based). The authors report not only accuracy metrics (NDCG, Recall) but also calibration (ECE, Brier), diversity, and interpretability metrics."}, "weaknesses": {"value": "1. The approach assumes meaningful and stable concept/tag structures. In many real-world systems, tags are sparse, noisy, or unavailable, limiting generalization and scalability.\n2. The radius is treated as an isotropic uncertainty term, but the paper does not empirically show whether σ correlates with user preference variability or data sparsity. Without such evidence, the calibration claim feels a bit qualitative.\n3. The fuzzy composition function (Eq. 7) is predefined (prod or min), making the reasoning deterministic. While the formulation is elegant, it may still behave more like probabilistic metric learning rather than an explicit reasoning paradigm."}, "questions": {"value": "1. How robust is SPHERIQ when tag information is incomplete or inconsistent? Would the model’s uncertainty (σ) increase under tag noise, acting as a form of self-calibration?\n2. Have the authors considered learning the composition function **f** in Eq. 7 instead of fixing it to product or min? This could make the reasoning mechanism more adaptive to domain semantics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P0kHiJJKqD", "forum": "YEzhahKASg", "replyto": "YEzhahKASg", "signatures": ["ICLR.cc/2026/Conference/Submission20617/Reviewer_UNNp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20617/Reviewer_UNNp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20617/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725672128, "cdate": 1761725672128, "tmdate": 1762934020008, "mdate": 1762934020008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\n\nThis paper proposed a method named SpheriQ, which is a geometric framework that embeds users, items, and tags as probabilistic regions in hyperbolic space. SpheriQ focuses on tackling recommendation task with the aim to improve calibration and semantic diversity. All in all, SpheriQ aims to unify ranking, calibration, and explanation by casting recommendation as probabilistic concept level reasoning in hyperbolic space."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n\n-\tThe approach is interesting by exploring probabilistic hyperbolic reasoning in recommender system domain. It’s good that the authors consider unifying ranking accuracy, calibration and explanation, which are important factors in recommendation.\n-\tThe authors provided various experiments on publicly available benchmark datasets against some well-known baselines. \n-\tMany appendices were given such as Appendix F for reproducibility"}, "weaknesses": {"value": "Weaknesses:\n\n-\tAlthough the idea of exploring hyperbolic space is interesting, the ‘original’ motivation of this paper is marginal and a bit not very clear to me. Are we exploring hyperbolic geometry simply because “hyperbolic geometry is effective for modelling hierarchical structure” (Line 037) and we want to apply to tags? Throughout the paper, I personally do not see a solid motivation. Perhaps the authors should better build up the story to convince the readers.\n-\tIn my opinion, Section 2.4 and Appendix D are important. The authors should expand more in these sections, and link to Figure 1. We have a little bit of disconnection here.\n-\tAll the datasets have small size. We should also report other statistics such as the number of interactions. Moreover, baselines are old and we should consider recent works as baselines, especially works that tackle recommendation tasks in hyperbolic space.\n-\tI believe one of the main impact of this paper is about the ability of ‘explanation’ via ‘tags’ in ‘hyperbolic space’. However, it’s also not very clear to me the impact of explanation even through the authors showed Table 7 and 8 with case studies. I believe it’d be better if we could show visualizations of our embeddings for a particular user ID, together with tag explanation and confidence. The embeddings in hyperbolic space would help us to understand more about behaviours of user, tag, item in that space (assuming it’s better than Euclidean). Showing visualizations perhaps could also give a better view on Figure 1? I understand we have Appendix G.7 but it’s not enough in my opinion.\n-\tHow do we compare the complexity of our proposed method with other baselines? Table 16 shows that SpheriQ achieves the fastest convergence. Is it a big contribution? Can we compare run time with other hyperbolic based recommendation models?"}, "questions": {"value": "Please refer to my comments in the Weaknesses section above. Overall, I believe more works need to be done."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xL9oaFFqLd", "forum": "YEzhahKASg", "replyto": "YEzhahKASg", "signatures": ["ICLR.cc/2026/Conference/Submission20617/Reviewer_AwE6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20617/Reviewer_AwE6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20617/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926206193, "cdate": 1761926206193, "tmdate": 1762934019456, "mdate": 1762934019456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SpheriQ presents a probabilistic hyperbolic recommendation framework that embeds users, items, and tags as uncertainty-aware spheres in hyperbolic space. The model composes similarities along user--tag--item paths using a Gaussian semantic kernel, enabling calibrated confidence estimates and interpretable explanations. Evaluated on news (MIND), book (GoodBooks, BookCrossing), and reasoning (Avicenna) datasets, SpheriQ demonstrates improvements in ranking accuracy (up to 8.3% NDCG@10 gain), calibration (6.7% lower ECE), and semantic diversity over neural, graph-based, and hyperbolic baselines.\n\nThis is a well-executed paper that makes solid theoretical and empirical contributions to recommendation systems. The unification of probabilistic modeling, hyperbolic geometry, and semantic reasoning is novel and the experiments demonstrate advantages across multiple evaluation dimensions. \n\nHowever, the framework fundamentally requires a tag set, which may limit applicability when tags are unavailable or poorly defined. There are theoretical gaps left in the paper that doesn't prove the kernel is positive definite or analyze learnability guarantees. Some experimental choices lack justification. This paper needs revisions for clarity and deeper engagement with limitations to showcase its value in addition to the literature on trustworthy and interpretable recommendation systems."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper makes innovative contributions by unifying three typically separate research directions: \n\n1. Novel geometric formulation: Probabilistic spheres in hyperbolic space where radii encode predictive uncertainty is creative and well-motivated.\n\n2. Semantic transitivity: The explicit user--tag--item path decomposition with fuzzy composition operators provides a principled bridge between symbolic and embedding-based reasoning.\n\n3. Integrated framework: Unlike prior work that treats calibration, interpretability, and ranking as separate objectives, SpheriQ addresses all three simultaneously through its geometric design.\n\nThe theoretical connection between sphere inclusions and logical entailments (Proposition 9) is intellectually interesting, though its practical utility could be explored further."}, "weaknesses": {"value": "The paper could be further improved if addressing the following concerns:\n\n1. The paper's entire framework depends on tag quality, yet tag construction receives minimal treatment and varies inconsistently across datasets. Publisher metadata (MIND) vs. automated clustering (books) vs. symbolic concepts (Avicenna) makes it impossible to disentangle whether improvements come from the model or from tag quality differences.\n\n2. The paper claims to unify uncertainty, interpretability, and hyperbolic geometry, but the ablation study doesn't compare against methods that combine subsets of these.\n\n3. Theoretical analysis of the paper is incomplete and disconnected from practice. Proposition 4 claims score calibration under increasing uncertainty, but the experiments don't validate this relationship. Figure 2(a) shows reliability diagrams but doesn't plot predicted σ² against actual error—the core prediction of the theory. For a paper emphasizing \"trustworthy\" systems, the absence of theoretical confidence intervals is notable.\n\n4. The calibration evaluation could be further improved by adding temporal/stratified analysis, prediction intervals, and abstention strategies. All calibration metrics are computed on held-out test sets with the same distribution as training, while real deployments face distribution shift. \n\n5. The paper claims efficiency, but test on large-scale data (100K+ users, 1000+ tags) is missing.\n\n6. Explanation evaluation could be further improved by providing human evaluation or at minimum contrastive/stability analysis. If a user has multiple relevant tags, masking just t* may route through t**, leaving scores largely unchanged. If masking any tag causes similar drops, the explanations aren't selective.\n\n7. \"COLD-START AND OOD ROBUSTNESS\" need more clarification. \"Cold-item\" and \"Cold-user (5-shot)\" are vaguely defined. 89-91% retention sounds impressive but lacks context. No comparison to explicit cold-start methods.  Semantic shift or tag shift is underspecified.\n\n8. The hyperparameter sensitivity analysis is missing for fairness concerns.\n\n9. The paper could be further improved in writing and presentation. For instance,  \"Semantic kernel\" (line 126) is used both for the Gaussian similarity K(·,·) and the reasoning mechanism. O_i is introduced as (µ_i, σ²_i) but sometimes appears as just µ_i in equations (e.g., Eq. 1 uses µ_i not O_i)\n\n10.  A discussion section of limitations and when method doesn't apply will be helpful for the method clarification."}, "questions": {"value": "If the authors can address the following questions in the rebuttal, it would significantly clarify the contribution and help reviewers assess the work more accurately. \n\n1. Could you provide more explanations for the reason why you use K-means with k=20 for GoodBooks/BookCrossing based on \"Silhouette analysis\" (line 138)? Did you try other Silhouette scores or clustering methods?\n\n2. Why there is no \"Poincaré + learned variance\" baseline? This seems like the natural ablation to isolate your semantic kernel's contribution from simply adding uncertainty to hyperbolic embeddings.\n\n3. All calibration metrics (ECE, Brier, AURC) are computed on i.i.d. test sets. Did you evaluate calibration under distribution shift, such as temporal drift, population shift .etc?\n\n4. Table 4 shows masking the top explanatory tag t* causes 4.7% Hit@10 drop for SpheriQ vs. 0.2-0.9% for baselines. Could you provide further explanation for the reason? What happens if you mask the second-best tag? Or a random tag? Are the same tags consistently selected as t* across different random seeds?\n\n5. Is the 3% NDCG gain over JIT2R partly due to 2× more hyperparameter search? Could you provide detailed justification for why SpheriQ requires more hyperparameter search (e.g., additional variance parameters σ²_i)\n\n6. Tables 7-8 provide case studies, but these are cherry-picked. Is there any human validation of explanation quality? How do humans perceive the tag-based rationales compared to no explanation?\n\n7. The authors cite Wang et al. (2023) on CaD-VAE but don't compare against it. Could you provide further justification?\n\n8. Given the complexity (Riemannian optimization, tag construction, multiple hyperparameters), when is SpheriQ worth the effort over simpler baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sJdfNu4FBi", "forum": "YEzhahKASg", "replyto": "YEzhahKASg", "signatures": ["ICLR.cc/2026/Conference/Submission20617/Reviewer_xr56"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20617/Reviewer_xr56"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20617/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998027314, "cdate": 1761998027314, "tmdate": 1762934018993, "mdate": 1762934018993, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a probabilistic hyperbolic model for recommendation systems that integrates tags, semantic attributes, and hierarchical structures into a unified Poincaré space. Each tag is modeled as a probabilistic sphere, allowing uncertainty-aware reasoning through composable semantic kernels. The model introduces fuzzy and soft-transitive reasoning mechanisms for interpretability and transitive inference, aiming to bridge symbolic and geometric methods in explainable recommendation."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The formulation of users, items, and tags within the same hyperbolic space is elegant and could enable meaningful transitive reasoning.\nThe path-based reasoning (e.g., u → t → j) offers potential for transparent recommendations.\n\n\n2. Extending hyperbolic embeddings with fuzzy composition functions (min/product) and temperature-controlled softmax is a technically interesting methodological contribution."}, "weaknesses": {"value": "The introduction transitions abruptly into tags and semantic attributes without explaining why they form an appropriate starting point. The authors should provide a clear motivation for introducing soft-transitive reasoning, supported by concrete illustrative examples. Substantial improvements in clarity and narrative flow can be made in the introduction.\n\nThe paper lacks a thorough discussion of prior work on geometric embedding methods and their applications in recommendation, which would help contextualize the proposed approach within existing literature.\n\nThe model’s performance appears highly dependent on the quality and completeness of tag extraction, which is inherently limited and may introduce bias or coverage gaps in practical settings."}, "questions": {"value": "Clarify the advantage of probabilistic kernels over tripartite reasoning.\nThe paper should clearly explain why probabilistic kernel composition provides a substantive improvement over traditional tripartite or deterministic tag-diffusion methods. What specific limitations of tripartite reasoning—such as lack of uncertainty modeling or limited semantic flexibility—are addressed by the probabilistic formulation?\n\nConsider including strong geometric baselines.\nIt would strengthen the empirical evaluation to include recent geometric models such as (a) “A Geometric Approach to Personalized Recommendation with Set-Theoretic Constraints Using Box Embeddings” and (b) “Enhancing Recommendation Accuracy and Diversity with Box Embedding: A Universal Framework.” The authors should also discuss why these box-embedding methods might be less effective or less suitable than the proposed approach for soft transitive reasoning or uncertainty modeling.\n\nClarify the single-path reasoning choice.\nThe decision to select only a single conceptual path (user → tag → item) for explanation seems restrictive. Users often like items for multiple semantic reasons—for example, a film might be recommended both for being romantic and comedic. Please justify this modeling choice and discuss whether multi-path reasoning could provide more complete or interpretable explanations.\n\nDiscuss scalability under large tag vocabularies.\nAs the number of tags increases, computing the soft surrogate or evaluating all tag-based kernel compositions could become computationally expensive. The authors could analyze the scalability of their approach and discuss whether approximation strategies (e.g., top-k filtering or sampled softmax) are employed to mitigate training costs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "swYlM6ByqE", "forum": "YEzhahKASg", "replyto": "YEzhahKASg", "signatures": ["ICLR.cc/2026/Conference/Submission20617/Reviewer_cLnQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20617/Reviewer_cLnQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20617/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762155229530, "cdate": 1762155229530, "tmdate": 1762934017807, "mdate": 1762934017807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}