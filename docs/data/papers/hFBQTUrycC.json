{"id": "hFBQTUrycC", "number": 19190, "cdate": 1758294262280, "mdate": 1759897053124, "content": {"title": "An algebraic approach to approximately equivariant networks", "abstract": "Equivariant neural networks incorporate symmetries through group actions, embedding them as an inductive bias to improve performance. Prominent methods learn an equivariant action on the latent space, or design architectures that are equivariant by construction. These approaches often deliver strong empirical results but can impose architecture-specific constraints, large parameter counts, and high computational cost. We challenge the paradigm of complex equivariant architectures with a parameter-free approach grounded in representation theory. We prove that for an equivariant encoder over a finite group, the latent space must almost surely contain one copy of the regular representation for each linearly independent data orbit, which we explore with a number of empirical studies. Leveraging this foundational algebraic insight, we impose the regular representation as an inductive bias via an auxiliary loss, adding no learnable parameters. Our extensive evaluation shows that this method matches or outperforms specialized models in several cases, even those for infinite groups. We further validate our choice of the regular representation through an ablation study, showing it consistently outperforms a defining representation baseline.", "tldr": "We prove that an equivariant encoder's latent space must contain the regular representation, and enforce this with a lightweight auxiliary loss without additional learnable parameters to achieve state-of-the-art performance.", "keywords": ["equivariance", "representation-learning", "group-theory", "symmetry"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/03f0733b03f6ea818a139adc3a1affc74bafc3ce.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper suggests training neural networks using an equivariance loss on an intermediate latent space. Given a priori knowledge of a task symmetry group, a representation of the group can be chosen and used to define the equivariance loss. Furthermore, theoretical and empirical analysis is presented that suggests that for finite groups, using multiple copies of the regular representation is the optimal choice of representation.\n\nIn experiments, the suggested approach is shown to work well."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper contributes empirical evidence that using a pre-chosen group representation in latent space and training a network to be equivariant wrt to it can work just as well as more complicated methods for obtaining (approximate) equivariance.\n2. The flow from checking what representation is learned to fixing the representation is natural and well presented."}, "weaknesses": {"value": "**Missing references:**\n\nEncouraging equivariance by using a fixed representation in latent space is an idea that goes back at least to Cohen & Welling (Transformation Properties of Learned Visual Representations, ICLR 2015), see also Worrall & al (Interpretable transformations\nwith encoder-decoder networks, ICCV 2017).\n\nStudying the case of a learnable group representation in latent space was done by Bökman & al, albeit only for keypoint description (Steerers: A framework for rotation equivariant keypoint descriptors, CVPR 2024). However, Bökman & al found that the final distribution of eigenvalues in the learned group representation depends on their initialization, which is not tested in the submitted paper.\n\nNotably, the above works also consider infinite groups (by using finite representations), while the submitted paper states that “a direct extension to infinite groups is a non-trivial challenge for future work”.\n\n**Theory:**\n\nTheorem 1 contains an “almost surely”, which requires a probability measure on the space of equivariant functions considered. Such a probability measure is not presented. Even changing to “almost everywhere” or similar would require defining a measure on the function space.\n\nTheorem 1 further only considers injective functions. Neural networks for classification are typically less and less injective the deeper layer one considers (Mahendran & Vedaldi, Understanding Deep Image Representations by Inverting Them, CVPR 2015)."}, "questions": {"value": "1. Does changing the initialization of $\\rho_Z$ in Section 4.2 change the conclusions? For instance if $\\rho_Z(g)$ is initialized close to the identity?\n2. What layer of the network is $Z$? Is it in the middle or towards the end of the network? Do the experimental conclusions change if different layers are considered for $Z$?\n3. What is meant by \"almost surely\" in Theorem 1? I.e. what is the measure considered?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LBGBtbsemv", "forum": "hFBQTUrycC", "replyto": "hFBQTUrycC", "signatures": ["ICLR.cc/2026/Conference/Submission19190/Reviewer_LN8t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19190/Reviewer_LN8t"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761029084194, "cdate": 1761029084194, "tmdate": 1762931189411, "mdate": 1762931189411, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors consider the problem of learning network that respect an equivariance condition. They argue for not confining the architecture to be exactly equivariant, but rather to penalize non-adherence to the equivariance conditions. \n\nA problem with imposing equivariance by architecturial means in general is the a-priori non-fixed action of the group on the intermediate spaces. The authors argue theoretically as well as empirically that the regular action of the group is a reasonable choice. Using this choice, the authors propose to train an architecture consisting of an encoder E to a latent space Z (on which the group is acting regularly) and then a decoder/classifier/etc. D from Z to the output space, regularizing E to be equivariant with respect to the fixed input action and regular action on Z during training."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The manuscript is easy to read. The main ideas are easy to digest. The main idea, to achieve equivariance through regularization rather than hard constraints, is sound."}, "weaknesses": {"value": "* Clarity *  While the manuscript as a whole is simple to read, there are many details that remain unclear. \n\n1. The statement and proof of the main theorem is correct, but I am unsure of its significance. It is only applicable to quite small groups because of the condition $\\dim(Z)\\geq \\abs{G}$ (think about the group of permutation on, say, more than 10 elements). If the action $\\alpha_X$ is linear, one can always $\\rho_Z=\\alpha_X$ and $\\calA = X$ and choose $E$ as the identity to obtain an injective, equivariant map, irregardless of whether $X$ contains the regular representation.\n \nAlso, the interpretation the authors make (the 'key theoretical insight' on page 4) is unclear to me. First, it is unclear what the meaning of a 'linearly independent orbit' is. Does it mean that the spans of the images of the two orbits have a trivial intersection? That they are not contained in each other? It is also unclear how the statement follows from Theorem 1 : While the group acts transitively on each orbit, it does not act transitively on the union of the orbits.\n\n2. In the exploratory experiments, the authors seem to be making a point out of that the irrep counts always exactly corresponds to the number of linearly independent embedded orbits. It is however unclear how this number is measured, also after looking at the code.\n\n3. The authors claim in the introduction that their method leads to lower parameter counts. I do not understand this. In fact, a constrained architecture will in some sense always have a lower number of effective parameters -- the dimension is reduced by the restriction.\n\nSee questions on smaller details below.\n\n* Novelty * What the authors ultimately propose is to penalize non-conformance to the equivariance condition both for the network as a whole and the encoder part. This ultimately is very close to simply using augmentations, and is the driving idea behind e.g. residual pathway priors (see also [1] and references therein). If the only novel idea is the use of the regular representation on the latent space, it is limited.\n\n* Experimental validation* The authors test their method in three settings, and they do showcase good performance. However, their method never outperforms their baseline by more than a standard deviation over three runs, which is slightly unconvincing. \n\n\n[1] Pertigkiozoglou, S., Chatzipantazis, E., Trivedi, S., & Daniilidis, K. (2024). Improving equivariant model training via constraint relaxation. Advances in Neural Information Processing Systems, 37, 83497-83520."}, "questions": {"value": "See the questions under weaknesses. Consider also the following more detailed questions below:\n\n1. In the main body of the text, the TMNIST experiments use a latent dimension of 8, but in the appendix and the code supplement, a latent dimension of 6 is claimed. Which is correct?\n\n2. For the MNIST/D3 experiments, the authors say that the digits are augmented by 'arbitrary' rotations. Does this mean that the rotations are random $\\mathrm{SO}(2)$-rotations, or something else?  The group is then chosen as $D_3$, which also contains reflections. Can the authors comment why this choice is made (it does not seem to be compatible with the symmetries of the dataset?)\n\n3. In the main text, the rotations building D3 are 120 degrees, but in the appendix, they are specified as rotations of 60 degrees. Which is correct?\n\n4. In Table 4, the wrong number in the Nodule column seems to have been underlined.\n\n5. In the appendix, the inclusion of Figure 7 is confusing,  in that it is never referenced. In which experiment is reorientation applied/not applied?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1VtwWSdy8I", "forum": "hFBQTUrycC", "replyto": "hFBQTUrycC", "signatures": ["ICLR.cc/2026/Conference/Submission19190/Reviewer_g1LT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19190/Reviewer_g1LT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761648115946, "cdate": 1761648115946, "tmdate": 1762931188987, "mdate": 1762931188987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a parameter-free approach for promoting equivariance in neural networks by imposing, through an additional loss term, that the intermediate latent representation of the network contains multiples of the regular representations. The authors' main theoretical argument motivating this choice is that, for an injective function equivariant to a finite group, if its codomain is sufficiently large, then it almost surely contains the regular representation. The authors empirically evaluate this claim by first testing whether simple networks trained to be equivariant indeed learn latent representations that contain the regular representation. Additionally, they showcase across various approximate equivariant tasks that promoting this structure in the latent space of an encoder improves performance compared to previous approximate equivariant methods, which typically achieve equivariance through specific network design."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The simplicity of the proposed method allows it to be clearly presented and easily implemented, which may encourage broader adoption, especially compared to more complex works on approximate equivariant architecture.\n- The experimental results provide empirical evidence that unconstrained networks tend to learn latent spaces containing the regular representations, and that explicitly promoting this structure through a loss can improve overall performance. Although, as stated in the weaknesses, these results are limited to relatively small finite groups, the method can still be of interest to the community and may be applicable to a broader range of tasks."}, "weaknesses": {"value": "- The main weakness of this work is the inconsistencies in the proof of Theorem 1, which serves as the motivating result for the method. In the proof, the authors assume an injective equivariant function $E$ and construct a linear map $\\tilde{E}$, represented in matrix form as $M$. They argue that if $\\det(M)\\not =0$ then the output of the equivariant function contains the regular representation, and that $\\det(M)\\not=0$ almost surely, since random matrices are almost surely invertible. However, this probabilistic argument is problematic, since $M$ is not a randomly sampled matrix. On the contrary, $M$ is constructed from an optimized/trained function $E$. Thus, the claim that $\\det(M)\\not=0$ almost surely lacks formal justification and doesn't hold in the current version of the proof. There may exist deeper conditions under which $M$ is generically invertible, but these are not discussed in the current proof.\n- The experimental results are limited to small finite groups,  such as $C_4$ and $D_3$. In most cases, the more challenging settings for equivariant and approximately equivariant networks involve larger or continuous groups. There is no clear indication whether the results presented in this paper can scale as the dimensionality of the group increases, which will also result in an increase in the latent representation's dimensionality and potentially its computational cost."}, "questions": {"value": "- How can we make a probabilistic argument about the determinant of $M$ and, more broadly, about the nature of the representation of the encoder, when $M$ is constructed by the learned network $E$ and not randomly sampled? Is there any other connection that makes $M$ almost surely invertible?\n- How does the method scale for larger finite groups where the size of the latent representation also increases? Did the authors observe any tradeoff, or does the regular representation empirically always seem to be the best choice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AVtkWr4PeS", "forum": "hFBQTUrycC", "replyto": "hFBQTUrycC", "signatures": ["ICLR.cc/2026/Conference/Submission19190/Reviewer_awTB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19190/Reviewer_awTB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19190/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762227500947, "cdate": 1762227500947, "tmdate": 1762931188516, "mdate": 1762931188516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}