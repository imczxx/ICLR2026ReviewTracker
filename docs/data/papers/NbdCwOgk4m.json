{"id": "NbdCwOgk4m", "number": 5475, "cdate": 1757913366805, "mdate": 1763722301099, "content": {"title": "Efficient Hyperparameter Tuning via Trajectory Invariance Principle", "abstract": "As hyperparameter tuning becomes \nincreasingly costly at scale, efficient tuning methods are essential. Yet principles for guiding hyperparameter tuning remain limited.\nIn this work, we seek to establish such principles by considering a broad range of hyperparameters, including batch size, learning rate, and weight decay.\nWe identify a phenomenon we call \\emph{trajectory invariance}, where pre-training loss curves, gradient noise, and gradient norm exhibit invariance--closely overlapping--with respect to a quantity that combines learning rate and weight decay. This phenomenon effectively reduces the original two-dimensional hyperparameter space to one dimension, yielding an efficient tuning rule: follow the salient direction revealed by trajectory invariance. Furthermore, we refine previous scaling laws and challenge several existing viewpoints.\nOverall, our work proposes new principles for efficient tuning and inspires future research on scaling laws.", "tldr": "", "keywords": ["pre-training", "batch size", "scaling laws", "optimization", "hyperparameter tuning", "large language models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/32b9ea92f6b0e1e51b5298b1171e4abf3977b822.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a trajectory invariance phenomenon in language model pretraining, where loss, gradient noise, and gradient norm curves remain nearly identical across runs sharing a composite of learning rate and weight decay. This observation suggests that the two-dimensional hyperparameter space of learning rate and weight decay can be reduced to a single tuning direction. The authors also discuss implications for hyperparameter scaling laws and efficient hyperparameter tuning strategies."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper identifies a trajectory invariance phenomenon in pre-training dynamics, showing that certain combinations of learning rate and weight decay yield similar training trajectories. This observation may help reduce the effective hyperparameter search space and improve tuning efficiency."}, "weaknesses": {"value": "- The study is conducted on a single model size (164M-parameter model), meaning there is no cross-scale analysis. Without experiments on multiple model sizes (e.g., ≥1B parameters), the generality and robustness of the proposed principle cannot be established.\n\n- The paper claims to refine or challenge existing scaling laws, but prior scaling-law research derives conclusions from cross-scale comparisons across multiple model sizes. Since this work relies on a single-scale setting, the evidence is not sufficient to support the broader implications suggested by the paper."}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wvG2gyQ6Ea", "forum": "NbdCwOgk4m", "replyto": "NbdCwOgk4m", "signatures": ["ICLR.cc/2026/Conference/Submission5475/Reviewer_qowG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5475/Reviewer_qowG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761810087250, "cdate": 1761810087250, "tmdate": 1762918084238, "mdate": 1762918084238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents how the space of hyperparameters in llm optimization may be simplified by considering solely the effective learning rate (product of learning rate and weight decay) rather than learning rate and weight decay separated. This claim is corroborated through numerous experiments that help understand its relevance and its limitations in different situations. Namely, the authors show that for a small number of iterations (independent of batch size interestingly), losses overlap for a given learning rate and not the effective learning rate. This fact guides the authors to try batch size schedulers that help retrieve invariance of the losses with effective learning rates. In general the experimental results, looed through many faces help revise and question our understanding of some learning rate scaling rules such as the square root LR-BS scaling rule."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is very well presented and written. Key concepts are introduced early. Each experiment is well thought and illustrates well the claims.\n- The relevance of the effective leraning rate (ELR) is presented under many facets: overlapping losses, pairwise relative distances, optimal direction in the hyperparameter search space.\n- The authors fit some scaling laws with effective learning rate that could be reused by the community.\n- The authors also show that gradient noise can overlap with effective learning rate.\n- The batch-size scheduling appears new to me and is a very interesting approach to capture benefits of various batch size scales.\n- Discussion of related work is well done. The reader understands that similar observations were done and understands how this paper differs."}, "weaknesses": {"value": "- It is unclear whether the effects are observed at different model sizes. \n- The experiments are limited to a single optimizer. SignSGD or Muon for example would be great candidates to explore the claims."}, "questions": {"value": "- The authors point that previous studies found different conclusions in terms of scaling laws for example. How is it possible? What changed between these studies?\n- Can the authors test their claim on another optimizer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gZLpES6pDb", "forum": "NbdCwOgk4m", "replyto": "NbdCwOgk4m", "signatures": ["ICLR.cc/2026/Conference/Submission5475/Reviewer_vF4o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5475/Reviewer_vF4o"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954475656, "cdate": 1761954475656, "tmdate": 1762918083873, "mdate": 1762918083873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces \"trajectory invariance,\" a phenomenon in deep learning pre-training where loss curves and other metrics closely overlap. Early in training, this invariance is with respect to the learning rate (LR), meaning runs with the same LR but different weight decays (WDs) follow similar paths. As training progresses, particularly with a sufficient number of iterations, this invariance shifts to the effective learning rate (ELR), defined as the product of LR and WD. The authors demonstrate that this principle effectively reduces the two-dimensional tuning space of LR and WD to a single dimension, proposing a more efficient tuning strategy: tune along the \"salient direction\" (ELR in small-batch or sufficient-iteration regimes, and LR in large-batch regimes) to optimize performance. The work also refines existing hyperparameter scaling laws, challenging prior viewpoints on optimal batch size and learning rate scaling."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper introduces a novel scaling law for hyperparameter tuning, providing insights for practical applications.\n2. The comprehensive experiments and discussions indicate that the proposed principle demonstrates some robustness."}, "weaknesses": {"value": "1. The paper is poorly written and falls significantly below the standards expected of a top-tier conference. Many concepts are introduced before being properly defined (even without definition). The figures are also of very low quality, curves often overlap and are difficult to distinguish. The figure legends lack consistency; for instance, in Figure 1, the left subfigure uses “2^-12” (which is already too casual for scientific publications) while the right subfigure uses “2e−4.” Additionally, Figure 3’s caption redundantly includes “For example, For example”. The appendix appears incomplete, particularly Sections A.2 and A.3.\n2. There is a lack of analytical discussion regarding this invariance phenomenon. For instance, insights can already be drawn from the update rule of algorithms incorporating weight decay. A typical update takes the form $w_{t+1} = (1 - \\eta \\lambda) w_t + \\eta g_t$,\nwhere $g_t$ denotes a gradient estimator, such as the stochastic gradient in SGD or $m_t / (\\sqrt{v_t} + \\epsilon)$ in Adam. From this expression, it becomes intuitive that early in training, the gradient magnitude is relatively large and thus dominates, making the learning rate $\\eta$ the more influential factor. As training progresses and the gradients tend to converge, the first term with coefficient $(1 - \\eta \\lambda)\n$ becomes dominant, thereby amplifying the relative effect of the factor $\\eta \\lambda$.\n3. The paper makes rather strong claims, such as “we find that scaling law for LR is wrong.” The authors should provide sufficient justification for such assertions. Are the experimental findings reported in existing scaling law studies incorrect, or do those conclusions simply not apply under the specific conditions of the authors’ setup? Does this also imply that the authors’ findings lack generality and may not extend to the experimental setups used in those prior studies?\n4. The generality of the proposed invariance remains uncertain. How does this phenomenon manifest across different optimizers, tasks, and network architectures? Moreover, can the same behavior be consistently observed when employing various deep learning techniques, such as different forms of normalization?\n5. As an empirical study, the paper omits certain important implementation details. For instance, how is $\\Sigma$ computed in practice? Is it estimated using an additional sampled batch? What batch size is used for this estimation, and how reliable or accurate is the resulting approximation?"}, "questions": {"value": "Please refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jBQmkkPyEX", "forum": "NbdCwOgk4m", "replyto": "NbdCwOgk4m", "signatures": ["ICLR.cc/2026/Conference/Submission5475/Reviewer_zBM1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5475/Reviewer_zBM1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762097167532, "cdate": 1762097167532, "tmdate": 1762918083396, "mdate": 1762918083396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of hyperparameter tuning. Concretely, they propose a phenomenon in neural network training, called \"trajectory invariance\", which claims that the loss curves admit an invariance w.r.t. $\\gamma$ - a quantity that combines the learning rate and weight decay. Based on such a phenomenon, the authors propose a promising way to tune multiple hyperparameters in practice. For example, practitioners can fix the learning rate and only tune the weight decay, turning a problem of 2 hyperparameters into one effectively."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is easy to follow."}, "weaknesses": {"value": "First things first, I am not an expert in this field, so maybe my evaluation is a bit off. However, it seems to me that the paper is over-claiming (a lot):\n\n1. The paper claims to have discovered the \"trajectory invariance principle\" for efficient hyperparameter tuning. However, there is one critical thing: the paper only conducts its experiments on the AdamW optimizer (and with the standard setting as well). Note that in AdamW, the weight decay $\\lambda$ is a simple, direct decay applied to the weights, __separated__ from the gradient update. Therefore, I assume that the joint effect of learning rate $\\eta$ and weight decay $\\lambda$ parameter might be simple, leading to a simple term ELR $\\eta = \\lambda \\cdot \\eta$ that can capture the trajectory (in some sense). However, this does not mean that the analysis can be applied to other optimizers, including Vanilla Adam, and especially LION, Muon, of which the update principles are very different. \n\n2. The above suggests that the finding might not be a \"principle\", but rather an \"artifact\" that happens in some sense only for AdamW. In such a case, I expect a (simplified) theoretical analysis on why this phenomenon happens for AdamW (or at least some strong intuitive explanation with concrete evidence), so that the paper might be interesting in some sense. Unfortunately, this is not the case for this paper.\n\n3. Moreover, if we reluctantly accept the experiments restricted to AdamW, I still think that the experiments are insufficient. For example, the authors explicitly acknowledge that optimizer states of AdamW, like $\\beta_2$, are \"important\" and \"influence\" the training. However, the authors only consider the experiments with one value of $\\beta_2$\n\nIn summary, I believe that the empirical findings in this paper are insufficient for a high-quality paper. I strongly recommend that the authors should at least validate their findings with: (1) more optimizer settings, (2) more configuration in each optimizer, ... or try to develop some (simplified) theoretical justifications for their findings, so that they can boost this paper's contribution. As of this state, I unfortunately cannot recommend an acceptance for this paper."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "thpj33Ywwr", "forum": "NbdCwOgk4m", "replyto": "NbdCwOgk4m", "signatures": ["ICLR.cc/2026/Conference/Submission5475/Reviewer_J8na"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5475/Reviewer_J8na"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762232872447, "cdate": 1762232872447, "tmdate": 1762918082868, "mdate": 1762918082868, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}