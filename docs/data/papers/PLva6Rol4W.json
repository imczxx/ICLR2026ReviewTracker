{"id": "PLva6Rol4W", "number": 15863, "cdate": 1758256268130, "mdate": 1763696543374, "content": {"title": "Increasing Information Extraction in Low-Signal Regimes via Multiple Instance Learning", "abstract": "In this work, we introduce a new information-theoretic perspective on Multiple Instance Learning (MIL) for parameter estimation with i.i.d. data, and show that MIL can outperform single-instance learners in low-signal regimes. Prior work \\citep{nachman_learning_2021} argued that per-instance methods are often sufficient, but this conclusion presumes enough per-instance signal to train near-optimal classifiers. We demonstrate that even state-of-the-art per-instance models can fail to reach optimal classifier performance in challenging low-signal regimes, whereas MIL can mitigate this sub-optimality. As a concrete application, we constrain Wilson coefficients of the Standard Model Effective Field Theory (SMEFT) using kinematic information from subatomic particle collision events at the Large Hadron Collider (LHC). In experiments, we observe that under specific modeling and weak signal conditions, pooling instances can increase the effective Fisher information compared to single-instance approaches.", "tldr": "We introduce an information-theoretic view of Multiple Instance Learning for its use in parameter estimation problems in High-Energy Physics, and demonstrate improved performance.", "keywords": ["Multiple Instance Learning", "High-Energy Physics", "Hypothesis Testing", "Fisher Information", "Parameter Estimation", "Simulation-based Inference"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d2052c9157811a19186311763d656a1d44c875a0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose using a Multiple Instance Learning framework to improve parameter estimation in scientific analyses in low signal regimes. They provide an information-theoretic motivation, arguing that by aggregating multiple independent instances into a 'bag', the SNR of the learning task is effectively increased. This does allow a machine learning model to extract more Fisher Information than it could from processing each instance individually. The method is demonstrated by applying it to a high-energy physics problem."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-written and the information-theoretic motivation is sound and clearly described in the Reviewers' opinion. The empirical demonstration of performance degradation in single-instance models versus the MIL approach in the presence of background contamination is also a well-executed and easy to follow experiment. \nAdditionally also the discovery that models violate the second Bartlett identity and the suggested fix are interesting results by itself."}, "weaknesses": {"value": "- The paper focuses on a single application only. While the application problem seems important, given that the authors introduce a general framework, the Reviewer would expect at least one other examples to show the applicability of the approach. Especially as the authors claim a general-purpose framework, this should also be reflected in the experiment section.\n- The technical contribution of the paper seems to be limited, the core architecture is a simple MLP, and the multiple instance learning aggregation is a standard global average pooling of embeddings. There are currently no novel architectures, loss functions or training procedures proposed although the authors mention this as an important next step. From the Reviewers' perspective, the paper seems to be an exploration of a known model limitation rather than the introduction of a novel learning paradigm."}, "questions": {"value": "See weaknesses and:\n-The multi-class results were achieved by creating a large ensemble of 20 independently trained models. What would happen for a lower number of models and does this suggest a reduced robustness of a single model ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LHdGpkkovG", "forum": "PLva6Rol4W", "replyto": "PLva6Rol4W", "signatures": ["ICLR.cc/2026/Conference/Submission15863/Reviewer_wFd7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15863/Reviewer_wFd7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901775058, "cdate": 1761901775058, "tmdate": 1762926083916, "mdate": 1762926083916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper discusses a hypothesis testing scenario, where evaluating the likelihood function is intractable and hence the standard likelihood ratio test (LRT) becomes infeasible. The paper considers an alternative approach, where a neural classifier is trained based on simulated data under different hypotheses. In particular, it considers a solution where multiple instances are assigned to one common label (called MIL). The paper examines this idea in particle physics, for detecting deviations from Standard Model in collision experiments. By experimentation on synthetic data, it is shown that the proposed method is superior to the combination of decisions on individual instances (ensemble methods). This observation is further theoretically justified by arguments involving Fisher information and Cramer-Rao bound."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I am not familiar with physics literature and hence cannot assess the significance of the paper within this field. From a general statistics perspective, especially in the context of data fusion, the contribution of the paper is a lightweight method, based on LRT, which fuses multiple instances at a feature level rather than at a decision level. Feature-level fusion is known to be superior to decision-level fusion, especially in low-SNR regimes, but is generally considered a complex task."}, "weaknesses": {"value": "I wonder how novel or substantial contribution is. As already mentioned, the fact that feature-level fusion is superior to the decision level is well-known and intuitive. The use of NNs for estimating likelihood ratios is not entirely new and is extensively discussed in the context of neural ratio estimation (NRE). From the perspective of MIL, the paper considers a simplified scenario, which to me is a repetition of the\nstandard point estimation theory with multiple observations. A major part of the theoretical discussions, e.g. the vanishing of ML error and growth of FI with O(\\sqrt{N}), can be found in multiple classical sources.\n\nAnother drawback of the suggested approach is that for deployment, it requires an ensemble of independent observations of similar size to the ones used for training. This can be a limitation in practice.\n\nThe presentation of the paper can also be improved. It is sometimes difficult to understand the motivation behind the concepts introduced. For example, I am not familiar with the notion of effective Fisher information, and it is not clear to me what it implies. Some notations remain unexplained too. For example, in line 198 e_ij seems to refer to the elements of e_i, but this is not defined. Moreover, \\theta_SM and \\theta_SMEFT are not properly introduced."}, "questions": {"value": "After understanding the problem of interest, I am surprised about the use of LRT, in this context. The reason is that one of the alternatives is presented as a composite hypothesis (theta\\neq 0). A consequence of applying LRT is that the alternative values of theta (e.g. \\theta_1) must be selected beforehand. How can this be done? And are not tests such as GLRT more suitable for this scenario?\n\nIf I understand it correctly, the training procedure does not explicitly bias the logits toward the individual likelihood ratios. Is it possible to guarantee that they are estimates of LRs? Indeed, Appendix C shows that they are biased in nature. And if biased, how is the presented theory based on CRB relevant to them?\n\nAs a minor comment in (11), do you mean by “+ 0” a higher order term?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Uzuy7w1t89", "forum": "PLva6Rol4W", "replyto": "PLva6Rol4W", "signatures": ["ICLR.cc/2026/Conference/Submission15863/Reviewer_PHoD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15863/Reviewer_PHoD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922730501, "cdate": 1761922730501, "tmdate": 1762926083373, "mdate": 1762926083373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper demonstrates and theoretically justifies that multiple instance learning (MIL) for parameter estimation with i.i.d. data can outperform single instance learning (SIL) at low signal-to-noise ratios. Prior work demonstrated that single-instance learning is sufficient, assuming the training is optimal, but for low signal-to-noise, this may not be satisfied. They demonstrate the effectiveness of MIL in constraining Wilson coefficients of the standard model effective field theory (SMEFT) using kinematic information from subatomic particle collision events at the CERN LHC, observing that, for low signal-to-noise ratios, pooling instances can increase the effective Fisher information compared to single-instance approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Investigation of multiple instance learning in a new setting (low signal-to-noise ratios), which is of practical importance at the CERN LHC. \n* Theoretical justification using effective Fisher information to explain why MIL practically improves on SIL for low SNRs.\n* Comparison to multiple baselines, including parameterized neural networks, and in multiple settings, including binary and multi-class classification.\n* Code is made public."}, "weaknesses": {"value": "* Unclear if the data has been or will be made public.\n* Some details on the training procedures are missing, e.g. how large is the training data set? How many epochs was each algorithm trained for? Were training hyperparameters, e.g., learning rate, optimized? Etc. Since part of the claims depend on (non)optimality of the models, these are important considerations."}, "questions": {"value": "* Was min/max pooling studied in addition to the average pooling of rht embedding vectors in a given bag? Min/max pooling seems like a more suitable choice if the goal is to classify if there is *any* signal instance in the bag.\n* Can the studied datasets be made public?\n* Could you define the effective Fisher information or clarify how/why it differs?\n* Fig. 1: How large is the training data set? Are all of these models trained with the same size data set? How many epochs was each algorithm trained for? Were training hyperparameters, e.g., learning rate, optimized?\n* Would the single-instance learning eventually “catch up” to the multiple instance learning if provided a large enough dataset even in the low SNR regime? If so, then another way to cast these results are that MIL is more data efficient.\n* Fig. 2: Fix typo “Ensamble”"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vEALVU7Tig", "forum": "PLva6Rol4W", "replyto": "PLva6Rol4W", "signatures": ["ICLR.cc/2026/Conference/Submission15863/Reviewer_FvWc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15863/Reviewer_FvWc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972106988, "cdate": 1761972106988, "tmdate": 1762926082856, "mdate": 1762926082856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank the reviewers again for their constructive comments and feedback, which we have used to refine our manuscript. We would like to summarize the key modifications made in the revised version:\n\n*   **Code Availability:** Added detailed data generation scripts and instructions to the anonymous GitHub repository.\n*   **Contextualization:** Referenced data fusion literature in the introduction to better frame the contribution.\n*   **Training Details:** Explicitly referenced the machine learning training and optimization details (Appendix B.2) within the Results section.\n*   **Theoretical Clarification:** Expanded the Theory section (Section 3.2) to clearly distinguish between *effective* Fisher Information ($I_{eff}$) and *true* Fisher Information ($I_{true}$), and elaborated on the asymptotic behaviour of neural estimators in low- vs. high-signal regimes.\n*   **Corrections:** Fixed notation inconsistencies and minor typos.\n\nWe remain available to respond to any further questions or comments during the discussion period."}}, "id": "MXvCulmxTi", "forum": "PLva6Rol4W", "replyto": "PLva6Rol4W", "signatures": ["ICLR.cc/2026/Conference/Submission15863/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15863/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission15863/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763696824767, "cdate": 1763696824767, "tmdate": 1763696824767, "mdate": 1763696824767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}