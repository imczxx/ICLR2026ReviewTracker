{"id": "PTDaG0NytX", "number": 13999, "cdate": 1758226668590, "mdate": 1763728206057, "content": {"title": "Optimized Minimal 4D Gaussian Splatting", "abstract": "4D Gaussian Splatting has emerged as a new paradigm for dynamic scene representation, enabling real-time rendering of scenes with complex motions. However, it faces a major challenge of storage overhead, as millions of Gaussians are required for high-fidelity reconstruction. While several studies have attempted to alleviate this memory burden, they still face limitations in compression ratio or visual quality.\nIn this work, we present $\\textit{OMG4}$ (Optimized Minimal 4D Gaussian Splatting), a framework that constructs a compact set of salient Gaussians capable of faithfully representing 4D Gaussian models.\nOur method progressively prunes Gaussians in three stages: (1) $\\textit{Gaussian Sampling}$ to identify primitives critical to reconstruction fidelity, (2) $\\textit{Gaussian Pruning}$ to remove redundancies, and (3) $\\textit{Gaussian Merging}$ to fuse primitives with similar characteristics.\nIn addition, we integrate implicit appearance compression and generalize Sub-Vector Quantization (SVQ) to 4D representations, further reducing storage while preserving quality.\nExtensive experiments on standard benchmark datasets demonstrate that $\\textit{OMG4}$ significantly outperforms recent state-of-the-art methods, reducing model sizes by over 60\\% while maintaining reconstruction quality.\nThese results position $\\textit{OMG4}$ as a significant step forward in compact 4D scene representation, opening new possibilities for a wide range of applications.", "tldr": "", "keywords": ["dynamic scene representation", "compression", "4D Gaussian Splatting"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6676717991c4c208b50a2aa908aea3e597c70a84.pdf", "supplementary_material": "/attachment/96589d3bae9b3171ef71cec6df4ae20103c0de43.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a pipeline to compress Gaussian Splatting based 4D dynamic spatial representations. The method concludes several stages, as selecting salient Gaussians based on Static-Dynamic scores, pruning low-importance primitives, merging similar Gaussians within grids, and compressing attributes with MLPs and arithmetic compressors. The resulting 4DGS can provide a highly compact storage size while maintaining the visual quality. This pipeline is applicable to multiple off-the-shelf baselines and achieves compactness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. One impressive point of this work is that this paper proposes a universally applicable pipeline as a post-processing for multiple 4DGS representations. This highlights the method's generality, which I think is meaningful for this task.\n2. The SD-Score, presenting the spatial and temporal sensitivity, guides the pipeline to distinguish the important Gaussians and provides effective compression.\n3. The performances are impressive compared to the baselines, achieving a low storage size of several MB to represent a 4D dynamic space."}, "weaknesses": {"value": "1. Although the proposed method provides superior compactness, the proposed components in the method are not very impressive in the aspect of novelty.  The Gaussian importance score, MLP based color coding, and post-processing compressors are upgraded from 3DGS compression techniques or previously established in other 4D Gaussian compression works. These make the novelty of this work weaker, and the authors fail to distinguish their designs from the previous techniques. My own opinion is that the author can emphasize more on the generality of the proposed method: The authors can establish the whole pipeline as a more robust and general post-processing progress to all (or most of) the previous 4DGS baselines, and investigate how to specifically implement the proposed method to each distinct baselines and fit the special property of each method. \n2. Another concern is a highly engineered pipeline with many hyperparameters. The whole pipeline includes multiple thresholds, quantiles, grid sizes and merge / iteration budgets. These elements raise concerns on the robustness of the proposed method. Naturally, some scenes require high quantity of Gaussians for representation, while some other may not. Some scenes contain complex lattice or textures. The discussion or ablation on these issues should be provided for a solid presentation."}, "questions": {"value": "Regarding the weaknesses listed above:\n1. The authors are suggested to provide more clarifications on the generality of the proposed method, such as elaborating on how the proposed pipeline fits different baselines and analysis on the effectiveness on them. The authors are recommended to provide further attempts on other baselines and clarify the effectiveness, and in which cases the method fits better.\n2. The authors are recommended to provide more justifications and ablations on the hyperparameters, and how these hyperparameters are affecting the final compression performance. Are these hyperparameters tuned for each scene or each dataset? \n3. Some previous 4D reconstruction methods use zero-shot dynamic-static distinguishment [R1, R2]. Can they benefit the proposed pipeline? These methods should also be considered or discussed.\n\n[R1] Dai, P., Zhang, P., Dong, Z., Xu, K., Peng, Y., Ding, D., Shen, Y., Yang, Y., Liu, X., Lau, R.W. and Xu, W., 2025. 4d gaussian videos with motion layering. ACM Transactions on Graphics (TOG), 44(4), pp.1-14.\n\n[R2] Liu, Z., Hu, Y., Zhang, X., Song, R., Shao, J., Lin, Z. and Zhang, J., 2024. Dynamics-Aware Gaussian Splatting Streaming Towards Fast On-the-Fly 4D Reconstruction. arXiv preprint arXiv:2411.14847.\n\nI am looking forward to the authors' reply on the above issues, based on which I am willing to further adjust my review."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JD75sUhaDG", "forum": "PTDaG0NytX", "replyto": "PTDaG0NytX", "signatures": ["ICLR.cc/2026/Conference/Submission13999/Reviewer_3wjx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13999/Reviewer_3wjx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761374015551, "cdate": 1761374015551, "tmdate": 1762924495178, "mdate": 1762924495178, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "OMG4 (Optimizing Minimal 4D Gaussian Distributions) constructs a compact set of salient Gaussians that faithfully represent the 4D Gaussian model.\nThe method progressively prunes Gaussians in three stages:\n(1) **Gaussian sampling** to identify primitives critical to reconstruction fidelity,\n(2) **Gaussian pruning** to remove redundancies, and\n(3) **Gaussian merging** to fuse primitives with similar characteristics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The three strategies proposed in the paper are interesting, and the writing is well-organized.\n2. The proposed method achieves a significant reduction in storage while maintaining comparable performance.\n3. The paper provides extensive visualization videos."}, "weaknesses": {"value": "1. The experiments are too limited — most evaluations are conducted only on the N3DV dataset. Testing on large-scale dynamic scenes such as NVIDIA[1], Dynamic3DGS[2], or VRU [3] would make the results much more convincing.\n2. The proposed compression and pruning strategies are all based on 4DGS; however, 4DGS has inherent limitations, such as its inability to handle fast motion or long-sequence dynamic videos. Therefore, this method is somewhat restricted in its applicability.\n\nIf the authors can demonstrate strong experimental results (both quantitative and qualitative) on large-scale datasets, this paper would deserve a score of 8 and be worth accepting.\n\n[1] Neural Trajectory Fields for Dynamic Novel View Synthesis\n\n[2] Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis\n\n[3] Swift4D: Adaptive divide-and-conquer Gaussian Splatting for compact and efficient reconstruction of dynamic scene"}, "questions": {"value": "1. How long does the model take to train?\n2. Is the model initialized using Gaussian points from all frames to represent the entire scene, followed by the sampling, merging, and pruning strategies? If so, wouldn’t this result in high GPU consumption and require long training times — possibly several hours?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yinJSakFLk", "forum": "PTDaG0NytX", "replyto": "PTDaG0NytX", "signatures": ["ICLR.cc/2026/Conference/Submission13999/Reviewer_jaTu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13999/Reviewer_jaTu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761549304775, "cdate": 1761549304775, "tmdate": 1762924494442, "mdate": 1762924494442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OMG4 (Optimized Minimal 4D Gaussian Splatting), a novel framework for compact and high-fidelity dynamic scene representation. While prior 4D Gaussian Splatting (4DGS) approaches have achieved impressive real-time rendering results, they typically require millions of Gaussians, leading to significant memory and storage overheads."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed Static–Dynamic Score (SD-Score) is an elegant and effective contribution that unifies spatial and temporal importance estimation for Gaussian primitives.\n- The multi-stage pipeline (Sampling → Pruning → Merging) is conceptually simple yet powerful, providing interpretability and modular extensibility.\n- Extending Sub-Vector Quantization (SVQ) to the 4D domain and introducing a staged quantization strategy for stability is a non-trivial and meaningful extension of prior work.\n- The paper is clearly written, with strong motivation and logical flow across sections."}, "weaknesses": {"value": "(1) Experimental depth and comparison limitations:\n- While the reported compression ratio and reconstruction quality are impressive, the paper could benefit from a more diverse set of baselines, including recent hybrid deformation-based approaches (e.g., ADC-GS or D-NeRF variants).\n- It remains unclear how OMG4 scales with scene complexity or duration—e.g., whether compression quality degrades for highly non-rigid motions or long temporal spans.\n\n(2) Computational cost and runtime:\n- The paper focuses primarily on memory efficiency, but does not clearly state the training or optimization time overhead introduced by multi-stage pruning and merging.\n- It would strengthen the work to clarify whether OMG4 maintains real-time rendering throughput post-compression, and how merging affects rendering speed and differentiability.\n\n(3) Generality of SVQ extension:\n- The adaptation of SVQ to 4D is interesting, but the explanation of why staged quantization improves stability is somewhat qualitative.\n- A quantitative analysis (e.g., convergence behavior, quantization error curves) would substantiate this claim."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "HPFqp9ahSZ", "forum": "PTDaG0NytX", "replyto": "PTDaG0NytX", "signatures": ["ICLR.cc/2026/Conference/Submission13999/Reviewer_ZNMV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13999/Reviewer_ZNMV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13999/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757603094, "cdate": 1761757603094, "tmdate": 1762924493559, "mdate": 1762924493559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We are grateful to all the reviewers for their reviews and invaluable feedback. Before responding to each review in detail, we first address several common questions in this general response. For better assessment, we provide additional qualitative results at [link]( https://anonymous.4open.science/r/OMG4_Qualitative).\n## **Generality of the proposed method**\nAs shown in Tab. 3 in the manuscript, we also applied the proposed method to FreeTimeGS (FTGS) [Ref 1]. We reduced the storage requirement of FTGS by 90\\%, demonstrating the generality of OMG4. To further secure the robustness of OMG4, we applied our method to SpaceTimeGaussian (STG) [Ref 2] and evaluated it on the N3DV dataset. The aggregated results are reported in the table below. On STG, OMG4 reduces the model size by 88\\% with comparable reconstruction quality. As OMG4 aims to effectively reduce the number of primitives required for modeling the scene, it can be broadly adopted to various approaches, including RealTime4DGS, FTGS, and STG. \n| Method       | PSNR ↑ | SSIM ↑ | LPIPS ↓ | # Gaussians ↓ | Storage (MB) ↓ |\n|-------------|--------|--------|---------|----------------|----------------|\n| STG         | 32.00      | 0.948      | 0.046       | 1,289,577              | 200              |\n| STG + OMG4  | 31.72      | 0.945      | 0.049       | 863,716              | 24.38              |\n\n[Ref 1] Wang, Yifan, et al. \"FreeTimeGS: Free Gaussians at Anytime and Anywhere for Dynamic Scene Reconstruction.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2025.\n\n[Ref 2] Li, Zhan, et al. \"Spacetime gaussian feature splatting for real-time dynamic view synthesis.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024."}}, "id": "0C7Al7FjDR", "forum": "PTDaG0NytX", "replyto": "PTDaG0NytX", "signatures": ["ICLR.cc/2026/Conference/Submission13999/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13999/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13999/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763727806429, "cdate": 1763727806429, "tmdate": 1763727806429, "mdate": 1763727806429, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}