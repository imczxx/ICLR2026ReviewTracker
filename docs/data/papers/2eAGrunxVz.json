{"id": "2eAGrunxVz", "number": 14944, "cdate": 1758245883736, "mdate": 1763735263726, "content": {"title": "Spherical Watermark: Encryption-Free, Lossless Watermarking for Diffusion Models", "abstract": "Diffusion models have revolutionized image synthesis but raise concerns around content provenance and authenticity. Digital watermarking offers a means of tracing generated media, yet traditional schemes often introduce distributional shifts and degrade visual quality. Recent lossless methods embed watermark bits directly into the latent Gaussian prior without modifying model weights, but still require per-image key storage or heavy cryptographic overhead. In this paper, we introduce Spherical Watermark, an encryption‐free and lossless watermarking framework that integrates seamlessly with diffusion architectures. First, our binary embedding module mixes repeated watermark bits with random padding to form a high-entropy code. Second, the spherical mapping module projects this code onto the unit sphere, applies an orthogonal rotation, and scales by a chi-square-distributed radius to recover exact multivariate Gaussian noise. We theoretically prove that the watermarked noise distribution preserves the target prior up to third-order moments, and empirically demonstrate that it is statistically indistinguishable from a standard multivariate normal distribution. Adopting Stable Diffusion, extensive experiments confirm that Spherical Watermark consistently preserves high visual fidelity while simultaneously improving traceability, computational efficiency, and robustness under attacks, thereby outperforming both lossy and lossless approaches.", "tldr": "Employing a novel spherical mapping mechanism, we propose a novel lossless watermarking scheme for text-to-image diffusion models.", "keywords": ["AIGC Watermarking; Diffusion Models;"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0a42a62884feb8cac54d4edc6aa4fe1038434aaf.pdf", "supplementary_material": "/attachment/cd1b61038937018bbb86a37f55f26932e30758ca.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Spherical Watermark, a novel encryption-free and lossless watermarking framework for diffusion models designed to overcome the drawbacks of existing methods that either degrade image quality or rely on computationally expensive cryptography. The core contribution is an elegant method that embeds a binary watermark into the model's initial Gaussian noise latent vector. This is achieved first through a binary embedding module that creates a high-entropy bitstream, which is then processed by a spherical mapping module that projects it onto a unit sphere, applies an orthogonal rotation, and scales it with a chi-square distributed radius. This process yields a noise vector that is statistically indistinguishable from a standard Gaussian distribution, a claim supported by theoretical proofs. The framework's key contributions include this new mapping technique, the elimination of cryptographic overhead, and state-of-the-art performance. Experiments show that Spherical Watermark preserves high visual fidelity while offering superior robustness against attacks and a dramatic improvement in computational efficiency, with watermark extraction being orders of magnitude faster than its closest lossless competitor."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe core methodology is novel and elegant, using spherical geometry to transform a binary watermark into statistically standard Gaussian noise, which successfully bypasses the need for complex and computationally heavy cryptographic components used in prior lossless methods.\n2.\tThe paper is supported by a strong theoretical foundation, providing formal proofs that the watermarked noise distribution matches a true Gaussian prior up to the third-order moments by leveraging concepts like spherical 3-designs.\n3.\tThe method demonstrates exceptional performance and efficiency, as it is extremely fast in the extraction phase (approximately four orders of magnitude faster than its closest competitor), shows superior robustness against various attacks, and maintains high fidelity and undetectability.\n4.\tIt offers excellent scalability and capacity, handling large watermark payloads without the performance degradation seen in competing approaches, which makes it highly flexible for applications requiring the embedding of rich metadata."}, "weaknesses": {"value": "1.\tThe comparison of computational efficiency should be included in the main paper instead of the appendix as it can effectively demonstrate the advantages of this method compared to PRC watermark.\n2.\tLack of experimental comparison on newer models such as FLUX and Qwen image.\n3.\tDoes this method rely on the accuracy of inversion? I want to know if different inversion methods will affect the accuracy of extraction, and if the sampling step size will also have an impact. In other words, when will the deviation between the latent obtained from inversion and the latent obtained from the original embedding render this method ineffective?"}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "zRfY2zlvyB", "forum": "2eAGrunxVz", "replyto": "2eAGrunxVz", "signatures": ["ICLR.cc/2026/Conference/Submission14944/Reviewer_Hgmm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14944/Reviewer_Hgmm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761483887525, "cdate": 1761483887525, "tmdate": 1762925283628, "mdate": 1762925283628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Responses and Revision Summary"}, "comment": {"value": "We sincerely thank all reviewers for their valuable comments and constructive suggestions. We have revised the paper accordingly, with all updates highlighted in **blue** in the revised version. The feedback has greatly helped us improve the clarity, completeness, and experimental evaluation of our work. We summarize the main changes below:\n\n1. **Robustness under re-generation and editing attacks (Appendix F.2).**  \n   Following the comments from reviewers *YSkV*, *vTJw*, and *K12q*, we added comprehensive experiments on re-generation attacks (Regen-Diff, Rinse-2xDiff, Regen-VAE) and image editing (MagicBrush, UltraEdit, InstructPix2Pix, GAN-edit). These results show that our method remains traceable under these attacks.\n\n2. **Evaluation on newer generative models (Appendix F.1).**  \n   As suggested by reviewer *Hgmm*, we extended our study to modern latent-space diffusion architectures, including **Stable Diffusion v3** and **FLUX.1-DEV**, demonstrating that our approach generalizes well to transformer-based diffusion models.\n\n3. **Ablation studies on sampling configurations and inversion accuracy (Sec. 4.3 and Appendix F.5).**  \n   As suggested by reviewer *Hgmm*, we added ablations covering (i) different ODE solvers, (ii) generation/inversion timesteps, and (iii) latent-space perturbations. These results show that the extraction accuracy is stable across solvers, timestep choices, and moderate inversion errors.\n\n4. **Improved writing quality and organization.**  \n   We refined our paper in terms of clarity and formatting, following reviewer suggestions.\n\nWe appreciate the reviewers’ thoughtful feedback and positive recognition. Their suggestions significantly strengthened this paper, and we hope the revisions adequately address all concerns."}}, "id": "CCPl8m7W3t", "forum": "2eAGrunxVz", "replyto": "2eAGrunxVz", "signatures": ["ICLR.cc/2026/Conference/Submission14944/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14944/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14944/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763735364089, "cdate": 1763735364089, "tmdate": 1763735364089, "mdate": 1763735364089, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Spherical Watermark, an encryption-free and lossless watermarking approach designed for diffusion models. It focuses on tracing and verifying the provenance and authenticity of AI-generated images, addressing recognized limitations of current watermarking techniques, such as quality degradation, detectable shifts, and key management complexity. The method embeds watermarks into the latent noise with indistinguishable Gaussian statistics, utilizing a high-entropy binary embedding and spherical mapping mechanism. The framework maintains perfect image fidelity and allows rapid watermark extraction without modifying the diffusion model. Empirical results demonstrate strong robustness against common image manipulations and adversarial attacks, competitive and often superior to prior approaches. The paper also emphasizes ethical considerations and provides theoretical analysis for transparency and reproducibility."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed watermarking technique preserves image quality, making watermarked and non-watermarked images visually indistinguishable. The framework is efficient, enabling fast watermark extraction with no need for per-image keys or model modifications.\n- Robustness is demonstrated against a wide range of image processing operations and adversarial settings.\n- The solution is well-supported with both theoretical analysis and comprehensive experiments.\n- The method is deployable on mainstream diffusion architectures and easy to integrate in practice. The authors address the ethical implications of watermarking and ensure reproducibility standards."}, "weaknesses": {"value": "- The method may have limitations when facing extremely sophisticated adversarial attacks specifically designed to break watermark recovery.\n- There is limited discussion on extending the approach to content editing or direct forgeries, such as partial GAN-based manipulations.\n- Some implementation parameters may require careful adjustment for different generative scenarios and applications."}, "questions": {"value": "This is an interesting paper. So I want to know what the main motivation is for the introduction of the spherical mapping module in the context of watermark embedding. Secondly, if this method is so promising, are there any limitations for this method to scale up in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "FfUuQktdpZ", "forum": "2eAGrunxVz", "replyto": "2eAGrunxVz", "signatures": ["ICLR.cc/2026/Conference/Submission14944/Reviewer_K12q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14944/Reviewer_K12q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556123171, "cdate": 1761556123171, "tmdate": 1762925282642, "mdate": 1762925282642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a training-free and lossless diffusion watermarking method that encodes a binary watermark message into the initial noise of a diffusion model. The method consists of two main transformation steps. First, the message is encrypted by mixing it with random padding through a structured binary embedding matrix. Second, the resulting vector is projected onto a unit sphere and then transformed by a random orthogonal rotation followed by a radius rescaling using a chi distribution. This produces a final watermark vector that closely matches the distribution of standard Gaussian noise, making it suitable as the initial noise for diffusion models and statistically indistinguishable from normal noise. The method is compatible with multiple diffusion models, does not modify model parameters, and enables fast decoding."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well motivated and logically structured. The paper addresses the problem of embedding watermarks in diffusion-generated images in a clean and motivated way. \n2. The proposed method is reasonable and effective. The approach avoids any model fine-tuning or training and leverages statistical geometry (spherical design + chi rescaling) to achieve high-quality watermarking while maintaining indistinguishability.\n3. The experiments are comprehensive. The paper evaluates watermark accuracy and detectability under different attacks. The ablation study also demonstrates the effectiveness of their key designs.\n4. The paper is easy to read and well-organized, with clear diagrams and concrete definitions."}, "weaknesses": {"value": "1. Lack of diffusion-based attacks: While the paper evaluates robustness under post-processing and adversarial attacks, it does not include experiments on regeneration or rinse-based attacks (e.g., re-diffusion or editing using other diffusion models), which have been recently identified as strong attacks for watermark removal. I suggest the authors refer to arXiv:2401.08573 and consider incorporating some of their benchmarking strategies.\n\n2. Storage overhead for decoding: To decode the watermark, the user must store the embedding matrix $T$ (specifically, the sparse matrix \n$R$) and the rotation matrix $C$. Since $R \\in \\mathbb{F}_2 ^{N l_m \\times l_r}$ and $C \\in \\mathbb{R}_2 ^{l_x \\times l_x}$, the memory cost could be significant, especially when generating high-resolution images with large latent dimensions. A naïve implementation would incur nontrivial storage. Discussion about the storage overhead should be included in the main text."}, "questions": {"value": "1. Have you evaluated your method under regeneration-based or rinse attacks? If not, can you comment on the potential vulnerability under such transformations?\n\n2. Could you elaborate on whether $T$ and $C$ are reused across images, or whether they are derived per image? What is the typical memory overhead for storing or generating them in a realistic deployment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rG81BHxBtD", "forum": "2eAGrunxVz", "replyto": "2eAGrunxVz", "signatures": ["ICLR.cc/2026/Conference/Submission14944/Reviewer_vTJw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14944/Reviewer_vTJw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761723712814, "cdate": 1761723712814, "tmdate": 1762925282265, "mdate": 1762925282265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical need for provenance in diffusion-generated images by proposing a new watermarking scheme. The authors introduce \"Spherical Watermark,\" a lossless and encryption-free framework that embeds a binary watermark into the initial Gaussian noise by mixing it with random padding, projecting it onto a unit sphere, applying an orthogonal rotation, and scaling it with a chi-square-distributed radius. The method is theoretically proven and empirically demonstrated to be statistically indistinguishable from standard Gaussian noise, while also being computationally efficient and robust to various post-processing and adversarial attacks, outperforming prior lossless methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "S1 (technical novelty): The proposed spherical mapping module is a novel technical contribution. It provides a clear mathematical pipeline to transform a structured binary vector into a vector that is statistically indistinguishable from a standard Gaussian distribution.\n\nS2 (theoretical foundation): The \"lossless\" claim is strongly supported by a rigorous theoretical analysis. The paper proves that the watermarked noise distribution matches a true Gaussian prior up to third-order moments by leveraging the properties of spherical 3-designs.\n\nS3 (strong performance): The paper shows clear improvements in efficiency and robustness over baseline methods. The method is also shown to be effectively indistinguishable from the original, non-watermarked distribution.\n\nS4 (comprehensive experiments): The ablation studies clearly justify the design, demonstrating the necessity of both the binary embedding and spherical mapping modules for undetectability and robustness, respectively."}, "weaknesses": {"value": "W1 (motivation): The paper claims that existing methods require per-image key storage or cryptographic overhead, but this method also has cryptographic overhead (Eq. 13). Hence, The \"encryption-free\" claim is potentially misleading.\n\nW2 (scope of robustness): The paper does not explicitly test against attacks that are more specific to generative models, such as watermark destruction via diffusion-inversion and re-generation with different noise. The authors have acknowledged that resisting editing/forgery is a limitation but is out of scope.\n\nW3 (missing related work): Some recent works are not discussed, such as [1,2].\n\n- [1] Wei et al. Robust watermarking for diffusion models: A unified multi-dimensional recipe. 2025.\n- [2] Wang et al. SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models. 2025."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YrEnVqyyXn", "forum": "2eAGrunxVz", "replyto": "2eAGrunxVz", "signatures": ["ICLR.cc/2026/Conference/Submission14944/Reviewer_YSkV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14944/Reviewer_YSkV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882789651, "cdate": 1761882789651, "tmdate": 1762925281861, "mdate": 1762925281861, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}