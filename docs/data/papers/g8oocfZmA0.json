{"id": "g8oocfZmA0", "number": 13268, "cdate": 1758215856436, "mdate": 1759897450571, "content": {"title": "EVA-Flow: Environment-Aware Flow Matching for Unified 3D Molecular Conformation Generation", "abstract": "Predicting the 3D geometry of molecules is central to applications in drug discovery, materials design, and molecular modeling. However, molecular geometry can change dramatically across environments (e.g., crystal lattice versus protein binding pocket). Existing generative approaches are typically environment-agnostic or require separate models for each environment, which limits generalization. We introduce EVA-Flow, a unified framework for environment-aware conformation generation. EVA-Flow combines a variational autoencoder with a flow matching decoder and incorporates environment information through a learned embedding. Across four environments including vacuum, protein-ligand docking, solvation, and crystal packing, EVA-Flow substantially improves generation accuracy through pretraining and unification. Analysis of shared molecules that appear in multiple environments further shows that EVA-Flow generates distinct, environment-specific conformations rather than memorizing a single geometry.", "tldr": "EVA-Flow is a unified VAE + flow-matching model that generates environment-aware 3D molecular conformations across vacuum, protein–ligand docking, solvation, and crystal packing.", "keywords": ["Flow matching", "Conditional generative modeling", "Geometric deep learning", "3D molecular conformation generation"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6f1e54d24ea6bf3705bc16897ab21b4ec2c456f7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work argues that previous molecular conformation generation methods lack the ability to model environment-conditioned conformations. To address this limitation, the authors propose **EVA-Flow**, a method that generates conformations under four environmental conditions: vacuum, protein–ligand docking, solvation, and crystal packing. The overall framework integrates an **environment embedding module**, a **molecule–environment interaction encoder**, and a **flow matching decoder**."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The consideration of environment-conditioned molecular conformations introduces a certain level of novelty to the study.\n2. The manuscript is clearly written and logically organized.\n3. The overall framework, a VAE with an encoder and an FM decoder, is newly introduced in this area. The ablation study in Section 4.5 provides strong evidence supporting the effectiveness of the framework and the combined loss functions."}, "weaknesses": {"value": "1. The encoder does not appear to be SE(3)-invariant with respect to molecular positions. In other words, the latent representation $z$ should remain unchanged when the molecular coordinates $x \\in \\mathbb{R}^{N\\times3}$ are rotated by a rotation matrix $R \\in \\mathbb{R}^{3\\times3}$.\n2. There are no additional baselines for comparison. I believe there may exist well-established methods tailored for each environment-conditioned scenario. For example, in **Environment: Vacuum** (using the GEOM-Drugs dataset), is the setting essentially the same as in many previous works [1, 2, 3]? If there is no substantial difference, then the results reported in **Table 1 (Environment: Vacuum)** may not be particularly meaningful. The same concern applies to **Environment: Docking** (using the PDBBind-v2020 dataset) [4].\n3. The “pretrain-then-finetune” paradigm has long been a standard practice in most areas. Although the experiments show that both **Pretrain + Individual** and **Pretrain + Unified** setups consistently outperform the **Unified (no pretraining)** and **Individual** baselines, I view this more as a conventional approach for improving results rather than a major contribution worth emphasizing.\n\n[1] Xu M, Yu L, Song Y, et al. GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation[C]//International Conference on Learning Representations.\n\n[2] Wang Y, Elhag A A A, Jaitly N, et al. Swallowing the Bitter Pill: Simplified Scalable Conformer Generation[C]//International Conference on Machine Learning. PMLR, 2024: 50400-50418.\n\n[3] Hassan M, Shenoy N, Lee J, et al. Et-flow: Equivariant flow-matching for molecular conformer generation[J]. Advances in Neural Information Processing Systems, 2024, 37: 128798-128824.\n\n[4] Corso G, Deng A, Polizzi N, et al. Deep Confident Steps to New Pockets: Strategies for Docking Generalization[C]//The Twelfth International Conference on Learning Representations."}, "questions": {"value": "1. How can you demonstrate that your framework performs better than an Equivariant Diffusion or Flow Matching method [1, 3] augmented with a conditioning module (e.g., adding your environment embedding to the model inputs)? I understand that this is not a strictly fair comparison and that there are no official results available. However, considering **Weakness 2**, in **Environment: Vacuum** (GEOM-Drugs), your results are much worse than those of ET-Flow [3].\n2. What is the efficacy of the method, given that the main results in Table 1 were obtained from the large-sized (68.3M) model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H61nrUY7fG", "forum": "g8oocfZmA0", "replyto": "g8oocfZmA0", "signatures": ["ICLR.cc/2026/Conference/Submission13268/Reviewer_PeAA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13268/Reviewer_PeAA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13268/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761038547773, "cdate": 1761038547773, "tmdate": 1762923942874, "mdate": 1762923942874, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EVA-Flow, a unified framework for environment-aware conformation generation.\n\nIn particular, EVA-Flow couples a VAE with an environment-conditioned flow-matching decoder and a learned base distribution, thereby overcoming the limitations of existing environment-agnostic methods.\n\nExperiments demonstrate that EVA-Flow truly generates distinct conformations for the same molecule in different environments."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. Considering that the same molecule can adopt different conformations in different environments, it is very necessary and meaningful to construct such a unified framework for environment-aware conformation generation.\n\n2. The paper is well-written, and the method introduction is quite detailed."}, "weaknesses": {"value": "1. As mentioned in Section 2.2, both the Encoder and the Base Distribution Network are based on GCN, indicating that EVA-Flow lacks SE(3) equivariance—an essential property for conformation generation.\n\n2. The paper claims to construct a unified framework for conformation generation across different environments. However, the experimental results indicate that the best performance is achieved only through fine-tuning the pre-trained model separately for each scenario, thereby failing to support the claimed contribution.\n\n3. The four environments mentioned in this paper are already well-defined, and numerous methods have been proposed for them. However, the paper fails to compare EVA-Flow with any of these previous methods, which is clearly inappropriate."}, "questions": {"value": "1. For Table 2, I would like to know which training strategy is used to obtain those generated conformations. Is it Pretraining + Individual Finetuning, Pretraining + Unified Finetuning, Unified Finetuning, or Individual Finetuning?\n\n2. I would like to know whether you provide code, as this is crucial for reproducibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LxhLaq7txd", "forum": "g8oocfZmA0", "replyto": "g8oocfZmA0", "signatures": ["ICLR.cc/2026/Conference/Submission13268/Reviewer_Vh2w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13268/Reviewer_Vh2w"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13268/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761499978201, "cdate": 1761499978201, "tmdate": 1762923942142, "mdate": 1762923942142, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EVA-Flow, a hybrid model combining a variational autoencoder with a flow-matching decoder, designed to recover 3D molecular conformations from 2D molecular graphs. Existing methods often overlook the critical dependence of molecular conformation on the surrounding environment (e.g., crystal lattices, protein binding pockets), limiting their generalizability. EVA-Flow addresses this limitation through two core innovations: (1) It integrates environmental information as a conditional embedding within a flow-matching decoder, endowing the model with environment-aware generation capabilities; (2) It employs a graph convolutional network-based encoder to fuse molecular and environmental information into a shared latent space, effectively capturing their feature relationships.\nExperimental results demonstrate that EVA-Flow achieves superior performance on both Vacuum and Protein-Ligand Docking datasets compared to ETFlow and DiffDock. The model's performance is further enhanced through pre-training followed by unified fine-tuning. Visualization analyses confirm that EVA-Flow can generate distinct conformations for the same molecule in different environments, validating its robust environment-aware capabilities and generalizability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The work is innovative in its explicit integration of environmental information into conformation generation, proposing a novel hybrid architecture based on a variational autoencoder and flow matching.\n2. The model design is sound, utilizing a graph convolutional network to effectively fuse molecular and environmental features within a latent space while preserving their structural relationships.\n3. The comprehensive experimental validation across multiple datasets, supplemented by visualization analysis, lends credibility to the reported results.\n4. This research provides a more generalizable tool for molecular conformation generation, with significant potential for practical applications in drug and crystal design."}, "weaknesses": {"value": "1. The experimental configuration is suboptimal. The \"Experiments\" section lacks direct comparisons with key contemporary models. Using DiffDock and ETFlow merely as reference points, rather than in a rigorous, head-to-head benchmark, makes it difficult to accurately assess EVA-Flow's performance advantages.\n2. The model diagram (Figure 1) is insufficiently detailed. While it illustrates the overall EVA-Flow architecture, it fails to clearly depict how the four loss functions (Equations 8-11) relate to specific model components, hindering understanding of the training process.\n3. The conclusion is underdeveloped. It primarily reiterates the main contributions and findings without a critical discussion of the study's limitations or a clear, actionable outlook for future work.\n4. The placement and content of the related work section are problematic. Positioning it after the methodology section (\"Environment-Aware Flow Matching\") deviates from standard academic structure. Furthermore, the section itself does not adequately articulate the primary motivation for EVA-Flow or the core challenges and innovations in its design."}, "questions": {"value": "1. The \"Experiments\" section should be revised to include direct, comprehensive comparisons with state-of-the-art models to more convincingly demonstrate EVA-Flow's advantages.\n2. Figure 1 should be revised to explicitly include and annotate the loss terms, making the training mechanism more transparent.\n3. The \"Conclusion\" should be expanded to include a summary of the study's limitations and to propose specific, feasible directions for future research.\n4. The \"Related Work\" section should be relocated to follow the \"Introduction\" and precede the methodology section. Its content should be revised to clearly establish the research gap, the motivation for EVA-Flow, and a detailed discussion of the core challenges and how the proposed innovations address them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bEjvtAtzfa", "forum": "g8oocfZmA0", "replyto": "g8oocfZmA0", "signatures": ["ICLR.cc/2026/Conference/Submission13268/Reviewer_tjH8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13268/Reviewer_tjH8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13268/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878107510, "cdate": 1761878107510, "tmdate": 1762923941873, "mdate": 1762923941873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}