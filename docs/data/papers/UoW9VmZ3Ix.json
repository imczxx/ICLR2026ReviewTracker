{"id": "UoW9VmZ3Ix", "number": 3237, "cdate": 1757383941277, "mdate": 1759898100629, "content": {"title": "Hierarchical Fusion with Dual Contrast for Incomplete Multi-View Representation Learning", "abstract": "Real-world multi-view data often suffers from partial incompleteness, posing challenges to traditional clustering methods. Existing approaches face two key limitations: (1) rigid fusion strategies that fail to dynamically select complementary views, and (2) contrastive learning methods that struggle to capture high-order dependencies and suppress intra-view redundancy. To address these issues, we propose DFHDC, a novel framework integrating dendritic fusion and hierarchical dual contrast mechanisms to dynamically select optimal\n view combinations and construct multi-level semantic fusion pathways. The dendritic fusion strategy progressively fuses views in a bottom-up manner to maximize inter-view complementarity, while the hierarchical dual contrast mechanism performs contrastive learning in both local and global semantic spaces, simultaneously maximizing cross-view mutual information and minimizing intra-view redundancy, thereby enhancing the consistency and discriminability of the learned representations. Additionally, the framework incorporates a view-specific fine-tuning strategy to implicitly recover missing views. Experiments show DFHDC outperforms state-of the-art methods, especially under high missing rates, validating its effectiveness in incomplete multi-view learning.", "tldr": "DFHDC", "keywords": ["Incomplete multi-view clustering;Dendritic fusion;Hierarchical dual contrast"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/661f895b89f66e275fec7d438eb872cd5b365219.pdf", "supplementary_material": "/attachment/d62c447a76c2f718b40e7024901104b98c3bd340.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces DFHDC, a new framework for deep incomplete multi-view clustering (DIMC). The method aims to learn consistent representations from incomplete multi-view data by addressing two key limitations of existing work: rigid fusion strategies and limitations of contrastive learning. The framework's core components are a Dendritic Fusion (DF) mechanism, which performs a bottom-up, hierarchical fusion of views by iteratively pairing the most complementary representations, and a Dual Contrast mechanism. This dual contrast operates at both a local (view-specific) level, where it aims to maximize mutual information ($L_{MI}$) while minimizing feature redundancy (${L}_{{red}}$), and a global level, where it aligns view-specific representations with the fused common representation. The model also incorporates a view-specific fine-tuning network to implicitly recover missing data. The authors conduct experiments on several multi-view datasets to demonstrate the performance under high missing rates."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a novel optimization objective for local contrastive learning, $L_{LOC}$. By explicitly modeling both the maximization of mutual information ($L_{MI}$) and the minimization of intra-view feature redundancy ($L_{red}$), the framework attempts to learn representations that are not only consistent but also disentangled and efficient. \n- The authors conduct a set of experiments, including detailed ablation studies and t-SNE visualizations. These experiments provide insight into how the framework's components interact and how the learned representations evolve during training to form distinct clusters."}, "weaknesses": {"value": "- As the core innovation mentioned in the paper, the significance of the Dendritic Fusion (DF) mechanism  is unclear. Aside from its complementary description, the fusion process ultimately produces a feature $\\mathbf{H} = \\alpha_1\\mathbf{Z}_1 + \\cdots + \\alpha_i\\mathbf{Z}_i$, where $\\alpha_i$ is a weight parameter. The practical meaning of these weights is not as intuitive as the attention scores generated by an Attention module. In particular, DF has a critical issue: when the number of views is $2^k$, the global representation degenerates into a simple average. This raises the question of whether this algorithm is nonsensical. Furthermore, in the ablation study, the improvement brought by the DF mechanism is not significant; for example, on Hdigit and 100leaves, most metric improvements are within the 0.2 range.\n- The local and global contrastive objectives mentioned in the paper are not unique. A similar architecture has been proposed in Zhang et al. (2024), which also features a fusion module to obtain a global feature for contrastive learning. Particularly, on datasets with only two views, the DF mechanism degenerates into a simple average. Therefore, the performance improvement over other SOTA methods is likely attributable to $L_{LOC}$. Within $L_{LOC}$, the $L_{MI}$ component was previously proposed in DCP (Lin et al., 2022). Consequently, the primary innovation appears to be concentrated in the redundancy loss, $L_{red}$, and further experiments are needed to analyze its specific contribution.\n- There are concerns about the suppression of baseline performance in the main experiments. For instance, on the MNIST_USPS dataset (complete view scenario), the MCAC (Zhang & Zhu, 2023)method reported ACC=99.37, NMI=98.22, and ARI=98.61 in its original publication (Table 4), which is actually superior to the performance of the method proposed in this paper.\n- Many of the selected baselines in this paper have been tested on common benchmark datasets such as Scene15, Reuters, and Caltech101. It is unclear why the authors did not select these datasets, which would facilitate easier comparison. Additionally, the reported performance improvements are not significant and may very well fall within the margin of error. For example, on the Hdigit dataset, the proposed method's improvement over the second-best method is only in the range of +-0.05 to 0.15, a situation that also occurs on the MNIST_USPS dataset.\n\n**References**\n\n[1]Lin, Y., Gou, Y., Liu, X., Bai, J., Lv, J., and Peng, X. (2022). Dual Contrastive Prediction for Incomplete Multi-View Representation Learning. *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 45(4):4447-4461.\n\n[2]Zhang, Y., Lin, Y., Yan, W., Yao, L., Wan, X., Li, G., Zhang, C., Ke, G., and Xu, J. (2024). Incomplete Multi-view Clustering via Diffusion Contrastive Generation.\n\n[3]Zhang, Y., Zhu, C. Incomplete multi-view clustering via attention-based contrast learning. *Int. J. Mach. Learn. & Cyber.* **14**, 4101–4117 (2023)."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GYpDZFBauv", "forum": "UoW9VmZ3Ix", "replyto": "UoW9VmZ3Ix", "signatures": ["ICLR.cc/2026/Conference/Submission3237/Reviewer_m1hA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3237/Reviewer_m1hA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761296957760, "cdate": 1761296957760, "tmdate": 1762916618945, "mdate": 1762916618945, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a \"dendritic fusion + hierarchical double contrast\" DFHDC framework for incomplete multi-view clustering: first, independent autoencoders are used to obtain the latent representation of each view, and cross-view contrastive learning is performed at the local level with the \"maximum mutual information-minimum redundancy\" (MaxMI-MinRed) constraint; then, through a bottom-up \"dendritic\" pairing and parallel fusion, they are continuously converged to a common representation H, and at the global level, each view is aligned with H using the InfoNCE-style objective; for missing views, the statistical aggregation of available views is first used for initial interpolation, and then refined with a view-specific fine-tuning network; end-to-end training is carried out to jointly minimize the four losses of reconstruction, local contrast, global contrast, and fine-tuning, and finally k-means clustering is performed on the spliced ​​representation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Dendritic fusion formalizes the issues of \"who to fuse first\" and \"how to pair them\" into an iterative pairing optimization.\n2. Local-global dual comparison simultaneously optimizes \"cross-view consistency\" (maximizing mutual information) and \"suppressing intra-view redundancy,\" and then re-aligns in the common space, balancing fine-grained alignment and global distribution consistency at the target level.\n3. Missing view interpolation employs a two-stage approach of \"statistical mean initialization + view-specific fine-tuning,\" coupling reconstruction, comparison, and fine-tuning under a unified goal, thereby mutually reinforcing representation learning and data completion."}, "weaknesses": {"value": "1. Lack of clear causal attribution between multi-parameter settings and performance gains\n2. Ambiguity in joint feature similarity normalization and scale sensitivity in mutual information estimation\n3. High computational complexity (O(V³)) limiting scalability to large-scale multi-view scenarios\n4. Fusion path randomness due to unconstrained Hungarian pairing dynamics across epochs"}, "questions": {"value": "1. The proposed DFHDC framework includes four core modules: view reconstruction (LREC), local contrastive learning (LLOC), global contrastive learning (LGLO), and view completion fine-tuning (LREF). Each module corresponds to an independent balancing parameter (e.g.,λ1,λ2,λ3,λ4 in the total loss function). The paper does not systematically demonstrate the causal relationship between \"multiple parameter settings\" and \"performance advantages.\" Consequently, the attribution of the model's performance gains remains ambiguous, making it difficult to confirm whether the improvements stem from algorithmic design innovations or rely on meticulous fine-tuning of multiple parameters.\n2. Formula (3) constructs the \"joint feature similarity matrix\" P by summing the inner products of the sample dimensions, and then \"normalizes them to be non-negative and sum to 1\" for mutual information calculation (Formula (4)); however, the inner product can be negative, and the paper does not explain how to truncate/translate negative values ​​to non-negative, nor does it explain whether temperature/softmax normalization is performed, which makes it sensitive to scale.\n3. The paper mentions that the time complexity of the dendritic fusion strategy is O(V^3), which may limit its application on large-scale datasets. It is recommended to discuss this issue in more detail in the paper and explore possible solutions, such as using approximate algorithms or parallel computing to reduce computational complexity.\n4. Although dendritic fusion uses the Hungarian algorithm to determine the pairings at each layer, the pairing order may change between epochs due to fluctuations in view encoding, introducing structural instability (fusion path randomness). The current algorithm does not constrain or regularize this uncertainty, which may cause the convergence result to depend on the random seed. Please discuss this situation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ON4MCg09r0", "forum": "UoW9VmZ3Ix", "replyto": "UoW9VmZ3Ix", "signatures": ["ICLR.cc/2026/Conference/Submission3237/Reviewer_etbz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3237/Reviewer_etbz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761384415172, "cdate": 1761384415172, "tmdate": 1762916618647, "mdate": 1762916618647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework named DFHDC for incomplete multi-view representation learning. It integrates a dendritic fusion strategy to dynamically combine complementary views and a hierarchical dual contrast mechanism to enforce consistency and suppress redundancy at both local and global levels. The framework also incorporates view-specific fine-tuning for implicit completion of missing views. Experimental results on five datasets reportedly demonstrate performance gains over other existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The writing of the paper is clear, and its method diagram effectively illustrates the process of the method.\n2. The authors validate the effectiveness of their method through experiments, with results showing advantages over existing methods on five datasets."}, "weaknesses": {"value": "Please see questions."}, "questions": {"value": "1. How sensitive is the dendritic-fusion mechanism to the similarity metric used in the Hungarian pairing (e.g., cosine similarity)? Would alternative metrics change the pairing quality or stability of the fusion tree?\n2. While the ablation study demonstrates the contribution of each loss component, could the authors provide further intuition on how the local and global contrastive objectives interact? \n3. The adopted datasets for comparison in the experiment is not large enough, please conduct experiments on larger-scale real data.\n4. The claimed robustness of DFHDC in handling redundant noise in real-world data is not well-demonstrated. More experiments simulating practical conditions are needed to validate this aspect.\n5. How does the method perform when the number of views increases or when the views are highly heterogeneous? More experiments are needed to be provided.\n6. Regarding the computational cost of the dendritic-fusion process, the paper reports a time complexity of $O(V^3)$, I would still like to know if the authors have plans for further research in the future to tackle more complex data in practice."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OD4Zg4kfbD", "forum": "UoW9VmZ3Ix", "replyto": "UoW9VmZ3Ix", "signatures": ["ICLR.cc/2026/Conference/Submission3237/Reviewer_7noY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3237/Reviewer_7noY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761729096750, "cdate": 1761729096750, "tmdate": 1762916618455, "mdate": 1762916618455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}