{"id": "Azgxj7ZGCX", "number": 10392, "cdate": 1758169639030, "mdate": 1759897653888, "content": {"title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models", "abstract": "While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.", "tldr": "We frame LLM pruning as a cooperative game and use surrogate-assisted Shapley value estimation to identify and remove redundant layers efficiently while preserving performance.", "keywords": ["Layer-wise Pruning", "Cooperative Game Theory", "Shapley Value Approximation"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e64441632c86dac1dcb02e2293fef4cd6fa91a21.pdf", "supplementary_material": "/attachment/2743fcd9e32009f64b71b871234539ad36a07f2e.zip"}, "replies": [{"content": {"summary": {"value": "The paper points out that existing layer pruning methods mostly rely on static heuristic rules, overlooking the dynamic interdependencies between layers, which leads to suboptimal results. To address this issue, the authors propose a game-theoretic approach that formulates the layer pruning problem as a cooperative game. In this game, each Transformer layer is treated as a “player,” and the overall model performance (measured by perplexity, PPL) represents the collective “utility” produced through cooperation among all players. Since computing the exact contribution of each player (i.e., the Shapley value) is computationally intractable, the authors further design an efficient two-stage approximation framework to estimate these contributions and prune layers with lower importance. Experimental results show that this method consistently and significantly outperforms existing depth-wise and width-wise pruning baselines on both language modeling (PPL) and zero-shot reasoning tasks. Moreover, it generalizes well to non-Transformer architectures and demonstrates strong compatibility with quantization techniques such as GPTQ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear, and the results in Figure 1 clearly demonstrate the interdependence among layers.\n2. The paper proposes an efficient two-stage approximation framework that significantly reduces the computational complexity of solving the cooperative game.\n3. The experimental evaluation is comprehensive, covering both Transformer and non-Transformer model architectures."}, "weaknesses": {"value": "1. The paper’s core innovation is insufficient. The idea of viewing pruning from a cooperative game theory perspective has already been explored in prior work, such as “Using Cooperative Game Theory to Prune Neural Networks.” In addition, “Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding” also formulates the layer pruning problem as an optimization task through binary pruning masks.\n2. The experimental validation is not sufficiently comprehensive. The benchmarks used are limited to perplexity (PPL) and multiple-choice tasks, without evaluation on generation benchmarks such as GSM8K. In the generalization experiments on non-Transformer architectures, only PPL was reported, lacking broader task evaluation."}, "questions": {"value": "1. Why did the authors choose to evaluate on the ANLI benchmark?\n2. Why was MMLU not included in the evaluation? According to the results reported in the ShortGPT paper, its pruning method performs well on MMLU. Given that MMLU is a standard benchmark for evaluating reasoning and knowledge retention in large language models, the authors should at least include results on this task to make the evaluation more complete.\n3. Regarding the implementation of iterative pruning, the paper mentions “iteratively removing the least contributive layers.” Could the authors clarify how this iterative process is carried out?\n(A) Are all layers’ Shapley values computed once, and then layers are removed in batches (e.g., first pruning the three least contributive layers, then the next three)?\n(B) Or after each batch of layers is removed (e.g., three layers), are both Stage 1 and Stage 2 rerun to recompute the Shapley values for the remaining layers?\nIf the process follows (A), it seems inconsistent with the paper’s main motivation that pruning changes the relative importance of other layers. If it follows (B), the overall computational cost would increase significantly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3YboPo2Jyr", "forum": "Azgxj7ZGCX", "replyto": "Azgxj7ZGCX", "signatures": ["ICLR.cc/2026/Conference/Submission10392/Reviewer_jT3z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10392/Reviewer_jT3z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663357505, "cdate": 1761663357505, "tmdate": 1762921711957, "mdate": 1762921711957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a game-theoretic framework for pruning LLMs, aiming to reduce computational cost while preserving model performance. Instead of treating layers independently, the authors model pruning as a cooperative game, where each transformer layer is a “player” and the model’s performance serves as the utility function."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper reformulates LLM pruning as a cooperative game, capturing inter-layer dependencies ignored by static heuristics.\n2. This paper proposes a scalable Shapley-based pruning framework using stratified sampling and a surrogate model for efficient layer contribution estimation.\n3. This paper demonstrates consistent improvements over depth- and width-wise pruning baselines on multiple benchmarks, including WikiText2, PTB, C4, and zero-shot reasoning tasks."}, "weaknesses": {"value": "1. While the paper proposes a surrogate-assisted approach to estimate Shapley values efficiently, it lacks a clear theoretical analysis quantifying how well the surrogate approximates true layer contributions.\n2. The method relies on a small calibration set, which may not adequately represent diverse data distributions or downstream task requirements. The resulting Shapley estimates might therefore be dataset-dependent and unstable across domains.\n3. The study focuses solely on one-shot pruning without retraining, which may restrict achievable performance. Many recent works (e.g., ShortGPT) benefit from lightweight fine-tuning. It will be helpful to investigate how minor retraining after pruning interacts with the cooperative-game framework."}, "questions": {"value": "1. The paper uses 10 BookCorpus samples for calibration. How was this number chosen, and how does increasing or diversifying the calibration set affect Shapley estimation quality?\n2. Have you explored whether minimal fine-tuning after pruning further improves performance?\n3. Have you profiled the wall-clock speedups and memory reductions on real hardware (e.g., A100, H100, or consumer GPUs)? How does the pruning affect model latency when combined with quantization in real-time inference settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7AqW49WTLR", "forum": "Azgxj7ZGCX", "replyto": "Azgxj7ZGCX", "signatures": ["ICLR.cc/2026/Conference/Submission10392/Reviewer_CfBF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10392/Reviewer_CfBF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761669773351, "cdate": 1761669773351, "tmdate": 1762921711636, "mdate": 1762921711636, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a game-theoretic approach to layer-wise pruning in large language models, casting the problem as a cooperative game where each layer is a player and model performance serves as utility. Since computing exact Shapley values to measure each layer’s marginal contribution is infeasible at scale, the authors design a two-stage approximation using stratified Monte Carlo mask sampling and a lightweight surrogate network to efficiently estimate layer importance. The framework reportedly captures inter-layer dependencies better than prior methods and consistently surpasses strong depth-wise and width-wise pruning baselines across multiple downstream and generative benchmarks for Transformer and non-Transformer models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Principled Formulation & Theoretical Motivation**: The paper introduces a compelling game-theoretic framing for layer pruning, challenging the prevalent assumption of independent layer importance and instead recognizing context-dependent inter-layer dynamics. This principled approach addresses a core limitation of widely-used heuristics.\n- **Efficient Approximation of Shapley Values**: By incorporating a lightweight surrogate network trained on stratified Monte Carlo mask samples, the method approximates Shapley values efficiently, enabling practical application to large-scale LLMs—this is articulated with clear algorithmic details and demonstrated scalability (see Algorithm 1 & Figure 2).\n- **Conceptual Generality**: The approach is validated across Transformer and non-Transformer architectures, and shown to integrate compatibly with quantization and LoRA fine-tuning (Figure 7), suggesting broad applicability for LLM deployment."}, "weaknesses": {"value": "- **Surrogate Network Limitations and Validation**: While Figure 6 and Table 7 specify the surrogate’s structure, the paper lacks a rigorous quantitative evaluation of its prediction fidelity, especially for masks far from the training distribution. There is little discussion of failure modes, e.g., overfitting to calibration samples, brittleness under extreme masking, or calibration data misspecification (see Appendix F.1), limiting confidence for highly compressed regimes or out-of-domain settings. For instance, the impact of surrogate error on Shapley ranking stability is not systematically assessed.\n- **Potential Optimization and Mask Generation Shortcomings**: The stratified Monte Carlo mask sampling strategy (Section 3.3, Table 21) is justified primarily by ablation, with theoretical explanations on sampling sufficiency or representativeness lacking. While empirical results (Table 21) suggest an advantage over random sampling, the method’s robustness to choice of Hamming weights, number of samples, and potential for bias due to nonuniform coverage of important layer subsets remains underexplored. The mask set’s coverage and the potential for missed critical coalitions, particularly as $L$ increases, are not discussed in depth.\n- **Missing Related Work and Baselines**: The paper mentions SparseGPT but the citation to SparseGPT is pointing to the wrong paper (from the same research group).  Adding SparseGPT to the results would also make the experiments more complete. Furthermore, there has been research using Shapely values [1,2] and Influence Functions [3] for LLM pruning and LLM layer importance estimation that the paper fails to acknowledge.\n- **Ambiguity in Theoretical Guarantees**: While the game-theoretic formulation is elegant, there is no quantification of the approximation gap between true Shapley values and those estimated by the surrogate. No guarantees or bounds are provided regarding the surrogate’s reliability or the stability of resulting pruning strategies as masking regimes change. This undermines full confidence in the method’s reliability for critical compression tasks.\n- **Additional Minor Concerns**: Certain tables (such as Table 2) require careful reading to parse due to excessive fragmentation of sub-columns; legend clarity could be improved (see also Figure 3, Figure 4); some experimental settings (e.g., LoRA fine-tuning, ablation tasks) are relegated to the appendix without high-level results in the main paper."}, "questions": {"value": "- How robust is the surrogate model to mismatches between the calibration data distribution and the actual deployment or test distribution? Have the authors quantified the surrogate’s error rate, particularly for masks not seen during training?\n\n- Can the authors provide theoretical or empirical insights into the approximation gap between surrogate-predicted and true Shapley values, especially regarding stability of the ranking under different sampling or masking regimes?\n\n- Can authors provide results for SparseGPT as well and acknowledge or compare against the newer pruning methods that were left out.\n\n- Could the authors provide more interpretability on which types of layers (e.g., attention, feed-forward, early vs. late) are most frequently pruned, and relate this to observed task degradations"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YXHsJaX6G4", "forum": "Azgxj7ZGCX", "replyto": "Azgxj7ZGCX", "signatures": ["ICLR.cc/2026/Conference/Submission10392/Reviewer_FgAt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10392/Reviewer_FgAt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761888527051, "cdate": 1761888527051, "tmdate": 1762921711246, "mdate": 1762921711246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This is a well-executed paper with a creative idea (cooperative game formulation + surrogate Shapley approximation) and extensive empirical validation. While more theoretical analysis of the surrogate approximation would strengthen the paper, the methodological novelty and practical effectiveness make it strong."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Viewing layer pruning as a cooperative game is original and well-motivated. It captures inter-layer dependencies often ignored in prior pruning methods based on static heuristics. The surrogate-assisted estimation is elegant and computationally practical, bridging theory and application.\n2. Experiments are thorough, covering multiple models (transformer and non-transformer), datasets, and both generative and reasoning tasks, and generalization to quantization. \n3. Consistently outperforms strong baselines (SliceGPT, SLEB, ShortGPT, Shortened-LLaMA) across tasks and pruning ratios. The improvements are meaningful, especially at high pruning levels."}, "weaknesses": {"value": "1. While inspired by cooperative game theory, the connection remains mostly heuristic. The surrogate model approximates marginal contributions but lacks analysis of approximation error or variance bounds.\n2. There is limited discussion of the surrogate’s accuracy or potential biases (e.g., overfitting to sampled masks). Reporting R² or correlation between predicted and true perplexities would strengthen the claim.\n3. Although the method reduces evaluation costs compared to naive Shapley computation, 8k–80k mask evaluations and 200-epoch surrogate training are still substantial for large models. Quantitative runtime comparisons to baselines would help."}, "questions": {"value": "1. What is the computational overhead (GPU hours) compared to simpler pruning baselines like ShortGPT or SliceGPT?\n2. How sensitive is the method to the number of sampled masks or surrogate capacity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1DjMAzAXjW", "forum": "Azgxj7ZGCX", "replyto": "Azgxj7ZGCX", "signatures": ["ICLR.cc/2026/Conference/Submission10392/Reviewer_gSFA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10392/Reviewer_gSFA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10392/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928495689, "cdate": 1761928495689, "tmdate": 1762921710806, "mdate": 1762921710806, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}