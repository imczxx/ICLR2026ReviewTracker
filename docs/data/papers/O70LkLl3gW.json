{"id": "O70LkLl3gW", "number": 1395, "cdate": 1756879469694, "mdate": 1759898211060, "content": {"title": "Enhancing Geometric Perception in VLMs via Translator-Guided Reinforcement Learning", "abstract": "Vision-language models (VLMs) often struggle with geometric reasoning due to their limited perception of fundamental diagram elements. To tackle this challenge, we introduce GeoPerceive, a benchmark comprising diagram instances paired with domain-specific language (DSL) representations, along with an efficient automatic data generation pipeline. This design enables the isolated evaluation of geometric perception independently from reasoning. To exploit the data provided by GeoPerceive for enhancing the geometric perception capabilities of VLMs, we propose GeoDPO, a translator-guided reinforcement learning framework. GeoDPO employs an NL-to-DSL translator, which is trained on synthetic pairs generated by the data engine of GeoPerceive, to bridge natural language and DSL. This translator facilitates the computation of fine-grained, DSL-level scores, which serve as reward signals in reinforcement learning. We assess GeoDPO on both in-domain and out-of-domain datasets, spanning tasks in geometric perception as well as downstream reasoning. Experimental results demonstrate that, while supervised fine-tuning (SFT) offers only marginal improvements and may even impair performance in out-of-domain scenarios, GeoDPO achieves substantial gains: $+26.5\\\\%$ on in-domain data, $+8.0\\\\%$ on out-of-domain data, and $+39.0\\\\%$ on downstream reasoning tasks. These findings underscore the superior performance and generalization ability of GeoDPO over SFT. All code and data are released at https://anonymous.4open.science/r/GeoPerceive-9846, ensuring full reproducibility.", "tldr": "", "keywords": ["Vision Language Models", "Geometry Perception", "Reinforcement Learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1d34e77e69e361bec95c3bd9bc4687f25c4a670d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper highlights the limitations of visual language models (VLMs) in geometry perception and introduces the GEOPERCEIVE benchmark along with the GEODPO training framework. By incorporating a standardized domain-specific language and a translation-guided reinforcement learning approach, substantial advancements in geometry perception are achieved."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper accurately identifies a core limitation of existing VLMs in geometric problem solving: the inability to disentangle perceptual errors from reasoning failures. By decoupling geometric perception from downstream reasoning, the work provides a fine-grained evaluation perspective that is crucial for understanding model limitations in geometry tasks. \n\n2. This paper proposes an automated data generation pipeline centered on GEODSL, comprising a generation engine and a solving engine. This design enables the creation of large-scale, complexity-controllable training and evaluation data at low cost, addressing the limitations of human-annotated datasets. \n\n3. This paper proposes GEODPO, a translator-guided reinforcement learning framework that employs an NL-to-DSL translator to bridge natural language and GEODSL."}, "weaknesses": {"value": "1. The experimental evaluation primarily compares GEODPO against supervised fine-tuning (SFT), but lacks comparisons with other reinforcement learning methods (e.g., PPO) and some recent geometric reasoning approaches (e.g., GeoX).\n\n2. The downstream evaluation is limited to a small subset of MathVista (203 problems ), without evaluation on widely-recognized geometric reasoning datasets such as GeoQA , UniGeo , Geometry3K , and PGPS9k ."}, "questions": {"value": "1. Could the authors provide comparisons with other reinforcement learning methods, such as ppo?\n2. How does the translator quality impact the downstream DPO training performance? \n3. The downstream evaluation is currently limited to 203 MathVista problems . Could the authors evaluate GEODPO on widely-recognized geometric reasoning benchmarks such as GeoQA , UniGeo , Geometry3K , and PGPS9k to demonstrate broader applicability?\n4. How would GEODPO-enhanced models perform when integrated into complete geometric problem-solving pipelines, such as existing systems like GeoX ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WgHeFct3XX", "forum": "O70LkLl3gW", "replyto": "O70LkLl3gW", "signatures": ["ICLR.cc/2026/Conference/Submission1395/Reviewer_nm2u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1395/Reviewer_nm2u"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1395/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761559817992, "cdate": 1761559817992, "tmdate": 1762915761062, "mdate": 1762915761062, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents two key components, GeoPerceive and GeoDPO, aimed at enhancing geometric perception in vision-language models. Specifically, the authors propose:\n1. GeoPerceive, a novel benchmark that explicitly disentangles geometric perception from reasoning. It employs a canonical domain-specific language (GeoDSL) to represent diagrams in a precise and unambiguous manner.\n2. GeoDPO, a translator-guided reinforcement learning framework that improves perception alignment by leveraging natural-language-to-DSL translation as a fine-grained reward signal, while maintaining consistency with the model’s natural-language pretraining distribution.\n\nThe authors conduct a relatively comprehensive set of experiments to validate the effectiveness of their proposed methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors clearly identify geometric perception as a distinct subproblem within vision-language reasoning, separating low-level perception (recognition of geometric primitives and relations) from high-level symbolic reasoning (logical deduction). This represents a novel and well-motivated decomposition that has not been explicitly formalized in prior VLM research.\n2. The paper conducts extensive benchmarking across multiple major vision-language model backbones (Qwen2.5-VL, InternVL3, LLaVA-Next). The proposed method achieves substantial quantitative gains, and downstream reasoning tasks gains. Detailed element-level F1 analyses (covering points, lines, circles, and constraints) further confirm consistent improvements across all geometric subtypes.\n3. The GeoDPO formulation is mathematically well-specified, grounded in a principled DPO objective augmented by a translator-based reward model. The authors carefully address critical challenges such as permutation invariance, distributional shift, and the design of fine-grained reward signals, ensuring both theoretical rigor and practical stability.\n4. The implementation and codebase are open-sourced, providing transparency and reproducibility for future research."}, "weaknesses": {"value": "1. In Section 3, the paper introduces the GeoPerceive Benchmark, but it does not provide sufficient details regarding its categorical composition, dataset scale, or comparative positioning relative to existing benchmarks. It is recommended that the authors include a summary table outlining the dataset’s structure, sample counts, and distinctions from related benchmarks to improve clarity and reproducibility.\n2. The experimental comparisons primarily focus on SFT-based fine-tuning, without incorporating other reinforcement or reward-based baselines (e.g., PPO, DAPO, or similar methods) that could leverage scalar rewards derived from GeoDSL F1 scores. Including such baselines would strengthen the empirical validation of GeoDPO’s effectiveness and robustness.\n3. The qualitative analysis of perception failures remains limited. Readers currently lack a clear understanding of the specific types of perception errors that GeoDPO mitigates. It is recommended to include before–after visualization pairs illustrating vision-language model outputs on representative examples, both before and after GeoDPO training, to better demonstrate qualitative improvements."}, "questions": {"value": "1. Do the authors anticipate that GeoDPO could generalize to 3D geometric perception or other structured visual domains such as charts, circuit diagrams, or mechanical drawings? A discussion on this potential extension would strengthen the paper’s generalizability claims and highlight broader applicability.\n2. Did the authors attempt to apply PPO or DAPO using the same reward signal? If not, it would be valuable to discuss the expected behavioral differences, computational trade-offs, and design rationale behind choosing DPO over other preference-optimization methods. Clarifying this choice would help readers better understand the methodological positioning of GeoDPO within the broader landscape of reinforcement and alignment approaches.\n3. Regarding the downstream performance improvements, it would be helpful if the authors could provide additional results on benchmarks beyond MathVista, to demonstrate the model’s transferability and robustness across diverse geometric reasoning tasks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Eu0SX55FgB", "forum": "O70LkLl3gW", "replyto": "O70LkLl3gW", "signatures": ["ICLR.cc/2026/Conference/Submission1395/Reviewer_3WG9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1395/Reviewer_3WG9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1395/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635812531, "cdate": 1761635812531, "tmdate": 1762915760683, "mdate": 1762915760683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "1. This paper proposes GEODSL to uniquely describe each specific diagram, and builds GEOPERCEIVE based on it, combining a generation engine and a solving engine to randomly generate DSL-diagram pairs. It provides low-cost and high-quality data for training and evaluating geometric perception models;\n2. They trains a NL-to-DSL translator based on GEOPERCEIVE data, and combines it with the scoring metric to form an effective reward model. It solves the difficulty of scoring caused by the equivalence of order-permutation or shift of natural language description, and makes the training for VLM remain in the original NL field;\n3. Experiments on Qwen2.5-VL, InternVL3, and LLaVA Next show that, compared with raw or SFT models, DPO training based on GEOPERCEIVE and the translator can effectively improve the perception ability, as well as achieve improvement in downstream reasoning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper provides a rigorous and clear exposition of its methodology and experiment;\n2. The proposed GEOPERCEIVE pipeline provides an efficient automation scheme for the generation of geometric perception related data;\n3. It emphasizes the distinction between perception and reasoning, realizes the transformation from ambiguous natural language to strict DSL through NL-to-DSL translator, and provides a standard reward model for geometric perception results."}, "weaknesses": {"value": "1. Lack of comparison with related methods in the experiment (e.g. [Slow Perception](https://arxiv.org/abs/2412.20631), [EAGLE](https://arxiv.org/abs/2408.11397));\n2. Partial experimental results show no significant improvement compared to the SFT method."}, "questions": {"value": "1. How do you view the lag of DPO training compared to SFT in some specific indicators on the main-test split? (For example, the F1 score of circles perception, which serves as the aspect with the lowest score among all raw models)\n2. Does the GEODPO perform better than other methods, such as [Slow Perception](https://arxiv.org/abs/2412.20631) and [EAGLE](https://arxiv.org/abs/2408.11397)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gheS0BJEkD", "forum": "O70LkLl3gW", "replyto": "O70LkLl3gW", "signatures": ["ICLR.cc/2026/Conference/Submission1395/Reviewer_cHmt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1395/Reviewer_cHmt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1395/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902722653, "cdate": 1761902722653, "tmdate": 1762915760119, "mdate": 1762915760119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents GEOPERCEIVE, a new benchmark and synthetic data pipeline for evaluating and training geometric perception in vision-language models (VLMs) using diagrams paired with a canonical domain-specific language (GeoDSL). To improve VLMs' geometric grounding, the authors propose GEODPO, a translator-guided reinforcement learning (RL) framework that uses an NL-to-DSL translator to provide fine-grained reward signals for DPO-based preference optimization. Extensive experiments on both in-domain and out-of-distribution setups show that GEODPO yields stronger and more robust improvements over supervised fine-tuning (SFT), especially in geometric perception and downstream reasoning tasks"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Benchmark and Synthetic Data Pipeline: The paper introduces GEOPERCEIVE, which systematically generates and renders diagrams with unambiguous geometric DSLs. The pipeline creates diverse complexity-controlled data at scale, providing a solid resource for both evaluation and training.\n\n2. Meaningful Visualizations: Figures such as Figure 1 (exposing ambiguity in existing DSLs), Figure 2 (illustrating GeoDSL syntax), Figure 3 (full pipeline including RL steps), and Figure 4 (showing data complexity across iterations), are thoughtfully constructed. Figure 3, in particular, makes the RL and preference generation workflow concrete, aiding reproducibility and interpretability"}, "weaknesses": {"value": "1. Lack of Rigor in the Task: The geometric perception task is not merely a simple perceptual task. Specifically, the geometric information obtained through basic image perception should undergo rigorous verification (at least ensuring that the perceived constraints are consistent and non-conflicting). For example, certain relationships in the image, such as perpendicularity or numerical data, must be strictly validated against predefined conditions.\n\n2. Insufficient Explanation of Geometric Relations: In the defined quadruplet (comprising points, lines, and circles), can these elements sufficiently cover all basic geometric entities? Additionally, what specific constraints are included? Further clarification is needed to demonstrate the rationality and completeness of the definition.\n\n3. Regarding OOD Data: Further clarification is needed on the distinction between Out-of-Distribution (OOD) data and the benchmark data. Specifically, why is the manually annotated data considered out-of-distribution? Is this due to differences in drawing style, or does it pertain more to the complexity and nature of the geometric relationships?\n\n4. Limited Analysis of Failure Cases and Limitations: The main text barely addresses where GEODPO (or GeoDSL itself) struggles. Section E (Limitations) is confined to algebraic constraints, but a frank, quantitative error analysis (e.g., visualizations of failed cases, confusion matrices on specific primitives or constraints, qualitative outlier examples) is absent. For instance, Figure 4 shows only successful, rendered samples; missing are diagrams or programs leading to failure, which could inform limitations of the framework or concrete bottlenecks in the translation pipeline or RL optimization.\n\n5. Ablation and Baseline Completeness: The experimental section (Table 3, Table 4) lacks comparison to several baseline RL/population-based approaches used in the field, including those explicitly referenced in missing related works. There is also a missed opportunity for ablation—e.g., separating out the effect of NL2DSL translator quality from the DPO RL signal, or evaluating against other forms of preference optimization."}, "questions": {"value": "please see the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "AuL8hT7wDR", "forum": "O70LkLl3gW", "replyto": "O70LkLl3gW", "signatures": ["ICLR.cc/2026/Conference/Submission1395/Reviewer_MwSA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1395/Reviewer_MwSA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1395/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979254645, "cdate": 1761979254645, "tmdate": 1762915759948, "mdate": 1762915759948, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}