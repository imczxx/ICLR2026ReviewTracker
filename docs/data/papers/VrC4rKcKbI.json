{"id": "VrC4rKcKbI", "number": 24433, "cdate": 1758356887457, "mdate": 1759896766098, "content": {"title": "Revisiting Feature Interaction Selection in Neural Additive Models", "abstract": "In this work, we revisit the paradigm of feature interaction selection for additive models.\nThis paradigm generalizes the selection of a model's input features to the selection of a model's feature interactions by equipping any model with the additive structure of a generalized additive model.\nWhen applied to neural networks,\nthis restricts the network's learned representations to interactions between the specified sets of features.\nIn the study of the training dynamics of these neural additive models,\nwe discover a new phenomenon which we call `medium dimensionality',\ncorresponding to a balance between data complexity and model complexity.\nWe find that this phenomenon helps to explain the good performance of additive models on tabular datasets.\nWe moreover find that the tool of additive models is able to \nunify insights for many of the recently explored phenomenon of deep learning theory:\ndouble descent, grokking, leap dynamics, and the staircase property.\nFinally, we present developments on selections algorithms and neural additive models, benchmarking performance across a suite of tabular datasets.", "tldr": "", "keywords": ["additive models", "feature interactions", "deep learning theory", "staircase phenomenon"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e4ad8fcabc40e332653cc1f9aed5c2caeb1a05d8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper revisits the use of Neural Additive Models and the feature interaction selection paradigm. The authors introduce a new concept called \"medium dimensionality,\" describing a balance between data complexity and model complexity. They argue this phenomenon explains why additive models perform exceptionally well on tabular datasets. Furthermore, the authors further argue that the additive model framework serves as a valuable tool to unify and provide a data-centric perspective on several major deep learning theories, including double descent, grokking, and the staircase property.\n\nThe authors then proceed to also present a key algorithmic and architectural improvements for training these models. The authors do so by proposing a \"batchwise \" selection algorithm for identifying feature interactions, which they find easier to tune than previous methods. They also incorporate \"masked training\" to compute interaction scores, significantly accelerating the process. Finally, they introduce a \"mixed block sparsity\" architecture that balances GPU parallelism and memory requirements, proving to be both faster and more memory-efficient than prior implementations. The paper benchmarks these developments, demonstrating the value of NODE-GAMs for both applied performance and theoretical insight."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper's main strength lies in its ambitious conceptual setting, which aims to provide a novel and valuable contribution by attempting to create a unifying framework to explain four complex deep learning phenomena, such as double descent and grokking. The authors do so through the relatively simplistic lens of additive models. This is a positive highlight, as it offers a simpler, data-centric explanation for these intricate, and well-studied behaviors in the field.\n\nBeyond this theoretical insight, the paper delivers algorithmic and architectural improvements. It introduces a \"batchwise\" feature interaction selection algorithm that appears to be an enhancement over the previous layerwise method, offering better performance, faster computation, and simpler tuning with fewer hyperparameters. Furthermore, the proposed \"mixed block sparsity\" architecture appearingly provides a practical solution as it strikes an effective balance between sequential and parallel approaches to be both faster/more space-efficient."}, "weaknesses": {"value": "I have several significant issues with the paper in its current form.\n\n1. Poor Clarity and Precision in Core Concepts\n\nFirstly, the introduction of key deep learning concepts in Section 2 is quite poorly written and lacks precision.#\n\nOn Double Descent: The description of double descent merely mentions \"two local minima\" but completely omits the most critical components of the phenomenon: the spike in test error at the interpolation threshold and the subsequent increase and decrease in test error as model complexity grows. While many readers may be familiar with the concept, it is crucial for an academic paper to define its terms with clarity and precision. \n\nOn Grokking: The explanation for grokking is similarly imprecise. The authors characterize one of the learning phases as \"weight decay.\" This is very vague. It would be more accurate to describe this as a compression or regularization-driven search phase, or at the very least, the authors should explicitly define what they mean by \"weight decay\" in this specific context.\n\nOn Notation: In Section 2.2, the authors fail to introduce their notation properly. A clear example is in Equation (4), where the notation is used without any prior definition, leaving the reader to guess its meaning.\n\n2. Unsubstantiated Claims and Vague Concepts\n\nThe paper makes several bold claims that are either unsupported or poorly integrated into the narrative.The authors make a broad and, frankly, rude and unnecessary assertion on line 187 that high-dimensional statistics is \"mainly applied to specific domains like biostatistics.\" This is an inaccurate generalization that dismisses a vast field of research. \n\nThe newly introduced concept of \"medium dimensionality\" feels flat. The paper does not clearly demonstrate how or where this concept is truly used. It would be essential for the authors to clarify which of their settings, experiments, or results hold specifically for medium dimensions and not for high dimensions. As it stands, the term is introduced without a clear purpose or payoff.\n\n3. Weak Experimental Design and Justification\n\nSeveral of the experiments and claims in Section 3 are unconvincing or poorly justified. In Section 3.1, the authors describe a synthetic dataset but would be better served by explicitly and formally defining what this dataset is rather than just describing it in prose. In Section 3.2, the authors state, \"even if we know the true model, it may not be the best to fit with finite data.\" This is a very bold claim to include without solid proof, clarification, and strong experimental backing. The provided experiments are in my opinion too weak to support such a general statement.\n\nThe experiment in Section 3.3 is also problematic. The authors introduce an uncommon multiplicative setting to demonstrate grokking. The choice of this dataset and the $y \\leftrightarrow x$ relationship seems arbitrary. The results are not convincing, as they only appear to show the grokking phenomenon for a single step\n\n4. Structural and Narrative Flaws \n\nThe paper suffers from a lack of cohesion, in my opinion it currently reads a bit like a collection of disparate parts. Section 4 feels completely disconnected from the rest of the paper. After a theoretical setup in the preceding sections, this section on algorithmic improvements arrives \"out of nowhere\", ruining the flow of the paper. \n\nThe results in Section 5 (Tables 1 and 2) are concerning. In several instances, the optimized models with tuned hyperparameters perform worse than their untuned counterparts. For example, in Table 2, the tuned GA2M EBM has a lower normalized MSE than its counterpart, and the same occurs for the SVM on the Appliances Energy dataset. This pattern repeats across both tables and multiple datasets/methods, undermining the claims about the proposed optimizations. If i misundsterstood this, I would greatly appreciate if the authors could clarify it.\n\nFinally, the conclusion's mention of \"tightening statistical convergence rates\" also seems to appear from nowhere and is not linked to any of the paper's actual content or analysis. In general, while the theme of the paper is additive models, it feels like a bundle of many small, underdeveloped analyses. Unfortunately, I do not believe any of these analyses are independently sufficient for acceptance, and their links are too weak. I strongly suggest the authors focus on building a better narrative and either thoroughly corroborate the claims I pointed out or remove them entirely."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aNuUJsvvZx", "forum": "VrC4rKcKbI", "replyto": "VrC4rKcKbI", "signatures": ["ICLR.cc/2026/Conference/Submission24433/Reviewer_3oKc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24433/Reviewer_3oKc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24433/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937795490, "cdate": 1761937795490, "tmdate": 1762943082130, "mdate": 1762943082130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "this paper analyzes a few deep learning phenomena with NAM (neural network generalized additive models). The authors focused on the set of medium dimensionality where 2^d >> n (d is the feature dimension, n is the number of training data) and reproduced a few phenomena (double descent, staircase dynamics. From these observations, the authors proposed batchwise feature interaction selection/masked training/mixed block sparsity for improving NAM."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* this paper shows some lead that one can improve the NAM by leveraging known properties of deep learning training dynamics\n* focusing on medium dimensionity setup is useful because many real world problems fall into this category"}, "weaknesses": {"value": "the paper presentation is pretty bad:  \n* figure 2 is not readable: all subtitle are the same,\n* figure 3 is hard to understand\n* figure 6 is much hard to reader than that if you just present a table\n\n\non the other side, the connection from section 3 to section 4 can be significantly improved. it's probably the most important part (where you observe somethings and then adjust the methodology accordingly) so I would suggest spend more sentences/paragraphs to highlight how and why you made the proposals on section 4 based on what you found on section 3."}, "questions": {"value": "questions about medium dimensionality\n1. it's a quite wide spectrum between [d, 2^d]. does things happen in the whole spectrum or there are some more precision criterion?\n2. is the medium dimensionality feature for data, or for model, or for both together?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EuQyOdFoJE", "forum": "VrC4rKcKbI", "replyto": "VrC4rKcKbI", "signatures": ["ICLR.cc/2026/Conference/Submission24433/Reviewer_QFjS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24433/Reviewer_QFjS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24433/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762020620101, "cdate": 1762020620101, "tmdate": 1762943081894, "mdate": 1762943081894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of feature interaction selection for neural additive models. The authors first review existing deep learning theory and empirical observations of training dynamics. Then, they experimentally show that the relationship between data complexity and model complexity helps to explain the good performance of additive models. Additionally, they demonstrate that the phenomenon of deep learning theory can be observed in additive models. Finally, the authors propose a feature interaction selection method by modifying the existing SIAN method, and apply it to several tabular datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- This paper focuses on the deep learning phenomena, such as double descent and grokking, on neural additive models. The authors experimentally show that these phenomena can be observed in neural additive models.\n- The authors propose a feature interaction selection method by modifying the existing method, SIAN. The proposed method introduces a batch-wise selection and masked training to SIAN. In addition, the authors employ a mixed block-wise sparsity approach to accelerate the computational time of neural additive models."}, "weaknesses": {"value": "- The presentation of this paper is not well. The relationship between empirical observations of additive models presented in Section 3 and the algorithm development in Section 4 is not clear.\n- The experimental results do not support a clear advantage of the proposed method. The reviewer assumes that the SIAN-X in Tables 1 and 2 refers to the proposed method. There is no comparison between the original SIAN and the proposed method.\n- The ablation study is missing to show the effectiveness of each component of the proposed method, batchwise selection, and masked training.\n- The proposed method seems an incremental extension of the existing SIAN. The novelty and significance of the proposed method are limited.\n- The detailed experimental settings, such as the hyperparameter settings for SIAN, are missing."}, "questions": {"value": "- The authors should clarify how the observations in Section 3 lead to the proposed method in Section 4.\n- How is the contribution of each component in the proposed method for the performance?? An ablation study is necessary to clarify this point.\n- How do the authors determine the hyperparameters for SIAN and the proposed method? ($K$, $B$, $T$, etc.)\n- The following literature tackles a feature interaction selection for neural additive models. In addition, the efficient implementation of neural additive models is mentioned, which is related to Section 4.3 of this paper.\n\nKishimoto, Y., et al., Neural Additive and Basis Models with Feature Selection and Interactions, PAKDD 2024, https://doi.org/10.1007/978-981-97-2259-4_1"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IszEfh7iQS", "forum": "VrC4rKcKbI", "replyto": "VrC4rKcKbI", "signatures": ["ICLR.cc/2026/Conference/Submission24433/Reviewer_JAkH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24433/Reviewer_JAkH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24433/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762144195148, "cdate": 1762144195148, "tmdate": 1762943081602, "mdate": 1762943081602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}