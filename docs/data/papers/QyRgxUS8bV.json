{"id": "QyRgxUS8bV", "number": 2597, "cdate": 1757161002054, "mdate": 1763201174207, "content": {"title": "Avatar Concept Slider: Controllable Editing of Concepts in 3D Human Avatars", "abstract": "Text-based editing of 3D human avatars to precisely match user requirements is challenging due to the inherent ambiguity and limited expressiveness of natural language. To overcome this, we propose the Avatar Concept Slider (ACS), a 3D avatar editing method that allows precise editing of semantic concepts in human avatars towards a specified intermediate point between two extremes of concepts, akin to moving a knob along a slider track. To achieve this, our ACS has three designs: Firstly, a Concept Sliding Loss based on linear discriminant analysis to pinpoint the concept-specific axes for precise editing. Secondly, an Attribute Preserving Loss based on principal component analysis for improved preservation of avatar identity during editing. We further propose a 3D Gaussian Splatting primitive selection mechanism based on concept-sensitivity, which updates only the primitives that are the most sensitive to our target concept, to improve efficiency. Results demonstrate that our ACS enables controllable 3D avatar editing, without compromising the avatar quality or its identifying attributes.", "tldr": "", "keywords": ["3D Human Avatar Editing", "Controllable Editing"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/38a377298a387baf2cbc6943d8601a8db1a5d91c.pdf", "supplementary_material": "/attachment/d8fe54c3c582f2f2eead336f09f0d3c78b283b8b.pdf"}, "replies": [{"content": {"summary": {"value": "This paper investigates text-based 3D avatar editing and introduces an avatar concept slider (ACS) method allowing precise control the desired degree of expression of a given concept. Specifically, a concept sliding loss is introduced, which leverage linear discriminant analysis (LDA) to pinpoint the concept-specific axes. An attribute preserving loss is introduced to extract the key attribute information orthogonal to the target concept using principal component analysis (PCA). In addition, based on the concept-sensitivity, a 3DGS primitive selection mechanism is introduced to improve efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ Using a concept slider for controllable text-based 3D editing is practical.\n+ The overall paper is technically sound and easy to understand.\n+ Extensive editing results are provided to demonstrate the effectiveness and generalization ability of the proposed method.\n+ The authors provide video demos to show the promising editing capabilities with good 3D consistency and controllable attribute changes."}, "weaknesses": {"value": "- The proposed concept slider is somewhat complicated. Each new concept requires training a new LoRA adapter and manually designing a positive-negative text pair. The quality may rely on the manually defined opposite descriptions. It would be better to add a discussion or analysis on this.\n- The experiments only showcase some simple concepts (simple attributes modification described using short phrases such as age, hair color/length and body shape). I am wondering if it is possible to adjust a combination of multiple concepts or more complex concepts using a single concept slider?\nIn addition, the attribute preserving approach shows low quality (e.g., woman’s jeans in Figures 4a and man’s jeans in Figure4b.\n- Although the proposed concept-sensitive primitive selection shows promising efficiency (12 minutes as reported in Table 2), it heavily relies on fine-tuning the concept-specific adapter (~1 hour as mentioned in Section 5). Reporting only 12 minutes of editing time is misleading and somewhat unfair.\n- The organization and writing could be further improved. Several paragraphs (particular Section 4) are somewhat wordy and redundant. It is also weird the implementation details become an independent section (i.e., Section 5). The text in tables and figures is extremely tiny, which seriously affects readability.\n- There is no video demo to showcase the superiority compared to state-of-the-art methods."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aKrgjylTRk", "forum": "QyRgxUS8bV", "replyto": "QyRgxUS8bV", "signatures": ["ICLR.cc/2026/Conference/Submission2597/Reviewer_DeGG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2597/Reviewer_DeGG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760616478526, "cdate": 1760616478526, "tmdate": 1762916295835, "mdate": 1762916295835, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We sincerely thank all reviewers and AC for your time in reviewing our submission. We respectfully believe our paper merits a more balanced evaluation, specifically we feel that the comments provided by reviewer kyf1 did not fully support the score assigned. Thus, we are withdrawing our submission."}}, "id": "aPZyDNcXfV", "forum": "QyRgxUS8bV", "replyto": "QyRgxUS8bV", "signatures": ["ICLR.cc/2026/Conference/Submission2597/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2597/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2597/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763114184188, "cdate": 1763114184188, "tmdate": 1763114184188, "mdate": 1763114184188, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mp3P9CTY4J", "forum": "QyRgxUS8bV", "replyto": "QyRgxUS8bV", "signatures": ["ICLR.cc/2026/Conference/Submission2597/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2597/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763201173348, "cdate": 1763201173348, "tmdate": 1763201173348, "mdate": 1763201173348, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes avatar concept silder,  which aims to edit the 3D human avatars at a specified intermediate point between two extremes of concepts.The ACS can be represented in two stages. The first stage will finetuen a lora with a diffusion model to handle different alpha weights to combine positive and negative features. In the second stages, the 3D human avatars will be edited by the lora with given alpha. The results show the proposed method can modify the 3D avatar with some simple prompts."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method shows a better visualization compared with the baselines."}, "weaknesses": {"value": "1. The writing is EXTREMELY HARD to follow. \n2. The principle mentioned in the paper should be more general techniques for editing, like scene editing. It is hard to understand why the author only uses it in 3D human avatars, since LDA is irrelevant to \"3D human avatars\".\n3. All the experiments only show two simple prompts, like fitness.\n4. The details of training lora are missing. Part a of fig 2 is missing leading because it looks like the diffusion block only takes prompts as input.\n5. The comparison with dramavatar is unfair. The author should provide the results with the same avatar."}, "questions": {"value": "The usage of /cite in the paper looks like not correct.\n\nBased on the overall writing quality of the paper, and considering the idea of sds is a little bit out-of-date, I tend to give a negative recommendation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0GaIiVS1Dr", "forum": "QyRgxUS8bV", "replyto": "QyRgxUS8bV", "signatures": ["ICLR.cc/2026/Conference/Submission2597/Reviewer_kyf1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2597/Reviewer_kyf1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645885022, "cdate": 1761645885022, "tmdate": 1762916295604, "mdate": 1762916295604, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a 3D avatar editing method: avatar concept slider (ACS), which allows editing of semantic concepts in human avatars towards a specified intermediate point between two extremes of concepts, akin to moving a knob along a slider track. The authors introduce a Concept Sliding Loss, an Attribute Preserving Loss and 3D Gaussian Splatting primitive selection mechanism to try achieving editing with the concept slider."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Precisely editing a human avatar at a specified intermediate point between two extreme concepts is an interesting and practically valuable topic. \n\nThe method proposed by the authors is simple and appears to have high convergence efficiency."}, "weaknesses": {"value": "From the examples provided by the authors, the concepts seem quite limited. How many concepts can your method support? Are the concepts limited to a predefined set, or can they be arbitrary open-vocabulary terms? If the concepts are indeed limited, how can the work be justifiably termed “full-body avatar editing”? This is a critical point that affects the practical significance and generalizability of the method.\n\nThe authors claim to address the challenging problem of isolating and editing only the desired concept without altering other identifying information of the avatar. They introduce an “Attribute Preserving Loss” that attempts to achieve this through PCA and feature orthogonalization. However, the proposed method does not seem to guarantee that different attributes are truly decoupled. Could the authors provide more rigorous proof or a more comprehensive experimental analysis to demonstrate the effectiveness of their decoupling approach?\n\nRegarding the User Study, were the 16 sets of edited avatars and their corresponding descriptions prepared in advance by the authors? If so, this raises a concern about potential bias. How did you ensure that the selection of examples and descriptions does not favor your method? To mitigate this, could the editing text prompts be provided by the test participants themselves, rather than being pre-selected by the authors?"}, "questions": {"value": "The author needs to respond to the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uLVnaTWzfn", "forum": "QyRgxUS8bV", "replyto": "QyRgxUS8bV", "signatures": ["ICLR.cc/2026/Conference/Submission2597/Reviewer_2GTW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2597/Reviewer_2GTW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807238270, "cdate": 1761807238270, "tmdate": 1762916295470, "mdate": 1762916295470, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}