{"id": "PJIOTqYHnm", "number": 14786, "cdate": 1758243716639, "mdate": 1759897349445, "content": {"title": "Testing Fairness with Utility Trade-offs: A Wasserstein Projection Approach", "abstract": "Ensuring fairness in data-driven decision-making has become a central concern across domains such as marketing, lending, and healthcare, but fairness constraints often come at the cost of utility. We propose a statistical hypothesis testing framework that jointly evaluates approximate fairness and utility, relaxing strict fairness requirements while ensuring that overall utility remains above a specified threshold. Our framework builds on the strong demographic parity (SDP) criterion and incorporates a utility measure motivated by the potential outcomes framework in causal inference. The test statistic is constructed via Wasserstein projections, enabling auditors to assess whether observed fairness–utility trade-offs are intrinsic to the algorithm or attributable to randomness in the data. We show that the test is computationally tractable, interpretable, broadly applicable across machine learning models, and extendable to more general settings. We apply our approach to multiple real-world datasets, offering new insights into the fairness–utility trade-off through the perspective of statistical hypothesis testing.", "tldr": "", "keywords": ["statistical test of fairness hypothesis", "Wasserstein Projection", "Optimal Transport", "Strong Duality", "Asymptotic Analysis"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2c2bef10852ff1dba82ec8cda7428ddd3765fa7f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper builds a statistical hypothesis testing framework to check whether a model is approximately fair in terms of SDP, while still results in enough utility. It defines a null set of fair and utility-ensured distributions $\\mathcal{g}(r,\\epsilon)$ and then performs a hypothesis testing to examine how far the empirical data distribution is from this set using Wasserstein projection. If this distance is large, the test rejects the null hypothesis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The framework is theoretically rigorous. The authors develop formal hypothesis testing procedures, prove strong duality/asymptotic results, and demonstrate clear statistical guarantees for the proposed test.\n\n2. The problem formulation is concrete and well-structured.\n\n3. Empirical evaluations are provided."}, "weaknesses": {"value": "1. While the framework is theoretically rigorous, I am not sure of the practical significance, i.e., the test indicates whether \"fairness–utility trade-offs\" are significant, but it seems not to offer insight into how such findings inform model design or real-world decision-making.\n\n2. The work mainly contributes a statistical testing procedure rather than a learning algorithm. This makes me a bit unsure about its fit for ICLR."}, "questions": {"value": "How can practitioners use the framework?\nHow can we use the framework to guide learning algorithm designs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SdwHryMhA4", "forum": "PJIOTqYHnm", "replyto": "PJIOTqYHnm", "signatures": ["ICLR.cc/2026/Conference/Submission14786/Reviewer_yZVT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14786/Reviewer_yZVT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760562366649, "cdate": 1760562366649, "tmdate": 1762925138830, "mdate": 1762925138830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies statistical fairness testing under a joint fairness–utility perspective. The authors propose a Wasserstein projection-based test that simultaneously accounts for (i) approximate fairness constraints, formalized as a relaxed variant of Strong Demographic Parity (SDP) that must hold across all thresholds; and (ii) a minimum-utility requirement under a potential-outcomes model. The idea is to project the empirical distribution onto the set of distributions satisfying both constraints and to measure the resulting Wasserstein distance; this projection defines a test statistic with strong duality guarantees. The paper derives asymptotic properties for the test statistic (level-$\\alpha$ control, convergence) and provides a convex dual program that can be efficiently computed. Experiments on synthetic and real datasets illustrate how varying the fairness tolerance or utility constraint shifts rejection rates, demonstrating interpretability of fairness–utility trade-offs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "echnical soundness and mathematical rigor.\nThe paper is well executed on the theoretical side: the Wasserstein projection formulation, convex duality derivation, and asymptotic control of the test statistic are all clearly presented and appear correct. The proofs are detailed and internally consistent, suggesting a high level of mathematical care.\n\nConceptual clarity of fairness–utility trade-off.\nAlthough not new in spirit, the joint treatment of fairness and utility within a single optimization constraint provides a structured way to visualize and quantify trade-offs. The use of Wasserstein geometry offers interpretability through distances in distributional space.\n\nQuality of exposition.\nWriting is clean and formal. Definitions, lemmas, and proofs are well organized, and the authors use intuitive diagrams to illustrate projection behavior and rejection regions. The paper reads smoothly and is self-contained.\n\nPractical interpretability.\nThe fairness–utility trade-off plots and contour diagrams convey useful intuitions for how fairness constraints affect acceptance regions. Even if originality is limited, the framework might help practitioners audit fairness tests in a rigorous statistical way."}, "weaknesses": {"value": "Limited originality relative to prior OT-based fairness work. The main conceptual contribution (casting fairness testing as a Wasserstein projection with dual formulation) is incremental, given several recent studies that already apply optimal transport to fairness measurement or correction (e.g., Gordaliza et al., 2019; Chzhen et al., 2020; Xu et al., 2022; Pérez-Serrano & Oosterlee, 2023). The novelty here lies mainly in combining fairness and utility in one projection, but this extension is modest. Suggestion: Explicitly acknowledge overlapping prior work and clarify what differentiates this method, e.g., whether the test’s dual form or asymptotic control offers unique theoretical guarantees.\n\nWeak empirical evidence. Experiments are limited to small synthetic setups and a simple tabular dataset (COMPAS). There are no comparisons to other fairness-testing metrics or OT-based methods. As a result, the claimed advantages remain speculative.\nSuggestion: Include empirical baselines (e.g., equalized-odds distance, Kolmogorov–Smirnov test, prior OT fairness auditors) to substantiate claims.\n\nUnclear practical relevance. The fairness constraint (“approximate strong demographic parity across thresholds”) and the potential-outcomes utility model are abstract and may not map easily to the fairness notions used in ML practice (EO, DP, PPV). This makes it hard for practitioners to adopt the test. Suggestion: Offer a translation table or case study linking this formalism to standard metrics.\n\nLack of guidance on parameter selection. The fairness and utility tolerances ($\\epsilon_f$, $\\epsilon_u$) are varied in plots but not justified. Without principled tuning, users cannot reproduce or interpret real-world decisions based on this test. Suggestion: Add heuristics or theoretical discussion for choosing tolerance levels.\n\nScalability and applicability not demonstrated. Solving the Wasserstein projection exactly via convex optimization may be intractable in high-dimensional data; no experiments beyond low-dimensional settings are shown.\nSuggestion: Provide at least one medium-scale experiment or mention possible entropic/Sinkhorn approximations, or sequential transport.\n\nPositioning and related work. The paper’s framing underplays the volume of closely related literature on fairness via optimal transport and statistical testing. Without stronger contextualization, the work risks appearing as a variant rather than a new direction."}, "questions": {"value": "Statistical power: How does the test’s power compare empirically to simpler metrics (e.g., equality-of-odds distance, or KS-distance between groups)?\n\nUtility estimation: In practice, how are potential-outcome utilities estimated? Are counterfactual estimates required, or can surrogate utility functions (like accuracy or F1) suffice?\n\nChoice of $\\epsilon$ parameters: Could you provide theoretical or empirical guidance on selecting fairness and utility tolerance levels?\n\nScalability: Can the proposed projection be implemented using entropic-regularized OT solvers (e.g., Sinkhorn) to handle large datasets?\n\nGeneralization beyond binary sensitive attributes: Can the test handle continuous or multi-valued sensitive attributes, or does the constraint structure depend on discrete group partitions?\n\nConnection to fairness metrics: How does approximate SDP relate to other definitions (equalized odds, predictive parity)? Clarifying this would make the test’s scope clearer.\n\nRuntime / convergence: What are typical runtimes of the dual solver, and how sensitive are they to regularization parameters?\n\nVisualization: The fairness–utility contour plots are insightful; adding joint contour density or rejection boundaries for real datasets would strengthen interpretability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "c5uMM5Bzfh", "forum": "PJIOTqYHnm", "replyto": "PJIOTqYHnm", "signatures": ["ICLR.cc/2026/Conference/Submission14786/Reviewer_Yb7p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14786/Reviewer_Yb7p"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760776353979, "cdate": 1760776353979, "tmdate": 1762925138389, "mdate": 1762925138389, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a statistical hypothesis testing framework that jointly evaluates approximate fairness and utility in algorithmic decision-making. The proposed test assesses whether a data distribution satisfies approximate Strong Demographic Parity (for fairness) and exhibits low expected utility loss (for efficiency), using observed classification labels and predicted propensity scores. The method is based on a Wasserstein projection of the data to the nearest distribution satisfying both criteria, with an asymptotic stochastic upper bound on the projection distance. The main results address the binary case, with generalizations to the multi-valued case discussed in Appendix D."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "The strengths of the paper come from its contributions, summarized at the end of Section 1.2 (lines 99-105). In particular, it proposes a statistical test that is computationally tractable, interpretable, and broadly applicable. The idea of mapping the data to the nearest $r$-efficient and $\\epsilon$-fair distribution using a Wasserstein projection appears to be novel. The mathematical derivations appear technically sound based on an initial reading of the appendix. Based on the examples provided in Section 4 and Appendix F, along with the discussion of extensions beyond the binary case in Appendix D, the test seems to be widely applicable in practice."}, "weaknesses": {"value": "There are several significant aspects of the paper’s presentation that could be improved, particularly with respect to clarity and reproducibility. The primary weakness lies in the limited intuition provided for the main result, Theorem 3.2. Specifically, the connection between the right-hand side of Equation (8) and the test statistic from Hypothesis Test (4) is not clearly explained. Readers are left to infer how $\\eta_{1-\\alpha}$ corresponds to the $(1-\\alpha)$ quantile of the distribution in (8), and how Equations (7) and (P) justify rejecting $\\mathcal{H}_0$ when $t_N(\\epsilon, r) > \\eta_{1-\\alpha}$ (lines 374–377). The method for computing the test statistic itself (lines 392–398) is similarly vague.\n\nFurthermore, while the numerical experiments offer helpful illustrations, the paper lacks a clear description of how to implement the proposed test in practice. In particular, it would benefit from a worked example using real-world data mapped into the framework introduced in Equation (3), as well as guidance on how the approach generalizes beyond the binary case. As written, the current exposition makes it difficult for others to reproduce or build upon the method. With significant revisions to improve exposition and accessibility, this paper could make a valuable contribution.\n\nBelow is a list of specific points that could be communicated more clearly:\n- The infinity signs on lines 213--215 are undefined\n- Gradients $\\nabla$ and $D$ are used interchangeably without necessity\n- On line 164, $W_i$ is defined as \"utility\", but it is then specified as a treatment level $w_i$ on line 170. Also, $y_i(w_i)$ is then specified as observed utility, while $Y_i(W_i)$ is an outcome on line 162.\n- The description of Wasserstein distance and projection on lines 209--218 is unclear for readers unfamiliar with the literature.\n- As the paper describes how SDP holds in Jiang et al. (2020)'s setting and your setting, on lines 233--248, it is unclear what is the same or different between these settings.\n- It seems that you overload notation $p_{\\pi_a(X_i}$, $\\pi_a(X_i)$, $\\pi(X, a)$, and $\\mathbb{P}(W_i | X_i, a)$ on lines 166 and 244. $r_i$ on line 235 is also used for this concept.\n- There is no Proposition C.1 on line 247, only Lemma C.1. In the proof, on line 930, it is not clear whether C.1 is your own or stated verbatim from Jiang et al. (2020).\n- Why is $\\mathcal{G}(r, \\epsilon)$ written in terms of $\\mathcal{X}$ whereas $\\mathcal{F}_{r, \\epsilon}$ written in terms of $\\mathcal{Z}$?\n- infimum on line 290 appears to be repeated without significant change\n- The discussion about non-convex optimizations algorithms for solving Eq (11) could be made clearer.\n- $N \\mathcal{R}_{r, \\epsilon}(\\hat{\\mathbb{P}}_N)$ is undefined on line 364.\n- Why is DP written in terms of $\\mathbb{P}(\\mathbf{1}\\{\\mathbb{P}(W_i = 1 | X_i, S_i) > \\tau\\} = 1|S_i=1)$, rather than $\\mathbb{P}(W_i = 1 | X_i, 1) > \\tau)$ on line 238? Can you please clarify this coherence?\n- $M(x)$ should be defined outside Theorem 3.1 since it is used throughout the rest of the paper. \n- What is $\\delta_{x_i}$ on line 287?\n\n\nMinor:\n- Typo in Assumption 1: forgot \"(i)\" for Uncounfoundedness\n- Typo Definition 1: \"semiconinuous\" should be \"semi-continuous\"?\n- Incomplete sentence on line 209\n- Definition 1: might be worthwhile to write $(\\pi, \\pi') \\in \\mathbb{Q}_1 \\times \\mathbb{Q}_2$\n- $\\mathcal{Z}$ on line 258 should be defined on line 160. Stating $\\{0,1\\}$ on line 258 is confusing.\n- Since the test statistics $t_N$ introduced on line 312 is undefined, it may be worthwhile to discuss how it will be contructed via Theorem 3.2."}, "questions": {"value": "- In figures 2 and 3 (line 420), the test statistic and 95% upper bound are written in terms of $r$, $\\epsilon$, and $\\theta_1$. Where is this presented in Equation (8) and the discussion on lines 374--377 or 392--397?\n- How do the variables defined in Theorem 3.2 and lines 340--349 relate to (P) and Theorem 3.1? It seems that there was a disconnect in this discussion.\n- To check my understanding, does the test statistic in Figure 1(a) correspond with the probability that the data does correspond with a $r$-efficient and $\\epsilon$-fair distribution, as indexed by the regularization strength?\n- Can you clarify what the expectation is taken over in the definition of expected utility $m_w(x, a)$ on line 177, and how this connects to the sample-wise loss discussed on line 433?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oFQGFeJzq0", "forum": "PJIOTqYHnm", "replyto": "PJIOTqYHnm", "signatures": ["ICLR.cc/2026/Conference/Submission14786/Reviewer_uyZP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14786/Reviewer_uyZP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761101510197, "cdate": 1761101510197, "tmdate": 1762925137970, "mdate": 1762925137970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for assessing fairness-utility trade-offs, for a specific utility function. Specifically, for a threshold on the average reward ($r$) and a violation level ($\\epsilon$) of strong demographic parity (the used fairness criterion), the goal is produce a hypothesis test which assesses whether the underlying data distribution comes from family which has an average reward $\\geq r$ and a fairness violation $\\leq \\epsilon$. For the hypothesis testing, an optimal transport formulation is used, and the dual problem of the optimization problem is constructed in order to make the formulation tractable."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(S1) The paper deals with an interesting topic of fairness-utility trade-offs, a topic which still does not \n\n(S2) The proposed formulation seems interesting and novel. \n\n(S3) There are some good ingredients in the part related to duality and deriving a test."}, "weaknesses": {"value": "(W1) A core question is what kind of utility functions can be analyzed using the described approach. Here, specifically, two types of utilities are worth distinguishing:\n\n(a) pre-specified, known utility functions where $m_0, m_1$ are given,\n\n(b) unknown utilities, which need to be inferred from data.\n\nThis key discussion seems to be largely absent in the manuscript. Specifically, in Line 388, it is stated that “we may require that M(\\cdot) be concave”. Even in the case (a), is this a reasonable assumption? For commonly used utilities, such as accuracy, does this hold true? This seems quite important for the applicability of the proposed approach.\n\nFor case (b), things seem even more subtle. In the current formulation, is $M()$ assumed to be known perfectly? For instance, in the setting of patient treatment allocation (mentioned in the text), the function $M$ is almost never known, but estimated from data. \nCan such cases be handled, where there is inherent uncertainty over $M$? \nFor instance, is the derivative of $M$ needed for computing $\\xi$ values? How can one obtain such a derivative of $M$ in this case?\nAlso, in these cases, it is unclear whether any convexity/concavity can be expected. It is really important to delineate the scope for which the described hypothesis tests can be described -- currently, this is not done sufficiently well.\n\n(W2) Relating to the previous point, it is unclear whether the potential outcomes framework is needed, especially if only utilities of type (a) can be handled. If so, one could simply say that the utility $Y$ is computed through a known function $f_y (x, a, w)$. The causal semantics may be superfluous if this is the case; potential outcomes seem to be relevant for cases of type (b).\n\n(W3) Another question that comes to mind is computational complexity. It seems that an optimization problem needs to be solved for each $X_i$ — does this become very hard / intractable when there are many distinct values of $X_i$?\n\n(W4) The paper would benefit from better exposition in the start. Adopting a graphical representation (even though not necessarily a causal graph), would be helpful. Covariates $(X, S)$ influence a decision $W$, and $(X, S, W)$ influence the utility $Y$. A graph / visual with $(X, S) \\rightarrow W$, $(X, S) \\rightarrow Y$, $W \\rightarrow Y$ would help ground the mental model.\n\nPart of the issue is that the notation is not quite consistent with other parts of the literature, and this may be worth clarifying; the fairness criterion is placed on $W$, while, usually in the literature, the outcome on which fairness constraints are considered is labeled $Y$. In this work, the utility function is labeled $Y$. This may confuse the reader somewhat.\n\n(W5) The citations for statistical/demographic parity seem incorrect (Dwork et. al. 2012, Agarwal et. al. 2019 are not the correct citations). \n\n(W6) Some of the notation is confusing. In Line 72, $\\pi_{S_i}(X_i)$ is defined; in Line 166, this is redefined via $\\pi(x, a)$, and then a shorthand is adopted $\\pi_a(x)$. This complicates things unnecessarily.\n\n(W7) Second paragraph of Section 1.1 has some overlap with the later parts of the text. The writing could be more tight in this respect.\n\n(W8) The setting description in Section 1.1 would substantially benefit from an example which grounds all of the notions.\n\n(W9) Verifying the ignorability assumption: this part seems unusual; if I understand the appendix correctly, the ignorability criterion is implied by the simple fact that the decision $W$ is based on the observed covariates, since it is a machine learning predictor? If so, saying that this assumption is “tested” seems unusual.\n\n\n(W10) Assumption 3 — is it reasonable to assume $\\pi_1(x) = \\pi_0(x)$ for the $x$ that attains a utility $\\geq r$? It would be worth reflecting on this, since the condition is not just about $M(x) \\geq r$ as mentioned in the text?\n\nMinor:\n\n(W11) Definition 1, typo in semiconinuous\n\n(W12) in Line 213, $c(\\cdot, \\cdot)$ has $\\infty$ appearing in its definition; this seems quite unusual.\n\n(W13) Eq. (3) should $\\tilde Q$ be an element of $\\mathcal{P}(\\mathcal{Z})$ instead of $\\mathcal{P}(\\mathcal{X})$?"}, "questions": {"value": "(Q) Are the choices of $r, \\epsilon$ considered to be supplied by the user? Is it easy for the user to decide what level of fairness violation they are willing to tolerate?\n\n(Q) A question about a naive baseline comes to mind: how about quantifying the uncertainty over the expected reward E[Y(W)] and the fairness violation, using bootstrap; and then performing a hypothesis test based on how likely it is that $E^b[Y(W)] \\geq r, |SDP^b| \\leq \\epsilon$ over different bootstrap samples $b$? Is there way of justifying the proposed method over this approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DTeh4lfKdn", "forum": "PJIOTqYHnm", "replyto": "PJIOTqYHnm", "signatures": ["ICLR.cc/2026/Conference/Submission14786/Reviewer_NFVQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14786/Reviewer_NFVQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761694399373, "cdate": 1761694399373, "tmdate": 1762925137615, "mdate": 1762925137615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}