{"id": "NWoHQbALl4", "number": 25628, "cdate": 1758369591767, "mdate": 1759896712675, "content": {"title": "Compositional HyperModules for Few-Shot Code Adaptation in Meta-Reinforcement Learning", "abstract": "We propose Compositional HyperModules (CHM), which is a novel architectural framework for few-shot code adaptation in meta-reinforcement learning (Meta-RL), that dynamically composes reusable neural modules in order to capture the syntactic and semantic structure of code. Existing Meta-RL methods often have a difficult time with codes since they are monolithic and do not model the hierarchical and compositional nature of programming languages. For this purpose, CHM combines a transformer based hypernetwork with a hierarchical code representation layer, which allows the system to break code apart into function blocks (e.g. loops, conditionals) and recompose them smoothly for new tasks. The hypernetwork generates the task-specific weights for lightweight sub-modules, which are used to perform computations on structured code subgraphs as well as keeping the residual connections that preserve the functionalities of pre-trained modules. In addition, a gated attention mechanism aggregates the module outputs to jointly produce a global representation which serves as guidance to a Meta-RL policy network in order to generate context-aware actions (e.g., code edits). In contrast to previous work, CHM explicitly models code compositionality which allows for interpretable and efficient few-shot adaptation without full-fine-tuning. Experiments on code synthesis and bug fixing demonstrate a 20\\% improvement in few-shot accuracy over monolithic baselines, highlighting the framework's ability to generalize across diverse code patterns. The modular design not only gives adaptability but understanding what neural components correspond to specific code construct, leveraging neural procedures towards program undertaking analysis.", "tldr": "", "keywords": ["Meta-Reinforcement Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/770ffe4d1685855b8965e603c13a7584fd29021d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles the problem of few-shot adaptation in meta-reinforcement learning for code-related tasks, where conventional monolithic meta-reinforcement learning struggles due to the hierarchical structure of code. The authors propose Compositional HyperModeuls, a novel meta-reinforcement learning framework that uses a transformer-based hypernetwork to generate task-specific weights for modular sub-networks that process AST subgraphs corresponding to code constructs, and a gated attention mechanism aggregates module outputs to guide a meta-reinforcement learning policy for code synthesis and bug fixing. The paper reports 20% improvement over monolithic baselines like GraphCodeBERT-MAML and claims the advantage of interpretability benefits through explicit module-to-construct mappings. However, the paper suffers from inconsistent naming conventions (e.g., CHM vs HyperCodeNet) and significant reproducibility concerns."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. For originality and novelty, the paper proposes a very novel architectural integration that explicitly aligns neural modules with AST-based code constructs and leverages domain structure in a principled way, differentiating from monolithic meta-reinforcement learning approaches. The paper also proposes to use residual weights to preserve foundational module behavior during few-shot adaptation is well-motivated and addresses catastrophic forgetting.\n2. For clarity, the exposition of the proposed modular decomposition and the gated attention-based module aggregation is clear and conceptually coherent. The framework's structure naturally mirrors the organization of programming languages, making the approach intuitive and well-aligned with the underlying semantics of code tasks."}, "weaknesses": {"value": "1. The paper inconsistently refers to the proposed framework as “CHM” (in the title, abstract, and figures) and “HyperCodeNet” (throughout the main text) without clarification. This inconsistency causes confusion about whether these terms refer to the same system or to distinct components.\n2. The proposed approach critically depends on successful AST parsing. However, this requirement fails on syntactically invalid code, which is common in real-world bug-fixing scenarios. Although the paper acknowledges this limitation in section 5.4, it neither quantifies the failure rate nor proposes a mitigation strategy, leaving an important gap unaddressed.\n3. The ablation study explores only three configurations: \"No Residual Priors\", \"Monolithic Attention\", and \"Random Module-Task Assignment\". Additional analyses would have provided deeper insight, such as the effect of the regularization coefficient (λ), the number or granularity of modules, and alternative attention mechanisms.\n4. The experimental section is missing comparisons to recent code-specialized large language models, like CodeLlama, Qwen3-Coder, Claude, etc., which are now standard baselines for code synthesis and repair.\n5. The paper doesn't mention code release, and the hyperparameter specifications (hidden dimensions, learning rates, etc.) are incomplete. No compute budget disclosed and training procedures are not fully specified."}, "questions": {"value": "1. Will the code and full experimental details be released, and what were the complete hyperparameters and training procedures?\n2. In bug-fixing, how frequently does AST parsing fail on syntactically invalid code? What is the performance impact?\n3. What do M4 and M5 in figure 3 stand for?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UV60zI4LWa", "forum": "NWoHQbALl4", "replyto": "NWoHQbALl4", "signatures": ["ICLR.cc/2026/Conference/Submission25628/Reviewer_gUWS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25628/Reviewer_gUWS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25628/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887685024, "cdate": 1761887685024, "tmdate": 1762943498852, "mdate": 1762943498852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose Compositional HyperModules, a framework for few-shot code adaptation in meta-reinforcement learning. Their method decomposes programs into function blocks using abstract syntax trees and assigns each block to a lightweight neural module. A transformer-based hypernetwork dynamically generates parameters for these modules, which are aggregated by a gated attention mechanism to produce a global code representation. Experiments on code synthesis and bug fixing benchmarks show that the approach improves few-shot adaptation performance compared to monolithic baselines."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "**Important Domain**\n\nThe paper addresses an important and challenging area—few-shot adaptation for code tasks—which has high practical relevance in software engineering and AI."}, "weaknesses": {"value": "**1. Lack of Implementation Details**\n\nThe method section omits critical details regarding implementation. For example, it is unclear how the GNNs are built, what the graph structures look like, which GNN variants are used, how many layers and what parameter settings are applied, and where exactly GNNs are incorporated in the architecture. The core sub-modules are also only described in terms of inputs and outputs, with no details on their internal structure, making reproduction impossible.\n\n**2. Insufficient Related Work Discussion**\n\nThe related work section fails to discuss or compare against several closely related approaches, such as TreeGen[1] and ASN[2], both of which leverage ASTs and graph-based neural techniques. The differences between the proposed method and these prior works, especially in terms of module assignment and architectural novelty, are not clearly explained.\n\n**3. Questionable Experimental Validity**\n\nWithout thorough discussion and comparison with these related methods, the validity of the experimental results is difficult to assess.\n\n**4. Incomplete Ablation Study**\n\nThe ablation experiments do not cover all aspects of the proposed novelty. For instance, the role and robustness of the AST parser are not evaluated.\n\n**5. Missing Training Procedure Details**\n\nThe paper does not clearly describe the training process. It remains unclear how the model is trained and how meta-learning is actually implemented.\n\nReferences:\n\n[1] Sun, Z., Zhu, Q., Xiong, Y., Sun, Y., Mou, L., & Zhang, L. (2020, April). Treegen: A tree-based transformer architecture for code generation. In Proceedings of the AAAI conference on artificial intelligence (Vol. 34, No. 05, pp. 8984-8991).\n\n[2] Rabinovich, M., Stern, M., & Klein, D. (2017, July). Abstract Syntax Networks for Code Generation and Semantic Parsing. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1139-1149)."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bDBXFEKeKv", "forum": "NWoHQbALl4", "replyto": "NWoHQbALl4", "signatures": ["ICLR.cc/2026/Conference/Submission25628/Reviewer_LUeD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25628/Reviewer_LUeD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25628/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898617042, "cdate": 1761898617042, "tmdate": 1762943498685, "mdate": 1762943498685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HyperCodeNet, a meta-RL architecture that composes syntax aligned hypermodules mapped to AST substructures and aggregates them with a gated attention mechanism. The approach reports large few-shot gains on CodeSearchNet and DeepFix and argues for interpretability via module, construct alignment."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "•\tSound alignment of model design with code structure (AST-partitioned modules + residual priors + gated aggregation).\n•\tClear empirical story with ablations showing the value of residual priors, attention, and AST mapping.\n•\tClaimed few-shot improvements (~20% over baselines) across two code tasks."}, "weaknesses": {"value": "•\tUnder-specified meta-RL setup (states/actions/rewards/episode design) and few-shot protocol; metrics like “functionally accurate code” are not concretely defined.\n•\tBaselines omit strong contemporary code LLMs and retrieval-augmented methods; current list skews dated.\n•\tReproducibility gaps: missing module inventory/capacity tables, training details, and seeds/significance.\n•\tLimitations acknowledged but impactful: reliance on robust AST parsing; hand-designed module library.\n•\tWriting quality: noticeable phrasing/typos (e.g., “less reconciling,” odd wording around residual priors)."}, "questions": {"value": "1.\tPlease specify the meta-RL formulation: action space (edit primitives), reward, horizon, offline vs. online adaptation, and 5-shot episode construction.\n2.\tWhat exact metrics (e.g., unit-test pass rate, exact match) implement “syntactically correct and functionally accurate,” and how are significance and variance reported? \n3.\tCan you add stronger baselines (recent code LLMs under the same few-shot budget) and report module-library details and sensitivity to λ and module count?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FjGirS3Ey4", "forum": "NWoHQbALl4", "replyto": "NWoHQbALl4", "signatures": ["ICLR.cc/2026/Conference/Submission25628/Reviewer_CFHZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25628/Reviewer_CFHZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25628/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927465341, "cdate": 1761927465341, "tmdate": 1762943498508, "mdate": 1762943498508, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Compositional HyperModules (CHM), implemented as HyperCodeNet—a novel meta-reinforcement learning (Meta-RL) framework designed for few-shot code adaptation. The key innovation is a transformer-based hypernetwork that dynamically generates weights for syntax-aware neural modules aligned with Abstract Syntax Tree (AST) substructures. These modules (e.g., for loops, conditionals, function calls) are composed using a gated attention mechanism to build interpretable, modular representations of code.\n\nCHM achieves up to 20% higher few-shot accuracy on CodeSearchNet and DeepFix benchmarks compared with baselines (e.g., GraphCodeBERT-MAML, Hyper-Transformer). The model’s modular design offers both interpretability, each neural component corresponds to a code construct, and data efficiency, requiring no full fine-tuning.\n\nThe paper discusses the limitations of dependency on AST parsing, hand-crafted module types, and rigidity from residual priors."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Novel Architectural Design\nThe introduction of Compositional HyperModules unifies hypernetworks, modular neural architectures, and structured code representations. This explicit AST-aligned modularization is original and well-motivated for few-shot code learning.\n\nStrong Empirical Gains\nDemonstrated 20% improvement over baselines in few-shot code synthesis and repair tasks, coupled with clear module-to-syntax alignment that enhances interpretability, a rare combination in Meta-RL models.\n\nWell-Scoped Analysis & Ablations\nThe paper includes informative ablations (e.g., removal of residual priors, attention gating, or module alignment) that substantiate each component’s contribution to accuracy and adaptation speed."}, "weaknesses": {"value": "1. No training procedure is specified. The paper introduces CHM/HyperCodeNet with equations and components but never states how the policy is trained (which RL algorithm, on-policy/off-policy, horizon, reward shaping, meta-training loop, inner/outer updates, optimizer, batch sizes, learning rates, or compute). Sections 4.1–4.3 define abstract modules and a composite loss but stop short of a concrete recipe for training or adaptation episodes\n\n2. Task descriptor and parsing pipeline are underspecified. The definition of the task descriptor z, how it’s computed from few-shot examples, and the exact AST parsing/mapping from nodes to module instances are not described at implementable granularity; even the paper itself flags reliance on ASTs as a limitation without giving a practical parser/error-tolerant setup.\n\n3. Evaluation protocol lacks detail. Datasets and baselines are named, but there’s no description of episode construction, splits, prompts/I-O formats, or significance tests. “Accuracy” is defined only as “success rate in generating syntactically correct and functionally accurate code,” with no oracle, unit-test harness, or exact pass criteria; Table 1 reports single numbers without variance/CI.\n\n4. Release plan is unclear. There is no code or artifact release plan."}, "questions": {"value": "1. Training loop & RL specifics: What exact algorithm(s) and hyperparameters train π and the hypernetwork? How are inner vs. outer updates scheduled, and what is the per-task adaptation budget during meta-test?\n\n2. Task descriptor and module wiring: How is the task descriptor z computed from few-shot examples, and what is the deterministic/probabilistic rule that maps AST nodes to module instances at inference time?\n\n3. Evaluation harness: For CodeSearchNet and DeepFix, what are the exact pass criteria, unit tests, decoding settings, seeds, and number of tasks/episodes used to compute the “accuracy” in Table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "POygjJrhgq", "forum": "NWoHQbALl4", "replyto": "NWoHQbALl4", "signatures": ["ICLR.cc/2026/Conference/Submission25628/Reviewer_7HuU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25628/Reviewer_7HuU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25628/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978161775, "cdate": 1761978161775, "tmdate": 1762943498219, "mdate": 1762943498219, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}