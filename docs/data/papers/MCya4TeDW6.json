{"id": "MCya4TeDW6", "number": 18535, "cdate": 1758288912168, "mdate": 1763731214213, "content": {"title": "Transformers Can Do Bayesian Clustering", "abstract": "Bayesian clustering accounts for uncertainty but is computationally demanding at scale. Furthermore, real-world datasets often contain missing values, and simple imputation ignores the associated uncertainty, resulting in suboptimal results. We present Cluster-PFN, a Transformer-based model that extends Prior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained entirely on synthetic datasets generated from a finite Gaussian Mixture Model (GMM) prior, Cluster-PFN learns to estimate the posterior distribution over both the number of clusters and the cluster assignments. Our method estimates the number of clusters more accurately than handcrafted model selection procedures such as AIC, BIC and Variational Inference (VI), and achieves clustering quality competitive with VI while being orders of magnitude faster. Cluster-PFN can be trained on complex priors that include missing data, outperforming imputation-based baselines on real-world genomic datasets, at high missingness. These results show that the Cluster-PFN can provide scalable and flexible Bayesian clustering.", "tldr": "We present Cluster-PFN, a transformer-based model for scalable Bayesian clustering that outperforms baselines in estimating clusters and handling missing data, while being orders of magnitude faster than variational inference.", "keywords": ["Meta Learning", "Transformers", "Clustering"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a29a2364070b8362cae7ea1553120b930ceefdb8.pdf", "supplementary_material": "/attachment/6d8638135d84ba4e247c1cb804ea86e6cf14fdc0.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose to use PFNs for Bayesian clustering. They introduce an augmented version of classical TabPFNs for the purpose of predicting the number of clusters and the cluster assignments in a given dataset. \nThey evaluate their approach on the synthetic training data sampled from their prior, and a limited set of real-world datasets and benchmark against a variational inference (VI) approach, as well as \"GMM\" utilizing different information criteria. Several ablations, including one on relatively large datasets with 10 000 datapoints is conducted. \nFurthermore, a way to make the clustering robust to missing data is discussed and evaluated."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is relatively well-written and follows a clear structure. While some important details on the baselines and datasets are missing, the most critical aspects of the experiments and the approach are made very clear. Them explicitly stating research questions helps the structure. \n\nTo my best knowledge, using PFNs to predict cluster assignments **together with** the number of clusters has not been explored. The idea to make the model also robust to missing data is nice! \n\nIn terms of experiments, the results they obtain look correct and reasonable and the large-dataset experiment (10,000 points) is interesting. \n\nThe findings overall are somewhat interesting from a conceptual point of view or could form the foundation for very specific applications of PFNs to clustering where all other methods fail."}, "weaknesses": {"value": "Unfortunately, there are several major weaknesses: \n\n1.) The paper completely ignores related work. Especially the paper \"Reuter, Arik, et al. \"Can Transformers Learn Full Bayesian Inference in Context?.\" Forty-second International Conference on Machine Learning.\" is highly relevant and seems to look into very related aspects of PFNs. In this paper, the authors also consider a PFN-approach to Bayesian clustering using GMMs and provide detailed experimental results. A thorough discussion of this paper is missing. Any other discussion of related work is also absent. \n\n2.) The paper massively overclaims the scalability of the approach in the abstract. Not only do the authors not even consider datasets with more than five features, but also don't include any results on reasonably-sized **real-world** datasets. It is also highly questionable that proposed PFN approach (which do in-context learning) has any conceptual advantage in terms of scalability compared to other methods. \n\n3.) Insufficient baselines: Just using one type of VI, that is not even properly explained or introduced, is clearly insufficient. The authors should explain and justify why they choose this particular type of VI and ensure that its hyperparamters are correctly set. Further VI baselines would also be needed for thorough experiments. Any sampling-based methods (MCMC) to perform inference are also missing. \n\n4.) Insufficient real-world experiments: Only one real-world dataset for the non-missing scenario is definitely not enough and makes the reader highly suspicious. \n\n5.) Insufficient number of tasks: It would be very interesting to see the Cluster PFN being trained on models other than GMMs to truly investigate Clustering as a problem and not just GMM clustering. \n\n5.) Details, including implementation details, on the datasets and all baselines are missing.\n\n6.) Lacking Novelty: The approach is conceptually very similar to existing PFN approaches and investigates essentially the same task as Reuter et al.  \n\n7.) The real-world applicability of this particular method is quite questionable. Why should anyone bother to fit a GMM with such an inefficient approach?"}, "questions": {"value": "Why do the authors believe that their method is scalable?\n\nWhy is the proposed PFN method conceptually a good approach for (Bayesian) clustering? \n\nWhat exactly is the type of VI that is used? \n\nWhich hyperparameters are used for the VI method? \n\nWhy don't the author's consider other VI methods? \n\nWhy don't the authors consider sampling-based methods, in particular Hamiltonian Monte Carlo Samplers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nVPEk37CME", "forum": "MCya4TeDW6", "replyto": "MCya4TeDW6", "signatures": ["ICLR.cc/2026/Conference/Submission18535/Reviewer_Qm5R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18535/Reviewer_Qm5R"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760807750983, "cdate": 1760807750983, "tmdate": 1762928233437, "mdate": 1762928233437, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Cluster-PFN, a Transformer-based model for computing posterior cluster assignments.\nThe model is trained entirely on synthetic Gaussian mixture datasets to predict both the number of clusters and posterior cluster responsibilities in a single (or two-step) forward pass."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1) The idea of adapting PFNs to perform Bayesian clustering is interesting and original.\n\n2) The code for reproducibility is available.\n\n3) The authors also discuss the limitations of the proposed approach."}, "weaknesses": {"value": "See *Questions*."}, "questions": {"value": "1) The paper is very difficult to follow. Already from the abstract, key acronyms (AIC, BIC) appear before being defined. Throughout the text, the authors make strong but insufficiently supported claims (‚ÄúThe results are clear‚Äù, ‚ÄúCluster-PFN approximates the true Bayesian posterior over the number of clusters‚Äù), yet the actual mechanism of the model remains opaque. After several readings, it is still unclear what Cluster-PFN concretely does and how it differs from the seminal work of Muller et al. In practice, the model appears to be trained via supervised meta-learning on synthetic GMMs and to only imitate posterior-like outputs, without estimating latent parameters or uncertainty over model parameters. **The work needs substantial rewriting**.\n\n2) The presentation of results is confusing, with synthetic and real-data experiments mixed together and no clear boundary between what is meant to demonstrate ‚Äúproof of concept‚Äù and what supports the claimed generalization ability. Most importantly, the Discussion section exposes a conceptual contradiction. The entire point of PFN-like and meta-learning models is to perform meta-training on synthetic tasks so that the learned model can generalize to a wide variety of real-world datasets. However, the authors themselves acknowledge that their approach must be trained ‚Äúfor a particular prior‚Äù and that ‚ÄúCluster-PFN is not always competitive on real-world data, only offering clear benefits on the GLS1 dataset.‚Äù This statement undermines the main motivation of the work: if the model needs to be retrained for each prior and fails to generalize across domains, it is unclear what advantage Cluster-PFN offers over standard inference methods.\n\n3) The model formulation is difficult to follow. It is not clear how the conditioning on the number of clusters $k$ is implemented in practice, and why two forward passes are required when $k=0$. This seems to contradict the usual ‚Äúsingle forward-pass inference‚Äù property of PFNs. \n- Could the authors clarify how these two stages (estimating $k$ and computing cluster responsibilities) interact in the final inference pipeline?\n- In addition, the model breaks label permutation invariance by assigning cluster labels through a fixed heuristic (‚Äúthe cluster closest to the origin is label 0‚Äù). How much does this arbitrary rule influence the learned mapping?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gAb9Zn5Xr9", "forum": "MCya4TeDW6", "replyto": "MCya4TeDW6", "signatures": ["ICLR.cc/2026/Conference/Submission18535/Reviewer_qNDq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18535/Reviewer_qNDq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761670194501, "cdate": 1761670194501, "tmdate": 1762928233025, "mdate": 1762928233025, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a modification of Prior-Data Fitted Networks (PFNs) to implicitly perform Bayesian clustering. The model is trained on synthetic datasets generated from Gaussian Mixture Models (GMMs) with specified priors, using the corresponding cluster assignments as supervision for a Transformer. To support inference of the number of clusters, the model is also provided with special tokens that guide the prediction of cluster counts. Empirical evaluation focuses primarily on synthetic data generated from GMMs with dimensionality up to five, with a limited number of real-world datasets included for additional validation."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper reads well overall, making it easy for the reader to follow the core ideas.\n\n- To the best of my knowledge, this is the first work to apply Prior-Data Fitted Networks (PFNs) to clustering, opening a promising new direction for amortized Bayesian inference in unsupervised learning."}, "weaknesses": {"value": "- **Limited methodological novelty**: the approach primarily adapts existing PFNs by treating known cluster assignments as supervised labels, with only minor modifications to the training procedure. This incremental extension reduces the overall contribution, and in my opinion, could only be mitigated if highly significant results were provided, which is not the case.\n\n- **Lack of motivation**: while the abstract emphasizes *\"missingness\"* as a central motivation, this aspect is not meaningfully developed in the main text. It is only briefly addressed in the experiments through a simple masking setup, making it feel peripheral and disconnected from the paper's core contributions.\n\n- **Overly simplistic datasets**: unless supported by references to recent work, the use of five-dimensional synthetic data generated from Gaussian mixtures appears insufficient for evaluating clustering performance. This setting does not reflect the complexity of modern clustering tasks, which often involve high-dimensional, noisy, and structurally diverse data.\n\n- **Weak baselines**: similarly, the baseline methods used (e.g., GMM and variational inference) are outdated and overly simplistic, limiting the relevance of the empirical comparisons to current challenges in clustering.\n\n- **Weak empirical evaluation**: the evaluation relies heavily on qualitative visualizations using simple, easily separable datasets. This is insufficient for demonstrating the robustness or scalability of the approach. \n\n- **Unjustified computational cost**: while inference is reported to be ~50√ó faster, the training cost is cited as 60 GPU hours for clustering on five-dimensional Gaussian blobs, which seems unreasonable given the simplicity of the task, and reduces the practicality of the method.\n\n- **Lack of experimental transparency**: key details are missing. I include some of them in the questions section.\n\n### Minor Issues\n\n- The methodological section (Section 3) is too brief and lacks details. Several important methodological details are deferred to Section 4, which is nominally focused on experiments. This separation impairs the paper's readability and logical flow.\n\n- The use of the term *\"Bayesian prior\"* to describe data generated from a GMM does not align with the conventional meaning of priors in Bayesian inference‚Äîspecifically, priors over model parameters or cluster assignments. This creates confusion.\n\n- The Old Faithful dataset is not mentioned in the real-world dataset descriptions, yet it appears in the experimental results. This inconsistency should be addressed."}, "questions": {"value": "- How is the maximum number of generated clusters $ùêæ$ defined?\n\n- How does the $\\beta$ parameter produce cluster overlapping?\n\n- What are the hyperparameters and implementation details for the baselines?\n\n- The real-world datasets are poorly described, limiting reproducibility and interpretability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k3NKC2pByM", "forum": "MCya4TeDW6", "replyto": "MCya4TeDW6", "signatures": ["ICLR.cc/2026/Conference/Submission18535/Reviewer_y1XC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18535/Reviewer_y1XC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927610945, "cdate": 1761927610945, "tmdate": 1762928232611, "mdate": 1762928232611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors extend Prior‚ÄëData Fitted Networks (PFNs) from supervised prediction to *Bayesian clustering*. Their **Cluster‚ÄëPFN** is a Transformer that, given a set of points (X) and an input (k), outputs (i) a distribution over the *number of clusters* (P(k \\mid X)) (when fed (k=0)) and (ii) *responsibilities* (p(z_i=k\\mid X,k)) for each point when a cluster count is provided. A special ‚Äúcollector‚Äù token (\\rho) aggregates information to predict (P(k\\mid X)) (Figure 2, p.3), and the model conditions on (k) via an embedding added to all tokens. \nThe model is trained entirely on synthetic datasets drawn from a *finite GMM* with Normal‚ÄìInverse‚ÄëWishart priors; versions include 2D and up to 5D inputs as well as *random missingness* up to 80%. Architecture uses a 4‚Äëlayer, 4‚Äëhead encoder with 256‚Äëdim embeddings (Appendix C)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Demonstrates that a single Transformer forward pass‚Äîtrained purely on synthetic prior‚Äësamples‚Äîcan approximate *both* (P(k\\mid X)) and responsibilities, a compelling extension of PFNs into unsupervised Bayesian modeling. The special (\\rho) token for (k) prediction (Fig. 2) and conditioning mechanism are simple but elegant.  Clear runtime wins vs VI, even when VI uses multiple inits (Table 2), and scaling tests up to 20k points show consistent advantages (times reported on p.8)."}, "weaknesses": {"value": "For AIC/BIC/silhouette, the search over (k) *excludes (k=1)* ‚Äúsince the silhouette score is undefined for a single cluster‚Äù (p.5). But AIC and BIC are perfectly well‚Äëdefined at (k=1). Excluding (k=1) likely *penalizes* AIC/BIC whenever the truth is one cluster, inflating Cluster‚ÄëPFN‚Äôs relative accuracy in Table 1. A fair protocol would allow (k\\in{1,\\ldots,K}) for AIC/BIC and handle silhouette separately. \n\nThe paper argues Cluster‚ÄëPFN ‚Äúapproximates the true Bayesian posterior over the number of clusters‚Äù by analogy with supervised PFNs, but *responsibilities are learned independently* , not via a coherent joint posterior over ((\\theta,z)). Moreover, when (k) is unknown, the method ultimately uses a *two‚Äëpass MAP (k)* rather than integrating over (k) (the fully Bayesian option the model initially formulates), because of label‚Äëordering bias. This iweakens the Bayesian claim for responsibilities. \n\n The model sometimes fails to obey a user‚Äëspecified (k), especially when the instruction is ‚Äúwildly different‚Äù from the data‚Äôs structure; the authors quantify this and show accuracy improves when conditioning near the unconditioned prediction. For downstream pipelines that *require* exactly (k) clusters, this is a limitation. \n\n The deterministic relabeling uses distance to the origin after zero‚Äëone scaling. While consistent across training tasks, it encodes an *arbitrary geometry* (e.g., clusters near (\\mathbf{0}) get low indices), is sensitive to min‚Äìmax scaling quirks, and is not feature‚Äëpermutation invariant‚Äîan issue the authors also list as a limitation (Section 7). More principled label alignment (e.g., Hungarian matching to learned prototypes) or an equivariant architecture would be cleaner. \n\nThe paper itself notes that on real datasets without severe missingness, Cluster‚ÄëPFN is ‚Äúnot always competitive,‚Äù with clear wins mainly on GLS1 and under high missingness (Section 6). This underscores *prior mismatch*: training solely on finite‚ÄëGMM priors may not capture real data complexity (also discussed on p.9).  Further,  experiments cap at 5D and produce 10 logits (Appendix C). This raises questions about behavior in high‚ÄëD tabular domains (common in genomics) and for larger (K). The paper mentions feature‚Äëpermutation invariance and scaling to higher (d) as future work (Section 7). \n\nTransformer‚Äôs (O(N^2)) attention remains; so  very large (N) regimes may still be challenging without sparse/linear attention variants. \n\nThe paper reports NLL of responsibilities (with label‚Äëpermutation minimization) and shows a histogram (Fig. 5c‚Äìd), but does not assess calibration of (P(k\\mid X)) or of per‚Äëpoint responsibilities (e.g., reliability diagrams, ECE). This matters if outputs are to be trusted as Bayesian probabilities."}, "questions": {"value": "Fix the (k=1) baseline issue  Re‚Äërun AIC/BIC with (k\\in{1,\\ldots,K}); report per‚Äë(k) accuracy and overall accuracy marginalizing (k\\sim U(1,K)). \n\nCompare against EM/VI that marginalize missing features directly for GMMs, not only imputation‚Äëbased pipelines. \n\nReliability diagrams and proper scoring (e.g., Brier) for (P(k\\mid X)); temperature scaling if needed. Include calibration for responsibilities. \n\n Train on broader priors (non‚ÄëGaussian, skewed/cluster‚Äësize imbalance, heavy‚Äëtailed, anisotropic covariances) and evaluate on real data; quantify sensitivity to prior misspecification (Section 6 hints at this). \n\n Demonstrate feature‚Äëpermutation‚Äëequivariant variants (as suggested in Section 7) and report how accuracy and runtime change."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "40Pi34kuVA", "forum": "MCya4TeDW6", "replyto": "MCya4TeDW6", "signatures": ["ICLR.cc/2026/Conference/Submission18535/Reviewer_3zPn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18535/Reviewer_3zPn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967704672, "cdate": 1761967704672, "tmdate": 1762928232212, "mdate": 1762928232212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}