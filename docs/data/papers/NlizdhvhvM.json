{"id": "NlizdhvhvM", "number": 16124, "cdate": 1758260306133, "mdate": 1759897260315, "content": {"title": "PipeTune: Tuning Pipeline Parallelism for Efficient Vision-Language Model Training", "abstract": "Training vision-language models (VLMs) efficiently is crucial for advancing multimodal understanding, yet remains challenging due to the heterogeneity of training data. Variations in sequence lengths and modality composition significantly degrade the performance of pipeline parallelism (PP), leading to increased idle times and low hardware utilization.\n\nWe present PipeTune, a unified framework that systematically mitigates these inefficiencies by jointly optimizing micro-batch construction, ordering, size, and vision encoder computation. PipeTune adopts a computation-aware packing algorithm to balance workloads, dynamically adjusts micro-batch sizes based on sampled data, reorders execution to minimize stalls, and exploits idle times for encoder pre-computation. A lightweight simulator guides runtime decisions, enabling performance optimization without altering training semantics.\n\nAcross diverse model sizes, dataset mixtures, and hardware configurations, PipeTune consistently accelerates training, achieving up to 40.7\\% reduction in iteration time. Our evaluation demonstrates that each optimization component contributes complementary gains, and the overall overhead remains minimal. By holistically addressing data-induced inefficiencies, PipeTune enables more scalable and efficient training of VLMs.", "tldr": "PipeTune improves vision-language model training efficiency by adaptively tuning pipeline parallelism.", "keywords": ["Pipeline Parallelism", "Vision-Language Model", "Efficiency"], "primary_area": "infrastructure, software libraries, hardware, systems, etc.", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/df5540112d25ccefdbb0ef2c7e39c51d2995ade2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses low GPU utilization in Vision-Language Model training under pipeline parallelism. The core problem is that heterogeneous samples with variable sequence lengths and mixed modalities create imbalanced microbatches and pipeline bubbles, wasting compute time.\n\nPipeTune is a runtime framework that jointly optimizes four strategies: computation-aware packing of samples into microbatches, adaptive microbatch sizing based on real-time statistics, microbatch reordering to balance workload across stages, and vision encoder pre-computation that overlaps ViT work with downstream processing. A lightweight simulator guides these decisions without changing training semantics.\n\nContributions:\n* A unified scheduling approach that jointly optimizes packing, sizing, and ordering of microbatches rather than tuning each parameter independently, minimizing per-stage compute variance to reduce pipeline bubbles.\n* Dynamic microbatch size selection that adapts to heterogeneous sample characteristics and fits stage-wise memory constraints, plus an encoder precompute strategy that co-locates the ViT with the first pipeline stage to overlap computation.\n* Empirical validation showing up to 40.7% iteration time reduction across VLMs with 3-13B parameter LLMs, with the approach being practical to deploy since it requires no changes to model architecture, training objectives, or optimizer code."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* **Joint, runtime optimization of PP knobs.** Treats packing, microbatch sizing, and microbatch ordering as a coupled problem (plus ViT precompute), directly reducing per-stage variance and 1F1B bubbles rather than tuning any single knob in isolation.\n\n* **Practical, low-friction integration.** Preserves training semantics (no loss/optimizer changes), uses a lightweight simulator/profiler, and leverages a sensible PP topology (ViT on stage-0 + caching) that fits common VLM stacks.\n\n* **Strong empirical signal with ablations.** Demonstrates sizable iteration-time reductions across models/hardware, with ablations that attribute additive gains to each component, suggesting robustness beyond a single setup."}, "weaknesses": {"value": "* Workload sensitivity (benefits fade as image fraction rises). The largest gains appear in regimes dominated by text (e.g., ≳80–90% text tokens or samples). As the image proportion increases, stage-0 (ViT+projector), the benifite of PipeTune decreases quickly.\n* Comparison to other PP approaches (e.g., LongVILA)\n* Dataset selection: rather a-typical. Most VLMs are post-trained on datasets such as LLaVA-OneVision / FineVision / Cambrian1"}, "questions": {"value": "* How do the reported gains scale when the image ratio rises beyond the text-heavy regime (e.g., 30–60% image samples) and when resolution/augments increase ViT FLOPs? Please include a sweep over modality mix and input resolution, with breakdown of stage-0 utilization, NVLink traffic, and end-to-end step time."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZnlxdhrHdj", "forum": "NlizdhvhvM", "replyto": "NlizdhvhvM", "signatures": ["ICLR.cc/2026/Conference/Submission16124/Reviewer_mxG1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16124/Reviewer_mxG1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761435385214, "cdate": 1761435385214, "tmdate": 1762926296441, "mdate": 1762926296441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PipeTune, a framework for improving the efficiency of vision-language model (VLM) training under pipeline parallelism. The authors propose to jointly optimize micro-batch construction, ordering, size, and vision encoder scheduling. The method includes a computation-aware packing strategy, dynamic micro-batch resizing, encoder pre-computation, and reordering. A lightweight simulator guides runtime decisions. Experiments reportedly show up to 40% iteration-time reduction across different data mixtures and model scales."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper clearly identifies practical inefficiencies in pipeline-parallel VLM training due to workload imbalance.\n2.\tThe paper provides a unified framework integrating several optimization strategies.\n3.\tThe paper is generally well-structured, and figures (e.g., Figure 2 and Figure 6) help clarify the ideas."}, "weaknesses": {"value": "1.\tThe paper refers to DistMM, Dynapipe, OrchMLLM, and DistTrain, which tackle highly similar efficiency and load balancing issues in pipeline parallelism. However, the experimental section only compares PipeTune against simple baselines (Original, Balanced), without direct comparisons to these strong baselines.\n2.\tThe technical novelty is limited. The method mainly combines existing heuristics (packing, reordering, pre-computation), without new theoretical insights.\n3.\tOnly limited hardware and dataset configurations were tested, downstream task performance was not reported, and training stability and convergence were not analyzed."}, "questions": {"value": "Refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ARFo39O6dW", "forum": "NlizdhvhvM", "replyto": "NlizdhvhvM", "signatures": ["ICLR.cc/2026/Conference/Submission16124/Reviewer_awvn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16124/Reviewer_awvn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879716118, "cdate": 1761879716118, "tmdate": 1762926296058, "mdate": 1762926296058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PipeTune, a framework for optimizing pipeline parallelism in VLM training by addressing inefficiencies caused by data heterogeneity. The system jointly optimizes four aspects: micro-batch construction through computation-aware packing, dynamic micro-batch sizing, micro-batch execution ordering, and vision encoder pre-computation scheduling. PipeTune uses a lightweight DAG-based simulator to guide runtime decisions and achieve up to 40.7% reduction in iteration time across various model sizes (3B-13B parameters) and dataset mixtures. The approach is evaluated on two GPU clusters using pipeline parallelism across 4 nodes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Problem formulation: The paper clearly identifies and categorizes three distinct sources of inefficiency in VLM training (micro-batch imbalance, inter-iteration fluctuation, and modality composition variance); good motivation for the proposed solutions.\n\n2. Holistic optimization approach: Rather than addressing individual bottlenecks in isolation, PipeTune jointly optimizes multiple dimensions (e.g., packing, sizing, ordering, scheduling), demonstrating complementary gains through ablation studies.\n\n3. Practical implementation and evaluation: The system is built on PyTorch-native TorchTitan framework and evaluated across diverse realistic settings, with detailed breakdown of contribution from each component."}, "weaknesses": {"value": "1. Limited novelty of individual components: While the holistic combination is valuable, each individual technique may have prior works... The computation-aware packing is acknowledged as inspired by WLB-LLM, encoder pre-computation follows Optimus, and micro-batch reordering builds on established ideas from DynaPipe. The paper's primary contribution appears to be engineering integration rather than algorithmic innovation. The authors should more explicitly position their contribution as a systems integration work and provide clearer articulation of what technical challenges arise from combining these techniques.\n\n2. Only tested with relatively small vision encoders (0.4B SigLIP); scalability to larger encoders (e.g., 4B+ models used in state-of-the-art VLMs) is unclear\n\n3. No comparison with recent concurrent work (OrchMLLM, Zheng et al., 2025 is cited but not compared)\n\n4. Missing convergence validation - while the paper claims \"without affecting convergence behavior,\" no learning curves or downstream task performance is shown\n\n5. Algorithm 1's two-stage greedy strategy (lines 4-9: minimize FLOPs, lines 8-9: fallback to minimum length) lacks theoretical or empirical justification for why this heuristic is optimal\n\n6. The clustering-based approach for micro-batch ordering (Section 5.2) limits clusters to six but provides no analysis of this hyperparameter choice or its impact on solution quality\n\n\n7. Simulator accuracy and validation concerns: The DAG-based simulator is central to PipeTune's decision-making, yet its accuracy is never validated. The paper mentions offline profiling to characterize computation time vs. sequence length relationships, but provides no details on: (1) the functional form of these models, (2) their prediction error across different sequence lengths and hardware, (3) how communication costs are modeled, (4) whether the simulator accounts for GPU kernel launch overhead, memory bandwidth constraints, or other real-world factors. Without this validation, it's unclear whether observed gains come from good optimization decisions or from systematic simulator bias that happens to align with reality. The authors should provide detailed simulator validation showing predicted vs. actual latency across representative scenarios."}, "questions": {"value": "Please address the implicitly embedded questions in the weakness.\n\nHow does encoder pre-computation affect peak memory usage? How are communication costs for encoder outputs modeled in the simulator, especially when pre-computed results need to be transferred?\n\nWhat APIs or interfaces would practitioners use to integrate PipeTune into their training pipelines? How sensitive is the approach to profiling accuracy - what happens if hardware characteristics change during training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KIkU41qQs1", "forum": "NlizdhvhvM", "replyto": "NlizdhvhvM", "signatures": ["ICLR.cc/2026/Conference/Submission16124/Reviewer_jsBD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16124/Reviewer_jsBD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984436201, "cdate": 1761984436201, "tmdate": 1762926295735, "mdate": 1762926295735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PipeTune, a framework designed to optimize pipeline parallelism for training VLMs.  The core problem it addresses is the inefficiency in pipeline parallelism caused by data heterogeneity."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a computation-aware packing algorithm to balance workloads across micro-batches. \n2. The paper employs a pipeline simulator to estimate the latency to dynamically adjust the micro-batch size, addressing the fluctuations in the number of micro-batches across iterations.\n3. The paper uses encoder pre-computation and micro-batch reordering to solve the modality composition variance problem across micro-batches."}, "weaknesses": {"value": "1. The paper's primary contribution is the joint optimization guided by a simulator, yet the details are  underdeveloped.  The details of how the DAG-based simulator actually models computational time from input sequence length, and the search process for the optimal micro-batch sizes and ordering are omitted.\n2. The simulator's latency estimates depend on an offline profiling step that is specific to a given hardware setup and model architecture. Therefore, any change in hardware or model requires a costly re-profiling. The paper does not discuss the overhead of this mandatory profiling, making the practical adoption cost in new environments unclear.\n3. According to Fig.6, the effectiveness of the Balance Packing Algorithm is inconsistent and appears limited to specific data compositions. While it provides a significant reduction in iteration time in the text-dominant setting (DataMix1) , its benefit is far less pronounced in multimodal-heavy settings (DataMix2 and DataMix3). This suggests that it only partially addresses the data heterogeneity problem.\n4. The ablation study in Table 2 groups \"Micro-batch reordering\" with \"Encoder pre-computation\". However, the encoder pre-computation follows prior work (Feng et al., 2025), therefore it is impossible to isolate the contribution. \n5. The novelty of this work is a bit moderate. While the proposed PipeTune consist of multiple individual techniques (e.g. FLOPs-based packing, micro-batch reordering, and lightweight simulator–guided search), most of them are incremental extensions or integrations of existing ideas."}, "questions": {"value": "1. Please provide a detailed description for the pipeline simulator. How are stage latencies estimated from the offline profiling? Also, please provide the full search algorithm of how optimal micro-batch sizes and ordering are determined.\n2. Please include the experiment to clarify the practical benefit of using a FLOPs-based packing estimate versus the latency-based one from prior work (Wang et al. 2025). \n3. The paper claims that the proposed adaptive micro-batch sizing do not alter \"training semantics\". However, dynamically changing the micro-batch size alters the number of gradient accumulation steps, which could impact convergence. Please provide experimental evidence (e.g., training loss curves) to support your claim that convergence is unaffected."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MMzNdtgo81", "forum": "NlizdhvhvM", "replyto": "NlizdhvhvM", "signatures": ["ICLR.cc/2026/Conference/Submission16124/Reviewer_vZY6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16124/Reviewer_vZY6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994818511, "cdate": 1761994818511, "tmdate": 1762926295387, "mdate": 1762926295387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}