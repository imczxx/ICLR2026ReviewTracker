{"id": "5VXJPS1HoM", "number": 754, "cdate": 1756816871077, "mdate": 1759898243611, "content": {"title": "Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning", "abstract": "Deepfake detection remains a formidable challenge due to the evolving nature of fake content in real-world scenarios. However, existing benchmarks suffer from severe discrepancies from industrial practice, typically featuring homogeneous training sources and low-quality testing images, which hinder the practical usage of current detectors. To mitigate this gap, we introduce **HydraFake**, a dataset that contains diversified deepfake techniques and in-the-wild forgeries, along with rigorous training and evaluation protocol, covering unseen model architectures, emerging forgery techniques and novel data domains. Building on this resource, we propose **Veritas**, a multi-modal large language model (MLLM) based deepfake detector. Different from vanilla chain-of-thought (CoT), we introduce *pattern-aware reasoning* that involves critical patterns such as \"planning\" and \"self-reflection\" to emulate human forensic process. We further propose a two-stage training pipeline to seamlessly internalize such deepfake reasoning capacities into current MLLMs. Experiments on HydraFake dataset reveal that although previous detectors show great generalization on cross-model scenarios, they fall short on unseen forgeries and data domains. Our Veritas achieves significant gains across different out-of-domain (OOD) scenarios, and is capable of delivering transparent and faithful detection outputs.", "tldr": "We introduce a MLLM-based detector for transparent deepfake detection, along with a holistic dataset for deepfake detection.", "keywords": ["Deepfake Detection", "MLLMs"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/87fbd7a6dccb9abfb545573136331a8bb8036c4a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces the HydraFake dataset and the VERITAS model.\nThe HydraFake dataset encompasses a diverse range of deepfake generation techniques and real-world forgery cases. It provides a rigorous training and evaluation protocol that covers unseen model architectures, emerging forgery techniques, and novel data domains.The VERITAS detector, built upon a Multimodal Large Language Model (MLLM), differs from conventional Chain-of-Thought (CoT) based reasoning frameworks. It employs a two-stage training pipeline — pattern-guided cold start followed by pattern-aware exploration — with a particular emphasis on key reasoning modes such as “planning” and “self-reflection”.By simulating the human forensic reasoning process, VERITAS integrates the cognitive capabilities of large language models into deepfake detection (DFD), thereby achieving enhanced cross-manipulation and cross-domain generalization performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposed VERITAS framework demonstrates strong innovation in the field of Deepfake detection. Its core contribution lies in transforming the traditional feature-memorization-based detection paradigm into a reasoning-based framework grounded in pattern-aware reasoning.Unlike previous models that rely on specific forgery artifacts, VERITAS explicitly models forgery patterns as transferable reasoning units, enabling the understanding of common structural characteristics shared across different forgery types. In addition, the authors introduce a Chain-of-Thought (CoT) reasoning mechanism, allowing the model to progressively identify manipulated regions through multi-step logical inference, thereby enhancing interpretability and robustness.\nThe paper further proposes a Mixed Preference Optimization (MiPO) strategy, which balances the learning preferences among various forgery patterns, effectively improving the model’s cross-manipulation and cross-domain generalization capabilities.Overall, this study presents substantial innovation and academic value across three dimensions — detection paradigm, reasoning mechanism, and optimization strategy."}, "weaknesses": {"value": "1. Lack of fair comparison with recent large-scale multimodal frameworks.\n\nAlthough VERITAS demonstrates impressive performance, the experimental comparison is incomplete and lacks fairness.\nThe paper does not include evaluations against recent large-scale multimodal or reasoning-based deepfake detection frameworks, such as FakeShield (ICLR 2025), M2F2-Det (CVPR 2025), and SIDA (CVPR 2025).\n\nThese methods share similar reasoning or multimodal fusion paradigms and therefore represent the most relevant baselines for comparison.\n\nIn contrast, most of the reported baselines are lightweight detectors (with only tens or hundreds of millions of parameters), while VERITAS is built upon an 8B-scale MLLM.\n\n\n2. Limited domain coverage.\n\nThe current work focuses exclusively on face-oriented deepfake detection, whereas a growing number of studies have begun exploring cross-domain and generalized forgery detection, such as AIGC-generated content, IMDL (image manipulation localization), and general multimedia forensics frameworks (e.g., Effort, FakeShield, ForensicHub(NeurIPS 2025) ).\n\nExpanding the scope of VERITAS to handle non-facial or multi-domain forgery types would not only enhance its practical value but also align it with the emerging trend toward universal content authenticity verification."}, "questions": {"value": "Q1: Could the authors provide additional comparisons or discussions with recent large multimodal reasoning-based detectors (e.g., FakeShield, M2F2-Det, SIDA) to better contextualize VERITAS?\n\nIf this question is properly addressed, it would increase my score, as a fair comparison with large models is the most critical issue.\n\nQ2: Does the proposed VERITAS framework have the potential to generalize beyond face forgery detection — for example, to AIGC-generated or other cross-domain manipulation tasks?\n\nIf this aspect is explored or discussed, it would further raise my score, though it is secondary to the first point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UnnOwhnUMz", "forum": "5VXJPS1HoM", "replyto": "5VXJPS1HoM", "signatures": ["ICLR.cc/2026/Conference/Submission754/Reviewer_wJ4c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission754/Reviewer_wJ4c"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760948385372, "cdate": 1760948385372, "tmdate": 1762915598581, "mdate": 1762915598581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper makes two primary contributions to the field of deepfake detection. First, it introduces HydraFake dataset, which extends the evaluation into a rigorous and hierarchical setting, providing a more realistic and challenging benchmark to the field. Second, the paper proposes Veritas, a novel MLLM-based detector. Experiments show both qualitatively and quantitatively the effectiveness of the model."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- The proposed dataset is well-motivated. The division of four evaluation levels (i.e., in-domain, cross-model, cross-forgery and cross-domain) is reasonable. A fine-grained evaluation protocol is critical and reasonable at the moment, and the constructed dataset is of high quality, providing a challenging evaluation suite for the community.\n- The proposed pattern-aware reasoning is effective and insightful compared to previous explainable methods. Experiments clearly show its superiority compared to previous pipelines.\n- The proposed MiPO and P-GRPO is coherent with the proposed reasoning framework. Thorough ablations are conducted to validate their effectiveness."}, "weaknesses": {"value": "- The authors should provide some failure cases to understand the model’s limitations.\n- More fine-grained ablations on the reasoning patterns could be done, e.g., what if removing the “reflection”/“planning” pattern?\n- How \"reflection\" improves model's generalization capability to unseen forgeries? The author should provide more explanations to it.\n- The human has very good reasoning capabilities. Why even human cannot accurately detect some (realistic) deepfakes? Is semantic-level reasoning capability truly crucial for deepfake detection?"}, "questions": {"value": "1.\tIn Figure 1, the proposed Veritas can perceive the textual anomalies. Is such type of analysis contained in the training set? If not, can the base model conduct similar analysis?\n\n2.\tIn the MiPO stage, how is the image selected? What if removing the non-preference $s_l^{\\phi}$ in the training data? It would be great to provide some case studies."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nXNZhwATM0", "forum": "5VXJPS1HoM", "replyto": "5VXJPS1HoM", "signatures": ["ICLR.cc/2026/Conference/Submission754/Reviewer_dw7z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission754/Reviewer_dw7z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893420559, "cdate": 1761893420559, "tmdate": 1762915598459, "mdate": 1762915598459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HydraFake, a deepfake detection dataset with hierarchical OOD evaluation (in-domain, cross-model, cross-forgery, cross-domain), and VERITAS, an MLLM-based detector using pattern-aware reasoning. VERITAS employs five thinking patterns (fast judgment, planning, reasoning, self-reflection, conclusion) trained via a two-stage pipeline: pattern-guided cold-start with MiPO and pattern-aware exploration with P-GRPO. The approach shows significant improvements in cross-forgery and cross-domain scenarios, which are important in real-life scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed HydraFake dataset addresses a crucial gap between academic benchmarks and industrial deployment scenarios, making it valuable for real-world applications.\n- The authors have conducted comprehensive experiments, including comparisons with SOTA methods and detailed ablation studies, verifying the effectiveness of the proposed VERITAS model.\n- The pattern-aware reasoning approach is reasonable, drawing inspiration from human cognitive processes to create more interpretable and robust detection systems."}, "weaknesses": {"value": "- The two-stage training pipeline with MiPO and P-GRPO, though modified for forgery detection tasks, still seems to be a direct application of vanilla DPO and GRPO methods, which may undercut its novelty.\n- The paper evaluates VERITAS exclusively on the proposed HydraFake dataset, raising concerns about overfitting to their specific evaluation protocol. It would strengthen claims about VERITAS's superiority and provide more convincing evidence of its effectiveness if authors could perform evaluations on other benchmarks such as LOKI [cite 1] and Forensics-bench [cite 2].\n\n[cite 1] LOKI: A COMPREHENSIVE SYNTHETIC DATA DETECTION BENCHMARK USING LARGE MULTIMODAL MODELS. In ICLR 2025.\n\n[cite 2] Forensics-Bench: A Comprehensive Forgery Detection Benchmark Suite for Large Vision Language Models. In CVPR 2025."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZdQeP2pw55", "forum": "5VXJPS1HoM", "replyto": "5VXJPS1HoM", "signatures": ["ICLR.cc/2026/Conference/Submission754/Reviewer_MgHh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission754/Reviewer_MgHh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981383671, "cdate": 1761981383671, "tmdate": 1762915598165, "mdate": 1762915598165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper first introduces the HydraFake dataset, which aggregates real and fake images from existing sources and by reimplementing and crawling 10K deepfake samples produced by 10 advanced generators, resulting in 50K real and 50K fake images. It also proposes a two-stage training pipeline for MLLM-based deepfake detection. In the first (SFT) stage, MiPO is introduced to internalize reasoning patterns; in the second stage, the pattern-aware GPRO promotes comprehensive reasoning and enables potential self-reflection. Extensive experiments on in-domain, cross-model, cross-forgery, and cross-domain evaluation sets demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "a.The proposed dataset spans diverse domains and sources of real and manipulated images, including generative face‑swapping, visual autoregressive models, and deepfakes collected from social media.\nb.The two‑stage training pipeline substantially outperforms existing deepfake detection methods, as demonstrated in Table 1."}, "weaknesses": {"value": "a.The proposed method employs SFT and GPRO within an MLLM‑based deepfake detection framework—an established post‑training strategy.\nb.The difference between the proposed pattern \"<fast><planning><reasoning><conclusion>\" and the commonly used \"<think>... </think>\" paradigm has not been analyzed."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hWBtcmkj04", "forum": "5VXJPS1HoM", "replyto": "5VXJPS1HoM", "signatures": ["ICLR.cc/2026/Conference/Submission754/Reviewer_bRzS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission754/Reviewer_bRzS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762258045102, "cdate": 1762258045102, "tmdate": 1762915597985, "mdate": 1762915597985, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}