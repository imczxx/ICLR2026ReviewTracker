{"id": "38ioKDbyP7", "number": 22676, "cdate": 1758334365788, "mdate": 1759896852930, "content": {"title": "DP-Nav: Dynamic Exploration Driven by Semantic Region Potential for Zero-shot Visual Navigation", "abstract": "Visual navigation requires the agent to autonomously navigate to a specified goal based on sequential visual perception. A key challenge is to achieve target localization and optimize the path simultaneously. However, most existing frontier-based methods rely on static navigation policies, which update the target frontiers at fixed time intervals to guide the agent's exploration. These approaches cannot dynamically assess potential regions encountered during navigation, thereby preventing timely policy adjustments. Moreover, the presence of multiple frontiers within the same region often leads to repeated exploration of identical regions, further exacerbating path redundancy and inefficiency. To address the above limitations, we propose DP-Nav, a novel dynamic navigation framework driven by the potential of semantic regions. Our approach first identifies distinct semantic regions from sequential visual perception and treats an independent semantic region as a policy unit. Furthermore, we introduce a Scoring-Screening Mechanism (SSM) that evaluates and filters these semantic regions based on their potential utility. Then SSM assigns exploration priorities to different regions, selecting the semantic region with the highest potential value for the agent's subsequent exploration. More significantly, we design a Dynamic Policy Trigger (DPT) module that enables on-demand activation of the SSM, allowing the agent to dynamically adapt its exploration policy in response to environmental changes and perceptual feedback, thereby addressing the rigidity of static policies. Extensive experiments on Object Goal Navigation, Text Goal Navigation, and Instance Image Goal Navigation across Gibson, HM3D, and MP3D datasets demonstrate that DP-Nav achieves SOTA performance and improves path efficiency by about $7\\%\\sim17\\%$.", "tldr": "we propose DP-Nav, a novel dynamic navigation framework driven by the potential of semantic regions.", "keywords": ["visual navigation", "large language model", "path optimization"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c3b04619d527c7db3cca8f4332dd123d6acbacc5.pdf", "supplementary_material": "/attachment/01aba34c50785f114353b05bffe450e2e387f36c.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes DP-Nav, a dynamic visual navigation framework driven by semantic region potential. It represents the scene with a “region–junction graph” and aggregates each region via representative views. At the policy level, a Scoring–Screening Mechanism (SSM) fuses VLM semantic scores with path cost, and four Dynamic Policy Triggers (DPT) enable on-demand replanning. Experiments on ObjectNav, TextNav, and InstanceNav in Gibson/HM3D/MP3D report improvements over zero-shot baselines along with ablations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* **Cross-task and cross-dataset zero-shot comparisons**  \n  • On HM3D ObjectNav, DP-Nav outperforms UniGoal by +8% SR and +10.5% SPL.  \n  • On HM3D TextNav, it surpasses UniGoal by +5.4% SR and +8.1% SPL.  \n  • On InstanceNav, it shows substantial gains over GOAT and PSL.  \n\n* **Relatively complete implementation and appendix details**  \n  • The paper specifies the VLM used (Qwen2.5-VL-3B-Instruct) and the step limit / success radius.  \n  • The appendix explains prompt usage scenarios (scoring prompts and deep-exploration prompts)."}, "weaknesses": {"value": "* **Insufficient direct validation that VLM scoring reflects “navigability”**  \n  • The textual example in Fig. 4 (“Looks like a restroom, give 0.8”) appears to measure semantic visibility rather than reachability.  \n  • SSM treats $VLM(V*_r)$ as the core of region potential, yet provides no correlation or calibration curves versus success rate or SPL.  \n  • Only one VLM model is used; there is no cross-model consistency or degraded controls (e.g., random or heuristic scores).  \n\n* **Coverage and omissions of hand-crafted triggers are not systematically evaluated**  \n  • The four triggers are rule-based; despite gains, there is no quantitative diagnostic for misses and false alarms.  \n  • The view-update gate $φ_pug$ being too small induces “action oscillation,” while too large causes “policy lag,” indicating strong hyperparameter sensitivity.  \n  • No specific analysis is provided for difficult layouts such as long corridors, loops, dead ends, or repeated visits.  \n  • For the Region-Reached trigger that re-invokes the VLM to decide “deep exploration,” the false-trigger rate and backtracking cost are unreported.  \n\n* **Limited interpretability and sensitivity analysis for SSM weighting and screening**  \n  • For preference score ( $\\mathrm{PS}=\\gamma\\cdot \\mathrm{VLM}+(1-\\gamma)e^{-\\lambda\\cdot \\mathrm{Path}}$ ), γ and λ appear only in a table without theoretical or empirical calibration procedure.  \n  • The assignment to progressing/backtracking lists depends on threshold sets (ϕ, ζ), but systematic sensitivity curves are missing.  \n\n* **Experimental fairness and statistical rigor need strengthening**  \n  • The SOTA claims in Table 1 lack variance, confidence intervals, and multiple random seeds.  \n  • Although there are ablations on triggers and SSM, significance testing and stratified comparisons across scenarios are absent."}, "questions": {"value": "* **Validate and calibrate VLM scoring for navigability**  \n  • Construct counterfactual scenes that are semantically visible yet hard to reach, and report correlations and segmented trends between VLM scores and success rate/SPL. Provide an ROC curve for ζ with target AUC above random.  \n  • Conduct cross-model consistency experiments (add 1–2 more VLMs) and degraded controls (random scores, simple heuristics) to verify robust ranking. Target an improvement of at least x% over degraded controls, presented as new columns in a Table 1–style summary.  \n  • Report sensitivity scans of ζ and performance under OOD conditions (occlusion, camouflage, atypical appearances); provide threshold–performance curves and select a stable operating point.  \n  • In Appendix A.11, include full prompts, few-shot examples, failure cases, and statistics of failure types (false positives/negatives) aligned with the subjective text in Fig. 4.  \n \n* **Systematically evaluate trigger coverage to reduce omissions and false triggers**  \n  • Build benchmark sets for long corridors, loops, dead ends, and repeated visits; report trigger rates, false-trigger rates, and miss rates for each of the four triggers with PR curves or box plots.  \n  • Perform fine-grained scans over $φ_pug$ and couple them with different numbers of representative views (RP) to quantify “oscillation” versus “lag,” reporting policy-switch frequency and average path redundancy.  \n  • Add a “trigger failure type” column to a Table 3/4–style ablation, quantifying each failure category and its contribution to SR/SPL to verify improved coverage.  \n\n* **Enhance experimental fairness and statistical rigor**  \n  • For all entries in Table 1, report mean ± standard deviation with 3–5 random seeds.  \n\n* **Assess VLM output consistency and sampling variance (same environment, different sampling)**  \n  • Fix the environment and camera pose; vary the VLM random seed, temperature, or sampling strategy (top-k, top-p). Re-score multiple times and report consistency of region scores and rankings using ICC, Kendall τ, or Spearman ρ. Criterion: τ or ρ ≥ 0.8; if lower, analyze causes.  \n  • Apply small pose jitter within the same environment (translation ±5 cm, rotation ±5°), resample representative views, and replicate scoring. Compute per-region score variance and coefficient of variation; plot variance versus jitter magnitude. Criterion: within task tolerance, score variance should not cause frequent flips among the top-k regions.  \n  • Test prompt robustness via minor paraphrases and synonym substitutions; compare ranking differences and report the similarity distribution. Criterion: high median similarity with a small interquartile range.  \n  • Quantify the effect of consistency on navigation outcomes by comparing the distributions of SR and SPL across repeated scoring-driven plans. Report mean differences and confidence intervals and the maximum observed fluctuation. Criterion: SR/SPL variation remains within a preset bound, for example absolute difference ≤ 1 percentage point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aymyT5AnjG", "forum": "38ioKDbyP7", "replyto": "38ioKDbyP7", "signatures": ["ICLR.cc/2026/Conference/Submission22676/Reviewer_8dHA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22676/Reviewer_8dHA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753048521, "cdate": 1761753048521, "tmdate": 1762942330712, "mdate": 1762942330712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for constructing a topological graph for object-goal navigation. This graph consists of two types of nodes: region nodes and junction nodes, where region nodes represent areas to explore and junction nodes connect region nodes. A Score-Screening Mechanism (SSM) is proposed using LVM to assign scores to each region node and divide them into a processing list and a backtracking list. A Dynamic Policy Trigger (DPT) module is introduced to activate SSM and dynamically drive the agent's exploration. Experiments are conducted on three types of navigation tasks across three datasets, achieving superior performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper identifies two issues in existing frontier-based exploration (FEB) navigation: frontiers are updated at fixed time steps, and the agent may jump inconsistently between different regions due to each frontier being treated individually.\n\n2. The method part is technically sound. Note that it refers to the correctness and feasibility, with a clear illustration of nice-looking figures. \n\n3. The experiment performance is superior to the recent works on all three tasks across different datasets. In some cases, the SR and SPL improvement is evident by a margin."}, "weaknesses": {"value": "There are several weaknesses concerning novelty and claim:\n\n1. Sections 3.3.1 to 3.4.3 are more engineering-oriented; that is, it is hard to identify new network architectures, algorithms, or pipelines. This is not questionable with respect to the correctness of the method, but rather concerns the novelty. The authors should highlight the key novelty that is different from previous works.\n\n2. In Related Work (Line 141 - 142), the authors briefly mention that the proposed method is a policy with self-adaptation, which is different from previous graph-based methods. However, it lacks support or evidence for \"self-adaptation\" in the Method section. The main distinction from previous graph-based methods is not highlighted.\n\n3. The authors mention two key issues in existing FBE methods in the Introduction (Line 49 - 76), but how the proposed method addresses these two issues is not clearly stated. For example, does the DPT module update frontiers at varying time steps? Do we only consider one frontier in each semantic region, or consider all frontiers in the semantic region as a whole for the decision?\n\n4. The authors mention \"semantic\" regions several times. But in Section 3.3.1, the region node is constructed purely based on geometry with traditional approaches. It is questionable these regions truly contain meaningful semantics.\n\n5. The four triggers described in Section 3.4.4 are not clearly presented. It is hard to follow this section. I regard this as a writing issue. In addition, it is unclear whether others can borrow this idea without using the graph built in Section 3.3.1, as these triggers closely coupled with the graph."}, "questions": {"value": "1. Can we merge two junction nodes in the topological graph regardless of their distance? In Line 229 - 230, there is a radius threshold to fuse junction nodes, which I think can be removed.\n\n2. Why do we need to differentiate the Processing list and the Backtracking list? We can just explore regions based on the combination of VLM scores and distance in descending order."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mbupc9YSfO", "forum": "38ioKDbyP7", "replyto": "38ioKDbyP7", "signatures": ["ICLR.cc/2026/Conference/Submission22676/Reviewer_ZTxk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22676/Reviewer_ZTxk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834972092, "cdate": 1761834972092, "tmdate": 1762942330464, "mdate": 1762942330464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DP-Nav, which performs VLM-guided dynamic exploration on a Region–Junction Graph (RJG). The system comprises four modules: (1) RJG construction from RGB-D by extracting traversable skeletons and identifying region/junction nodes; (2) Representative Perspectives (RP) that store multi-view evidence per region; (3) a Scoring–Screening Mechanism (SSM) that fuses a VLM score and distance-based path cost to split nodes into a Progressing List (PL) and a Backtracking List (BL); (4) a Dynamic Policy Trigger (DPT) with four events (region discovery, perspective update, junction pass, region reached) to activate SSM for on-demand replanning. Experiments on ObjectNav, TextNav and InstanceNav over Gibson/HM3D/MP3D report improvements in SR/SPL."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The decision unit is lifted from frontier points to the region level.\n- Figures are visually appealing and clearly convey the main ideas.\n- The writing is clear and easy to follow."}, "weaknesses": {"value": "- Although the specific implementation details differ slightly, the overall idea appears quite similar to existing approaches that also rely on region-based potential estimation and multi-scale scoring mechanisms. Without a clearer articulation of the conceptual innovation or the insight that motivates this design, the contribution feels incremental.\n- Heavy hand-tuning of triggers and thresholds makes the pipeline look like a “strategy stack”; the learning-based adaptivity appears limited. Sec. 3.4.4 defines four trigger types, specifies update rules via formulas, and fixes a trigger priority order—these timings and conflict resolutions are hand-crafted. In SSM, the fusion weights/thresholds (e.g., the near-distance and low-score thresholds and diversity parameters in Eqs. 7–11) are also manually set, with little justification or comparative evidence as to why these choices are necessary.\n- RJG construction relies on skeletonization with depth thresholds, traversability masks, and node degree. It is unclear whether this geometric heuristic is stable in challenging cases such as cross-level transitions, stairs, or irregular rooms, and whether it can properly merge multiple entrances of the same room or handle mixed room types when identifying nodes.\n- The region potential mainly comes from the VLM score of RP plus a distance term, with no explicit semantic support or updatable pixel-level evidence. Under viewpoint changes, occlusion, or similar-appearance distractors, the score reliability is uncertain. Although the authors use Progressing and Backtracking lists, there seems to be no record of “sufficiently searched but goal not found”, which may still cause repeated exploration of already visited regions."}, "questions": {"value": "- After reaching a region, how do you define “sufficiently searched so we won’t return”?\n- What is the rationale for the fixed priority order of the four triggers? In practice, what are the frequency histograms and average intervals of each trigger?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jEnsCKIoJy", "forum": "38ioKDbyP7", "replyto": "38ioKDbyP7", "signatures": ["ICLR.cc/2026/Conference/Submission22676/Reviewer_Jzgx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22676/Reviewer_Jzgx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958540379, "cdate": 1761958540379, "tmdate": 1762942330268, "mdate": 1762942330268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a dynamic framework based on semantic regions, called DP-Nav to enable semantic navigation in embodied agents. This is in contrast to existing frontier based methods that ignore semantic region information. DP-Nav builds an additional region-junction graph to keep track of semantic regions and the corresponding frontiers. Through experiments the authors show that their method outperforms SOTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The idea to keep track of semantic regions seems to be useful to efficiently explore the environment. The paper is well written and easy to understand."}, "weaknesses": {"value": "I find the work presented in this paper to provide useful insights for the community. I didn’t find any significant weaknesses."}, "questions": {"value": "1. Do you think the region potential can be extended to incorporate textual semantics (e.g., “bathroom” vs. “corridor”)?\n\nMinor comments:\nThe formatting of some table captions needs to be revised. For example, it’s hard to distinguish the wrapped text from the caption of Table 4. Same for Figure 3."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ppbXlkpD3J", "forum": "38ioKDbyP7", "replyto": "38ioKDbyP7", "signatures": ["ICLR.cc/2026/Conference/Submission22676/Reviewer_57Qp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22676/Reviewer_57Qp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22676/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970210896, "cdate": 1761970210896, "tmdate": 1762942329911, "mdate": 1762942329911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}