{"id": "6qDxK4Gz7F", "number": 15237, "cdate": 1758249203635, "mdate": 1759897319537, "content": {"title": "Gradient-Direction-Aware Density Control for 3D Gaussian Splatting", "abstract": "The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced Novel View Synthesis (NVS) through explicit scene representation, enabling real-time photorealistic rendering. However, existing approaches manifest two critical limitations in complex scenarios: (1) Over-reconstruction occurs when persistent large Gaussians cannot meet adaptive splitting thresholds during density control. This is exacerbated by conflicting gradient directions that prevent effective splitting of these Gaussians; (2) Over-densification of Gaussians occurs in regions with aligned gradient aggregation, leading to redundant component proliferation. This redundancy significantly increases memory overhead due to unnecessary data retention. We present Gradient-Direction-Aware Gaussian Splatting (GDAGS) to address these challenges. Our key innovations: the Gradient Coherence Ratio (GCR), computed through normalized gradient vector norms, which explicitly discriminates Gaussians with concordant versus conflicting gradient directions; and a nonlinear dynamic weighting mechanism leverages the GCR to enable gradient-direction-aware density control. Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting operations to enhance geometric details while suppressing redundant concordant-direction Gaussians. Conversely, in cloning processes, GDAGS promotes concordant-direction Gaussian densification for structural completion while preventing conflicting-direction Gaussian overpopulation. Comprehensive evaluations across diverse real-world benchmarks demonstrate that GDAGS achieves superior rendering quality while effectively mitigating over-reconstruction, suppressing over-densification, and constructing compact scene representations.", "tldr": "We present Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware adaptive density control framework to address over-reconstruction and over-densification.", "keywords": ["Novel View Synthesis", "3D Gaussian Splatting", "Point-based Radiance Field", "3D reconstruction"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b564e3dd80a7b18ee04da348798c0a84854da1d4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses a fundamental flaw in the \"densification\" process of 3D Gaussian Splatting (3DGS)—the mechanism that decides where to add more detail. The original 3DGS method relies solely on the magnitude (or norm) of the position gradient (which can be seen as the \"rendering error signal\") while completely ignoring its direction. To resolve this fundamental issue, the paper proposes a Gradient-Direction-Aware density control framework (GDAGS). Its core idea is to quantify and leverage gradient directional information to make smarter decisions. The method consists of two main components: The Gradient Coherence Ratio (GCR) and The Nonlinear Dynamic Weighting System. The method not only resolves the blurring issue and improves rendering quality but, more importantly, it reduces redundancy, producing compact 3D models than AbsGS."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and easy to follow. \n2. The work's originality lies in its more complete diagnosis of a known issue. While prior work like AbsGS had already identified the problem of gradient cancellation causing blur, this paper correctly points out that this is only half of the story; gradient amplification in aligned regions is an equally important problem that leads to model bloat. The proposed Gradient Coherence Ratio (GCR) is a novel and intuitive metric to directly measure this directional consistency. Using this metric to create a dual-purpose control system—one that simultaneously encourages splits in chaotic regions and suppresses them in stable ones—is a clever and well-motivated approach."}, "weaknesses": {"value": "1. The authors correctly identify in their limitations section that the GCR metric may be unreliable in very sparse regions with little gradient information. However, this critical failure mode is only mentioned briefly and not explored empirically.\n2. The method introduces new hyperparameters for its weighting function. Although a sensitivity analysis is provided in the appendix, the paper offers little intuition or practical guidance on how these should be set. This lack of guidance could make the method difficult for others to apply effectively to new and different scenes."}, "questions": {"value": "1. To better understand the method's limitations, the authors should include a targeted experiment on a scene with known sparse viewpoints or textureless surfaces. A qualitative analysis showing how GDAGS behaves in these low-information areas compared to the baseline would be very instructive. Does it fail gracefully by simply not adding primitives, or does it make poor decisions? A discussion of potential fallback strategies in such cases would also strengthen the work.\n2. The authors should report end-to-end training times and compare them against the key baselines. This is essential for a fair assessment of the trade-offs. It would also be helpful to include a brief profiling analysis that quantifies the specific overhead of the GCR computation step."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "98G1AI1JPL", "forum": "6qDxK4Gz7F", "replyto": "6qDxK4Gz7F", "signatures": ["ICLR.cc/2026/Conference/Submission15237/Reviewer_52Pb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15237/Reviewer_52Pb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825456202, "cdate": 1761825456202, "tmdate": 1762925533849, "mdate": 1762925533849, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GDAGS, a framework that addresses the over-densification, over-reconstruction, and memory inefficiency issues caused by the ill-posed densification mechanism in the original 3DGS, leveraging the directional consistency method and online dynamic weighting schemes. Experimental results show the efficacy of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well writen and easy to follow.\n2. This paper targets a general and key component in the 3DGS pipeline and provides a simple yet effective solution.\n3. The experimental results show promising performance improvements."}, "weaknesses": {"value": "1. The proposed GDAGS introduces additional computational overhead during the optimization process. I believe it is necessary to report a comparison of training and testing times to better characterize the efficiency of the proposed method.\n\n2. In Eq. (1), the variable \\( i \\) is not clearly defined. Does it refer to the Gaussian kernel? In addition, how is the number of views \\( V \\) determined in the experiments? Has the effect of different \\( V \\) values on performance been examined?"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TxVk7O3lwk", "forum": "6qDxK4Gz7F", "replyto": "6qDxK4Gz7F", "signatures": ["ICLR.cc/2026/Conference/Submission15237/Reviewer_5e9Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15237/Reviewer_5e9Z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959330303, "cdate": 1761959330303, "tmdate": 1762925532928, "mdate": 1762925532928, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "3DGS introduced an adaptive density control algorithm to grow the number of Gaussians to fit the underlying scene structure. However, it is relatively suboptimal in properly splitting and cloning Gaussians, an issue that even prior work such as AbsGS could not fully address. This paper identifies that this issue arises from: 1) gradient cancellation due to diverging sub-gradient directions, and 2) exaggerated gradients caused by the simple aggregation of absolute values of diverging sub-gradients in local regions. To capture the directional consistency of sub-gradients, the authors define the Gradient Coherence Ratio (GCR; Equation 5) and modulate gradients using a nonlinear weighting function defined in Equation 6. Using this criterion, they not only promote the splitting of large Gaussians with diverging sub-gradients but also suppress the cloning of small Gaussians with diverging sub-gradients. Experimental results demonstrate state-of-the-art scene reconstruction quality while maintaining lower memory consumption on standard benchmarking datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper properly identifies the shortcomings of the prior method (AbsGS) and achieves the best control of the number of Gaussians during training by addressing this problem."}, "weaknesses": {"value": "Please see Questions section for my major concerns.\n\nPresentation issues:\n- Math error in Equation 3. The expansion of $T_k$ is incorrect. It must be $\\prod_{j=1}^{k-1} (1-\\alpha_jG'_j(\\textbf{x}'))$.\n- Typo in line 273: $(1 − C_i)^a$ → $(1 − C_i)^p$.\n- Clarify the unit of x-axis in Figure 5. It seems k (thousand)."}, "questions": {"value": "* Please provide the training duration in the experiments. This will help readers understand the training efficiency of the method.\n* In Figure 3, some images show that GDAGS fails to reconstruct particular areas compared to vanilla 3DGS, which weakens the authors’ argument that GDAGS avoids over-densification and over-reconstruction issues. Do the authors have an explanation for why GDAGS renders these artifacts? For example, GDAGS produces noisy artifacts on the crown molding (top-left of the first-row image) and blobby artifacts in the area between trees and the sky (top-left of the second-row image).\n* One major limitation is that the newly introduced hyperparameters $\\alpha, \\beta, p$ are tuned specifically for different scenes. They need to be searched heuristically to find the best trade-off between quality and efficiency (VRAM usage), which is cumbersome. Is there a learnable approach for these parameters?\n* In Figure 5, the authors show the dynamics of the number of Gaussians associated with clone/split operations. According to the graphs, AbsGS tends to split Gaussians far more frequently than GDAGS, yet AbsGS retains poorer reconstruction quality than GDAGS according to Table 1. This seems counter-intuitive because generally, propagating more Gaussians should improve the reconstruction of complex structures. What is the authors’ explanation for why AbsGS has lower PSNR despite splitting Gaussians much more than GDAGS? In other words, what is the key factor that allows GDAGS to achieve the highest rendering performance without splitting as many Gaussians?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hzQeO6BeNo", "forum": "6qDxK4Gz7F", "replyto": "6qDxK4Gz7F", "signatures": ["ICLR.cc/2026/Conference/Submission15237/Reviewer_dpMa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15237/Reviewer_dpMa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002348426, "cdate": 1762002348426, "tmdate": 1762925532379, "mdate": 1762925532379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work trying to achieve a balance between over-reconstruction and over-densification which raise from gradient based adaptive control in classical 3DGS. The authors propose Gradient-Direction-Aware Gaussian Splatting (GDAGS), which introduces the Gradient Coherence Ratio (GCR) to quantify the directional consistency of view-space gradients and a nonlinear dynamic weighting mechanism that regulates Gaussian splitting and cloning based on gradient alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe proposed method achieves a good balance between performance and storage, aligns well with intuition, and enhances the overall usability of Gaussian Splatting models.\n2.\tThe authors conduct experiments across three benchmark datasets and compare against a wide range of strong baselines (NeRF, 3DGS, AbsGS, Pixel-GS, etc.). The inclusion of ablation studies and sensitivity analyses provides convincing evidence for the method’s robustness and interpretability.\n3.\tThe motivation of this paper is well articulated, and the proposed solution is intuitive. In particular, Figure 1 clearly illustrates the problems of over-reconstruction and over-densification that occur in 3D reconstruction under two extreme scenarios."}, "weaknesses": {"value": "1.\tThe overall performance(especially the LPIPS metric) is highly influenced by the Hyper parameters(α、β、p) which raises concerns about the generalization of the method.\n2.\tStill about generalization ability. In section 4.3.4 the authors evaluate the proposed module combine with MCMC-3DGS and Compact-3DGS. However, noticeable performance changes appear mainly in the LPIPS metric and the SSIM metric on the Deep Blending dataset. Therefore, a qualitative analysis corresponding to these metric variations should be presented. \n3.\tAlthough experiments show that GDAGS is superior to AbsGS and Pixel-GS but the analysis of the reasons for their performance differences in the paper is relatively insufficient. \n4.\tWhile the GCR is well-defined, the paper lacks theoretical insights into how it affects optimization dynamics or convergence. The justification for its effectiveness is mostly empirical."}, "questions": {"value": "1.\tWhy is the directionality measurement of GCR superior to the Pixel weighting mechanism of Pixel-GS?\n2.\tThe nonlinear dynamic weighting model proposed in this paper is intuitive and effective. But why adopt the current form instead of the exponential weighting function among numerous nonlinear models? This point requires sufficient explanation and clarification.\n3.\tThe comparison methods cited in the main text are up to conference works from 2024.  Since over-reconstruction and over-densification are widely discussed topics in the 3DGS community, have there been related works published in 2025?  If so, what are the advantages of this paper compared to those?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TKWp9zZ1DO", "forum": "6qDxK4Gz7F", "replyto": "6qDxK4Gz7F", "signatures": ["ICLR.cc/2026/Conference/Submission15237/Reviewer_QXqY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15237/Reviewer_QXqY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019725795, "cdate": 1762019725795, "tmdate": 1762925532019, "mdate": 1762925532019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}