{"id": "13jshGCK9i", "number": 333, "cdate": 1756735696450, "mdate": 1759898267235, "content": {"title": "D-REX: Differentiable Real-to-Sim-to-Real Engine for Learning Dexterous Grasping", "abstract": "Simulation provides a cost-effective and flexible platform for data generation and policy learning to develop robotic systems. However, bridging the gap between simulation and real-world dynamics remains a significant challenge, especially in physical parameter identification. In this work, we introduce a real-to-sim-to-real engine that leverages the Gaussian Splat representations to build a differentiable engine, enabling object mass identification from real-world visual observations and robot control signals, while enabling grasping policy learning simultaneously. Through optimizing the mass of the manipulated object, our method automatically builds high-fidelity and physically plausible digital twins. Additionally, we propose a novel approach to train force-aware grasping policies from limited data by transferring feasible human demonstrations into simulated robot demonstrations. Through comprehensive experiments, we demonstrate that our engine achieves accurate and robust performance in mass identification across various object geometries and mass values. Those optimized mass values facilitate force-aware policy learning, achieving superior and high performance in object grasping, effectively reducing the sim-to-real gap. Our code is included in the Supplementary Material and will be open source to facilitate reproducibility. Anonymous project page is available at https://robot-drex-engine.github.io.", "tldr": "Differentiable Real-to-Sim-to-Real Engine for Learning Robotic Grasping", "keywords": ["Real-to-Sim-to-Real; Differentiable Simulation; Learning Robotic Policies from Videos; System Identification;"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3b030e242a529f1ad519a84f1769b90a7395b737.pdf", "supplementary_material": "/attachment/3bd2106e00972ff1710d086acfd45b53b8a4513e.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes D-REX, a real-to-sim-to-real method to improve the performance of grasping policies. The method first leverages off-the-shelf tools to convert human videos to robot kinematic trajectories. After that, the method identifies object masses based on differentiable physics engines. The identified object masses are further utilized to develop a force-based control policy for grasping. Extensive experiments prove the effectiveness of the method. Overall, the paper makes a step forward in developing physics-aware policies utilizing real-to-sim-to-real methods and demonstrates the effectiveness of incorporating physical properties into robot policies. Main limitations lie in the inherent restrictions of the mass identification method and the restricted upper limits of only identifying and utilizing masses in the robot policy learning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Good motivations. The problem is well motivated. Real-to-sim system identification is an important way to bridge the sim-to-real gap. Beyond properties reflected from the visual appearances, such as object meshes, the paper makes a step forward and proposes to identify physical properties, i.e., masses, from a dynamic interaction sequence. After identifying masses, a force-adaptive method is developed to improve the grasping policy. \n- Reasonable methodology. Estimating masses from hand-object interaction sequences and the force-based policy are reasonable approaches. \n- Solid experiments. The authors carefully design experiments to validate the effectiveness of the object mass identification method design and the superiority of the force-based grasping policy."}, "weaknesses": {"value": "- The paper utilizes the foundation pose to estimate the object pose sequences from real videos. However, the foundation pose cannot deal with axis-symmetric objects and tiny objects. Moreover, the estimated object poses always suffer from noise. Therefore, the quality of the mass identification step would be restricted by the quality of the identified masses. The applicability of the method would also be restricted to objects that the foundation pose can handle. Besides, utilizing foundation models to generate scene configurations, such as the robot mjcf, may also introduce errors. \n- When identifying masses from videos, the sim-to-real gap in other properties, such as frictions, is neglected, which would further make the estimation prone to errors."}, "questions": {"value": "- How do you train the grasping position policy? \n- Could the method be extended to small objects, including both the mass identification and the grasping process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EsMnLSuAIq", "forum": "13jshGCK9i", "replyto": "13jshGCK9i", "signatures": ["ICLR.cc/2026/Conference/Submission333/Reviewer_KAq7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission333/Reviewer_KAq7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761384184040, "cdate": 1761384184040, "tmdate": 1762915495846, "mdate": 1762915495846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a differentiable real-to-sim-to-real engine for object mass identification and grasping policy learning. Specifically, the Gaussian Splat representation is leveraged to facilitate estimation object mass through visual observations and robot control signals during interaction. Besides, a learning-based method is also proposed to train force-aware grasping policies from limited human demonstration videos. Comprehensive experiments have been conducted to validate the performances on mass identification and object grasping."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe topic of end-to-end object mass identification is valuable and the solution using differentiable simulation is novel. \n2.\tBased on the mass estimation, the proposed system achieves satisfactory performances on the object grasping, reducing the gap between simulator and real-world environment.\n3.\tThe proposed approach outperforms strong baselines in object grasping, especially for the challenging object grasping. \n4.\tThe paper is well-written and the ablation studies are comprehensive."}, "weaknesses": {"value": "1.\tThere should more details in the section of parameter identification from robot-object interactions. For instance, the rationale behind the trajectory discrepancy minimization for the object mass identification should be included. What’s the effects of the semi-implicit Euler modeling. Is there any ablation study for this learning objective?"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "S2fGt5q2Sc", "forum": "13jshGCK9i", "replyto": "13jshGCK9i", "signatures": ["ICLR.cc/2026/Conference/Submission333/Reviewer_M426"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission333/Reviewer_M426"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761546199593, "cdate": 1761546199593, "tmdate": 1762915495705, "mdate": 1762915495705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents D-REX, a differentiable real-to-sim-to-real framework for dexterous grasping. It combines 4D Gaussian Splatting (4DGS) for scene reconstruction and differentiable physics for identifying physical parameters (notably object mass) from real-world robot trajectories. The identified mass is then used to train a force-aware grasping policy, which achieves higher grasp success rates in both simulation and limited real-world settings.\n\n\nThe paper explores an interesting and relevant direction by combining differentiable physics and 4DGS for Real2Sim2Real learning. While the current experiments do not fully validate the motivation of building a high-fidelity differentiable Real2Sim pipeline, the proposed idea is novel and potentially impactful. Overall, the paper presents a promising step toward differentiable Real2Sim learning and merits a weak accept pending more thorough validation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper is clearly written and presents a coherent overall system.\n- The proposed framework is conceptually appealing, and incorporating mass identification for robot policy learning is a novel and promising idea.  \n- The experimental results demonstrate accurate mass estimation and consistent grasping improvement with mass-aware policies."}, "weaknesses": {"value": "- **The evaluation of Real2Sim quality is lacking.**  \n  The paper presents no analysis or evaluation of either appearance or geometry (mesh) of the generated digital scenes—offering neither quantitative metrics nor qualitative discussion. As a result, the claimed Real2Sim objective remains unsupported and unvalidated, which weakens the overall completeness and credibility of the contribution.\n\n- **The validation of the “force-aware policy” is insufficient.**\n  To validate the effectiveness of the force-based control, the authors report grasping success rates in Table 3 and Figure 5 undering different settings. A visual or quantitative comparison of force values across different settings during robot execution would better substantiate the effectiveness of the proposed force-aware policy learning.\n\n- **The efficiency and scalability should be discussed.**  \n  The authors present mass-loss curves in Figure 11 but seem to have omitted the actual optimization or training time, which is also an important factor for evaluating system efficiency. In addition, the offline 4DGS reconstruction step can be computationally expensive; however, no quantitative analysis (e.g., runtime or memory usage) is provided. Therefore, the practicality of the proposed Real2Sim pipeline for large-scale or online applications remains somewhat unclear.\n\n- **The generalization ability of D-REX is limited.**\n  The proposed pipeline requires real-world object trajectories (obtained via FoundationPose) and matched real/sim robot interactions to optimize object mass. Consequently, the generalization ability of the proposed method to novel scenes or objects, where such real trajectory data and robot interactions are unavailable, appears limited."}, "questions": {"value": "1. The paper introduces two separate sets of Gaussians to represent the visual appearance and geometry of the scene. How might potential optimization misalignment between these two representations affect the accuracy of mass identification and the subsequent policy learning?\n2. The Appendix mentions that the optimization of 4D Gaussian Splatting for photometric alignment is unstable and inaccurate. Could you provide detailed explanations or illustrative failure examples to clarify this issue?\n\n## Suggestions for Improvements\n\n1. Provide more qualitative and quantitative results/comparisons after Real2Sim stage, evaluating both the 4DGS scenes and the generated mesh.\n2. Provide more visual or quantitative results/comparisons of force values during robot excution to better substantiate the force-aware policy.\n3. Provide a systematic runtime analysis for different modules of D-REX to better assess the overall computational efficiency of the pipeline.\n4. Minor formatting issues: Line 97: “Empirically, We” — the word “We” should be lowercase; Line 1737: “Physics-constrained identification” — a line break is recommended for proper formatting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vlduxfB2vS", "forum": "13jshGCK9i", "replyto": "13jshGCK9i", "signatures": ["ICLR.cc/2026/Conference/Submission333/Reviewer_6NV8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission333/Reviewer_6NV8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966316722, "cdate": 1761966316722, "tmdate": 1762915495507, "mdate": 1762915495507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents D-REX, a differentiable real-to-sim-to-real pipeline that couples Gaussian Splat Representations for photorealistic 3D reconstruction with a differentiable physics engine for object-mass identification and force-aware grasp policy learning. The system jointly optimizes physical parameters (mass) from robot interaction videos and learns manipulation policies conditioned on the inferred mass, closing the sim-to-real loop for dexterous grasping tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper demonstrates a technically competent system that merges 3DGS and differentiable physics for vision-based grasping. Authors have performed real-world experiments validating some of their claims."}, "weaknesses": {"value": "**1. Pipeline composition rather than a learning contribution.**\nThe full system is essentially a sequential pipeline: (1) Gaussian Splatting for 3D reconstruction with VLMs, (2) System identification to calibrate physical parameters, and (3) a procedural grasping policy that uses hand-designed grasp position and orientation heuristics. There is no novel algorithmic contribution or learning formulation that connects these modules beyond standard differentiable chaining. \n\n**2. Hand-designed grasp prediction.**\nThe grasping procedure relies on manually defined rules. This is not significantly different from prior grasp pipelines that use geometry-based scoring or analytical quality metrics.\n\n**3. No clear advantage over existing methods.**\nThe paper does not demonstrate how D-REX materially improves over existing differentiable grasping frameworks that already combine differentiable rendering and physics. The quantitative differences appear modest and could stem from tuning rather than a new principle. Additionally, just identifying mass, without taking materials into consideration, seems incomplete for robotics purposes."}, "questions": {"value": "Please see my weaknesses section, thanks!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3nSMUZEWeR", "forum": "13jshGCK9i", "replyto": "13jshGCK9i", "signatures": ["ICLR.cc/2026/Conference/Submission333/Reviewer_snrT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission333/Reviewer_snrT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762201169636, "cdate": 1762201169636, "tmdate": 1762915495237, "mdate": 1762915495237, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}