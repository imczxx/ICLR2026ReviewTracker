{"id": "lSSGmgIPNO", "number": 15614, "cdate": 1758253196879, "mdate": 1763119004241, "content": {"title": "LLM-mediated pathology models for robust cross-institution generalization", "abstract": "Pathology foundation models (PFMs) have shown strong potential across clinical and scientific applications. Their performance, however, is often limited by batch effects, which are non-biological variations across tissue source institutions (TSIs) that distort feature representations and reduce generalization. Existing mitigation methods, such as stain normalization, have limited success in addressing these high-dimensional and complex artifacts. We introduce the General-purpose LLM-Mediated Pathology model (GLMP), a novel framework that generates robust numerical embeddings from histology image patches by first converting them into text descriptions. By leveraging pretrained multimodal large language models (MLLMs) and text encoders, GLMP prioritizes genuine biological signals over TSI-specific signatures and improves cross-TSI generalization compared to existing PFMs. Our findings demonstrate the effectiveness of broad-domain, non-specialized MLLMs in computational pathology and provide an alternative framework for developing versatile, generalizable, and robust pathology models that do not require large-scale, histology-specific pretraining data. Code is provided in Supplementary Materials for reproducibility and will be released to the public upon paper acceptance.", "tldr": "We introduce an LLM-mediated pathology model that uses multimodal LLMs to generate robust, generalizable embeddings from histology images, mitigating batch effects across institutions without requiring large-scale histology-specific pretraining.", "keywords": ["pathology foundation models", "computational pathology", "batch effects", "multimodal large language models", "vision-language models"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/dcce401eb0487e2099726119296ca37682600a56.pdf", "supplementary_material": "/attachment/a43cc21308f6e91f0207c37ddb0073716b8c0d3e.zip"}, "replies": [{"content": {"summary": {"value": "This work presents GLMP, an LLM-based model for patch feature extraction, which generates patch-level features by using text embeddings from LLM-generated image captions. These LLM-based patch embeddings can then be used for downstream classification, demonstrating substantially-improved generalizability across tissue sites. While this model does not always achieve state-of-the-art, its consistency across tissue sites is impressive and a meaningful step towards improving clinical reliability. However, the paper currently evaluates on tasks with clearly defined morphological criteria, making its overall utility unclear. A wider range of tasks, such as molecular subtyping and survival prediction, would provide critical insight into which tasks this GLMP approach is appropriate.\n\nOverall, I found the work interesting, as it introduces a relevant and unexplored approach for generating patch-level features with less tissue site bias. I would be willing to increase my score pending my comments described below."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "There is substantial benefit to a patch foundation model with increased tissue site robustness. In current practice, this is primarily achieved by increasing institutional diversity within the model’s training set. Meanwhile, GLMP provides a VLM-agnostic method for obtaining highly generalizable patch embeddings without the need for self-supervised training.\nThe work compares against an extensive number of SOTA patch foundation models\nThe work examines performance across a satisfactory number of datasets."}, "weaknesses": {"value": "- While this patch-level performance is impressive, the majority of computational pathology tasks are performed at the slide level. Slide-level performance using ABMIL and mean pooling should be shown. In addition to C16 and TCGA-LUSC, which have corresponding slide labels from more WSIs than used for the patch-level tasks, the PANDA dataset can be utilized, which can be divided between the Radboud and Karolinska institutes. If used, please report quadratic weighted kappa.\n\n- While the empirical results indicate that the patch embeddings based on GLMP are relatively agnostic to tissue site, it remains unclear why the text captions would not be subject to those tissue site biases. For instance, could it be that variations in brightness, staining color, etc, affect the quality of the captions, and subsequently, the model’s ability to detect subtle changes such as mitotic figures? \n\n- Figure 2 is important for building intuition on tissue site biases. Please show examples on an additional dataset in the appendix. \n\n- ***The examined tasks all relate to tissue morphology, which have clearly-defined criteria for each tissue class. Meanwhile, I suspect the model will struggle on tasks such as molecular subtyping or survival prediction, which do not have as clearly-defined criteria and will require more detailed textual descriptions. Ideally, multiple target tasks on a single WSI dataset (e.g TCGA NSCLC prediction of tp53, kras, egfr) would substantially improve the reliability of these results, showing that a single set of captions can encode sufficient information for a wide range of tasks. I believe this is the most important component missing from the paper. \n\n- Please define the meaning of “cross-TSI generalization” in Line 259. While GLMP exhibits a smaller drop in performance from training to test site, Figure 4 shows that GLMP achieves lower overall performance on both the internal and external institution. \n\n- Line 269 is not sufficiently supported in my opinion. There are a large number of differences between c16 and TCGA-LUSC, and so the conclusion that GLMP performs better on more challenging tasks requires additional experiments, such as evaluation on molecular subtyping tasks. \n\n- Clarity can be substantially improved by describing the procedure for creating tissue site correlations  (Lines 299-301) within the paragraph it is introduced. \n\n- The results in Figure 5 are misleading by including 100/0 high bias. While the 100/0 bias case does indicate GLMP’s efficacy at removing tissue site bias, this tissue site invariance is already extensively shown in section 4.6. Meanwhile, differences at lower bias ranges are of substantially higher interest to the research and clinical community. Inclusion of this 100/0 case disrupts the scale, making differences at more realistic bias rations difficult to discern. Please move the 100/0 bias case from the main figure into a supplemental figure, and include additional experiments in the 50-90 range.\n\n- Performance on Tissue4Skin and TumSeg should be included in Figure 4. \n\n- Table 4 is an important result. This ablation should be performed on additional datasets."}, "questions": {"value": "- Why does institution 3’s image look strange? There appears to be some filter applied on top of the image. \n\n- What happens to performance when you exclude the explicit instruction to include non-biological characteristics (Lines 426-428). \n\n# Additional Feedback\n- In the introduction, it would be more clear to distinguish between patch foundation models and slide foundation models. \n\n- Figure 1 could be aesthetically improved\n\n- In section 4.2, please specify that k-means is performed inter-slide. \n\n- The captions should be more detailed. For instance, figure 2 should specify the tissue type and dataset, and that k-means is performed inter-slide."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xJKqDgH8Ar", "forum": "lSSGmgIPNO", "replyto": "lSSGmgIPNO", "signatures": ["ICLR.cc/2026/Conference/Submission15614/Reviewer_Ggnd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15614/Reviewer_Ggnd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15614/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761158989002, "cdate": 1761158989002, "tmdate": 1762925883908, "mdate": 1762925883908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "The authors thank the reviewers for their helpful feedback."}}, "id": "7q2w91C5Bq", "forum": "lSSGmgIPNO", "replyto": "lSSGmgIPNO", "signatures": ["ICLR.cc/2026/Conference/Submission15614/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15614/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763119003200, "cdate": 1763119003200, "tmdate": 1763119003200, "mdate": 1763119003200, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GLMP, a model that tackles non-biological \"batch effects\" (like stain variations) that cause pathology models to fail across different institutions. Instead of encoding images directly, GLMP uses a multimodal LLM to generate a text description focused only on biological features, filtering out the batch effect artifacts. This text-based embedding proves more robust and generalizable than standard models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThis work proposes new inspiration for mitigating batch effects inside pretrained pathology foundation models.\n\n2.\tExperimental analysis is comprehensive, and the proposed solution seems effective."}, "weaknesses": {"value": "1.\tThe logic of this paper is that, to mitigate batch effects (assumed), the pretrained pathology foundation models are completely discarded, and instead, a general-purpose MLLM such as Gemini-2.5-Pro is used to first describe the pathology image and then generate the feature of it, with no measure to ensure the correctness of the description. This seems to neglect the essential and pursue the trivial.\n\n2.\tThe efficiency of the proposed workflow is a major concern. Describing every patch in a WSI with Gemini-2.5-Pro and then projecting it into a feature vector should take much more time compared to pre-trained pathology foundation models. And I suggest the authors add an efficiency comparison between the proposed model and baselines. \n\n3.\tI acknowledge the importance of the proposed research question; however, whether the proposed pipeline is the best way to solve it remains a question. The proposed method seems too preliminary, and it cannot be deployed to scenarios like WSI-level diagnosis or prognosis. Moreover, the contribution came more from Gemini's powerful capabilities. I suggest the authors read this work [1], which also works on the robustness of pathology foundation models, to understand how to come up with their own contribution.\n\n$\\quad$ [1] Kömen, Jonah, et al. \"Towards Robust Foundation Models for Digital Pathology.\" arXiv preprint arXiv:2507.17845 (2025)."}, "questions": {"value": "1.  Could the authors elaborate more on the choice of leveraging general-purpose MLLMs instead of pathology-specific MLLMs [1,2]?\n\n$\\quad$ [1] Xu, Zhe, et al. \"A versatile pathology co-pilot via reasoning enhanced multimodal large language model.\" arXiv preprint arXiv:2507.17303 (2025).\n\n$\\quad$ [2] Sun, Yuxuan, et al. \"Cpath-omni: A unified multimodal foundation model for patch and whole slide image analysis in computational pathology.\" Proceedings of the Computer Vision and Pattern Recognition Conference. 2025.\n\n2.\tThe authors mentioned “A structured prompt guides the MLLM to describe only biological characteristics, such as cellular morphology and tissue architecture,” in the last paragraph of Introduction. But how to ensure the accuracy of the statement generated by MLLMs? \n\n3.\tIn the Cross-TSI Generalization task, why choose linear probe rather than MIL models such as ABMIL for evaluation?\n\n4.\tThe authors mentioned that “However, reliance on large-scale annotated pathology data makes these methods non-scalable given the scarcity and cost of such data.” in the first paragraph of Related Work. However, the proposed method leverages the MLLMs to describe the pathology images. In this sense, researchers could also use MLLMs to caption unlabeled pathology images to create scalable image-text paired datasets. The logic here does not really work out.\n\n5.\tCould the author please add these papers to the experimental comparison since they are relevant:\n\n$\\quad$ [1] Wang, Xiyue, et al. \"A pathology foundation model for cancer diagnosis and prognosis prediction.\" Nature 634.8035 (2024): 970-978.\n\n$\\quad$ [2] Ma, Jiabo, et al. \"A generalizable pathology foundation model using a unified knowledge distillation pretraining framework.\" Nature Biomedical Engineering (2025): 1-20.\n\n$\\quad$ [3] Xu, Yingxue, et al. \"A multimodal knowledge-enhanced whole-slide pathology foundation model.\" arXiv preprint arXiv:2407.15362 (2024)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "echzl1Ew7K", "forum": "lSSGmgIPNO", "replyto": "lSSGmgIPNO", "signatures": ["ICLR.cc/2026/Conference/Submission15614/Reviewer_WoM7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15614/Reviewer_WoM7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15614/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828755254, "cdate": 1761828755254, "tmdate": 1762925883550, "mdate": 1762925883550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The submission proposes a method for encoding histopathology image patches into a feature representation that is invariant to batch effects. Batch effects in medical datasets arise when datasource signatures are present in data collected in separate batches, potentially confounding predictions.\n\nOverall, the method involves asking a multimodal LLM to describe an input pathology image in text, and then encoding the text with a text encoder. This encoding of the generated text is then used to showcase better independence of information from tissue-source-site through separability-analysis with visualization tools such as clustering/PCA on the embeddings. Experiments with tissue-classification further confirm that the proposed method is less confounded by tissue source information, relative to pathology foundation models that provide image embeddings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The submission explores a very critical problem when working in data-variability-constrained areas in medical AI such as histopathology, namely batch effects. \n\nThe key takeaway for me is that modern day LLMs might already be useful at extracting clinically useful information without being overwhelmed by extraneous information."}, "weaknesses": {"value": "The fundamental weakness in this work is that it does not adequately explore the way by which the MLLM, Gemini in this case, actually enables agnosticism to batch effects to how generalizable the overall approach is likely to be. \n\nTo my knowledge, we do not know what data-sources are actually used to train Gemini, and how. The submission posits it is \"general image-text data\", but given the clinically-oriented outputs, it seems likely that the training involved a fair bit of histopathology data, perhaps even including all of the data used for the experiments in the submission. The prompts are very specifically asking for clinically-oriented outputs, thus it seems quite likely that the information being assessed is already within Gemini training, and already perfectly-aligned with the tests in the experiments. Therefore, the submission may only be demonstrating that Gemini is good at histopathology, and it is unclear if the overall methodology for avoiding batch-effects is sound, i.e. what if one trained an MLLM from scratch on limited data carefully curated to exhibit batch-effects from train to test sets? The lack of visibility into the chosen MLLM makes the results hard to interpret in terms of overall methodology."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nkX0M0vjl6", "forum": "lSSGmgIPNO", "replyto": "lSSGmgIPNO", "signatures": ["ICLR.cc/2026/Conference/Submission15614/Reviewer_a5So"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15614/Reviewer_a5So"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15614/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911032526, "cdate": 1761911032526, "tmdate": 1762925882777, "mdate": 1762925882777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}