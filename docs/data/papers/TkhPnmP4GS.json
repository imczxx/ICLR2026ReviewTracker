{"id": "TkhPnmP4GS", "number": 6453, "cdate": 1757985045666, "mdate": 1759897913331, "content": {"title": "Equilibrium flow: From Snapshots to Dynamics", "abstract": "Scientific data, from cellular snapshots in biology to celestial distributions in cosmology, often consists of static patterns from underlying dynamical systems. These snapshots, while lacking temporal ordering, implicitly encode the processes that preserve them. This work investigates how strongly such a distribution constrains its underlying dynamics and how to recover them. We introduce the *Equilibrium flow* method, a framework that learns continuous dynamics that preserve a given pattern distribution. Our method successfully identifies plausible dynamics for 2-D systems and recovers the signature chaotic behavior of the Lorenz attractor. For high-dimensional Turing patterns from the Gray-Scott model, we develop an efficient, training-free variant that achieves high fidelity to the ground truth, validated both quantitatively and qualitatively. Our analysis reveals the solution space is constrained not only by the data but also by the learning model's inductive biases. This capability extends beyond recovering known systems, enabling a new paradigm of inverse design for Artificial Life. By specifying a target pattern distribution, we can discover the local interaction rules that preserve it, leading to the spontaneous emergence of complex behaviors, such as life-like flocking, attraction, and repulsion patterns, from simple, user-defined snapshots.", "tldr": "We show how to recover possible hidden dynamics from pattern snapshots with Equilibrium flow", "keywords": ["pattern formation", "diffusion model", "chaos", "artifical life", "generative model"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/46f78008ce288f64a13a6316702c912040257939.pdf", "supplementary_material": "/attachment/861304a9705d777094f809458213f71fc6b50d8b.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces the _Equilibrium flow_ method for inference of the underlying continuous dynamics of a system from a distribution of static snapshots, without any temporal information. The principal idea is to recover a vector field that preserves the distribution of a given static pattern. The authors demonstrate the method's effectiveness on 2D systems, the chaotic Lorenz attractor, and high-dimensional Turing patterns from the Gray-Scott model, for which they also develop an efficient training-free variant. Beyond recovering known dynamics, the framework enables a new \"inverse design\" paradigm for creating Artificial Life by specifying a target pattern and discovering the local interaction rules that preserve it and lead to emergent behaviors like flocking."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Originality**:  addresses an ongoing challenge / fundamental problem --  inferring dynamics from static data -- in a novel way; avoiding the compute intensive task of finding dynamics for a single static pattern, and focusing on distributions.  In addition, the application to inverse design (Artificial Life) is creative and demonstrates the potential of the framework beyond tyoical system recovery.\n\n- **Quality**: the work is of good quality -- coupling theoretical foundations and motivation with empirical evaluations. The mathematical derivations are clearly explained and easy to follow, and the experiments span a wide diversity of systems. Specifically the effort on the methods' relevance, applicability and value is highly appreciated. \n\n- **Clarity**: The paper is very well-written and easy to follow. The motivation is clearly established, and the methodology is presented logically. The appendix, along with supplementary code assist following the framework and grasping the papers' contribution. At last, the discussion nicely summarized the paper and outlines future direction. \n\n- **Significance**: The method is of high value as it addresses a setting which is prevalent in many scientific domains--scarce time-series data yet abundant static snapshots. In addition, as indicated by the authors, the inverse-design approach could be used in future work concerning artificial life formation."}, "weaknesses": {"value": "- **Quantitative evaluation**: while the authors presented a diverse set of experiments it will be valuable to provide additional quantitative evaluation, supporting the qualitative results, especially for the training-free setting.\n- **Hyper-parameters selection**: while the existence of hyper-parameters is inevitable, for practical reasons it will be valuable to present how these shall be set / tuned, the robustness to these or alternatively their impact. \n- **Limitations and failure modes**: the paper is lacking a discussion on the limitations of the approach and potential failure modes."}, "questions": {"value": "Following the above weaknesses: \n1. would the authors be able to provide additional quantitative assessment of performance, including failure points and limitations.\n2. relate to hyper-parameters defined and used. \n3. discuss existing limitations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "LwBN1xRBrp", "forum": "TkhPnmP4GS", "replyto": "TkhPnmP4GS", "signatures": ["ICLR.cc/2026/Conference/Submission6453/Reviewer_9gCf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6453/Reviewer_9gCf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6453/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761536113431, "cdate": 1761536113431, "tmdate": 1762918845901, "mdate": 1762918845901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Equilibrium flow, a method to infer continuous dynamics that preserve a given static pattern distribution—without requiring any temporal information. The core idea leverages the steady-state continuity equation $\\nabla \\cdot \\[p(x)v(x)\\] = 0$, which is reformulated into a local constraint $\\nabla \\cdot v(x) + v(x)\\cdot s(x) = 0$ using the score function $s(x) = \\nabla \\log p(x)$. The authors demonstrate applications on 2D distributions, the Lorenz chaotic attractor, high-dimensional Gray-Scott Turing patterns (via a training-free variant), and even \"inverse design\" of artificial life forms. A key claim is that the pattern distribution strongly constrains the space of possible dynamics, and that the learned dynamics exhibit high fidelity to ground-truth systems."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The basic problem (from snapshots to dynamics) is interesting, with potential applications in several scientific fields.\n- The training-free variant for high-dimensional data—based on skew-symmetric transformations of the score—is a practical and computationally efficient adaptation of known irreversible Langevin dynamics.\n- Broad experimental scope and strong visual results.\n- Overall I found the paper well-written in terms of organization, flow, among other aspects."}, "weaknesses": {"value": "1. Ill-posed problem misrepresented: The inverse problem \"recover $v$ from $p$ \" is severely underdetermined, yet ill-posed. The condition $\\nabla \\cdot(p v)=0$ is a single scalar PDE for a $d$-dimensional vector field $v$. In $\\mathbb{R}^d$, the solution space is infinite-dimensional. By Helmholtz decomposition, $v=-\\nabla \\phi+\\nabla \\times A$,the continuity equation only constrains the irrotational part via $\\phi=\\log p+\\operatorname{const}$; the solenoidal part $\\nabla \\times A$ is completely free. Thus, any divergence-free flow on level sets of $p$ is admissible. The paper acknowledges this in passing (Sec. 4) but frames the problem as if the data \"strongly constrains\" dynamics-this is misleading without additional physical priors.\n\n2.  Singular Invariant Measures:\nFor the Lorenz system, the invariant measure $\\mu$ is singular with respect to Lebesgue measure: it is supported on a fractal attractor of Hausdorff dimension $\\approx 2.06$. Consequently, $p(x)=d \\mu / d x$ **does not exist**, and $\\nabla \\log p(x)$ is mathematically undefined.\nThe diffusion model instead estimates the score of a smoothed measure $p_\\tau=\\mu * \\mathcal{N}\\left(0, \\tau^2 I\\right)$, which has a smooth density. But there is no theoretical guarantee that the dynamics derived from $s_\\tau(x)=\\nabla \\log p_\\tau(x)$ approximate the true Lorenz vector field $v_{\\text {Lorenz }}(x)$. In fact, as $\\tau \\rightarrow 0, s_\\tau(x)$ becomes increasingly noisy and uninformative off the attractor, making the learned $v(x)$ unreliable.\n\n3. Fidelity metrics are misleading: Cosine similarity of 0.25 ± 0.01 (Table 1) for Lorenz is labeled “high fidelity,” but corresponds to ~75° average angle—far from alignment.\n\nMoreover, chaotic systems are not characterized solely by positive  Lyapunov exponents. The Lorenz system has a specific Lyapunov spectrum $\\left(\\lambda_1 \\approx 0.91, \\lambda_2=0, \\lambda_3 \\approx-14.57\\right)$, **a strange attractor topology**, and a **kneading invariant**. None of these are verified. The learned system could be any chaotic flow (e.g., Rössler), and the paper provides no evidence it is topologically conjugate to Lorenz.\n\n\n4. Gray–Scott validation is insufficient: The training-free method uses a $1 \\times 1$ convolutional kernel (Eq. 13), i.e., a **pointwise linear transformation**\n$$\nv_S(x)=\\gamma\\left[\\begin{array}{cc}\n0 & -1 \\\\\n1 & 0\n\\end{array}\\right] s(x)\n$$\nThis cannot represent the Laplacian terms $\\nabla^2 u, \\nabla^2 v$, which are non-local (require spatial neighborhoods). Thus, the learned $v(x)$ cannot satisfy the Gray-Scott PDE structure. The visual similarity in Figure 3 is insufficient; *the method recovers some distribution-preserving flow, but not the reaction-diffusion dynamics.*\n\n5. Uniqueness misattributed: Figure 4A shows neural solutions cluster tightly while training-free ones scatter—yet the paper claims “data strongly constrains dynamics.” In fact, clustering stems from neural inductive bias (smoothness, simplicity), not data (as even the authors note on p.7)."}, "questions": {"value": "1. On Lorenz fidelity: Given that the cosine similarity is only 0.25 , what dynamical invariants (e.g., Lyapunov exponents, fractal dimension, Poincaré return maps) confirm that the learned system is specifically the Lorenz system rather than an arbitrary chaotic flow?\n2. On singular measures: Since the Lorenz invariant measure has no density, how do you justify using $\\nabla \\log p(x)$ ? What is the relationship between the smoothed score $s_\\tau(x)$ and the true vector field $v_{\\text {Lorenz }}(x)$ in the limit $\\tau \\rightarrow 0$ ?\n3. On uniqueness: Why do training-free solutions exhibit higher variance than neural network solutions if the data strongly constrains dynamics? Doesn't this imply that \"uniqueness\" is due to model bias, not data?\n4. On Gray-Scott: How can a $1 \\times 1$ convolution capture the non-local Laplacian terms $\\nabla^2 u$ ? \n5. On well-posedness: What minimal additional assumptions (e.g., smoothness, locality, conservation laws) would make the inverse problem well-posed? Have you considered incorporating such priors?\n6. On the use of MMD for long-term validation: Figure 7 shows low MMD over time, but MMD is insensitive to dynamical structure—it only measures marginal distribution similarity. Could two systems with identical invariant measures but different ergodic properties (e.g., mixing rates, recurrence times) yield the same MMD?\n7. On scalability: How does the method scale to higher-dimensional systems or systems with more complex dynamics？"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KQkvQyNumU", "forum": "TkhPnmP4GS", "replyto": "TkhPnmP4GS", "signatures": ["ICLR.cc/2026/Conference/Submission6453/Reviewer_hmyh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6453/Reviewer_hmyh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6453/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806709894, "cdate": 1761806709894, "tmdate": 1762918845263, "mdate": 1762918845263, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a method for learning “equilibrium flows” under which a given distribution of data is invariant. They are motivated by the problem of snapshot modeling, in which a dynamical system leaves a static trace of an underlying dynamical process. They take a standard continuity-equation approach with the technical innovation of approximating the divergence term through sampling. This is paired with a training-free method which uses an extension of Langevin Monte Carlo dynamics. The equilibrium flows approach is then applied to a collection of synthetic data sets, starting with low-dimensional but still interesting point clouds, turning next to reaction-diffusion PDEs and ultimately to images of repeated tokens which fall for the authors under the rubric of “artificial life”. They evaluate their results both qualitatively–for example, by how well their learned flows preserve the coarse structure of the point clouds or whether a flow learned from a chaotic system remains chaotic–and quantitatively via similarity scores between flows learned in various competing ways. The authors attribute the performance of their neural-network-based method to certain basic inductive biases encouraged by such an architecture."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. Snapshots are an interesting data type, as the authors convincingly argue, and the field needs more methods for modeling the underlying generative dynamic model. Also, I think that their focus on preservation of qualitative features of the underlying dynamics is interesting and goes beyond more common approaches for merely predicting specific time series or end-states. \n\n2. The qualitative results on 2-3d point clouds and reaction diffusion dynamics mostly look quite good, and it’s nice to see, for example, that the Lorenz case doesn’t blow up and deviations between nearby trajectories seem similar to the underlying model. \n\n3. I thought the sampling approach via the Hutchinson estimator was interesting and differentiated their approach from other flow learning methods, though, as I will explain later, I don’t think this was explored deeply enough."}, "weaknesses": {"value": "*Areas for improvement*\n\n1. The main technical novelty of the paper, to my eye, seems to be the efficient way of computing the divergence. Otherwise, replacing Eq. 8 with a non-sampling approach would more or less be a reproduction of established methods. However, I don’t think the sampling approach is justified well. It is introduced as a way of estimating the divergence, which “is computationally expensive for high-dimensional x”. The authors claim they can “efficiently approximate it using Hutchinson’s Trace Estimator.” Yet, they seem to only use this estimator in the low-dimensional cases where div(v) would seem to be computable without sampling. Further, when they turn to those aforementioned high-dimensional cases, they do away with the Hutchinson estimator, saying  “...applying our original method to such high-dimensional data is challenging due to the computational cost of Hutchinson’s trace estimator.” This seems like a contradiction with the earlier quote. The authors need to clarify (1) when the estimator is useful, ideally by showing numerical results on performance as dimensionality grows and (2) if the use of estimator is not the sole novelty of the approach, where that novelty lies. \n\n\n2. I think the quantitative analysis and evaluation could be greatly strengthened and applied more consistently. Most importantly, I think the authors should show quantitatively that the flows they learn are indeed equilibrium flows. This should be straightforward: perhaps they could simply push their data forward in time and show that some MMD does not increase much (as they do in the appendix)? It is not clear to me that this is even true. For instance, flow for the “moons” data in Fig 2a seems like it would destroy that distribution but this is hard to tell by eye. I would like to see this sort of distributional stability analysis applied consistently through the paper–assuming this is indeed what the authors want to show. Furthermore, the comparison between learned and training-free is not carried out consistently. If a flow could be learned in a training-free way for the 2d systems in Fig 2a, shouldn’t we compare those two approaches? This could be facilitated by the sort of quantitative metrics I proposed. \n\n\n3. From Sec. A.3.3., it seems like the variance rescaling is important for preventing the model from converging to the zero flow. Could the authors verify this explicitly with a simple ablation experiment–batch normalization on vs off during training? \n\n\n4. I am not yet convinced by artificial life example. The images look cool, but it’s not clear how to evaluate the results: are those squiggles on the image tokens in Fig 5 good or bad? Maybe you could generate these with ground truth dynamics and then try to recover it?\n\n\n5. The training-free method seems like a restatement of earlier work on Langevin MC. If not, the authors should explain the novelty. Again, I think it should be compared systematically to the training-based approach, ideally on a performance metric that relates to equilibrium or the preservation of the distribution. \n\n\n6. If I’m reading Sec. 3.1 correctly, the authors only use a simple rotation matrix for a convolutional kernel. But Fig. 8 shows many different kernels. Could the authors show the effect of different K? Could K be learned? \n\n\n7. I think that the paper would be greatly strengthened with the inclusion of real data. For example, snapshot data is prevalent in single-cell transcriptomic studies. Could the authors show that they learn the cell cycle using data from, e.g., Riba et al., 2022 (Nat. Commun.)? This is just a suggestion, and really any real data would suffice–I just think that single cell data is a great use case for this approach. \n\n*Small remarks*\n\nFig 4 caption says the training-free solutions are in green, but for me they show up as yellow."}, "questions": {"value": "To restate some questions I hinted at above: \n\n1. Can the authors clarify (1) when the Hutchinson estimator is useful, ideally by showing numerical results on performance as dimensionality grows and (2) if the use of estimator is not the sole novelty of the approach, where that novelty lies. In short, can you try to resolve the contradiction I pointed out above? \n\n2. Could you include MMD scores or something else that demonstrates the distributions are indeed preserved? This should be ideally done for all data sets. \n\n3. Could you consistently compare (again via a metric like in point 2 above) the training-free vs learned approach? For now, the similarity scores are not so convincing. If you are learning equilibrium flows, you have to show either that the flows are the \"true\" flows given an underlying true dynamics or that the flows do preserve the distribution or both. \n\n4. Can you show results with and without batch normalization? \n\n5. Is it possible to show that the method recovers the true generative dynamics of your artificial life examples? If this is not possible, I think you will have to show in some other way why this example is technically interesting. \n\n6. What is the novelty of the training-free approach? \n\n7. What is the effect of different K? Could K be learned? \n\n8. Have the authors thought of trying real data? Could this be used for the single-cell data I mentioned above? On its own, a detailed study on real data (even with the bulk of results in the appendix if necessary) would be enough for me to reconsider my scores."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YOIoVrypYX", "forum": "TkhPnmP4GS", "replyto": "TkhPnmP4GS", "signatures": ["ICLR.cc/2026/Conference/Submission6453/Reviewer_tfX3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6453/Reviewer_tfX3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6453/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910377696, "cdate": 1761910377696, "tmdate": 1762918844831, "mdate": 1762918844831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Equilibrium Flow, a framework for inferring continuous dynamics directly from static pattern distributions, without temporal data. Using score-based neural representations, it reconstructs plausible dynamics across systems ranging from 2D flows to chaotic attractors and high-dimensional Turing patterns. The method further supports inverse design, enabling the discovery of local interaction rules that generate user-specified, life-like patterns."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method is grounded in solid theoretical foundations. Its connection to the continuity equation, score-based modeling, and Helmholtz decomposition is well-motivated and mathematically coherent.\n2. The method is thoroughly evaluated on diverse systems: 2D distributions, the chaotic Lorenz system, and Gray-Scott Turing patterns, effectively demonstrating the method’s versatility."}, "weaknesses": {"value": "The paper only presents successful cases, without discussing when or why the method fails (e.g., under noisy data, non-stationary distributions, or ambiguous patterns). This limits understanding of the robustness and failure boundaries of the approach."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "bwqLZb3TWJ", "forum": "TkhPnmP4GS", "replyto": "TkhPnmP4GS", "signatures": ["ICLR.cc/2026/Conference/Submission6453/Reviewer_UXYh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6453/Reviewer_UXYh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6453/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762043390557, "cdate": 1762043390557, "tmdate": 1762918844220, "mdate": 1762918844220, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The idea of learning how data points move within a distribution without changing its overall shape by inferring a continuous vector from static samples using a pretrained diffusion model and neural network is reasonable. However, the reviewer has some concern regarding the assumption, motivation and performance of the proposed method, the detailed comments are as follows:  \n1) the authors state that the related methods are either computationally expensive or requiring the temporal information, however, the results does not really show how the proposed method avoid these. \n2) the authors did not clarify why not using temporal information is an advantage, in other words, under what scenarios the temporal information is not available? \n3) the proposed method has the assumption that the dynamics still follow the original distribution, but if the system is highly dynamic, is the proposed method still effective? Since the proposed method uses the continuity equation meaning the system is balanced. \n4) the related work presented in the introduction is not logically sound to point out the contribution of the proposed method since the related work has some conditions meanwhile this paper does not fully clarify the difference. \n5) the authors could use some figures to illustrate the high-level idea of the proposed method to increase the readability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper presents the technical details in rigorous math formulation. \n2) Broad empirical coverage by different categories of datasets."}, "weaknesses": {"value": "1) readability: the paper is not sufficiently clear for non-experts, especially regarding the practical motivation and potential applications of the proposed framework. \n2) justification of contribution: the paper does not adequately compare the proposed method with prior approaches mentioned in the Introduction."}, "questions": {"value": "See detail comments in Summary."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jHP0Pbed5J", "forum": "TkhPnmP4GS", "replyto": "TkhPnmP4GS", "signatures": ["ICLR.cc/2026/Conference/Submission6453/Reviewer_8dfP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6453/Reviewer_8dfP"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission6453/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762485541023, "cdate": 1762485541023, "tmdate": 1762918843524, "mdate": 1762918843524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}