{"id": "avUVW1g6uS", "number": 22922, "cdate": 1758337121522, "mdate": 1759896840016, "content": {"title": "SAMerging: Sharpness-aware Model Merging via Multi-Teacher Knowledge Distillation", "abstract": "Model merging offers a lightweight alternative to joint multi-task learning (MTL), which is often costly or data-prohibitive. While the task arithmetic seems promising, it is brittle to coefficient scaling, and we observe that recent approaches, such as AdaMerging, that learn these coefficients, remain sensitive to initialization. This raises a key question: can merging coefficients be learned in a principled, label-free way? We introduce SAMerging, a method that learns coefficients by seeking flat minima. Our approach is grounded in two theoretical contributions. First, we derive a flatness-aware PAC-Bayes generalization bound for the merged model, featuring a novel cross-task heterogeneity term that quantifies expert-task mismatch. Second, this analysis guides us to frame merging as multi-teacher knowledge distillation on a small, unlabeled dataset. We formally show that minimizing the student-teacher KL divergence tightens an upper bound on the merged model's excess risk. We then employ Sharpness-Aware Minimization (SAM) to find robust solutions that generalize better. Empirically, SAMerging establishes a new state of the art on vision and NLP benchmarks. Notably, it surpasses AdaMerging with accuracy gains of $+4.5\\%$ on TA-8 and $+11.7\\%$ on TALL-20. This is achieved with remarkable data efficiency, using $10\\times$ fewer calibration data and proving effective even in data-scarce settings with as few as $16$ examples per task. Furthermore, it requires no original training data and incurs no additional inference-time or memory overhead.", "tldr": "We introduce SAMerging, a method for model merging that does sharpness-aware multi-teacher knowledge distillation.", "keywords": ["model merging", "multi-task learning", "flat minima", "knowledge distillation", "generalization"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/69a3c47f8588fac357bde4a5711d3c3b4e5f051a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "First, the authors derive a PAC-Bayes generalization bound for the merged model, which highlights the importance of finding \"flat\" minima in the loss landscape and introduces a \"cross-task heterogeneity\" term to quantify the mismatch between different models. Second, they frame the model merging problem as a multi-teacher knowledge distillation task. This involves minimizing the KL divergence between the merged model's predictions and the expert models' predictions on a small, unlabeled dataset. To find solutions that generalize well, they employ Sharpness-Aware Minimization, which explicitly seeks out flat regions in the loss landscape."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The derivation of the PAC-Bayes bound (Theorem 2) and the excess risk bound (Theorem 3) logically connects the goals of finding flat minima and minimizing KL divergence to the ultimate objective of better generalization. The results convincingly demonstrate the superiority of SAMerging over existing data-dependent methods, particularly in its data efficiency.\n* The connection between the theoretical insights and the final algorithm is explained logically, making the design choices easy to follow.\n* By providing a robust, data-efficient method, SAMerging addresses key limitations of prior work, such as sensitivity to initialization and high data requirements. It achieves state-of-the-art performance with minimal calibration data and no inference overhead."}, "weaknesses": {"value": "* The theoretical proofs and methods used in this paper, such as SAM and multi-teacher knowledge distillation, have been widely explored in previous work. The contribution here appears to be more of a combination of existing techniques applied to model merging, rather than a novel approach.\n* The paper acknowledges this limitation, noting that the NTK regime is most accurate near the pretrained initialization. It remains unclear how well this assumption holds in practice, especially when the fine-tuned models have diverged significantly from the pretrained model.\n* The experiments are primarily focused on classification tasks. While these are standard benchmarks, the paper's claims would be strengthened by evaluating SAMerging on a more diverse set of tasks, particularly on modern LLMs."}, "questions": {"value": "It adds computational cost during the merging process due to the use of SAM, which involves an additional forward/backward pass to find the \"worst-case\" perturbation. The authors acknowledge this as a \"calibration-time cost\" but do not quantify it relative to other methods. A brief analysis of this trade-off would provide a more complete picture of the method's practicality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8Wk5z65Qox", "forum": "avUVW1g6uS", "replyto": "avUVW1g6uS", "signatures": ["ICLR.cc/2026/Conference/Submission22922/Reviewer_fHM9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22922/Reviewer_fHM9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761035251356, "cdate": 1761035251356, "tmdate": 1762942439498, "mdate": 1762942439498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SAMerging, a method for model merging in the context of multi-task learning. SAMerging selects layer-wise merging coefficients by optimizing for flat minima and aligning with expert teachers via multi-teacher knowledge distillation on small amounts of unlabeled data. The theoretical backbone includes a PAC-Bayes generalization bound for the merged model, introducing a new cross-task heterogeneity term and connecting optimization of the merged model's sharpness and KL fit to rigorous generalization control. Empirically, SAMerging is tested on a range of computer vision and NLP benchmarks, consistently outperforming both data-free and data-dependent baselines, including AdaMerging, using significantly fewer calibration data, with no added inference overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper establishes a detailed PAC-Bayes generalization bound for MTL model merging and introduces an explicit cross-task heterogeneity term. This analysis provides motivation for practical design choices and clarifies failure modes.\n- The method proposed in this paper addresses how to train a model with excellent performance even under zero initialization, which differs from previous works that require task arithmetic information.\n- This paper also presents extremely detailed ablation experiments, which fully demonstrate the superiority of the SAMerging method."}, "weaknesses": {"value": "- The paper does not include a comparison with the work ProDistill [1]. This is because the paper mentions that it requires 1,600 samples to achieve optimal performance, while the number of samples used in ProDistill is far fewer than that required by SAMerging. Is it necessary to further validate the conclusion that SAMerging requires fewer samples by comparing it with ProDistill?\n- The description of experimental details is insufficient. The paper does not provide specific values for parameters such as ρ and η, nor does it conduct basic ablation experiments on these hyperparameters—these details need to be supplemented.\n- The paper does not mention the memory overhead or time overhead during training. As the number of tasks increases, is the memory overhead completely proportional to the number of tasks? If so, how to address such significant memory overhead? If possible, please provide relevant calculation formulas or training methods.\n\n[1] Jing Xu, Jiazheng Li, and Jingzhao Zhang. Scalable model merging with progressive layer-wise\ndistillation. (arXiv:2502.12706), May 2025. doi: 10.48550/arXiv.2502.12706. URL http:\n//arxiv.org/abs/2502.12706. arXiv:2502.12706."}, "questions": {"value": "My questions are listed with my weaknesses above.\n\nI'm excited to engage with the authors to clear up the aspects I don't fully understand and I'm optimistic that with some iteration this paper can be made stronger."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LWVi1aDKRo", "forum": "avUVW1g6uS", "replyto": "avUVW1g6uS", "signatures": ["ICLR.cc/2026/Conference/Submission22922/Reviewer_kw7H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22922/Reviewer_kw7H"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761585390041, "cdate": 1761585390041, "tmdate": 1762942438975, "mdate": 1762942438975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SAMerging, a framework for data-efficient and label-free model merging. The authors derive a flatness-aware PAC-Bayes generalization bound that connects model sharpness with cross-task heterogeneity, providing theoretical insight into when merging succeeds. They further reinterpret coefficient learning as multi-teacher knowledge distillation, minimizing the KL divergence between the merged model and its experts while incorporating Sharpness-Aware Minimization (SAM) for better generalization. Extensive experiments on TA-8, TALL-14/20, and GLUE benchmarks show consistent competitive results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1 SAMerging achieves consistent performance gains over both data-free and data-dependent baselines across multiple benchmarks.\n2 The paper has a good organizational structure."}, "weaknesses": {"value": "1 While the PAC-Bayes and SAM integration are new, the overall combination of KD + SAM resembles existing fine-tuning or merging extensions (e.g., AdaMerging + SAM). The contribution feels evolutionary rather than fundamentally new, since the method is essentially “AdaMerging + SAM + KD reformulation” without deeper empirical diversity.\n\n2 The paper devotes extensive space to mathematical derivations (PAC-Bayes, NTK linearization, and multiple lemmas), but the empirical link between theory and practice is unclear. There is no ablation or visualization showing how the “flatness” or “heterogeneity” terms actually correlate with the final performance, making the theoretical results appear decorative rather than explanatory.\n\n3 The experimental validation is confined to relatively standard benchmarks (TA-8, TALL-14/20, GLUE) using image classification and text classification tasks. This setting does not reflect the diversity or difficulty of modern model-merging scenarios. In particular,\nall tasks share similar architectures and backbone initializations (CLIP or GPT-2), there are no tests on heterogeneous architectures, domain shifts, or large-scale multimodal models.\n\n4 Several recent and competitive merging methods (e.g., Twin-Merging, PCB-Merging, 2024–2025) are missing, weakening the empirical thoroughness of the study.\n\n5 Figure 2(a) is redundant, as its information is already presented in Table 1."}, "questions": {"value": "Q1: Which previous does the experimental setup (e.g., Table 1) in this paper follow?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cq5AJrQKKp", "forum": "avUVW1g6uS", "replyto": "avUVW1g6uS", "signatures": ["ICLR.cc/2026/Conference/Submission22922/Reviewer_P26t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22922/Reviewer_P26t"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839780478, "cdate": 1761839780478, "tmdate": 1762942438431, "mdate": 1762942438431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper derives a flatness-aware PAC-Bayes generalization bound that provides theoretical guidance for the design of model merging methods. The authors further propose SAMerging, which improves model merging through multi-teacher knowledge distillation on a small, unlabeled dataset. Theoretically, the paper proves that SAMerging tightens an upper bound on the merged model’s excess risk."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper theoretically identifies the key factors that influence model merging performance, providing guidance for the design of new merging methods.\n\n2. The proposed method is also supported by solid theoretical analysis, which enhances the rigor and credibility of the approach.\n\n3. The experimental results demonstrate that the proposed method achieves promising performance across various benchmarks."}, "weaknesses": {"value": "1. **Unclear connection between the proposed method and the core Theorem 2.** The method introduced in Section 3.1 appears to have a weak connection with the main theoretical contribution presented in Theorem 2. In other words, it is unclear how the core theoretical result in Theorem 2 technically guides the design of the proposed SAMerging method in concrete technical details. Besides, Section 3.1 and Section 3.2 appear to follow two different theoretical frameworks, with limited connection between them.\n\n2. **Reliance on training data.** The proposed approach depends on access to training data, which may limit its practical applicability, especially given the existence of several data-free model merging methods."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns."}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xH7PK5IOBn", "forum": "avUVW1g6uS", "replyto": "avUVW1g6uS", "signatures": ["ICLR.cc/2026/Conference/Submission22922/Reviewer_NAr3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22922/Reviewer_NAr3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937667452, "cdate": 1761937667452, "tmdate": 1762942438049, "mdate": 1762942438049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}