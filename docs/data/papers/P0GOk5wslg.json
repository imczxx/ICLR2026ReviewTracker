{"id": "P0GOk5wslg", "number": 22399, "cdate": 1758330570283, "mdate": 1759896868335, "content": {"title": "Speculative Actions: A Lossless Framework for Faster AI Agents", "abstract": "AI agents have attracted growing interest across industry and academia, but in practice their execution can be slow. For example, letting two state-of-the-art agents play a game of chess may take hours. A key bottleneck is that agent behavior unfolds sequentially: each action requires an API call, and these calls can be time-consuming. Inspired by speculative execution in microprocessors and speculative decoding in LLM inference, we propose speculative actions—a lossless framework that predicts likely actions using faster models, enabling multiple API calls to be executed in parallel. We evaluate this framework across four agentic environments: gaming, e-commerce, web search, and operating systems. In all cases, speculative actions yield substantial acceleration, with potential speedups of up to 30%. Moreover, performance can be further improved through stronger guessing models and top-K action prediction, opening a promising path toward real world, efficient deployment of AI agents.", "tldr": "We introduce speculative actions—a lossless framework that predicts likely actions using faster models, enabling multiple API calls to be executed in parallel and thus yields substantial acceleration.", "keywords": ["AI Agents", "Speculative Decoding", "Parallel Execution", "Agentic Serving", "Agentic Simulation"], "primary_area": "infrastructure, software libraries, hardware, systems, etc.", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/37d9484288132ce560ca42207808db623cb95e04.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a way to increase the speed of agent-environment interactions by leveraging speculative execution.\n\nThey call this framework \"Speculative Actions\". It is a lossless framework that predicts the K most likely next actions using fast models, enabling multiple steps to be executed in parallel (before the real next action of the slow model is obtained).\n\nThe authors evaluate it on multiple settings, showing that it yields noticeable speedups."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper addresses the very practical need of maximizing efficiency and throughput in agentic settings, where API calls can be costly and time-consuming.\n\nThe authors show that the proposed method works well on a diversity of practical settings.\n\nThe paper is mostly easy to follow and understand. The logical order of presentation makes sense.\n\nThe paper includes bar charts that visually illustate the advantage of the proposed method. I appreciate the error bars in Figure 2."}, "weaknesses": {"value": "There are a few places where terms, acronyms, or notations are used before first being defined and explained. More on this below.\n\nPage 1:\n\nDefine what the acronym \"MCP\" means (\"Model Context Protocol\") before it's first used. Explain what it means, either here or on page 2 (where it says \"MCP servers for agentic systems...\").\n\nPage 2:\n\n\"while waiting results\" -> \"while waiting for results\"\n\nPage 3:\n\n\"with simple implementation\" -> \"with a simple implementation\"\n\n\"in computer architecture\" -> \"in the field of computer architecture\"\n\n\"wrong and\" -> \"wrong, and\"\n\n\"an Markov\" -> \"a Markov\"\n\n\"(MDP) (st, at), where st denotes\" -> \"(MDP). We let st denote...\"\n\nPage 4:\n\n\"a set of API responses {\\hat{a}_t}\" -> \"a set of k API responses {\\hat{a}_t^(i)}_{i=1}^k\". This explains what k refers to before it's used later on.\n\nYou have not defined what \"Exp\" means in Exp(α) and Exp(β). Define the notation before it's first used, by explicitly stating that Exp(λ) means an exponential distribution with rate λ.\n\nPage 5:\n\n\"speculation need to be\" -> \"speculation must be\"\n\n\"via fork\" -> \"via forking\"\n\n\"Consider a game at turn t, \" -> \"Consider a game at turn t: \"\n\n\"reasoning eliciting\" -> \"reasoning-eliciting\"\n\n\"prompt\" should not be in italics inside math formulas Use \\text{prompt} to avoid this.\n\n\"applying predicted\" -> \"applying the predicted\"\n\nPage 6:\n\n\"match\" should not be in italics inside math formulas. Use \\text{match} to avoid this.\n\n\"If there exist no match\" -> \"If no match exists\"\n\n\"next turn where Q is in turn to\" -> \"next turn, where it is Q's turn to\"\n\n\"play while time is\" -> \"play, while time is\"\n\n\"and computational complexity\" -> \"and the computational complexity\"\n\nPage 7:\n\n\"agent need to\" -> \"the agent needs to\"\n\n\"is the API calls... that are needed\" -> \"is the API call... that is needed\"\n\nPage 8:\n\n\"predicts API call\" -> \"predicts the API call\"\n\nSpace missing after \"yielding predicted states\".\n\n\"ht + 1\" the \"t + 1\" is not properly subscripted.\n\n\"k ∈ {1,3}\" should be typeset as a formula.\n\n\"k = 3\" should be typeset as a formula.\n\nPage 9:\n\n\"Our evaluation shows that the Speculator:\" -> \"Our evaluation shows that the Speculator-Actor system:\" ?"}, "questions": {"value": "Page 3:\n\nBy \"regenerating failures\", did you really mean \"recovering from failures\"?\n\nFigure 2: What do the error bars show? Standard deviation? Standard error? A 95% confidence interval for the mean (computed with which method)?\n\nWhat's the best way to set k in practice? Can this be done in an online manner?\n\nAlternatively, could one automate the selection of k situationally (i.e., on a step-by-step basis)? For example, you could have a fast model that's been trained to predict the *thinking times* of the slow models and/or transition function, and that could allow you to budget the number of speculations appropriately.\n\nAre error bars missing from Figures 3 and 4? Were these run for multiple trials?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UPc6cqBbs2", "forum": "P0GOk5wslg", "replyto": "P0GOk5wslg", "signatures": ["ICLR.cc/2026/Conference/Submission22399/Reviewer_qQio"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22399/Reviewer_qQio"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789601503, "cdate": 1761789601503, "tmdate": 1762942202824, "mdate": 1762942202824, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Speculative Actions, a framework for accelerating AI agent–environment interactions by predicting future actions with a smaller, faster “Speculator” model, while the main “Actor” validates them asynchronously. The idea is to make agent execution more parallel and efficient, analogous to speculative decoding in LLMs or speculative execution in CPUs. The paper demonstrates this concept across multiple domains (chess, e-commerce, HotpotQA, and OS tuning) and claims consistent speedups.\n\nOverall, the motivation is reasonable as reducing agent latency makes sense, especially in complex API-driven workflows. However, in many realistic agent scenarios, I don't think the latency bottleneck is as severe as claimed, and the proposed speculative mechanism may introduce new costs or practical issues that are not fully addressed."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper identifies a clear, relevant problem: latency in sequential agent–environment interactions.\n\n- The proposed speculative framework is simple and implementable, with clear lossless and lossy variants.\n\n- Multi-domain experiments demonstrate feasibility and some measurable speedups.\n\n- The topic (efficient agent execution) is timely and of practical interest."}, "weaknesses": {"value": "The paper provides strong empirical results but lacks deeper theoretical justification for why the speculative framework remains “lossless” under all conditions. Moreover, the evaluation mainly focuses on latency gains without a detailed analysis of trade-offs in resource consumption or potential instability in large-scale multi-agent settings. I may raise my evaluation on this paper if the authors could provide better justification for this concern."}, "questions": {"value": "- The paper claims “up to 30% end-to-end speedup.” What is the variance across environments, and how were these averages computed?\n- Could speculative execution introduce hidden costs that offset real-world gains?\n- In multi-step speculation, how do you control exponential growth in parallel branches?\n- How reproducible are the speedups given that API latency for large models may not be consistent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1fQMvuGe0h", "forum": "P0GOk5wslg", "replyto": "P0GOk5wslg", "signatures": ["ICLR.cc/2026/Conference/Submission22399/Reviewer_hwQA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22399/Reviewer_hwQA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987589269, "cdate": 1761987589269, "tmdate": 1762942201278, "mdate": 1762942201278, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes the concept of speculative actions, which uses speculative models in sequential environments to achieve significant speedups (up to 30%). Concretely, the paper considers the setting where an API determines the next action based on the current state, and this API is instantiated by either an expensive LLM (e.g., high-reasoning mode) or a human response. The paper proposes an algorithm that uses a much faster model, in this case a smaller LLM, to predict the likely output and to precompute the next state based on this action. If the action matches the prediction of the expensive model (or human), the algorithm can directly proceed to the next state, thereby processing two steps at a time. Otherwise, the environment generates the next state based on the true action, progressing without overhead compared to the sequential baseline. The paper considers four different environments with different constraints, and shows that the proposed approach achieves speedups of up to 30%."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper considers an important topic, namely, decreasing the latency of LLM agents in sequential environments, and introduces a novel algorithm to achieve significant speedups. The proposed approach is naturally inspired by speculative decoding from other domains, but the paper makes a significant contribution by showing that it is also applicable to this setting. The paper is well written, with clear illustrations and a convincing motivation. The claims are backed up by substantial experimental evidence across a wide range of real-world environments."}, "weaknesses": {"value": "I think the cost-vs-latency tradeoff is an important aspect of this approach and should be discussed in the main paper, e.g., using the additional page of the camera-ready version (if applicable). In a practical application, it would be great for the user to have a tunable knob between costs and latency.\n\nI found two typos: sequantial (L293) and gameply (L316)."}, "questions": {"value": "How can a user find an appropriate speculative model? Did any smaller LLMs not achieve a satisfactory performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZM5iN4CT1M", "forum": "P0GOk5wslg", "replyto": "P0GOk5wslg", "signatures": ["ICLR.cc/2026/Conference/Submission22399/Reviewer_SJo2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22399/Reviewer_SJo2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762186085641, "cdate": 1762186085641, "tmdate": 1762942200888, "mdate": 1762942200888, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new general framework called \"Speculative Actions\" in which agents predict future states of the world that will come about as a consequence of e.g. the environment, other actors, computation, API calls, and performs API calls based on that prediction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The idea is solid and the experiments convincingly show a speedup."}, "weaknesses": {"value": "No weaknesses"}, "questions": {"value": "No questions"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iwEQJCqxmX", "forum": "P0GOk5wslg", "replyto": "P0GOk5wslg", "signatures": ["ICLR.cc/2026/Conference/Submission22399/Reviewer_Ktyn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22399/Reviewer_Ktyn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762350657109, "cdate": 1762350657109, "tmdate": 1762942200618, "mdate": 1762942200618, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}