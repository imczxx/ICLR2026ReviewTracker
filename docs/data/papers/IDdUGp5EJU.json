{"id": "IDdUGp5EJU", "number": 15943, "cdate": 1758257412547, "mdate": 1763460933886, "content": {"title": "SkillWrapper: Generative Predicate Invention for Skill Abstraction", "abstract": "Generalizing from individual skill executions to solving long-horizon tasks remains a core challenge in building autonomous agents. A promising direction is learning high-level, symbolic abstractions of the low-level skills of the agents, enabling reasoning and planning independent of the low-level state space. Among possible high-level representations, object-centric skill abstraction with symbolic predicates has been proven to be efficient because of its compatibility with domain-independent planners. Recent advances in foundation models have made it possible to generate symbolic predicates that operate on raw sensory inputs—a process we call generative predicate invention—to facilitate downstream abstraction learning. However, it remains unclear which formal properties the learned representations must satisfy, and how they can be learned to guarantee these properties. In this paper, we address both questions by presenting a formal theory of generative predicate invention for skill abstraction, resulting in symbolic operators that can be used for provably sound and complete planning. Within this framework, we propose SkillWrapper, a method that leverages foundation models to actively collect robot data and learn human-interpretable, plannable representations of black-box skills, using only RGB image observations. Our extensive empirical evaluation in simulation and on real robots shows that SkillWrapper learns abstract representations that enable solving unseen, long-horizon tasks in the real world with black-box skills.", "tldr": "", "keywords": ["Robotic Planning", "Model Learning", "Concept Learning", "Symbolic Abstraction Learning", "Symbolic World Model"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9b5036bd19a4b3b0d9b47a1931464bcccb992a60.pdf", "supplementary_material": "/attachment/32500dbb65691e3a32c9bc1fc673f3ffd838b77a.zip"}, "replies": [{"content": {"summary": {"value": "The paper tackles the problem of learning plannable, high-level models of black-box skills from raw RGB observations by inventing predicates and composing them into PDDL operators that can be used with off-the-shelf planners. The core idea is a formal framework for generative predicate invention with explicit target properties (soundness, completeness, “suitability”), and an algorithm, SKILLWRAPPER, that alternates between (i) actively collecting data by proposing skill sequences, (ii) inventing predicates when current abstractions cannot explain observed success/failure or effects, and (iii) learning operators by clustering transitions on lifted effects and intersecting preconditions. The system uses a foundation model both to generate predicate candidates and to classify their truth values from images; only RGB images are assumed. Theoretical results show operators are supported by data (soundness) and that the learned model is probabilistically complete under finite-hypothesis assumptions. Empirically, the method is evaluated in Robotouille (a simulated kitchen domain) and on two real setups (Franka Panda; bimanual Kuka). In simulation, SKILLWRAPPER achieves 73.3% solved on “Easy” with PB=2.9, 38.3% on “Hard” with PB=6.1, and 100% correct detection of impossible tasks, outperforming ViLa and random exploration and competitive with expert operators on some splits. On real robots, it generalizes predicates learned in restricted settings to a larger test setting (e.g., 60.0% solved in generalization split; PB=4.0). Iterative runs show performance improves as more predicates are invented and data collected."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality.\n\n • Provides a formal target for predicate invention in the context of skill abstraction, not merely state abstraction, and uses it to drive algorithmic design (two concrete invention triggers based on executability and effect inconsistencies).\n • Uses a foundation model as a relational classifier (truth assignment for grounded predicates) and not just a planner, enabling learning from RGB images without pre-defined state factors.\n\nQuality (theory).\n\n • Clear statements of soundness (operators backed by observed transitions) and probabilistic completeness w.r.t. a distribution over transitions, with proofs/sketches and finite-hypothesis assumptions.\n\nQuality (empirics).\n\n • Evaluations span simulation and two real robot platforms; the setup probes both generalization across environments (Franka) and iterative improvement under irreversible actions (bimanual Kuka). The Robotouille benchmark comparison includes expert, system predicates, ViLa, and random exploration. Metrics include solved rate and a planning budget proxy (PB) tied to completeness.\n\nClarity.\n\n • The paper is organized around a tight loop: data → predicates → operators, with pseudocode, invention conditions, and scoring functions, plus prompt details in the appendix. Examples of learned predicates/operators (with natural-language semantics) help assess interpretability.\n\nSignificance.\n\n • Demonstrates that language/VLM priors can yield plannable, interpretable abstractions from raw images, and that these abstractions can scale to longer-horizon problems than open-loop LLM planning—an important step for integrating FM-driven perception with symbolic planning in robotics."}, "weaknesses": {"value": "Theoretical scope and assumptions.\n • The soundness guarantee is empirical (“supported by at least one observed transition”) and does not formalize robustness to classification noise from the VLM. In practice, VLM truth assignments will be imperfect; the theory currently does not propagate uncertainty through operator learning or planning, nor does it bound error from misclassifications.\n • The probabilistic completeness bound relies on a finite hypothesis class H and i.i.d. sampling; it is unclear how H is instantiated in practice when predicate proposals are open-ended (FM-generated) and when pruning/reevaluation can expand or contract the model class over time. The bound risks being vacuous without a concrete characterization of |H| or sample complexity as a function of invented predicates. \n • The method assumes deterministic skills and that skills affect only the bound objects. Many real skills are stochastic and produce side effects; the invention conditions and operator learning rules may need adaptation to handle such cases. \n\nAlgorithmic design choices.\n • Operator learning computes preconditions via intersection of initial abstract states within a cluster; this is conservative and can produce spurious preconditions when data are sparse—acknowledged by the authors—but the paper offers limited guidance on when predicate re-evaluation suffices versus when additional data are required. A quantitative analysis of false-positive preconditions over iterations would strengthen the claim.\n • Predicate selection hinges on thresholds in score functions (Algorithm 6). The paper does not study sensitivity to the threshold h, nor how choices trade off compactness vs. coverage (e.g., learned operator sparsity, PB, solved rate). \n • The active data collection relies on LLM-proposed sequences and heuristic scores (coverage/chainability). While well-motivated, there is no ablation isolating the gain from these heuristics vs. random or simpler curricula.\n\nEmpirical evaluation.\n • Baselines: “System Predicates” lacks invention and has privileged state access; by construction it will underperform on tasks requiring new predicates, making it a weak comparator. Missing are stronger learned-predicate/action-model baselines (e.g., neurosymbolic predicate learners or prior predicate-invention techniques) to more precisely attribute gains to the proposed invention logic.\n • Scale and variance: Many results are averaged over three runs; the real-robot evaluation uses small problem sets, limiting statistical confidence. Reporting confidence intervals and significance tests would help.\n • VLM-as-classifier reliability: Since abstract states are inferred directly from a VLM on RGB images, experiments should report truth-assignment accuracy against labeled ground truth (even on a subset) and robustness to viewpoint changes/occlusion; currently, the paper assumes full observability from images."}, "questions": {"value": "Questions\n1. Hypothesis class & bounds. How do you instantiate the finite hypothesis class H used in Theorem 2 when predicates are FM-generated and can be reevaluated/removed? Can you provide a practical upper bound on |H| (e.g., as a function of max invented predicates and arity) and a sample-complexity estimate in transitions to achieve a target \\epsilon?\n2. Noise-aware guarantees. Do you foresee modifying the framework to incorporate noisy predicate truth values (e.g., via probabilistic predicates or confidence-weighted effects), and can the soundness/completeness results be extended to this setting? Empirically, what is the observed misclassification rate of the VLM over your predicates?\n3. Ablations. Please provide ablations for (a) coverage/chainability in skill-sequence proposal, (b) predicate re-evaluation (on/off), and (c) threshold h in Algorithm 6. How do these affect solved %, PB, number of predicates, and operator sparsity?\n4. Stochastic or side-effectful skills. How does the effect-inconsistency trigger behave if a skill succeeds but produces variable effects (or mid-execution failure) due to stochasticity? Do you anticipate inventing context predicates vs. effect predicates, and how are these disambiguated empirically?\n5. Portability across embodiments. In the real-robot experiments, to what extent were the same predicates reused across Panda and Kuka (vs. reinvented)? Could you report a transfer study where operators learned on one platform are applied to the other with minimal additional data?\n6. VLM classifier robustness. Have you measured sensitivity to camera viewpoint/lighting/occlusion or to minor domain shift (e.g., new mugs/utensils not seen during learning)? Even a small held-out labeled set would be informative.\n7. Metrics. Beyond solved% and PB, could you report plan optimality gaps, planning time, interaction budget, and predicate/operator counts over iterations (with variance), to better illuminate data efficiency and model compactness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0eqFZOb2aL", "forum": "IDdUGp5EJU", "replyto": "IDdUGp5EJU", "signatures": ["ICLR.cc/2026/Conference/Submission15943/Reviewer_eiUT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15943/Reviewer_eiUT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761518813903, "cdate": 1761518813903, "tmdate": 1762926156826, "mdate": 1762926156826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "We thank all the reviewers for their thoughtful and actionable comments. We are glad that reviewers found our work original, “generally well-written”, “easy to understand”, clear, and significant. We are happy that our paper was able to convey to reviewers our core contribution on developing a theory that learns symbolic models for skills while providing guarantees of completeness and soundness of learned models. \n\nWe would now like to respond to some of the questions raised by the reviewers. Here, we post a common response that answers questions raised by more than one reviewer and then respond to each reviewer separately to address reviewer-specific questions. \n\n__1. Deterministic skills and fully observable environment. (Reviewer 3RUj ,eiUT)__\n\nWe make two key assumptions: deterministic skills and a fully observable environment. These assumptions are commonly made in prior and concurrent work in predicate invention for model learning [1, 2, 3, 4, 5, 6, 7]. We have updated the paper to clarify this. While we did not relax these assumptions in the paper, we would like to highlight our contribution on the formal theory for provably sound and complete skill abstraction, the SkillWrapper algorithm for principled generative predicate invention, and implementation and evaluation on real robots. To our knowledge, SkillWrapper is the first method to demonstrate generative predicate invention for skill abstraction on real robots using RGB image observations. \n\nWe believe that relaxing these assumptions without losing formal guarantees is a promising direction for future work, potentially by using approaches such as SLAM that can incorporate spatial memory. However, these extensions are out of scope for this paper, and we would like to defer stochastic and partially observable settings to future work. \n\n__2. Additional Experiments.__\n\nWe thank reviewers for their constructive feedback to improve the quality of the papers. We have compiled a list of experiments that one or more reviewers have suggested. We will try our best to finish the suggested experiments. However, due to time limitations, we may not be able to complete all the experiments promptly. Therefore, here is an ordered list of experiments (higher priority = higher in the order) that we would try to conduct. \n\n1. VLM classification test on viewpoint/lighting/occlusion (Franka, Kuka)\n2. Table 1 with 5 individual runs (Robotouille)\n3. Ablation for skill sequence proposal (Robotouille)\n4. VLM classification test on minor domain shift (Franka, Kuka)\n5. Experiment with controlled label noise (Robotouille)\n\nWe note that additional simulation results will likely be completed first, while experiments on the robots will take more time. We would try to report the results as we have them. Please let us know if you have different opinions on the proposed ordering of these additional experiments.\n\n__3. Classification noise from VLMs. (Reviewer 3RUj ,eiUT)__\n\nWe agree that VLM classification accuracy is an important factor in our system. However, this highlights the importance of having a correct and complete theory, as our proposed method uses theoretically motivated conditions to identify reliable predicates. We emphasize that our contributions do not center on the current visual capabilities of VLMs, but rather on how principled algorithms can use these potentially noisy classifiers to produce sound representations for planning. Additionally, as VLMs continue to evolve, SkillWrapper offers a modular framework that can directly benefit from their advancement. \n\nIn practice, we incorporate a per-predicate scoring function to account for this classification noise (see Alg. 6). Specifically, this scoring function is used to verify that any proposed predicate empirically improves the accuracy of the symbolic model over the available data. If the VLM cannot reliably classify the condition for a predicate, that predicate is unlikely to improve the symbolic model and would therefore not be kept. This process may discard “near-reliable” predicates, but in doing so, it maintains the soundness and probabilistic completeness properties of our approach.\n\nWe also conducted analyses on VLMs’ accuracy in both robotic experiments, since multiple reviewers expressed their concerns about the real-world reliability of the VLMs. From the result, we can conclude that the VLMs are reliable enough for the predicate classification task. Despite specific predicates failing to get reliably correct results on certain objects or due to lighting conditions, the overall accuracy achieves 86.7% in Franka and 98.5% on bimanual Kuka (more details could be found in Appendix G). We believe a more advanced vision pipeline or pre-trained model could potentially further improve the performance of SkillWrapper, which we will leave for future work."}}, "id": "8M48iJ3Y3C", "forum": "IDdUGp5EJU", "replyto": "IDdUGp5EJU", "signatures": ["ICLR.cc/2026/Conference/Submission15943/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15943/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15943/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763455348342, "cdate": 1763455348342, "tmdate": 1763455348342, "mdate": 1763455348342, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "We thank all the reviewers for their thoughtful and actionable comments. We are glad that reviewers found our work original, “generally well-written”, “easy to understand”, clear, and significant. We are happy that our paper was able to convey to reviewers our core contribution on developing a theory that learns symbolic models for skills while providing guarantees of completeness and soundness of learned models. \n\nWe would now like to respond to some of the questions raised by the reviewers. Here, we post a common response that answers questions raised by more than one reviewer and then respond to each reviewer separately to address reviewer-specific questions. \n\n__1. Deterministic skills and fully observable environment. (Reviewer 3RUj ,eiUT)__\n\nWe make two key assumptions: deterministic skills and a fully observable environment. These assumptions are commonly made in prior and concurrent work in predicate invention for model learning [1, 2, 3, 4, 5, 6, 7]. We have updated the paper to clarify this. While we did not relax these assumptions in the paper, we would like to highlight our contribution on the formal theory for provably sound and complete skill abstraction, the SkillWrapper algorithm for principled generative predicate invention, and implementation and evaluation on real robots. To our knowledge, SkillWrapper is the first method to demonstrate generative predicate invention for skill abstraction on real robots using RGB image observations. \n\nWe believe that relaxing these assumptions without losing formal guarantees is a promising direction for future work, potentially by using approaches such as SLAM that can incorporate spatial memory. However, these extensions are out of scope for this paper, and we would like to defer stochastic and partially observable settings to future work. \n\n__2. Additional Experiments.__\n\nWe thank reviewers for their constructive feedback to improve the quality of the papers. We have compiled a list of experiments that one or more reviewers have suggested. We will try our best to finish the suggested experiments. However, due to time limitations, we may not be able to complete all the experiments promptly. Therefore, here is an ordered list of experiments (higher priority = higher in the order) that we would try to conduct. \n\n1. VLM classification test on viewpoint/lighting (Franka, Kuka)\n2. Table 1 with 5 individual runs (Robotouille)\n3. Ablation for skill sequence proposal heuristics (Robotouille)\n4. VLM classification test on minor domain shift (Franka, Kuka)\n\nWe note that additional simulation results will likely be completed first, while experiments on the robots will take more time. We would try to report the results as we have them. Please let us know if you have different opinions on the proposed ordering of these additional experiments.\n\n__3. Classification noise from VLMs. (Reviewer 3RUj ,eiUT)__\n\nWe agree that VLM classification accuracy is an important factor in our system. However, this highlights the importance of having a correct and complete theory, as our proposed method uses theoretically motivated conditions to identify reliable predicates. We emphasize that our contributions do not center on the current visual capabilities of VLMs, but rather on how principled algorithms can use these potentially noisy classifiers to produce sound representations for planning. Additionally, as VLMs continue to evolve, SkillWrapper offers a modular framework that can directly benefit from their advancement. \n\nIn practice, we incorporate a per-predicate scoring function to account for this classification noise (see Alg. 6). Specifically, this scoring function is used to verify that any proposed predicate empirically improves the accuracy of the symbolic model over the available data. If the VLM cannot reliably classify the condition for a predicate, that predicate is unlikely to improve the symbolic model and would therefore not be kept. This process may discard “near-reliable” predicates, but in doing so, it maintains the soundness and probabilistic completeness properties of our approach.\n\nWe also conducted analyses on VLMs’ accuracy in both robotic experiments, since multiple reviewers expressed their concerns about the real-world reliability of the VLMs. From the result, we can conclude that the VLMs are reliable enough for the predicate classification task. Despite specific predicates failing to get reliably correct results on certain objects or due to lighting conditions, the overall accuracy achieves 86.7% in Franka and 98.5% on bimanual Kuka (more details could be found in Appendix G). We believe a more advanced vision pipeline or pre-trained model could potentially further improve the performance of SkillWrapper, which we will leave for future work."}}, "id": "8M48iJ3Y3C", "forum": "IDdUGp5EJU", "replyto": "IDdUGp5EJU", "signatures": ["ICLR.cc/2026/Conference/Submission15943/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15943/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15943/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763455348342, "cdate": 1763455348342, "tmdate": 1763498079894, "mdate": 1763498079894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a formal theory to characterize the necessary conditions for generative predicate invention, and present the SKILLWRAPPER framework, which leverages the capability of LLMs to perform operator learning and skill abstraction. Both simulation and real-world robot experiments are conducted to validate the framework."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper provides a theoretical proof of completeness for skill learning. Although I did not go through the detailed derivation, I believe this is likely one of the main innovations of the paper.\n\n2.The paper includes real-robot experiments, which convincingly demonstrate that the SKILLWRAPPER framework can be effectively deployed in real-world settings."}, "weaknesses": {"value": "1. In Table 1, the experimental results of SKILLWRAPPER do not consistently outperform expert-designed predicates and operators. This raises concerns about whether the proposed framework offers a real advantage over manually defined predicates and operators.\n2. The experimental section lacks sufficient task descriptions. It is difficult to understand how task difficulty is defined or differentiated. If such details exist, please indicate where they are presented.\n3. The authors only evaluate on the Robotouille simulated task. Why not conduct experiments on more well-known benchmarks such as IsaacGym (https://github.com/isaac-sim/IsaacGymEnvs), MetaWorld(https://github.com/Farama-Foundation/Metaworld)? Please explain the rationale behind this choice.\n4. The paper’s main contributions are not clearly highlighted. Both skill abstraction and predicate generation using LLMs are not entirely new techniques. The paper lacks comparisons with these baselines, and the overall presentation fails to make the core novelty of the work clear."}, "questions": {"value": "1. Why does ViLA not include the Planning Budget metric? Please provide a rough explanation.\n2. How are the conclusions derived from the formal theory used to guide the design of the SKILLWRAPPER framework?\n3. Has any ablation study been conducted—for example, how would removing active data collection affect the skill abstraction process? What would happen if expert-designed operators and SKILLWRAPPER-learned skills were combined?\n4. Other questions are mentioned in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "s6Z0OTzlBl", "forum": "IDdUGp5EJU", "replyto": "IDdUGp5EJU", "signatures": ["ICLR.cc/2026/Conference/Submission15943/Reviewer_FNJ2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15943/Reviewer_FNJ2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761734492178, "cdate": 1761734492178, "tmdate": 1762926155854, "mdate": 1762926155854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper discusses how to learn predicates and operators for given skills. It builds a system like VisualPredicctor that asks LLMs to propose and ground predicates and uses symbolic methods to evaluate and manage the proposed predicates and operators. It also asks LLMs, together with symbolic heuristics, to propose sequences of actions for exploration and data collection. The method is evaluated in several simulated and real-robot environments."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper shows that generative predicate invention works in real-robot settings. \n\nThe paper is generally well-written and easy to understand. \n\nThe LLM exploration heuristics are more interesting to me and deserve more space in the main paper, in my understanding. It would be great to study the exploration effectiveness given each combination of the heuristics in practice."}, "weaknesses": {"value": "* The theories are either trivial or missing important strong assumptions in the main context. For example, Theorem 2 relies on i.i.d. samples which is a strong assumption (never true in online-exploration or LLM-exploration settings in practice) and is **not** stated in Theorem 2. With i.i.d. samples, Theorem 2 is true for any method (such as VisualPredicator) that satisifies $\\hat Err(\\hat M_n) = 0$.\n* The predicate-invention method is very similar to VisualPredicator.\n* Missing baseline such as VisualPredicator"}, "questions": {"value": "* Are there results to compare with VisualPredicator? What's the difference and why? \n* Are there results analyzing the effectiveness of various exploration strategies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xR5Bqk5VWX", "forum": "IDdUGp5EJU", "replyto": "IDdUGp5EJU", "signatures": ["ICLR.cc/2026/Conference/Submission15943/Reviewer_2cbF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15943/Reviewer_2cbF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879036566, "cdate": 1761879036566, "tmdate": 1762926154358, "mdate": 1762926154358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SKILLWRAPPER, a framework for generative predicate invention that learns human-interpretable symbolic models of black-box skills for long-horizon planning from RGB images only. The method formalizes when and how to invent new predicates so that the resulting abstraction yields provably sound and (probabilistically) complete PDDL operators for planning. Practically, the system (i) actively gathers data by proposing skill sequences, (ii) invents predicates when failures/successes are indistinguishable under the current vocabulary, and (iii) learns operators via associative model learning with type hierarchies and periodic predicate re-evaluation (Algs. 1–2). Experiments in the Robotouille grid-world kitchen and on two real robot setups (Franka Panda; bimanual Kuka) show higher solve rates and lower planning budgets than VLM prompting and random exploration, and competitive performance against expert-authored operators; results include generalization to richer environments and handling “impossible” tasks. The novelty lies in a formal theory of predicate invention tailored to skill abstraction with guarantees, plus a concrete system that uses a foundation model both to propose predicates and to classify their truth values directly from images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Originality: Provides a formal theory for generative predicate invention specifically for skill abstraction, with explicit conditions tied to precondition/effect indistinguishability (Sec. 3.2), addressing a gap in prior ad-hoc predicate generation.\n2. Real-world evaluation: Includes two real-robot settings (Franka; bimanual Kuka), with generalization across object/skill subsets and learning curves that surpass baselines as predicates accumulate (Figs. 3–5, Table 2).\n3. Proves soundness of learned operators and probabilistic completeness relative to a finite hypothesis class (Theorems 1–2), linking learning criteria directly to planning guarantees (Sec. 3.4)."}, "weaknesses": {"value": "1. The approach assumes accurate truth-value predictions from a foundation model (Sec. 4.1), which might not always work in real world.\n2. Results are averaged over three runs, with no error bars or significance tests (Sec. 4). \n3. Real-robot sections assume deterministic skills and fully observable states (Sec. 4), which may not hold in cluttered, partially observable settings.\n4. Lack of compute budgets (GPU/CPU hours), inference costs for predicate evaluations (the cost of GPT-5)."}, "questions": {"value": "1. What is the per-predicate truth-value accuracy of the VLM classifier, and how does plan success degrade under controlled label noise?\n2. Can you report mean and std (or confidence intervals) over >= 5 seeds for Table 1 and Table 2?\n3. What are the compute budgets (GPU/CPU hours)? How much do you spend on GPT-5 for evaluation and predicate generation?\n4. Could you list some scenarios of failure as case studies?\n5. In the real-robot setups, how often did image viewpoint changes alter predicate truth judgements? Any mitigations (multi-view, temporal smoothing)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ThEbDIFlXY", "forum": "IDdUGp5EJU", "replyto": "IDdUGp5EJU", "signatures": ["ICLR.cc/2026/Conference/Submission15943/Reviewer_3RUj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15943/Reviewer_3RUj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931043719, "cdate": 1761931043719, "tmdate": 1762926153882, "mdate": 1762926153882, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}