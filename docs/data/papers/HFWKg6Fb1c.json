{"id": "HFWKg6Fb1c", "number": 9466, "cdate": 1758123516036, "mdate": 1759897720667, "content": {"title": "FastTracker: Real-Time and Accurate Visual Tracking", "abstract": "Conventional multi-object tracking (MOT) systems are predominantly designed\nfor pedestrian tracking and often exhibit limited generalization to other object\ncategories. This paper presents a generalized tracking framework capable of\nhandling multiple object types, with a particular emphasis on vehicle tracking in\ncomplex traffic scenes. The proposed method incorporates two key components: (i)\nan occlusion-aware re-identification mechanism that enhances identity preservation\nfor heavily occluded objects, and (ii) a road-structure-aware tracklet refinement\nstrategy that utilizes semantic scene priors—such as lane directions, crosswalks,\nand road boundaries—to improve trajectory continuity and accuracy. In addition,\nwe introduce a new benchmark dataset comprising diverse vehicle classes with\nframe-level tracking annotations, specifically curated to support evaluation of\nvehicle-focused tracking methods. Extensive experimental results demonstrate that\nthe proposed approach achieves robust performance on both the newly introduced\ndataset and several public benchmarks, highlighting its effectiveness in general-\npurpose object tracking. While our framework is designed for generalized multi-\nclass tracking, it also achieves strong performance on conventional pedestrian\nbenchmarks, with HOTA scores of 66.4 on MOT17 and 65.7 on MOT20 test sets.", "tldr": "We propose a generalized MOT framework with occlusion-aware ReID, road-structure-guided refinement, and a new vehicle-focused benchmark, achieving SOTA results on both multi-class and pedestrian tracking benchmarks.", "keywords": ["MOT", "Visual tracking"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/116d05a2a1f3381123a7210ae0254d67c3b09de9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes FastTracker, a lightweight, real-time multi-object tracking framework. Its core contributions include: occlusion handling without ReID via DampenVelocity and EnlargeBox，and trajectory regularization using environment priors defined by a direction cone and a quadrilateral ROI. In addition, the authors introduce FastTrack, an internal CCTV multi-class traffic benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1、Originality: Explicitly encode the scene prior with ProjectToCone to correct the prediction before association. Use center proximity for occlusion detection and stabilize trajectories with DampenVelocity and EnlargeBox.\n2、Quality: The method is well designed, the modules are interrelated, and the experimental pipeline is clear, with ablation and comparative experiments provided to demonstrate the framework’s performance.\n3、Clarity: The flowcharts, visual examples, and algorithmic steps are easy to follow, and the experimental results are comprehensive.\n4、Significance: By modularizing the various components, the paper provides a reusable, comparable baseline for subsequent Kalman-based trackers, and provides a dataset for complex scenarios that meaningfully advances engineering evaluation in MOT."}, "weaknesses": {"value": "1、The association backbone follows ByteTrack’s two-stage matching scheme; the method’s novelty lies primarily in the pre-association constraints and occlusion heuristics rather than in the association paradigm itself.\n2、Dependence on priors: The ROI/direction constraints must be predefined manually, and the ROI is restricted to a quadrilateral. This strong reliance on scene priors limits deployment and generalization.\n3、Implementation details: Although the paper states that a Kalman filter is used, it does not fully specify the motion model, including the definition of the state vector and the settings for process noise and measurement noise."}, "questions": {"value": "1、Will the FastTrack dataset be made publicly available? Please describe the privacy handling, data collection, and the compliance policies and procedures for external release.\n2、How robust is the method when scene priors are missing or mis-registered? Does performance degrade substantially in such cases?\n3、Please provide the complete mathematical specification of the NSA Kalman filter and the default parameter settings for categories such as pedestrians and bicycles."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "oiAvGZ0ZPs", "forum": "HFWKg6Fb1c", "replyto": "HFWKg6Fb1c", "signatures": ["ICLR.cc/2026/Conference/Submission9466/Reviewer_Rd4h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9466/Reviewer_Rd4h"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761531532271, "cdate": 1761531532271, "tmdate": 1762921056883, "mdate": 1762921056883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "FastTracker proposes a lightweight, general multi-object tracking (MOT) framework for vehicle-rich traffic scenes. Building on ByteTrack’s two-stage association, it replaces deep re-identification with motion and spatial cues. Two key modules are introduced: (1) an occlusion-aware re-ID using geometric coverage and velocity dampening for ID continuity, and (2) a road-structure-aware refinement leveraging manually defined ROIs and lane-direction constraints to enforce plausible trajectories. The authors also release the FastTrack dataset (9 classes, 12 scenes, 800K annotations) for vehicle-centric tracking. It achieves state-of-the-art results on MOT17 (HOTA 66.4), MOT20 (65.7), DanceTrack, and the new dataset, with notably fewer ID switches. Ablation studies show consistent gains from each module."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Comprehensive Experiments: The authors evaluate on a wide range of benchmarks (MOT16/17/20, DanceTrack, and FastTrack) with detailed ablation studies (Tables 2–5) verifying each module’s impact. The improvements in key metrics (MOTA, HOTA, IDF1) and especially the reduction in ID switches (e.g. lowest IDs on MOT17/20) are convincingly shown.\n\n- Strong Empirical Results: FastTracker achieves state-of-the-art or competitive performance on multiple datasets. For instance, it reaches HOTA 66.4 on MOT17 and 65.7 on MOT20 (test sets), and outperforms all baselines on DanceTrack (MOTA 93.4, HOTA 65.9). These results indicate a high practical impact.\n\n- New Benchmark Dataset: The introduction of the FastTrack dataset (800K frames, 9 classes, diverse traffic scenes) fills a notable gap. The paper provides dataset statistics and sample frames, and demonstrates that existing trackers perform significantly worse on it, highlighting its challenge. Making this dataset available would be a great resource for the community."}, "weaknesses": {"value": "- Manual ROI/Direction Constraints: A key limitation is the reliance on manually defined polygonal ROIs and fixed cone directions for scene priors. As acknowledged by the authors, this is labor-intensive and may not generalize to complex or evolving environments (e.g. intersections, roundabouts). The current system only supports quadrilateral regions, limiting flexibility. This reliance diminishes the novelty and practicality of the road-structure module.\n\n- Lack of Runtime Analysis: The claim of real-time operation is not quantitatively supported. The paper reports performance with lighter detectors but does not give actual frame rates or hardware details. It is unclear whether the occlusion and ROI modules introduce any latency, or how the system performs on typical edge devices.\n\n- Many parts of the system (velocity dampening factor, coverage thresholds, direction-angle limits) are hand-designed. While ablations show they work, it is not clear how sensitive the system is to these hyperparameters. In some cases, learned re-ID features might be more robust to varied conditions than the proposed heuristics."}, "questions": {"value": "- ROI/Direction Robustness: How sensitive is FastTracker to inaccuracies in the manually defined ROI or direction cones? If the annotated road boundaries are slightly off, does performance degrade significantly?\n\n- Automatic Priors: Do the authors plan to incorporate automatic scene understanding (e.g. segmentation of roads/lanes) to generate the ROI and direction constraints? Have any preliminary tests been done in this direction?\n\n- Runtime Performance: Can the authors provide empirical runtime measurements (e.g. frames per second) for FastTracker on a typical hardware setup, both with the heavy (YOLOX-L) and lightweight detectors (YOLOX-Nano)?\n\n- Failure Cases: Are there particular scenarios where FastTracker fails (e.g. very long occlusions, heavy clutter)? Can you provide qualitative examples of its limitations?\n\n- Dataset Release: Will the FastTrack benchmark and annotations be made publicly available, and under what license?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T6sfc5HnYV", "forum": "HFWKg6Fb1c", "replyto": "HFWKg6Fb1c", "signatures": ["ICLR.cc/2026/Conference/Submission9466/Reviewer_X9FY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9466/Reviewer_X9FY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761562387169, "cdate": 1761562387169, "tmdate": 1762921056589, "mdate": 1762921056589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FastTracker, a lightweight, motion-centric online MOT framework designed for multi-class tracking in complex urban scenes, with particular emphasis on vehicles. The method builds upon a two-stage association strategy (high- then low-confidence detections) and augments it with: (i) an occlusion-aware module that stabilizes track states without CNN-based ReID by damping velocity and enlarging boxes during occlusions, and (ii) environment-aware constraints based on road geometry and directional priors (ProjectToCone, ClampToROI). The authors also introduce a CCTV-based benchmark (FastTrack) with diverse traffic scenarios and claim state-of-the-art results on MOT16/17/20 and DanceTrack while remaining real-time and resource efficient."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear problem motivation: addresses generalization beyond pedestrian tracking and the need for multi-class vehicle-centric tracking under occlusions and complex layouts.\n2. Practical, lightweight design: avoids deep appearance models in the online pipeline; relies on motion, geometry, and simple heuristics that are attractive for real-time deployments.\n3. Environment-aware modeling: novel use of region semantics and directional constraints to limit drift and enforce plausible motion without heavy learning modules."}, "weaknesses": {"value": "1. Clarity and correctness of some definitions:\nThe “center-proximity score CP” is described as computed via IoU, which is conceptually inconsistent (center-proximity is not IoU). A precise definition is missing.\n2. Occlusion handling design details:\nMarking occlusion based on overlap with other active tracklets via a single threshold may conflate crowding with occlusion and induce false occlusion states.\n3. Dataset details and release:\nThe FastTrack dataset has only 12 videos (albeit very dense). More details are needed: annotation protocol, quality control, train/val/test splits, licensing, and release plan. Without public release, the dataset’s impact is limited."}, "questions": {"value": "1. Please precisely define CP(t, t′) and how occlusion is decided, including edge cases in crowded scenes. Is CP IoU, or a center-distance metric?\n2. How are occluded tracks re-associated upon reappearance if they are excluded from association? What gating, timing, and matching logic ensure ID continuity?\n3. Do you output predicted boxes during occlusion? If yes, how do enlarged boxes affect FP/FN and HOTA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "y3I4Pl6n4m", "forum": "HFWKg6Fb1c", "replyto": "HFWKg6Fb1c", "signatures": ["ICLR.cc/2026/Conference/Submission9466/Reviewer_xSDA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9466/Reviewer_xSDA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958207922, "cdate": 1761958207922, "tmdate": 1762921056301, "mdate": 1762921056301, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a new method for multi-object tracking. It focuses on vehicle tracking on complex traffic scenes. It proposes a mechanism to handle occlusions by moderating Kalman Filter and enlarging the candidate box. It also introduces a tracklet refinement strategy, which uses scene information to improve trajectory continuity and accuracy. A new traffic benchmark is collected as well. Experiments on public benchmarks and the new one demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of handing occlusion situations and utilizing scene information makes sense.\n2. The implementation of the occlusion handling and the scene prior constraints is reasonable.\n3. The collected dataset can be helpful for the community.\n4. The proposed method is effective on public benchmarks and the new one."}, "weaknesses": {"value": "1. Experiments on efficiency are lacking. The paper claims that the tracker is real-time, but related experiments, like running speed, computational burden, etc., are missing. These experiments are needed to support the claim.\n2. Methodology contribution is limited. This work focuses on the Kalman Filter-based data association process, and improves the process from multiple aspects. However, these improvements are more like engineering optimization, instead of methodology contribution from my view. It has practical value, but the methodology contribution is not enough."}, "questions": {"value": "How's the method's performance on BDD100k? BDD100k[1] is a popular MOT dataset with multiple classes on traffic scenes. It should be included for dataset and method comparison.\n\nRef.\n\n[1] Yu, Fisher, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashisht Madhavan, and Trevor Darrell. \"Bdd100k: A diverse driving dataset for heterogeneous multitask learning.\" CVPR 2020."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "blgPlJkBJM", "forum": "HFWKg6Fb1c", "replyto": "HFWKg6Fb1c", "signatures": ["ICLR.cc/2026/Conference/Submission9466/Reviewer_k4Wq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9466/Reviewer_k4Wq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965315265, "cdate": 1761965315265, "tmdate": 1762921056034, "mdate": 1762921056034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}