{"id": "qumy27hMDY", "number": 3272, "cdate": 1757390768924, "mdate": 1759898098532, "content": {"title": "MAS$^2$: Self-Generative, Self-Configuring, Self-Rectifying Multi-Agent Systems", "abstract": "The past two years have witnessed the meteoric rise of Large Language Model (LLM)-powered multi-agent systems (MAS), which harness collective intelligence and exhibit a remarkable trajectory toward self-evolution. This paradigm has rapidly progressed from manually engineered systems that require bespoke configuration of prompts, tools, roles, and communication protocols toward frameworks capable of automated orchestration. Yet, dominant automatic multi-agent systems, whether generated by external modules or a single LLM agent, largely adhere to a rigid \\textit{generate-once-and-deploy} paradigm, rendering the resulting systems brittle and ill-prepared for the dynamism and uncertainty of real-world environments.\nTo transcend this limitation, we introduce MAS$^2$, a paradigm predicated on the principle of recursive self-generation: a multi-agent system that autonomously architects bespoke multi-agent systems for diverse problems. Technically, we devise a ``\\textit{generator-implementer-rectifier}'' tri-agent team capable of dynamically composing and adaptively rectifying a target agent system in response to real-time task demands. Collaborative Tree Optimization is proposed to train and specialize these meta-agents. Extensive evaluation across seven benchmarks reveals that MAS$^2$ achieves performance gains of up to $19.6\\\\%$ over state-of-the-art MAS in complex scenarios such as deep research and code generation. Moreover, MAS$^2$ exhibits superior cross-backbone generalization, effectively leveraging previously unseen LLMs to yield improvements of up to $15.1\\\\%$. Crucially, these gains are attained without incurring excessive token costs, as MAS$^2$ consistently resides on the Pareto frontier of cost-performance trade-offs.", "tldr": "we introduce MAS$^2$, a paradigm predicated on the principle of recursive self-generation: a multi-agent system that autonomously architects bespoke multi-agent systems for diverse problems.", "keywords": ["Multi-Agent System", "LLM Agent"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c5ca13244db5c058058900d096921c49166e2fc5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes MAS², a \"recursive self-generative\" multi-agent paradigm built on a tri-agent architecture: a generator designs high-level workflow templates based on tasks, an implementer assigns specific LLM backbones to turn templates into executable systems, and a rectifier monitors real-time operations and dynamically rectifies configurations. The paper also introduces the Collaborative Tree Optimization (CTO) framework, which specializes meta-agents by collecting trajectory data via a collaborative decision tree, generating preference signals through path credit propagation, and optimizing policies via value-guided preference alignment. Experiments show the effectiveness of the proposed model."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The Collaborative Tree Optimization (CTO) framework addresses meta-agent training challenges (e.g., ambiguous rewards, low data efficiency) via collaborative decision trees, path credit propagation, and value-guided alignment. It attributes terminal feedback to upstream decisions and prioritizes high-impact preferences, enabling efficient specialization of each meta-agent.\n\n2. Experiments cover 8 benchmarks across 4 domains (multi-hop search, deep research, code generation, mathematical reasoning) and 13 baselines. \n\n3. The overall framework seems reasonable and effective."}, "weaknesses": {"value": "1. Rectifier Threshold Lacks Clear Justification: The rectifier’s trigger relies on a resource budget threshold θ_C (for excessive consumption), but the paper does not explain how θ_C is determined, whether it is set manually or adaptively. No sensitivity analysis is provided to show how θ_C adjustments affect system performance, leaving uncertainty about its practical flexibility.\n\n2. CTO Parameter Selection Lacks Optimization Proof: The CTO framework uses fixed parameters (e.g., 4 candidate templates for the generator, 2 instantiations for the implementer) in experiments. The paper fails to justify why these values are optimal or how changing them (e.g., more templates) might impact training efficiency or trajectory quality.\n\n3. Dynamic Interference Scenarios Are Undertested: While MAS² claims to handle real-world dynamism (e.g., tool crashes), experiments only use static benchmarks. No tests simulate dynamic disruptions (e.g., random tool failures during execution), making it hard to fully verify its robustness in actual unstable environments.\n\n4. The paper lacks key engineering insights for real-world use, such as the computational resources (GPU type, training time) needed for meta-agent training or the latency of generating executable MAS. These omissions hinder practical deployment planning for industrial users."}, "questions": {"value": "1. For the rectifier’s threshold θ_C, could you clarify whether it is set manually or adaptively, and provide sensitivity analysis on how θ_C adjustments affect system performance?\n\n2. Regarding the CTO framework’s fixed parameters (4 generator templates, 2 implementer instantiations), could you explain the rationale for these values and test results of other parameter combinations?\n\n3. Since experiments lack dynamic interference simulations, could you add tests (e.g., random tool failures) to verify MAS²’s robustness in unstable environments?\n\n4. For engineering deployment, could you provide details like meta-agent training resources  and executable MAS generation latency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LLvAky6ZwI", "forum": "qumy27hMDY", "replyto": "qumy27hMDY", "signatures": ["ICLR.cc/2026/Conference/Submission3272/Reviewer_3oGm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3272/Reviewer_3oGm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839193066, "cdate": 1761839193066, "tmdate": 1762916640756, "mdate": 1762916640756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MAS2, a new paradigm for automatic multi-agent system (MAS) construction powered by large language models (LLMs). Unlike prior methods that generate a system once and execute it statically, MAS2 enables a meta MAS to recursively generate, configure, and rectify MASs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel Recursive MAS Paradigm: The paper introduces MAS2, a self-generative, self-configuring, self-rectifying multi-agent paradigm, moving beyond the dominant “generate once and deploy” paradigm. This conceptual shift is original and timely for dynamic real-world settings.\n2. Agent Meta Architecture: The generator–implementer–rectifier division of labor provides clear modularity: generator → architectural workflow; implementer → LLM backbone assignment; rectifier → online adaptation\nThis creates specialization, interpretability, and controllability."}, "weaknesses": {"value": "1. In the Introduction, the authors claim that previous methods based on Bayesian optimization, GNNs, and MCTS suffer from the limitations of predefined search spaces and atomic operators. However, in Figure 2, the workflow template of MAS² also appears to be composed of similar atomic operators such as \"manager\", \"coder,\" and \"summarizer.\" This design seems structurally indistinguishable from earlier works, weakening the claimed motivation and novelty.\n2. The paper lacks crucial implementation details: How large is the dataset used to train the generator, implementer, and rectifier agents? Were any of the training tasks reused during evaluation, or are they strictly separated?\n3. On the BrowseComp+ benchmark, MAS² shows only a 3.6% improvement over the CoT baseline, does it suggests limited effectiveness when handling high-difficulty, complex reasoning tasks.\n4. Inconsistent Benchmark Reporting: The number of benchmarks is contradictory — abstract (7), §4.1 (8), and contribution summary (6), while Table 1 actually contains seven columns. This inconsistency undermines clarity of experimental coverage."}, "questions": {"value": "CTO calibration: How are Rₚ(τ) (success condition) and θ₍C₎ (cost threshold) determined? Are they fixed, learned, or task-adaptive? What is the effect of varying them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DcMpX0CtAC", "forum": "qumy27hMDY", "replyto": "qumy27hMDY", "signatures": ["ICLR.cc/2026/Conference/Submission3272/Reviewer_UFEM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3272/Reviewer_UFEM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967098472, "cdate": 1761967098472, "tmdate": 1762916640402, "mdate": 1762916640402, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MAS2, a novel multi-agent system (MAS) framework endowed with self-generation, self-configuration, and self-correction capabilities for dynamic construction and optimization of multi-agent systems to address complex and evolving task scenarios. MAS2 employs a recursive approach involving a team of agents—generators, executors, and correctors—to build multi-agent systems, thereby overcoming the rigidity of traditional \"generate-once-and-deploy\" paradigms. Additionally, it leverages collaborative tree optimization (CTO) to enhance the task adaptability and efficiency of meta-agents. MAS2 demonstrates exceptional generality and efficiency across multiple benchmark tasks, particularly in complex domains such as code generation, deep research, and mathematical reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1.The MAS2 paradigm introduces a novel approach to multi-agent systems through recursive self-generation and self-adaptation. The use of a generator-implementer-rectifier tri-agent architecture is a significant advancement over traditional \"generate-once-and-deploy\" frameworks, enabling dynamic and robust system design.\n2.The paper conducts extensive experiments across seven benchmarks, demonstrating MAS2's superior performance in diverse domains such as multi-hop search, deep research, code generation, and mathematical reasoning. The performance improvements (up to 23.8% over SOTA) and cost-efficiency analysis provide strong evidence for the practical utility of MAS2.\n3.MAS2 effectively integrates unseen large language models (LLMs) without additional fine-tuning, showcasing its flexibility and scalability. This feature is especially valuable for real-world applications where new models are frequently introduced."}, "weaknesses": {"value": "1. The tri-agent architecture and collaborative tree optimization (CTO) framework, while innovative, introduce significant complexity. The practical challenges of implementing and maintaining such a system, especially in resource-constrained settings, are not thoroughly addressed.\n2.Although the rectifier agent is designed to handle runtime errors, the paper provides limited quantitative analysis of how often and effectively the rectifier resolves failures."}, "questions": {"value": "1. While the paper demonstrates MAS2's effectiveness on academic benchmarks, it lacks real-world deployment or interaction scenarios. Is it possible to verify the effectiveness of the method in a real-world dynamic environment, or to provide some examples of real users using multi-agent systems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0F19RLsp6q", "forum": "qumy27hMDY", "replyto": "qumy27hMDY", "signatures": ["ICLR.cc/2026/Conference/Submission3272/Reviewer_Bhu1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3272/Reviewer_Bhu1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976567163, "cdate": 1761976567163, "tmdate": 1762916640009, "mdate": 1762916640009, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel paradigm for multi-agent systems (MAS) that enables recursive self-generation, automatic configuration, and real-time rectification to handle real-world uncertainties beyond traditional \"generate-once-and-deploy\" approaches.\n\nContributions include:\n\n- Shifts from the traditional \"generate-once-and-deploy\" paradigm to a dynamic process that generates and adjusts MAS configurations iteratively, enabling adaptation to real-world uncertainties.\n- Introduces a three-meta-agent architecture: Generator for creating high-level workflow templates, Implementer for assigning LLMs to roles, and Rectifier for real-time monitoring and fault correction.\n- Proposes the Collaborative Tree Optimization (CTO) framework, an offline reinforcement learning method using decision trees, reward propagation, and preference alignment to train and optimize the meta-agents for enhanced performance and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- A paradigm for dynamic and scalable MAS: A self-generative, adaptive multi-agent system that evolves iteratively is presented as an alternative to existing MAS frameworks, aiming to address their noted limitations in scalability and adaptability.\n\n- Generalization via CTO: The experimental results report that meta-agents optimized through the CTO framework exhibit generalization to unseen LLMs, with performance improvements of up to 15.1%, suggesting a degree of practical transferability.\n\n- A concise three-agent architecture: The system is built around a three-meta-agent design (Generator, Implementer, and Rectifier), which is characterized by its modularity and is proposed to be amenable to future extensions."}, "weaknesses": {"value": "Writing\n- In section 3.1 you defined $\\mathcal{T}$ as the set of available tools, but in section 3.2 $\\mathcal{T}$ means the trajectory set\n- To better assess the reward function design in Section 3.2, a more complete definition of $C(\\tau)$ (\"raw resource consumption\") would be beneficial, as the current article and its appendix lack the necessary details and examples.\n\nUnderstanding of the paper:\n\n- The lack of information regarding the training datasets undermines the evaluability of the reported benchmark results. I think it would be beneficial if the authors provide a detailed description of the source and composition of all problem datasets used in their training data.\n- In Table 2 of Section 4.3, the score of 68% achieved by Gemini 2.5 Pro on the MATH benchmark appears notably low. Given that the official Gemini reaches 21.6 on HLE and 88 on AIME [1], there is a discrepancy that requires clarification. Further details regarding the evaluation of Gemini 2.5 Pro need to be clarified. \n\n[1] https://deepmind.google/models/gemini/pro/"}, "questions": {"value": "- Section 3.2 notes that training the CTO requires efficient value function computation. I am concerned that the current approach to preference dataset construction may not be scalable. I suggest providing a more detailed explanation of the sampling strategy to clarify how computational overhead was managed, especially with an eye toward scaling the dataset size.\n- In section 3.2 equation 11, the role of \\delta V in adjusting the per-sample loss requires further clarification. It would be important to understand the theoretical motivation or mathematical derivation behind this design."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "W0zjCM5Je7", "forum": "qumy27hMDY", "replyto": "qumy27hMDY", "signatures": ["ICLR.cc/2026/Conference/Submission3272/Reviewer_u18B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3272/Reviewer_u18B"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3272/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978449770, "cdate": 1761978449770, "tmdate": 1762916639748, "mdate": 1762916639748, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}