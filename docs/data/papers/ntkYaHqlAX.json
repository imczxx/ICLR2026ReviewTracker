{"id": "ntkYaHqlAX", "number": 16125, "cdate": 1758260306769, "mdate": 1763622823767, "content": {"title": "Global Sharpness-Aware Minimization Is Suboptimal in Domain Generalization: Towards Individual Sharpness-Aware Minimization", "abstract": "Domain generalization (DG) aims to learn models that perform well on unseen target domains by training on multiple source domains.  \nSharpness-Aware Minimization (SAM), known for finding flat minima that improve generalization, has therefore been widely adopted in DG.  \nHowever, we argue that the prevailing approach of applying SAM to the aggregated loss for domain generalization is fundamentally suboptimal. This ``global sharpness'' objective can be deceptive, leading to convergence to fake flat minima where the total loss surface is flat, but the underlying individual domain landscapes remain sharp. To establish a more principled objective, we analyze a worst-case risk formulation that reflects the true nature of DG. Our analysis reveals that individual sharpness provides a valid upper bound on this risk, while global sharpness does not, making it a more theoretically grounded target for robust domain generalization. Motivated by this, we propose \\textit{Domain-wise Gradual SAM (DGSAM)}, which applies gradual, domain-wise perturbations to effectively control individual sharpness in a computationally efficient manner. Extensive experiments demonstrate that DGSAM not only improves average accuracy but also reduces performance variance across domains, while incurring less computational overhead than SAM.", "tldr": "While SAM seeks flat minima for domain generalization, it may converge to fake flat minima by ignoring sharpness in individual domains. To address this, we propose DGSAM, a gradual and efficient domain-wise sharpness minimization method.", "keywords": ["Domain generalization", "domain shift", "sharpness-aware minimization"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/17e062728ae2c819d857f329b3efa3bc70b1901c.pdf", "supplementary_material": "/attachment/016bc8fda2260b54d5da4c1b9bb0ea78ac48a92d.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents an idea of using individualized SAM to mitigate the domain generalization problem. Authors call the previous SAM approach to be \"global\", which I am uncomfortable because SAM is originally an idea of local flat minima (having said that I understand the authors claim and I concur that \"aggregated\" loss can be deceiving flat minima). They make an individualaity to represent a certain domain. Then, they present a method named DGSAM to control the individual sharpness. Experiments support the claim well."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Very nice problem discovery of the aggregated loss from the SAM perspective.\n2. Good principled approach to define the domain generalization and its relation toward the individual sharpness\n3. Necessary proofs are all provided. The defined individual sharpness will reduce the domain generalization errors. Stationary aspect, and its derived optimization approach path. \n\nClassic problem definition and solving it."}, "weaknesses": {"value": "1.\nI am very uncomfortable with the terminology that they defined or used.\nAs I mentioned earlier in the summary, all SAM approaches assume the parameters will be favored if they are located at the flat minima. However, this flat minima in the parameter space is always epsilon small, so SAM is always localized approach to a certain extent controlled by the epsilon. If authors agree with this aspect, then they would agree calling \"global sharpness\" is in its contradiction. What they are really pointing out is \"the aggregated flat-minima loss surface over the parameter space\". I would rather use \"aggregation\" instead of using a word \"global\".\n\n2.\n\"Decreased-overhead\" is your methodology name. I partially agree that the computational requirement could be reduced in the line of SAM researches. Having said that, I don't think that the overhead decrement would be your key contribution throughout the paper. Your key contribution is treating the \"domain-specific\" parameter space perturbation before \"domain-aggregation\" (yes. I don't like your wording 'individual' either), whereas the previous approaches have been \"domain-aggregated\" parameter space perturbation. Does this reversed process reduce the overhead? Could be. Is it the main-theme? No."}, "questions": {"value": "I don't have much question on this paper. I think that I understand enough to see the merit of this paper. I would like to get answers from my weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "pure methodology. no ethics needed"}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "EBWMg6ikcf", "forum": "ntkYaHqlAX", "replyto": "ntkYaHqlAX", "signatures": ["ICLR.cc/2026/Conference/Submission16125/Reviewer_E45h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16125/Reviewer_E45h"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760572529784, "cdate": 1760572529784, "tmdate": 1762926297015, "mdate": 1762926297015, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work examines how Sharpness-Aware Minimization (SAM) should be applied in the context of domain generalization (DG), and it challenges the conventional “global” use of SAM on aggregated training loss. The authors point out that simply finding a flat minimum for the average loss over all source domains can be misleading: it may produce a “fake flat” solution that appears robust overall but still has sharp (high-curvature) loss landscapes on individual domains, leaving the model vulnerable to domain-specific shifts.\n\nTo address this, they analyze a worst-case (adversarial) risk formulation for DG and show theoretically that minimizing individual-domain sharpness provides an upper bound on this worst-case risk, whereas minimizing global sharpness does not. In other words, each source domain’s loss landscape needs to be flat for true robustness, not just the combined loss. \n\nBuilding on this insight, the paper proposes DGSAM (Decreased-overhead Gradual SAM), which explicitly targets sharpness on a per-domain basis while keeping computational cost manageable."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Empirical results on five standard DG benchmarks show that DGSAM achieves better overall accuracy and significantly lower performance variance across domains compared to both standard training and globally-applied SAM. \n\nModels trained with DGSAM are consistently more robust to unseen target domains, indicating that the individual sharpness objective indeed translates to improved domain generalization. \n\nMoreover, DGSAM is shown to be computationally efficient – it incurs less overhead than traditional SAM (which doubles the compute) – and scales to large architectures like Vision Transformers. \n\nThe paper’s contribution is notable in reframing SAM for multi-domain settings and providing both a theoretical justification and a practical algorithm that improves robustness."}, "weaknesses": {"value": "DGSAM adds algorithmic complexity by requiring domain-specific updates (which could scale in cost with the number of domains), but the authors claim that they mitigate this with their gradual update scheme. Would this also fit with the case when the number of domains get really high (about 100 ~ )?\n\nIt would be beneficial to discuss more about related SAM works.\n- https://arxiv.org/abs/2410.14802 : Discussion about data-responsive regularization, and why still per-domain sharpness is required?\n- https://arxiv.org/abs/2403.07329 : How DGSAM differs from UDIM, when UDIM tries to generalize toward unseen domain?\n\nI also want authors to measure \"the zeroth-order sharpness result at converged minima\" not only compared to original SAM, and other algorithms. To more precisely compare the impact of sharpness.\n\nI think that this method is somewhat incremental from existing methods, because there were heavy-amount of SAM variants for domain generalization. But, if questions above are treated well, i will change my score."}, "questions": {"value": "DIscussed in weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WRIE6DTWQ7", "forum": "ntkYaHqlAX", "replyto": "ntkYaHqlAX", "signatures": ["ICLR.cc/2026/Conference/Submission16125/Reviewer_QcVt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16125/Reviewer_QcVt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635308181, "cdate": 1761635308181, "tmdate": 1762926296340, "mdate": 1762926296340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper argues that the common practice of applying SAm to the global loss across source domains (in the context of DG) is suboptimal, i.e., it can lead models toward fake flat minima that remain sharp on individual domains. The authors introduce an average worst-case risk formulation and prove that individual sharpness per-domain yields a valid upper bound to this risk, whereas global sharpness does not. In response, the authors propose DGSAM, a gradual, domain-wise perturbation method that controls individual sharpness with lower cost than SAM and improves both average acc. and cross-domain variance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Thank you for your submission, I enjoyed reading the paper and the fresh ideas on generalization from the loss landscape perspective. Below I have listed some aspects of the paper I've appreciated. \n\n- The paper points a conceptual flaw in how SAM has been ported to DG: \"optimizing flatness of all the domains combined is not the same as ensuring generalization for each domains shift\". From that perspective, the authors' idea that \"individual domain sharpness is the right surrogate for DG\" is sound and convincing.\n- The proposed algorithm DGSAM aligns well with the problem formulation, and its effectiveness is supported through multiple empirical gains over a number of standard DG benchmarks. Also, the gradient re-use is notable, its efficiency was shown empirically (Sec. 5.4).  \n- From my understanding, this paper is an extension of previous works in two key ways: (1) The authors suggest that minimizing the average of per‑domain sharpness provides a valid upper bound, while minimizing the global (aggregated) sharpness does not guarantee flat minima, and thus in improving generaliztion. Prior works do not explicitly mention the issue of fake flat minima. (2) It proposes a sequential, domain‑wise perturbation scheme that reuses gradients, so each domain’s loss surface is explicitly flattened.\n- Overall, the paper was easy to read and the message was clear. The theoretical analysis was also sound (Sec.3) and in accordance with the previous literature."}, "weaknesses": {"value": "- Positioning: While the paper aims to address an important, yet often overlooked issue in applying SAM to DG (or approaching generalization from the loss landscape perspective), it is still close to previous works (SAGM, ISAM, DISAM) that are aware of the issues in the naive application of SAM. Each of these works modifies the SAM objective to address specific deficiencies (e.g., inaccurate sharpness measures and gradient conflicts -- ISAM, inconsistent convergence across domains -- DISAM). Although they are cited and included among baselines, the paper would largely benefit from a sharper positioning. \n    - For instance, the idea that 'global sharpness' and 'per-domain sharpness' may not align was previously observed in Le et al. (2024). Although the paper was cited in line 484, we believe that their observation should be further noted as it aligns with the core idea of the paper. Similarly, the global vs. local sharpness/flatness idea was also studied in the federated learning literature [1].\n\n- Cost Measure: A minor one, but in the paper, per-iteration gradient counts are reported (Sec 5.4), but end-to-end wall-clock, FLOPs, and peak memory comparisons are missing. Could the authors provide this? Again, this is a minor suggestion.\n\n- Statistical Stability: Also a minor one, but in the camera-ready version, we suggest the authors to provide the average performance and standard error across more than 3 runs.\n\n- Sharpness: In Sec 5.3 (and Tab. 3), the zeroth-order sharpness is measured to show that DGSAM can effectively reach flat minima. To my understanding, the zeroth-order sharpness refers to the maximal loss within the perturbed neighborhood. While they are a useful objective, they are still limited proxies that have distinct limitations [2,3]. In the generalization literature, different metrics are also commonly used (e.g., the largest eigenvalue of the Hessian), owing to their theoretical implications. \n    - In response, I believe that the authors should supplement their analysis with additional diagnostics. e.g., reporting the maximum Hessian eigenvalue or trace per domain (or at least proxies such as top‑eigenvalue estimates) would provide stronger evidence that the method genuinely finds flatter minima.\n\n***\n### Reference\n\n[1] Caldarola et al., Beyond Local Sharpness: Communication-Efficient Global Sharpness-aware Minimization for Federated Learning, CVPR, 2025.\n\n[2] Zhuang et al., Surrogate gap minimization improves sharpness-aware training, ICLR, 2022.\n\n[3] Bian et al., Make Continual Learning Stronger via C-Flat, NeurIPS, 2024."}, "questions": {"value": "- Expansion: One small question is whether the method can also be applied to single-source settings (Single-source Domain Generalization). My guess is that it wouldn't work (simply out of scope!) and would collapse to SAM, unless there are simulated (commonly augmented) domains. I acknowledge that the paper focuses on multi-domain settings, and this question is purely out of curiosity.\n\n- Ablation Study: I'm interested in several components of the method and their effect on the performance gains. For instance, (1) what happens if the domain order is fixed, instead of being random (Line 3 in Algorithm 1)? (2) re-using vs. not re-using the ascent gradients. \n\nPlease refer to the Weaknesses section for the questions. I'm mostly interested in the Sharpness measure and the Ablation study."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "82sInz4rns", "forum": "ntkYaHqlAX", "replyto": "ntkYaHqlAX", "signatures": ["ICLR.cc/2026/Conference/Submission16125/Reviewer_JpK6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16125/Reviewer_JpK6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762408973002, "cdate": 1762408973002, "tmdate": 1762926295921, "mdate": 1762926295921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}