{"id": "s7q4Sh7PPo", "number": 523, "cdate": 1756744021252, "mdate": 1759898255895, "content": {"title": "CLiMRS: Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System", "abstract": "Cooperative multi-robot tasks often require heterogeneous agents to collaborate over long horizons while managing spatial constraints and execution uncertainties.\nAlthough large language models (LLMs) excel at reasoning and planning, their potential for coordinated control in heterogeneous multi-robot teams has not been fully explored.\nWe present CLiMRS, a human-team-inspired adaptive negotiation paradigm that pairs each robot with an independent LLM agent and forms dynamic sub-groups for perception-driven discussions and cooperative planning under long-horizon uncertainty.\nWithin each group, local oracle planners lead parallel discussions to synchronize actions, while agents provide feedback to refine plans. This grouping–planning–feedback–execution loop enables efficient long-horizon planning and robust execution.\nTo evaluate these capabilities, we introduce CLiMBench, a heterogeneous multi-robot benchmark of challenging assembly tasks with diverse robot types and skill libraries.\nAcross both CLiMBench and a simpler benchmark, CLiMRS surpasses the best baseline, boosting success rates and improving efficiency by over 40% on complex tasks while maintaining very high success on simpler tasks.\nOur results demonstrate that leveraging human-inspired group formation and negotiation principles markedly enhances the\nefficiency of heterogeneous multi-robot collaboration.", "tldr": "", "keywords": ["Heterogenous Robot Collaboration", "Multi-LLM Planning", "Robot Assembly"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6a7c50cf37459947832aa734e257a6180c6b8fee.pdf", "supplementary_material": "/attachment/8d557b61714365fb6eec4424d0b18582588551e7.zip"}, "replies": [{"content": {"summary": {"value": "This work presents CLiMRS, a framework for leveraging large language models (LLMs) for heterogeneous multi-robot collaboration tasks. A  major distinction between this and prior method in the same domain is using an adaptive negotiation framework, where different robots are dynamically formed into subgroups during task execution, and the grouping can be changed throughout a task. \n\nFor evaluation, the authors use both a simpler prior benchmark and introduce a new multi-robot benchmark, CLiMBench, which contains assembly tasks with multiple robot types and skill libraries. Empirically, CLiMRS significantly outperforms baseline methods and enhances the efficiency of heterogeneous multi-robot collaboration especially on complex tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed dynamic grouping formulation offers several advantages in multi-robot coordination, i.e. reducing communication overhead while enabling concurrent discussions, plan refinement, and parallel action execution. \n\n2. The CLiMBench task environments show good simulation support for various robot types and skill primitives. \n\n3. Experiment results show clear performance over basement methods."}, "weaknesses": {"value": "1. Lack of qualitative results. Visualizations for the CLiMBench tasks are limited in both the main paper and the appendix pdf file. The empirical results would have been much more convincing if the authors showed task videos of the robots completing the tasks with the reported success rates. \n\n2. Lack of considerations for real world robot deployments. Although the authors dedicated efforts into building diverse simulation tasks environments, it's difficult to access the applicability of the proposed framework to real world robot systems without real world results or a extensive discussion section on additional challenges for real world transfer. The authors claim the simulation tasks to represent 'real-world scenarios', but beyond the basic task definition, the simulation tasks do not properly reflect real world deployment requirements. A major challenge in real world would have been occlusion, i.e. as the AGV robots moving in a task space big as the proposed CLiMBench scenarios, the robots would not have been able to easily get the location and statuses of each other as in simulation where oracle simulation state information can be easily acquired. \n\n3. Presentation quality. Sections 4 and 5 randomly switches between high-level task descriptions and low-level implementation details, which obstructs the readability of the manuscript. For example, in Line 358, mentioning the Franka robot task space controller would have been sufficient for the main text, but the authors added \"uses the task-space inertia matrix and gravity compensation to compute joint torques, yielding a spring–damper response\"."}, "questions": {"value": "1. In Table 1, what is this Franka skill really doing and how is it implemented in simulation? \"[check] <franka>check <right wheel>\"\n\n2. How is RRT path planning done with multiple AGV robots moving at once? Do all the mobile cars move together?\n\n3. What exactly is in the observation space for the Franka and AGV robots? The paper only mentioned observation parameters for the humanoid."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ym9eM58sfT", "forum": "s7q4Sh7PPo", "replyto": "s7q4Sh7PPo", "signatures": ["ICLR.cc/2026/Conference/Submission523/Reviewer_62Hf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission523/Reviewer_62Hf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761675575954, "cdate": 1761675575954, "tmdate": 1762915537892, "mdate": 1762915537892, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CLiMRS, a LLM–driven framework for heterogeneous multi-robot collaboration. Each robot is paired with an LLM agent, and the system organizes robots into dynamic subgroups for joint planning via a grouping–planning–feedback–execution loop inspired by human teamwork.\n\nThe authors also propose CLiMBench, a new benchmark built in IsaacGym for evaluating heterogeneous robot collaboration in realistic physics-based settings. Experiments show that CLiMRS improves task success and efficiency by over 40% compared to baselines such as COHERENT and CMRS, and achieves 100% success in benchmark tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Novel Framework: Innovative use of dynamic subgrouping and negotiation principles inspired by human teamwork.\nBenchmark Contribution: CLiMBench provides a realistic and valuable testbed for heterogeneous multi-robot systems.\nStrong Experimental Results: Clear, consistent quantitative improvements across tasks; ablations validate each module’s contribution.\nClarity and Presentation: Well-organized writing, clear figures."}, "weaknesses": {"value": "I am worried about novelty. Many previous works have discussed about the framework of LLM for multiple robot collaboration, and also the heterogeneous condition. The centralized planner + local planning and feedback have been proposed by many studies before.\n\nThe studied multiple robot condition and task is not difficult in the task planning level. The robot number is not large. Whether this framework can be scalable to robot number over 10 or 20 is not clear.\n\nHow to do the motion planning is not explained, by pre-defined rules? Then how to handle the cases with different motion planning difficulty such as the obstacles and objects."}, "questions": {"value": "The current appendix is not in the same file as main article.\n\nRobots handle different tasks with different execution time. Step by step planning and sync may not be effective enough. How to consider the case with asynchronous communication?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J5Pm4OQ9vJ", "forum": "s7q4Sh7PPo", "replyto": "s7q4Sh7PPo", "signatures": ["ICLR.cc/2026/Conference/Submission523/Reviewer_Jq68"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission523/Reviewer_Jq68"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926098468, "cdate": 1761926098468, "tmdate": 1762915537784, "mdate": 1762915537784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents CLIMRS (Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System), a novel framework for multi-robot collaboration designed to manage complex, long-horizon tasks for heterogeneous teams under uncertainty. The core of the proposed architecture is a \"grouping-planning-feedback-execution\" loop, which is inspired by human teamwork principles. In this system, a high-level \"General Proposal Planner\" dynamically forms agent sub-groups, which are then managed by parallel \"Local Oracle Planners\" that generate specific commands.\n\nTo evaluate this system, the authors also introduce CLIMBench, a new simulation benchmark built in IsaacGym. This benchmark is designed to test multi-agent assembly tasks and, notably, models realistic physics and skill execution failures, which the authors contrast against other benchmarks that assume perfect skill execution. The experimental results show that CLIMRS achieves a 100% success rate on CLIMBench, significantly outperforming baselines like COHERENT (70%) and other decentralized and centralized methods (0%)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a significant and challenging problem at the intersection of large language models and multi-robot systems, specifically focusing on heterogeneous agent collaboration. The core architectural idea of a human-inspired, dynamic grouping and negotiation framework  is a novel contribution to the field of multi-agent LLM-based planning.\n\n2. A significant strength is the introduction of the CLIMBench benchmark. The authors correctly identify a limitation in existing work, such as the COHERENT benchmark , which assumes perfect skill execution. By building CLIMBench in a realistic physics simulator (IsaacGym) and explicitly modeling execution failures, the authors contribute a potentially valuable testbed for evaluating the robustness of planning frameworks, a critical aspect of real-world robotics.\n\n3. The proposed CLIMRS framework is presented clearly, with its modular components and the information flow of the \"grouping-planning-feedback-execution\" loop well-articulated  (e.g., in Figure 2)."}, "weaknesses": {"value": "1. The paper's primary claim of a \">40% efficiency\" improvement  rests on an insufficient metric. This gain is measured only by the \"Average Step (AS)\" count. This metric fails to capture the computational cost and, more importantly, the inference latency of the system. The proposed framework involves a sequential hierarchy of multiple LLM calls (General Planner, Local Planners, Agent Executors) within each loop. In any practical robotic application, wall-clock time is a dominant, if not the most critical, measure of efficiency. As the authors acknowledge in their limitations section, \"inference latency and computational cost of the LLMs [are] outside the present scope\". Without an analysis of wall-clock time, the claim of improved efficiency is unsubstantiated, as a lower step count could easily be offset by significantly longer per-step planning time.\n\n2. A significant ambiguity in the methodology lies in the \"Local Oracle Planner\". In robotics and machine learning, the term \"oracle\" typically implies access to privileged, ground-truth information (e.g., perfect global state, simulator-internal data) not available to a deployed agent. The paper never defines what \"oracle\" signifies in this context. If these planners possess such privileged information, it would (a) contradict the paper's positioning of operating under \"spatial constraints and execution uncertainties\"  and (b) constitute an unfair advantage over the baseline methods, which would compromise the validity of the experimental comparison.\n\n3. The feedback mechanism described in Section 3.3 appears to rely on unrealistically strong assumptions. The \"Agent Executor\" LLM is tasked with categorizing failures at a high level of causal abstraction, such as \"(1) improper grouping\" or \"(2) incorrect agent selection\". It is unclear how a local agent executor, whose scope is to verify and execute a specific command, could possess the global context necessary to deduce such a high-level, systemic reason for failure. This feedback provides an information-rich, structured signal that directly guides the high-level planner. If the baseline methods do not have access to a comparable feedback signal, this represents a significant confounding variable that, much like a potential oracle, could explain the performance gap.\n\n4. The authors propose both the method and the primary benchmark (CLIMBench) used for evaluation. The results on CLIMBench (Table 4) show a stark disparity: CLIMRS achieves a 100% success rate, while the DMRS and CMRS baselines score 0%. This result suggests the benchmark's challenges may be specifically tailored to the dynamic grouping architecture of CLIMRS. On this benchmark, the performance gap is negligible: CLIMRS and the COHERENT baseline both achieve an identical 97.5% average success rate. The fact that CLIMRS’s overwhelming superiority vanishes on a benchmark not designed by the authors is a questionable observation."}, "questions": {"value": "1. Could the authors provide wall-clock time comparisons for task completion, in addition to \"Average Step\"? This would account for the cumulative LLM inference latency of the CLIMRS framework versus the baselines\n\n2. Can the authors please provide a precise definition of the \"Local Oracle Planner\"?\n\n3. How does a local \"Agent Executor\" LLM obtain the necessary global context to provide high-level causal feedback like \"improper grouping\"? Is this information provided to the agent, or is it expected to infer it? How does this compare to the feedback available to the baseline methods?\n\n4. How do the authors explain the performance discrepancy between CLIMBench and the COHERENT benchmark? Why do the DMRS and CMRS baselines, which are established architectures, fail with 0% success on CLIMBench while performing reasonably on COHERENT?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PHSriVNZsy", "forum": "s7q4Sh7PPo", "replyto": "s7q4Sh7PPo", "signatures": ["ICLR.cc/2026/Conference/Submission523/Reviewer_m3z7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission523/Reviewer_m3z7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957199330, "cdate": 1761957199330, "tmdate": 1762915537665, "mdate": 1762915537665, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}