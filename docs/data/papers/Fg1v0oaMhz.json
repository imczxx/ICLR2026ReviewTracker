{"id": "Fg1v0oaMhz", "number": 7670, "cdate": 1758031292443, "mdate": 1762930846458, "content": {"title": "CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks", "abstract": "Personalized federated learning (PFL) aims to collaboratively train personalized models for multiple clients with heterogeneous and scarce local samples.\nHowever, the substantial heterogeneity in sample distributions across clients undermines the effectiveness of vanilla federated learning where a consensus model is trained and shared among clients.\nMore specifically, vanilla federated learning aggregates local models via heuristic or data-volume-based weighted averaging without considering the actual contribution per client's update, which often induces suboptimal personalization performance on heterogeneous client data.\nTo improve the personalization performance, we propose a contribution-oriented PFL (CO-PFL) algorithm that jointly assesses gradient direction discrepancies and prediction deviations across client updates.\nIn the proposed CO-PFL algorithm, we leverage information from both the gradient and data subspaces to estimate the contribution per client (i.e., the aggregation weight) for global aggregation.\nTo further enhance personalization adaptability and optimization stability, our proposed CO-PFL algorithm cohesively integrates the parameter-wise personalization mechanism with the mask-aware momentum optimization. \nThe proposed CO-PFL algorithm mitigates aggregation bias, enhances global coordination and local personalization performance, and facilitates tailored submodels construction alongside stable model updates.\nExtensive experiments on four practical datasets (e.g., CIFAR10, CIFAR10C, CINIC10, and M-ImageNet) demonstrate that the proposed CO-PFL consistently outperforms state-of-the-art benchmarks.", "tldr": "", "keywords": ["Personalized federated learning", "data heterogenity"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8dcbbedee62c43c32b4c38cc8230fabd9ef7d9de.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces **CO-PFL (Contribution-Oriented Personalized Federated Learning)**, an algorithm that enhances personalization in federated learning by weighting client updates and adaptively selecting personalized parameters. It integrates three key modules: **COWA (Contribution-Oriented Weighted Aggregation)**, which assigns aggregation weights based on gradient discrepancy and prediction deviation to capture each client’s contribution; **PWPM (Parameter-Wise Personalization Module)**, which performs parameter-wise personalization by dynamically identifying and retaining client-specific parameters under a capacity budget; and **MAMO (Mask-Aware Momentum Module)**, which keeps separate momentum tracks for shared and personalized parameters to ensure stable convergence. Experiments on CIFAR-10, CIFAR-10C, CINIC-10, and M-ImageNet demonstrate that CO-PFL consistently outperforms existing personalized FL methods, showing higher accuracy, smoother convergence, and robustness across heterogeneous data distributions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**1) Clear and well-structured presentation:**\nThe paper is clearly written, with a logical decomposition of ideas across the three modules. Each module addresses a distinct challenge in personalized federated learning—aggregation bias, over/under-personalization, and unstable optimization due to masking. The overall workflow and pseudocode are easy to follow, and the explanations are intuitive.\n\n**2) Strong empirical results:**\nThe method shows consistent performance gains across multiple datasets with varying degrees of heterogeneity. The experiments include a solid set of baselines, along with ablation and convergence studies, which together provide convincing empirical support for the proposed approach.\n\n**3) Novel and intuitive aggregation mechanism:**\nThe idea behind the COWA module is both novel and meaningful for PFL. By moving beyond uniform or heuristic aggregation and introducing a contribution-based weighting scheme, it represents a clear conceptual advancement. That said, I have raised some related questions and concerns in the later sections of my review."}, "weaknesses": {"value": "**1) Clarification on the COWA computation:** It is not entirely clear where the computation of the COWA module, particularly the prediction score $\\Gamma_n^{\\mathrm{data}}$, is performed. Calculating this score requires access to the leave-one-out aggregated model $w_{-n}^k$, which itself depends on $\\alpha_n^k$. However, $\\alpha_n^{k+1}$ is computed on the *server side* using the contribution scores of all clients, as described in Algorithm 1. This creates uncertainty about the flow of information between the server and clients. It is unclear how $w_{-n}^k$ becomes available to each client if $\\alpha_n^k$ is determined centrally. If the server computes $w_{-n}^k$ in order to evaluate the prediction score, it would need access to client $n$’s data, which would violate the privacy guarantees of federated learning. Conversely, if each client computes this score locally, the server would need to send $w_{-n}^k$ or all other clients’ updates in every round, which would be communication intensive and could leak information about other clients. The paper does not currently clarify how this step is implemented in a privacy-preserving or communication-efficient manner, and providing such details would improve the reproducibility and practicality of the proposed approach.\n\n**2) Computational and communication overhead:**\nThe proposed method introduces additional computation during the contribution scoring and masking steps. The paper does not provide a quantitative analysis of this overhead, such as the extra cost of computing the prediction-based contribution score or transmitting additional information. A clear runtime and communication comparison with standard baselines would make the method’s practicality easier to assess.\n\n**3) Lack of theoretical convergence analysis:**\nWhile the empirical results are strong, the paper would benefit from at least a brief convergence guarantee or theoretical discussion. Given the use of dynamic masks and weighted aggregation, even a simplified analysis under standard smoothness assumptions would add significant value and help justify the method’s stability.\n\n**4) Redundancy in figures and tables:**\nSome results appear to be duplicated, such as Figures 2 and 4 and Tables 1 and 3, which present identical findings. Removing redundancy would improve clarity and presentation.\n\n**5) Reproducability Concern:** At the time of review, the provided anonymous repository link was accessible; however, the uploaded archive (`CO-PFL.tar.gz`) appears to contain the codebase of a different paper (specifically, FedSelect) rather than the implementation of CO-PFL. This seems likely to be a simple mistake or a placeholder upload, but as it stands, it limits the reproducibility of the work. I encourage the authors to double-check the uploaded files and ensure that the correct CO-PFL implementation is included.\n\n**6) Suggestions for improving the experimental evaluation:**\nThe experimental section could be further strengthened by exploring richer regimes, such as settings with larger per-client data sizes or non-vision tasks like text and tabular datasets. This would help demonstrate the broader applicability and robustness of CO-PFL beyond the current benchmarks. In addition, reporting standard deviations alongside mean accuracies would provide a clearer picture of the variability across runs and improve the statistical reliability of the results."}, "questions": {"value": "**1) Clarification on computation and privacy:**\nCould you please clarify where the COWA computation, particularly the prediction score $\\Gamma_n^{\\mathrm{data}}$, is performed (client or server side)? It would be helpful to discuss how this design affects privacy and potential communication overhead in practice.\n\n**2) Inconsistency in momentum equations:**\nIn Eq. (4), both the first- and second-moment updates use $\\beta_1$, while the bias-correction in Eq. (5) divides by $(1 - \\beta_1^t)$ and $(1 - \\beta_2^t)$. This appears inconsistent, as $\\beta_2$ should likely be used in the second-moment recursion. Could the authors please confirm and specify the intended default parameter values?"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}, "details_of_ethics_concerns": {"value": "At the time of review, the provided anonymous repository link was accessible; however, the uploaded archive (`CO-PFL.tar.gz`) appears to contain the codebase of a different paper (specifically, FedSelect: Personalized Federated Learning with Customized Selection of Parameters for Fine-Tuning (Tamirisa et al., CVPR 2024)) rather than the implementation of CO-PFL. For reference, here is the corresponding FedSelect repository: https://github.com/lapisrocks/fedselect. \n\nThe uploaded archive even includes the same README file as the FedSelect project. While FedSelect is listed as one of the experimental benchmarks in the paper (see Fig. 2), it is not the sole baseline. Therefore, this might be an accidental or placeholder upload, but as it stands, it limits the reproducibility of the work."}}, "id": "HAC27gp2i5", "forum": "Fg1v0oaMhz", "replyto": "Fg1v0oaMhz", "signatures": ["ICLR.cc/2026/Conference/Submission7670/Reviewer_2dvG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7670/Reviewer_2dvG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760820975938, "cdate": 1760820975938, "tmdate": 1762919736627, "mdate": 1762919736627, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "hXIVCoVkDo", "forum": "Fg1v0oaMhz", "replyto": "Fg1v0oaMhz", "signatures": ["ICLR.cc/2026/Conference/Submission7670/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7670/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762929946015, "cdate": 1762929946015, "tmdate": 1762929946015, "mdate": 1762929946015, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CO-PFL, a three-part framework—COWA, PWPM, and MAMO—to address heterogeneity in federated learning. Experiments suggest the approach is effective."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Each component is intuitively reasonable.\n* The empirical results indicate that every module contributes positively."}, "weaknesses": {"value": "1. Overstated novelty on contribution-aware aggregation.   Line 114 claims that “most existing methods fall short in effectively quantifying and incorporating the value of each client’s contribution during aggregation.” However, prior work has already studied contribution/weight learning (e.g., AFL [1], **Shapley-driven weighting*[2]). The paper neither compares with nor discusses these lines sufficiently.\n\n2. PWPM and MAMO appear closely related to prior masked/sparse personalization and mask-aware optimization.\n   Modules similar in spirit have been explored (e.g., sparse/masked personalization [3], federated dynamic sparse training [4]). At present, the paper reads like a combination of known components. Please highlight the unique contribution of each module and explain why/how your design outperforms these prior approaches.\n\n3. Inconsistency in the MAMO optimizer equations.   In MAMO, the second-moment update in Eq. (4b) uses β₁ instead of β₂, while Eq. (5a) applies β₂ for bias correction—this is self-contradictory and should be corrected.\n\n4. Presentation issues.   For example, line 402 refers to Figure 4, which appears to be Figure 2; the COWA ablation is called Table 8 in the text but Table 3 in the main body; there is also noticeable duplication between the main text and the appendix. Please clean up cross-references and remove redundancies.\n\n\n```\nReferences\n1. Mohri, M., Sivek, G., & Suresh, A. T. Agnostic Federated Learning. Proceedings of ICML (PMLR), 2019, pp. 4615–4625.\n2. Tastan, N., Fares, S., Aremu, T., Horvath, S., & Nandakumar, K. Redefining Contributions: Shapley-Driven Federated Learning. arXiv preprint arXiv:2406.00569, 2024.\n3. Huang, T., Liu, S., Shen, L., He, F., Lin, W., & Tao, D. Achieving Personalized Federated Learning with Sparse Local Models. arXiv preprint arXiv:2201.11380, 2022.\n4. Bibikar, S., Vikalo, H., Wang, Z., & Chen, X. Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better. Proceedings of the AAAI Conference on Artificial Intelligence, 2022, 36(6): 6080–6088.\n```"}, "questions": {"value": "1. Why is there no ablation that removes PWPM?\n2. What exactly are the differences between the personalization rate (p) and the budget (r)? Both seem to control the degree of personalization in PWPM. Please clarify how each parameter is defined, how they differ conceptually or functionally.\n3. The gradient  score effectively up-weights clients whose directions differ more, and the prediction score up-weights clients that others perform poorly on. Could this amplify outliers or noisy clients? Have you evaluated robustness (e.g., label flip/Byzantine)?\n4.  Computing $\\Gamma_n^{\\text{data}}$ requires evaluating $w_{-n}$ on client $n$’s private data.  Is the time or communication cost high in practice?\n5. Most experiments appear highly non-IID. Do you have results under IID or milder Dirichlet settings?\n6. With partial participation (e.g., 10% of clients per round), how do you approximate $\\delta_{-n}$ and  $w_{-n}$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ptAsR7MBlb", "forum": "Fg1v0oaMhz", "replyto": "Fg1v0oaMhz", "signatures": ["ICLR.cc/2026/Conference/Submission7670/Reviewer_F2Mj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7670/Reviewer_F2Mj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761033300312, "cdate": 1761033300312, "tmdate": 1762919736184, "mdate": 1762919736184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CO-PFL framework to enhance the performance in pFL. Specifically, it introduces PWPM, MAMO, and COWA modules to improve the weight selection and aggregation ability. The authors validate the performance of the proposed method through small-scale experiments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The introduction section is well written, providing a fairly comprehensive summary of the developments in the related research area.\n\n2. The authors present the fundamental formulation of the optimization problem clearly, making it easy to understand the problem to be addressed."}, "weaknesses": {"value": "1. The notation in the paper is rather confusing, as many symbols are not clearly defined at the point of use or beforehand. This includes those related to the structured decomposition of the model and the corresponding variables used during training.\n\n2. The paper lacks sufficient theoretical analysis. It is built upon a series of pruning and aggregation strategies, introducing modifications at several key stages of the PFL framework. However, it remains unclear whether these modifications preserve the original convergence properties.\n\n3. The paper only presents the motivation for introducing the proposed modules but does not clearly demonstrate their specific advantages. This makes the study appear rather trivial and more like an engineering-level combination of components. Whether it is reasonable to justify the design merely based on a few empirical observations remains open to discussion.\n\n4. Regarding the design of the mask, there appears to be a certain risk in PFL tasks. When all nodes have highly consistent model masks, the global model update may nearly stagnate. This suggests that stronger robustness guarantees are needed to maintain the feasibility of the proposed method.\n\n5. The experimental section is not very convincing. The evaluation scale is relatively small, considering only training with 10 or 20 clients, and the validation is conducted solely on relatively simple datasets and models. Moreover, some of the reported results do not appear to demonstrate clear or significant advantages."}, "questions": {"value": "1. The plus sign in line 145 seems ambiguous. It is recommended that the authors revise it to represent a set operation or explicitly define the expression, rather than using it as a vector addition. The concatenation of two submodels differs conceptually from the summation of two parameter sets.\n\n2. Could the authors provide additional theoretical analysis or other forms of validation to clarify the specific advantages of the three proposed modules? In fact, it is not entirely clear to me whether some of the challenges mentioned in the motivation are truly critical. The proposed module improvements are all derived from the motivation described in the paper, but I would like to understand why pruning is used to distinguish importance, and why correcting through angular adjustments during aggregation can lead to better results. How do these approaches offer advantages compared with the original baseline method?\n\n3. What is the `client` function in line 195? Where is it defined? Why does the algorithm box not include any corresponding update steps?\n\n4. In line 206, during the update of all servers, there is a term denoted as $w^{k}\\circ m_0^{k+1}$. If the worst-case scenario occurs, that is, when $m_0^{k+1}$ takes the value 1 over a large scale, the update process would nearly stagnate. I did not find any statistical analysis from the authors regarding this ratio. Could the authors explain the potential training risks under such circumstances?\n\n5. I noticed that the FedAvg baseline in Table 1 achieves only 62%, which appears to be much lower than the commonly reported results in existing FL baselines. I would like to know whether the hyperparameters used in these experiments are standard. The reported results seem somewhat unreasonable—FedAvg typically achieves over 80% accuracy even when trained with up to 100 clients, whereas this paper uses only 10 clients. Why is the performance so low in this case?\n\n6. Could the authors provide larger-scale experiments, such as with 100 clients and longer training rounds? In fact, 200 training rounds only reflect early-stage performance. Achieving faster convergence in the early phase can essentially be done by using a larger learning rate; however, this does not represent the true convergence behavior. Over longer training periods, such a setup could significantly hinder convergence efficiency. Conventional training typically requires around 1000 rounds to verify convergence stability, and in some studies, the training is extended to as many as 4000 rounds to obtain more reliable and realistic results.\n\n7. The experiments seem to lack analysis on several key parameters. For instance, the effects of local training length and batch size are not discussed, and many critical hyperparameters remain unspecified. Could the authors provide additional experimental results to address these aspects? I would also like to know whether the reported results in the paper were obtained under optimal hyperparameter settings, and to what extent the performance is affected by variations in these hyperparameters."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4jtRNgN2eh", "forum": "Fg1v0oaMhz", "replyto": "Fg1v0oaMhz", "signatures": ["ICLR.cc/2026/Conference/Submission7670/Reviewer_BA4w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7670/Reviewer_BA4w"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761212654656, "cdate": 1761212654656, "tmdate": 1762919735791, "mdate": 1762919735791, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes `CO-PFL`, a contribution-oriented adaptive aggregation method for personalized federated learning setting. The are realized by three major components: COWA (client-specific aggregator module), PWPM (client-specific parameter importance ranking module) and MAMO (mask-based momentum module to stabilize the overall optimization process)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The proposed method is novel in terms of specializing three modules for the improvement of PFL.\n- The authors validated proposed method extensively on multiple vision benchmark datasets."}, "weaknesses": {"value": "- The definition of \"contribution\" should have been clearly defined. It is supposed to be a contribution toward an optimization of a global model, but it could differ in the PFL context, e.g., contribution to clients having similar distributions, contribution to data-deficient clients, ...\n- The rationale behind each module is heuristic and incremental rather than theory-driven or based on prior arts.\n  - For example, the MAMO module resembles MADA module proposed in [7], as well as Adam optimizer [8], but there's no justification.\n  - The usage of mask to selectively filter out important information in FL has also been proposed in [9,10].\n  - The usage of gradient score based on cosine distance for an adaptive aggregation has been proposed in [11,12], and the leave-one-out-style prediction score in Eq. (9) bears resemblance to Shapely value-based FL proposed in [13].\n- The communication costs are unavoidably increased compared to other parameter decoupling-based PFL methods.\n  - The downlink cost is doubled compared to FedAvg, due to additional communication of server mask.\n  - The uplink cost is tripled due to the mask and contribution score communiation.\n- No theoretical guarantee on convergence or generalization, especially how the MAMO module can _accelerate_ and _stabilize_ convergence.\n- The empirical validation is only limited to 10 and 20 clients, which should be a cross-silo FL setting. However, PFL is more suitable in practice for cross-device FL setting [1-3] where we usually assume massive number of clients participate [4]. Thus, I respectfully request authors to:\n  - 1) consider complementing justification on having a small number of clients in terms of a cross-silo FL setup, with, for example, plausible and convincing real-world scenario.  \n  - 2) or consider providing additional results to prove the scalability of `CO-PFL` in cross-device FL setting. Related benchmark datasets: `FEMNIST` [5], `Sent140` [5], and `StackOverflow` [6].\n\n- [1] Federated Evaluation of On-device Personalization\n- [2] Federated Evaluation and Tuning for On-Device Personalization: System Design & Applications\n- [3] Personalized Learning with Limited Data on Edge Devices using Federated Learning and Meta-Learning\n- [4] Advances and Open Problems in Federated Learning\n- [5] LEAF: A Benchmark for Federated Settings\n- [6] TensorFlow Federated (https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow)\n- [7] PRISM: Privacy-Preserving Improved Stochastic Masking for Federated Generative Models\n- [8] Adam: A Method for Stochastic Optimization\n- [9] Federated Continual Learning with Weighted Inter-client Transfer\n- [10] FedMask: Joint Computation and Communication-Efficient Personalized Federated Learning via Heterogeneous Masking\n- [11] Federated Learning with Fair Averaging\n- [12] Redefining Contributions: Shapley-Driven Federated Learning\n- [13] ShapleyFL: Robust Federated Learning Based on Shapley Value"}, "questions": {"value": "- Please also check the \"Weaknesses\" section above.\n- The gap this work would like to fill is ambiguous. Does the authors aim to improve the personalization performance in FL? Or does the authors want to propose adaptive aggregation algorithm for FL? Or does the authors intend to propose incentive-aware (P)FL algorithm? Or does the authors intend to propose pruning method specialized for FL? Please clearly define which branch of PFL this work aims to address, and refine the main contribution of this work. \n- Why advanced parameter decoupling-based PFL algorithms, such as `FedRep`, `FedBABU`, `Ditto`, were not compared although they are known to show better performance than `LG-FedAvg` and `FedPer`? These baselines are seemed a bit outdated.\n- The main objective, i.e., Eq. (2) needs an improvement. Can it be modified into, for example, $g^\\star, w_n^* = \\arg\\min_{g, [w_n]} \\frac{1}{N} \\sum_{n=1}^N f_n(g, w_n)$. Please let me know if I'm incorrect.\n- Please add a comparison table on communication cost and discuss a tradeoff between increased communication costs and performance gain or convergence speed. \n\n### Minor comments\n- Please consider changing citation style for better readability, e.g., (Collins et al., 2021)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "saKC4AlM5s", "forum": "Fg1v0oaMhz", "replyto": "Fg1v0oaMhz", "signatures": ["ICLR.cc/2026/Conference/Submission7670/Reviewer_HiMA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7670/Reviewer_HiMA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7670/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966174041, "cdate": 1761966174041, "tmdate": 1762919734522, "mdate": 1762919734522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}