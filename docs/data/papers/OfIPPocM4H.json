{"id": "OfIPPocM4H", "number": 10535, "cdate": 1758174930789, "mdate": 1763551781492, "content": {"title": "HAMMER: Hamiltonian Curiosity Augmented Large Language Model Reinforcement", "abstract": "Recent curriculum reinforcement learning for large language models (LLMs) typically rely on difficulty-based annotations for data filtering and ordering. However, such methods suffer from local optimization, where continual training on simple samples in the early steps causing the policy to lose its exploration. We propose a novel schema, namely *Hamiltonian curiosity AugMented large language ModEl Reinforcement (HAMMER)*, that transfers diversity metrics, commonly used in dataset evaluation, into the dynamic reinforcement learning procedure, where training samples are ordered via a minimum-semantic Hamiltonian path making the initial training retrain more exploration. From a theoretical perspective of generalization bounds, diversity-driven ordering facilitates stable convergence. Empirical evaluations indicate that *HAMMER* stimulates model \"curiosity\" and consistently achieves a 3% to 4% average accuracy gain across diverse inference benchmark.", "tldr": "Large Language Model Curriculum Learning Based on Minimum Semantic Similarity Hamiltonian Cycle", "keywords": ["LLM reinforcement learning", "curriculum learning", "sample efficiency", "hamiltonian path"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8124754d6aa54b6a7aa5a196383cabf36d08935f.pdf", "supplementary_material": "/attachment/3eb27798dae5870e19d6f143620662d9b92d6af2.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel curriculum learning schema for reinforcement learning in LLMs. Instead of traditional difficulty-based curricula, HAMMER proposes ordering the training data to maximize diversity.  The authors claim that by presenting the model with a sequence of semantically diverse samples in training, the model is encouraged to explore more of the data space, leading to more stable training, faster convergence, and better accuracies on mathematical reasoning benchmarks. The paper also provides theoretical arguments suggesting this approach tightens generalization bounds while preserving the optimal policy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of framing the data sequencing problem for curriculum learning as a path-finding problem on a semantic similarity graph is novel and creative. Applying a concept from graph theory like the Hamiltonian path problem to RL-based LLM fine-tuning is interesting.\n2. The proposed method presents a potentially practical advantage. Difficulty-based curriculum learning often requires expensive data annotation or evaluation runs with powerful proprietary models. HAMMER offers a data-centric alternative that is computationally cheaper, requiring only a one-time forward pass to generate embeddings and a subsequent heuristic search."}, "weaknesses": {"value": "1. Serious incorrectness in the Example 3. In the sole example for Hamiltonian Curiosity Order, the given path $(x_2, x_3, x_5, x_4, x_1)$ has similarity $w_2=-0.8-0.3+0.4+0.7=0.0$, instead of the proposed -0.5. Actually, the targeted paths are  $(x_1, x_3, x_2, x_5, x_4)$ and its reverse $(x_4, x_5, x_2, x_3, x_1)$. \n2. Theorems 1 and 2 are general learning theory results that argue for the effectiveness of training on a diverse subset of data. While they correctly suggest that starting with a diverse set of samples is beneficial, they do not provide a compelling reason for why the entire dataset must be structured into a single Hamiltonian sequence. The theory supports diverse mini-batches, but not necessarily this specific and restrictive global ordering.\n3. The η-GHS algorithm's performance depends on the \"expand factor η\". The paper dismisses its importance by stating, \"varying η has little impact on overall performance, so we fix η=3\", but provides no ablation study or evidence to support this claim. This is a critical omission for a key algorithmic component. \n4. The entire method relies on meaningful semantic embeddings from the backbone LLM itself. The paper does not discuss how the quality of these embeddings at the start of training affects the curriculum. If the initial model has poor representations, it could generate a nonsensical or even detrimental training order. An analysis of the robustness of the method to the initial model's capabilities is missing.\n\nTypos:\n1. Line 422: As shown in Figure 7 show that... ->Figure 7 shows that\n2. Figure 4 (c): varing -> varying"}, "questions": {"value": "1. How was η=3 chosen? Please give more detailed explanations and empirical validations. Is the performance robust to this choice?\n2. Have you considered or compared HAMMER to a simpler baseline that enforces diversity at the mini-batch level (e.g., using maximal marginal relevance or similar techniques for batch selection) instead of ordering the entire dataset?\n3. How sensitive is the HAMMER curriculum to the initial state of the backbone model? Did you experiment with generating the embeddings from a different, external model (e.g., a dedicated sentence-transformer) versus the backbone LLM? Could a curriculum generated by a poorly pre-trained model be detrimental, and does the curriculum need to be recomputed as the model trains and its representations change?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M5R49y31kQ", "forum": "OfIPPocM4H", "replyto": "OfIPPocM4H", "signatures": ["ICLR.cc/2026/Conference/Submission10535/Reviewer_HLW8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10535/Reviewer_HLW8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761168835674, "cdate": 1761168835674, "tmdate": 1762921816240, "mdate": 1762921816240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Feedback and Summary"}, "comment": {"value": "We sincerely appreciate the reviewers for their careful review and feedback, which has provided valuable suggestions for our research. Our gratitude also extends to the PC/AC/SAC and ICLR 2026 for offering this opportunity for open communication. \n\n# Revision Summary\nWe have submitted the revised manuscript, with major changes highlighted in **RED**. Below is an index of the key revisions and corresponding locations in the LATEST VERSION of the manuscript.\n\n| Item | Content | Index | Source |\n|-|-|-|-|\n| Typos of Example 3 | We forgot to update the path of $\\mathcal{P}$ in Example 3 (causing ambiguity with Figure 1); the remaining description and weight calculations are correct. | Example 3 (line 199) | HLW8 |\n| Curriculum-order Construction Time | We provide HAMMER and a difficulty-based method for curriculum-order construction. Results show HAMMER is significantly faster. | Appendix C, Table 4 (line 1062) | uEBG |\n| Main Results | Added isomorphic Qwen3-8B and heterogeneous Deepseek-R1-Distill-Llama3-8B results on top of Qwen3-1.7B/4B. | Table 1 (line 324-355) | uEBG |\n| Training Dynamics | Provided training curves for Qwen3-8B, Deepseek-R1-Distill-Llama3-8B and Qwen3-1.7B. | Figure 4 (line 409-417) | — |\n| Zero-shot Results | Aligned with main experiments, we report zero-shot results of the newly added models. | Table 2 (line 474-485) | — |\n| Ablation on $\\eta$ | Supplemented the missing $\\eta=3$ ablation experiment. | Figure 6 & Discussion (line 459-466) | HLW8 |\n| Comparison with Other CL Methods | Due to differing models/data across works, we conduct two fair comparison groups on Qwen2.5-Math-1.5B / Qwen2.5-1.5B-Instruct against ADARFT [1], SEC [3], E2H-G/C [2]. | Discussion (line 492-499); Table 5; Appendix E | h9kM, WNod |\n| Embedding Model Ablation | Incorporated external BERT / Qwen3-Embedding-4B as sentence encoders into HAMMER. | Line 500-504, Figure 7(a) (line 518-525) | uEBG, HLW8 |\n| Additional Exploratory Experiments | (1) Combine difficulty-based curriculum learning with HAMMER; (2) Dynamic diversity sampling. | (1) Discussion (line 506-509), Figure 7(b); (2) Discussion (line 511-517), Figure 7(c) | uEBG, HLW8 |\n| Theoretical Discussion | Detailed theoretical analysis of HAMMER, including three theorems and their connections to the method (Discussion 1-3). | Appendix B.2 | h9kM, WNod, HLW8 |\n\nWe appreciate and welcome all feedback you provide. If you have any other concerns, please feel free to contact us.\n\n# References\n[1] Taiwei Shi, Yiyang Wu, Linxin Song, Tianyi Zhou, and Jieyu Zhao. Efficient reinforcement finetuning via adaptive curriculum learning, 2025.\n\n[2] Shubham Parashar, Shurui Gui, Xiner Li, Hongyi Ling, Sushil Vemuri, Blake Olson, Eric Li, Yu Zhang, James Caverlee, Dileep Kalathil, and Shuiwang Ji. Curriculum reinforcement learning from easy to hard tasks improves LLM reasoning. CoRR, abs/2506.06632, 2025. doi: 10.48550/ARXIV.2506.06632. URL https://doi.org/10.48550/arXiv.2506.06632.\n\n[3] Xiaoyin Chen, Jiarui Lu, Minsu Kim, Dinghuai Zhang, Jian Tang, Alexandre Piché, Nicolas Gontier, oshua Bengio, and Ehsan Kamalloo. Self-evolving curriculum for llm reasoning, 2025a. URL https://arxiv.org/abs/2505.14970."}}, "id": "K9SiqlOAXz", "forum": "OfIPPocM4H", "replyto": "OfIPPocM4H", "signatures": ["ICLR.cc/2026/Conference/Submission10535/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10535/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10535/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763551864142, "cdate": 1763551864142, "tmdate": 1763551864142, "mdate": 1763551864142, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel curriculum learning schema for reinforcement learning in LLMs. Instead of traditional difficulty-based curricula, HAMMER proposes ordering the training data to maximize diversity.  The authors claim that by presenting the model with a sequence of semantically diverse samples in training, the model is encouraged to explore more of the data space, leading to more stable training, faster convergence, and better accuracies on mathematical reasoning benchmarks. The paper also provides theoretical arguments suggesting this approach tightens generalization bounds while preserving the optimal policy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of framing the data sequencing problem for curriculum learning as a path-finding problem on a semantic similarity graph is novel and creative. Applying a concept from graph theory like the Hamiltonian path problem to RL-based LLM fine-tuning is interesting.\n2. The proposed method presents a potentially practical advantage. Difficulty-based curriculum learning often requires expensive data annotation or evaluation runs with powerful proprietary models. HAMMER offers a data-centric alternative that is computationally cheaper, requiring only a one-time forward pass to generate embeddings and a subsequent heuristic search."}, "weaknesses": {"value": "1. Serious incorrectness in the Example 3. In the sole example for Hamiltonian Curiosity Order, the given path $(x_2, x_3, x_5, x_4, x_1)$ has similarity $w_2=-0.8-0.3+0.4+0.7=0.0$, instead of the proposed -0.5. Actually, the targeted paths are  $(x_1, x_3, x_2, x_5, x_4)$ and its reverse $(x_4, x_5, x_2, x_3, x_1)$. \n2. Theorems 1 and 2 are general learning theory results that argue for the effectiveness of training on a diverse subset of data. While they correctly suggest that starting with a diverse set of samples is beneficial, they do not provide a compelling reason for why the entire dataset must be structured into a single Hamiltonian sequence. The theory supports diverse mini-batches, but not necessarily this specific and restrictive global ordering.\n3. The η-GHS algorithm's performance depends on the \"expand factor η\". The paper dismisses its importance by stating, \"varying η has little impact on overall performance, so we fix η=3\", but provides no ablation study or evidence to support this claim. This is a critical omission for a key algorithmic component. \n4. The entire method relies on meaningful semantic embeddings from the backbone LLM itself. The paper does not discuss how the quality of these embeddings at the start of training affects the curriculum. If the initial model has poor representations, it could generate a nonsensical or even detrimental training order. An analysis of the robustness of the method to the initial model's capabilities is missing.\n\nTypos:\n1. Line 422: As shown in Figure 7 show that... ->Figure 7 shows that\n2. Figure 4 (c): varing -> varying"}, "questions": {"value": "1. How was η=3 chosen? Please give more detailed explanations and empirical validations. Is the performance robust to this choice?\n2. Have you considered or compared HAMMER to a simpler baseline that enforces diversity at the mini-batch level (e.g., using maximal marginal relevance or similar techniques for batch selection) instead of ordering the entire dataset?\n3. How sensitive is the HAMMER curriculum to the initial state of the backbone model? Did you experiment with generating the embeddings from a different, external model (e.g., a dedicated sentence-transformer) versus the backbone LLM? Could a curriculum generated by a poorly pre-trained model be detrimental, and does the curriculum need to be recomputed as the model trains and its representations change?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M5R49y31kQ", "forum": "OfIPPocM4H", "replyto": "OfIPPocM4H", "signatures": ["ICLR.cc/2026/Conference/Submission10535/Reviewer_HLW8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10535/Reviewer_HLW8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761168835674, "cdate": 1761168835674, "tmdate": 1763678207368, "mdate": 1763678207368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Hammer, an automated curriculum learning method by ordering the training samples via minimum-semantic Hamiltonian path. a training samples are ordered via a minimum-semantic Hamiltonian path. This is intended to induce curiosity, encourage exploration across diverse semantic regions, and avoid overfitting to local clusters. Extensive experiments are provided to show performance gains compared with GRPO, DAPO, and \"easy-to-hard\" curriculum baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and easy-to-follow.\n- Introducing automated curriculum learning into reinforcement learning for large language models is timely and relevant. The idea of structuring training data through semantic ordering is interesting from an application perspective.\n- The paper provides theoretical justifications for main claims.\n- The paper evaluates HAMMER with extensive experiments and compares against several baselines, showing consistent improvements for pass@k metrics across multiple Math benchmarks."}, "weaknesses": {"value": "1. The paper claims that \"training with the selected Hamiltonian cycle promotes convergence by tightening the generalization bound with a small set of diverse samples”. However, the presented generalization bound (Theorem 1–2) is a standard VC-type inequality that depends only on sample size $n$, confidence $\\delta$, and hypothesis class complexity $d$. It's not clear how it is related to sample ordering and diversity of the subset. More justifications will be helpful.\n2. Theorem 3 states that maximizing the diversity score $\\max_S \\mu_{DCS}(S)$ is equivalent to minimizing total pairwise similarity in subset $S$, which is a global diversity objective over a subset $S$. However, the Hamiltonian curiosity order (Definition 3) solves a permutation problem over all samples by minimizing path cost, which minimizes the sum of adjacent similarities, not global pairwise similarity. There seems some fundamental mismatch. \n3. The empirical improvements over E2H and other baselines are marginal, and no confidence intervals or error bars are provided. It is therefore unclear if the gains are statistically significant."}, "questions": {"value": "1. Is each subset $S$ selected once or repeatedly per epoch? How many RL update steps are done per subset? Does ordering reset every epoch? Or is it fixed once?\n2. Could you empirically compare the diversity metric of samples selected by Hammer, random ordering and other baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fd4ibLv5Ae", "forum": "OfIPPocM4H", "replyto": "OfIPPocM4H", "signatures": ["ICLR.cc/2026/Conference/Submission10535/Reviewer_WNod"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10535/Reviewer_WNod"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761448547034, "cdate": 1761448547034, "tmdate": 1762921815819, "mdate": 1762921815819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HAMMER, a curriculum learning schema for reinforcement learning of LLMs, which structures training by ordering samples based on minimum semantic similarity (formulated as a Hamiltonian path) to promote early exposure to diverse examples. Theoretical analysis demonstrates that this approach preserves the optimal policy and tightens generalization bounds, while experiments on mathematical reasoning benchmarks show consistent 3–4% accuracy gains and improved sample efficiency over baselines using difficulty-based or random sample orderings.​"}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novelty: Transferring diversity metrics from static dataset analysis for RL curriculum to address the exploration-exploitation imbalance common in difficulty-based curricula.\n- Theoretical section justifies generalization bounds and shows that sample diversity ordering does not compromise learning optimality, even as it reduces variances.\n- Performance: Improving upon the baseline using randomly shuffled samples.\n- Efficiency: Training with faster and better convergence compared to baselines."}, "weaknesses": {"value": "- The complexity of Algorithm 1 is $O(n^2)$, thus, the scalability of Hamiltonian ordering as the number of training samples grows is not fully explored, especially when models and datasets scale up beyond several thousand samples.\n- Include embedding model ablations comparing internal vs. external representations could be helpful to support the use of backbone LLM's embeddings (L162-166).\n- While the performance gained is good given the model sizes of 1.7B and 4B, I wonder if we can see this benefit in a larger model.\n- Minor: add citations for training and evaluation datasets."}, "questions": {"value": "- Is the performance improvement mainly attributable to the use of the backbone LLM’s own embeddings, or could similar gains be realized using pre-trained external sentence encoders?\n- While using the backbone LLM's embeddings might align well semantically, would it introduce bias or restrict exploration to the model’s current latent space structure?\n- Could HAMMER be applied to other RL methods (e.g., DPO)?\n- Have authors ever considered mixing HAMMER (semantic diversity ordering) and easy-to-hard progression?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HD3XtuzsMP", "forum": "OfIPPocM4H", "replyto": "OfIPPocM4H", "signatures": ["ICLR.cc/2026/Conference/Submission10535/Reviewer_uEBG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10535/Reviewer_uEBG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903754816, "cdate": 1761903754816, "tmdate": 1762921814681, "mdate": 1762921814681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HAMMER, a new curriculum learning schema for reinforcement learning with LLMs. Instead of ordering training samples by difficulty, it orders them by semantic diversity. It constructs a Hamiltonian Curiosity Order, a data sequence with minimum semantic similarity, so that the model encounters the most diverse samples first. It also proposes a heuristic algorithm to compute the Hamiltonian Curiosity Order. Theoretical analysis shows that the proposed method preserves the optimal policy and tightens generalization bounds. Experiments on several benchmarks also demonstrates its effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed HAMMER method can achieve the data ordering using only semantic embeddings, without requiring extra annotations or difficulty metrics, making it more practical and scalable.\n2. It provides theoretical analysis that supports the effectiveness of the proposed method.\n3. The experimental results show that HAMMER outperforms the baseline methods on several benchmarks."}, "weaknesses": {"value": "1. Most of the experiments compare HAMMER only with a baseline that uses random data ordering. There is only one experiment comparing HAMMER with E2H and H2E. It lacks comprehensive comparisons with other curriculum learning methods that use different data ordering strategies. \n2. The theoretical analysis does not provide insight into why the Hamiltonian Curiosity Order is better than other possible ordering strategies, e.g., random sampling.\n3. The novelty of the proposed method is somewhat limited, as it mainly combines existing ideas of curriculum learning and semantic embeddings without introducing significant new techniques."}, "questions": {"value": "1. Can you provide more experiments comparing HAMMER with other curriculum learning methods to better demonstrate its effectiveness?\n2. Can you provide additional theoretical analysis or discussion on why ordering by the proposed Hamiltonian Curiosity Order leads to better performance compared to other ordering strategies, or under what conditions can it work better?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wPAm5wA7Qx", "forum": "OfIPPocM4H", "replyto": "OfIPPocM4H", "signatures": ["ICLR.cc/2026/Conference/Submission10535/Reviewer_h9kM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10535/Reviewer_h9kM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762092613812, "cdate": 1762092613812, "tmdate": 1762921814115, "mdate": 1762921814115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}