{"id": "Va2tLzb1NX", "number": 4558, "cdate": 1757706451063, "mdate": 1763502403357, "content": {"title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers", "abstract": "Transformers have achieved state-of-the-art performance across diverse language and vision tasks. This success drives the imperative to interpret their internal mechanisms with the dual goals of enhancing performance and improving behavioral control. Attribution methods help advance interpretability by assigning model outputs associated with a target concept to specific model components. Current attribution research primarily studies multi-layer perceptron (MLP) neurons and addresses relatively simple concepts such as factual associations (e.g., Paris is located in France). This focus tends to overlook the impact of the attention mechanism and lacks a unified approach for analyzing more complex concepts. To fill these gaps, we introduce Scalable Attention Module Discovery (SAMD), a concept-agnostic method for mapping arbitrary, complex concepts to specific attention heads of general transformer models. We accomplish this by representing each concept as a vector, calculating its cosine similarity with each attention head, and selecting the TopK-scoring heads to construct the concept-associated attention module. We then propose Scalar Attention Module Intervention (SAMI), a simple strategy to diminish or amplify the effects of a concept by adjusting the attention module using only a single scalar parameter. Empirically, we demonstrate SAMD on concepts of varying complexity, and visualize the locations of their corresponding modules. Our results demonstrate that module locations remain stable before and after LLM post-training, and confirm prior work on the mechanics of LLM multi-lingualism. Through SAMI, we facilitate jailbreaking on HarmBench (+72.7%) by diminishing “safety” and improve performance on the GSM8K benchmark (+1.6%) by amplifying “reasoning”. Lastly, we highlight the domain-agnostic nature of our approach by suppressing the image classification accuracy of vision transformers on ImageNet.", "tldr": "", "keywords": ["transformers; language models; multi-head self-attention; interpretability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bc4235415d4aa9e1397613361b98147a3abbad04.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents Scalable Attention Module Discovery (SAMD), a method for identifying attention heads associated with abstract “concepts” in transformers via cosine similarity, and Scalar Attention Module Intervention (SAMI), a one-parameter mechanism to amplify or suppress their influence. The approach is demonstrated across LLMs and ViTs, with qualitative interpretability results and modest quantitative effects on reasoning, safety, and vision benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Introducing attention-head–level concept attribution is an original direction that is computationally light and easily applicable to diverse transformer architectures.\n\n - The same pipeline is used across text and vision models, suggesting potential generality and extensibility.\n\n - The paper contributes to ongoing efforts to connect internal transformer components to semantic behaviors, particularly through sparse, interpretable “modules.”"}, "weaknesses": {"value": "- The evaluation is dominated by qualitative visualizations and anecdotal examples. There are no robust statistical analyses, reproducible metrics, or causal validation to confirm that the discovered modules truly mediate the claimed concepts.\n\n - The use of cosine similarity as a proxy for conceptual alignment is not theoretically or empirically justified; results may reflect correlation, not causation.\n\n - Choices of K (number of heads) and s (scaling factor) appear arbitrary, tuned via small grid searches without sensitivity analysis.\n\n - The paper never clearly defines in what sense the approach is “concept-agnostic.” This weakens the interpretive and theoretical clarity of the contribution."}, "questions": {"value": "How is a “concept” defined in this framework, and how can the method be considered “concept-agnostic” if it depends on concept-specific vectors?\n\nCan the identified attention modules be causally validated (e.g., via path patching or feature ablation)?\n\nHow robust are the discovered modules to randomization, different seeds, or model variants?\n\nCould quantitative measures (e.g., mutual information or probing accuracy) strengthen the claims?\n\nThe heatmap figures are difficult to distinguish between colors, which are somehow important (e.g., with bold borders) and which are not.\nPlease, change the color."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xGZE3X9ulP", "forum": "Va2tLzb1NX", "replyto": "Va2tLzb1NX", "signatures": ["ICLR.cc/2026/Conference/Submission4558/Reviewer_WBy6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4558/Reviewer_WBy6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761226449883, "cdate": 1761226449883, "tmdate": 1762917438572, "mdate": 1762917438572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an attribution method (of model components, not the input) for explaining transformer-based models. Specifically, it identifies the most important attention heads across the model which are relevant to a concept of interest i.e. the French language. To do so, they identify the maximally close (in terms of cosine similarity) attention heads to concept vectors captured from a positive dataset. They then propose that the identified components of the model can be up- or downscaled to change model behavior, thus verifying their component extraction, and providing a real use case for the method."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "Very interesting method with good novelty. Unlike many previous MLP neuron attribution approaches, this is the first I have seen which identifies attention concepts. This is an interesting and critical result with the stronger push for mechanistic interpretability and adjacent approaches in the modern XAI literature. \n\nWell written with extensive experimental results.  \n\nI think the simplicity of the approach is a benefit to its usability. I feel that I could replicate this with a few hours of work if I had access to the datasets."}, "weaknesses": {"value": "Minor – plainly calling this an attribution method feels misaligned with the literature. Attribution methods often refer to input (feature) attribution. This is more aligned with neuron attribution. Perhaps it should be attention attribution but not to be confused with input attribution using attention weights/gradients. \n\nThere are not any true comparisons against other methods. It is hard to tell if this should be negative because it may be challenging to create a fair comparison against a similar MLP based method. I think it could have been possible to use knowledge editing benchmark."}, "questions": {"value": "Did the authors consider a knowledge editing style benchmark?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "As6sAuOEL6", "forum": "Va2tLzb1NX", "replyto": "Va2tLzb1NX", "signatures": ["ICLR.cc/2026/Conference/Submission4558/Reviewer_HhFz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4558/Reviewer_HhFz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761602924852, "cdate": 1761602924852, "tmdate": 1762917438150, "mdate": 1762917438150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose SAMD and SAMI - Scalable Attention Module Discovery and Intervention. Given a feature vector $v_c$, SAMD discovers a set of $K$ attention heads whose output $a_{l,h}$ has on average high cosine similarity to $v_c$. They call this set of attention heads (which is a circuit in a way) a module.  Given a the circuit of $K$ attention heads, SAMI amplifies or suppresses the module by scaling the attention heads output $a_{l,h}$ by a scaling factor $s$ which they choose on a per problem basis using grid search. They demonstrate the effectiveness of their methods in 4 different experiments:\na) They find and steer modules that correspond to SAE features. This motivates the name - as they choose concepts, and search for relevant modules related to the concept. This is done by generating a dataset $D_p$ for which an SAE feature $v_c$ is highly activated and then running SAMD with $v_c$ and $D_p$.\nb) They find and steer a module that corresponds to reasoning capabilities in the model. They report improved scores on the GSM8K reasoning benchmark.\nc) They find and steer a module that corresponds to a refusal direction. The report improved attack success rate over orthogonalization of the refusal direction in two out of three cases. \nd) They find and steer a module that corresponds the classification of a given ImageNet target on ViT-B/32 21k, showcasing effectiveness of targeted unlearning of a single class."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Novel and elegant method for circuit discovery\n* Clear presentation of the findings\n* Demonstration of effectiveness of method on a broad variety of applications over two different modalities. Especially in the vision literature this is addressing a research gap, as vision-circuit discovery remains under-explored."}, "weaknesses": {"value": "* 4.2 the construction of $D_p$ is unclear from just reading the main body of the paper. \n* Concept figure should be improved\n\t* Font way to small\n\t* No order of panels provided\n\t* SAMI is not explained in the rightmost panel\n* Comparison to baseline such as e.g. difference in means is missing for 4.1, 4.2 and 4.4. If this concern is addressed appropriately I will improve my score.\n* In 4.2 the authors only report evals on the dataset that they used for construction. An OOD reasoning benchmark eval would be useful to evaluate the generality of the reasoning-module.\n* Only ViT-B 32 evaluated in 4.4). Experiments with at least ViT-L would be recommended as ViT-B often shows different behaviors from its bigger counterparts. If this concern is addressed I will improve my score."}, "questions": {"value": "* Did the authors explore including highly negative cosine sim attention heads (e.g. Fig 24.) and flipping the $s$ value for these heads? If so, that did they find? Especially in Fig 24 gemma 7b one head seems to have the highest absolute alignment with -0.4 similarity while the highest positive alignment is only 0.3.\n* What is the rational behind the $D_p$ construction via the test samples of GSM8K? Is it that the prompts are explicitly encouraging to reason?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mG01iFYFQD", "forum": "Va2tLzb1NX", "replyto": "Va2tLzb1NX", "signatures": ["ICLR.cc/2026/Conference/Submission4558/Reviewer_BQcd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4558/Reviewer_BQcd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917228026, "cdate": 1761917228026, "tmdate": 1762917437861, "mdate": 1762917437861, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response by Authors"}, "comment": {"value": "We sincerely thank all reviewers for taking the time to review our paper and providing valuable feedback. We appreciate all reviewers for the consistent recognition of the novelty and elegance of our proposed pipeline, and the broad experimental coverage across both language and vision fields. Our key insight of the concept vector abstraction and the cosine similarity importance assignment allows us to discover attention modules across concepts with varying granularities, from simple nouns as “dogs” to highly abstract ones as “safety”. Beyond attention module discovery, our proposed intervention effectively diminishes or amplifies the target concept in both language and vision models, which is the first model-component-based intervention method that achieves such effects.\n\nThe reviewers have raised several important common concerns that we are eager to address.\n\n1. The comparison to baselines and the use of qualitative demonstrations.\n\n2. The robustness of our Scalable Attention Module Discovery.\n\n\n\nWe appreciate these insightful comments and are pleased to provide detailed clarifications to each of these points below.\n\n\n\n**Comprehensiveness of our evaluation.** In our paper, we consider both the language and vision modality, demonstrating the generality of our proposed pipeline. Since we are the first to discover attention modules in general transformers and apply interventions on them, there is no directly comparable work. To facilitate a comprehensive evaluation, we compare our intervention against steering-vector-based baselines when applicable, in Section 4.1 and Section 4.3. The qualitative visualizations are used to show the location of our discovered modules, and we only provide qualitative demonstrations for the concepts that are not easy to measure quantitatively.\n\n\n\n**Robustness of our Scalable Attention Module Discovery.** In our rebuttal, we claim the robustness of our method through the following three new sets of experiments.\n\n1. Re-discover the modules using only half of the original data.  We find the modules remain largely unchanged under this situation, with 0-1 attention heads being different. We have attached these results in Appendix I.\n2. Out-of-distribution test of the “reasoning module”. Using the module discovered with GSM8K, we demonstrate improved accuracy on the MATH benchmark, showing our intervention even carries over out-of-distribution. We have attached this result to our paper.\n3. Vision experiment on larger ViTs. We launch our pipeline on a larger Vision Transformer, ViT-L/16, and obtain similar observations as we have seen on ViT-B/32. We have attached these results in Appendix G.\n\n\n\nWe would be eager to summarize our contributions and emphasize the importance of our work again as follows.\n\n\n**The first attention module discovery method for arbitrary concepts on general transformers.** We propose a novel method that utilizes vector abstraction of concepts and finds important attention heads through cosine similarity. It addresses challenges such as the difficulty of representing concepts through concrete tokens and shows the importance of attention mechanisms for model attribution research.\n\n\n\n**The first model component-based intervention method to steer model behavior.** Our proposed intervention only relies on a single scalar and is easily applicable to general transformer structures. Its effectiveness has been verified both quantitatively and qualitatively on diverse model families in both language and vision domains.\n\n\n\nWe sincerely thank all reviewers for their time on our rebuttal. We hope our response addresses your concerns and highlights the significance of our contributions. We would be delighted to discuss further in the rebuttal period."}}, "id": "PUjBqQ1RQG", "forum": "Va2tLzb1NX", "replyto": "Va2tLzb1NX", "signatures": ["ICLR.cc/2026/Conference/Submission4558/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4558/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission4558/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763502244103, "cdate": 1763502244103, "tmdate": 1763502244103, "mdate": 1763502244103, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}