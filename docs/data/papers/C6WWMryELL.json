{"id": "C6WWMryELL", "number": 8616, "cdate": 1758092648548, "mdate": 1759897773057, "content": {"title": "On Stable Long-Form Generation: Benchmarking and Mitigating Length Volatility", "abstract": "Large Language Models (LLMs) excel at long-context understanding but exhibit significant limitations in long-form generation. Existing studies primarily focus on single-generation quality, generally overlooking the volatility of the output (i.e., the inconsistency in length and content across multiple generations). This volatility not only leads to significant computational costs but also severely impacts the models' reliable application. To address this gap, our work unfolds in three stages: *benchmarking, probing, and mitigation*. We first propose the **VO**latility in **L**ong-form **T**ext **Bench**mark (**VOLTBench**), a novel heterogeneous-task benchmark designed to systematically quantify the length volatility of long-form generation. Subsequently, by analyzing attention traces, we conduct an in-depth probe to identify several common internal patterns that cause this volatility. Finally, to mitigate long-form output volatility, we propose SELB (Structural Enforcement via Logits Boosting), a lightweight decoding-stage optimization strategy, designed to significantly enhance both the length accuracy and stability of long-form generation without additional training. Extensive experiments on VOLTBench provide the first systematic confirmation of severe long-form output instability in mainstream models and validate that our proposed method successfully improves the mean output length of the base model by 148\\% and reduces the length volatility by 69\\%, while maintaining high generation quality.", "tldr": "", "keywords": ["Long-Form Generation", "Length Volatility"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/754d0ad4b4a05427c640d1605277c17867b46408.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper reframes long-form generation around a neglected reality: outputs vary wildly across samples, especially in length. It introduces VOLTBench to measure that volatility with clear stability metrics (variance/ratio and mean-length alignment) across structured and unstructured tasks. By visualizing attention over “constraint” tokens in the prompt, the authors surface two failure signatures—Attention Collapse (periodic peaks fade, the model drifts into repetition or early stop) and Attention Instability (a sudden oversized peak that tempts the model to jump straight to the final section). To counter this, they propose SELB, a training-free, decoding-time controller that boosts logits for next-section titles at length thresholds and suppresses EOS/boilerplate until the final section, yielding longer, steadier, and still coherent outputs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work is refreshingly practical: it defines stability as a first-class objective, offers an interpretable diagnostic (attention traces that align peaks with section starts), and delivers a simple plug-in method that doesn’t require retraining yet tracks task constraints directly. Evidence spans multiple models and tasks, showing volatility reductions and better length adherence without obvious quality collapse. The paper also documents metrics and templates clearly and commits to releasing code/benchmark, which should make these ideas easy to adopt."}, "weaknesses": {"value": "1) The paper’s “quality” evidence leans on structural or task-specific signals (e.g., section adherence, execution checks) rather than human-perceived writing quality. For creative long-form text, improved stability and length alignment on VOLTBench do not necessarily guarantee unchanged or better writing quality versus strong baselines.\n\n2) SELB addresses sampling volatility but does not clearly separate it from infrastructure nondeterminism. In creativity-oriented settings where temperature cannot be set very low, it remains unclear how much instability comes from stochastic decoding versus platform/kernel nondeterminism (fixed seeds, deterministic math, op ordering), as discussed in resources like https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/.\n\n3) The method implicitly relies on explicit section templates by boosting “next-section title” tokens. This structural bias limits applicability to essays or narratives without clear headings, where attention peaks tied to title tokens are weak or absent and structural enforcement can become brittle or intrusive."}, "questions": {"value": "ref weekness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "y4fhxha1T7", "forum": "C6WWMryELL", "replyto": "C6WWMryELL", "signatures": ["ICLR.cc/2026/Conference/Submission8616/Reviewer_Kq9F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8616/Reviewer_Kq9F"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760781238047, "cdate": 1760781238047, "tmdate": 1762920453899, "mdate": 1762920453899, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of \"length volatility\" in long-form text generation by LLMs, where models produce inconsistent output lengths and content for the same prompt that requires long output. The authors tackle this issue through a three-stage approach:\n\n- Benchmarking: They introduce VOLTBench, a new benchmark designed to quantify length volatility across diverse structured and unstructured tasks, languages, and complexities.\n- Probing: They analyze the internal attention mechanisms of models to identify root causes of volatility, defining failure patterns like \"Attention Collapse\" and \"Attention Instability.\"\n- Mitigation: They propose SELB (Structural Enforcement via Logits Boosting), a lightweight, training-free decoding strategy that dynamically modifies logits to enforce structural adherence and prevent premature termination.\n\nExperiments on VOLTBench show that existing models suffer from severe volatility. The proposed SELB method is shown to be effective, increasing the mean output length by 148% and reducing volatility by 69%."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Well-designed benchmark (VOLTBench): The proposed benchmark's inclusion of both unstructured (e.g., story writing) and structured (e.g., code generation) tasks allows for a more robust and objective evaluation than benchmarks that rely solely on subjective creative tasks.\n- Strong empirical support: The authors conduct extensive experiments across a wide range of modern LLMs. The inclusion of attention trace visualizations provides compelling qualitative evidence that links internal model behavior to the observed volatility, strengthening the paper's claims."}, "weaknesses": {"value": "- Limited Applicability of SELB: The SELB method appears to be designed for tasks with explicit, predictable structural markers (e.g., \"Chapter 1, Chapter 2...\"). It is unclear how it would perform on long-form generation tasks that do not have such a clear, chapter-based structure, such as generating a single, long-form essay.\n- Potential for Quality Degradation: The SELB method forces a model to continue generating content until a length threshold is met. This could potentially lead to lower-quality, repetitive, or \"filler\" content within sections, even if the overall structure is maintained."}, "questions": {"value": "- How adaptable is the SELB framework to long-form generation tasks that lack a discrete, repetitive structure like chapters? Could the logic be modified to, for example, enforce length by preventing the generation of end-of-sequence tokens until a target length is met, and how might that affect quality? Perhaps on unstructured long-text benchmarks such as LongBench-Write in the LongWriter paper.\n- In your analysis of generation quality, did you investigate the possibility of increased repetition or the use of filler phrases within a single section as a result of forcing the model to meet a minimum length before it could generate the next section title?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aM5IFNd7GU", "forum": "C6WWMryELL", "replyto": "C6WWMryELL", "signatures": ["ICLR.cc/2026/Conference/Submission8616/Reviewer_dTnx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8616/Reviewer_dTnx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805571783, "cdate": 1761805571783, "tmdate": 1762920453468, "mdate": 1762920453468, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical issue of output volatility in Large Language Models (LLMs) —the inconsistency in length and content across multiple runs for the same prompt. It conducts a three-stage investigation: \"Benchmarking, Probing, and Mitigation\"."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Value of Problem Definition: The paper successfully identifies and defines a problem that is critical in practice but often overlooked in academic research: output volatility. This stability across runs is arguably more important for cost-control and system reliability than the quality of a single generation.\n- Systematic Benchmark: VOLTBench is a solid contribution. It is the first to center its evaluation on \"volatility\" and \"multiple sampling\". Its multi-dimensional design (structured/unstructured, multi-lingual, multi-complexity ) makes it more comprehensive and rigorous than existing long-text benchmarks.\n- Intuitive Probing: While the analysis of \"Attention Collapse/Instability\" may not be a strict causal proof , it provides an intuitive and reproducible internal mechanism explanation for the two most common failure modes (premature termination and section skipping ). This goes beyond mere phenomenological observation."}, "weaknesses": {"value": "- Questionable Generalizability: SELB is a \"brute-force patch\" based on hard-coded rules, rather than an improvement to the model's intrinsic long-range planning capabilities. It relies heavily on two parameters that must be manually preset for each specific task: $V_{title}$ (chapter title tokens) and $\\tau_{max}$ (minimum length). This severely limits its generalizability:\n  - Task Limitation: If a long-text task lacks explicit section markers (e.g., \"Write a 10,000-word essay on the societal impact of AI\"), SELB would be completely ineffective.\n  - Rule Fragility: The $V_{banned}$ (banned vocabulary) is also fragile. In some contexts, a banned phrase (e.g., \"I hope...\") might be a perfectly reasonable and necessary conclusion.\n- Benchmark-Method \"Collusion\": SELB's remarkable performance stems largely from VOLTBench being a testbed \"tailor-made\" for it. All prompts in Appendix contain explicit, predictable structural markers like #*# Title:, #*# Floor 1:, etc. This turns SELB's \"structural enforcement\" into a simple \"find-and-replace\" task. Its performance on non-cooperative, in-the-wild prompts is unknown."}, "questions": {"value": "- Local Coherence vs. Global Structure: What is the true impact of the $\\tau_{max}$ mechanism on local-level semantics? Could a \"softer\" enforcement strategy be designed, e.g., only allowing the chapter-boost to trigger after the model has generated a natural paragraph break?\n- The Root Cause of Failure: If attention collapse is just a symptom, what is the root cause? Is it the model losing its representation of the task instructions over a long context? Could representation analysis tools (like CKA) be used to track the fidelity of key constraint representations (e.g., \"number of chapters,\" \"total length\") during the generation process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qgNqMIlDl0", "forum": "C6WWMryELL", "replyto": "C6WWMryELL", "signatures": ["ICLR.cc/2026/Conference/Submission8616/Reviewer_4xJJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8616/Reviewer_4xJJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832894798, "cdate": 1761832894798, "tmdate": 1762920453049, "mdate": 1762920453049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies output volatility in long-form generation—i.e., the inconsistency of both length and structure across repeated runs on the same prompt. It contributes (1) VOLTBench, a heterogeneous benchmark that explicitly measures multi-sample stability across unstructured (story/diary/dialogue) and structured (code/JSON/LaTeX) tasks in EN/ZH; (2) attention-trace analysis diagnosing two failure signatures—Attention Collapse and Attention Instability; and (3) SELB, a lightweight decoding-time logit modification scheme combining structural boosting (enforcing section boundaries) and proactive failure suppression (banning filler/EOS prematurely). Reported results show large improvements in stability and length adherence (e.g., LVC down from 45.4% to ~14%, MLA up to ~78%), while maintaining quality (SCA ~100% on structured tasks; UCA ~87% on unstructured) across 5-run evaluations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear problem framing & novelty: Prior long-form work mostly evaluates single generations; the multi-sample stability focus and metrics (LSD/LVC/MLA; FAD/SCA/UCA) are useful and likely to influence evaluation practice. \n\n2. Neat benchmark design: Heterogeneous tasks, dual languages, scalable chapterized targets (up to very long outputs), and automatic checks via fine-grained constraints and execution-based verification. \n\n3. Evident empirical gains: On a 100-section setting, volatility is reduced (~69% LVC reduction vs LongWriter-8B), lengths better match targets (MLA ~78%), and quality is strong (SCA 100%, UCA ~86.7%)."}, "weaknesses": {"value": "1. Scope & generality of SELB: The structural prior assumes explicit, chapter-style sectioning with recognizable “title” tokens; it’s unclear how well this transfers to non-templated long-form tasks (e.g., essays, reports without section tokens) or to multilingual tokenization quirks. Ablations on more free-form schemas are needed.\n\n2. Fairness of baselines: Stronger inference-time baselines (e.g., length controllers, look-ahead/ITR, stop-entropy controls, repetition penalties tuned to parity) could be included to ensure SELB’s gains aren’t mostly from adding any simple structure prior."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gbHxk8xkwu", "forum": "C6WWMryELL", "replyto": "C6WWMryELL", "signatures": ["ICLR.cc/2026/Conference/Submission8616/Reviewer_fkNi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8616/Reviewer_fkNi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907207046, "cdate": 1761907207046, "tmdate": 1762920452588, "mdate": 1762920452588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}