{"id": "CvXrh2mKEi", "number": 20504, "cdate": 1758306889862, "mdate": 1759896974389, "content": {"title": "Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical Signatures", "abstract": "We introduce a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination using Lyapunov exponent-based labels, and self-supervised contrastive representation learning with NT-Xent loss. A convolutional backbone combined with a Transformer encoder captures spatial-temporal structure, while the dynamical task encourages sensitivity to nonlinear brain dynamics. This staged design mitigates interference between reconstruction and discriminative goals, improves stability across datasets, and supports reproducible training by clearly separating noise reduction from higher-level feature learning. Empirical studies show that our framework not only enhances robustness and generalization but also surpasses strong baselines and recent state-of-the-art methods in EEG decoding, highlighting the effectiveness of combining denoising, dynamical features, and self-supervised learning.", "tldr": "", "keywords": ["Multi-Task Learning", "Nonlinear Dynamics", "Dynamical System", "Chaos", "Contrastive Learning", "EEG Brain Signal", "Denoising Autoencoder", "RNN"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5aea6fd7343f96d99f5c2b53ed64cc7354cc69b1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "A neural decoding model that combines multitask learning with contrastive learning. As a part of tasks, predicting dynamicity signatures (chaos vs non-chaos) by Lyapunov Exponents is included and show improvements in decoding accuracy, suggesting the effectiveness of the proposed multitask training including the dynamics objective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Adoption dynamic theory in a multitask training setting for neural decoding which is shown effective.\n\n* Achieved state-of-the-art performance in motor imagery classification task using EEG."}, "weaknesses": {"value": "* While the decoding results are promising, the ideas of multitask training and contrastive learning using NT-Xent are already well-proven and frequently deployed methodologies in the field for years. Adopting the LE-based loss is an interesting and novel idea, but the major source of performance gain is driven by denoising as shown in Table 3. \n\n* Moreover, integrating dynamic state theory is interesting but the main results and discussions are mostly focused on the decoding performance. This can provide some potential novel interpretation of the modeling of EEG. I encourage to including more insightful analysis that can better leverage this idea to demonstrate scientific utility of the proposed method beyond improving performance."}, "questions": {"value": "No specific question."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JBQp38LcpY", "forum": "CvXrh2mKEi", "replyto": "CvXrh2mKEi", "signatures": ["ICLR.cc/2026/Conference/Submission20504/Reviewer_BLEy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20504/Reviewer_BLEy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760974296477, "cdate": 1760974296477, "tmdate": 1762933932550, "mdate": 1762933932550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a two-stage multitask learning framework for EEG signal analysis that integrates denoising, dynamical modeling, and representation learning. The multitask architecture incorporates three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination, and self-supervised contrastive representation learning. Experimental results demonstrate its superiority over recent state-of-the-art methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is clearly organized and easy to follow."}, "weaknesses": {"value": "- The contribution of this paper appears unclear to me. The multitask design is somewhat confusing, and further clarification is needed on the motivation for incorporating motor imagery (MI) classification into the original contrastive self-supervised representation learning framework. Moreover, the determination of whether signal dynamics are chaotic or non-chaotic through Lyapunov exponent estimation requires stronger theoretical justification and empirical evidence to demonstrate its effectiveness in capturing meaningful temporal dynamics and improving decoding performance.\n\n- The schematic illustration presented in Figure 1 lacks sufficient detail to clearly convey the proposed contributions. More explicit formulations are needed to describe how each loss term, such as L_constrastive is computed. The experimental evidence provided is also not sufficiently strong; additional datasets and evaluation metrics should be included to more convincingly demonstrate the superiority of the proposed multitask architecture. Furthermore, a more comprehensive analysis of the chaotic temporal dynamics is warranted."}, "questions": {"value": "- What is the role of the ConvNet illustrated in Figure 1? Is it integrated as part of the Transformer encoder or used as a separate feature extractor?\n\n- How is the NT-Xent loss computed, and what strategy is used to generate augmented views of the EEG signals?\n\n- How does discriminating between chaotic and non-chaotic trials contribute to improving behavioral decoding performance?\n\n- Considering that Lyapunov exponents (LE) can be directly estimated from the original signals, what is the necessity of fitting a specific model to perform this estimation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TDT7cZM9Ox", "forum": "CvXrh2mKEi", "replyto": "CvXrh2mKEi", "signatures": ["ICLR.cc/2026/Conference/Submission20504/Reviewer_V5Xr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20504/Reviewer_V5Xr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762091104118, "cdate": 1762091104118, "tmdate": 1762933931927, "mdate": 1762933931927, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a two-stage framework for EEG decoding that integrates denoising, multitask learning, and contrastive self-supervision. The use of Lyapunov exponent–based chaos detection is a novel approach that bridges nonlinear dynamical systems theory with deep learning, introducing an additional layer of interpretability to the model’s behavior. Experiments on the BCI2000 and BNCI Horizon datasets show steady improvements over strong baselines, and the ablation studies clearly highlight the value of each component in the overall design. The approach is technically solid and conceptually innovative, though the study would benefit from testing on a wider range of datasets and including details on training time and efficiency. Overall, this work effectively combines insights from neuroscience and machine learning to enhance EEG analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper demonstrates originality by introducing a combination of denoising, multitask learning, and contrastive self-supervision within a unified EEG decoding framework. \n\n* The incorporation of Lyapunov exponent–based chaos detection is particularly novel, as it bridges nonlinear dynamical systems theory with modern deep learning, an intersection rarely explored in this domain. \n\n* The architectural design is well-motivated. \n\n* The paper is clearly written, with a logical flow that makes complex concepts, such as Lyapunov analysis, accessible to a broader audience. \n\n* The proposed approach advances EEG signal modeling by improving both robustness and interpretability, and it has potential implications for neuroscience-inspired machine learning more broadly."}, "weaknesses": {"value": "* The experimental validation is limited to two datasets (BCI2000 and BNCI Horizon 2020), both focused on motor imagery, which constrains the generalizability of the results. \n\n* Including additional datasets, such as BCI Competition IV-2a, PhysioNet EEG Motor Movement, or emotion and clinical EEG corpora, would better demonstrate cross-domain robustness. \n \n* The paper does not report computational metrics such as training time, parameter count, or inference latency, which are important for assessing scalability and reproducibility. \n\n* The chaos detection task relies on Lyapunov exponent–derived labels rather than empirical ground truth, introducing potential circularity in evaluation. The authors could strengthen this aspect by validating chaos labels against known nonlinear EEG benchmarks (e.g., Bonn or CHB-MIT datasets).\n\n* The paper would benefit from more interpretability analysis, such as attention visualizations or feature importance studies, to better illustrate what the model learns about neural dynamics. \n\nAddressing these points would make the work more comprehensive, reproducible, and broadly convincing."}, "questions": {"value": "1. Could the authors elaborate on how consistent the Lyapunov exponent–based chaos/non-chaos labels are across subjects and datasets? For instance, what is the variability in label assignment when using RNN-derived Lyapunov exponents versus entropy-based clustering? Providing a quantitative agreement measure (e.g., Cohen’s κ or correlation) would clarify the stability of the labels.\n\n\n2. Do the authors expect the framework to generalize to other EEG paradigms, such as emotion classification or seizure detection?\n\n\n3. What are the training times and resource requirements for each stage (DAE pretraining and multitask Transformer)? A runtime comparison against baselines, such as EEGNet or DeepConvNet, would help readers assess the practical trade-offs between performance and complexity.\n\n\n4. How sensitive is the framework to the selection of augmentations and temperature parameters in the NT-Xent loss?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rR5fI8DRoW", "forum": "CvXrh2mKEi", "replyto": "CvXrh2mKEi", "signatures": ["ICLR.cc/2026/Conference/Submission20504/Reviewer_4QHr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20504/Reviewer_4QHr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762540283248, "cdate": 1762540283248, "tmdate": 1762933931531, "mdate": 1762933931531, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new framework for motor-related EEG decoding that is build on denoising autoencoders, multitask training (motor-related classification. chaotic vs non-chaotic discrimination and contrastive learning). They evaluate their hybrid convolutional-transformer-architecture trained in this way on two EEG motor-related datasets and report improved performance over competing decoding methods."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "*  Novel idea of using chaotic vs nonchaotic as a pretext task\n* ablation study to show effect of individual components\n* I found the writing to be fairly understandable"}, "weaknesses": {"value": "**Result inconsistencies**\n\nThis work proposes a fairly complicated two-stage multi-task architecture for EEG decoding. To justify the complexity of the pipeline, the empirical evaluation must be very rigorously done and show where the pipeline improves over simpler decoding pipelines. Unfortunately, there seem to be multiple fundamental errors that question the results, especially the reported results of other methods in the manuscript:\n\nIn Table 4, the \"best-effort extractions from literature\" are likely incorrect, at least for some cases. \nE.g., for [52] ShallowConvNet and DeepConvNet:\n* there had never been any evaluation on BCI2000. For BCIC IV Dataset 2a/2b reported metrics were accuracy and kappa, never F1. There was no LOSO or CV evaluation, but the results were evaluated within-subject following the official train-test split of those datasets. So it is entirely unclear how those results in the table were obtained\n\nIn general, there is also a confusion about BNCI and BCIC IV-2a/b.\nBNCI 2014-001 is BCIC IV 2a and BNCI 2014-002 is BCIC IV 2b.\nIn A.1 the authors mention both of them in addition to BCI2000, in 4.1 the authors write about \"**two** datasets [....] BCI 2000 [...] and  BNCI Horizon 2020 (004/008/009), with 9 subjects, 22 channels, and a sampling rate of 250 Hz\" which would be consistent with BCIC IV 2a, however then it is unclear to me how exactly they compute F1 for multi class case? The table caption \"Both data include left/right hand and foot MI.\" is again incosistent as none of BCIC IV 2a/b contain foot MI. The sentence \"Other CNN variants (e.g., SCCNet, EEG-TCNet) have reported strong results on BCI Competition IV-2a, though their performance on BCI2000 or BNCI Horizon 2020 remains untested.\" does not make sense, again as BNCI 2014-001 is BCIC IV 2a and BNCI 2014-002 is BCIC IV 2b.\n\nAlso, while an ablation is helpful, the small differences (e.g.  with or without contrastive learning) suggest using multiple seeds to further check the statistical significance of the differences.\n\nOverall, in my view, unfortunately these errors and inconsistenties question the entire reported results.\n\n**Autoencoder spectrum effects**\n\nRegarding the reported effects of the autoencoder on the spectrum:\n\"The DAE effectively suppresses high-frequency and non-physiological noise while preserving task-relevant spectral features, as demonstrated by the PSD plot.\"\nHigher frequencies between 50-90 (high-gamma) can also be task-informative in some EEG datasets, so this statement is not true in general. Also it then would be interesting to see a comparison of a pure lowpass below 40 Hz to the autoencoder."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "E6Mot1XTFi", "forum": "CvXrh2mKEi", "replyto": "CvXrh2mKEi", "signatures": ["ICLR.cc/2026/Conference/Submission20504/Reviewer_rqr5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20504/Reviewer_rqr5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762879040629, "cdate": 1762879040629, "tmdate": 1762933931066, "mdate": 1762933931066, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}