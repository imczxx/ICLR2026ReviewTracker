{"id": "FwVL5ckUdF", "number": 13485, "cdate": 1758218494729, "mdate": 1759897433715, "content": {"title": "A General Theoretical Paradigm to Understand Two Tower Recommendation Models", "abstract": "Production-grade recommender systems rely heavily on a large-scale corpus used by online media services, including Netflix, Pinterest, and Amazon. These systems enrich recommendations by learning users' and items' embeddings projected in a low-dimensional space with two tower models (two deep neural networks), which facilitate their embedding constructs to predict users' feedback associated with items. Despite its popularity for recommendations, its theoretical behaviors remain comprehensively unexplored. We study the asymptotic behaviors of the two tower model applied in two-stage recommenders that entail a strong convergence to the optimal recommender system. We establish certain theoretical properties and statistical assurance of the two tower recommender. In addition to asymptotic behaviors, we demonstrate that recommendation with two tower architecture attains faster convergence by relying on the intrinsic dimensions of the input features. Finally, we show numerically that the two tower recommender enables encapsulating the impacts of items' and users' attributes on ratings, resulting in better performance compared to existing methods conducted using synthetic and real-world data experiments.", "tldr": "", "keywords": ["Recommendation", "Collaborative filtering", "Deep learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f3fcff49fe9db036758e5accfbd5e4d860384e39.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a theoretical study of the two-tower recommender system model. The authors analyze the asymptotic behaviors of the model, focusing on its convergence to the optimal recommender system. They establish theoretical properties, including the relationship between the convergence rate and the inherent dimensionality of the input features. The study demonstrates that the two-tower model converges faster as the smoothness of the true model increases or the intrinsic dimensionality decreases."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides a theoretical analysis perspective of the two-tower recommender model, establishing key properties and convergence behaviors.\n2. The paper highlights the two-tower model's ability to address challenges like cold-start problems, offering insights into its effectiveness in real-world recommendation scenarios with both synthetic and real-world data.\n3. The paper introduces a novel approach to quantifying the convergence speed and robustness of two-tower models, contributing new statistical guarantees to the understanding of their performance."}, "weaknesses": {"value": "1. Does the convergence speed of the two-tower model depend on the specific architecture of the model itself?\n2. Convergence speed is influenced by various factors such as data, model parameters, and training time. Why is the inherent dimensionality of user and item features the primary focus in this study?\n3. How does the convergence speed of the two-tower model compare to other deep learning models or LLM-based models in terms of convergence rate? What factors can demonstrate that the two-tower model converges faster?"}, "questions": {"value": "The citation format seems to mix content with references, which affects readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "L693SwvscQ", "forum": "FwVL5ckUdF", "replyto": "FwVL5ckUdF", "signatures": ["ICLR.cc/2026/Conference/Submission13485/Reviewer_mrTr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13485/Reviewer_mrTr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826252826, "cdate": 1761826252826, "tmdate": 1762924102268, "mdate": 1762924102268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a theoretical framework to analyze the asymptotic behavior of two-tower recommendation models commonly used in large-scale recommender systems. The authors prove that under certain smoothness and boundedness assumptions, the two-tower model converges to the optimal recommender system and achieve explicit convergence rates in terms of approximation and estimation errors. The convergence rate depends on the Hölder smoothness of user/item embedding functions and the intrinsic dimensions of input features. Additionally, the paper complements theoretical results with synthetic and real-world experiments to demonstrate the performance and convergence trends of two-tower models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper provides a new perspective to analyze the approximation and convergence properties of two-tower models.\n\n2. The paper derives explicit convergence rates that depend on the smoothness of the target function and the intrinsic dimensionality of user and item feature spaces. \n\n3. The inclusion of empirical validation on synthetic and real-world datasets helps connect theoretical results to practical scenarios such as cold-start recommendation. The results show consistency with derived asymptotic behaviors."}, "weaknesses": {"value": "1. Limited perceived novelty for core ICLR audience: Two-tower recommendation models, while impactful in practice, belong to a niche within recommender systems and information retrieval. The main contribution is theoretical interpretation rather than a new learning paradigm. As a result, its impact may be underestimated by ICLR community than data mining venues.\n\n2. Mathematical presentation issues: It's interesting that some simple concepts (e.g., l2-norm in line 110) are formally defined while more complex objects like $\\epsilon$-balls, $ |\\cdot |\\_0 $ in line 111 and 123 are used without definition or intuition; notation is occasionally introduced after first usage (e.g., $k_{ui}$ appears in Eq.(2) but is defined in Eq.(3)), which shows structural inconsistencies; Several typos exist: e.g. $B_1$ in line 114, improper capitalization at line 149; overly complex notation with poor layout: lines 180–190 use highly dense notation and problematic formatting to describe what is essentially a standard gradient descent update. This creates unnecessary cognitive burden and reduces readability—even for technically strong readers.\n\n3. Misinterpretation of ranking metrics: The paper claims to provide theoretical guarantees for “ranking objectives” in 4.2.1, yet the analysis and experiments are primarily based on Top-k accuracy. However, Top-k metrics are classification-style metrics (whether the ground-truth item appears in the top k), rather than a true ranking metric. In recommender systems, ranking objectives more commonly refer to metrics that account for ordered relevance, such as NDCG, MRR, or MAP. Therefore, the paper’s claim of analyzing “ranking guarantees” is somewhat misleading, as it does not address position-sensitive ranking quality. This mismatch between theoretical objective and commonly accepted ranking metrics undermines the applicability of the theoretical results.\n\n4. Experiments insufficiently tied to core theory: The experiments illustrate the practical usefulness of the two-tower model but do not rigorously validate the core theoretical claims. In particular, no experiments quantify the effect of intrinsic dimension or smoothness on convergence, and key ablation/sensitivity analyses are missing. Hence, while functional, the experimental section lacks depth for an ICLR-level theoretical paper."}, "questions": {"value": "Please refer to Weakness. The reviewer strongly recommends that the authors substantially improve the presentation and clarity of the theoretical exposition — including notation consistency, definition of symbols, and mathematical layout — otherwise the theoretical contributions may not be fairly assessed by the community."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8VPXuTtQRl", "forum": "FwVL5ckUdF", "replyto": "FwVL5ckUdF", "signatures": ["ICLR.cc/2026/Conference/Submission13485/Reviewer_rH1A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13485/Reviewer_rH1A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990781967, "cdate": 1761990781967, "tmdate": 1762924101948, "mdate": 1762924101948, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the theoretical foundation of the two-tower model. It proves that the two-tower model’s approximation error and convergence are related to the intrinsic dimension and smoothness, suggesting its superiority in handling complex functions. Additionally, the theorem on ranking suggests that a pairwise loss can lead to good performance on a Top-K ranking task."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides solid theoretical proofs that are applied specifically to the two-tower model, which has been lacking this kind of formal backing .\n\n2. It proves the model's advantage comes from its performance scaling with the data's low intrinsic dimension, not its high nominal dimension. This explains why it works so well on sparse, high-dimensional data."}, "weaknesses": {"value": "1. The theoretical guarantees offer few actionable guidelines for real-world tasks. The key factors identified intrinsic dimension and smoothness are inherent properties of the *data*, not model hyperparameters that an engineer can easily measure or change.\n2. The experiments demonstrate that the two-tower model is superior to baselines like SVD++ and KNN. This are more likely to confirm a known result rather than to provide novel insights."}, "questions": {"value": "1. The synthetic experiments do not test different nominal dimensions. What is the effect of this?\n\n2. What is the relationship shown with the rating matrix sizes in the synthetic experiments? With different intrinsic dimensions, the results show different trends. What is the cause?\n\n3. What is the relationship between the theory and the cold-start problem? My understanding is that the cold-start capability is mainly based on the idea of covariates, not the theorems.\n4. What is the meaning of the shading in the experiment tables? It seems some better results from other models are not correctly shaded."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ASo8gES0AQ", "forum": "FwVL5ckUdF", "replyto": "FwVL5ckUdF", "signatures": ["ICLR.cc/2026/Conference/Submission13485/Reviewer_6buT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13485/Reviewer_6buT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762502762338, "cdate": 1762502762338, "tmdate": 1762924101662, "mdate": 1762924101662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}