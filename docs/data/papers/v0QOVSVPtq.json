{"id": "v0QOVSVPtq", "number": 25047, "cdate": 1758363486241, "mdate": 1759896736536, "content": {"title": "Exploring Diverse Generation Paths via Inference-time Stiefel Activation Steering", "abstract": "Language models often default to a narrow set of high-probability outputs, leaving their generation paths homogeneous and prone to mode collapse. Sampling-based strategies inject randomness but still struggle to guarantee diversity across multiple concurrent generation runs. We address this limitation by introducing STAR (**St**iefel-based **A**ctivation Steering for Diverse **R**easoning), a training-free, inference-time intervention method that transforms activation steering into an exploration engine. At each token, STAR collects the hidden activations of concurrent generation runs and optimizes multiple additive steering directions jointly on the Stiefel manifold. STAR maximizes the geometric volume of the steered activations, while the Stiefel manifold induces orthogonality of the steering interventions. This formulation explicitly promotes divergent activation vectors of concurrent generation runs, and implicitly promotes divergent generation trajectories. This manifold optimization formulation can be solved using a Riemannian gradient descent algorithm with convergence guarantees, but this algorithm is too time-consuming for real-time inference. To guarantee low latency, we further design a lightweight one-step update with an aggressive, closed-form stepsize. For test case generation and scientific discovery benchmarks, STAR consistently outperforms standard sampling methods, achieving greater diversity without sacrificing qualitative performance.", "tldr": "", "keywords": ["activation steering", "generation diversity", "manifold opimization"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4eb957af1cb78f43d0cbbcd5abb382f237f5c400.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies batch inference with the goal of maximizing diversity amongst the generated responses. The author's propose a training-free inference-time intervation method, cointed STAR, which modifies intermediate activations. Namely, for each of the N generations, STAR collects the hidden activations across each of the N generations and solves optimization problem to learn a set of perturbation vectors that when added to the activations, maximizes the volume of the corresponding set of N hidden states. The authors show that this optimization problem can be solved using a Riemannian gradient descent algorithm and provide convergence guarantees, along with a more loghtweight one-step update algorithm. Experiments using the one-step optimization algorithm across test-case generation and scientific discovery benchmarks show that this method outperforms standard sampling methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and organized. The authors do a good job of motivating the problem at hand, and I believe the problem studied is of interest to the ML community\n- The authors complement their experimental results with theory, proving the feasibility of their proposed optimization procedure."}, "weaknesses": {"value": "My biggest issue with this paper is its lack of clarity. I summarize my concerns below. \n\n- **Some of the algorithmic details were unclear to me**. For a particular layer, are the hidden states for all the tokens modified or just one token? Is steering done only once on a pre-determined layer (with the modified hidden states propagated forward)? Or, do you do steering at several different layers? How do you pick the layers for steering? \n\n- **The evaluation metrics are unclear to me**. In particular, the method proposed by the authors produces a collection of N responses. However, it seems to me that the metrics in Tables 1 and 2 are for specific responses? If so, how are these metrics aggregated across the N responses and shouldn't you be using a metric that evaluates the collection of N responses as a whole? Overall, the authors should make very clear whether the metrics in Table 1 and 2 are batch- or  individual-level. In my opinion, this is the biggest weakness, because the authors should be using a batch-level diversity metric (since that's what their method optimizes for) along with an individual-level quality metric. \n\nMy other concern is with the lack of comparisons to the related methods the authors summarize in Section 2. It would be great if the authors can explain why they didn't compare their method with these ones (and include this explanation in the final version)."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t7KUSY1fz1", "forum": "v0QOVSVPtq", "replyto": "v0QOVSVPtq", "signatures": ["ICLR.cc/2026/Conference/Submission25047/Reviewer_a1Ka"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25047/Reviewer_a1Ka"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760886881753, "cdate": 1760886881753, "tmdate": 1762943300390, "mdate": 1762943300390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a method to increase diversity in LLM generations. The proposed STAR approach optimizes a steering vector at inference time, trying to maximize the volume spanned by $N$ tokens at the same timestep. By repeating this procedure at each decoding step, STAR obtains diverse sequences which still preserve good quality. The authors propose to obtain the steering vectors by means of Riemannian optimization, also deriving a fast 1-step approach alternative. The experiments show that STAR is more effective than standard temperature-based sampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**S1:** I believe that studying diversity is somehow lacking in the current research efforts. The applications of \"diversity increase\" are underexplored, and could lead to improvements of generative models both at inference (reduce bias, increase creativity, etc.) and at training time. This work tackles the topic at its core, which is refreshing.\n\n**S2:** This work proposes to use steering to induce diversity. To the best of my knowledge, this is an unexplored application of steering, which I deeply appreciated. The proposed approach trying to maximize the volume, although having practical limitations, is of interest to the community and can spark new research on this topic. \n\n**S3:** The approach using Riemannian optimization to maximize volume while preserving the manifold of intervention vectors is sensible and well explained. I have suggested some clarifications, but overall I am confident about the proposed approach. \n\n**S4:** The text is well written and easy to follow. The mathematical notation is clean."}, "weaknesses": {"value": "**W1:** STAR applies to a single layer of the model by construction. This is a fundamental drawback in my opinion. First, the best layer must be found in advance, as the authors have done in Tables 3,4. Second, previous work has shown that intervening carefully on all layers is more effective ([Rodriguez et al. NeurIPS 2025](https://arxiv.org/abs/2503.10679)). Additionally, while being a common choice, intervening at the output of attention layers is less effective than intervening on the residual path. The latter is typically the choice when the intervention is only applied to 1 layer. I believe more discussion about the layer choice (beyond the experiment in Tables 3,4) is required, pointing out the pros/cons of the choices made. \n\nNB. Tables 3,4 are not referenced in the text.\n\n**W2:** STAR uses the same scaling for all tokens. I understand the underlying reason for that, scaling being hard to tune or adapt per token. It is true that the scaling is \"normalized\" by $||H||_2^2$ but still _fixed_ and not adaptive to what the generation requires. Indeed, it might happen that tokens don't need to deviate from each other at a specific time step. Have the authors considered some adaptive steering such as MERA ([Hedström et al., ICML 2025](https://arxiv.org/abs/2510.13290))? \n\nAdditionally, could $\\alpha$ be optimized together with $v_i$ in Eq. 2?\n\n**W3:** No samples are provided. As a reader, I was expecting a subjective analysis of the sentences obtained using sampling temperature, and using STAR. Also how do these sentences differ when $N$ increases. How different, and at the same time correct, they are from a subjective point of view? I encourage the authors to share generation samples, and include them in the manuscript. For example, I am really curious to see what are the generations for simple prompts like _\"A house\"_ while increasing $N$.\n\n**W4:** I encourage the authors to include generation timings of STAR compared to $N$ generations using standard temperature-based sampling. I believe this is a critical aspect that has been overlooked in the manuscript.\n\n**W5:** The experimental section is limited. I understand that it is hard to find suitable experiments for diversity (given how underexplored this area is). I may suggest leveraging the comment on L48: _For safety and alignment, a lack of diversity prevents us from discovering varied failure modes_. I believe this is an important aspect to tackle with methods like STAR. I think this work would benefit from having an experiment showing how increasing diversity reduces bias, or shows better performance for minority groups (eg. talks about different genders with more parity).\n\n---\n\n### **Recommendations:**\n\n> Please take the following as just recommendations, feel free to comment on them or pushback if you feel they are not justified.\n\n**R1:** I suggest the authors to emphasize why Riemannian optimization is useful in this setting, and which is the manifold we are trying to _preserve_ while optimizing. The latter is defined by the the constraing $V^{\\top}V=\\alpha I$, which might not be evident as the text is now. For the former, I defer to the authors' to complete, but probably commenting on Riemannian opt. being faster and better behaved than using Euclidean gradients + projections in this setting.\n\n**R2:** I also suggest the authors to run at least some test applying STAR at the residual path of some layer of choice, and compare to applying STAR at the attention output. With residual path I mean right after the sum with the residual connection. This is usually easier to capture as the input to the next Transformer block."}, "questions": {"value": "**Q1:** One aspect that I would like to discuss with the authors is the fact that STAR tries to maximize the volume spanned by the activation vectors of the $\\tau$-th token of $N$ sequences. Isn't this implying somehow that there is a temporal correspondence across sentences? Otherwise, always pushing for orthogonality and max volume at each timestep might lead to sub-optimal quality sequences, right? Do the authors have ideas on how to modify STAR so it takes the whole _trajectory_ (tokens for $t\\leq \\tau$) into account. Could this lead to more meaningful, and at the same time diverse, sequences?\n\n**Q2:** L201: _To encourage diversity between different generations, we require the steering vectors to be orthogonal with each other_\n\nIs this truly required? Do we need orthogonal tokens at each timestep to ensure diversity? For a bias related example, one could argue that diverse sentences are those that convey the same message, but using all possible choices of gender. This does not imply that all tokens must be orthogonal. Also, why would gender options be orthogonal? In my opinion, this assertion is very strong. Very interested in knowing the authors' arguments.\n\n**Q3:** L203: _A too big $\\alpha$ may break the meaningful information in $h_i$, leading to generation collapse._ \n\nUsing an unbounded scaling parameter for vector-based addition has been shown to not respect the activation distributions. Recent work by  [Rodriguez et al. ICLR 2025](https://arxiv.org/abs/2410.23054v1) showed that respecting distributions is key, allowing interpolation between original and intervened (linearly mapped) activations, thus having a bounded scaling between 0 and 1. In further work,  [Rodriguez et al. NeurIPS 2025](https://arxiv.org/abs/2503.10679) show how to do that with gradient descent. I suggest considering a steering approach similar to the provided works, effectively avoiding the scaling problem. I completely understand that this is a fundamental change in your work, so I am not directly asking for this, but feel the authors should at least discuss on how these approaches could improve their work.\n\n**Q4:** L206: In Eq.2 $\\alpha$ is a parameter set by the user? It might be read as it is optimized jointly with $v_i$, which is not after reading the rest of the paper. Maybe I would clarify how $\\alpha$ is chosen upfront. \nUpdate: after reading the full manuscript, I see $\\alpha$ is implicitly set by the user through $C$. I still believe that this aspect should be stated earlier on in the manuscript. \n\n**Q5:** L224: In algorithm 1, $\\alpha$ is required but never used. Consider removing it, or fixing the algorithm if $\\alpha$ was not included by mistake.\n\n**Q6:** The results in Table 2 show very close numbers across methods. Could the authors provide statistical significance for this experiment? Probably the standard deviation across 3-4 runs would be enough. This would help the reader understand the real benefit of each method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5SIPClFOkF", "forum": "v0QOVSVPtq", "replyto": "v0QOVSVPtq", "signatures": ["ICLR.cc/2026/Conference/Submission25047/Reviewer_ZBFD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25047/Reviewer_ZBFD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761585158986, "cdate": 1761585158986, "tmdate": 1762943299920, "mdate": 1762943299920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper explores methods for steering large language model activations at inference time, with the goal of diversifying reasoning trajectories. \nThe work is situated within the area of activation and steering vectors for LLMs. \nThe authors propose adding a learned steering vector to the output of an attention head, \nwith the vector being initialized and subsequently updated to minimize the objective described in Equation 2.\n\nIn Section 4, the paper introduces an initialization approach based on singular value decomposition (SVD), \nfollowed by refinement using Riemannian gradient descent. \nThis combination allows the model to identify meaningful steering directions while maintaining stability in optimization. \nIn Section 5, the authors further propose a simplified, single-step variant of the method, aimed at improving computational efficiency.\n\nThe experimental results compare the proposed approach against a single diffusion-based baseline, \nalthough the specific diffusion method used is not clearly specified. \nOverall, the paper presents an interesting and technically sound contribution to the growing field of activation steering, \nthough the evaluation setup could benefit from additional baselines and clarity regarding the comparison method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an important and timely topic—enhancing diversity in large language model reasoning. \n- The idea of using training-free steering vectors is particularly interesting, as it offers a lightweight and potentially generalizable approach to influencing model behavior without fine-tuning."}, "weaknesses": {"value": "- The evaluation is somewhat limited, relying primarily on a single “sampling” method as the baseline. Comparing only against one approach makes it difficult to assess the broader effectiveness of the proposed method. \n- Additionally, the reported results, while suggestive, are not particularly strong or conclusive. A more comprehensive experimental section would strengthen the paper’s empirical claims."}, "questions": {"value": "- Could the authors include comparisons with other existing steering methods to better contextualize their approach? \n- Additionally, have the authors considered testing their method against alternative diffusion-based approaches to provide a more complete evaluation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "GSFp51WrF6", "forum": "v0QOVSVPtq", "replyto": "v0QOVSVPtq", "signatures": ["ICLR.cc/2026/Conference/Submission25047/Reviewer_BKyG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25047/Reviewer_BKyG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653732786, "cdate": 1761653732786, "tmdate": 1762943299437, "mdate": 1762943299437, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an inference-time method (STAR) to diversify LLM generation by steering hidden activations from multiple concurrent decoding runs such that they maximise the geometric volume spanned by them. \n\nThe authors present a Riemannian gradient-descent solution with convergence guarantees to find the optimal steering vectors according to this objective. Based on the insight that it is too computationally heavy for acceptable latency, they propose a lightweight one-step update as approximation for real-time decoding. \n\nThe empirical evaluation is on TESTEVAL (test-case generation) using Gemma-1.1-2b-it and QWEN3-1.7B, as well as on LiveIdeaBench (scientific idea generation) using QWEN2.5-3B-INSTRUCT. STAR is compared to temperature sampling as a baseline for temperatures varying between 0.2 and 1.0. STAR significantly outperforms this baseline in these evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is very well and pedagogically written\n- The method is an inference-time method and as such training free, saving compute overhead and making it accessible \n- The theoretical part of the paper is strong, from guaranteeing existence of a solution to providing an algorithm for finding the optimal solution and deriving convergence guarantees\n- The paper proposes a practical algorithm to approximate the algorithm guaranteed to find the optimal solution with a more lightweight approach for real-time low latency decoding\n- Compared to the baseline that is included in the paper, the proposed method performs strongly\n\nMinor:\n- I appreciate the comment in lines 214 to 216 on the realism of the assumption necessary in Proposition 1."}, "weaknesses": {"value": "- One key element of the method, namely the constraint on $V$ to be an orthogonal matrix, is not motivated too well. Only in line 201 it briefly says “To encourage diversity between different generations, we require the steering vectors to be orthogonal with each other, i.e. […]”.  But why does this constraint ensure diversity? Is it not rather the orthogonality of the columns of the resulting $H + V$ that would maximise diversity and the objective? \n- In the experiments, the comparison to baselines is weak. \n    - The only baseline the proposed method is compared against in the experiments is temperature sampling. At the bare minimum, the 2 baselines/ablations that I would need to see to lean towards accept would be 1) adding random vectors of same magnitude $\\alpha$ (how much better than random additions are the directions you find?) 2) $v_j=(h_j - M_j * mean(H, dim=1))*s$, where $mean$ across $dim=1$ corresponds to mean across the $N$ vectors and $M_j$ is $-1$ when $H - mean$ is negative in said dimension and $+1$ when $H-mean$ is positive, while $s$ is scaling $v_j$ to be of magnitude $\\alpha$ (how much better than just pushing away from the mean is the proposed steering direction).   Ideally, it would also be good to see comparisons against other methods mentioned in lines 52-62, in particular also to a training based method among those mentioned in lines 59 - 60.  Another good baseline would be to compare to the objective of maximising variance between vectors $h_j$ rather than the volume. \n    - The only baseline that the model is compared against (temperature sampling) is only exploring temperatures between 0.2 and 1.0, even though in Table 1 for QWEN3-1.7B (all metrics) and in Table 2 for QWEN2.5-3B-INSTRUCT (all metrics except feasibility) have a positive trend for increasing temperature (in absolute terms and in relative terms to the proposed method). Higher temperatures should thus be tried to see if similar performance can be achieved through this. \n- Also, in the experiments only one model is evaluated for Section 6.2. As someone having worked on activation steering myself I have found that the effectiveness of steering methods can vary a lot by model family so would always advise to evaluate on at least 2 different models from different model families. Furthermore, weirdly enough the one model evaluated in Section 6.2 is different from the 2 models evaluated in Section 6.1, raising doubts about what the results would have looked like for the models evaluated on the other task. \n- Given that the authors put an emphasis on the need for the one-step update for smaller latency, a comparison of added latency in Section 6 would be good to characterise the trade-off between improved performance and (latency) cost of the proposed method over simple baselines such as temperature sampling\n\nMinor:\n- I would suggest using a different acronym than STAR, since there is a fairly well-known paper aiming to improve LLM generations with an almost identical acronym (*STaR: Self-Taught Reasoner - Bootstrapping Reasoning With Reasoning* by Zelikman et al. (2022)) \n- Typo: Line 217 is basically a repetition of lines 215/216 \n- Line 266/267: a small explanation why sufficient decrease prevents rank-deficiency would be helpful\n- More depth could be added to the discussion in Section 6.1, e.g. by commenting on the performance of the baseline (temperature sampling), e.g. why it catastrophically fails at the task for Gemma-1.1-2b-it (incl. why higher temperature does not increase coverage but rather decreases it after T=0.6) or by explaining the u-shaped performance of the proposed method wrt temperature for most metrics for Gemma-1.1-2b-it"}, "questions": {"value": "- Line 61: “[…] and their benefits can be fragile across domains” -> Source?\n- Line 66: “If multiple runs occupy nearly the same region in this space, surface-level stochasticity has little impact” -> Source? \n- Figure 1: How do the particularities of ending the generations work? Does one of the N candidate sequences have to output a EOS token or all of them simultaneously or is a sequence outputting the EOS token simply removed from the algorithm until every sequence eventually outputs an EOS token?\n- Section 3.1: Have the authors tried to other locations for their intervention, e.g, the residual stream that Panickssery et al. (2023) intervene on?\n- Section 3.2: How is the pre-determined layer $l$ chosen?\n- Algorithm 1, requirements: what is $\\mathbb{R}_{++}$? \n- Section 4: why do the authors resort to riemannian gradient descent if the retraction step is still necessary to ensure $V_{k+1}$ is feasible? Could you not do some sort of projected gradient descent using the Euclidean gradient directly, i.e. moving a step along the Euclidean gradient and then projecting back to the manifold of feasible solutions?\n- Theorem 1: is a Riemannian gradient of 0 a necessary condition for a minimum of the objective function? Maybe a small comment on this for readers unfamiliar with Riemannian gradient descent could be helpful"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "52VqBHwork", "forum": "v0QOVSVPtq", "replyto": "v0QOVSVPtq", "signatures": ["ICLR.cc/2026/Conference/Submission25047/Reviewer_D4n2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25047/Reviewer_D4n2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25047/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761669927691, "cdate": 1761669927691, "tmdate": 1762943299062, "mdate": 1762943299062, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}