{"id": "MxR3uzejdO", "number": 21587, "cdate": 1758319308878, "mdate": 1759896913674, "content": {"title": "DiBS-MTL: Transformation-Invariant Multitask Learning with Direction Oracles", "abstract": "Multitask learning (MTL) algorithms typically rely on schemes that combine different task losses or their gradients through weighted averaging. These methods aim to find Pareto stationary points by using heuristics that require access to task loss values, gradients, or both. In doing so, a central challenge arises because task losses can be arbitrarily, nonaffinely scaled relative to one another, causing certain tasks to dominate training and degrade overall performance. A recent advance in cooperative bargaining theory, the Direction-based Bargaining Solution ($\\texttt{DiBS}$), yields Pareto stationary solutions immune to task domination because of its invariance to monotonic nonaffine task loss transformations. However, the convergence behavior of $\\texttt{DiBS}$ in nonconvex MTL settings is currently not understood. To this end, we prove that under standard assumptions, a subsequence of $\\texttt{DiBS}$ iterates converges to a Pareto stationary point when task losses are possibly nonconvex, and propose $\\texttt{DiBS-MTL}$, a computationally efficient adaptation of $\\texttt{DiBS}$ to the MTL setting. Finally, we validate $\\texttt{DiBS-MTL}$ empirically on standard MTL benchmarks, showing that it achieves competitive performance with state-of-the-art methods while maintaining robustness to nonaffine monotonic transformations that significantly degrade the performance of existing approaches, including prior bargaining-inspired MTL methods.", "tldr": "We propose a multitask learning algorithm invariant to monotonic nonaffine transformations inspired from cooperative bargaining theory.", "keywords": ["Multitask Learning", "Cooperative Game Theory", "Centralized Bargaining Theory"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/75265871c09fce74b922d0b6a8104ca2659ee6d9.pdf", "supplementary_material": "/attachment/b115d3db4a2a7f51f0d16135ee12526527ffe5c4.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces DiBS-MTL, a new multitask learning (MTL) method based on the Direction-based Bargaining Solution (DiBS). The method is invariant to monotonic non-affine transformations of task losses, differently from previous works on MTL. The authors extend DiBS to nonconvex MTL settings and theoretically prove that a subsequence of its iterates converges to a Pareto stationary point. They then propose a practical and efficient approximation that updates parameters according to the normalized sum of task gradients. Empirical results are provided for the NYU-v2 and MT10 benchmarks. DiBS-MTL matches the performance of baselines. The paper also presents synthetic and engineered examples to demonstrate the methodâ€™s invariance to monotone transformations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and easy to read.\n- The paper provides a theoretical contribution by proving the convergence of DiBS under nonconvex losses.\n- The proposed approximation (DiBS-MTL) is fairly efficient and simple, while maintaining the invariance property."}, "weaknesses": {"value": "I generally like the paper, it is well written, theoretically grounded, and quite elegant. However, I have three main issues:\n1. Approximation vs. theoretical derivation: The proposed single-step DiBS-MTL approximation appears too strong and far from the exact theoretical derivation of DiBS. It is unclear whether this approximation maintains the proven convergence properties. The paper provides no theoretical justification or formal link between the full Multi-step DiBS-MTL and its approximation, beyond an empirical comparison on a low-dimensional synthetic example. This illustrative example does not reflect realistic MTL behavior. As a result, it remains uncertain how the theoretical motivation and convergence guarantees carry over to the practical version actually used in experiments. Is it possible to provide a comparison on a larger-scale benchmark (even with a small number of DiBS steps)?\n1. Motivation for invariance to monotone transformations: The motivation for focusing on invariance to monotone non-affine transformations is interesting and well-articulated, but it should be better supported with real-world evidence. Currently, the usefulness of this property is demonstrated only on synthetic and engineered examples (modified MT10), rather than on natural or widely used benchmarks where such transformations occur in practice.\n1. Empirical evaluation is too limited and weak: At its current state, the empirical evidence for the effectiveness of DiBS-MTL is insufficient.\n    - The paper reports results on only two datasets (NYU-v2 and MT10). I suggest adding additional common MTL benchmarks, such as QM9, Cityscapes, or CelebA, to strengthen the empirical scope.\n    - The baseline coverage is limited. For NYU-v2, only NashMTL (2022) and FAMO (2023) are recent, strong baselines; others are relatively older and less strong. The authors should include more modern MTL approaches such as FairGrad, CAGrad, IMGrad, or DB-MTL. The MT10 evaluation is even more limited, with only a single recent strong baseline (which also achieves better performance compared to the proposed approach).\n    - Finally, the reported results show that DiBS-MTL performs comparably to existing methods but does not significantly improve over them on any benchmark. Combined with the limited experimental coverage and limited baselines, this makes the empirical evidence inconclusive regarding the claimed advantages and effectiveness of the approach."}, "questions": {"value": "- Could you provide a more detailed analysis of the computational complexity of DiBS-MTL, especially its scaling with the number of tasks? How does its runtime compare to recent gradient-based approaches beyond the small-scale runtime figure reported?\n- The update rule depends directly on the step-size parameter $\\epsilon$, but its value and tuning strategy are not reported. How was it selected in your experiments, and how sensitive is performance to this choice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BwKSeLH5fs", "forum": "MxR3uzejdO", "replyto": "MxR3uzejdO", "signatures": ["ICLR.cc/2026/Conference/Submission21587/Reviewer_vr8R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21587/Reviewer_vr8R"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760729058237, "cdate": 1760729058237, "tmdate": 1762941846171, "mdate": 1762941846171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose to adapt a recently proposed method named DiBS for MTL in convex settings to general MTL problems. The main motivation for that is that DiBS is invariant to monotonic non-affine transformation, making it less susceptible to arbitrary scaling of the loss values. The authors first show a convergence guarantee to a Pareto stationary point for DiBS under standard SGD conditions. Then they apply DiBS to MTL under a bargaining formulation and present an efficient version of their method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Showing convergence to a Pareto stationary point asymptotically for the proposed approach under minimal and reasonable assumptions.\n* Present an efficient extension of DiBS to MTL.\n* Good empirical results on the NYU dataset.\n* Unlike the compared approaches, the proposed approach was shown to be resilient to non-affine scalings."}, "weaknesses": {"value": "* Regarding the method:\n  - The novelty of this paper is limited. The main novel contribution of this paper, if I understand correctly, is the adaptation of DiBS to general MTL settings, namely DiBS-MTL.\n  - If I understand correctly, the shared update direction is found by summation over the normalized gradients. However, while it is invariant to scaling, it loses information about the magnitude, which can be important at different stages of the learning procedure. Furthermore, it is a special case of Nash-MTL in which one assumes that all the gradients are orthogonal to each other. Perhaps I am missing something here, and I will be happy if the authors can clarify that point.\n  - Related to the previous bullet, suppose we have two tasks with collinear gradients in opposite directions. The shared update direction will probably not be useful for any of them and may cause slow convergence. Taking inspiration from [1] where uncertainty was used, how does the authors suggest to handle that?\n* The experimental comparisons and grounding in the MTL literature are severely lacking:\n  - Missing references and *comparisons* to recent MTL studies, non-exhaustive list [1-4]. These papers should be addressed and compared to where appropriate. \n  - The method was also not compared to recent and leading methods on common MTL benchmarks, such as CityScapes, QM9, and UTKFace.\n  - Missing a proper comparison (on a non-syntactic benchmark) between Multi-step DiBS-MTL and DiBS-MTL to evaluate the strengths and limitations of each approach.\n  - The dynamics of the loss weights across training are not clear. A proper analysis (even an empirical one) is missing.\n  - Implementation details are missing. What are the hyperparameters of the method besides $\\epsilon$? How sensitive is the method to these hyperparameters? Is there a special schedule for the learning rate?\n* In my opinion, an algorithm of the method is missing to help better understand the update rule.\n\n[1] [1] Achituve, I., Diamant, I., Netzer, A., Chechik, G., & Fetaya, E. (2024, July). Bayesian uncertainty for gradient aggregation in multi-task learning. In Proceedings of the 41st International Conference on Machine Learning (pp. 117-134).  \n[2] Senushkin, D., Patakin, N., Kuznetsov, A., & Konushin, A. (2023). Independent component alignment for multi-task learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 20083-20093).  \n[3] Dai, Y., Fei, N., & Lu, Z. (2023, July). Improvable gap balancing for multi-task learning. In Uncertainty in Artificial Intelligence (pp. 496-506). PMLR.  \n[4] Xiao, P., Dong, C., Zou, S., & Ji, K. (2025). LDC-MTL: Balancing Multi-Task Learning through Scalable Loss Discrepancy Control. arXiv preprint arXiv:2502.08585."}, "questions": {"value": "- Regarding DiBS-MTL, it seems that $\\Delta \\theta$ grows with the number of tasks. How do you control its magnitude? Would it be more sensible to take the mean instead of the sum? If so, how does that affect the theory?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CTHKbPz9id", "forum": "MxR3uzejdO", "replyto": "MxR3uzejdO", "signatures": ["ICLR.cc/2026/Conference/Submission21587/Reviewer_Uctf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21587/Reviewer_Uctf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761681770276, "cdate": 1761681770276, "tmdate": 1762941845876, "mdate": 1762941845876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DiBS-MTL, a method that computes a bargaining solution based solely on gradient direction. It effectively addresses the issue of varying loss scales, which can negatively influence the performance of current MTL methods. The paper also provides a convergence analysis in the nonconvex MTL setting, showing that the proposed method converges to a Pareto stationary point. Experiments on common MTL benchmarks demonstrate the effectiveness and robustness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The comparisons of transformed loss functions are interesting (Figure 2, Figure 3); they clearly show that DiBS-MTL is more robust than other baselines.\n2. Theoretical analysis is provided to demonstrate that DiBS-MTL converges to a Pareto stationary point. Additionally, extensive experiments have been conducted to show that DiBS-MTL performs comparably to existing baselines."}, "weaknesses": {"value": "1. The theoretical analysis is based on the multi-step DiBS-MTL (Line 229-233), but in practice, the DiBS-MTL uses a single-step approximation. There should be a gap. It would be helpful if the theoretical analysis could account for the approximation error.\n\n2. The practical DiBS-MTL reduces to the average of normalized task gradients, which is not particularly novel. The comparison between multi-step DiBS-MTL and single-step DiBS-MTL (Figure 2 vs Figure 5) is not sufficient. I would like to see more comparisons on real MTL benchmarks, such as Cityscapes, NYU-v2, and MT10, covering both performance and running time. \nFrom the current result, it is difficult to determine whether the observed improvement comes from only gradient normalization or the DiBS framework. Additionally, it would be informative to evaluate how the baselines perform when using normalized gradients.\n\n3. For DiBS-MTL (Line 237-240), there is a term $\\epsilon$. How to set its value in practice? Are there any sensitivity analyses? Or is it absorbed into the learning rate?\n\n4. The results shown in Table 1 are not promising enough. The baselines are too old, and many recent methods are not included."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bRmpWdTM0U", "forum": "MxR3uzejdO", "replyto": "MxR3uzejdO", "signatures": ["ICLR.cc/2026/Conference/Submission21587/Reviewer_wQnK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21587/Reviewer_wQnK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941275839, "cdate": 1761941275839, "tmdate": 1762941845574, "mdate": 1762941845574, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents DiBS-MTL, a method for multitask learning (MTL) designed to be robust to monotonic, non-affine transformations of task loss functions. Existing challenges in MTL arise because different task losses can be scaled differently, which may cause one task to dominate the others. DiBS-MTL uses only normalized gradients and a Direction-based Bargaining (DiBS) approach, enabling the identification of Pareto stationary points while maintaining invariance to changes in loss scaling.\n\nAdditionally, the paper shows that DiBS-MTL asymptotically converges to a Pareto stationary point even when task losses are non-convex, and it presents the mathematical mechanism of the method. The work includes experiments on two-dimensional illustrative examples to demonstrate balanced objectives, as well as applications in computer vision and multitask reinforcement learning benchmarks. Moreover, the paper details the adaptation of DiBS to existing bargaining frameworks and efficient computation of normalized gradients."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper introduces robustness to monotonic non-affine task loss transformations, representing a key and distinctive contribution.\nThe paper establishes convergence guarantees for DiBS in non-convex settings.\nThe paper demonstrates how DiBS can be naturally integrated with multitask learning.\nThe paper proposes a single-step approximation of DiBS-MTL, offering a computationally practical solution."}, "weaknesses": {"value": "The paper tackles a relevant problem. However, the novelty of the problem itself appears somewhat incremental, which may limit the overall impact of the contribution for the community.\nSome experiments are missing, as also acknowledged by the authors."}, "questions": {"value": "Please address the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ss3Fpzn7ui", "forum": "MxR3uzejdO", "replyto": "MxR3uzejdO", "signatures": ["ICLR.cc/2026/Conference/Submission21587/Reviewer_Db7p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21587/Reviewer_Db7p"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952739167, "cdate": 1761952739167, "tmdate": 1762941845238, "mdate": 1762941845238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}