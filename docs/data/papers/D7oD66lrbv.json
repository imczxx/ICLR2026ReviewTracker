{"id": "D7oD66lrbv", "number": 19589, "cdate": 1758297488078, "mdate": 1763006150943, "content": {"title": "OmniDFA: A Unified Framework for Open Set Synthesis Image Detection and Few-Shot Attribution", "abstract": "AI-generated image (AIGI) detection and source model attribution remain central challenges in combating deepfake abuses, primarily due to the structural diversity of generative models. \nCurrent detection methods are prone to overfitting specific forgery traits, whereas source attribution offers a robust alternative through fine-grained feature discrimination. \nHowever, synthetic image attribution remains constrained by the scarcity of large-scale, well-categorized synthetic datasets, limiting its practicality and compatibility with detection systems. \nIn this work, we propose a new paradigm for image attribution called open-set, few-shot source identification. \nThis paradigm is designed to reliably identify unseen generators using only limited samples, making it highly suitable for real-world application. \nTo this end, we introduce OmniDFA (Omni Detector and Few-shot Attributor), a novel framework for AIGI that not only assesses the authenticity of images, but also determines the synthesis origins in a few-shot manner. \nTo facilitate this work, we construct OmniFake, a large class-aware synthetic image dataset that curates $1.17$ M images from $45$ distinct generative models, substantially enriching the foundational resources for research on both AIGI detection and attribution. \nExperiments demonstrate that OmniDFA exhibits excellent capability in open-set attribution and achieves state-of-the-art generalization performance on AIGI detection. \nThe integration of the new task enhances detection performance and offers an efficient and scalable path toward practical adoption.", "tldr": "This paper propose a large-scale synthetic image datasets and a novel deepfake detector.", "keywords": ["Deepfake Detection", "Synthetic Image Detection", "Few-Shot Learning", "Image Attribution"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/ced9e8b0e7987f7e99ee650f41556343b3334f2d.pdf", "supplementary_material": "/attachment/d5695ee8100f383cec81b91deb1116f3b48aa9b4.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes an AIGC detection method from the few-shot perspective. It aims to provide additional category information from the generator’s viewpoint and uses supervised contrastive learning for optimization. Furthermore, based on the reorganization of existing datasets, the OmniFake dataset is constructed. Experiments on this dataset demonstrate certain advantages over existing works."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- It reorganizes existing datasets to form the OmniFake dataset.\n- It uses contrastive learning to characterize model-specific artifacts and integrates low- and high-level features to build the OmniDFA detector.\n- It demonstrates certain effectiveness on datasets such as OmniFake and GenImage."}, "weaknesses": {"value": "- The claim in Contribution 1 that \"few-shot identification as a previously unexplored task\" lacks sufficient literature review. Exploring AIGC detection from the few-shot (or open-set) perspective is not a first attempt. For example, the work \"Raising the bar of AI-generated image detection with CLIP\" was presented at CVPR'24.\n\n- The term \"Distinct\" in Table 1 is highly imprecise. What defines a \"distinct architecture\"? Does a difference in model parameter count make an architecture \"distinct\"? Or do architectures with similarities (e.g., ResNet-18 and ResNet-50) belong to the \"same architecture\"? Why does the proposed OmniFake dataset cover 45 \"distinct\" architectures while other methods are not considered to involve \"distinct\" ones? Additionally, the fake images in the OmniFake dataset are sourced from existing datasets such as GenImage and WildFake (as stated in Line 150), yet the authors classify GenImage and WildFake as non-\"Distinct\" in Table 1. Finally, since the data in OmniFake is merely a reorganization of existing datasets, it cannot be regarded as a new dataset. Thus, the contribution of the constructed OmniFake dataset is overstated, and the comparison with existing datasets is inaccurate.\n\n- Insufficient technical innovation:\n(1) Extracting low- and high-level features is a commonly used approach, but the paper fails to explain the necessity of adopting this method and its connection to multiple categories. (2) There is no reasonable explanation for why images generated by different architectures possess distinct forensic traces and thus are opposed to each other in the contrastive loss. What if some architectures generate identical traces? The use of contrastive loss lacks a valid rationale, and the paper does not conduct an in-depth exploration of the correlation between the fake image space and its original generation architecture. (3) Moreover, Sections 3.2 and 3.3 simply adopt existing contrastive loss and center loss without making effective improvements tailored to the AIGC detection task.\n\n- Since the OmniFake dataset explicitly includes GenImage during its construction, why is the detection of GenImage classified as zero-shot in Table 4? Additionally, in Table 4, the comparative algorithms (e.g., CNNSpot and UnivFD) and the proposed method are trained on different datasets; comparing them together here is meaningless.\n\n- From the results in Fig. 5, removing the local branch has no impact on the AP metric. Given this, what is the motivation for using the local branch as described in Section 3?\n\n- In Fig. 1, the borders of \"in set\" and \"real\" are blue and green respectively, which are difficult to distinguish."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "TJ6QDLdRtP", "forum": "D7oD66lrbv", "replyto": "D7oD66lrbv", "signatures": ["ICLR.cc/2026/Conference/Submission19589/Reviewer_eKfg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19589/Reviewer_eKfg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829977426, "cdate": 1761829977426, "tmdate": 1762931458038, "mdate": 1762931458038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "X9eJrVEmAw", "forum": "D7oD66lrbv", "replyto": "D7oD66lrbv", "signatures": ["ICLR.cc/2026/Conference/Submission19589/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19589/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763006149978, "cdate": 1763006149978, "tmdate": 1763006149978, "mdate": 1763006149978, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OmniDFA, a unified framework for both AI-generated image (AIGI) authenticity detection and open-set few-shot source attribution. The authors further provide OmniFake, a large-scale and category-aware synthetic image dataset covering 45 generative models across various architectures. OmniDFA employs a dual-path feature extractor to capture local and global visual signals, along with contrastive learning and a sphere center loss to improve discrimination. Experiments demonstrate superior performance over existing approaches on detection and attribution tasks, particularly under zero-shot and few-shot settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The OmniFake dataset is a meaningful contribution that fills a gap in large-scale, category-aware synthetic image benchmarks. It includes a diverse set of 45 generative models, enabling more rigorous investigation into model-specific attribution. This dataset will likely benefit future research in both AIGI detection and source tracing.\n- The integration of authenticity detection with open-set, few-shot attribution in a single framework is practically impactful. This unified approach aligns well with real-world forensic needs where both detection and model tracing are required. It reduces pipeline redundancy and improves applicability compared to prior work focusing on one task only.\n- The model consistently outperforms competitive baselines across multiple benchmarks, including zero-shot settings on GenImage and Chameleon. The robustness analysis further highlights resilience to image compression and blur within reasonable ranges. These results suggest that the framework generalizes well and holds practical promise for deployment in unconstrained environments."}, "weaknesses": {"value": "- The dual-path feature design for capturing low-level and high-level features is conceptually incremental, as similar multi-scale hybrid modeling has been employed in prior forensics and vision models. The paper does not sufficiently justify why this design is uniquely effective for AIGI detection and attribution. A deeper comparative ablation against more advanced multi-scale architectures (e.g., Swin variants, multi-level ViT) would strengthen the novelty claim\n- The use of contrastive learning combined with sphere center loss seems effective but lacks theoretical explanation tailored to AIGI properties. Center loss is not new and has been widely used in face recognition and metric learning, thus requiring clearer justification for its necessity and superiority here. Additional experiments comparing with alternative losses (e.g., ArcFace, triplet loss, prototype-based loss) would improve the contribution.\n- Few-shot and open-set attribution is a key claim, yet comparisons to state-of-the-art few-shot or OOD/meta-learning methods are missing. The evaluation lacks analysis on how performance scales with the number of novel classes and number of shots beyond the limited scenarios shown. Including baselines such as Prototypical Networks, Matching Networks, or OOD detection methods would make the attribution claim more convincing."}, "questions": {"value": "- Does the dual-path design offer clear advantages over more principled multi-scale feature extractors such as hierarchical ViT or feature pyramids? Can you provide comparisons?\n- Why was center loss chosen instead of more advanced metric-learning losses (e.g., ArcFace, triplet, prototypical loss)? What specific property of AIGI data makes center loss preferable?\n- Can you provide results on attribution performance as the number of unseen generators increases or number of shots decreases?\n- How robust is the attribution component of OmniDFA to real-world perturbations beyond JPEG compression and Gaussian blur？\n- The baselines used in Table 3 and Table 4 are not aligned, which makes it difficult to directly compare the results across settings. Could the authors clarify the criteria for selecting different baseline methods for these experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "kwF12fHhMH", "forum": "D7oD66lrbv", "replyto": "D7oD66lrbv", "signatures": ["ICLR.cc/2026/Conference/Submission19589/Reviewer_NR7M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19589/Reviewer_NR7M"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984820865, "cdate": 1761984820865, "tmdate": 1762931457581, "mdate": 1762931457581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OmniDFA, a unified framework for open-set AI-generated image detection and few-shot source attribution, targeting the practical challenge of identifying synthetic content from previously unseen generative models with limited reference samples. To support this, the authors construct OmniFake, a large-scale, class-aware dataset comprising images from distinct generative models and a matching set of real images. OmniDFA employs a dual-path architecture with supervised contrastive learning and center loss to achieve strong generalization for both detection and attribution tasks. Extensive experiments verify the efficiency of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper introduces the open-set few-shot source attribution task, exploring the attribution of unknown models under few-shot conditions, framing a practical and scalable challenge that better reflects real-world needs compared to closed-set or naive open-set rejection.\n\n2. The authors introduce OmniFake, a comprehensive and diverse synthetic image dataset capturing structural heterogeneity across 45 generator categories, supporting the real-world attribution scenarios.\n\n3. The paper employs a dual-stream detection model, which enhances the extraction of image source attribution features by preserving global semantic content and maintaining local details. Ablation studies validate the effectiveness of this module."}, "weaknesses": {"value": "1. The literature review in this paper is insufficient, lacking citations of recent work on open-set source attribution methods, e.g., POSE (Yang et al. CVPR 2023). Furthermore, the experimental comparisons omit state-of-the-art open-set zero-shot source attribution approaches.\n\n2. The experimental comparison settings are unfair. For example, in Table 4, other methods are trained on a single type of generated data, whereas the proposed method is trained on data from multiple models. Therefore, the performance improvement does not convincingly demonstrate the effectiveness of the proposed approach.\n\n3. The authors have an incorrect definition of the source attribution task. In practical scenarios, the task should include tracing models that have been fine-tuned from the same base model but with different LoRA adaptations. However, the dataset constructed in this paper does not encompass such scenarios, resulting in an incomplete formulation of the source attribution problem."}, "questions": {"value": "1. Can the proposed method perform source attribution when dealing with the same model architecture but different LoRA adaptations, and to what extent would the attribution results be affected by factors such as random seeds?\n\n2. In the zero-shot binary classification task, if other methods were also trained on multi-model data, how much would their generalization performance improve, and how would this compare with the proposed approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "URPz3eT1AJ", "forum": "D7oD66lrbv", "replyto": "D7oD66lrbv", "signatures": ["ICLR.cc/2026/Conference/Submission19589/Reviewer_sa51"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19589/Reviewer_sa51"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19589/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985955131, "cdate": 1761985955131, "tmdate": 1762931457081, "mdate": 1762931457081, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}