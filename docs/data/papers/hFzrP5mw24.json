{"id": "hFzrP5mw24", "number": 157, "cdate": 1756729835881, "mdate": 1759898273825, "content": {"title": "What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging", "abstract": "State-of-the-art vision-language models (VLMs) suffer from a critical failure in understanding negation, often referred to as affirmative bias. This limitation is particularly severe in described object detection (DOD) tasks. To address this, we propose two primary contributions: (1) a new dataset pipeline and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a dataset constructed with a systematic chain-of-thought (CoT) and VQA-based pipeline to generate high-quality, instance-grounded negation data. Second, we propose NegToMe, a novel text token merging module that directly tackles the architectural cause of affirmative bias. NegToMe fundamentally addresses the structural loss of negation cues in tokenization, grouping them with attributes into coherent semantic phrases. It maintains correct polarity at the input level, enabling robust negation understanding even with limited data. For instance, to prevent a model from treating the fragmented tokens \"not\" and \"girl\" as simply \"girl\", NegToMe binds them into a single token whose meaning is correctly distinguished from that of \"girl\" alone. This module is integrated with a parameter-efficient and strategic LoRA fine-tuning approach. Our method significantly improves performance on challenging negation benchmarks with a lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval and demonstrating generalization to SoTA VLMs. This work marks a crucial step forward in addressing negation understanding for real-world detection applications.", "tldr": "Enhances vision-language models' negation understanding in object detection through a novel dataset built with chain-of-thought reasoning and negation-aware token merging techniques.", "keywords": ["Vision Language Model", "Negation Understanding", "Affirmative Bias", "Described Object Detection", "Chain-of-Thought Reasoning", "Token Merging"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f8f76eb5e84e1d1cbe613e99b7846aa25ce1dc36.pdf", "supplementary_material": "/attachment/ddd33eb6c2bc0d29c48dfdc96727c9bece768c7a.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses an under-explored limitation of VLMs: the inability to correctly handle negation. The authors introduce two key contributions:\n\n+ COVAND, a systematically generated dataset focusing on negation through a chain-of-thought (CoT) reasoning and VQA-based alignment pipeline, producing region-grounded caption pairs that explicitly encode presence/absence attributes.\n\n+ NEGTOME, a token merging method that binds negation cues  to their associated scope (usualy nouns), to increase model attention to negation.\n\nUsing LoRA fine-tuning, the approach significantly improves negation understanding across multiple negation-focused object detection benchmarks (e.g., +10.8 NMS-AP on OVDEval, +7.2 mAP on the D3 absence subset).\n\nOverall the paper is well-written, method is intuitive, and experiment is sound, but may not have a broader impact beyond negation understanding (or similar types of linguistics phenomenon) as it is hard to apply this method to the default training pipeline of VLM/LLM. Below I detailed some concerns that I hope the authors can clarify further."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles an underexplored yet fundamental issue in VLM. The proposed method include both data (COVAND) and architectural (NEGTOME) innovation, with clear ablation to show the contribution of each. \n- Both the dataset creation pipeline and token merging method can potentially be extended to other linguistics phenomena (quantifier, hedging).\n- Experiments are well conducted with good empirical results showing substantial improvement over baselines."}, "weaknesses": {"value": "A general concern is on overlap between COVAND and the evaluation datasets:\n+ W1: If I understand correctly, COVAND and D3, OVDEval follow similar pattern in their captions (e.g. paired caption of X with Y/ X without Y), if they also have the same distribution of object types, would the gains be from training from more in-domain data rather than actually understanding negation? The task evaluated in 4.4 is image captioning from COCO and again may overlap with Flickr30k. \n\n+ W2: ...Each caption includes negation cues such as “no”, “not”, “never”, “without”, the prefix “un-”, or the contraction “n’t”. The cue list is open to keep language natural and diverse...: statistics on negation cue distribution is needed to show that the generations are diverse. I'm skeptical that the LLM is able to generate diverse patterns of negations if we don't explicitly include a list of cues. A small suggestion is to use existing taxonomies of negation to ensure we generate a diverse and systematic dataset.\n\nRelated work seems limited. Perhaps more coverage of the literature should be included in the appendix"}, "questions": {"value": "- Q1: VLM detectors architecturally ignore or undervalue negation cues => I think using attention scores is not robust as models usually encode information into the later token (like punctuation), so lower attention score on negation token does not mean that it does not understand negation, but negation information maybe encoded in subsequent token. \n\n- Q2: Follow up on W1 and W2, it would be nice to see an analysis of the results on unseen negation cues (no need , and results on a different domain/task.\n\n- Q3: Follow up on Q1, did the authors consider boosting the attention score for the negation cue token only, rather than merging it with the following noun tokens?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dK1x0tIfv2", "forum": "hFzrP5mw24", "replyto": "hFzrP5mw24", "signatures": ["ICLR.cc/2026/Conference/Submission157/Reviewer_6vMb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission157/Reviewer_6vMb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760571531374, "cdate": 1760571531374, "tmdate": 1762915458813, "mdate": 1762915458813, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript identifies a critical flaw in state-of-the-art Vision-Language Models (VLMs): their inability to understand negation, often referred to as \"affirmative bias.\" For instance, VLMs frequently treat semantically contradictory phrases (e.g., \"person with skateboard\" vs. \"person without skateboard\") as equivalent. The authors quantitively validate this motivation by showing that negation words occupy only 0.04% of Flickr30k and 0.08% of LAION-400M—far lower than their prevalence in real-world language (13.76% in scientific papers, 22.23% in Conan Doyle’s stories).\nThe authors attribute this bias to two root causes: scarcity of negation data and architectural defects (low attention weights on negation tokens). To address these, they propose two core solutions: (1) COVAND, a synthetic negation-enhanced dataset built via Chain-of-Thought (CoT) reasoning and VQA-based alignment; and (2) NEGTOME, a text token merging module that binds negation cues (e.g., \"not\") with modified attributes (e.g., \"lying\") into coherent semantic phrases. This method achieves state-of-the-art (SOTA) performance on two benchmark datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1.\tCompelling Motivation with Practical Implications: The authors clearly articulate the real-world risks of affirmative bias (e.g., misdiagnosing \"a tumor that is not malignant\" as malignant in medical imaging) and back it with quantitative data on negation scarcity in popular datasets. This not only highlights the urgency of the problem but also provides a clear roadmap for future research.\n2.\tReasonable and Targeted Method Design: COVAND’s three-step CoT pipeline and VQA-based region alignment directly solve \"attribute-level negation\" and \"label ambiguity\"—limitations of prior template-based negation data (e.g., NegCLIP). With 9.29% negation word frequency, COVAND effectively balances data quality and negation coverage. While NEGTOME’s token merging (binding \"not\" + \"lying\" into a single unit) and negation address the structural loss of negation cues in tokenization, deep-layer LoRA ensures parameter efficiency—aligning with real-world deployment needs.\n3.\tRobust Experimental Results: The method consistently improves performance across architectures."}, "weaknesses": {"value": "1.\tLack of Transformative Innovation: The core components (CoT for data generation, Token Merging for text processing, LoRA for fine-tuning) are all mature technologies. The manuscript focuses on \"combining and adapting\" these tools rather than proposing a novel framework. This incremental design may limit its impact on the broader VLM community.\n2.\tOver-Reliance on GPT-4o Leads to Normalized Negation Expressions: GPT-4o’s generation is constrained by its training data, leading to over-reliance on \"regularized\" negation cues (e.g., \"without,\" \"not\") while underrepresenting flexible, real-world negation types (e.g., \"lacks,\" \"absent of,\" \"non-\"). For example, COVAND likely prioritizes attribute negation (e.g., \"a table without drawers\") over relational negation (e.g., \"drawers not beside the table\") due to prompt biases. This mismatch may hurt the model’s generalization to unstructured scenarios.\n3.\tSelf-Consistency Bias in GPT-4o-Based Validation: The third step of COVAND’s pipeline uses GPT-4o to verify the same captions it generates. This \"generator-as-verifier\" setup creates a loop: if GPT-4o misinterprets visual attributes (e.g., mistaking \"pink\" for \"red\") during generation, it will likely repeat the error during validation."}, "questions": {"value": "1.\tRegarding Weakness 2: Have you compared this distribution to real-world corpora (e.g., COCA, biomedical literature) to validate its alignment with natural language? \n2.\tPlease refer to Weakness 3\n3.\tThe manuscript applies LoRA only to deep cross-attention layers. Have you tested LoRA placement in shallow layers or all layers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oRSS5frGBZ", "forum": "hFzrP5mw24", "replyto": "hFzrP5mw24", "signatures": ["ICLR.cc/2026/Conference/Submission157/Reviewer_pMrC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission157/Reviewer_pMrC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958561775, "cdate": 1761958561775, "tmdate": 1762915458647, "mdate": 1762915458647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of negation descriptions in the described object detection (DOD) task. To tackle this issue, the authors construct a large-scale training dataset COVAND that significantly raises the occurrence probability of negation semantics. Simultaneously, they propose NEGTOME which employs a novel token-merging module to enhance the model’s attention to negation semantics. Experimental results on the D3 and OVDEval datasets demonstrate the superior performance of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Understanding negation is a significant and critical weakness of current Vision-Language Models (VLMs). This paper provides a rational and important perspective for addressing this issue by analyzing it from two key aspects — the insufficiency of existing datasets and the limitations of model tokenizers.\n- This paper proposes a large-scale training dataset, COVAND, specifically designed for negation semantics, along with its corresponding construction pipeline, providing an important data contribution toward addressing the negation problem.\n- This paper proposes NEGTOME, which enhances model's attention on negation at the tokenizer-level, offering an interesting and novel perspective for addressing the negation problem.\n- The paper is clearly written and easy to read."}, "weaknesses": {"value": "- This work lacks comparision with SOTAs on the DOD task, for example, Real-Model (Re-Aligning Language to Visual Objects with an Agentic Workflow, ICLR 2025) which achieves 34.1 on D3 benchmark. The citations to such recent SOTAs are also missing. The compared methods in the paper are not sufficiently strong.\n- The detailed designs of NEGTOME are somewhat unclear. (1) It's not clear how \"softmax-weighted average\" (line 240) is performed. Specifically, what's the logits before softmax? (2) The description of \"Negation-aware Boost\" is somewhat confusing. Since the original vectors have been replaced by  \"softmax-weighted averaged\" ones (line 240), would equation (2) make any changes to tokens?"}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WUtyye0QpU", "forum": "hFzrP5mw24", "replyto": "hFzrP5mw24", "signatures": ["ICLR.cc/2026/Conference/Submission157/Reviewer_gNbc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission157/Reviewer_gNbc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762089398979, "cdate": 1762089398979, "tmdate": 1762915458523, "mdate": 1762915458523, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}