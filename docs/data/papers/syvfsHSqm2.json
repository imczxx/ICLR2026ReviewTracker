{"id": "syvfsHSqm2", "number": 7647, "cdate": 1758030462656, "mdate": 1759897841442, "content": {"title": "Dual Randomized Smoothing: Beyond Global Noise Variance", "abstract": "Randomized Smoothing (RS) is a prominent technique for certifying the robustness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accuracy at large radii requires a large noise variance. However, the global noise variance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, in this work we propose a dual RS framework which enables one to use input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance estimator is independently smoothed via RS to ensure local constancy, enabling flexible design. We also introduce training strategies to iteratively optimize the two components involved in the framework. Extensive experiments on the CIFAR-10 dataset demonstrate that our dual RS method provides strong performance for both small and large radii—unattainable with global noise variance—while incurring only a 60\\% computational overhead. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with particularly large gains at 0.5, 0.75, and 1.0, achieving relative improvements of 19.2\\%, 24.2\\%, and 20.6\\%, respectively. Additionally, the proposed dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.", "tldr": "We extend randomized smoothing with global noise variance to input-dependent locally constant noise variance.", "keywords": ["robustness certification", "randomized smoothing"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e927b751a96ae55a3b02607739c6d43b01340e2e.pdf", "supplementary_material": "/attachment/f4e539c9bf22b47fcc0999121cd6e64aa4a7fc86.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel Randomized Smoothing (RS) method called Dual Randomized Smoothing. It dynamically estimates an optimal noise variance for each input and then apply it to the RS classifier, which shows stronger performance than prior input-dependent RS."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper introduces a dynamically method to find the optimal $\\sigma(x)$ for each input $x$ to maximize the verifiable robustness radius $R$, obtaining the stronger robustness. And it is supported by theory.\n2. They show the strong performance compared with SOTA input-dependent RS method. And show the comprehensive ablations study such as alternating fine-tuning, expert classifiers, and the trade-off between accuracy and robustness."}, "weaknesses": {"value": "1. For each type of data, specific processing for training data is required. Only a relatively small dataset (CIFAR-10) is shown, and there is no research on generalization (for ImageNet). And the generation of training data takes a huge amount of time, reaching an extremely long duration of 703 hours just for CIFAR-10 alone.\n2. The presentation of empirical accuracy lacks clarity. And all the results are almost presented in the form of figures. The important results are clearer in the form of tables. (Refer to the Multiscale [1] that they compared with.)\n\n[1] Multi-scale diffusion denoised smoothing, NeurIPS 2023."}, "questions": {"value": "1. Could you show the trade-off between the amount of training data? Such as 20000, 10000 rather than 50000 in whole CIFAR-10 (Just randomly separate it from the dataset you have already processed). Thereby reducing the processing time for the training data.\n2. Could you adjust the presentation method of the results based on weakness 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yLbv7ozvG4", "forum": "syvfsHSqm2", "replyto": "syvfsHSqm2", "signatures": ["ICLR.cc/2026/Conference/Submission7647/Reviewer_ERq3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7647/Reviewer_ERq3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727865749, "cdate": 1761727865749, "tmdate": 1762919720984, "mdate": 1762919720984, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper extends randomized smoothing (RS) to allow input-dependent noise variances, addressing the accuracy–robustness trade-off inherent in global noise settings. The authors theoretically prove that RS remains valid under locally constant variance, and propose a “dual RS” framework with a variance estimator and a standard RS classifier, showing empirical improvements on CIFAR-10. While the idea is clearly presented and theoretically sound, the paper’s novelty and empirical depth are limited, reducing its potential impact."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies a well-known limitation of traditional RS and provides a theoretically justified extension to input-dependent noise while maintaining certification validity.\n\n2. The decomposition into a variance estimator and a classifier, with the option to interpret it as a routing system among expert models, is conceptually clean and practical."}, "weaknesses": {"value": "1. The core idea, using input-dependent noise variance in randomized smoothing, has already been discussed in several prior works. The theoretical extension to “locally constant variance” is incremental rather than fundamentally new.\n\n2. The paper repeatedly claims distinctions from prior approaches in different sections (sections 4 and 5), but these differences are scattered and qualitative. I would like to suggest that the authors add a clear summary table comparing key assumptions, theoretical guarantees, and computational overhead across existing input-dependent RS methods (e.g., Data-Dependent RS, Multiscale RS, Adaptive RS, etc.) to make the claimed advances more transparent.\n\n3. The experiments are limited to CIFAR-10 only, without ablation on larger or diverse datasets (e.g., ImageNet, CIFAR-100). Moreover, many results are shown in curves without concrete numerical tables, making it hard to assess statistical significance."}, "questions": {"value": "I have no further questions. Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "v29t3CezLv", "forum": "syvfsHSqm2", "replyto": "syvfsHSqm2", "signatures": ["ICLR.cc/2026/Conference/Submission7647/Reviewer_8RPB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7647/Reviewer_8RPB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791694318, "cdate": 1761791694318, "tmdate": 1762919719851, "mdate": 1762919719851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Dual Randomized Smoothing (Dual RS), a framework that generalizes randomized smoothing (RS) to input-dependent noise variances while maintaining valid robustness guarantees. The key theoretical result (Theorem 4.1–4.2) shows that RS remains certifiably correct when the variance function $\\sigma(x)$ is locally constant within the certified region. Building on this, the authors introduce a two-stage “dual” framework: a smoothed variance estimator predicts $\\sigma(x)$, and a standard RS classifier uses this estimate for certification. The resulting method achieves stronger accuracy–robustness trade-offs on CIFAR-10 compared to both standard and multiscale RS baselines."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The theoretical contribution is clear, rigorous, and well-motivated. Previous input-dependent RS methods (e.g., Súkeník et al., 2022; Alfarra et al., 2022) were conceptually appealing but failed to provide valid certification due to the dependence of $\\sigma(x)$ on the evaluation point. Here, the authors convincingly fix this flaw by proving that local constancy of $\\sigma(x)$ is sufficient for correctness. The proof is clean, self-contained, and does not rely on unreviewed external results. I found the argument based on Lipschitz continuity much more convincing than earlier Neyman–Pearson-based approaches. The routing interpretation in Section 5.3 is also insightful and connects RS to the mixture-of-experts design."}, "weaknesses": {"value": "The framework introduces double certification: one for the classifier and one for the variance estimator. While theoretically sound, this adds non-trivial complexity and sampling cost. More importantly, ensuring or certifying local constancy of $\\sigma(x)$ can be difficult as the input space scales up. In high-dimensional domains such as ImageNet, verifying that $\\sigma(x)$ is approximately constant in a local neighborhood is challenging, and the accuracy of the second-stage certification will heavily depend on how stable the variance estimator itself is. I would like to see a discussion (or experiment) analyzing the behavior of the variance estimator in such large-scale settings."}, "questions": {"value": "See weakness\n\nCan you please experiment on ImageNet? If results scale to this dataset, I will upgrade my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6G5jozllZm", "forum": "syvfsHSqm2", "replyto": "syvfsHSqm2", "signatures": ["ICLR.cc/2026/Conference/Submission7647/Reviewer_AMmt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7647/Reviewer_AMmt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811300796, "cdate": 1761811300796, "tmdate": 1762919718692, "mdate": 1762919718692, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Dual Randomized Smoothing (Dual RS), a novel framework that addresses the fundamental limitation of standard Randomized Smoothing (RS), which uses a global noise variance across all inputs. The authors prove that RS certification remains valid with input-dependent noise variances, provided the noise variances are locally constant within the certified region. Based on this theoretical foundation, they propose a two-stage framework: (1) a variance estimator that predicts optimal noise variance for each input, and (2) a classifier that uses the predicted variance for certification. The authors also introduce a new procedure for jointly training the prediction of $\\sigma$ and the base classifier. Finally, the authors also introduce a MoE setting for RS. The method is evaluated on CIFAR-10 and shows significant improvements over existing approaches."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper provides a rigorous theoretical foundation by proving that RS certification remains valid with locally constant noise variances (Theorems 4.1 and 4.2). This generalizes the original RS framework and opens new possibilities for adaptive certification methods.\n\nThe paper also provides a new training methodology using soft labels based on certified radius quality rather than hard labels for variance estimation. The proposed iterative training scheme, which alternates between learning the variance estimator given a classifier and classifier optimization given a variance estimator, is also interesting.  \n\nThe Mixture of Experts generalization of the certification procedure also provides a novel method for improving certified accuracy.\n\nThe experiments in the paper demonstrate consistent improvements over state-of-the-art methods with only 60% computational overhead compared to standard RS. The paper provides a detailed analysis of design choices, including the effects of hyperparameters for consistency loss, training iterations, and variants of the loss function."}, "weaknesses": {"value": "The evaluation is restricted to CIFAR-10. The paper would benefit from experiments on larger datasets (e.g., ImageNet) and across other domains to demonstrate generalizability.\n\nThe training process requires substantial computational resources (1517 GPU hours total, with 703 hours just for building the optimal variance dataset). This high cost may limit practical adoption. As the framework relies on a discrete set of candidate variances $\\Sigma = \\{0.25, 0.5, 1.0\\}$, there should be ablation studies examining how the choice, number, and granularity of $\\Sigma$ affect performance."}, "questions": {"value": "Please refer to the Weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dCKifWuq31", "forum": "syvfsHSqm2", "replyto": "syvfsHSqm2", "signatures": ["ICLR.cc/2026/Conference/Submission7647/Reviewer_Ee6d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7647/Reviewer_Ee6d"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996597387, "cdate": 1761996597387, "tmdate": 1762919718321, "mdate": 1762919718321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}