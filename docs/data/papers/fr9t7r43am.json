{"id": "fr9t7r43am", "number": 21865, "cdate": 1758322810999, "mdate": 1759896899415, "content": {"title": "Hidden Markov Modeling of Reasoning Dynamics in Large Language Models", "abstract": "Reasoning in language models involves both explicit steps in the generated text and implicit structural shifts in hidden states, yet their joint dynamics remain largely underexplored. We propose a Hierarchical Hidden Markov Model (HHMM) that captures these two dimensions: semantic roles and latent depth regimes. This framework models how reasoning evolves through semantic stages and how the depth of computation shifts across the network. By linking what function a step serves to where it arises in the network, our approach provides a unified lens for both understanding reasoning dynamics and offering insights into steering strategies. Our analysis reveals consistent patterns: successful reasoning trajectories follow stable semantic paths and align with well-formed structural anchors, whereas failures are characterized by hesitation loops and unstable depth transitions. We further validate our findings by applying step-aware intervention: we derive steering vectors from the transition matrices that encourage trajectories to follow the paths associated with correct reasoning. Across multiple open-source reasoning models, these targeted nudges consistently convert failing runs into correct ones without increasing output length.", "tldr": "", "keywords": ["Reasoning dynamics", "Hidden Markov Model", "Transition analysis", "Large language models", "Interpretability."], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b52ed8c51c32377a8e2300e7ff8625ad6df01095.pdf", "supplementary_material": "/attachment/423509e95cee1556cf30aa9e84bf660720e31f02.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a Hierarchical Hidden Markov Model (HHMM) that unifies explicit reasoning in text and implicit reasoning in hidden states. It models reasoning as semantic transitions over depth regimes and finds that successful trajectories align semantic and structural dynamics, while failures show unstable loops. Derived steering vectors enable targeted interventions that correct reasoning without increasing output length."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The HHMM provides an elegant probabilistic formalism unifying textual reasoning steps with internal representational dynamics—bridging behavior-level and mechanism-level reasoning analysis."}, "weaknesses": {"value": "Both the correct and incorrect trajectories show strong self-loops at the analysis step (0.382 and 0.396), yet the paper provides different explanations for these similar patterns. This suggests the need for additional experiments and statistical analysis to ensure the interpretation is reliable. Similarly, when comparing the correct and incorrect transition matrices, the relative ranks of most elements appear similar. It would be better to include statistical significance tests or clearer evidence to support the claim that the transition dynamics truly differ between the two cases.\n\nThe experimental criterion — “included in the consensus set if at least two out of four models agree” — is also unconvincing. As Table 3 suggests, different models exhibit distinct reasoning strategies; thus, using shared anchors across architectures may conflate semantically different depth regions. More justification is needed to claim cross-model consensus on reasoning anchors.\n\nSome descriptions are unclear or imprecise. For example, in Section 5, “surface-level” should likely be “top-level.” Further clarifications are needed (see questions below)."}, "questions": {"value": "What models and datasets were used to compute the statistics in Table 1? Could the authors include more datasets and LLMs to better illustrate the transition dynamics? Also, what do the colors in Table 1 represent?\n\nIn Table 2, what exactly does “retrieval” mean in the term setup_and_retrieval?\n\nThe paper poses an important question — how explicit and implicit reasoning work together in solving problems — but the conclusion remains unclear. Could the authors provide a more explicit summary or interpretation of how these two dimensions interact?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NUINEr55WJ", "forum": "fr9t7r43am", "replyto": "fr9t7r43am", "signatures": ["ICLR.cc/2026/Conference/Submission21865/Reviewer_HKvS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21865/Reviewer_HKvS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21865/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761590140377, "cdate": 1761590140377, "tmdate": 1762941960695, "mdate": 1762941960695, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper models LLM reasoning as a two-level process that couples what each step is doing with how hidden states evolve across layers. It introduces a hierarchical HMM: a top chain over step semantics (setup/retrieval, analysis, verification, final answer) and a bottom HMM over latent “depth regimes” that capture layer-wise computation during each step. Using this joint model, the authors show that successful solutions follow stable semantic paths anchored by consistent late-layer patterns, while failures loop in verification or show unstable depth transitions. They then derive step-aware steering vectors from the learned transitions to gently nudge hidden states at critical moments, correcting some failures without changing weights or lengthening outputs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strengths\n\n- Unified lens: Couples step semantics with hidden-state dynamics, giving a clear “reasoning trajectory.”\n\n- Actionable diagnostics: Pinpoints where runs stall (e.g., verification loops) and which layers fail to anchor.\n\n- Lightweight steering: Step-aware vectors nudge failing traces without changing weights or lengthening outputs."}, "weaknesses": {"value": "Weaknesses\n\n- Small gains: Correction improvements over baselines are modest; may feel insignificant for production.\n\n- Label reliance: Top-level step tags are self-annotated by the model, risking bias and propagation of errors.\n\n- Simplifying assumptions: Bottom-level uses PCA + diagonal Gaussians; may miss richer, non-Gaussian structure."}, "questions": {"value": "same as weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KT1Uhf1p4A", "forum": "fr9t7r43am", "replyto": "fr9t7r43am", "signatures": ["ICLR.cc/2026/Conference/Submission21865/Reviewer_J8mT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21865/Reviewer_J8mT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21865/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854598206, "cdate": 1761854598206, "tmdate": 1762941960364, "mdate": 1762941960364, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a Hierarchical Hidden Markov Model (HHMM) framework to jointly capture explicit semantic stages and implicit structural depth regimes underlying reasoning processes in large language models (LLMs). Experiments demonstrate that the approach can systematically characterize reasoning motifs. Based on HHMM, intervention can be applied to improve performance without increasing sequence length."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Important Topic**: The interpretability of LLM reasoning is an important and under-explored research area.\n\n2. **Novel and Interesting Modeling**: The introduction of HHMM to connect explicit semantic transitions with latent computational regimes is a non-trivial approach for interpreting and intervening in LLM reasoning. The analytical results offer interesting insights about reasoning behaviors of current LLMs.\n\n3. **Actionable Steering Mechanism**: Beyond analytical experiments, this paper proposes intervention technique derived from transition matrices. The steering mechanism not only helps validate the analysis reliability, but offers a pragmatic way to rescue failing trajectories at some times."}, "weaknesses": {"value": "1. **Limited Justification of HHMM Assumptions**: This paper lacks a formal discussion or ablation on the necessity of the hierarchical structure for capturing meaningful interaction between semantic roles and depth regimes. It is unclear the observed improvements stem from hierarchy or from simply more latent structure.\n\n2. **Experimental Issues** Some experimental settings including models, $C$, $K$, boundary clusters, etc., seem arbitrary. Results in Table 1, 2 and the relative differences are not significant enough for the analytical claims about reasoning patterns in Section 4 Q1, Q2.\n\n3. **Insufficient Baseline Comparison for Steering**: In Table 6, the proposed intervention technique is only compared with a basic edge-agnostic baseline, rather than established steering or latent intervention frameworks. Considering the modest intervention improvement (about 1pp), comparison with more related methods is important."}, "questions": {"value": "1. **Necessity of Hierarchy (Weakness 1 Related)**: Could the authors experimentally or theoretically justify why the hierarchical HMM is preferable to a single-level HMM or other latent-state models? For example, would a flat HMM over step * depth suffice?\n\n2. **Model Selection (Weakness 2 Related)** Why use a Qwen3-1.7B instead of its 4B or 8B variations, which are consistent in parameter size with other models?\n\n3. **Robustness (Weakness 2 Related)**: How sensitive are the bottom-level HMMs to number of regimes ($K$), or the PCA preprocessing step? And other experimental variations like tasks and models? Are the results stable across runs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qJfJ1ytY7r", "forum": "fr9t7r43am", "replyto": "fr9t7r43am", "signatures": ["ICLR.cc/2026/Conference/Submission21865/Reviewer_q8fR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21865/Reviewer_q8fR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21865/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909829731, "cdate": 1761909829731, "tmdate": 1762941959980, "mdate": 1762941959980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Reasoning in LLMs can be viewed as explicit and implicit steps. By explicit reasoning, the authors refer to step by step generation of text and by implicit reasoning, they refer to the changes in hidden states. By modeling explicit steps as Markov chains and implicit steps as Hidden Markov Chains they propose a new framework, HHMM (Hierarchical Hidden Markov Model), to model the reasoning trajectories in both explicit and implicit dimensions. Finally, they use their framework to steer the reasoning trajectories by adding step-aware steering vectors to the hidden states of the final layer during generation in order to guide the reasoning toward correct reasoning trajectories. Overall, they improve the reasoning for incorrect reasoning trajectories and also provide an interpretable framework to study reasoning behavior in terms of layer concentration and different aspects such as verification, analysis, and outputting the final answer."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "A new framework that can discover and explain the patterns in reasoning and highlight the differences between correct and incorrect reasoning trajectories. \n\nIn addition to studying semantic reasoning and structural reasoning dynamics, they propose a steering method based on their framework that can correct the incorrect reasoning trajectories and help the generation to be stable and truthful.\n\nWhile many methods for improving reasoning lead to an increase in the number of generated tokens, their approach maintains almost the same and sometimes even lower token count."}, "weaknesses": {"value": "There are no results for the fraction of originally correct predictions becoming incorrect after steering (since in inference time we can't predict the model is going to do it wrong or correct and this experiment would help in observing the possible harmful effect of steering for already correct reasonings)\n\nLack of baselines in the steering section. A simple baseline like directly prompting the model to be more decisive during reasoning could suffice to show the superiority of using HHMM for steering as well."}, "questions": {"value": "Could you use a more powerful LLM for classification (final_answer, setup_and_retrieval, …) for making sure there would be less error and mistakes in this phase?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pkCl7aNSL7", "forum": "fr9t7r43am", "replyto": "fr9t7r43am", "signatures": ["ICLR.cc/2026/Conference/Submission21865/Reviewer_RnB2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21865/Reviewer_RnB2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21865/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011320155, "cdate": 1762011320155, "tmdate": 1762941959635, "mdate": 1762941959635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}