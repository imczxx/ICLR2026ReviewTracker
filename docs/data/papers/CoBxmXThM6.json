{"id": "CoBxmXThM6", "number": 13912, "cdate": 1758224904420, "mdate": 1759897404153, "content": {"title": "AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents", "abstract": "We introduce AgentSynth, a scalable and cost-efficient pipeline for automatically synthesizing high-quality tasks and trajectory datasets for generalist computer-use agents. Leveraging information asymmetry, AgentSynth constructs subtasks that are simple during generation but significantly more challenging when composed into long-horizon tasks, enabling the creation of over 6,000 diverse and realistic tasks. A key strength of AgentSynth is its ability to precisely modulate task complexity by varying the number of subtasks. Empirical evaluations show that state-of-the-art LLM agents suffer a steep performance drop, from 18\\% success at difficulty level 1 to just 4\\% at level 6, highlighting the benchmark's difficulty and discriminative power. Moreover, our pipeline achieves a low average cost of \\$0.60 per trajectory, orders of magnitude cheaper than human annotations. Code is available in the supplementary materials.", "tldr": "We present AgentSynth, a scalable pipeline that automatically generates diverse and realistic computer-use tasks and trajectories.", "keywords": ["Synthetic data", "Computer-use agents", "Scalable"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/50b758fba1d50b428e28c70b979c15845b93cd66.pdf", "supplementary_material": "/attachment/1cca2b33e089bb2033e5a1577d48eed0e369d6c3.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces AgentSynth, a scalable and cost-efficient pipeline for automatically synthesizing high-quality tasks and trajectory datasets for generalist computer-use agents. Motivated by information asymmetry, AgentSynth iteratively proposes and solves simple subtasks and summarizes them into a complex task. This process is also monitored by a task verifier and a task reviser. The paper conducts a comprehensive statistical analysis on the generated datasets. Experiments show that even strong multimodal models fall short in the challenging tasks generated through AgentSynth."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The main contribution of this paper is the establishment of a challenging benchmark that is more cost-effective compared to other methods. Additionally, the paper provides a detailed statistical analysis regarding the benchmark."}, "weaknesses": {"value": "1. Despite its effectiveness, the \"easy-to-hard\" data synthesis approach in this paper is not entirely novel and can be observed in data synthesis across various other domains. This aspect diminishes the paper's innovativeness.\n\n2. The paper devotes a significant amount of content to statistical analysis of the dataset. Some data cases presented in the main text are unnecessary, resulting in a limited experimental section and potentially giving the impression of a less robust study. It is recommended that the authors allocate more space to additional experimental analyses to provide readers with more insights.\n\n3. The evaluation setting in the experimental section of this paper lacks the use of any agent scaffold, which is too simplistic and may not adequately represent the true capabilities of the model. For instance, if we were to follow the AgentSynth pipeline (breaking down complex problems into subtasks and gradually solving each subtask, equipped with a verifier and reviser), would this significantly improve the results?"}, "questions": {"value": "1. How significantly would replacing the base model for data synthesis with other models impact the quality of the synthesized data?\n\n2. Can this pipeline be extended to domains beyond OS agents?\n\n3. Can training with open-source models on this trajectory library achieve far superior results compared to closed-source models?\n\n4. Will this dataset be open-sourced?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4RS7oxgECG", "forum": "CoBxmXThM6", "replyto": "CoBxmXThM6", "signatures": ["ICLR.cc/2026/Conference/Submission13912/Reviewer_CsTg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13912/Reviewer_CsTg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760899522288, "cdate": 1760899522288, "tmdate": 1762924419549, "mdate": 1762924419549, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes AgentSynth, an automated pipeline that synthesizes long-horizon, realistic computer-use tasks by chaining LLM-generated simple subtasks and then summarizing them into a single complex instruction. The key idea is to exploit information asymmetry between generation and evaluation. Difficulty is tunable by subtask count, spanning web/OS/office/coding; benchmark shows steep agent performance decay with horizon. MLLMs perform poorly and degrade steeply with difficulty; the pipeline is also inexpensive ($0.60 per trajectory)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clever use of information asymmetry to make generation easy but evaluation hard; difficulty is tunable via subtask count (d), enabling principled long-horizon benchmarks.\n2. Results show a sharp success-rate drop as d increases, making the benchmarkâ€™s discriminative power evident.\n3. Practicality & scale: diverse, multi-tool tasks on real desktop environments; cost-efficient generation with transparent cost accounting."}, "weaknesses": {"value": "1. Limited causal evidence: missing ablations of asymmetry vs. direct instruction, and broader verifier calibration (agreement curves, partial-credit) across tools and difficulty.\n2. Difficulty = horizon is not fair enough: other metrics like complementary axes (fine-grained perception, long-term memory, interrupt handling) would enrich difficulty control.\n3. The verifier is still LLM-based and can misjudge corner cases. More human audits or adversarial stress tests for the verifier would strengthen claims."}, "questions": {"value": "1. Can you provide asymmetry ablations and verifier calibration results to justify the difficulty and scoring?\n2.  Although increasing task horizon typically enhances diversity and difficulty, it also increases training cost. Under a fixed training compute/token budget, have you evaluated whether curating higher-quality (e.g., cleaner supervision, lower noise, stronger verifiability, clearer goal decomposition) short/medium-horizon data can outperform simply lengthening horizons in terms of compute-normalized effectiveness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "10Pm1L2G1G", "forum": "CoBxmXThM6", "replyto": "CoBxmXThM6", "signatures": ["ICLR.cc/2026/Conference/Submission13912/Reviewer_jFe8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13912/Reviewer_jFe8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761215693320, "cdate": 1761215693320, "tmdate": 1762924419074, "mdate": 1762924419074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AgentSynth, a dataset of synthetic computer-use agent tasks in the OSWorld environment, generated using a subtask-based compositional approach. The approach leverages a loop of subtask-level proposal, execution, verification and potential subtask revision, then summarization to compose the subtasks into one coherent task. The authors show that baseline agent's performance suffers for more difficult tasks consisting of more subtasks, indicating the effectiveness of the AgentSynth in exposing gaps in agent capabilities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles an important problem of testing LLM agents in complex tasks involving multiple subtasks, which is not easily controllable in existing benchmark works. The proposed approach is intuitive and cost effective for composing arbitrarily complex sequences of salient subtasks.\n- The results indicate that baseline agents indeed suffer from compositional tasks.\n- The paper is well written and easy to follow."}, "weaknesses": {"value": "- My main concern with the paper is the lack of advanced agent approaches evaluated on the benchmark. The baseline agent tested consists of a basic agent with a simple prompt, and in my understanding only represents the performance lowerbound on the benchmark. Without evaluating more advanced approaches, it is difficult to understand how well competitive agents would perform on the benchmark.\n- A missing citation is [1].\n\n[1] Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web. Furuta et al., TMLR 2024"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jgXmWHvLqB", "forum": "CoBxmXThM6", "replyto": "CoBxmXThM6", "signatures": ["ICLR.cc/2026/Conference/Submission13912/Reviewer_kK3T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13912/Reviewer_kK3T"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982423259, "cdate": 1761982423259, "tmdate": 1762924418610, "mdate": 1762924418610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}