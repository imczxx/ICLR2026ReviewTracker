{"id": "3ZesmvOJ6o", "number": 21441, "cdate": 1758317634114, "mdate": 1759896921737, "content": {"title": "UnRe: Zero-Shot LLM Unlearning via Dynamic Contextual Retrieval", "abstract": "Inference-time machine unlearning with only the forget data, also known as zero-shot unlearning, is becoming increasingly important for bias mitigation, privacy preservation, copyright protection, etc. Most approaches in this domain focused on query updating, decoder modification, offline module training, or reverse-generation by the forget data. Recent works found that providing offline-prepared contexts can realize in-context unlearning. However, leveraging dynamic context (conditioned on real-time queries) to achieve zero-shot unlearning has not yet been explored, which has the potential to enforce context unlearning while preserving the performance of the original LLM. In this paper, we propose UnRe, a novel unlearning framework for LLMs that employs dynamic contextual retrieval from retrieval-augmented generation (RAG) while only leveraging the forget data. Specifically, UnRe dynamically updates contexts to guide the unlearning process in a zero-shot setting. During the inference, the user query is first leveraged for online membership inference to identify a query-specific forget set. Using this set, UnRe refines the embeddings of the retrieved chunks via gradient descent, producing adaptive contexts that steer the LLM toward a query-specific unlearned distribution. We evaluate UnRe on multiple unlearning benchmarks and show that UnRe not only outperforms existing zero-shot and context-based unlearning approaches, but also preserves the original model performance.", "tldr": "This paper proposes UnRe, a novel unlearning framework for LLMs that employs dynamic contextual retrieval from retrieval-augmented generation (RAG) while only leveraging the forget data.", "keywords": ["LLM", "Machine Unlearning", "Retrieval Augmented Generation", "Inference", "Privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9322ec2f7e75b494946e52bbdade9167c4cba937.pdf", "supplementary_material": "/attachment/f3b29e40b4be53fcaf66dbd1cc0901f59726e147.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents an inference-time machine unlearning approach. The core idea is to apply gradient updates in the embedding space so that, during generation, the LLM avoids producing outputs that overlap with the forget data. The authors compare their approach against various baselines and report improved performance."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- Efficient and flexible unlearning is an important problem.\n- The idea of dynamic context editing is interesting.\n- However, many technical details are missing, and the writing requires substantial improvement."}, "weaknesses": {"value": "1. Clarity: The paper is very difficult to follow. Variables are introduced without clear definitions, and the exposition is often confusing (see questions below).\n2. Technical detail: Key details about how dynamic generation and context updates work are missing.\n3. Novelty: It is unclear how the method differs from or advances standard RAG-based unlearning.\n4. Efficiency: The method appears to require LLM generation, then RAG, then gradient updates, followed by another generation pass. This will likely slow inference substantially, which may make the approach impractical for real-world applications."}, "questions": {"value": "- Figure 1 is very difficult to interpret. The color coding is unclear, font sizes and families are inconsistent (even in the legend), and the flow alternates between left-to-right and right-to-left/top-to-bottom. The meaning of dashed versus solid arrows is not explained. It is also unclear where the LLM is involved: there is an arrow from the language model box to (3→4), but step 4 is labeled “retrieval” rather than “generation.” The figure does not clearly indicate which components are off-the-shelf (embedding model, LLM, etc.), and the legend uses vague categories such as “language model,” “embedding space,” and “offline preparation.” Overall, the figure looks unpolished and does not meet the clarity expected for an ICLR paper. Please revise for readability, consistent notation, and a coherent flow.\n- Citations are not consistently formatted in LaTeX. In many places, citep should be used instead of citet. For example: “operates during LLM inference with frozen weights and is generally regarded as suppression-intended unlearning (Ren et al., 2025).”\n- Line 167: What are the input x and label y in the forget piece? This is the first mention of labels in the paper. Why is a label needed here? Is x the content to forget? If so, why do we need y?\n- Line 171: The perturbed set \\tilde{O}_q is introduced without sufficient context. What is its purpose at this stage, and how does it feature in the problem formulation?\n- Line 173: Using M.G to denote the LLM’s generation process is unconventional. Please align the notation with standard practice.\n- Lines 186–188: The connection between performing gradient descent in V_R (the embedding model space) and imposing constraints on the LLM’s output distribution is not clear. Please provide a formal justification or an empirical rationale that links embedding-space updates to output distribution shifts.\n- Line 196: φ is used to denote the embedding model’s forward pass, but the embedding model itself is not clearly specified or defined. Please clarify the model choice, training status, and interface.\n- Section 3.5: Why is the LLM hidden state h_δ(t) directly comparable to the embedding space produced by φ? The last hidden state of an LLM is typically optimized for next-token prediction rather than capturing the global semantics of the answer. Please justify this assumption or provide empirical evidence.\n- Technical details on how the perturbation matrix is used in inference are missing. Is this matrix applied to all layers and all tokens of the transformer, or only to specific layers/states? Please provide a precise description of the application mechanism, scope, and computational overhead."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MLaenuukig", "forum": "3ZesmvOJ6o", "replyto": "3ZesmvOJ6o", "signatures": ["ICLR.cc/2026/Conference/Submission21441/Reviewer_M4qg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21441/Reviewer_M4qg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761586206941, "cdate": 1761586206941, "tmdate": 1762941777642, "mdate": 1762941777642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces UNRE, a framework for zero-shot, inference-time unlearning in large language models (LLMs) using dynamic, query-conditioned contextual retrieval. Unlike previous methods requiring retain sets or offline-trained modules, UNRE operates solely on a forget set and employs retrieval-augmented generation (RAG) with online membership inference to identify, adapt, and perturb context embeddings in response to real-time queries, aiming to suppress memorized or undesirable content while retaining overall model utility"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method transforms the unlearning problem into a context-level intervention, avoiding the costly retraining required for parameter-level unlearning.\n\n2. The theoretical and algorithmic design is simple yet effective, achieving context switching between forgetting and retention through embedding-space perturbation.\n\n3. UNRE is evaluated on multiple public benchmarks, including entity unlearning and copyright unlearning, demonstrating strong experimental performance."}, "weaknesses": {"value": "1. The method uses a similarity threshold ( \\tau ) to decide whether to trigger unlearning based on the similarity between the model output ( y_q ) and the forget set ( O ). Since ( \\tau ) is the key factor determining whether unlearning occurs, treating this decision as a binary classification may be oversimplified. Its value can be sensitive to the model, task, and data, and the paper does not explain how it is chosen.\n\n2. The loss ( \\mathrm{softplus}(N - S) ) aims to balance semantic preservation (high ( S )) and output divergence (low ( N )), which are conflicting goals. If ( S ) dominates, forgetting may be incomplete; if ( N ) dominates, the output may drift semantically. A tunable hyperparameter could help balance these effects.\n\n3. The Projected Gradient Descent (PGD) optimization may fall into local minima or become unstable in high-dimensional embedding spaces. Exploring contrastive-learning-based optimization or low-dimensional perturbation approximations could improve stability.\n\n4. Each unlearning step requires document retrieval, multiple PGD iterations, and re-decoding, which significantly increases inference latency. This may limit the method’s practicality in real-time applications.\n\n5. As a context-level approach, the method may be more vulnerable to jailbreak or adversarial attacks, where an attacker could craft prompts to bypass unlearning and recover forgotten content."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wrTyuXdxZq", "forum": "3ZesmvOJ6o", "replyto": "3ZesmvOJ6o", "signatures": ["ICLR.cc/2026/Conference/Submission21441/Reviewer_wMLX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21441/Reviewer_wMLX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926061605, "cdate": 1761926061605, "tmdate": 1762941777150, "mdate": 1762941777150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes UNRE, a zero-shot inference-time unlearning framework for large language models (LLMs). Unlike prior approaches that require retain sets, offline fine-tuning, or fixed unlearning contexts, UNRE leverages query-adaptive dynamic retrieval based on the forget set only. Specifically, it integrates an online membership inference module to identify query-related forget pieces, then applies gradient-based refinement of retrieved embeddings to steer model outputs toward an “unlearned” distribution."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper explores a new setting of zero-shot inference-time unlearning with dynamic retrieval, extending prior in-context unlearning (ICUL) work.\n\n- Unlike typical in-context learning methods, it operates at the embedding level to prevent the activation of information associated with the forget set.\n\n- The motivation is well-aligned with privacy and copyright unlearning, and the approach explicitly avoids model parameter modification, retain data, or retraining, making it highly practical for real-world deployment scenarios."}, "weaknesses": {"value": "- The paper could benefit from qualitative examples showing cases where UNRE fails (e.g., borderline membership detection, overly aggressive context updates) to better interpret its robustness.\n\n- Some improvements (e.g., small PPL changes) might result from threshold or step-size tuning in Algorithm 1. Sensitivity analyses on τ and ε would clarify stability and generalization.\n\n- The embedding-level perturbation may risk distorting semantic representations for complex queries. While PGD constraints are mentioned, an explicit analysis of semantic preservation vs. forgetting trade-off is missing."}, "questions": {"value": "1. There is an incorrect bolded value in Table 1 under the Falcon3-7B-Instruct setting, where Prompt FQ (0.0970) is actually much higher than UnRE (0.0611). In addition, for the same setting, it is unclear why the MU score of UnRE (0.0644) is significantly lower than that of the other methods  (0.66).\n\n2. Could you please bold the best value in Table 2 for clarity?\n\n3. How sensitive is UNRE to the similarity threshold (τ) and update budget (ε)?\n\n4. Could the authors provide ablation studies showing the contribution of each component — membership inference, gradient-based update, and semantic loss — to the overall unlearning performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UstyWR1ken", "forum": "3ZesmvOJ6o", "replyto": "3ZesmvOJ6o", "signatures": ["ICLR.cc/2026/Conference/Submission21441/Reviewer_qutX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21441/Reviewer_qutX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970004108, "cdate": 1761970004108, "tmdate": 1762941776449, "mdate": 1762941776449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}