{"id": "oY4CQ2GJkC", "number": 2584, "cdate": 1757153235933, "mdate": 1763714862214, "content": {"title": "Improving LoRA with Variational Learning", "abstract": "Bayesian methods have recently been used to improve calibration of LoRA fine-tuning but there is still room for improvements. For instance, with Laplace's method no effective gains in accuracy are seen while variational learning can sometimes even harm it and increase both runtime and implementation complexity. Here, we propose two simple modifications to variational learning that fix all of these issues. First, we reduce cost and simplify implementation by adapting the recently proposed IVON optimizer for LoRA training. Second, we propose new scaling and pruning techniques for posteriors to improve the accuracy-uncertainty trade-off. Empirically these modifications consistently yield multiple benefits over Adam where (a) both accuracy and calibration are boosted; (b) accuracy improves with longer training while overfitting is reduced; (c) test-time scaling is boosted for generation tasks; and (d) data efficiency during training is also improved. Our work proposes new modifications to variational learning that improve many aspects of the standard LoRA training.", "tldr": "", "keywords": ["Variational learning", "Low-rank adaptation", "Large language models"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a8eb9487965cfa360362e9a0a7a5f3ef8b53e111.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes to improve LoRA via Bayesian machine learning. In particular, the proposal is to integrate the Improved Variational Online Newton method coupled with testing time temperature scaling and posterior pruning. The proposed method also takes into account how to select and fine-tune some hyper-parameters to improve performance. Extensive empirical evaluation shows that the proposed method achieves both high prediction accuracy and well-calibrated models compared to existing methods in the literature."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents an extensive literature review and provide detailed background knowledge about different methods in Bayesian learning for LoRA. The proposed method is also intuitive and easy to follow. The proposed method is efficient in terms of computation. The implementation is also mentioned as minor modification into the existing Adam. The selection of hyper-parameters is justified and has associated with proper references.\n\nAnother plus point is the empirical study of tradeoff between accuracy and calibration error. This is known for Bayesian learning, which focuses on modeling uncertainty, and hence, may not be as confident as point estimation. Hence, simply comparing prediction accuracy alone is insufficient."}, "weaknesses": {"value": "The paper is more or less an incremental improvement with certain engineering finetuning. More specifically, it is an improvement of Blob using existing frameworks and hyper-parameter selection to set the prior. It does not mean the paper is bad, but the current contributions are limited.\n\n**Minors**\n- Typo at line 158: \"... accuracy. using ...\" => Using"}, "questions": {"value": "Because the paper claims efficiency in terms of computation, it is better to include a complexity analysis in terms of running time for the proposed method and other existing methods to easier compare theoretically."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hkzcnFbTTd", "forum": "oY4CQ2GJkC", "replyto": "oY4CQ2GJkC", "signatures": ["ICLR.cc/2026/Conference/Submission2584/Reviewer_Pxxq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2584/Reviewer_Pxxq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918013325, "cdate": 1761918013325, "tmdate": 1762916290962, "mdate": 1762916290962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates Bayesian approaches to Low-Rank Adaptation (LoRA) for fine-tuning Large Language Models. The motivation for such methods is their potential to improve not only model accuracy but also uncertainty calibration. The authors begin by identifying limitations in existing Bayesian LoRA methods, namely Laplace-LoRA and BLoB, arguing that they present a suboptimal trade-off between accuracy and calibration, and can introduce significant computational and implementation complexity. To address these issues, the authors propose a method based on the Improved Variational Online Newton (IVON) algorithm. They introduce several modifications to IVON tailored for LoRA fine-tuning: an online, per-matrix adaptation of the prior precision; a heuristic for setting the scaling parameter of the KL-divergence term in the ELBO; and two test-time techniques, posterior temperature scaling and posterior pruning, to enable an explicit trade-off between accuracy and calibration."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-written and the methodological contributions are easy to follow.\n- The proposed method, IVON-LoRA, is simple to implement and adds minimal computational overhead. This makes the approach a practical and valuable contribution.\n- The empirical evaluation is extensive and robustly demonstrates the benefits of the proposed method through comparisons with:\n  - The standard non-Bayesian Adam optimizer, showing that IVON-LoRA improves both accuracy and calibration.\n  - Bayesian competitors (Laplace-LoRA and BLoB), showing that IVON-LoRA often achieves a more favorable accuracy-calibration trade-off."}, "weaknesses": {"value": "The motivation for some of the algorithmic design choices could be further substantiated:\n\n- A more in-depth discussion is needed to motivate the adaptation of the prior precision *at each optimization step*. How does this procedure align with the Bayesian framework, where the prior is typically fixed to represent beliefs held before observing the data? Adapting the prior to the current state of the posterior seems to weaken its role as a fixed regularizer, as it no longer serves as a static anchor but rather co-adapts with the posterior.\n- The justification for the heuristic choice of the scaling parameter $\\lambda$ could be strengthened. The authors argue that a linear scaling, $\\lambda = N$, can fail for small $N$ by producing a $\\lambda$ that is too small, leading to excessively large posterior variance and training instability. While choosing a larger $\\lambda$ is a reasonable response, the specific motivation for a scaled square-root law ($\\lambda = \\gamma \\sqrt{N}$) is not provided. Do the authors have a theoretical or empirical rationale for this functional form over other alternatives? Furthermore, since $\\sqrt{N} < N$ for $N>1$, does the success of this heuristic rely on choosing a scaling factor $\\gamma \\gg \\sqrt{N}$ to ensure $\\lambda$ is sufficiently large?\n\nI also have some suggestions for improving the experimental evaluation:\n\n- The authors propose posterior pruning and scaling as effective tools for managing the accuracy-calibration trade-off for IVON-LoRA. Could these techniques also be applied to Laplace-LoRA and BLoB? If so, an evaluation of their effectiveness on these baselines would help clarify whether this is a general technique or specific to IVON.\n- Similarly, are the reported improvements in scaling with respect to training and test-time computation a general feature of variational learning for LoRA, or are they specific to IVON-LoRA? A small-scale comparison of how BLoB scales with these factors would provide valuable context.\n- The paper argues that IVON-LoRA has negligible overhead compared to Adam. However, a direct comparison of computational complexity (e.g., training time, memory usage) against the Bayesian competitors, Laplace-LoRA and BLoB, is missing and would be informative.\n- The result tables are dense and can be difficult to parse. To improve readability and facilitate direct comparison, could the authors add the point-estimates for Adam, IVON-LoRA@mean and IVON-LoRA to the accuracy-calibration trade-off plots in Figures 1 and 2?"}, "questions": {"value": "cf. my comments below \"Weaknesses\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RvmSP71kjb", "forum": "oY4CQ2GJkC", "replyto": "oY4CQ2GJkC", "signatures": ["ICLR.cc/2026/Conference/Submission2584/Reviewer_LL5V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2584/Reviewer_LL5V"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938572412, "cdate": 1761938572412, "tmdate": 1762916290821, "mdate": 1762916290821, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a variational Bayesian approach, LoRA-IVON, for fine-tuning large language models (LLMs) by adapting a mean-field Gaussian approximation method, IVON, to the LoRA fine-tuning framework. Both IVON and LoRA-IVON are appealing because they can be implemented through minor modifications to the widely used Adam optimizer, making them easily integrable into existing deep learning frameworks. The proposed extensions to IVON include the use of an empirical prior during optimization (i.e., fine-tuning) and the introduction of heuristics for posterior tempering and network pruning to improve posterior predictive sampling. The authors claim that the method achieves superior accuracy and uncertainty calibration with negligible computational overhead, a claim supported by empirical results."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The empirical Bayes formulation for determining the prior is the most novel and promising aspect of the work. This idea has potential applicability beyond the presented context and represents a fundamental improvement over IVON.\n- The experimental results provide convincing evidence that the proposed method performs on par with established Bayesian fine-tuning approaches such as BLoB and the Laplace approximation.\n- The proposed adaptation preserves the implementation simplicity of IVON."}, "weaknesses": {"value": "- The paper does not include a comparison with an IVON baseline, making it difficult to assess the actual contribution of the proposed adaptations relative to the existing IVON method.\n\n- The choice of tempering with $\\lambda$ during optimization is neither theoretically motivated nor empirically investigated. The experiments appear to either fix $\\lambda = 5k = \\gamma$ or disregard the $\\gamma \\sqrt{N}$ heuristic entirely (e.g., by setting $\\lambda = 5 \\cdot 10^6$).\n\n- The calibration analysis should include additional metrics such as the Brier Score and the Maximum Calibration Error to provide stronger evidence for the claimed improvements in calibration. ECE and MCE alone are sensitive to the number of bins.\n\n### Reason for rating\nI recommend rejecting the paper in its current form, as it would require considerable rewriting and additional experimentation to convincingly demonstrate empirical improvements over IVON. However, I encourage the authors to perform this evaluation and resubmit, as the approach is promising and the direction worthwhile."}, "questions": {"value": "- Under any reasonable weight-decay scheme, how does IVON compare to the proposed method?\n- Please provide the derivation for the closed form of $\\delta_i$. In particular, clarify what $\\hat{\\mu}$ in Eq. 15 of Graves (2011) corresponds to in the equation for $\\delta_i$ presented here.\n- What is the effect of tuning $\\gamma$, and what is the rationale for choosing $\\gamma = 5k$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XYtJ4dQwrU", "forum": "oY4CQ2GJkC", "replyto": "oY4CQ2GJkC", "signatures": ["ICLR.cc/2026/Conference/Submission2584/Reviewer_xHMR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2584/Reviewer_xHMR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762526365179, "cdate": 1762526365179, "tmdate": 1762916290684, "mdate": 1762916290684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed to adapt the existing method, IVON, to LoRA for LLMs.  \nThe major contributions are presented in Section 3, which includes:\n+ how to find the good values for the prior --- this is achieved by using a closed form expression of $\\delta_i$.\n+ how to select $\\lambda$ --- this is achieved by considering $\\lambda = \\gamma \\sqrt{N}$ and tuning $\\gamma$ instead.\n+ how to balance the trade-off of accuracy and calibration performance for this kind of Bayesian LoRA --- this is achieved by\n    +  taking $\\lambda_{test} = \\tau \\lambda$ and tuning the value of $\\tau$. This can scale the posterior variance to balance the trade-off between the accuracy and calibration.\n    + pruning a small fraction of parameters at test time using $|m_i|/\\sqrt{v_i}$ as a metric.\n\nFor the experiments:\n   + The author compared the proposed method to existing probabilistic LoRA methods including standard LoRA with Adam, Laplace-LoRA and BLoB on 6 datasets including BoolQ for the model Llama-3.2-3B.\n   + However, the authors use average accuracy/ECE on 6 datasets as an overall evaluation metric for these methods, this is a huge mistake. For instance, as shown in Table 2, the proposed method actually have mixed performance on ECE and NLL.\n\nOverall, the contributions are limited, and using the average accuracy/ECE values as evaluation metrics is problematic."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The paper is clearly written and is easy to follow. \n+ Related works are discussed though being limited to the literature of LoRA for LLMs. \n+ The contributions of the proposed method are clearly presented and discussed.\n+ Despite of the problematic evaluation metric, the authors have conducted good amount of experiments to demonstrate the performance of their method."}, "weaknesses": {"value": "+ The contributions are minor. See Section Summary for a detailed summary of the contributions of this paper.\n+ Problematic overall evaluation metric. The authors used average accuracy/ECE on 6 datasets as an overall evaluation metric for these methods, e.g.Table 1 and 2. This is a huge mistake and could cause misleading results and conclusions.\n+ Some typos: eg Line 158."}, "questions": {"value": "Q1. The authors mentioned that \"we disable the explicit weight decay in the parameter update step, as a\nzero weight decay empirically works well for LoRA finetuning\" in Line 207-208. Does it because it have similar effect as the KL divergence between $q(\\theta)$ and $p(\\theta)$ in Eq (1). Have you conduct some ablation studies on this problem as I believe this is a well-known property in the field of variational inference of neural networks.\n\nQ2. To select $\\lambda$, the authors proposed to use $\\lambda = \\gamma \\sqrt{N}$ of which $\\gamma$ need to be tuned. So why don't you just tune  $\\lambda$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qwuXfO5l0t", "forum": "oY4CQ2GJkC", "replyto": "oY4CQ2GJkC", "signatures": ["ICLR.cc/2026/Conference/Submission2584/Reviewer_Fiag"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2584/Reviewer_Fiag"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762792853579, "cdate": 1762792853579, "tmdate": 1762916290511, "mdate": 1762916290511, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}