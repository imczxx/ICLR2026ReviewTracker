{"id": "bUnG3WcSYX", "number": 23021, "cdate": 1758338283081, "mdate": 1763001991284, "content": {"title": "Evolving and Detecting Multi-Turn Deception using Geometric Signatures", "abstract": "Safety defenses for large language models (LLMs) are typically trained and evaluated on single-turn prompts, yet real attacks often unfold as indirect, multi-turn probing. To defend against this more nuanced form of deception, we present a unified pipeline that generates realistic multi-turn deceptive question sets via multi-objective genetic prompt optimization with co-evolving mutation operators. We validate this data set through a human study, which also revealed that early generations yielded the most convincing deception and practical constraints such as adherence filtering and ordering effects. Using this data, we were able to detect deceptive attempts to access prohibited information using simple, explainable geometric signals in embedding space coupled with a tiny feed-forward classifier. Three geometric features (angular coverage, distance ratio, and linearity) augmented with pairwise similarity statistics led to a compact predictive model that achieved consistently high recall (0.89) across base, reworded, and truncated (three-turn) scenarios, with test-time F1 ranging from 0.74-0.86. The results support a central hypothesis that multi-turn deceptive intent leaves a stable geometric footprint that enables lightweight, transparent screening without expensive end-to-end training. We further discuss responsible uses, limitations, and paths toward larger, more diverse human-evaluated datasets.", "tldr": "We investigate geometric signature of multi-turn deception in embeddings; we generate synthetic data, validate with a human study, and show detection", "keywords": ["Large Language Models", "Multi-Turn Deception", "Prompt Optimization", "Explainable AI", "Evolutionary Algorithms", "Synthetic Data", "Geometric Signatures"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/6a706c20831c310ded0a3e29e56fbaa2a0ef7aaf.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a unified pipeline to generate multi-turn deceptive questions and validates the dataset by a human study. The generation leverages multi-objective genetic prompt optimization with co-evolving mutation. The dataset can be used to help detect deceptive attempts in multi-turn conversations. Moreover, it identifies three geometric features, i.e., angular coverage, distance ratio, and linearity, as core indicators of deceptive attacks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper contributes a new dataset to the community, including multi-turn deceptive questions, which can be valuable for training and evaluating models in this area. Although the dataset cannot fully cover all scenarios, I think the proposed framework enables it to be extended to other scenarios.\n\nThe paper presents a small set of signals that can capture the geometric properties of deceptive conversations, which is surprising and can inspire future research. This provides good explainability for the detection of deceptive questions."}, "weaknesses": {"value": "There has been prior work on multi-turn deceptive question generation, or related topics, like multi-turn jailbreak generation. I am not sure why the paper choose to start from stretch and build their own dataset, rather than building on top of existing datasets. The paper should clarify this point.\n\nThe writing makes it a bit unclear, but I read this paper as a defense against existing systems. After all, the final product is a defense model that classifies deceptive questions. But the threat model is not clear in this case. Also, it does not really compare with alternative defense methods, like prompt rewriting, output filtering, etc. The paper should clarify the threat model and compare with alternative defense methods.\n\nThe paper also misses the discussion of efforts spent on Human-in-the-loop evaluation, which is important to evaluate the extendability of the dataset. I would appreciate it if the authors can present more details on how this part is done, e.g., expertise of the human evaluators, conflict of interests (authors, lab mates?), time spent, and cost.\n\nThe generated geometric features are interesting, but the paper does not provide a comprehensive evaluation of their robustness. Especially when the attack is adaptive, namely, optimizing prompts based on the defense, it is unclear how well these features can hold up. The paper should provide more evaluation on the robustness of these features."}, "questions": {"value": "1. Can you clarify the threat model considered in this work? Is it purely a defense against existing systems, or is there a more specific scenario in mind?\n\n2. How does the proposed defense model compare with alternative defense methods, such as prompt rewriting or output filtering? Have the authors conducted any experiments in this regard?\n\n3. What was the expertise of the human evaluators, were there any potential conflicts of interest, and what was the time and cost involved in this evaluation? More generally, how scalable is the human-in-the-loop evaluation process for extending the dataset?\n\n4. Have the authors evaluated the robustness of the identified geometric features against adaptive attacks? If so, what were the findings, and if not, do they have plans to conduct such evaluations in future work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1NVxQnACYz", "forum": "bUnG3WcSYX", "replyto": "bUnG3WcSYX", "signatures": ["ICLR.cc/2026/Conference/Submission23021/Reviewer_u9cX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23021/Reviewer_u9cX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791230046, "cdate": 1761791230046, "tmdate": 1762942479740, "mdate": 1762942479740, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "AGtbAxWYMH", "forum": "bUnG3WcSYX", "replyto": "bUnG3WcSYX", "signatures": ["ICLR.cc/2026/Conference/Submission23021/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23021/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763001990186, "cdate": 1763001990186, "tmdate": 1763001990186, "mdate": 1763001990186, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper primarily addresses the issue that LLM safety systems struggle to detect \"multi-turn, indirect\" deceptive questioning. The authors propose a unified pipeline: first, they use a \"multi-objective genetic prompt optimization\" method to automatically \"evolve\" and generate a large set of realistic multi-turn deceptive question sets ; then, they demonstrate that this multi-turn deceptive intent leaves a \"stable geometric footprint\" in embedding space. Based on this hypothesis, they trained a lightweight classifier using only a few simple geometric features (such as angular coverage, distance ratio, and linearity). Experiments show this model is highly effective, achieving a high recall of 0.89, and remains robust even when questions are \"reworded\" or the conversation is shortened. This indicates that this advanced attack can be detected using only explainable geometric signals, without expensive end-to-end training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The paper's originality lies in its unified pipeline, which uniquely combines a multi-objective evolutionary algorithm for generating novel multi-turn deceptive datasets with an innovative, lightweight detector based on a \"geometric footprint\" hypothesis. This approach of using simple, explainable geometric features to detect complex, coordinated multi-turn intent is a creative departure from common defenses that focus on single-turn heuristics, or end-to-end classifiers.\n\nQuality: The work is of high quality, supported by a rigorous methodology. The authors did not just generate synthetic data; they validated it through a Human-in-the-Loop (HITL) study involving 52 participants, confirming that the data captures human-perceived deception. The detector itself was subjected to thorough robustness checks, including evaluations on reworded (lexical variation) and truncated (turn-constrained) datasets, demonstrating consistently high recall and strong generalization.\n\nClarity: The paper is written with high clarity. It clearly defines the specific threat model of multi-turn, indirect probing, using a concrete 5-question example about explosives to illustrate the concept . The novel geometric features (angular coverage, distance ratio, linearity) are explicitly defined and motivated . The experimental design is logical, cleanly separating the data generation/validation (Experiment 1) from the detector performance evaluation (Experiment 2).\n\nSignificance: This work is significant as it addresses a critical and nuanced vulnerability in current LLM safety defenses. Its primary contribution is a detector that is lightweight, explainable, and effective, making it highly suitable for practical, near real-time deployment. The finding that the detector maintains high recall (0.89) even when conversations are truncated to just three turns is particularly important, as it demonstrates a viable path toward early intervention before a harmful goal is achieved."}, "weaknesses": {"value": "weakness 1: The Issue: The experimental design contains a significant confounding variable. All \"deceptive\" samples (60 sets) were generated around a single topic (\"bomb\") , while all \"non-deceptive\" samples (139 sets) were sourced from an entirely different dataset (Scale AI's general-purpose conversations).\n\nweakness 2: The authors claim to test robustness to \"lexical variation,\" but their method involved using Qwen-3B to generate paraphrases while enforcing an extremely strong constraint of \"minimum 80% word overlap\" This does not represent a genuine adversarial paraphrase. An 80% overlap implies the sentences are textually highly similar. A real attacker would use queries with far lower lexical overlap. Therefore, the reported performance on the \"Reworded\" set (F1 0.757) likely grossly overestimates the model's true robustness against a realistic adversary."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no Ethics Concerns"}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Y8ZHEYCpsT", "forum": "bUnG3WcSYX", "replyto": "bUnG3WcSYX", "signatures": ["ICLR.cc/2026/Conference/Submission23021/Reviewer_2YaF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23021/Reviewer_2YaF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839472494, "cdate": 1761839472494, "tmdate": 1762942479329, "mdate": 1762942479329, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a unified pipeline for generating and detecting multi-turn deceptive questioning of LLMs. The authors use multi-objective genetic algorithms to create synthetic datasets of indirect questions designed to elicit prohibited information, then develop a lightweight detector using geometric features in embedding space. The work addresses a timely and important problem in LLM safety."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**Novel and interesting approach**: Investigating multi-turn jailbreak defense from the perspective of geometric features in embedding space is creative and well-motivated.\n\n**Preliminary promising results**: The initial experiments demonstrate potential effectiveness of the approach."}, "weaknesses": {"value": "1.**Insufficient Model Generalizability** .The method's effectiveness is only explored on one target model. The authors should investigate the generalizability of their conclusions and methods across multiple models.\n\n2.**Incomplete Discussion and Comparison with Existing Work and Baselines**.This paper proposes a synthetic data generation method to construct multi-turn jailbreak inputs. However, there already exist many multi-turn jailbreak studies, including works that decompose jailbreaks into multiple seemingly benign questions.  The authors should evaluate whether their detector can successfully defend against existing multi-turn jailbreak attacks.\n\nReference, for example: Chain of attack: a semantic-driven contextual multi-turn attacker for LLM\n\n3.**Concerns About False Positive Rate on Non-deceptive Datasets** Although the paper reports test accuracy, considering the dataset imbalance (non-deceptive data comprises a small proportion), I worry this metric may not be sufficiently strong."}, "questions": {"value": "Can the detector proposed in this paper defend against existing multi-turn jailbreak attacks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TSGc9xhXsm", "forum": "bUnG3WcSYX", "replyto": "bUnG3WcSYX", "signatures": ["ICLR.cc/2026/Conference/Submission23021/Reviewer_Qv3q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23021/Reviewer_Qv3q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893604615, "cdate": 1761893604615, "tmdate": 1762942478926, "mdate": 1762942478926, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the underexplored problem of detecting multi-turn deceptive interactions targeting large language models (LLMs). Existing safety defenses are typically evaluated on single-turn prompts, overlooking the multi-turn strategies adversaries use to indirectly elicit prohibited information. The authors propose a unified framework that (1) generates realistic deceptive multi-turn question sets using multi-objective evolutionary optimization with co-evolving mutation operators and (2) detects deceptive intent through geometric signatures in embedding space. Three geometric features, angular coverage, distance ratio, and linearity, combined with pairwise similarity statistics are used to train a lightweight classifier that achieves high recall across several test conditions (base, reworded, and truncated scenarios). Human evaluation validates the realism of the generated data and demonstrates that deceptive multi-turn prompts exhibit consistent geometric patterns."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Introduces a novel and timely perspective on multi-turn deception detection in LLM interactions.\n\n* Develops a two-stage pipeline combining synthetic data generation and interpretable detection, both thoughtfully designed.\n\n* The multi-objective genetic optimization with human-in-the-loop validation is well-motivated and produces plausible multi-turn deceptive examples."}, "weaknesses": {"value": "* Rationale for geometric features needs deeper justification\n\nThe paper introduces angular coverage, distance ratio, and linearity as the core geometric features but does not sufficiently explain why these particular measures capture deceptive intent better than alternatives (e.g., manifold curvature, entropy of pairwise similarity, or graph centrality measures). The underlying intuition, that deception manifests as a geometric “footprint”, is intriguing but would benefit from theoretical or empirical support demonstrating these features’ discriminative value beyond heuristic reasoning. Including feature ablation studies or comparisons against alternative spatial statistics would make the claim more convincing.\n\n* Limited generalization and dataset diversity\n\nThe experiments focus primarily on a single task, eliciting dangerous information about explosives, which may limit generalization to other domains of deception (e.g., social manipulation, misinformation, or medical advice). Although the approach is general, the lack of cross-domain validation makes it unclear how robust the geometric signatures are across topics and languages. The authors could improve the paper by demonstrating transferability of the detector to a different harmful intent category.\n\n* Overemphasis on numeric performance without deeper interpretability\n\nWhile quantitative results are strong (F1 up to 0.86 and recall up to 0.89), the discussion of why these metrics manifest is shallow. Visualization of the embedding geometry, for instance, through PCA or t-SNE plots showing deceptive versus benign clusters, could greatly enhance interpretability and substantiate claims of distinct geometric patterns.\n\n* Limited theoretical grounding in cognitive or linguistic deception theory\n\nThe work would benefit from connecting the geometric patterns observed to linguistic or cognitive theories of deception, for instance, how deceptive multi-turn questioning reflects shifts in semantic coherence or topic exploration that manifest geometrically in embedding space. This would provide a richer conceptual explanation for the empirical results."}, "questions": {"value": "Could the authors elaborate on the intuitive or mathematical rationale for selecting angular coverage, distance ratio, and linearity as geometric indicators of deception?\n\n1. How do the results change if different embedding models (e.g., larger or domain-tuned sentence transformers) are used to compute geometric features?\n\n2. How do the geometric features compare against simpler statistical or linguistic baselines (e.g., perplexity shifts, topic coherence measures, or dialogue entropy)?\n\n3. Would visualizing the embedding trajectories of deceptive versus benign conversations help confirm that geometric separability exists?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "03R8UmUhAk", "forum": "bUnG3WcSYX", "replyto": "bUnG3WcSYX", "signatures": ["ICLR.cc/2026/Conference/Submission23021/Reviewer_sqqR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23021/Reviewer_sqqR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949491315, "cdate": 1761949491315, "tmdate": 1762942478542, "mdate": 1762942478542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}