{"id": "ClchcUk9Km", "number": 17910, "cdate": 1758281939957, "mdate": 1763485912451, "content": {"title": "Generalization of Gibbs and Langevin Monte Carlo Algorithms in the Interpolation Regime", "abstract": "The paper provides data-dependent bounds on the test error of the Gibbs algorithm in the overparameterized interpolation regime, where low training errors are also obtained for impossible data, such as random labels in classification. The bounds are stable under approximation with Langevin Monte Carlo algorithms. Experiments on the MNIST and CIFAR-10 datasets verify that the bounds yield nontrivial predictions on true labeled data and correctly upper bound the test error for random labels. Our method indicates that generalization in the low-temperature, interpolation regime is already signaled by small training errors in the more classical high temperature regime.", "tldr": "We give data-dependent generalization bound for the Gibbs algorithm in the interpolation regime, show their stability under Langevin Monte Carlo, and validate them on MNIST and CIFAR-10.", "keywords": ["Generalization bounds", "PAC-Bayesian analysis", "Gibbs posterior", "Langevin Monte Carlo", "stochastic gradient Langevin dynamics", "interpolation regime"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/065fe313dbcaeb1118ad61fa44218ab23177d55b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a PAC-Bayesian bound based generalization error. To make the bound applicable in practice, it is calibrated on the data with randomized labels. The bound is then tested on benchmark problems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is very transparent in the assumptions it makes and the conclusions it draws. I appreciate appendix C2 which provides experiments with different architectures and training losses."}, "weaknesses": {"value": "It is disappointing that the bound needs to be calibrated to hold in practice. To estimate the bound, one needs to repeat the experiment with randomized labels and for different temperatures, which is significantly more expensive than directly estimating the test loss. Combining this with the fact that the calibrated bound does not rigorously hold I am unsure of the proposed use the bound. \n\nGiven that the left-hand-side of Figure 1 is not a valid test of the bound (it is calibrated to hold there) the set of experiments where the bound is tested is somewhat small."}, "questions": {"value": "1. What is the proposed use of this bound? Could it be used instead of cross validation?\n2. The experiments section seems to suggest that the bound is not practically applicable for some losses. Can the authors provide some guidance here?\n3. How does the bound accuracy depend on the number of temperature levels?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lizqQJh4Wn", "forum": "ClchcUk9Km", "replyto": "ClchcUk9Km", "signatures": ["ICLR.cc/2026/Conference/Submission17910/Reviewer_FGWz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17910/Reviewer_FGWz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760962627919, "cdate": 1760962627919, "tmdate": 1762927728787, "mdate": 1762927728787, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes new generalization bounds for the Gibbs algorithm, where the algorithm output is sampled from a Gibbs posterior whose potential is proportional to the empirical risk. The main result are based on PAC-Bayesian argument and an integral decomposition of the error across the temperature parameter. This bound suggests that the generalization error at a given temperature is linked to the generalization error at higher temperatures. An important feature of the proposed theory is to be stable when the Gibbs posteriors at various temperatures are approximated (eg, by MCMC algorithms), making the bound computable in practice. Therefore, the theory is supported by experiments on the MNIST and CIFAR10 datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proof technique explicitly links the generalization error at different temperatures.\n- The stability by approximation makes the bounds computable in practice (with potentially an important computational cost). \n- The new bounds are data-dependent and fully computable in practice"}, "weaknesses": {"value": "*Main weaknesses:*\n - All results are written with placeholder functions in the main text. It would improve the readability to include actual generalization bounds directly in the main text.\n - Due to the representation of the bound as a discrete integral over several higher temperatures, the experiments are very computationally heavy, as Gibbs posteriors at several temperatures have to be approximated. This might diminish the practical reach of the proposed theory.\n\n*Other (more minor) issues:* \n - Line 73: $\\epsilon$ should be $\\epsilon_{\\beta_k}$\n - Line 105, $P(H) \\times P(H)$ should be $P(H \\times H)$.\n - Lline 206, as $\\exp(F)$ is positive, it seems to me that we do not need much condition to exchange the two expectations\n - $KL$ would be more beautifully written $\\mathrm{KL}$."}, "questions": {"value": "- Is it correct that Corollary 4.2 is a consequence of known results?\n- Line 415: why do we need to distinguish between $\\beta$ and $2\\beta$\n- Do you think that it could be possible to make the experiments less computationally heavy by using the estimation of the posterior at higher temperatures as a kind of \"warm-start\" for lower temperatures, if that can make sense in your setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mepkS7wuyT", "forum": "ClchcUk9Km", "replyto": "ClchcUk9Km", "signatures": ["ICLR.cc/2026/Conference/Submission17910/Reviewer_V25C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17910/Reviewer_V25C"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761568578925, "cdate": 1761568578925, "tmdate": 1762927728180, "mdate": 1762927728180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is way out of my expertise, I am not in a position to offer a meaningful evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "."}, "weaknesses": {"value": "."}, "questions": {"value": "."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "SKKNRKExu6", "forum": "ClchcUk9Km", "replyto": "ClchcUk9Km", "signatures": ["ICLR.cc/2026/Conference/Submission17910/Reviewer_miYM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17910/Reviewer_miYM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895288214, "cdate": 1761895288214, "tmdate": 1762927727522, "mdate": 1762927727522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper provides a mechanism for bounding test error in overparametrized regimes for Gibbs sampling algorithms (and approximations such as Langevin Monte Carlo), which accurately captures generalization error in the low temperature regime."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper shows a scheme for bounding the test error which is rigorously derived and implementable.\n\nIn the experiments presented, the predictions appear to align well with the ground truth."}, "weaknesses": {"value": "I think this paper is not doing anything particularly novel. On the sampling side, the rates of Vempala and Wibisono are already somewhat outdated by the standards of the field and much better analysis is known for the LSI setting. See for instance some of the works on the proximal sampler.\n\nConversely, although I am less familiar with the learning theory elements, Theorem 3.2 appears to me to be straightforward. Thus, even if this exact result has not appeared in the literature before, the ideas in this paper do not seem particularly novel or surprising.\n\nIt is not really possible to assess whether this schema will be useful in practice, as the experiments appear somewhat small in scale. I would imagine that Gibbs sampling on large datasets is both expensive and unlikely to yield informative bounds."}, "questions": {"value": "The terminology \\emph{interpolation regime} is never defined.\n\n219: iid -> i.i.d.\\\n\n224 has an extra comma\n\n326:  the Theorem 1 -> Theorem 1\n\n364: sand -> and"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VTspB8UVdA", "forum": "ClchcUk9Km", "replyto": "ClchcUk9Km", "signatures": ["ICLR.cc/2026/Conference/Submission17910/Reviewer_rD1H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17910/Reviewer_rD1H"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965591514, "cdate": 1761965591514, "tmdate": 1762927726973, "mdate": 1762927726973, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}