{"id": "gmHCxj1fYI", "number": 14665, "cdate": 1758241230056, "mdate": 1759897356351, "content": {"title": "Towards Knowledge‑and‑Data‑Driven Organic Reaction Prediction: RAG‑Enhanced and Reasoning‑Powered Hybrid System with LLMs", "abstract": "In organic reaction prediction, many recent approaches ranging from traditional task-specific models to Large Language Models (LLMs), have demonstrated notable success. However, these methods are inherently data-driven, exhibit constrained interpretability, and have hit fundamental performance bottlenecks. To overcome these limitations, we present Reaction-Thinker, a hybrid, knowledge‑and-data‑driven system that is enhanced by Retrieval‑Augmented Generation (RAG) and powered by advanced reasoning, improving both the interpretability of prediction process and the explainability of results. We develop similar-case retrieval database and train a RAG‑based LLM through supervised fine-tuning (SFT) to apply both reaction types and similar reaction cases as knowledge. We also construct a reaction reasoning chain-of-thought (CoT) dataset and train a reasoning-based LLM through SFT, then further optimize it using Group Relative Policy Optimization (GRPO). Experimental results show that our method outperforms all compared LLMs and task-specific models, achieving the highest accuracy (Exact Match) and fingerprint similarity (FTS). Ablation study indicates improvements in relative accuracy of 7.5% and 13.9% for RAG and GRPO, respectively. Further analysis of mispredictions reveals limitations in conventional evaluation metrics, which motivates our proposed benchmarking refinement.", "tldr": "", "keywords": ["Organic Reaction Prediction", "Large Language Models", "Retrieval‑Augmented Generation", "Chain‑of‑Thought Reasoning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d149d8c9321bf5eaf3c7125922acacd94e40098c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work targets the forward reaction prediction problem in organic chemistry, leveraging a combination of RAG, SFT, and GRPO techniques. Compared to prior works described in the paper, Reaction-Thinker demonstrates strong performance with enhanced interpretability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The authors effectively combine existing methods—SFT, RAG, and GRPO—to tackle the forward reaction prediction task.\n- A rigorous ablation study is presented to validate the contribution of each component in the proposed system."}, "weaknesses": {"value": "- It is somewhat limiting that the proposed system only addresses forward reaction prediction. Given that the system is built on RAG and LLM architectures, it would be more impactful to extend it to a broader range of chemistry problems.\n\n- Most baselines are distilled LMs from DeepSeek-R1, but comparisons with larger proprietary models such as GPT or Claude would strengthen the evaluation.\n\n- The proposed method utilizes 32B-scale Qwen/DeepSeek models, whereas the compared chemical LLMs are mostly T5-based or smaller models (up to 13B). A more comprehensive and rigorous baseline search for forward reaction prediction is needed. The related-work section should include a dedicated discussion of existing forward-reaction models, along with direct comparisons.\n\n- The authors use the USPTO and ORD datasets; however, to ensure a fair benchmark evaluation, it is necessary to evaluate on the USPTO/Pistachio dataset. Based solely on Table 1, it is difficult to clearly verify the claimed superiority of Reaction-Thinker.\n\n- The paper does not provide reproducible code or pseudocode."}, "questions": {"value": "- In Section 2.4, how exactly is the RAG-based LLM fine-tuned? Are the retrieved similar-case samples simply concatenated with the input during fine-tuning? What happens if retrieval is applied without additional fine-tuning?\n\n- Interpretability is emphasized as one of the main motivations, but no in-depth analysis is provided. Does “interpretable” simply mean that the model outputs a reasoning trace in natural language?\n\n- During inference, there could be cases where the final predicted product is correct but the intermediate reasoning steps are wrong. Is there any analysis of such discrepancies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NI4464rklA", "forum": "gmHCxj1fYI", "replyto": "gmHCxj1fYI", "signatures": ["ICLR.cc/2026/Conference/Submission14665/Reviewer_hZJv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14665/Reviewer_hZJv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799198523, "cdate": 1761799198523, "tmdate": 1762925036517, "mdate": 1762925036517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Reaction-Thinker, a hybrid “knowledge + data” framework for predicting products of organic reactions. The pipeline includes a reaction-type classifier, a similar-case retrieval library, and two predictors (RAG and CoT). The authors report SOTA Exact-Match and FTS on ORD (ORDERly split)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The method uses two routes that mirror practice in organic synthesis: cases with similar precedents are handled by RAG, while cases without precedents are handled by CoT + GRPO to strengthen step-by-step reasoning."}, "weaknesses": {"value": "As noted in section 3.4, the Retro* check only verifies that some retrosynthetic route exists and does not enforce consistency with the given reaction conditions (precursors, catalysts etc.). Counting “retrosynthesizable” as correct may therefore overestimate forward attainability in real settings."}, "questions": {"value": "1. The paper states that the retrieval library is built entirely from the training split. But what is the dataset scope used to construct the SFT and CoT corpus, is there any risk of data leakage?\n\n2. Results are reported under a single fixed threshold M (RAG subset Exact-Match 94.70%, CoT subset 68.24%, overall 89.86%). How was this M chosen?\n\n3. How is the quality of the CoT corpus ensured, and how is reaction mechanism correctness enforced? Can the method provide white-box organic reaction explanations that are consistent with the correct product prediction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HKshUYmm41", "forum": "gmHCxj1fYI", "replyto": "gmHCxj1fYI", "signatures": ["ICLR.cc/2026/Conference/Submission14665/Reviewer_q5vK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14665/Reviewer_q5vK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809570085, "cdate": 1761809570085, "tmdate": 1762925036149, "mdate": 1762925036149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Reaction-Thinker, a system for organic reaction prediction with the following pipeline: 1. a 2-layer MLP that takes molecular fingerprints and generates a reaction embedding and reaction classification; 2. a reaction embedding database for RAG; 3. a RAG LLM for reactions that have similar reactions in the database, trained with SFT; 4. a reasoning LLM trained with SFT and GRPO for reactions that don’t have similar reactions in the database."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. *Originality:* The work presents a novel application of NLP methods (RAG, SFT/RL post-training) to chemistry tasks.\n\n2. *Quality:* The work conducts extensive experiments and ablation studies, and the training and inference procedures are well-documented."}, "weaknesses": {"value": "1. The methodology itself is not novel, and the novelty lies in applying existing methods to an existing task. (Although retrieval for chemistry has been previously explored as well, see, e.g., [1]).\n\n2. The approach seems a lot more costly than, e.g., Chemformer, which may be a limitation when being applied to screen large numbers of potential reactions. (And the performance benefits w.r.t. Chemformer seem marginal.)\n\n3. The related work section (Appendix A.1) currently only mentions related work from the NLP literature. For completeness, it should also describe past work from the AI-for-chemistry literature, including the baselines the authors cited, papers cited in the introduction section, as well as potentially other works such as [1, 2, 3].\n\n4. The provided anonymous link to the source code doesn’t work—while I can see the directory structure of the repo, all files show up as “The requested file is not found.”\n\n5. By the way, there’s a formatting issue where all citations appeared to have used \\citet{} instead of \\citep{}. There are also scattered typos (line 22 missing “a”; line 706 “LLM” -> “LLMs”; etc.). \n\n[1] Qian, Yujie, et al. \"Predictive Chemistry Augmented with Text Retrieval.\" *EMNLP*, 2023.\n\n[2] Gao, Hanyu, et al. \"Using machine learning to predict suitable conditions for organic reactions.\" *ACS Central Science 4*(11), 2018.\n\n[3] Edwards, Carl, et al. \"mCLM: A Function-Infused and Synthesis-Friendly Modular Chemical Language Model.\" arXiv preprint arXiv:2505.12565, 2025."}, "questions": {"value": "1. The paper mentions the performance of RAG on reactions for which a reaction was retrieved, as well as the performance of the reasoning model on reactions for which no reaction was retrieved. I’m curious what the numbers are for the baselines and ablations for these two subsets as well.\n\n2. For the new evaluation method with retrosynthetic validation, only the number for Reaction-Thinker was given. I’m curious what the results are for the baselines? i.e., what does an additional column in Table 1 look like for this new evaluation method?\n\n3. For the USPTO-MIT test set, only the numbers for the reasoning model part of Reaction-Thinker (with SFT and GRPO ablations) were given (in Table 5). I’m curious what Table 1, which reports results for the ORD test set only, would look like for the USPTO-MIT test set?\n\nWhile not essential, I believe that answering the above questions in the main text would strengthen the paper’s evaluation and analysis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b3JOLQ0jGf", "forum": "gmHCxj1fYI", "replyto": "gmHCxj1fYI", "signatures": ["ICLR.cc/2026/Conference/Submission14665/Reviewer_1yzM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14665/Reviewer_1yzM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762333291863, "cdate": 1762333291863, "tmdate": 1762925035727, "mdate": 1762925035727, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}