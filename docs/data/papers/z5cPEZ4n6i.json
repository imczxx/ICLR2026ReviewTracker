{"id": "z5cPEZ4n6i", "number": 23007, "cdate": 1758338047918, "mdate": 1759896836137, "content": {"title": "LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning", "abstract": "Large Language Models (LLMs) demonstrate their reasoning ability through chain-of-thought (CoT) generation. However, LLM's  autoregressive decoding may limit the ability to revisit and refine earlier tokens in a holistic manner, which can also lead to inefficient exploration for diverse solutions. In this paper, we propose \\textit{LaDiR} (\\textbf{La}tent \\textbf{Di}ffusion \\textbf{R}easoner), a novel reasoning framework that unifies the expressiveness of continuous latent representation with the iterative refinement capabilities of latent diffusion models while operating effectively without large-scale pretraining. We first construct a structured latent reasoning space using a Variational Autoencoder (VAE) that encodes text reasoning steps into blocks of thought tokens, preserving semantic information and interpretability while offering compact but expressive representations. Subsequently, we utilize a latent diffusion model that learns to denoise a block of latent \\textit{thought tokens} with a blockwise bidirectional attention mask, enabling longer horizon and iterative refinement with adaptive test-time compute. This design allows efficient parallel generation of diverse reasoning trajectories, allowing the model to plan and revise the reasoning process holistically. We conduct evaluations on a suite of mathematical reasoning and planning benchmarks. Empirical results show that LaDiR consistently improves accuracy, diversity, and interpretability over existing autoregressive, diffusion-based, and latent reasoning methods.", "tldr": "LaDiR is a novel latent reasoning framework that encodes latent “thought tokens” with a VAE and predicts them via latent diffusion models, enabling adaptive test-time compute, parallel diverse generation, and better intepretability.", "keywords": ["Large Language Models", "Reasoning", "Diffusion Models", "Latent Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/703e7582d1426c08a9769fd857e2cbbb841b7e54.pdf", "supplementary_material": "/attachment/c16dd37e2c9a7d0eb1461657804dff56eb203fc7.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes LaDiR (Latent Diffusion Reasoner), a new framework to improve the reasoning capabilities of LLMs by modeling the reasoning process in a continuous latent space using a diffusion model. The framework consists of first learning a VAE to encode the textual reasoning traces to blocks of continuous though tokens, and then a latent diffusion model to generate a sequence of blocks of latent reasoning tokens.The authors demonstrate empirically that LaDiR, using a LLaMA 3.1 8B backbone, outperforms or matches autoregressive baselines (COT and SFT) and other latent-space reasoning methods on a suite of mathematical reasoning and planning benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-motivated and situated within the growing literature on reasoning in large language models (LLMs).\n2. The experiments provide convincing evidence of the method’s efficacy across multiple reasoning and planning tasks. Even though the gains over baselines are not always large or consistent, the method produces more interpretable reasoning traces (when decoded into text) and supports flexible trade-offs between inference compute and performance.\n3. The technical presentation is clear and well-organized, and the figures are particularly helpful in conveying key concepts."}, "weaknesses": {"value": "My major concern is on the computational cost and complexity of the method. \n1. The multi-stage training pipeline — involving VAE pretraining followed by two stages of diffusion model training — is considerably much more involved than the baselines. Inference requires T denoising steps for B blocks, which is substantially slower than a single-pass autoregressive generation. The paper would be stronger if the paper would include a more direct comparison of the FLOPs against its baselines, and some discussion on how the induced overhead could be reduced in the future, as well as the difficulties of tuning the hyperparameters.\n2. All experiments are conducted on an 8B model. It would be helpful if the model could include a more explicit discussion / analysis on how the framework scales (with data and model sizes of different components)."}, "questions": {"value": "1. Could you provide a more direct comparison of the computational cost (e.g., total FLOPs or wall-clock time) between LaDiR and the baselines?\n2. The example decoded reasoning trace is surprisingly readable from Table 3 on the Countdown task. While interpretability is nice, it also seems to suggest that the latent space is still very aligned with the text space. Did you experiment with other settings that induce less interpretable latent thoughts and if so how did that impact the downstream task performance?\n3. The method adopts a one sentence per block strategy. Although it seems natural for the tasks in the paper, it might not always be the optimal choice for all the cases. It could be helpful to include some analysis on how sensitive the model is to the blockization strategy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "arGCud5JG5", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_VgbG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_VgbG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890988059, "cdate": 1761890988059, "tmdate": 1762942476129, "mdate": 1762942476129, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Reviewer D4vn and nMv9's Concerns on Related Work and Novelty [Part 2]"}, "comment": {"value": "### 3. Planned Revisions\n\nTo address this feedback comprehensively:\n\n- We will add a new paragraph in Related Work comparing our approach with Diffusion-LM, LD4LG, and PLANNER (with citations and distinctions summarized as above).\n\n- We will reframe the Introduction and Figure 1 to emphasize our focus on latent reasoning rather than architectural novelty.\n\n- We will add an additional baseline comparison to the aforementioned latent diffusion text generation methods (e.g., PLANNER) using our reasoning datasets, acknowledging the methodological similarities.\n\nWe thank the reviewers again for this valuable feedback. We hope these clarifications and additions will substantially strengthen the paper’s positioning and transparency."}}, "id": "p2N2L5xUcQ", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763432340668, "cdate": 1763432340668, "tmdate": 1763432340668, "mdate": 1763432340668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Reviewer D4vn and nMv9's Concerns on Related Work and Novelty [Part 2]"}, "comment": {"value": "### 3. Empirical Comparisons and Planned Revisions\n\nTo provide a direct and controlled comparison with existing latent diffusion approaches, we re-ran **LD4LG** and **PLANNER** under the same experimental setting. Specifically, we used the same **LLaMA-3.1-8B** model for the VAE decoder for all methods, **FLAN-T5** as the encoder for LD4LG and PLANNER, and trained all methods on the same reasoning datasets. For LD4LG and PLANNER, following the implementation in the original papers, we encoded the **answer paragraph** into a single latent representation (i.e., no block diffusion).\n\nThe results are summarized below:\n\n| Method        | MATH | GSM8K |\n|---------------|------|--------|\n| **PLANNER**   | 5.7  | 18.7   |\n| **LD4LG**     | 9.1  | 32.9   |\n| **LaDiR (ours)** | **45.2** | **84.2** |\n\nThese results highlight a big performance gap: while LD4LG and PLANNER prioritize **fluency** of text generation, they do not effectively support **multi-step reasoning**. In contrast, LaDiR is explicitly designed for latent **reasoning**, resulting in significantly stronger performance on reasoning benchmarks.\n\nTo address the feedback comprehensively:\n\n- We will add a new paragraph in Related Work comparing our approach with Diffusion-LM, LD4LG, and PLANNER (with citations and distinctions summarized as above).\n\n- We will reframe the Introduction and Figure 1 to emphasize our focus on latent reasoning rather than architectural novelty.\n\n- We will add an additional baseline comparison to the aforementioned latent diffusion text generation methods in the main paper, acknowledging the methodological similarities.\n\nWe hope these clarifications and additions will substantially strengthen the paper’s positioning and transparency."}}, "id": "p2N2L5xUcQ", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763432340668, "cdate": 1763432340668, "tmdate": 1763447207902, "mdate": 1763447207902, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for text generation via latent diffusion using a block autoregressive generation strategy. They train a beta-VAE to auto-encode text. During training they incorporate a number of ad-hoc data augmentations including adding additional noise to the auto-encoder latents, and randomly replacing a token with another token randomly chosen from the vocabulary. Diffusion training requires two stages, the first is supervised training to match target latent blocks as well as generate correct answers and special token placements. Stage 2, requires rolling out latent blocks autoregressively and supervising it with the answer, backpropogating that signal through the rollout. They also propose a guidance technique for encouraging diversity among a group of samples in a batch. They benchmark against autoregressive and discrete diffusion baselines on math datasets. They also benchmark in the countdown setting which is common for evaluating planning/reasoning ability."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* The rollout training is interesting - specifically teaching the model to determine how long to think for.\n* Consistent improvement over CoT in math benchmarks.\n* Strong improvement over LLaMA and LLaDA on Countdown Pass@1"}, "weaknesses": {"value": "* The introduction and related work (including the related work in the appendix) carefully side steps any discussion of prior work on latent diffusion for language (yet all other topics in related work is discussed thoroughly). The current draft is incredibly misleading (almost implying they are the first to do latent language diffusion). There is a significant body of work in place that must be discussed in this paper, as this work is a direct followup to the existing work. A few of the relevant citations include,\nZhang, Y., Gu, J., Wu, Z., Zhai, S., Susskind, J., & Jaitly, N. (2023). Planner: Generating diversified paragraph via latent language diffusion model. Advances in Neural Information Processing Systems, 36, 80178-80190.\nLovelace, J., Kishore, V., Wan, C., Shekhtman, E., & Weinberger, K. Q. (2023). Latent diffusion for language generation. Advances in Neural Information Processing Systems, 36, 56998-57025.\n* Further all experiments in this work only compare against autoregressive and discrete diffusion models, while the obvious and necessary comparison is the existing latent language diffusion works mentioned above. The contribution of this paper is not clear without the direct comparison to other latent language diffusion models.\n* The improvements on the math benchmarks are pretty marginal, and there is no time/compute comparison provided in the paper.\n* The robustness augmentations to the VAE training are ad-hoc, and they provide no ablation or study of the affects of this choice.\n* This sentence \"Unlike AR models that generate a single reasoning trajectory sequentially, our framework can generate multiple diverse reasoning trajectories in parallel within a batch.\" implies that AR models cannot do batched sampling. This is incorrect you can do batched sampling with AR models.\n* The diversity improvements are not ablated. Even more concerning they are only used in the Countdown setting. If you are going to report with diversity improvements on Countdown you need to report with and without the diversity improvements in both Countdown and the mathematics benchmarks (otherwise it comes off as a trick to improve one setting).\n* Pass@100 is a strange metric to report, Pass@1 is much more meaningful.\n* On line 301 I believe you meant to write \"... analysis in Section 4.4 provide ...\""}, "questions": {"value": "Figure 5 shows performance as a function of denoising steps for LaDiR vs. CoT, would be interesting to see wall clock times comparing the two methods. How many denoising steps can you complete in the time it takes to do CoT? Do you have a compute/time controlled comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xMCJ4X0Nss", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_D4vn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_D4vn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962813839, "cdate": 1761962813839, "tmdate": 1762942475913, "mdate": 1762942475913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Reviewer D4vn and nMv9's Concerns on Related Work and Novelty [Part 1]"}, "comment": {"value": "We thank the reviewers for bringing up the prior works on continuous/latent diffusion models for language generation (e.g., Diffusion-LM [Li et al., ICLR 2022], LD4LG [Lovelace et al., NeurIPS 2023], PLANNER [Zhang et al., NeurIPS 2023]). We recognize that these papers are related to our work and we will revise the Related Work and Introduction sections to explicitly include these works. Also, we appreciate the opportunity to clarify both the relationship and difference between our approach and these prior methods.\n\n### 1. Clarifying Relationship to Continuous/Latent Diffusion for Text Generation\n In particular:\n\n- Diffusion-LM first introduced continuous diffusion for text generation in the embedding space;\n- LD4LG and PLANNER proposed autoencoder-based latent diffusion for text, where a VAE first maps text into a latent space and a diffusion model diffuse/denoise in this space, which finally requires a VAE decoder to reconstruct fluent text outputs after denoising.;\n- Our model builds on this general paradigm but **targets a fundamentally different goal: reasoning rather than generation**.\n\nUnlike prior works, which aim to improve text quality or diversity, our focus is on latent reasoning — modeling the reasoning process itself as a continuous diffusion over latent thought representations, rather than over token or embedding spaces. More importantly, **we emphasize the ability of latent tokens that lead to the correct answer**, as captured through our rollout training procedure: we explicitly propagate training signals from answer tokens back to the latent tokens that generated them. **This setup allows the diffusion process to learn which latent thoughts contribute to correct reasoning outcomes, rather than merely producing fluent text.** This reframing changes both the training objective — from text likelihood to reason consistency and answer alignment — and the evaluation protocol — from fluency to reasoning correctness on multi-step reasoning tasks.\n\n### 2. Novelty of Our Work\n\nWhile the underlying autoencoder–diffusion structure is similar in spirit to PLANNER and LD4LG, adapting latent diffusion to reasoning imposes several important changes. Prior latent diffusion works are designed for *language generation*, where the objective is to reconstruct or generate fluent text. In contrast, our focus is **latent reasoning**, which *requires learning latent trajectories that causally lead to correct answers, not textual fluency*. To make latent diffusion suitable for reasoning tasks, we introduce the following key adaptations:\n \n- **Variable-length continuous latent diffusion via blockwise reasoning:** Prior latent diffusion works such as PLANNER and LD4LG generate an entire sentence or paragraph from a single *fixed-sized* latent representation. In contrast, we model each reasoning step as a separate block and introduce a semi-autoregressive blockwise diffusion process that allows the model to *learn causal dependencies between reasoning steps*. This design naturally supports *variable-length* Chain-of-Thought (CoT) reasoning for tasks of different complexity. Moreover, unlike discrete block diffusion, continuous block diffusion suffers more from *error accumulation across steps*; *we address this challenge through a 2nd-stage rollout training* procedure that explicitly mitigates accumulated errors and stabilizes long-horizon reasoning.\n\n- **Improved efficiency and reduced error by avoiding unnecessary decoding:** Prior latent-diffusion text generation methods (e.g., PLANNER, LD4LG) must decode each intermediate latent back into text to evaluate generation quality or guide the next step. This repeated latent→text→latent conversion introduces **rounding and discretization errors**, which accumulate over long reasoning chains and can degrade performance. In contrast, our latent space is explicitly designed for reasoning. We only decode latent thoughts into text when interpretability is needed, rather than at every diffusion step. **This not only reduces computational cost by avoiding repeated decoder forward passes, but also prevents the accumulation of rounding error from repeatedly mapping between continuous latents and discrete tokens.** Conceptually, this aligns with recent large reasoning models (e.g., GPT-5), which keep most internal reasoning hidden—but our approach achieves this with even greater computational efficiency.\n\nWe will make this framing explicit to emphasize the novelty and architectural design tailored for reasoning tasks. The revision will clarify that our work represents an application and extension of latent diffusion modeling to the reasoning domain, introducing new learning objectives and empirical insights specific to this setting."}}, "id": "R5HSj1khPX", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763432405491, "cdate": 1763432405491, "tmdate": 1763432405491, "mdate": 1763432405491, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Reviewer D4vn and nMv9's Concerns on Related Work and Novelty [Part 1]"}, "comment": {"value": "We thank the reviewers for bringing up the prior works on continuous/latent diffusion models for language generation (e.g., Diffusion-LM [Li et al., ICLR 2022], LD4LG [Lovelace et al., NeurIPS 2023], PLANNER [Zhang et al., NeurIPS 2023]). We recognize that these papers are related to our work and we will revise the Related Work and Introduction sections to explicitly include these works. Also, we appreciate the opportunity to clarify both the relationship and difference between our approach and these prior methods.\n\n### 1. Clarifying Relationship to Continuous/Latent Diffusion for Text Generation\n In particular:\n\n- Diffusion-LM first introduced continuous diffusion for text generation in the embedding space;\n- LD4LG and PLANNER proposed autoencoder-based latent diffusion for text, where a VAE first maps text into a latent space and a diffusion model diffuse/denoise in this space, which finally *requires a VAE decoder to reconstruct fluent text outputs* after denoising;\n- Our model builds on this general paradigm but **targets a fundamentally different goal: reasoning rather than generation**.\n\nUnlike prior works, which aim to improve text quality or diversity, our focus is on latent reasoning — modeling the reasoning process itself as a continuous diffusion over latent thought representations, rather than over token or embedding spaces. More importantly, **we emphasize the ability of latent tokens that lead to the correct answer**, as captured through our rollout training procedure: we explicitly propagate training signals from answer tokens back to the latent tokens that generated them. **This setup allows the diffusion process to learn which latent thoughts contribute to correct reasoning outcomes, rather than merely producing fluent text.** This reframing changes both the training objective — from text likelihood to reason consistency and answer alignment — and the evaluation protocol — from fluency to reasoning correctness on multi-step reasoning tasks.\n\n### 2. Novelty of Our Work\n\nWhile the underlying autoencoder–diffusion structure is similar in spirit to PLANNER and LD4LG, adapting latent diffusion to reasoning imposes several important changes. Prior latent diffusion works are designed for *text generation*, where the objective is to reconstruct or generate fluent text. In contrast, our focus is **latent reasoning**, which *requires learning latent trajectories that causally lead to correct answers, not textual fluency*. To make latent diffusion suitable for reasoning tasks, we introduce the following key adaptations:\n \n- **Variable-length continuous latent diffusion via blockwise reasoning:** Prior latent diffusion works such as PLANNER and LD4LG generate an entire sentence or paragraph from a single *fixed-sized* latent representation. In contrast, we model each reasoning step as a separate block and introduce a semi-autoregressive blockwise diffusion process that allows the model to *learn causal dependencies between reasoning steps*. This design naturally supports *variable-length* Chain-of-Thought (CoT) reasoning for tasks of different complexity. Moreover, unlike discrete block diffusion, continuous block diffusion suffers more from *error accumulation across steps*; *we address this challenge through a 2nd-stage rollout training* procedure that explicitly mitigates accumulated errors and stabilizes long-horizon reasoning.\n\n- **Improved efficiency and reduced error by avoiding unnecessary decoding:** Prior latent-diffusion text generation methods (e.g., PLANNER, LD4LG) must decode each intermediate latent back into text to evaluate generation quality or guide the next step. This repeated latent→text→latent conversion introduces **rounding and discretization errors**, which accumulate over long reasoning chains and can degrade performance. In contrast, our latent space is explicitly designed for reasoning. We only decode latent thoughts into text when interpretability is needed, rather than at every diffusion step. **This not only reduces computational cost by avoiding repeated decoder forward passes, but also prevents the accumulation of rounding error from repeatedly mapping between continuous latents and discrete tokens.** Conceptually, this aligns with recent large reasoning models (e.g., GPT-5), which keep most internal reasoning hidden—but our approach achieves this with even greater computational efficiency.\n\nWe will make this framing explicit to emphasize the novelty and architectural design tailored for reasoning tasks. The revision will clarify that our work represents an application and extension of latent diffusion modeling to the reasoning domain, introducing new learning objectives and empirical insights specific to this setting."}}, "id": "R5HSj1khPX", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763432405491, "cdate": 1763432405491, "tmdate": 1763447428542, "mdate": 1763447428542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work adapts latent language diffusion to reasoning tasks. This work follows the typical pattern of first training a language autoencoder and then training a diffusion model in that continuous space. This work then trains a reasoning model which sequentially diffuses latent representations of textual thoughts before producing the final answer. They evaluate their approach for mathematical reasoning tasks and a synthetic puzzle task."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This work focuses on an interesting area (latent reasoning) that is gaining interest in the prior year.\n\nOne big problem with prior latent reasoning approaches (e.g. Coconut) is that it is challenging to appropriately supervise the latents. Diffusion modeling provides an elegant solution to that problem.\n\nThe authors report good results across both math reasoning tasks and a synthetic puzzle task. The visualization of the decoding process provides some nice intuition about the decoding process."}, "weaknesses": {"value": "This paper cannot be accepted without properly situating itself within the literature. This work extensively discusses discrete diffusion models and recent latent reasoning work, but completely omits any discussion of the most methodologically relevant work: continuous diffusion models for language generation. Although this work falls short of claiming to introduce continuous/latent language diffusion, they also fail to acknowledge or discuss prior work that has explored this approach. A reader unfamiliar with the area would reasonably be given the impression that this approach is entirely unexplored before this current submission.\n\nWorks like Diffusion-LM, LD4LG, PLANNER, have already explored continuous diffusion for language generation across a variety of tasks, the latter two exploring latent diffusion in a very similar setup to this work. These are not obscure papers. They are highly cited papers published at top conferences 1+ years ago. Basic searches (e.g. “latent language diffusion”) return these papers as top results. In particular, the autoencoder design in the current submission seems to follow PLANNER very closely. The core technical approach (i.e. autoencoder-based latent diffusion for text) is established in prior work. This paper’s contribution is applying this approach to reasoning tasks, which is potentially valuable but must be communicated clearly. \n\nThis is not an isolated oversight. The related works section is otherwise quite comprehensive and discusses discrete diffusion and latent reasoning at length, but completely omits any mention of continuous/latent language diffusion. This gap covers the most methodologically relevant prior work.\n\nThere are various downstream weaknesses that stem from this omission. Given that this is primarily an application of an existing approach, the framing in the intro and in Figure 1 gives an uninformed reader an incorrect impression of the contribution of this work.\nAn unnecessary amount of space is given to motivating and describing the VAE design when it is almost the same as the PLANNER VAE architecture. \n\nThere are other weaknesses that can be discussed, but the primary issue with this work is the above mentioned. The combination of a complete omission of the most methodologically relevant prior work and a framing that implies novelty for an existing approach warrants rejection.\n\nThe description of the diffusion and autoregressive architecture and how precisely they are trained is unclear. The figure makes them appear to be one model, but the text uses f() and p() to denote the diffusion and autoregressive models, respectively, with different parameters. If they are one model, the training procedure is unclear given that the autoregressive model and diffusion model receive different inputs (clean vs noisy latent thoughts). Are they simply multi-tasked? Are there two separate models as the notation, but not the figure, implies?\n\nThis statement is untrue:\n“Unlike AR models that generate a single reasoning trajectory sequentially, our framework can generate multiple diverse reasoning trajectories in parallel within a batch“\nAutoregressive models are also capable of batched inference.\n\nThe modification to improve diversity seem somewhat arbitrary and are only used to drive up the PASS@100 metric for the Countdown task which of course benefits significantly from increasing diversity. The benefits of these changes are not demonstrated elsewhere.\n\nMany training and implementation details are omitted. How long were various models trained for? With what hyperparameter settings, etc?\n\nDiscussion of inference latency is not present. Inference should be much slower than the purely autoregressive baselines."}, "questions": {"value": "I do not have additional questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "I0QVSqFF6r", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_nMv9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_nMv9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970536386, "cdate": 1761970536386, "tmdate": 1762942475513, "mdate": 1762942475513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response to Common Weaknesses"}, "comment": {"value": "We thank all reviewers for their time and feedback. We would like to address several common weaknesses from reviewers below:\n\n### Common Weakness 1 (from Reviewer nMv9, D4vn and VgbG): \n\n> Discussion of inference latency is not present. Inference should be much slower than the purely autoregressive baselines.\n\n**Response to Common Weakness 1:**  \nThank you for highlighting the missing latency comparison. We have now added **inference latency results** on the MATH dataset using the same evaluation batch size (8) and identical hardware:\n\n| Method | Avg Wall-Clock Time per Example | Pass@1 | Pass@100 |\n|--------|--------------------------------|--------|----------|\n| LLaMA CoT SFT | 4.7 s | 43.1 | 89.0 |\n| **LaDiR (10 steps)** | 4.9 s | 42.9 | 90.7 |\n| **LaDiR (30 steps)** | 14.8 s | 44.9 | 92.8 |\n\nThese results show that LaDiR can **match the latency** of autoregressive baselines at **10 diffusion steps**, while enabling a flexible compute–performance trade-off at more inference steps. This efficiency stems from the fact that **each latent block contains only 4 latent tokens**, representing on average **~22 text tokens**. Such compression reduces per-step computation and shortens the preceding context for later blocks—resulting in a lower cumulative cost than autoregressive decoding, which repeatedly processes long text-token contexts.\n\n\nWe will include these updated inference latency results in the revised version.\n\n### Common Weakness 2 (from Reviewer nMv9 and D4vn):\n> Diversity improvement in math reasoning tasks is unclear.\n\n**Response to Common Weakness 2:**  \nThank you for raising this concern. Please see the updated Pass@100 results for math reasoning tasks alongside Pass@1 in a single combined table below.\n\n| Method | MATH (P@1 / P@100) | GSM8K (P@1 / P@100) | Gaokao (P@1 / P@100) | DM-Math (P@1 / P@100) | College (P@1 / P@100) | Olympia (P@1 / P@100) | TheoremQA (P@1 / P@100) | Avg (P@1 / P@100) |\n|--------|----------------------|----------------------|------------------------|-------------------------|-------------------------|--------------------------|---------------------------|--------------------------|\n| LLaDA CoT SFT | 39.0 / 59.9 | 82.3 / 92.4 | 20.1 / 43.0 | 43.7 / 50.7 | 38.9 / 58.3 | 5.9 / 10.2 | 20.9 / 26.3 | 35.83 / 48.69 |\n| LLaMA CoT SFT | 43.1 / 49.8 | 84.5 / 89.0 | 30.7 / 37.9 | 47.8 / 52.0 | 45.7 / 54.9 | 10.1 / 12.9 | 21.2 / 25.0 | 40.44 / 45.93 |\n| Coconut | 37.3 / 39.3 | 68.3 / 74.3 | 26.8 / 29.3 | 33.5 / 36.9 | 40.2 / 42.9 | 5.8 / 6.3 | 11.4 / 14.9 | 31.90 / 34.84 |\n| Discrete Latent | 43.2 / 47.3 | 83.9 / 88.6 | 33.3 / 39.7 | 44.7 / 49.5 | 47.1 / 53.7 | 13.3 / 17.8 | 20.3 / 28.5 | 40.83 / 46.44 |\n| **LaDiR** | **45.2 / 63.7** | **84.2 / 93.7** | **33.4 / 45.8** | **46.3 / 54.2** | **48.6 / 60.3** | **11.9 / 15.3** | **22.9 / 30.7** | **41.79 / 51.96** |\n\n**Key takeaways:**  \n1. **LaDiR achieves the highest Pass@100 across math datasets**, showing that its diversity-improving mechanism **generalizes beyond Countdown** and consistently produces more diverse reasoning trajectories.\n2. **Coconut’s deterministic hidden-state latents** limit its ability to generate diverse solutions, which is reflected in its marginal increase from Pass@1 to Pass@100.\n3. **Standard AR SFT baselines (i.g., LLaMA CoT SFT)** also show relatively low Pass@100, indicating that *batched inference alone does not lead to better diversity in reasoning*.\n\n\nWe will consolidate these results in the revision and clarify both the accuracy and diversity benefits of LaDiR.\n\n### Common Weakness 3 (from Reviewer nMv9 and D4vn):\n> \"Unlike AR models that generate a single reasoning trajectory sequentially, our framework can generate multiple diverse reasoning trajectories in parallel within a batch.\" Autoregressive models are also capable of batched inference.\"\n\n\n**Response to Common Weakness 3:**  \nWe would like to clarify that this is a **misunderstanding**: although AR models can perform *batched inference*, batching alone does **not** guarantee **diverse** trajectories. In practice, AR models often produce highly similar reasoning traces across the batch—even at higher sampling temperatures (0.8), as shown for LLaMA 8B in Table 2 and the Response to Common Weakness 2 above.\n\nIn contrast, LaDiR includes an explicit **diversity-guidance mechanism** during inference (Lines 279–294), where a **repulsion term** encourages each latent trajectory to move away from others in the batch. This ensures that parallel trajectories explore *distinct* regions of the latent space rather than collapsing to similar solutions."}}, "id": "2Vj06vtx7Q", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763432579986, "cdate": 1763432579986, "tmdate": 1763432579986, "mdate": 1763432579986, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies LaDiR (Latent diffusion for reasoning), where the model utilizes blocked latent thoughts generated by diffusion methods and generates the final answer conditioned on these latent thoughts. The latent thoughts used for training are generated by training a VAE (variational autoencoder), which encodes the original textual CoT to latent representations. Comparisons on numerous benchmarks with several baseline methods (including SFT+CoT and several latent reasoning methods) prove the advantages of the proposed methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Using diffusion methods to generate latent thoughts is a good idea.\n2. The proposed method can flexibly control both the computational budget and the diversity of trajectories.\n3. The decoder of VAE makes the latent thought interpretable."}, "weaknesses": {"value": "1. For many equations, it would be better if the authors could define the function and variables more rigorously and clearly (e.g., by providing the shape of inputs or outputs, as discussed in the question section).\n2. In lines 35-38, the authors argued that “AR models generate a single linear chain of thought (CoT), which limits reasoning diversity and restricts exploration of multiple valid solutions”. However, AR models can also generate continuous CoT, which can explore multiple solutions in superposition as theoretically demonstrated by [1]. I think it’s worth discussing it or changing the wording to, e.g., “AR models with discrete CoT are limited by …”. \n3. In line 95, equation (1), I think the notation and definition of each function or variable should be made clearer and more rigorous. For example, what is $p\\_{\\theta}$, $p(\\cdot)$, and what’s the shape of their input and output? What is the shape of x and z, and what’s the distribution of $x$? \n\n**References**:\n\n[1] Zhu, Hanlin, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, and Yuandong Tian. \"Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought.\" arXiv preprint arXiv:2505.12514 (2025)."}, "questions": {"value": "1. When you are generating the next block, will you remove the timestamp from the previous block?\n2. I’m a bit confused by Equation (4). According to your notation, $Z^{(<=B)}$ should be the whole thought, and $y\\_{\\leq \\tau}$ is a prefix of the final answer. Why will $y_{\\tau}$ be a $< EOT >$ token since all $< EOT >$ should appear in $Z^{(<=B)}$. Am I missing anything?\n3. In line 294, what is the definition of $x\\_t$ and $x$, and what are their shape?\n4. In line 342, should it be 1\\% instead of 2\\%? (41.8 vs 40.8)\n5. In line 344, it seems that for DM-Math, CoT outperforms LaDiR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QGPSHkseXj", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_FWxU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_FWxU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972882511, "cdate": 1761972882511, "tmdate": 1762942475083, "mdate": 1762942475083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}