{"id": "z5cPEZ4n6i", "number": 23007, "cdate": 1758338047918, "mdate": 1759896836137, "content": {"title": "LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning", "abstract": "Large Language Models (LLMs) demonstrate their reasoning ability through chain-of-thought (CoT) generation. However, LLM's  autoregressive decoding may limit the ability to revisit and refine earlier tokens in a holistic manner, which can also lead to inefficient exploration for diverse solutions. In this paper, we propose \\textit{LaDiR} (\\textbf{La}tent \\textbf{Di}ffusion \\textbf{R}easoner), a novel reasoning framework that unifies the expressiveness of continuous latent representation with the iterative refinement capabilities of latent diffusion models while operating effectively without large-scale pretraining. We first construct a structured latent reasoning space using a Variational Autoencoder (VAE) that encodes text reasoning steps into blocks of thought tokens, preserving semantic information and interpretability while offering compact but expressive representations. Subsequently, we utilize a latent diffusion model that learns to denoise a block of latent \\textit{thought tokens} with a blockwise bidirectional attention mask, enabling longer horizon and iterative refinement with adaptive test-time compute. This design allows efficient parallel generation of diverse reasoning trajectories, allowing the model to plan and revise the reasoning process holistically. We conduct evaluations on a suite of mathematical reasoning and planning benchmarks. Empirical results show that LaDiR consistently improves accuracy, diversity, and interpretability over existing autoregressive, diffusion-based, and latent reasoning methods.", "tldr": "LaDiR is a novel latent reasoning framework that encodes latent “thought tokens” with a VAE and predicts them via latent diffusion models, enabling adaptive test-time compute, parallel diverse generation, and better intepretability.", "keywords": ["Large Language Models", "Reasoning", "Diffusion Models", "Latent Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/703e7582d1426c08a9769fd857e2cbbb841b7e54.pdf", "supplementary_material": "/attachment/c16dd37e2c9a7d0eb1461657804dff56eb203fc7.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes LaDiR (Latent Diffusion Reasoner), a new framework to improve the reasoning capabilities of LLMs by modeling the reasoning process in a continuous latent space using a diffusion model. The framework consists of first learning a VAE to encode the textual reasoning traces to blocks of continuous though tokens, and then a latent diffusion model to generate a sequence of blocks of latent reasoning tokens.The authors demonstrate empirically that LaDiR, using a LLaMA 3.1 8B backbone, outperforms or matches autoregressive baselines (COT and SFT) and other latent-space reasoning methods on a suite of mathematical reasoning and planning benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-motivated and situated within the growing literature on reasoning in large language models (LLMs).\n2. The experiments provide convincing evidence of the method’s efficacy across multiple reasoning and planning tasks. Even though the gains over baselines are not always large or consistent, the method produces more interpretable reasoning traces (when decoded into text) and supports flexible trade-offs between inference compute and performance.\n3. The technical presentation is clear and well-organized, and the figures are particularly helpful in conveying key concepts."}, "weaknesses": {"value": "My major concern is on the computational cost and complexity of the method. \n1. The multi-stage training pipeline — involving VAE pretraining followed by two stages of diffusion model training — is considerably much more involved than the baselines. Inference requires T denoising steps for B blocks, which is substantially slower than a single-pass autoregressive generation. The paper would be stronger if the paper would include a more direct comparison of the FLOPs against its baselines, and some discussion on how the induced overhead could be reduced in the future, as well as the difficulties of tuning the hyperparameters.\n2. All experiments are conducted on an 8B model. It would be helpful if the model could include a more explicit discussion / analysis on how the framework scales (with data and model sizes of different components)."}, "questions": {"value": "1. Could you provide a more direct comparison of the computational cost (e.g., total FLOPs or wall-clock time) between LaDiR and the baselines?\n2. The example decoded reasoning trace is surprisingly readable from Table 3 on the Countdown task. While interpretability is nice, it also seems to suggest that the latent space is still very aligned with the text space. Did you experiment with other settings that induce less interpretable latent thoughts and if so how did that impact the downstream task performance?\n3. The method adopts a one sentence per block strategy. Although it seems natural for the tasks in the paper, it might not always be the optimal choice for all the cases. It could be helpful to include some analysis on how sensitive the model is to the blockization strategy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "arGCud5JG5", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_VgbG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_VgbG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890988059, "cdate": 1761890988059, "tmdate": 1762942476129, "mdate": 1762942476129, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for text generation via latent diffusion using a block autoregressive generation strategy. They train a beta-VAE to auto-encode text. During training they incorporate a number of ad-hoc data augmentations including adding additional noise to the auto-encoder latents, and randomly replacing a token with another token randomly chosen from the vocabulary. Diffusion training requires two stages, the first is supervised training to match target latent blocks as well as generate correct answers and special token placements. Stage 2, requires rolling out latent blocks autoregressively and supervising it with the answer, backpropogating that signal through the rollout. They also propose a guidance technique for encouraging diversity among a group of samples in a batch. They benchmark against autoregressive and discrete diffusion baselines on math datasets. They also benchmark in the countdown setting which is common for evaluating planning/reasoning ability."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* The rollout training is interesting - specifically teaching the model to determine how long to think for.\n* Consistent improvement over CoT in math benchmarks.\n* Strong improvement over LLaMA and LLaDA on Countdown Pass@1"}, "weaknesses": {"value": "* The introduction and related work (including the related work in the appendix) carefully side steps any discussion of prior work on latent diffusion for language (yet all other topics in related work is discussed thoroughly). The current draft is incredibly misleading (almost implying they are the first to do latent language diffusion). There is a significant body of work in place that must be discussed in this paper, as this work is a direct followup to the existing work. A few of the relevant citations include,\nZhang, Y., Gu, J., Wu, Z., Zhai, S., Susskind, J., & Jaitly, N. (2023). Planner: Generating diversified paragraph via latent language diffusion model. Advances in Neural Information Processing Systems, 36, 80178-80190.\nLovelace, J., Kishore, V., Wan, C., Shekhtman, E., & Weinberger, K. Q. (2023). Latent diffusion for language generation. Advances in Neural Information Processing Systems, 36, 56998-57025.\n* Further all experiments in this work only compare against autoregressive and discrete diffusion models, while the obvious and necessary comparison is the existing latent language diffusion works mentioned above. The contribution of this paper is not clear without the direct comparison to other latent language diffusion models.\n* The improvements on the math benchmarks are pretty marginal, and there is no time/compute comparison provided in the paper.\n* The robustness augmentations to the VAE training are ad-hoc, and they provide no ablation or study of the affects of this choice.\n* This sentence \"Unlike AR models that generate a single reasoning trajectory sequentially, our framework can generate multiple diverse reasoning trajectories in parallel within a batch.\" implies that AR models cannot do batched sampling. This is incorrect you can do batched sampling with AR models.\n* The diversity improvements are not ablated. Even more concerning they are only used in the Countdown setting. If you are going to report with diversity improvements on Countdown you need to report with and without the diversity improvements in both Countdown and the mathematics benchmarks (otherwise it comes off as a trick to improve one setting).\n* Pass@100 is a strange metric to report, Pass@1 is much more meaningful.\n* On line 301 I believe you meant to write \"... analysis in Section 4.4 provide ...\""}, "questions": {"value": "Figure 5 shows performance as a function of denoising steps for LaDiR vs. CoT, would be interesting to see wall clock times comparing the two methods. How many denoising steps can you complete in the time it takes to do CoT? Do you have a compute/time controlled comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xMCJ4X0Nss", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_D4vn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_D4vn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962813839, "cdate": 1761962813839, "tmdate": 1762942475913, "mdate": 1762942475913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work adapts latent language diffusion to reasoning tasks. This work follows the typical pattern of first training a language autoencoder and then training a diffusion model in that continuous space. This work then trains a reasoning model which sequentially diffuses latent representations of textual thoughts before producing the final answer. They evaluate their approach for mathematical reasoning tasks and a synthetic puzzle task."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This work focuses on an interesting area (latent reasoning) that is gaining interest in the prior year.\n\nOne big problem with prior latent reasoning approaches (e.g. Coconut) is that it is challenging to appropriately supervise the latents. Diffusion modeling provides an elegant solution to that problem.\n\nThe authors report good results across both math reasoning tasks and a synthetic puzzle task. The visualization of the decoding process provides some nice intuition about the decoding process."}, "weaknesses": {"value": "This paper cannot be accepted without properly situating itself within the literature. This work extensively discusses discrete diffusion models and recent latent reasoning work, but completely omits any discussion of the most methodologically relevant work: continuous diffusion models for language generation. Although this work falls short of claiming to introduce continuous/latent language diffusion, they also fail to acknowledge or discuss prior work that has explored this approach. A reader unfamiliar with the area would reasonably be given the impression that this approach is entirely unexplored before this current submission.\n\nWorks like Diffusion-LM, LD4LG, PLANNER, have already explored continuous diffusion for language generation across a variety of tasks, the latter two exploring latent diffusion in a very similar setup to this work. These are not obscure papers. They are highly cited papers published at top conferences 1+ years ago. Basic searches (e.g. “latent language diffusion”) return these papers as top results. In particular, the autoencoder design in the current submission seems to follow PLANNER very closely. The core technical approach (i.e. autoencoder-based latent diffusion for text) is established in prior work. This paper’s contribution is applying this approach to reasoning tasks, which is potentially valuable but must be communicated clearly. \n\nThis is not an isolated oversight. The related works section is otherwise quite comprehensive and discusses discrete diffusion and latent reasoning at length, but completely omits any mention of continuous/latent language diffusion. This gap covers the most methodologically relevant prior work.\n\nThere are various downstream weaknesses that stem from this omission. Given that this is primarily an application of an existing approach, the framing in the intro and in Figure 1 gives an uninformed reader an incorrect impression of the contribution of this work.\nAn unnecessary amount of space is given to motivating and describing the VAE design when it is almost the same as the PLANNER VAE architecture. \n\nThere are other weaknesses that can be discussed, but the primary issue with this work is the above mentioned. The combination of a complete omission of the most methodologically relevant prior work and a framing that implies novelty for an existing approach warrants rejection.\n\nThe description of the diffusion and autoregressive architecture and how precisely they are trained is unclear. The figure makes them appear to be one model, but the text uses f() and p() to denote the diffusion and autoregressive models, respectively, with different parameters. If they are one model, the training procedure is unclear given that the autoregressive model and diffusion model receive different inputs (clean vs noisy latent thoughts). Are they simply multi-tasked? Are there two separate models as the notation, but not the figure, implies?\n\nThis statement is untrue:\n“Unlike AR models that generate a single reasoning trajectory sequentially, our framework can generate multiple diverse reasoning trajectories in parallel within a batch“\nAutoregressive models are also capable of batched inference.\n\nThe modification to improve diversity seem somewhat arbitrary and are only used to drive up the PASS@100 metric for the Countdown task which of course benefits significantly from increasing diversity. The benefits of these changes are not demonstrated elsewhere.\n\nMany training and implementation details are omitted. How long were various models trained for? With what hyperparameter settings, etc?\n\nDiscussion of inference latency is not present. Inference should be much slower than the purely autoregressive baselines."}, "questions": {"value": "I do not have additional questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "I0QVSqFF6r", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_nMv9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_nMv9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970536386, "cdate": 1761970536386, "tmdate": 1762942475513, "mdate": 1762942475513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies LaDiR (Latent diffusion for reasoning), where the model utilizes blocked latent thoughts generated by diffusion methods and generates the final answer conditioned on these latent thoughts. The latent thoughts used for training are generated by training a VAE (variational autoencoder), which encodes the original textual CoT to latent representations. Comparisons on numerous benchmarks with several baseline methods (including SFT+CoT and several latent reasoning methods) prove the advantages of the proposed methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Using diffusion methods to generate latent thoughts is a good idea.\n2. The proposed method can flexibly control both the computational budget and the diversity of trajectories.\n3. The decoder of VAE makes the latent thought interpretable."}, "weaknesses": {"value": "1. For many equations, it would be better if the authors could define the function and variables more rigorously and clearly (e.g., by providing the shape of inputs or outputs, as discussed in the question section).\n2. In lines 35-38, the authors argued that “AR models generate a single linear chain of thought (CoT), which limits reasoning diversity and restricts exploration of multiple valid solutions”. However, AR models can also generate continuous CoT, which can explore multiple solutions in superposition as theoretically demonstrated by [1]. I think it’s worth discussing it or changing the wording to, e.g., “AR models with discrete CoT are limited by …”. \n3. In line 95, equation (1), I think the notation and definition of each function or variable should be made clearer and more rigorous. For example, what is $p\\_{\\theta}$, $p(\\cdot)$, and what’s the shape of their input and output? What is the shape of x and z, and what’s the distribution of $x$? \n\n**References**:\n\n[1] Zhu, Hanlin, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, and Yuandong Tian. \"Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought.\" arXiv preprint arXiv:2505.12514 (2025)."}, "questions": {"value": "1. When you are generating the next block, will you remove the timestamp from the previous block?\n2. I’m a bit confused by Equation (4). According to your notation, $Z^{(<=B)}$ should be the whole thought, and $y\\_{\\leq \\tau}$ is a prefix of the final answer. Why will $y_{\\tau}$ be a $< EOT >$ token since all $< EOT >$ should appear in $Z^{(<=B)}$. Am I missing anything?\n3. In line 294, what is the definition of $x\\_t$ and $x$, and what are their shape?\n4. In line 342, should it be 1\\% instead of 2\\%? (41.8 vs 40.8)\n5. In line 344, it seems that for DM-Math, CoT outperforms LaDiR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QGPSHkseXj", "forum": "z5cPEZ4n6i", "replyto": "z5cPEZ4n6i", "signatures": ["ICLR.cc/2026/Conference/Submission23007/Reviewer_FWxU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23007/Reviewer_FWxU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972882511, "cdate": 1761972882511, "tmdate": 1762942475083, "mdate": 1762942475083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}