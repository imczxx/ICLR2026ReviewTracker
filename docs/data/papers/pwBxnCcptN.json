{"id": "pwBxnCcptN", "number": 13246, "cdate": 1758215620221, "mdate": 1759897452971, "content": {"title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark", "abstract": "We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA <--> HIP) and assembly-level (Nvidia SASS <--> AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the CASS family of domain-specific language models, achieving 95% source translation accuracy and 37.5% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce CASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation.", "tldr": "Nvidia to AMD Transpilation with Data, Models, and Benchmark", "keywords": ["CUDA", "Language Models", "HIP", "Assembly"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8c2f640c9dbbefef7c1bd23020ae87e08c0e8648.pdf", "supplementary_material": "/attachment/27fd97bb83253f4ee91786fe9c03a9fc00f48eac.zip"}, "replies": [{"content": {"summary": {"value": "The CASS dataset contains 70,000 verified code pairs spanning both host and device levels, covering source-level (CUDA ↔ HIP) and assembly-level (Nvidia SASS ↔ AMD RDNA3) translation.\nThe CASS family of domain-specific language models was developed. Trained on this dataset, these models achieve 95% accuracy in source code translation and 37.5% accuracy in assembly translation, significantly outperforming commercial baselines such as GPT-4o, Claude, and Hipify."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The dataset includes code from 16 different categories, covering CUDA, HIP, and assembly code.\n- It supports cross-compilation across host and device assemblies, as well as device-to-device translation.\n- Extensive experiments were conducted, with comparisons across various large language models and transpilation tools."}, "weaknesses": {"value": "- The dataset and models do not include tensor instructions such as Tensor Cores or matrix instructions, which are likely a major limitation for current transpilation tools.\n- The benchmark includes only 40 curated tasks, which is relatively small. Additionally, there is no kernel-level metadata provided (e.g., number of lines)."}, "questions": {"value": "- Regarding the functionality equivalence verification of CASS bench, most CUDAC functions modify the memory pointed to by the passed-in pointers in place, rather than returning outputs or standard outputs. How does your work ensure functionality equivalence? Specifically, do the memory contents pointed to by all parameters remain the same after both codes are executed?\n- See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aN5UTyiVXn", "forum": "pwBxnCcptN", "replyto": "pwBxnCcptN", "signatures": ["ICLR.cc/2026/Conference/Submission13246/Reviewer_tGTk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13246/Reviewer_tGTk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761547742403, "cdate": 1761547742403, "tmdate": 1762923927648, "mdate": 1762923927648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CASS, the first large-scale dataset and model suite for cross-architecture GPU code translation, containing 70,000 pairs of NVIDIA CUDA/AMD HIP source code and corresponding assembly (SASS/RDNA3). The paper proposes an automated pipeline for building and synthesizing data, and based on this data, constructs CASS-bench. By performing SFT on the CASS dataset, the model achieves results that far surpass other models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The experiments are comprehensive, the data analysis is thorough, and the writing is well-done.\n2. This work builds the CASS dataset and CASS-bench, making them the first cross-platform code translation datasets between NVIDIA and AMD, filling a gap in the field.\n3. This work holds significant importance for code migration in the high-performance computing domain."}, "weaknesses": {"value": "1. Limited innovation. This work performs direct SFT using crawled or synthesized data, where the synthesized data is generated by an LLM through prompt combinations. The approach is relatively simple, and the training process is also straightforward, so the overall innovation is limited.\n2. Case analysis is limited. In A.8.2, a comparison of translation results between CASS-7B and other models is provided. However, these examples are limited to simple translation errors, such as incorrect string translations, header file errors, and translating `std::cout` as `std::cerr`. These errors can be easily addressed by adjusting the prompt. The paper should focus more on analyzing logical errors based on CUDA/HIP characteristics and other more complex issues.\n3. The core issue remains unsolved. Fig 3(a) shows that a significant portion of the Assembly code has around 2k lines, and for such lengths, a 16k context LLM is clearly unsuitable. In Assembly translation, adding RoPE Extrapolation results in a 5-point improvement, indicating that context length is a core challenge in Assembly translation. However, the paper does not provide a solution to this challenge, nor does it analyze whether the performance limitation is due to context limitations or the inherent difficulty of Assembly translation itself."}, "questions": {"value": "1. Could you provide more targeted case studies? For example, cases where the logic of a function was translated incorrectly?\n2. Could you analyze whether the poor performance in Assembly is due to its inherent difficulty or context limitations? For example, what would be the effect of training a model with a 1M context using the CASS dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mmjgIlmova", "forum": "pwBxnCcptN", "replyto": "pwBxnCcptN", "signatures": ["ICLR.cc/2026/Conference/Submission13246/Reviewer_JyLG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13246/Reviewer_JyLG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761710842782, "cdate": 1761710842782, "tmdate": 1762923927338, "mdate": 1762923927338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper undertakes the ambitious and important goal of mitigating GPU vendor lock-in by creating a dataset and model suite for translating code between Nvidia and AMD architectures, at both source (CUDA-to-HIP) and assembly (SASS-to-RDNA3) levels. The authors contribute a large-scale dataset (CASS), a benchmark (CASS-Bench), and a family of models that are shown to outperform existing baselines.\nWhile the ambition is commendable and the contribution of a new public dataset is valuable, the work is hampered by significant methodological limitations and overstated claims. The source-to-source evaluation framework contains a circular dependency that calls into question the reported state-of-the-art results. Furthermore, the headline assembly-level accuracy of 37.5%, while a relative improvement over near-zero baselines, is profoundly impractical for any real-world application and highlights the sheer difficulty of the task rather than a viable solution. The representativeness of the dataset, particularly regarding complex, performance-critical kernels, is also a major concern. The paper is a valuable exploration, but it should be considered a preliminary step that reveals more challenges than it solves."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses a High-Impact Problem: The work tackles the critical issue of vendor lock-in in the GPU ecosystem, a problem of significant interest to both academia and industry. The attempt to address this at the challenging assembly level is novel.\n- Publicly Available Resources: The open-sourcing of the CASS dataset, benchmark, and data-generation pipeline represents a contribution to the community, providing a (flawed but useful) starting point for future research in this difficult domain."}, "weaknesses": {"value": "1.\tFundamentally Flawed Source-to-Source Evaluation: The methodology for evaluating source-to-source translation is critically flawed. The dataset was created by using AMD's Hipify tool to translate CUDA to HIP, discarding the ~44% of files that Hipify failed to convert (Line 251). The CASS model is then trained exclusively on Hipify's successes. The paper subsequently claims that CASS outperforms Hipify by 7.5% (Line 437). This comparison is misleading. The CASS model was not trained to be a general CUDA-to-HIP translator; it was trained to be a better translator for the subset of CUDA that is already translatable by Hipify. The true challenge lies in the 44% of code that Hipify cannot handle, a domain on which CASS was never trained or evaluated. This circular setup invalidates the claim of surpassing Hipify's general capability.\n\n2.\tImpractical Accuracy and Overstated Achievements: The paper presents 37.5% assembly-level accuracy as a headline achievement. In any practical engineering context, a tool that fails 62.5% of the time is unusable. While an improvement from 0%, this result primarily serves to demonstrate that the problem remains unsolved. Framing this as a successful outcome is an overstatement. The paper should more clearly position this as an initial baseline that underscores the immense difficulty of assembly-level translation, rather than a breakthrough in its own right.\n\n3.\tQuestionable Dataset Representativeness: The composition of the training data raises serious doubts about its applicability to real-world performance engineering.\na.\tDominance of Synthetic Data: The dataset is majority synthetic (40.6k samples) generated by an LLM (Qwen2.5-Coder32B). This data may not reflect the complex idioms, subtle edge cases, and intricate logic of production-grade, human-written GPU code.\nb.\tLack of Performance-Critical Kernels: The central motivation for low-level translation is to port highly optimized, hand-tuned kernels that are the primary source of vendor lock-in. There is no evidence presented that the dataset, sourced from general public repositories (The Stack) and LLM generation, contains a meaningful number of such kernels. The translation of simple or academic-level code is a far less compelling problem. The paper does not provide an analysis of the complexity or performance sensitivity of the kernels in its dataset.\n\n4.\tSuperficial Performance Evaluation: The claim that 85% of translated binaries have performance within ±5.6% of native code is presented without sufficient context (Line 426). This analysis is not stratified by kernel complexity, size, or domain. It is plausible that this high fidelity is achieved on simple kernels where performance is easy to match, while performance diverges significantly on the complex kernels that matter most. Without a more detailed breakdown, this aggregate statistic is not fully convincing.\n\n5.\tLimited Scope and Generalization: The work is effectively a case study on a single ISA pairing (Nvidia A100/sm85 to AMD RX 7900 XT/RDNA3). The \"Hardware Generalization\" section (Line 446) reports results on only one additional hardware pair. This is insufficient evidence for broad generalizability. The immense architectural differences between GPU generations and vendors suggest that the learned mappings are likely to be highly specific. The paper should be more circumspect about the portability of the methodology itself. Also, converting Nvidia A100 server-grade GPU code to RX 7900 XT workstation-grade GPU code is not a fair conversion. MI250 or MI300 would be fair."}, "questions": {"value": "1.\tHow do you justify the claim that the CASS source-to-source model is superior to Hipify when it was only trained on the subset of data that Hipify could successfully process? Would a more fair evaluation not require testing on the 43.9% of files that Hipify failed on?\n2.\tCould you provide a qualitative analysis of the assembly translation failures? What are the most common architectural divergences that the model fails to bridge? This would be more insightful for future work than the aggregate accuracy number.\n3.\tWhat steps were taken to ensure that CASS-Bench includes genuinely difficult, performance-critical kernels, as opposed to textbook examples? Is there a metric of kernel complexity or optimization level you can report for your dataset?\n4.\tRegarding the 0% accuracy of baselines like GPT-4o on assembly translation: Does this not suggest that the entire approach of treating assembly as a \"natural language\" for translation via LLMs may be fundamentally unsuited for this task, which requires precise, deterministic mapping of hardware states?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "63pjgOLM8v", "forum": "pwBxnCcptN", "replyto": "pwBxnCcptN", "signatures": ["ICLR.cc/2026/Conference/Submission13246/Reviewer_Aoyp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13246/Reviewer_Aoyp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944835644, "cdate": 1761944835644, "tmdate": 1762923927018, "mdate": 1762923927018, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}