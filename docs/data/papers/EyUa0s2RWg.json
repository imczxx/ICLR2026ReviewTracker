{"id": "EyUa0s2RWg", "number": 14922, "cdate": 1758245568629, "mdate": 1759897341159, "content": {"title": "PI-Controlled Uncertainty for Steady-State Error Elimination in  Ultrasound Image Segmentation", "abstract": "Accurate segmentation of anatomical structures from medical ultrasound images is essential for reliable diagnosis, yet conventional training losses often leave persistent steady-state errors, especially along ambiguous boundaries. These losses act as control variables generated by a proportional controller, since they respond only to instantaneous discrepancies and lack the memory required to correct long-term deviations. To overcome this limitation, we rethink segmentation training as a closed-loop control system where uncertainty acts as the control variable. Building on this perspective, we introduce a proportional–integral (PI) control mechanism that integrates both present and historical error signals into the optimization process, enabling the model to systematically eliminate steady-state errors and deliver sharper, more reliable boundary predictions. Unlike existing uncertainty-based approaches that rely solely on fixed loss terms, our method provides a principled mechanism to incorporate dynamic feedback into training. The framework is model-agnostic and introduces no additional inference overhead, making it directly compatible with real-time segmentation backbones. Extensive experiments on clinical medical ultrasound datasets demonstrate consistent improvements over state-of-the-art baselines. These results confirm that our framework offers an effective solution for eliminating steady-state errors in medical ultrasound image segmentation under challenging conditions. Our code is available at https://anonymous.4open.science/r/PI-control-uncertainty-B82C.", "tldr": "", "keywords": ["Medical Image Segmentation", "Uncertainty", "Control Theory", "PI Controller"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/096d544bb3d47b844db176b79f627c1bbcbc1f57.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a control-theoretic perspective to medical ultrasound image segmentation, proposing a Proportional–Integral (PI)-Controlled Uncertainty framework for training segmentation models. The authors argue that conventional loss functions behave like proportional controllers, reacting only to instantaneous errors, and thus cannot eliminate steady-state segmentation errors, particularly along ambiguous boundaries. Their approach integrates a PI controller that accumulates historical error information and modulates uncertainty during training through a Laplace-based loss term. The method is evaluated on two ultrasound datasets (MEIS and TN3K), where it reportedly improves Dice and mAP metrics over several state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Proposes a novel perspective by viewing neural network training as a closed-loop control system and analogizing the segmentation loss to a PI controller, which is relatively new in medical image segmentation.\n2. Introduces a Proportional–Integral (PI) controlled uncertainty mechanism that conceptually adds innovation by incorporating historical error information to improve model stability.\n3. The method is model-agnostic, requiring no modification to the inference architecture and adding no extra inference overhead.\n4. Includes ablation studies and sensitivity analyses, showing the authors’ awareness of the effects of model components and hyperparameters.\n5. Code is provided, supporting reproducibility.\n6. The idea of combining control theory with uncertainty learning is thought-provoking and may inspire future research directions.\n7. Achieves consistent performance improvements over multiple state-of-the-art methods across evaluation metrics."}, "weaknesses": {"value": "1. The proposed model lacks specificity, although the paper claims that PI-Control is motivated by the steady-state error in ultrasound images, steady-state errors are common across many image segmentation tasks. Moreover, the PI-Control does not include designs tailored for ultrasound-specific challenges such as low contrast, speckle noise, and ambiguous tissue boundaries.\n2. The paper frames the task as semantic segmentation, yet the loss function includes bounding box and classification terms, which may be inappropriate. Additionally, the choice of baselines and comparison methods excludes ultrasound-specific semantic segmentation models.\n3. The description of $K_p$ in Fig.6(a) is inconsistent with the explanation provided in the text.\n4. The core claim steady-state error is supported only by qualitative error maps. No quantitative analysis of error evolution or convergence curves during training is provided, making the evidence insufficient.\n5. The rationale for choosing the Laplace distribution is qualitative and lacks empirical comparison with Gaussian or other alternatives. Furthermore, there is insufficient system-level analysis of the control gain parameters ($K_p$, $K_i$, $N$).\n6. The connection between control theory and deep network training is not fully established. While the concept of closed-loop control is introduced, there is little experimental or theoretical evidence showing how it concretely improves optimization dynamics or generalization, such as in cross-domain experiments."}, "questions": {"value": "1. Does PI-Control facilitate real-time, continuous learning for cross-domain scenarios?\n2. If applied to other tasks or modalities, would PI-Control still be effective, or is it specific to ultrasound?\n3. How does the choice of N affect the results? The paper uses N = 5, which seems small; could this cause model forgetting?\n4. Why are bounding box and classification losses included in a semantic segmentation task, where they are not typically used?\n5. Can the authors provide visualizations showing how model attention changes under PI-Control after 30 training epochs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aHZAHPXHWr", "forum": "EyUa0s2RWg", "replyto": "EyUa0s2RWg", "signatures": ["ICLR.cc/2026/Conference/Submission14922/Reviewer_zuP6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14922/Reviewer_zuP6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761549334787, "cdate": 1761549334787, "tmdate": 1762925266267, "mdate": 1762925266267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework that reinterprets ultrasound image segmentation through the lens of control theory. The authors identify that conventional loss functions in segmentation behave like proportional (P) controllers, responding only to instantaneous errors without addressing long-term steady-state errors. To address this limitation, the paper introduces a Proportional–Integral (PI) Controlled Uncertainty mechanism, where uncertainty acts as the control variable and segmentation masks are the controlled variables."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The reinterpretation of segmentation training as a closed-loop control system is novel.\n\n2. The paper identifies an often-overlooked issue in medical image segmentation: persistent boundary errors that remain after convergence."}, "weaknesses": {"value": "1. The main contribution is the introduction of a PI-inspired loss modulation, which, although conceptually interesting, resembles weighted dynamic loss scheduling methods. The integral control analogy might be viewed as a relabeling of adaptive weighting techniques.\n\n2. Only two ultrasound datasets are used. No experiments are conducted on CT, MRI, or cross-modality data to test generalization.\n\n3. No comparison is made to uncertainty-regularized segmentation frameworks (e.g., Bayesian U-Net, Monte Carlo Dropout segmentation)."}, "questions": {"value": "1. How does the proposed PI-controlled uncertainty differ fundamentally from previous PIDNet (Xu et al., CVPR 2023) or Evidential U-Net approaches that also incorporate dynamic feedback into training?\n\n2. Does the method guarantee stability (bounded error accumulation), or is the gain tuning (Kp, Ki) entirely empirical?\n\n3. Have the authors compared against uncertainty-driven segmentation baselines such as Monte Carlo Dropout U-Net or Bayesian DeepLab?\n\n4. How sensitive is the method to the top-k selection of uncertain pixels (Section 3.2.2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DJ7Q88wBDP", "forum": "EyUa0s2RWg", "replyto": "EyUa0s2RWg", "signatures": ["ICLR.cc/2026/Conference/Submission14922/Reviewer_aLv8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14922/Reviewer_aLv8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831902377, "cdate": 1761831902377, "tmdate": 1762925265568, "mdate": 1762925265568, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel training approach for segmentation models, where instead of focusing on reducing instantaneous structural inconsistencies or regulating current prediction errors, the proposed loss function estimates uncertainty over historical errors. It then prioritizes pixels where the model repeatedly makes mistakes. This formulation is inspired by a PID controller, where the loss is not only a function of the proportional (instantaneous) error but also incorporates the influence of past (integral and derivative) errors. The results are shown in two ultrasound datasets, with some relevant ablations studies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The Strengths of the paper are :\n\n1. The proposed uncertainty-based segmentation approach is interesting, and the novel formulation of the loss function as a PID controller adds a unique and intuitive perspective.\n\n2. The evaluation is conducted on relevant medical datasets for ultrasound segmentation. Since boundary delineation in such datasets is particularly challenging, the choice of dataset for experimentation is well justified and strengthens the study."}, "weaknesses": {"value": "There are several Weaknesses i found in the paper:\n\n1. Novelty: The idea of hardness-based pixel sampling, as proposed in this paper, has been explored in prior works and shown to be effective. Therefore, it is unclear how this aspect constitutes a novelty. If the novelty lies primarily in the PID-based formulation, the authors should clearly delineate how their approach differs from and advances upon existing methods such as [1, 2, 3, 4]. There are more papers, but i hope these references give authors a good place to start.\n\n2. Major Concern – Evaluation Metrics: A key evaluation missing from the paper is the inclusion of boundary-based metrics such as the Hausdorff distance or surface distance. Without incorporating a distance-based measure, the claim that the proposed method produces well-defined boundaries remains less convincing.\n\n3. Ablation Study: It would be helpful to analyze how the number of historical predictions, N, influences the segmentation accuracy. This would clarify the sensitivity of the method to the length of the historical error window. \n\n4. Additional analysis on how extra memory is required to run, because historical prediction would be needed to be stored for each sample, therefore if the number of samples in the dataset is M, the memory required to run this code would would be O(N*M). This would not scale to 3D images or bigger datasets ?\n\n5. Statistical Significance: Although the reported results show improvements, their statistical significance is unclear. No standard deviations or confidence intervals are provided for any of the metrics, which reduces confidence in the validity and robustness of the claimed performance gains.\n\n\n[1] Chen, Lei, Tieyong Cao, Yunfei Zheng, Yang Wang, Bo Zhang, and Jibin Yang. \"Hardness-aware loss for object segmentation.\" Alexandria Engineering Journal 108 (2024): 50-59.\n\n[2] Zheng, Wenzhao, Zhaodong Chen, Jiwen Lu, and Jie Zhou. \"Hardness-aware deep metric learning.\" In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 72-81. 2019.\n\n[3] Zeng, Shuai, Wenzhao Zheng, Jiwen Lu, and Haibin Yan. \"Hardness-aware scene synthesis for semi-supervised 3D object detection.\" IEEE Transactions on Multimedia 26 (2024): 9644-9656.\n\n[4] Wang, Song, Jiawei Yu, Wentong Li, Wenyu Liu, Xiaolu Liu, Junbo Chen, and Jianke Zhu. \"Not all voxels are equal: Hardness-aware semantic scene completion with self-distillation.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 14792-14801. 2024."}, "questions": {"value": "Although I have outlined some of my major concerns above under the weaknesses, I have a few additional questions:\n\n1. The rationale behind selecting 500  as Top-k pixels and setting N = 5 is unclear. Were these values chosen arbitrarily, or were they determined through empirical analysis or prior experimentation? Providing justification or sensitivity analysis would strengthen the paper.\n\n2. How can the proposed framework be extended to larger images or 3D volumes? Given the substantial storage requirements, its applicability to 3D data appears limited. If the method cannot be feasibly used in such settings, the authors should explicitly acknowledge this as a limitation.\n\nA suggestion for Authors:\n\n2.  I am not entirely convinced that static segmentation is the most suitable setting for a PID-based formulation. This framework might be better suited for test-time adaptation[1,2] scenarios, where limited samples are available, and the model can be iteratively refined over multiple passes.\n\n[1] Janouskova, Klara, Tamir Shor, Chaim Baskin, and Jiri Matas. \"Single image test-time adaptation for segmentation.\" arXiv preprint arXiv:2309.14052 (2023).\n\n[2 ]Chen, Ziyang, Yongsheng Pan, Yiwen Ye, Mengkang Lu, and Yong Xia. \"Each test image deserves a specific prompt: Continual test-time adaptation for 2d medical image segmentation.\" In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 11184-11193. 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OZRLwHMVEm", "forum": "EyUa0s2RWg", "replyto": "EyUa0s2RWg", "signatures": ["ICLR.cc/2026/Conference/Submission14922/Reviewer_qSov"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14922/Reviewer_qSov"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761859473004, "cdate": 1761859473004, "tmdate": 1762925265030, "mdate": 1762925265030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel PI-Controlled Uncertainty framework to eliminate steady-state segmentation errors in ultrasound image segmentation. The central thesis is that traditional segmentation losses act like Proportional (P) controllers, which react to instantaneous errors but cannot eliminate persistent errors due to their lack of historical memory."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper reinterprets segmentation training through a control-theoretic lens, modeling the optimization process as a closed-loop feedback system. This conceptual bridge between control theory and uncertainty modeling is refreshing.\n2.The proposed PI-controlled uncertainty loss can be easily plugged into existing segmentation architectures without modifying inference-time behavior. This “training-only” modification offers good engineering practicality."}, "weaknesses": {"value": "1.Although results are consistently better, the improvements are modest (1–2 mAP or Dice), within the range that could result from hyperparameter tuning or additional regularization. The paper does not show statistical significance or multiple runs to confirm robustness.\n2.The paper adopts a Laplace likelihood rather than Gaussian for robustness.\n- Was this empirically validated? How sensitive is the system to this choice?\n- Would a Gaussian with learned variance yield similar behavior (i.e., is this truly a heavy-tail effect or just another reweighting)?\n3.Integrating accumulated errors can cause instability (overshoot) in true PI systems, yet the paper omits any analysis of such effects in the training dynamics."}, "questions": {"value": "-The authors state that L_uncertainty is only activated after the base loss converges.\n   Why is this necessary—does the controller destabilize early training?\n   Is this equivalent to curriculum learning or staged regularization rather than true closed-loop feedback?\n\n-The proportional term focuses on the top-k uncertain pixels.\n   How sensitive are results to the value of k (500)?\n   Is there a risk that the controller overfits to noisy or mislabeled pixels?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yTV7ioooC5", "forum": "EyUa0s2RWg", "replyto": "EyUa0s2RWg", "signatures": ["ICLR.cc/2026/Conference/Submission14922/Reviewer_pvHj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14922/Reviewer_pvHj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14922/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937620415, "cdate": 1761937620415, "tmdate": 1762925264578, "mdate": 1762925264578, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}