{"id": "jBSye8M3FQ", "number": 17576, "cdate": 1758277746301, "mdate": 1759897166741, "content": {"title": "Encode, Think, Decode: Scaling test-time reasoning with recursive latent thoughts", "abstract": "Most efforts to improve the reasoning capabilities of large language models (LLMs) involve either scaling the number of parameters and the size of training data, or scaling inference computation by letting models generate complex chains of thought. Motivated by interpretability studies showing that the crucial computation required for reasoning tasks is concentrated in a limited range of layers, we introduce Encode–Think–Decode (ETD), a method that enhances the reasoning capabilities of a base model by training it to iterate over a small subset of reasoning-relevant layers during the mid-training stage. ETD amplifies latent reasoning while preserving the original architecture, parameter count, hyperparameters, and training data composition. When iterating on the selected layers at inference time, ETD models yield substantial gains on 17 reasoning benchmarks, including +28.4% relative accuracy improvement on GSM8K and +36% on MATH with the OLMo-2 1B Base model. We also explore an adaptive depth strategy that adjusts the computation per input token. Our results show that recursive latent reasoning offers a simple and effective path to stronger LLM reasoning.", "tldr": "We improve LLM reasoning  by recursively reusing reasoning-relevant layers of pretrained models.", "keywords": ["Latent Reasoning", "recursive-depth models"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0ca80d0437c7dccc5375a64cdb27e16f0db2fe1e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Encode-Think-Decode (ETD), a method for converting Olmo-2-1b into a recursive reasoning model. The paper uses angular distance between layer outputs and the kneedle algorithm (for finding distinct changes) to define how to partition the model into Encoder, Recursive Block and Decoder. Later this decision is empirically validated, showing that for this model benchmarks tend to be higher in the region the algorithm finds (Fig. 3). \n\nThe paper shows gains over a selection of benchmarks from the OLMOes suite, showing multiple different recursive depths. The authors compare to the baseline (non-recursive) Olmo-2 model, finding that they often increase accuracy by between 2 and 5% in absolute terms on average but do use more FLOPs during training and inference.\n\nThe authors also baseline to different partitions of layers into the Encoder, Recurrent Block, Decoder. Finding a 2-12\\*2-2 model is very similarly matched to their 7-4\\*4-7 model and FLOPs equivalent. Finally, the authors train a linear probe for the latent space of the recurrent block which is used for early exiting, finding a trade off between efficiency and cost in most cases."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Analyses post training models to be recursive, an approach which may reduce cost of future research.\n2. Increases benchmark performance on average for Olmo-2-1b after mid-training, when using more FLOPs.\n3. Uses an interpretable approach to selecting layers for the recurrent block which is empirically verified."}, "weaknesses": {"value": "### Claims:\n- Some of the papers claims are overstated:\n    - The use of relative improvement feels abused here. For example: claiming +36% relative improvement on MATH in the abstract and only achieving a 1.65% absolute improvement feels misleading to the reader.\n    - The claim of +28% on GSM8K and +36% on MATH are regularly stated together. However, these are not achievable together with the same k value, this is never clearly stated.\n    - The paper claims “substantial” gains on 17 benchmarks, However, these are small in absolute terms.\n- In Table 4, when compared to baselines the margin of results becomes extremely small. What are the error bounds on these experiments as the 2-12\\*2-2 model is very similarly matched to their 7-4\\*4-7 model? Did the authors explore this further, perhaps training a 2-12\\*4-2 model is even better? This also increases my concerns that it is the FLOPs used for computation and less so the proposed method driving performance increases.\n\n### Scope:\n- The paper only considers one model Olmo-2-1b.\n- The is no FLOPs matched non-recursive baseline training run. For example, this increase in accuracy may be due to more computation during training and inference.\n    - The paper states: “Our goal in applying a recursive approach, conversely, is to boost reasoning capabilities by efficiently scaling inference-time computation.” However, I do not think this is a fair reason to eschew a FLOPs matched baseline.\n- On line 199, the authors claim access to the training data is required to run these types of experiments, however I think they can be conducted without access to training data as long as the same training data is used for all models being analysed.\n\n### Relation to prior work:\n- A lot of the citations used when trying to distinguish from prior work by highlighting the approach of using angular distance to locate layers are for models trained from scratch hence, I think these aren’t quite the right citations (e.g. line 149).\n- Line 185: “Prior works on recursive-depth models typically rely on simplified training setups.” Geiping et al. and Bae et al. (2025) train in standard set ups for long periods also.\n- In the “Key differences to prior work” many points are highlighted such as LoRA Adapters, Regularisation and Input Injections. However, there is a lot of nuance missed here, for example Geiping et al. train for a large number of iterations but this also allows extrapolation in terms of k. Moreover, Aleksandrov et al. find, like much other prior work, input injection is useful. Without baselining against these methods to show the new proposal is superior, I find this weak evidence of novelty."}, "questions": {"value": "1. Why is Figure 1 taken over C4 and not the training set? Or some other dataset meant to match the reasoning distribution the authors are targeting?\n2. Is the baseline “Olmo 2 (k=1)” model trained by the authors? I worry here about the authors training set up differing from the Olmo suite in minor ways leading to the small changed in accuracy we see.\n3. I have a large number of questions about Section 5:\n    1. What is the training data?\n    2. Is the whole model being trained or just the router?\n    3. Do the authors have any reasoning for the increase in DROP and OpenbookQA?\n    4. What value of K is the model trained with? If it can extrapolate to maximum k=10, one would assume 10 which is not shown as a result elsewhere in the paper.\n    5. What objective is used when training the router?\n\nDuring rebuttal, I would be most interesting in clarifications on the baselines accuracy and training, more baselines being considered and more architectures being considered."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cFDogdvNLJ", "forum": "jBSye8M3FQ", "replyto": "jBSye8M3FQ", "signatures": ["ICLR.cc/2026/Conference/Submission17576/Reviewer_8tY2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17576/Reviewer_8tY2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17576/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760459099202, "cdate": 1760459099202, "tmdate": 1762927437796, "mdate": 1762927437796, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a simple yet effective method for converting existing models to recurrent models by training the model to iterate over a small subset of the \"reasoning\"-relevant layers during mid-training. The paper shows the benefits of more \"reasoning\" benchmarks such as GSM8K and MATH."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- simple but effective method for increasing the performance of the model on GSM8k and MATH\n- introduce a mechanism to adaptively determine the number of iterations for each input"}, "weaknesses": {"value": "- results only on a single model. This is important for this study because the layers found to iterate over may be specific to the evaluations themselves.\n- How do methods like these compare to latent approaches like COCONUT [1] or similar? Although no baseline is necessarily directly comparable, for a better understanding, it would be useful to include another method as a comparison point.\n\n[1] https://arxiv.org/abs/2412.06769"}, "questions": {"value": "- How were the evaluations grouped into reasoning/non-reasoning benchmarks?\n- How can we confirm that the current results on layer choosing is not an artifact of the OLMo models?\n- Are different model sizes explored in the paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ocVy6q1R5Z", "forum": "jBSye8M3FQ", "replyto": "jBSye8M3FQ", "signatures": ["ICLR.cc/2026/Conference/Submission17576/Reviewer_cBrU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17576/Reviewer_cBrU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17576/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761199032818, "cdate": 1761199032818, "tmdate": 1762927437031, "mdate": 1762927437031, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper follows the recursive transformer idea and proposes Encode–Think–Decode, which decomposes a pretrained LLM into three functional components, latent encoder, recursive “thinking” block, and latent decoder, based on layerwise representational dynamics. Using the mean angular change of the residual stream between adjacent layers, the authors automatically identify “knee points” that delineate encoder and decoder boundaries. The middle block is then recursively executed multiple times during inference."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The experimental setup is clear and easy to follow, with well-defined baselines and ablation choices.\n* The paper conducts comprehensive empirical analysis, comparing multiple ETD configurations (e.g., varying iteration counts, layer boundaries, and adaptive depth)\n* The benchmark coverage is broad, across factual, commonsense, mathematical, and reasoning categories, which helps demonstrate the generality of the approach"}, "weaknesses": {"value": "* The evaluation relies primarily on a single model (OLMo-2 1B). It would strengthen the paper to include results across different model sizes or architectures (e.g., other OLMo sizes) to demonstrate that the Kneedle-based boundary detection generalizes beyond one model.\n* In Figure 2, the angular-distance curve appears rather smooth, without a clear “knee.” This make me wonder whether the automatically detected boundary is robust or merely an artifact of one model’s noise pattern. \n* The conceptual link between the angular change turning point and the claimed “encode then think” transition is somewhat heuristic. Reduced representational drift does not necessarily imply reasoning onset, more interpretation or insights into this will be appreciated\n* It's necessary to also compare with a larger model under the same FLOPs  to show the trade off ."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NtlkNRcxjb", "forum": "jBSye8M3FQ", "replyto": "jBSye8M3FQ", "signatures": ["ICLR.cc/2026/Conference/Submission17576/Reviewer_Qf7A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17576/Reviewer_Qf7A"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17576/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761382817457, "cdate": 1761382817457, "tmdate": 1762927436229, "mdate": 1762927436229, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents a practical methodology for turning fixed depth transformer LLMs in to recurrent transformers with the specific goal of enhancing reasoning performance without requiring additional trainable parameters. They propose an algorithmic method for choosing how to assign layers from the original model into a three phase encode, think, decode segmenting of the layers in the recurrent model and ablate their design choices. They also explore an adaptive exiting method for also assigning a variable amount of compute per token. Their strong results on mathematical and reasoning intensive benchmarks underscore the promise of recurrent approaches for efficient reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Experiments are performed on models at the now ubiquitous 1B parameter scale for open source models, implying their results could directly translate to open source resource constrained applications.\n2. They identify an important problem in the adaptation process for turning a fixed depth model into a recurrent one and apply both recent results from the LLM literature and a more classical technique from curvature analysis to propose an automated process for slicing up the model layers optimally when initializing their new model.\n3. They report non trivial improvements in reasoning performance over the fixed depth baseline they start with (given the limited absolute capability of 1B models)"}, "weaknesses": {"value": "Overall, the paper is rated very borderline on account of some of the ablation soundness and presentation clarity issues discussed below. As the available middle ratings this cycle are just 4 or 6, I am happy to lean very weakly in the direction of acceptance, however, the demerits are represented in the individual component scores above.\n\n### 1. More limited novelty in ETD structure than claimed\n\nNote that there is a bit of a is/ought distinction to be made about where to draw the line between encode think and decode layers. This first should be clarified in S1, and then it also factors into how ablations are performed in S4.3 against other recurrent layer assignment strategies. \n\nGeiping uses a \"Prelude, Recurrence, Coda\" structure and Bai proposes a \"Middle-Cycle\" recurrence strategy, which are both essentially the same as the \"Encode, Think, Decode\" setup proposed in this work. They key thing to note about whether or not a design is \"ad hoc\" or \"optimal\" here likely hinges on the training setting. Geiping trains their models from scratch with encode=prelude, think=recurrence, and decode=coda separations defined from the beginning of training and thus one would assume that by the end of training the \"roles\" of these layers have become aligned with their usage. \nIn this work, you instead start with a _pretrained_ fixed depth model whose layers have already implicitly come equipped with \"roles\" as a function of where they were in the original model during pretraining. Hence, one imagines there is likely an optimal way in which these layers could be partitioned when the model is adapted from fixed depth to recurrent; your work studies one such strategy. But the point is that whether or not there exists an optimal partitioning, and whether this one is the one, is more an artifact of the adaptation setting this work studies rather than a true difference between this proposal and architectures in recent work on recurrent llms.\n\n### 2. More limited evidence for optimality of layer division strategy than claimed\n\nThe evidence for the use of the Kneedle algorithm is weak and overall the draft space allocated to the optimality motivations in S 2.1 and the design of the S4.3 ablation doesn't support a strong claim that this work has identified a procedure that should generalize to any other model family or experimental setting. Please link Appendix E early on to indicate that _an_ ablation was performed to back the Kneedle based choice, but in S4.4 it would also be helpful to motivate why the recursive block was fixed to a size of 4 before this ablation was performed.\n\nThe reader is still left wondering whether the 7-4\\*k-5 splitting was actually optimal (even for just Olmo 2). We are missing more targeted experiments where another splitting is used based on a different criteria than the kneedle algorithm, except for the two comparisons in Table 4 against a 2-12\\*2-2 and 0-16\\*2-0 non recurrent setup. Related to the is/ought comment about the difference between a from-scratch and a pretrained setting above, the way this ablation is set up these are not even weak evidences in support of the optimality argument or use of the kneedle algorithm over a visual check of Figure 1. \n\nInstead the two comparisons are just two more extreme and suboptimal choices. One can interpret the results as 2-12\\*2-2 allocating too many layers (from this pretrained model) to the recurrence and not enough to the encoder or decoder, the 0-16\\*2-0 results can be viewed as an extreme even more obviously poor choice based on intuitions and prior work regarding the special role of embedding and unembedding layers. Point being, this ablation does not even answer a simple question like whether or not a small change like allocating 5 layers to the thinking stage rather than 4 would outperform the reportedly optimal setup that uses a fancy splitting algorithm. Based on Fig 1 right, it might perform nearly the same.\n\n\n### 3. Lacking clarity in ACT section\n\nTraining details for S5.1 describing the ACT method are missing. How is the router supervision performed? eg. what labels are used for the optimal depth per token position? As this is similar to any router problem such the MoEs expert selection, a non-differentiable choice is made when an exit occurs because no other routes (more iterations of think block in this case) are considered other than the one selected by top-k or argmax. This issue normally requires applying a straight through estimator for the router function to make the process trainable end to end. Additional details about exact what loss was used in these exiting experiments are required."}, "questions": {"value": "1. S4.1 and S 4.2 have similar titles and read very similarly. Essentially they discuss the same series of results on the effect of depth k but this isn't clear on first skim. They should be unified into a single section perhaps with bold paragraph titles that discuss Table 2, and then the breakdown in Table 3, and then maybe point ahead to the appendix (if that's where they are) discussing trends in various individual tasks, but I think this last part could be omitted or moved to just accompany wherever the table is that contains the full task breakdowns.\n\n2.  L45 seems to be an unfinished sentence"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "immQdvjWW5", "forum": "jBSye8M3FQ", "replyto": "jBSye8M3FQ", "signatures": ["ICLR.cc/2026/Conference/Submission17576/Reviewer_H7YH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17576/Reviewer_H7YH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17576/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876639785, "cdate": 1761876639785, "tmdate": 1762927435898, "mdate": 1762927435898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}