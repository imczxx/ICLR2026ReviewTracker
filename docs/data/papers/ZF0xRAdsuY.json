{"id": "ZF0xRAdsuY", "number": 16680, "cdate": 1758267573093, "mdate": 1759897225332, "content": {"title": "Bound by semanticity: universal laws governing the generalization-identification tradeoff", "abstract": "Intelligent systems must deploy internal representations that are simultaneously structured—to support broad generalization—and selective—to preserve input identity. We expose a fundamental limit on this tradeoff. For any model whose representational similarity between inputs decays with finite semantic resolution, we derive closed‑form expressions that pin its probability of correct generalization $p_S$ and identification $p_I$ to a universal Pareto front independent of input space geometry. Extending the analysis to noisy, heterogeneous spaces and to inputs $n>2$ predicts a sharp $1/n$ collapse of multi-input processing capacity and a non‑monotonic optimum for $p_S$. A minimal ReLU network trained end‑to‑end reproduces these laws: during learning a resolution boundary self‑organizes and empirical $(p_S,p_I)$ trajectories closely follow theoretical curves for linearly decaying similarity. Finally, we demonstrate that the same limits persist in two markedly more complex settings—a convolutional neural network and state‑of‑the‑art vision–language models—confirming that finite‑resolution similarity is a fundamental emergent informational constraint, not merely a toy‑model artifact. Together, these results provide an exact theory of the generalization‑identification trade‑off and clarify how semantic resolution shapes the representational capacity of deep networks and brains alike.", "tldr": "", "keywords": ["generalization", "multi-object reasoning", "cognitive science"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fbfdebcbad572376b5dac61f75fd3a77977a837d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors study the tradeoff between generalization and identification through a notion of finite semantic resolution. They support their theory through a variety of convincing empirics in both a toy neural network and real-world models."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper is very well written overall. The exposition is clear, precise, and convincing. The theory is impressively predictive of both synthetic and real-world empirics. The central role of semantic resolution and its influence on the generalization/identification makes for a very compelling story. Well done overall!"}, "weaknesses": {"value": "See Questions below."}, "questions": {"value": "For your empirics with the toy neural network model, do you have an idea why the model seems to learn a linearly decaying distance function? Since it sounds like the similarity task employed a conventional softmax output / cross-entropy loss, it seems like the natural distance function would be exponentially decaying?\n\nYou mention that increasing the decay rate in exponential distance will increase both generalization and identification. In your experiments with Transformers (which presumably employ an exponential distance hard-coded in softmax attention), did you find that increasing the decay rate boosts generalization and identification accordingly? Based on your prescriptions, to optimally employ these models, should we always increase decay rate at test time for maximal performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JNpMPHrFTy", "forum": "ZF0xRAdsuY", "replyto": "ZF0xRAdsuY", "signatures": ["ICLR.cc/2026/Conference/Submission16680/Reviewer_NGhr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16680/Reviewer_NGhr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16680/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760906430377, "cdate": 1760906430377, "tmdate": 1762926737610, "mdate": 1762926737610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes that neural systems with finite semantic resolution face a fundamental tradeoff between generalization (correctly judging similarity between different inputs) and identification (distinguishing exact inputs). The authors derive closed-form Pareto curves characterizing this tradeoff for systems that compare inputs via a decaying similarity function, showing that performance lies on a universal frontier independent of input space geometry. They extend the theory to cases with noise and multiple items, predicting a sharp $1/n$ capacity collapse in multi-input settings. They also provide extensive empirical evidence that semantic resolution acts as a general information constraint in complex systems"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The central tradeoff (Thm 1) is formally derived under clear assumptions about similarity decay and finite resolution. The analytical Pareto frontier is a nice contribution: mathematically precise, easy to reason about, and interpretable in terms of task accuracy. \n\n2. The empirical sections demonstrate that real-world models qualitatively follow the predicted tradeoff curves\n\n3. this work links the G-I tradeoff to well-known cognitive constraints like binding failures, generalization gradients, and working memory, providing a cohesive narrative."}, "weaknesses": {"value": "1. The core tradeoff is derived assuming specific forms of similarity decay and decision rules. Would the authors elaborate how universal or sensitive their conclusion is to the choice of decay function? In Discussion, the authors refer to “finite-resolution similarity” as a universal constraint, suggesting that the existence of the tradeoff is robust, even if the exact shape of the curve depends on the similarity decay. It is unclear whether in those larger models, the similarity function follows the linear decay or takes a different shape."}, "questions": {"value": "Is there an optimal distance function? the paper motivates its choice of decaying similarity functions using Shepard’s law, stating that generalization should decay with distance. Prior work (e.g., Sims, 2018) has shown that such generalization gradients follow from efficient coding via rate-distortion theory. Would you clarify whether the similarity function is intended to model a learned or designed encoding independently of such optimization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AmgsS6mExZ", "forum": "ZF0xRAdsuY", "replyto": "ZF0xRAdsuY", "signatures": ["ICLR.cc/2026/Conference/Submission16680/Reviewer_1bfK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16680/Reviewer_1bfK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16680/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932644268, "cdate": 1761932644268, "tmdate": 1762926737246, "mdate": 1762926737246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the tradeoff between representational fidelity and distinctness under \"finite semantic resolution\". It shows that if a model’s similarity function has finite “semantic resolution” ε, then its accuracy on generalization tasks (p_S) and on identification tasks (p_I) must lie on a universal Pareto front.\n\nIf a model's embedding/similarity has a finite-resolution \"floor\", we should expect identification to drop as one pushes for broader generalization, and vice versa. Handling n simultaneous items suffers a sharp ∼1/n collapse in identification capacity; i.e., multi-object reasoning should not scale linearly just by adding parameters.\nOne can choose ε (via architecture, temperature, or thresholding) to target the sweet spot where p_S is maximized (roughly when the “similarity ball” covers half the space).\n\nIn short, the paper provides a simple geometry+noise model one can use to set thresholds, pick temperatures, and anticipate how adding more items or pushing for “similarity-aware” training will impact identification."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Comprehensive background section with helpful literature review.\n\nThe authors take the time to carefully explain their setup, accompanying notation with helpful illustrative examples.\n\nAuthors tested both toy (allowing for theoretical analysis) and realistic models (allowing for confirmation at scale).\n\nText is well-written, figures are clear, elegant, and helpful.\n\nCode is provided showing how to reproduce the results and figures used the paper."}, "weaknesses": {"value": "1. As mentioned by the authors in Limitations subsection, compositional representations and hierarchy were outside the scope of the study. Adding a small pilot on a compositional task to show if/why the current theory breaks would strengthen the paper.\n\n\n__Minor points__:\n\n2. The concept of “semantic resolution” feels somewhat over-introduced. Mathematically, it appears equivalent to a kernel scale or bandwidth that simply controls how similarity decays with distance. While the term is evocative and may carry intuitive meaning across domains, its use risks adding unnecessary jargon. I suggest that the authors clarify whether “semantic resolution” represents a genuinely new construct (i.e., beyond a kernel bandwidth) or simply reinterprets that familiar notion in \"semantic\" terms. A short comparison or restatement using standard terminology would make the paper easier to follow for readers from machine learning backgrounds.\n\n3. Although there is nothing technically wrong with the abstract, it is very dense and hard to unpack on a first read. The authors could make it a bit lighter in order to appeal to a broader, non-expert audience. For example, by simplifying a few long sentences and highlighting the main contribution more explicitly rather than embedding it deep within the paragraph.\n\nTypos:\n- Please fix the m-dashes in line 84.\n- and [an] additional one (line 97).\n- maximal unncertain[ty] (line 158).\n- m-dash in line 189.\n- m-dash in line 457.\n- m-dashes in lines 464--465.\n- please fix hyphen in line 481."}, "questions": {"value": "How is \"semantic resolution\" estimated in practice, and does its value depend on how the embeddings are scaled or normalized? That’s important because, otherwise, \"semantic resolution\" might just be a unit-dependent artefact rather than a stable, interpretable quantity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3ylvbORVHe", "forum": "ZF0xRAdsuY", "replyto": "ZF0xRAdsuY", "signatures": ["ICLR.cc/2026/Conference/Submission16680/Reviewer_8DWP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16680/Reviewer_8DWP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16680/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948157701, "cdate": 1761948157701, "tmdate": 1762926736889, "mdate": 1762926736889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors derive a theory for how a representation (for constrained resolutions) trades off between generalization and identification, a long known phenomenon from the cognitive science literature. In particular, this theory implies a Pareto frontier between generalization and identification performance. They empirically demonstrate that ReLU networks navigate such a Pareto frontier and find similar performance in a CNN finetuned on a mixture of an identification and generalization task. Finally, they show that LLMs and VLMs both show evidence of a finite resolution, a key assumption of their theory."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This manuscript provides a well articulated contribution to the field, formalizing a tradeoff that had previously been empirically observed. The theory is well-presented and I think the ReLU experiments in particular provide helpful support for the existence of the noted tradeoff. I appreciated the detailed contextualization of this present work in the field. Finally, the paper is generally well-written and the figures are well-designed. Below are some additional parts of the paper I particularly liked:\n\n- The equations (3) and (4) are simply and immediately make the tradeoff intuitive.\n- I think it's very interesting that the ReLU networks show some emergent evidence of this tradeoff even though they are only trained on the similarity task, not the identification task.\n- Figure 4 demonstrates a good match between their (modified) theory and empirical observations\n- Their Proposition 1 demonstrates that this theory can extend beyond the (somewhat minimal) binary similarity measure case.\n- The detailed explanation of the different regimes and Fig. 2 are very helpful."}, "weaknesses": {"value": "As noted above, I liked this paper. My primary concern is that the experiments in section 5 provide rather limited evidence of this tradeoff. Your suggestion (and the suggestion of the prior literature) that this is a universal tradeoff would suggest that it should be apparent even in models that weren't trained explicitly on the identification and similarity task you're measuring. The fact that models become better at identification/similarity as you're varying the parameter prioritizing one or the other loss function is maybe not particularly surprising (though I agree that it demonstrates that there is a tradeoff between those two functions). Moreover, the LLM and VLM experiments don't demonstrate a tradeoff but rather just show that resolution is limited overall. I thought the ReLU experiment was more compelling in this direction, as it trained the ReLU networks only on the similarity task and still demonstrated this emergent tradeoff over different epochs. Unless I'm missing something, I think acknowledging this limitation would be important."}, "questions": {"value": "- Would you expect an emergent tradeoff between identification and similarity performance if you only trained the CNN on either the identification or similarity task over different epochs (akin to the ReLU network case)?\n- Similarly, would you expect such a tradeoff e.g. in different pretrained models?\n- Could you discuss how your insights would apply to e.g. the tasks examined in Campbell et al. (2024)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2NCOCLeZhm", "forum": "ZF0xRAdsuY", "replyto": "ZF0xRAdsuY", "signatures": ["ICLR.cc/2026/Conference/Submission16680/Reviewer_MQEJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16680/Reviewer_MQEJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16680/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951973253, "cdate": 1761951973253, "tmdate": 1762926736384, "mdate": 1762926736384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}