{"id": "ubaQqVuBnE", "number": 8484, "cdate": 1758086465826, "mdate": 1759897781436, "content": {"title": "Nonparametric Data Attribution for Diffusion Models", "abstract": "Data attribution for generative models seeks to quantify the influence of individual training examples on model outputs. Existing methods for diffusion models typically require access to model gradients or retraining, limiting their applicability in proprietary or large-scale settings. We propose a *nonparametric* attribution method that operates entirely on data, measuring influence via patch-level similarity between generated and training images. Our approach is grounded in the analytical form of the optimal score function and naturally extends to multiscale representations, while remaining computationally efficient through convolution-based acceleration. In addition to producing spatially interpretable attributions, our framework uncovers patterns that reflect intrinsic relationships between training data and outputs, independent of any specific model. Experiments demonstrate that our method achieves strong attribution performance, closely matching gradient-based approaches and substantially outperforming existing nonparametric baselines.", "tldr": "A nonparametric data attribution method for diffusion models.", "keywords": ["Diffusion Models", "Data Attribution", "Nonparametric Methods"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/000eb90db484637c06734fdd38e8a232c1b95659.pdf", "supplementary_material": "/attachment/973e965f7e73ad9534d6920a3cfc9b6044dcf132.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose Nonparametric Diffusion Attribution (NDA), a gradient-free data-attribution method for diffusion models that scores patch-level influence using the analytic optimal score, and is optimized with convolution-based operations. They target black-box/proprietary settings with no access to a model's parameters, and show attributions that outperform prior baselines and approach gradient-based methods on CIFAR-10 and CelebA."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper seems practical and easy enough to follow in situations where no model access is available. The authors also report spatially interpretable results, and the method is shown to outperform significantly the tested prior baselines."}, "weaknesses": {"value": "1. A few core assumptions and scope limits should be made explicit. Most derivations rely on naive score-matching or score identities for standard diffusion losses, so general statements about “model-agnostic” influence seem like an overreach.  For example, if we inject an exact-reconstruction penalty in the loss, the results may no longer hold.\n\n2. Compute requirements seem concerning. The convolutional trick proposed by the authors helps with peak memory blow-up, but the per-image convolution over all training patches and multiple timesteps/scales won't scale very well. \n\n3. The authors test their work in relatively low-resolution settings (up to 64×64).\n\n4. The visual distribution tested a relatively simple, with generally smooth contours and simple patches."}, "questions": {"value": "(number references to the Weekness section)\n\nOn (2). It would be valuable to report wall-clock vs. dataset size, have some theoretical scaling analysis on compute for data size/resolution, and give scaling guidances. \n\nOn (3). Are the multiscale tricks and hyperparameters stable at higher resolutions or for more scales?—an experiment at ≥256×256 would be very valuable. \n\nOn (4). How does the algorithm behave with more complex distributions (e.g. Imagenet)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ceaiEXeftQ", "forum": "ubaQqVuBnE", "replyto": "ubaQqVuBnE", "signatures": ["ICLR.cc/2026/Conference/Submission8484/Reviewer_E9AP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8484/Reviewer_E9AP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761062434130, "cdate": 1761062434130, "tmdate": 1762920361989, "mdate": 1762920361989, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a nonparametric approach to data attribution for diffusion models motivated by scalability. It computes patch-level influence scores derived from the optimal score-function formulation. Effectiveness is evaluated via Linear Datamodeling Score (LDS) and counterfactual removal-and-retrain experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well motivated and well presented. The proposed approach is solid, although more explanations will be helpful (see weakness). In the evaluated scenarios, the methods seem to perform well."}, "weaknesses": {"value": "1. While the method is motivated by a score-function view, the estimator still just behaves like a complicated version of a similarity measure against training patches. Additional ablations/theory to isolate what truly helps will be very appreciated. For example, do naive patch-level similarities across timesteps already recover most of the effect? \n2. The paper is motivated by scalability. However, it seems that the paper still only evaluates on smaller models that generate low-res images."}, "questions": {"value": "As the authors also point out, patch-level attribution seems to be interpretable. Do you think that for diffusion model kind image generation models, patch-level attribution is just fundamentally a better approach compared to image-level attribution, as it provides more fine-grained signals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gEBiEvVLGT", "forum": "ubaQqVuBnE", "replyto": "ubaQqVuBnE", "signatures": ["ICLR.cc/2026/Conference/Submission8484/Reviewer_m648"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8484/Reviewer_m648"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728432315, "cdate": 1761728432315, "tmdate": 1762920361479, "mdate": 1762920361479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method for quantifying the relevancy of individual training samples to the outputs generated by diffusion models without requiring model access or gradients. The method performs patch-level similarity comparisons between generated and training images to quantify the attribution. Evaluation results using CIFAR-2, CIFAR-10, and CelebA datasets, show that NDA performance is close to gradient-based approaches and outperforming existing nonparametric baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Proposing an efficient query-only/nonparametric, data attribution approach for diffusion models.\n2. The method is based on analytical properties of the diffusion score function.\n3. The patch-level mapping can be used for understanding the relationship between training and generated images.\n4. Experiments show consistent improvements over the baselines."}, "weaknesses": {"value": "1. Figure 1 – The proposed method is not clear from the figure. I suggest improving the figure.\n2. No clear description of what are the requirements for performing the attribution\n3. Not clear how the ground-truth was generated?\n4. Experiments should be extended to larger and more complex datasets (e.g., ImageNet) to prove scalability and generalization.\n5. Comparisons with other strong nonparametric or model-free baselines is missing, for example: \n\n[a] CustomMark: Customization of Diffusion Models for Proactive Attribution\n[b] Montrage: Monitoring training for attribution of generative diffusion models\n\n6. Method's runtime analysis is missing."}, "questions": {"value": "1. Please explain what are the requirements for performing the attribution?\n2. How the ground-truth was generated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tHc11gj5kR", "forum": "ubaQqVuBnE", "replyto": "ubaQqVuBnE", "signatures": ["ICLR.cc/2026/Conference/Submission8484/Reviewer_iVsD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8484/Reviewer_iVsD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762204113234, "cdate": 1762204113234, "tmdate": 1762920361213, "mdate": 1762920361213, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Nonparametric Diffusion Attribution (NDA), a novel, model-agnostic method for data attribution in diffusion models. The key insight is to reinterpret the weighting term from the analytical, optimal score function of a diffusion process as an influence score. By grounding this in a local score function, the method derives a patch-wise similarity metric that is computationally efficient and requires no access to model parameters. The method demonstrates strong empirical performance on the Linear Datamodeling Score (LDS) when compared to several baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel Non-Parametric Framework: The paper makes a valuable contribution by framing the attribution problem from a non-parametric, data-driven perspective.\n2. Theoretical Motivation: The method is motivated by reinterpreting the weighting term (W_t) from the analytical form of the optimal score function (Eq. 5-6) as a measure of influence. This provides a strong theoretical justification for why this specific form of similarity should be effective.\n3. Strong Empirical Performance (vs. Chosen Baselines): On the LDS and counterfactual retraining metrics, the proposed NDA method is shown to be highly effective. It substantially outperforms other full-image non-parametric baselines (Raw Pixel, CLIP)."}, "weaknesses": {"value": "1. Unsupported Claim of Model-Independence: The paper makes a strong, highly valuable claim that \"our empirical results show that the attribution scores remain consistent across a variety of architectures and training regimes\" (Page 6, Line 281). However, there are no empirical results presented in the manuscript (including the appendix) to substantiate this.\n\n2. Missing \"Apples-to-Apples\" Baselines: The paper's core method (NDA) is patch-based. However, the non-parametric baselines it is compared against (\"Raw Pixel\" and \"CLIP Similarity\") are full-image-based. This is an \"apples-to-oranges\" comparison that inflates the perceived contribution of NDA. The strong performance seen might not come from the specific \"score-function\" formulation but simply from the act of using patches, which is a known technique. Some \"naive patch-based\" baselines include:\n    * Patch-wise Raw Pixel: A method that computes L2 similarity on top-k raw patches and aggregates them.\n    * Patch-wise Feature Similarity: A method that uses a standard feature extractor (e.g., CLIP, a pretrained CNN, or DINOv2) to embed patches and then computes a top-k aggregated similarity.\n\n3. Failure to Disentangle Causal Factors: The paper's novelty rests on two assumptions: theoretical motivation via optimal score function and localization. The current experiments do not disentangle these. It is unclear whether the method's good performance comes from the \"locality\" assumption (Eq. 9) or the \"optimal score\" formula itself (Eq. 6). The authors should provide an ablation study for an \"Image-wise NDA\" baseline. This method would be derived directly from the full-image optimal score function (Eq. 5) and would use the full-image weighting term $W_t$ (Eq. 6) as the influence score, with no patch decomposition."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LizRjBdOMD", "forum": "ubaQqVuBnE", "replyto": "ubaQqVuBnE", "signatures": ["ICLR.cc/2026/Conference/Submission8484/Reviewer_Hezj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8484/Reviewer_Hezj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762214742307, "cdate": 1762214742307, "tmdate": 1762920360556, "mdate": 1762920360556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}