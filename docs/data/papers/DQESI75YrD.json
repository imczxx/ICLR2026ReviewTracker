{"id": "DQESI75YrD", "number": 10595, "cdate": 1758176764154, "mdate": 1759897641622, "content": {"title": "PathChat-SegR1: Reasoning Segmentation in Pathology via SO-GRPO", "abstract": "Pathological image segmentation faces critical challenges in generalizing to rare diseases and staining variations, while clinicians require interpretable outputs for diagnostic confidence. We present PathChat-SegR1, a reasoning-guided segmentation framework that addresses these challenges through three key contributions. First, we construct the PathChat-SegR1 Benchmark comprising 118,667 pathology image-mask-reasoning triplets, including challenging intraoperative frozen sections, establishing the first large-scale dataset for reasoning-driven pathological segmentation. Second, we develop a comprehensive framework that incorporates pathology-specific prior knowledge through RuiPath visual encoder integration, stain-invariant MedSAM pretraining, and parameter-efficient fine-tuning strategies. Third, and most critically, we propose SO-GRPO (Segmentation-Optimized GRPO), a novel reinforcement learning method that transforms the \\texttt{<SEG>} token generation paradigm from fixed insertion to autonomous generation. SO-GRPO introduces four theoretical innovations: (1) temporal credit assignment via GAE for precise action-level optimization, (2) differentiable reward design enabling end-to-end gradient propagation, (3) information-theoretic sparsity control to balance generation necessity, and (4) convergence guarantees through Robbins-Monro conditions. These innovations collectively address key challenges in reinforcement learning for reasoning segmentation. Training on our benchmark, PathChat-SegR1 achieves 0.58 Dice on zero-shot pulmonary metastasis segmentation, significantly outperforming existing reasoning-based models. Remarkably, the model demonstrates training-free, one-shot adaptation capabilities, improving performance from 0.53 to 0.72 Dice on rare diseases with a single example at test time. This establishes a new paradigm for pathological image analysis where reasoning drives both segmentation accuracy and clinical interpretability. Our code and benchmark will be released at https://anonymous.4open.science/r/PathChat-Seg-3116.", "tldr": "", "keywords": ["Clinical Reasoning", "Reinforcement Learning，Reasoning Segmentation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/100f1dea2c8cc6cceceead6ccc56d0d341655e0a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes PathChat-SegR1, a reasoning-based segmentation framework specifically designed for pathological image analysis. The approach integrates domain-specific vision encoders (RuiPath and MedSAM) with stain-invariant pretraining and enables autonomous emission of a special \\<SEG\\> token. To enhance reasoning quality, the authors propose SO-GRPO, a reinforcement learning algorithm adapted from GRPO to address the challenges in special-token generation: credit assignment, gradient discontinuity, generation redundancy, and convergence instability. Additionally, the authors contribute the PathChat-SegR1 Benchmark, a large-scale dataset comprising 118,667 image–mask–reasoning triplets and report strong performance among reasoning segmentation approaches in zero-shot and one-shot settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies the fundamental challenges in pathological image segmentation.\n2. The combination of RuiPath and MedSAM with stain-invariant pretraining to incorporate pathological priors is reasonable.\n3. The PathChat-SegR1 Benchmark is valuable to the research community."}, "weaknesses": {"value": "1. Missing or inconsistent definitions: The SO-GRPO algorithm section is poorly specified. Key terms such as $R({\\tau})$ and $S_{\\text{spatial}}$ in Eq.10, $R_{\\text{soft}}$ in Eq.12, the \"Length Reward\" and \"Spatial Reward\" in Table 3 lack formal definitions. The objective function of PathChat-SegR1 is inconsistent between Eq.12 and Eq.72. Symbols $\\beta$ and $\\lambda$ are reused across different sections to denote distinct coefficients.\n2. Missing Implementation Details: Critical hyperparameters are not reported: $\\alpha$, $\\gamma$ in Eq.4; $\\lambda_{\\text{CoT}}$, $\\lambda_{\\text{seg}}$ in Eq.5; $\\lambda$ in Eq.8; and $\\beta$, $\\gamma$ in Eq.10. Algorithm 1 mentions \"value network parameters $\\phi$\" and the computation of $\\hat{A}_{\\text{GAE}}$, but there is no description of its architecture, update schedule, or training stability techniques.\n3. The use of GAE for credit assignment is not novel. Actually, introducing a value model increases training overhead, yet the paper provides no analysis of this trade-off. Besides, the variance reduction derivation in Appendix A4.4 assumes independence of TD residuals and a constant variance $\\text{Var}[\\delta_t] = \\sigma^2 $, which may not hold in practice.\n4. Soft Dice and soft IoU losses have been standard in segmentation literature for years. The claimed contribution of \"overcoming non-differentiability\" in Section 2.3.2 is unclear, as differentiable surrogates for these metrics are well-established.\n5. The sparsity reward $R_{\\text{sparse}}$ (Eq.10) depends on an indicator $I(s_t \\in S_{\\text{spatial}})$, but $S_{\\text{spatial}}$ is never defined or estimated. Appendices A.4.6–A.4.7 inconsistently switch between sparsity formulations: penalizing the policy $\\pi(\\cdot|s)$ versus penalizing entropy $H(\\pi)$. Mutual information terms are introduced without any computable estimator (e.g., MINE, NWJ) or practical surrogate, rendering the approach non-implementable.\n6. Convergence claims lack rigorous proof or supporting theoretical analysis. The use of AdamW optimizer with cosine annealing is a standard engineering choice and should not be presented as a methodological contribution.\n7. PathChat-SegR1 significantly outperforms baselines (e.g., Seg-Zero), even though Seg-Zero is also trained with RL. The paper does not adequately explain this large performance discrepancy.\n8. While the qualitative example of the One-Shot Adaptation is compelling, the paper omits quantitative and algorithmic details on how the single reference example is integrated.\n9. Reproducibility Concerns: The anonymized code repository provided by the authors is empty, potentially hindering reproducibility."}, "questions": {"value": "Please see the \"Weaknesses\" above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dKfD5TtSfk", "forum": "DQESI75YrD", "replyto": "DQESI75YrD", "signatures": ["ICLR.cc/2026/Conference/Submission10595/Reviewer_t6jx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10595/Reviewer_t6jx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706695688, "cdate": 1761706695688, "tmdate": 1762921862978, "mdate": 1762921862978, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PathChat-SegR1, a framework that unifies a pathology-specific vision-language model (RuiPath encoder + LLM) with a segmentation decoder inspired by MedSAM. The model autonomously emits a <SEG> token to trigger segmentation reasoning and is optimized using a new reinforcement learning variant, SO-GRPO, which aims to balance reasoning quality and segmentation Dice through differentiable Dice or IoU rewards. A new benchmark, PathChat-SegR1-Bench, with over 118k reasoning–mask pairs is also proposed. Results show strong reasoning coherence and competitive segmentation performance across several datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and organized, with clear motivation, systematic methodology, and coherent narrative flow between reasoning and segmentation.\n\n2. The integration of autonomous reasoning and segmentation via the <SEG> token is novel and intuitively powerful, showing a concrete step toward coupling cognitive reasoning with dense visual prediction.\n\n3. The experimental and benchmark contributions are substantial, covering multiple pathology modalities, providing large-scale data with reasoning supervision, and demonstrating consistent gains."}, "weaknesses": {"value": "1. The SO-GRPO theoretical claims (variance reduction, convergence guarantee) depend on strong assumptions not satisfied in multimodal, non-stationary RL; empirical validation of these properties is missing.\n\n2. The differentiable Dice or IoU reward may misalign with true evaluation metrics; no calibration study verifies that reward improvements translate to better segmentation.\n\n3. The autonomous <SEG> emission is insufficiently isolated; no ablation compares it directly with fixed-token baselines to show causal benefit.\n\n4. Benchmark documentation lacks details on deduplication, inter-rater reliability, and site-level separation; LLM-generated reasoning may introduce bias or leakage.\n\n5. Reproducibility remains limited: training scripts, trained checkpoints, splits, and RL logs are not publicly available, preventing independent verification."}, "questions": {"value": "1. Can you provide empirical evidence (variance plots, ablation) that SO-GRPO actually stabilizes training compared to GRPO or PPO?\n\n2. What is the isolated contribution of autonomous <SEG> emission versus fixed prompt insertion under matched encoders?\n\n3. How was duplication and data leakage controlled in PathChat-SegR1-Bench, particularly across magnification levels and scanners?\n\n4. How were LLM-generated reasoning chains quality-checked? Any inter-rater agreement statistics?\n\n5. How does PathChat-SegR1 compare to strong open-vocabulary segmentation models (e.g., Med-GPT4-SAM, LLaVA-Med-SAM) when trained under the same data and compute budget?\n\n6. Could the authors release training scripts, trained weights, splits, and logs to ensure full reproducibility and external validation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hKg86xkzaS", "forum": "DQESI75YrD", "replyto": "DQESI75YrD", "signatures": ["ICLR.cc/2026/Conference/Submission10595/Reviewer_aana"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10595/Reviewer_aana"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885192016, "cdate": 1761885192016, "tmdate": 1762921862305, "mdate": 1762921862305, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PathChat-SegR1, a reasoning segmentation framework for digital pathology that combines pathology-specific visual encoders, autonomous <SEG> token generation, and reinforcement learning (SO-GRPO) for improved interpretability and domain adaptation. The authors further introduce a large-scale PathChat-SegR1 Benchmark (118k image–mask–reasoning triplets) and demonstrate strong performance across zero-shot and one-shot settings, including challenging intraoperative frozen sections. The study aims to unify reasoning-driven interpretability with high-performance segmentation in clinical contexts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strengths\n1. The combination of pathology-specific encoders with reinforcement-learning-optimised token emission represents an original and conceptually coherent contribution to multimodal pathology AI.\n2. The SO-GRPO algorithm is rigorously formulated, with explicit derivations of temporal credit assignment, differentiable reward propagation, and convergence guarantees—rarely seen in medical imaging work.\n3. Evaluation spans public and clinical datasets, including frozen sections and rare diseases, demonstrating robustness and strong zero-/one-shot generalisation.\n4. The reasoning-augmented segmentation outputs offer interpretable chains-of-thought that could support clinical decision-making, an important step toward trustworthy AI in pathology.\n5. The release of a large and well-annotated benchmark is a significant service to the research community."}, "weaknesses": {"value": "Weaknesses \n1. The paper is dense, sometimes obscuring its main contributions. Key ideas (e.g., <SEG> token autonomy) are diluted by extended mathematical detail that could be condensed or moved to the appendix.\n2. The training protocols, data splits, and baseline implementations are only briefly described. Reproducibility would benefit from clearer procedural descriptions and access to full code upon publication.\n3. While segmentation metrics are comprehensive, there is little quantitative or user-based assessment of the quality or utility of the reasoning text for clinical interpretation.\n4. The conceptual structure resembles LISA and Seg-Zero. The incremental novelty of SO-GRPO relative to existing GRPO extensions needs clearer articulation beyond theoretical derivation.\n5. Although the appendix includes an ethics statement, more transparency about data curation, de-identification, and inter-observer variability would strengthen credibility for clinical translation.\n6. The manuscript’s prose, though technically precise, is occasionally verbose and repetitive. The narrative could be tightened for readability and to align with ICLR’s 9-page limit."}, "questions": {"value": "plz see my detailed comments above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CAYfW9rHRS", "forum": "DQESI75YrD", "replyto": "DQESI75YrD", "signatures": ["ICLR.cc/2026/Conference/Submission10595/Reviewer_751j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10595/Reviewer_751j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927213037, "cdate": 1761927213037, "tmdate": 1762921861854, "mdate": 1762921861854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PathChat-SegR1, a reasoning-based segmentation framework for digital pathology that integrates domain-specific visual encoders, autonomous token generation, and reinforcement learning optimization.\nThe work aims to address three main challenges in pathological image segmentation: (1) adaptation to diverse staining protocols and rare disease morphologies, (2) the need for interpretable, reasoning-driven segmentation, and (3) the absence of standardized evaluation benchmarks for such reasoning systems. The proposed framework combines four technical components: (i) a pathology-specific visual backbone, obtained by fusing RuiPath and MedSAM encoders, trained for stain invariance via masked autoencoding and self-distillation; (ii) an autonomous <SEG> token emission mechanism, which allows the model to decide when segmentation should occur during its reasoning process, replacing fixed token insertion used in prior models such as LISA; (3) a novel reinforcement-learning algorithm, SO-GRPO (Segmentation-Optimized Generalized Reward Policy Optimization), designed to improve multi-step reasoning and segmentation quality by introducing temporal credit assignment (via GAE), differentiable reward propagation, sparsity regularization, and stability guarantees through Robbins–Monro scheduling; (4) a large-scale PathChat-SegR1 Benchmark, comprising 118,667 (image, mask, reasoning) triplets collected from public pathology datasets and clinical frozen-section slides, intended to evaluate both segmentation and reasoning performance.\n\nExperimental evaluation covers zero-shot and one-shot adaptation to unseen pathologies and experiments on  public datasets (Camelyon, GlaS, DigestPath, CRAG). These experiments demonstrate competitive performance with strong supervised baselines, while maintaining explainable, reasoning-based outputs. Ablation studies and extended appendix analyses show that each component of SO-GRPO contributes to stability and accuracy.\n\nOverall, the paper presents an ambitious and comprehensive framework combining domain adaptation, language-driven reasoning, and reinforcement learning for interpretable medical segmentation, accompanied by a new benchmark dataset for this emerging research direction."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper proposes a technically ambitious framework that combines reasoning-based segmentation, pathology-specific pretraining, and reinforcement learning optimization. Its originality lies in merging three components that have rarely been unified before:\n(1) domain-specific encoders (RuiPath + MedSAM) with stain-invariant pretraining,\n(2) autonomous generation of the special <SEG> token that determines when segmentation should occur, and\n(3) the new Segmentation-Optimized GRPO (SO-GRPO) algorithm, which adapts reinforcement learning to multi-step reasoning and non-differentiable segmentation metrics.\nThis combination is novel and directly addresses the limitations of prior models such as LISA that relied on fixed token insertion.\n\nIn terms of research quality, the experimental evidence in Table 1 is strong.\nOn intra-operative frozen sections (FS-Mic / FS-WSI), PathChat-SegR1 achieves 0.74 / 0.84 Dice, outperforming MedSAM (0.62 / 0.76) and all other reasoning-based baselines (e.g., LISA-7B = 0.42 / 0.51, MMR-7B = 0.56 / 0.62).\nOn zero-shot pulmonary metastasis segmentation (PMBT), the method reaches 0.58 Dice, over 60 % higher than previous reasoning models, and its one-shot adaptation improves this to 0.72 Dice on rare disease cases.\nThese results demonstrate good generalization to unseen tissue types and realistic clinical conditions.\nSuch robustness to staining variation and low-data regimes is an important contribution for pathology.\n\nThe SO-GRPO ablations further confirm that each algorithmic component contributes to stability and convergence, with full SO-GRPO improving Dice by +5 points over standard GRPO and reducing gradient variance by 35%.\nThe reasoning outputs are interpretable and clinically aligned: the model autonomously focuses on fibrous-capsule regions when detecting metastases, mimicking expert behavior.\nThis supports the authors’ claim of improved clinical interpretability.\n\nRegarding clarity and reproducibility, the supplementary material includes detailed pseudo-code, convergence proofs, and additional ablations, which significantly strengthen the technical completeness of the work.\nWhile the main text is dense, the appendix provides the necessary information for replication.\n\nFinally, the significance of the study is high.\nThe integration of reasoning, segmentation, and reinforcement learning defines a new research direction for reasoning-driven medical imaging.\nThe accompanying PathChat-SegR1 benchmark (118 k triplets) could become a valuable large-scale dataset for this task and can serve as a reference for future work."}, "weaknesses": {"value": "Although the paper proposes an ambitious and conceptually interesting framework, several aspects limit its clarity, reproducibility, and empirical conclusiveness.\n\n1. Complex and dense exposition.\nThe paper is difficult to follow due to its highly technical writing style and extensive mathematical derivations.\nThe reader must infer how the various modules (RuiPath, MedSAM, <SEG> token, SO-GRPO) interact during pretraining, fine-tuning, and inference. A concise algorithmic diagram and explicit explanation of data flow at each stage would significantly improve readability.\n\n2.Ambiguity in benchmark construction.\nThe PathChat-SegR1 Benchmark relies partly on reasoning text generated by large language models (Gemini, DeepSeek) and later refined by human experts. The extent of human correction and the inter-annotator consistency are not quantified, raising concerns about annotation bias. While the dataset is valuable, its semi-synthetic nature should be discussed more critically.\n\n3. Limited external validation.\nThe model and benchmark are developed by the same authors.\nAlthough results on public datasets are reported later, it is unclear whether hyper-parameters were tuned using the same benchmark, which may lead to optimistic estimates. Independent validation on unseen institutional data would strengthen the clinical relevance of the claims.\n\n4. Mixed quantitative evidence (Table 2).\nOn several standard datasets, nnU-Net and other segmentation-only baselines outperform the proposed model, for example, nnU-Net achieves 0.91 Dice on GlaS and 0.94 on CRAG, compared to PathChat-SegR1’s 0.87 and 0.92. The authors argue that their model offers interpretability and generalization, yet the trade-off between reasoning quality and raw segmentation accuracy is not quantitatively assessed. A joint metric or multi-objective analysis would clarify whether the reasoning component justifies the performance gap.\n\n5. Inconsistent citation of baselines.\nTable 1 lists multiple comparison methods (MedSAM, LISA-7B, MMR-7B, etc.) without bibliographic references, while Table 2 includes them. This inconsistency makes it difficult to determine which implementations or versions were used. All baselines should be properly cited, and the paper should specify whether results come from official checkpoints or internal re-training."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2pn4pplTal", "forum": "DQESI75YrD", "replyto": "DQESI75YrD", "signatures": ["ICLR.cc/2026/Conference/Submission10595/Reviewer_vLfa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10595/Reviewer_vLfa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762089067972, "cdate": 1762089067972, "tmdate": 1762921861547, "mdate": 1762921861547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}