{"id": "wVBVa09JVV", "number": 16443, "cdate": 1758264651574, "mdate": 1759897240390, "content": {"title": "Don't Guess the Future, Find the Bottleneck: Spectral Subgoals for Offline Goal-Conditioned RL", "abstract": "Offline goal-conditioned RL (OGCRL) learns to reach arbitrary goals from offline dataset, but long-horizon performance hinges on crossing a handful of hard-to-cross bottlenecks. These bottlenecks not only dictate the feasible paths toward the goal but also act as critical keypoints, marking the transitions between adjacent regions and providing the agent with essential directional guidance. Prior hierarchical methods pick subgoals by time or short-horizon value heuristics, which do not localize the bottleneck, as a result, the agent losing the clear guidance that bottlenecks could provide about where to pass next. We instead model long-horizon planning as “cross the next bottleneck”: we apply Laplacian spectral clustering to offline dataset to expose bottlenecks and then identify trajectories from the offline dataset that cross these boundaries, and the intersects are defined as keypoints (KPs).\nThen the most representative KPs are automatically selected and a directed KP reachability graph $\\mathcal G_{\\mathrm{KP}}$ is constructed based on the selected KPs.\nWe then restrict high-level choices to these bottleneck states and use a pluggable low-level controller to execute the short transitions between them. \nWe provide theory showing that the next bottleneck is the optimal one-step subgoal and that Laplacian spectra recover bottlenecks with high overlap. Thus, Laplacian spectral clustering can discover approximately optimal subgoals. Empirically, the same pattern holds: across D4RL and OGBench, our method achieves state-of-the-art results on a broad set of navigation and manipulation tasks and across diverse dataset regimes, for example, **96.5\\%** on **AntMaze** and **84.5\\%** on **Franka-Kitchen**.", "tldr": "", "keywords": ["offline goal conditional reinforcement learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f16f3adb7d5905150a718e4fd96f886defa80050.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new approach to hierarchical OGCRL. It first learns a representation of the state space and then applies K-means clustering to partition the space based on the learned representations. A graph is subsequently constructed to identify key points that must be traversed to reach the goal (although it is not entirely clear how these key points are selected as subgoals). Finally, the method trains a low-level policy to sequentially reach these key points, ultimately achieving the desired goal. The proposed approach demonstrates strong performance in long-horizon navigation tasks.\n\nAs suggested by the AC, I have added a list of the key claims made in the paper and briefly assessed their validity:\n\n1. The optimal one-step subgoal is the next bottleneck (claimed in line 65). I would suggest being cautious with the use of the word \"optimal\". I can show a counterexample: in AntMaze, the ant can reach the goal through the inner circle of the branch rather than the bottleneck in the middle of the branch.\n\n2. The proposed method shows consistent bottleneck recovery. This seems reasonable as shown in Figure 3, but it would be more convincing to include results from different environments rather than only navigation tasks.\n\n3. The proposed method brings performance gains. I would agree, as there are significant improvements over the baselines (Table 2).\n\n4. The method generalises well to different but similar environments. This is supported by the high-level and low-level transfer experiments, which are both interesting and convincing.\n\n5. The claim on the impact of the number of clusters $K$ is not thoroughly verified, since the experiments are conducted in only one environment."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Overall, this is a good paper with a clear presentation, a novel idea, and strong empirical performance."}, "weaknesses": {"value": "Compared to other work in OGCRL, the proposed method appears somewhat complicated, although this is not necessarily a drawback. The authors should provide the hyperparameters used in their experiments to demonstrate the robustness or potential vulnerability of the proposed approach. Furthermore, additional ablation studies should be included in the paper, as suggested in Question 5."}, "questions": {"value": "1. The sentence \"don’t guess the future, find the bottleneck\" is somewhat ambiguous. From my reading, I understand that the authors mean “we do not rely on remaining time or value guidance; instead, we propose to follow the bottleneck.” Therefore, the authors may consider revising the title and the statement in line 62 for greater clarity.\n\n2. OGCRL typically employs a state-to-goal mapping, often denoted as $\\phi$ in related literature. For example, the state $s$ in AntMaze includes the full dynamics of the ant (such as its location), while $\\phi(s)$ represents a slice of $s$, capturing only the ant’s location. In this paper, BASS learns a Laplacian encoder $\\phi_\\theta$ and uses the resulting latent code for state clustering (via K-means, as mentioned in line 199). My question is whether this representation learning step is necessary. Could we instead directly use $\\phi(s)$ for clustering? Based on my experience, this might already yield a similar structure to what is shown in Figure 1.\n\n3. What does $D$ denote in line 213? The state coordinate dropping requires further clarification.\n\n3. There is a duplicated sentence in lines 243–245. Within that sentence, the meaning of goal residual is unclear. It is also difficult to understand how the authors select the next KP. Do the authors plan the shortest sequence of KPs from $s_0$ to $s_{goal}$? If so, does this shortest sequence in the graph correspond to the shortest path from $s_0$ to $s_{goal}$?\n\n4. The proposed method is relatively more complicated than other OGCRL approaches; therefore, it is necessary to conduct more thorough ablation studies. For example, they could examine the impact of the representation learning step discussed in Question 2, the hyperparameter $\\tau$ in line 202, and the number of K-means clusters. Although the authors analysed the effect of the number of clusters $K$, conducting this analysis in only one environment is insufficient to fully support their claim."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AeChXoLo2r", "forum": "wVBVa09JVV", "replyto": "wVBVa09JVV", "signatures": ["ICLR.cc/2026/Conference/Submission16443/Reviewer_3mmM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16443/Reviewer_3mmM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761580386120, "cdate": 1761580386120, "tmdate": 1762926557513, "mdate": 1762926557513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an offline goal-conditioned reinforcement learning (OGCRL) method that learns to expose bottlenecks as subgoals and discover trajectories to cross these subgoals. Specifically, key points (KPs) on the cluster boundaries are revealed as bottlenecks, and a KP graph is constructed for further route planning. Experimental results on D4RL and OGBench show improved performance of the proposed method compared with representative offline methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed framework is clear and easy to follow.\n2. Leveraging state transitions to select boundaries is interesting, as the key points could indicate hard-to-cross regions.\n3. Experimental results show that the proposed method achieves an improved success rate compared with previous works."}, "weaknesses": {"value": "1. I have several concerns regarding the selection of key points (KPs):\n- First of all, KP selection is highly dependent on the clustering performance. As discussed in Section 5.4, reducing the number of clusters results in coarse discovered boundaries. In addition, increasing the number of clusters might introduce route complexity during planning. Although Section 5.4 includes an ablation study, the range of cluster numbers evaluated is, in my opinion, insufficient. Since the peak success rate is achieved when K=26, only K=28 is evaluated as an “extra cluster,” and the drop in success rate (6.7%) is non-trivial. I would recommend evaluating more cluster numbers. Furthermore, as route complexity may increase with more KPs, adding trajectory steps could strengthen the experiment.\n- Secondly, in practice, the offline dataset is often noisy, where the agent may reach unexpected states and get stuck (e.g., corners in AntMaze). In such cases, complex yet unnecessary KPs may appear, causing additional complexity during planning.\n\n2. The idea of exposing cluster boundaries as subgoals is interesting, but the similar idea has been studied in this paper (https://arxiv.org/pdf/2411.01396).\n\n3. Some questions regarding the claim that “KPs are optimal subgoals”:\n- To sufficiently support this claim, I would recommend adding trajectory steps in the experimental results for comparison with the baselines.\n- In addition to Section 5.4, a comparison of trajectory steps with high-quality demonstrations or expert-annotated routes could further strengthen the evidence.\n\n4. Minor Issues:\n- The visualization of KPs is interesting, but the visualization of trajectories seem not to be shown in Figure 3.\n- KP discovery in Section 4.1 is an essential and complex step of the proposed method. Including pseudocode could strengthen the readability."}, "questions": {"value": "Please answer the questions in weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PeXEIBs0xx", "forum": "wVBVa09JVV", "replyto": "wVBVa09JVV", "signatures": ["ICLR.cc/2026/Conference/Submission16443/Reviewer_Ne7X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16443/Reviewer_Ne7X"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761685313289, "cdate": 1761685313289, "tmdate": 1762926556343, "mdate": 1762926556343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a novel algorithm for generating a planning graph for the offline goal-conditioned reinforcement learning setting. The method works by discovering bottlenecks via a Laplacian Spectral Clustering Algorithm (specifically, ALLO). With this, they have a novel mechanism for identifying the optimal bottleneck to user as the next subgoal in a planning algorithm. The plan of subgoals is that leveraged with a diffusion planner or an MLP for generating actions using subgoals generated by a planner. The key contribution is a mechanism for generating nodes in a graph based on \"keypoints\" derived from ALLO, along with theoretical results for why these are the \"best\" nodes for planning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The theoretical foundation and the algorithm are very clearly explained. \n\nThe writing is clear as well.\n\nThe results are strong with the baselines they consider. They have many baselines, which is good. They use 3 environments: AntMaze, FrankaKitchen, and Maze2D, which is good.  They show generalization results across environments, which is good. Presence of ablations are also good."}, "weaknesses": {"value": "It’s unclear what the specific contribution of this paper is regarding the use of Laplacian graph clusters for subgoal identification compared to prior work. The authors claim that “none of the existing methods have been used to significantly enhance goal-conditioned decision-making,” but that doesn’t seem accurate. There are numerous papers that leverage Laplacian-based representations for goal-conditioned reinforcement learning (RL), where Laplacian bottlenecks are explicitly used to discover meaningful subgoals. Such representations have already been shown to benefit RL. Is it that most of those focused on the benefits for exploration, whereas this paper focuses on offline RL?\n\nIf the authors are arguing that their setting is distinct because it involves transferring from an offline dataset to multiple goals simultaneously, that distinction needs to be clarified. It’s also not clear from the evaluation description how generalization is being tested for each offline dataset---are we evaluating on 1 goal, 4 goals, 10 goals?\n\nFinally, an important missing ablation is a simple baseline using ALLO with cluster means as subgoals. Since the proposed method appears to extend ALLO with a more sophisticated subgoal planning strategy, this baseline would help isolate the contribution of the new approach."}, "questions": {"value": "Novelty:\n- Is the main novelty of your method that you have a new way to generate nodes for a planing algorithm based on a Laplacian Spectral Clustering Algorithm? How does this compare to other methods for deriving nodes from Laplacian Representation Learning algorithms. I believe using low-frequency eigencomponents is something that has been done, e.g. [1,2]\n- Confirming that your use of a diffusion planner is not novel?\n\nExperiments:\n- I don't think I understand why you should expect generalization if you swap keyboard graphs across domains?\n- How do I interpret Table 3? What is the baseline comparison? It's just your method, which is confusing without references.\n- How do I interpret table 4? Same question for baseline comparisons? Should I just be comparing to your method when trained on the original target environment? There isn't a size dimension for Table 2 as far as I understand. The transfer here is really good. All above 95%. How do comparison methods do?\n- For the visualization of keypoints, how do other methods for detecting keypoints work? This is relevant for Figure 3.\n- A naive bottleneck discovery method would just use cluster means. I don't see that as comparison method. This seems important as the main contribution of this paper, as I understand it, is that you choose the \"optimal\" subgoal based on properties on properties of Laplacian spectral clustering.\n\n[1] Proto-value Functions: A Laplacian Framework for Learning: Representation and Control in Markov Decision Processes\n[2] A Laplacian Framework for Option Discovery in Reinforcement Learning"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZozrqhEaIU", "forum": "wVBVa09JVV", "replyto": "wVBVa09JVV", "signatures": ["ICLR.cc/2026/Conference/Submission16443/Reviewer_gT9f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16443/Reviewer_gT9f"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761765514675, "cdate": 1761765514675, "tmdate": 1762926555821, "mdate": 1762926555821, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "* This paper proposes BASS (Bottleneck-Aware Spectral Subgoaling), an offline goal-conditioned reinforcement learning (OGCRL) framework that identifies bottleneck states which connect metastable regions in the state space and utilizes them as subgoals for hierarchical planning.\n\n* BASS argues that the primary difficulty in long-horizon planning within OGCRL environments arises from hard-to-cross bottlenecks, rather than short-term value estimation. It formulates the subgoal selection problem as a spectral graph problem, leveraging the low-frequency structure of the Laplacian operator computed from offline data.\n\n* BASS achieves superior performance compared to prior methods on D4RL and OGBench benchmarks. However, the method has only been validated on numeric-state environments, and the subgoal features appear to have been manually specified, which could further limit its applicability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper introduces a novel spectral perspective on hierarchical goal-conditioned reinforcement learning by framing subgoal discovery as a bottleneck identification problem in the state space.  BASS leverages the low-frequency eigenstructure of the Laplacian operator derived from offline data to reveal metastable regions and their connecting bottlenecks.\n\n* The paper demonstrates theoretical analysis (Theorem 1 & 2) with a coherent algorithmic design that ties Laplacian representation learning, spectral clustering, and keypoint graph construction into a unified pipeline.\n\n* By grounding subgoal discovery in topological structure rather than temporal heuristics, BASS offers a principled approach that could influence future research in hierarchical and representation-driven RL"}, "weaknesses": {"value": "1. The proposed method appears to be applicable only to numeric-state environments, and all experiments were conducted exclusively under such low-dimensional state settings. It remains unclear whether the approach can extend to high-dimensional visual-state environments (e.g., image-based observations), and whether the Laplacian-based embedding would still effectively identify bottlenecks in such cases.\nClarifying the applicability to more complex observation modalities would strengthen the generality of the contribution.\n\n2. The paper represents each keypoint (KP) as (IΔ, vΔ), constraining only a subset of the state coordinates. However, the process for determining IΔ that is, which dimensions to include (e.g., x,y) appears to rely on manual or environment-specific heuristics. A more principled or learnable mechanism for feature selection (e.g., through information bottleneck criteria or gradient-based relevance analysis) would improve both generality and reproducibility.\n\n3. In the GENERALIZATION ACROSS ENVIRONMENTS experiment, it is unclear what meaningful insight is gained by swapping keypoint graphs between AntMaze-Stitch and AntMaze-Explore. These two datasets share the same map and the same navigation objective, implying that their keypoint graphs should not differ substantially. Moreover, the reported cross-domain transfer between PointMaze and AntMaze is difficult to interpret: if subgoals are represented solely by (x,y) coordinates and the low-level controller also relies on these coordinates as its input, then the successful transfer is almost inevitable by design, rather than demonstrating genuine generalization.\n\n4. This hand-crafted use of (x,y) as subgoal features may also undermine the fairness of comparison with prior baselines such as HIQL and Diffuser, which employ full-state embeddings (including joint angles or high-dimensional latent representations) for subgoal conditioning.\n\n5. While the bottleneck-based subgoal concept is conceptually appealing, the paper lacks an in-depth comparison with temporal distance representation (TDR)-based approaches such as HILP, QRL, and GAS. TDR methods learn representations that reflect optimal time distances—allowing farther movement in open regions and shorter transitions in constrained areas like corners. Since these works also utilize temporally grounded structure for subgoal selection or graph construction, a quantitative comparison would help clarify the specific advantages of BASS’s spectral formulation.\n\n6. Finally, although BASS demonstrates improvements on numeric-state benchmarks, the paper does not analyze failure cases.\nIt remains ambiguous whether the failures arise from (i) imperfect keypoint extraction or graph connectivity, (ii) limited capability of the low-level controller, or (iii) excessive distances between consecutive keypoints. For instance, in AntMaze-giant-stitch and AntMaze-large-explore, the success rates drop significantly. It would be insightful to analyze these cases in light of concurrent work such as GAS (Baek et al., 2025), which achieves strong performance using a TDR-based graph representation. Such analysis could reveal whether BASS’s limitations stem from the keypoint discovery mechanism itself or from broader challenges in long-horizon offline control."}, "questions": {"value": "Please provide responses to the weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "eqyrqwTqSG", "forum": "wVBVa09JVV", "replyto": "wVBVa09JVV", "signatures": ["ICLR.cc/2026/Conference/Submission16443/Reviewer_PGk3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16443/Reviewer_PGk3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968487900, "cdate": 1761968487900, "tmdate": 1762926555336, "mdate": 1762926555336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}