{"id": "QhkW8xPH1v", "number": 24327, "cdate": 1758355481873, "mdate": 1763732461521, "content": {"title": "Reliability Scaling Laws for Quantized Large Language Models", "abstract": "Quantization is a powerful strategy to build capable and resource-efficient large language models (LLMs) by reducing the bitwidth of the parameters. While quantized LLMs achieve state-of-the-art performance on unperturbed inputs using standard predictive metrics, their performance on perturbed inputs, measured using subsidiary reliability metrics, remains underexplored, despite its importance for safe and reliable deployment. To address this gap, we conduct a comprehensive reliability evaluation of quantized LLMs consisting of three key components: (1) Uncertainty: We assess the trustworthiness of LLMs quantized to 2, 3, 4, and 8 bits using six different quantization methods, employing established uncertainty metrics operating at both token and sequence levels. \n(2) Robustness: We design character-level and word-level input perturbations to evaluate the reliability of quantized models under semantically-preserving variations in the inputs that commonly arise in real-world applications.\n(3) Reliability scaling trends: We investigate how the reliability scales with the total number of model bits. Interestingly, our study reveals that while the performance scales monotonically with the total number of bits, the reliability scalings show nonlinear trends. Specifically, a reliability peak occurs for 4-bit quantized models, indicating that quantizing moderately sized base models offers the best reliability-efficiency trade-off. Additionally, our empirical findings reveal that quantization can enhance the robustness of LLMs to natural input perturbations.", "tldr": "We study how reliability scales with the total number of bits in quantized LLMs.", "keywords": ["LLM Evaluation", "Quantization", "Scaling Laws", "Reliability"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/50983f84bfb2b793c42a8f0c16f6dd7b412ba1a6.pdf", "supplementary_material": "/attachment/cdde5b3e193cf30662a791d6675bdbf804ce6383.zip"}, "replies": [{"content": {"summary": {"value": "This work addresses an interesting problem, and the experiments are empirically robust. The proposed concept of a \"Reliability Scaling Law\" is insightful, breaking down reliability into three interrelated yet distinct concepts: uncertainty, robustness, and reliability scaling trends. These three focus on different aspects of model performance. However, the current contribution primarily focuses on empirical validation, lacking theoretical depth and systematic comparative analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Reliability is a key limiting factor in the application of large models, but there has been little systematic analysis of how this scales with time. The experimental design compares different models, tasks, sampling parameters, prompts, and other variables. Scaling curves and error decomposition plots clearly illustrate the key findings, and the fitting results in Figures 3–5 are particularly explanatory."}, "weaknesses": {"value": "**1. Limited Innovation and Insufficient Theoretical Depth:**\n\nThe main contribution of this paper is to transfer the scaling law framework of Kaplan et al. (2020) to the \"reliability\" dimension. However, it does not theoretically model the failure point, and lacks clarity on whether the occurrence of reliability saturation is related to capacity limits or calibration errors.\n\n**2. Inadequately Clear Metric Hierarchy:**\n\nThe paper uses \"reliability\" as a unified metric, but it actually mixes multiple concepts: stochastic consistency, logical soundness, and factual accuracy, resulting in limited interpretability.\n\nAlthough the authors attempt to decompose reliability using uncertainty and robustness, the numerical definitions and calculation methods of the three are not strictly distinguished. At the same time, in the direction of LLM security and trustworthiness, there are relatively systematic analysis frameworks available for reference ([1,2,3,4]). The author did not include these methods in the evaluation or comparison, which weakened the scientific persuasiveness of the paper.\n\n3. The logical structure is clear, but the language connection is a bit stiff, and there is a need to improve the paragraph transition and argument coherence.\n\n**Ref:**\n\n[1] Hong J, Duan J, Zhang C, et al. Decoding compressed trust: Scrutinizing the trustworthiness of efficient llms under compression. ICML'24\n\n[2] Dong P, Li H, Guo S. Durable quantization conditioned misalignment attack on large language models. ICLR'25\n\n[3] Chen K, Zhang J, Hu J, et al. Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models. ICML'25\n\n[4] Li, Shiyao, et al. \"Evaluating quantized large language models.ICML'24"}, "questions": {"value": "Is there a unified scaling exponent for the three dimensions (uncertainty, robustness, reliability)?"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aNuvFcuQc3", "forum": "QhkW8xPH1v", "replyto": "QhkW8xPH1v", "signatures": ["ICLR.cc/2026/Conference/Submission24327/Reviewer_yDuL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24327/Reviewer_yDuL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761039981844, "cdate": 1761039981844, "tmdate": 1762943043247, "mdate": 1762943043247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the reliability of quantized large language models (LLMs) under semantics-preserving natural perturbations, decomposing reliability into calibration/uncertainty and robustness to perturbations, and evaluating these aspects systematically. The core approach uses the total number of model bits (parameter count × bit-width) as a unified capacity axis to compare scaling trends across model sizes and quantization precisions, fitting a log-quadratic relationship. Across multiple benchmarks and perturbation types, task performance (accuracy and perplexity) increases monotonically with total bits, while reliability metrics are non-monotonic. In most configurations, a 4-bit reliability–efficiency sweet spot emerges. The key conclusion is that, under a fixed memory or storage budget, appropriate low-bit quantization (especially 4-bit) can not only save resources but also improve robustness and calibration to semantics-preserving noise."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The study performs experiments across multiple public benchmarks and diverse natural perturbations, uncovering a non-monotonic relationship between performance and reliability metrics and highlighting a clear 4-bit sweet spot.  \n2. The results offer practical guidance for deployment, showing that under resource constraints, 4-bit quantization can improve inference efficiency while enhancing model robustness and calibration.  \n3. Radar plots over 15 semantically-preserving perturbations show that 4-bit maintains performance, and quantization improves reliability."}, "weaknesses": {"value": "1. Does not cover newer or more diverse architectures (e.g., Qwen3, Llama 4); evaluation is limited to LLaMA 3 and OPT.  \n2. The setup focuses on QA/LM, with generation truncated at 20 tokens, which may bias toward short-answer scenarios; robustness and calibration for long-form generation remain untested.  \n3. Although the paper reports the GPUs used and rough runtime, it lacks a systematic comparison of throughput, latency, and memory footprint; “total number of model bits” functions more as a capacity axis than an efficiency axis.  \n4. Many of the benchmarks used are relatively dated."}, "questions": {"value": "1. Have you tried repeating the experiments on the Qwen series (such as Qwen2.5 or Qwen3) or on newer models like Llama 4 to verify the generality of the 4-bit sweet spot?  \n2. Are the conclusions stable under different decoding strategies, such as variations in temperature, top-k, or top-p sampling?  \n3. Have you compared models with the same total parameter bits on efficiency metrics such as output throughput, latency, and memory footprint, and is using total parameter bits as a unified capacity axis reasonable for efficiency comparisons?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z7e8GJWT9P", "forum": "QhkW8xPH1v", "replyto": "QhkW8xPH1v", "signatures": ["ICLR.cc/2026/Conference/Submission24327/Reviewer_wYHt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24327/Reviewer_wYHt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794968183, "cdate": 1761794968183, "tmdate": 1762943042819, "mdate": 1762943042819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how quantization affects robustness in large language models (LLMs), beyond standard performance metrics like accuracy or perplexity. They conduct a comprehensive reliability evaluation of six state-of-the-art quantization techniques. Their study reveals that while the performance scales monotonically with the total number of bits, the reliability scalings show nonlinear trends."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "This paper studies the effect of quantization from an underexplored perspective: reliability under quantization, including robustness to realistic perturbations. \n\nExperiments are extensive across several model families, sizes, bitwidths, and quantization methods, covering diverse datasets.\n\nThis study reveals that while the performance scales monotonically with the total number of bits, the reliability scalings show nonlinear trends. This is a new finding."}, "weaknesses": {"value": "**Limited backbone model**: The experiments are conducted on LLaMA and OPT series, which are a bit outdated. As an empirical study on LLM quantization, the authors should try more diverse model series to prove that the findings are not restricted to specific models.\n\n**Character-level and word-level perturbations are not efficient for robustness**: The paper is mainly investigating how well a quantized model resists perturbations. However, robustness has a broader meaning: all operations maintaining semantic invariance should be considered.\n\n**Lacking insight**: While this paper proposes some interesting findings, the mechanism behind these findings is unclear, it is too empirical."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LcHqJukeKd", "forum": "QhkW8xPH1v", "replyto": "QhkW8xPH1v", "signatures": ["ICLR.cc/2026/Conference/Submission24327/Reviewer_vEp6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24327/Reviewer_vEp6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761823040095, "cdate": 1761823040095, "tmdate": 1762943042439, "mdate": 1762943042439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides the first comprehensive analysis of how quantization influences the reliability of LLMs.\nThe authors examine both uncertainty and robustness dimensions by introducing 15 semantically-preserving input perturbations and evaluating their effects across multiple quantization levels and model families.\nThrough empirical scaling analyses, the paper uncovers a non-monotonic trend in reliability: while accuracy scales monotonically with total model bits, reliability peaks at 4-bit precision. \nThis work offers valuable insights for understanding how quantization impacts model robustness and calibration, suggesting that quantization may even improve resilience to natural perturbations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**1. Novel reliability-focused analysis of quantization.** This is the first study to systematically analyze reliability scaling laws under quantization, shifting focus from mere accuracy preservation to robustness and uncertainty calibration.\n\n**2. Comprehensive experimental evaluation.** The evaluation is thorough and well-designed, covering numbers of experiments across various base models, quantization methods, bitwidths, datasets, and perturbation types at varying intensities, providing strong empirical evidence for the claims.\n\n**3. Well-motivated perturbation design.** The character-level and word-level perturbations are carefully designed to reflect realistic typed digital communication scenarios rather than adversarial attacks, making the robustness evaluation ecologically valid.\n\n**4. Insightful and counterintuitive finding.** The observed reliability peak at 4-bit precision challenges common assumptions that higher precision monotonically improves reliability, revealing a new dimension of quantization effects."}, "weaknesses": {"value": "**1. Limited theoretical explanation for 4-bit peak.** While the paper observes and documents the reliability peak at 4-bit quantization across multiple settings, the theoretical explanation remains somewhat superficial, attributing it to a balance between quality degradation and overconfidence without deeper mechanistic analysis of why this particular bitwidth achieves optimal regularization.\n\n**2. Missing generalization to other compression forms.** The study excludes pruning and quantization-aware training, leaving open whether the observed reliability trends generalize to broader compression paradigms.\n\n**3. Insufficient validation.** All experiments focus on QA and language modeling benchmarks; it would strengthen the claims to evaluate reliability scaling in reasoning, dialog tasks."}, "questions": {"value": "**1. Generalization to other compression methods.** The paper briefly discusses pruning and knowledge distillation in the introduction, but it remains unclear how reliability scaling trends might differ across these alternative compression paradigms. \nCould the authors elaborate on their expectations regarding reliability behaviors under pruning (e.g., structured vs. unstructured) or distillation (e.g., teacher–student reliability transfer)? \nAdditionally, how might quantization-aware training (QAT) affect the observed reliability peak-does fine-tuning mitigate or amplify quantization-induced regularization effects? \nIt would be valuable if these hypotheses could be empirically verified or at least partially validated through controlled experiments.\n\n**2. Domain generalization to other modalities.** While the study focuses on textual LLMs, do the authors expect similar non-monotonic reliability trends to emerge during compression in other domains, such as the quantization of vision models, zero-shot quantization settings, or PTQ / QAT of VLMs?\nGiven that quantization in ViTs and multimodal encoders often interacts differently with robustness and calibration, extending this analysis to non-text modalities could provide stronger evidence for the universality of the proposed reliability scaling laws.\n\n**3. Perturbation-specific quantization benefits.** Among the designed perturbations, are there specific categories (e.g., character-level vs. word-level, or distinct perturbations such as emoji or slang) where quantization yields particularly strong or weak robustness gains? \n\n**Misc.**\nPlease adjust paragraph formatting to avoid orphaned lines at the end of paragraphs, and ensure figures are better integrated with text to prevent single-line overflows that disrupt the visual flow of the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Vi5rcvpM3g", "forum": "QhkW8xPH1v", "replyto": "QhkW8xPH1v", "signatures": ["ICLR.cc/2026/Conference/Submission24327/Reviewer_aRAR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24327/Reviewer_aRAR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921333550, "cdate": 1761921333550, "tmdate": 1762943042216, "mdate": 1762943042216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}