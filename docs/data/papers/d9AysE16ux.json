{"id": "d9AysE16ux", "number": 19427, "cdate": 1758296186960, "mdate": 1759897039533, "content": {"title": "GraIP: A Benchmarking Framework for Neural Graph Inverse Problems", "abstract": "A wide range of graph learning tasks—such as structure discovery, temporal graph analysis, and combinatorial optimization—focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process—such as message passing or network dynamics—that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse\nproblems.", "tldr": "We propose the Neural Graph Inverse Problem (GraIP) framework, which casts diverse graph learning tasks as inverse problems, providing a unified and principled approach to combinatorial optimization, structure learning, and dynamic graph inference.", "keywords": ["inverse problems", "graph learning", "benchmark"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/95f7ea2f950573d049506719ac168e8dbc084a63.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a unified and general framework for casting graph learning problems as *inverse problems on graphs*. The main idea is that many graph learning tasks can be viewed as finding an inverse mapping that explains a forward process (e.g., diffusion dynamics, biological interactions), thereby recovering the underlying graph structure that generated the observations. The proposed *Neural Graph Inverse Problem (GraIP)* framework formalizes this idea and is instantiated across several applications, including causal discovery, neural relational inference, and graph rewiring. For each task, the authors benchmark existing methods and discretization strategies, demonstrating both the generality and challenges of the framework.\n\nOverall, this is a well-written and timely paper that makes a valuable conceptual and benchmarking contribution. Unifying graph-learning tasks of different natures under the inverse-problem paradigm is novel and potentially impactful. However, there remains a noticeable misalignment between the theoretical formulation and its practical instantiations, and the experimental analysis is somewhat shallow in explaining and interpreting results. Addressing these issues would significantly strengthen the paper."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Timeliness and relevance:** The paper tackles an important and underexplored topic, aiming to fill a gap in the graph learning literature by bringing insights from inverse problems in imaging and physics-based domains to graph-structured data.  \n- **Generality and scope:** The framework is applied to several distinct graph learning problems (causal discovery, neural relational inference, and graph rewiring), supporting the claim of generality.  \n- **Clarity and writing quality:** The paper is clearly written and well structured, making it easy to follow.  \n- **Benchmarking contribution:** The inclusion of multiple tasks and comparison of discretization strategies (I-MLE, Gumbel, SIMPLE) is challenging, but the authors managed to include them all in a cohesive manner."}, "weaknesses": {"value": "1. **Presentation inconsistencies and limited analysis:**  \n  While the paper is generally well-written, some presentation issues remain. Figures in the experimental sections lack detailed captions, and the naming of methods is inconsistent (e.g., Table 1 refers to “GraIP” and “Max-DAG I-MLE,” which differ from names used in the text). In addition, the analysis of experimental results is minimal — sections such as causal discovery and graph rewiring offer only brief quantitative summaries without deeper interpretation or discussion. Expanding these analyses would clarify what is being learned, why specific methods succeed or fail, and the advantages of seeing these problems through the lens of inverse problems. Also, CD is mentioned in Section 4.4 (I assumed it refers to causal discovery), but it is never defined.\n\n2. **Unclear formulation:**  \n  The definition of the general framework could be more precise. In Section 2.1, the forward model maps from latent variables $z$ (and noise) to observations $y$, and the inverse mapping goes from $y$ back to $z$. In the graph case, however, the inverse mapping $I(G, X, y) \\to \\tilde{G}$ does not strictly invert the forward map $F(G, X) \\to y$; instead, it modifies or reconstructs the graph itself. This makes the notion of “inverse” somewhat ambiguous. The authors should clarify what is being inverted conceptually. In particular, whether $I$ aims to recover the underlying graph structure or optimize a reconstruction objective involving $F$.\n\n3. **Mismatch between framework and instantiations:**  \n  In some applications, especially graph rewiring, the inverse mapping operates within the same space (from $G$ to $\\tilde{G}$). At the same time, the forward map serves as a predictor for some downstream task (link prediction). This setup appears closer to a graph topology/graph learning or representation learning combined with a regressor than a classical inverse problem, at least from a conceptual perspective. The authors should better explain how such tasks fit within the general GrapIP framework and how using this formulation yields some improvement (even if not numerically, but at least conceptually).\n\n4. **Missing related work:**  \n  The related work section omits a recent work on *graph inverse problems*  [1], which is directly relevant and should be cited for completeness.\n\n5. **Comparison between blind and non-blind cases**\nThe framework supports both blind and non-blind cases, but it is not clear how going from the blind to the non-blind case complicates the general formulation. It would be good to see an experiment showing how well the proposed framework estimates a forward model, for example, by doing this in a controlled case where you have access to the forward model. This would be important to 1) understand if the method can recover the forward model, and 2) how stable the joint optimization is.\n\n6. **Discretization bottleneck**\n Section 3.1 says, \"It is sometimes preferable to relax the requirement to produce a\ndiscrete graph during training. An important insight from our framework is that discretization can be\nharmful, impairing stability and convergence, and also beneficial, by enforcing useful structural priors\nearly in learning\". Can the authors expand on the trade-off, and why is it sometimes preferable to relax the discrete requirements?  \n\n7. **Unclear contribution of GraIP**\nWhat are the concrete benefits of this general formulation?\nCan a single model be transferred across domains/applications? Or does the framework enable new methods? \nFurthermore, the paper proposes MPNN+I-MLE as a universal recipe, but results show it's often worse than continuous methods.\nIn particular, a core claim is that GraIP enables \"cross-pollination of existing methods across graph inverse problems. \nHowever, no experiments validate this. For example: a) Can an inverse map I^(θ) trained on NRI transfer to GRN inference (both involve temporal dynamics and complete graphs)? b) Does pre-training on one GraIP task improve performance on another?\nIt is important to demonstrate concrete transfer benefits or acknowledge this as a limitation and future work. \n\n8.  **Inconsistent baseline comparisons:**  \nThe description of the baselines needs to be improved. First, \"Base\" and \"Rand\" rewire are poorly defined. What is \"Base\" for example? For NRI, the comparisons are only with respect to the gradient estimator method, but not any domain-specific one or non-GraIP that performs well (even some SOTA method or close to SOTA with an open source implementation).\n\n\n[1] Eliasof, M., Siddiqui, M. S. R., Schönlieb, C. B., & Haber, E. (2025, April). Learning Regularization for Graph Inverse Problems. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 39, No. 16, pp. 16471-16479)."}, "questions": {"value": "1. **Learning of the inverse map (Eq. 1):**  \n   In conventional inverse problems (e.g., in imaging), the inverse mapping is typically learned by minimizing an error between the output of the inverse model (e.g., a denoiser) and the clean latent signal, sometimes using frameworks like SURE or diffusion-based self-supervised training. Here, the loss seems to minimize the discrepancy between $F(I(G, X, y))$ and the *noisy observations* $y$. Could the authors clarify the rationale and how this differs from standard inverse problem formulations?\n\n2. **Regularization:**  \n   The general formulation includes a regularization term $R(I(G, X, y))$, but its instantiation is not described in the experiments. Was any explicit regularization (e.g., sparsity, or smoothness) applied in the benchmarks, or was it omitted? \nFurthermore, Section 4.4 explains that the ill-posedness is stronger when the size of the graphs increases, which is expected. Is there any potential regularizer that might help to address this? Because the framework incorporates a regularizer, but as said above, it is never used\n\n3. **Generality of GraIP**\nWhile GraIP is a unifying framework, it would be good to explain which problems do not fit GraIP?\n\n4. **Drop in performance in CD**\nCan the authors expand on why the performance of Max-DAG I-MLE in Table 1 drops so drastically from ER2-30 to ER4-30?\n\n\n---\n\nI assign a score of 4 due to the concerns outlined above, particularly the missing experimental validation of transfer claims, ambiguities between the theoretical and generic formulation, its practical instance, and unused regularization. In particular, the most relevant points are:\n\n1. Clarify what is being \"inverted\" conceptually (Weaknesses #2-3)\n2. Provide preliminary transfer experiments or acknowledge as future work \n   (Weakness #7)\n3. Explain the CD performance collapse and potential remedies (Question #4)\n4. Discuss how well the method approximates the forward operator in some controlled experiment.\n5. Clarify why R(·) is never instantiated (Question #2)\n\nI would be happy to discuss the above-mentioned points and the remaining ones."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fg7MgY7mMd", "forum": "d9AysE16ux", "replyto": "d9AysE16ux", "signatures": ["ICLR.cc/2026/Conference/Submission19427/Reviewer_JtZo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19427/Reviewer_JtZo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761503323029, "cdate": 1761503323029, "tmdate": 1762931352233, "mdate": 1762931352233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GraIP (Graph Inverse Problems), a unified conceptual and benchmarking framework that reframes a wide range of graph learning tasks—including causal discovery, neural relational inference, graph rewiring, and combinatorial optimization—as inverse problems. Instead of learning on a given graph, GraIP aims to recover the latent graph structure that best explains observed data under a learnable forward model. The authors provide a general formulation, instantiate it across several domains, and propose corresponding benchmarks and baselines. They also empirically evaluate existing methods under the GraIP lens, highlighting shared challenges such as discretization, non-identifiability, and gradient estimation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Originality: This is the first systematic attempt to unify graph structure learning tasks under the inverse problem paradigm. The framing is conceptually novel and provides a fresh perspective on seemingly disparate tasks like rewiring, causal discovery, and relational inference. It opens up new avenues for cross-pollination between fields like combinatorial optimization, causal inference, and graph generation.\n\n- Technical Quality: The paper is mathematically rigorous and well-grounded in the classical inverse problem literature. The authors clearly define the forward map, inverse map, distance function, and regularization, and show how existing methods (e.g., NRI, NoTears, PR-MPNN) can be reformulated within GraIP. The benchmarking protocol is comprehensive, with standardized datasets, metrics, and baselines.\n\n- Clarity: Despite the breadth of content, the paper is well-organized and clearly written. The modular structure (inverse map, forward map, discretization, gradient estimation) makes the framework easy to understand and extend. Figures and tables effectively summarize the instantiations and results.\n\n- Significance: GraIP has the potential to redefine how we think about graph structure learning. By exposing shared algorithmic challenges (e.g., differentiating through discrete graphs, enforcing constraints), it encourages methodological innovation and fair comparison across domains. The framework is timely, as many graph learning tasks are currently silos with little cross-domain insight."}, "weaknesses": {"value": "- Limited Novel Algorithmic Contributions: While GraIP is conceptually elegant, the paper does not introduce new models or algorithms. It reframes existing ones and benchmarks them under a unified lens. As a result, the algorithmic novelty is low, and the empirical improvements are marginal in some domains (e.g., causal discovery).\n\n- Scalability and Efficiency Not Discussed: The paper does not address the computational scalability of GraIP formulations. For example, in causal discovery and GRN inference, the combinatorial explosion of possible graphs is a major bottleneck. The authors acknowledge ill-posedness at scale but do not propose principled solutions (e.g., amortized inference, hierarchical priors, or latent variable relaxations).\n\n- Discretization Remains a Bottleneck: Although the paper highlights the discretization challenge, it does not resolve it. The empirical results show that discretized methods (e.g., I-MLE) often underperform continuous relaxations (e.g., NoTears, GOLEM). A deeper analysis of when and why discretization fails, or how to improve it, is missing.\n\n- Lack of Theoretical Analysis: While the framework is general, there is no theoretical treatment of identifiability, sample complexity, or generalization bounds under GraIP. Such an analysis would strengthen the contribution, especially for blind inverse problems where both forward and inverse maps are learned."}, "questions": {"value": "1. Scalability: How does GraIP scale to larger graphs? Have you tested approximate inference or latent variable relaxations to handle the combinatorial explosion?\n\n2. Theoretical Guarantees: Are there conditions under which GraIP recovers the true graph (e.g., identifiability, consistency)? Can you provide sample complexity bounds or recovery guarantees under specific generative models?\n\n3. Discretization Improvements: What are the main failure modes of I-MLE and other gradient estimators? Have you explored hybrid methods (e.g., continuous pre-training + discrete fine-tuning) or regularization techniques to stabilize discretization?\n\n4. Foundation Models: Do you envision pre-training a general-purpose inverse map (e.g., a graph transformer) that can be adapted to multiple GraIP tasks? How would you handle task-specific constraints (e.g., DAG, sparsity, acyclicity)?\n\n5. Real-World Evaluation: Have you applied GraIP to real-world datasets (e.g., protein networks, brain connectivity, social graphs)? How does it perform in noisy, incomplete, or adversarial settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YXDZ9OzatF", "forum": "d9AysE16ux", "replyto": "d9AysE16ux", "signatures": ["ICLR.cc/2026/Conference/Submission19427/Reviewer_Ubr3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19427/Reviewer_Ubr3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909650309, "cdate": 1761909650309, "tmdate": 1762931351859, "mdate": 1762931351859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the GraIP framework, which formalizes different graph learning tasks—such as causal discovery, neural relational inference, and graph rewiring—as neural graph inverse problems. The goal of the graph inverse problem is to find both forward and inverse map. The inverse map recovers latent graph structures from observations, which is a tuple of the initial graph, node features, and the labels.  The forward map takes the output produced by the inverse map and predicts the outcomes. They instantiate GraIP across several domains, summarize the baseline implementations under this framework, benchmark datasets, and provide empirical results, aiming to bridge isolated methods and encourage cross-domain advancements."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and structured, ideas are presented clearly and easy to follow.\n- Interesting perspective on existing problems under the inverse problem lens, with detailed analysis casting them as instances of the proposed framework.\n- Interesting discussion on practical challenges: discretization bottleneck and ill-posedness for large graphs, along with potential future combinations of generative models."}, "weaknesses": {"value": "- While the unification is interesting, the core idea of framing graph inference as an inverse problem is not fundamentally new. The framework is largely a re-framing of existing approaches rather than a methodological advance.\n- While integrating discretization methods like I-MLE or STE for some existing models is somewhat novel, the core framework largely reframes existing methods without introducing new technical improvements.\n- Benchmarks for the first two instances are based on synthetic data, which is limited in scale and diversity, and restricted to ideal scenarios.\n- Limited baselines for each set of problems examined."}, "questions": {"value": "- While showing existing methods follow the proposed framework, does it lead to any new insights about these methods' limitations or common failure modes that weren't apparent when they were considered in isolation?\n- In the setting where both inverse and forward maps are learned, the system could find degenerate solutions (e.g., $F$ learns to ignore $\\tilde{G}$ , or $I$ produces a trivial graph that $F$ easily memorizes). How can we check and guard against this and ensure the inferred graph $\\tilde{G}$ is meaningful?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GHFeCv5TF7", "forum": "d9AysE16ux", "replyto": "d9AysE16ux", "signatures": ["ICLR.cc/2026/Conference/Submission19427/Reviewer_uJ8E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19427/Reviewer_uJ8E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988349364, "cdate": 1761988349364, "tmdate": 1762931351403, "mdate": 1762931351403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces \\textbf{GraIP}, a unifying framework that casts diverse graph-learning tasks---including causal discovery (CD), neural relational inference (NRI), and data-driven \\emph{rewiring}---as \\emph{graph inverse problems}. The setup learns (i) an \\emph{inverse map} $I_\\theta$ that proposes a graph $\\tilde G$ from observations, and (ii) a \\emph{forward map} $F_\\phi$ that uses $\\tilde G$ to reconstruct the observations. Training minimizes a reconstruction loss (with optional regularization and discretization). The paper provides recipes for $I_\\theta$ (scores/priors; Gumbel, I-MLE, STE for discretization) and $F_\\phi$ (MPNN/Transformer/simulator), and benchmarks three domains (CD, NRI, rewiring), highlighting when discretization helps or hurts and how scale induces ill-posedness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Unifying lens that cleanly separates I (inverse) vs F (forward) and makes many prior works “click together.” Easy to port methods across domains\n    Benchmarking clarity: clearly specified domains, data, metrics, and simple, reproducible baselines; tables communicate the discretization story well."}, "weaknesses": {"value": "Scope of benchmarks is modest. For CD, only linear-Gaussian synthetic settings are shown.  For NRI, only Springs is used. For rewiring, only ZINC.\n\nThe current baseline set is too narrow for a benchmarking paper. It does not fully establish where GraIP stands relative to strong alternatives across domains."}, "questions": {"value": "Rewiring on non-molecular data: Do the gains persist on heterophilous graphs or long-range tasks?\nIn blind GraIPs (jointly learning F and I), how does the method train these two components?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "USZsAFJNu7", "forum": "d9AysE16ux", "replyto": "d9AysE16ux", "signatures": ["ICLR.cc/2026/Conference/Submission19427/Reviewer_CBpu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19427/Reviewer_CBpu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762039728814, "cdate": 1762039728814, "tmdate": 1762931350714, "mdate": 1762931350714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}