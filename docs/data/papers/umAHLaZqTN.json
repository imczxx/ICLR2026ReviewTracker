{"id": "umAHLaZqTN", "number": 13895, "cdate": 1758224540498, "mdate": 1759897405639, "content": {"title": "Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment", "abstract": "Supervised Fine-Tuning (SFT) is an effective method for adapting Large Language Models (LLMs) on down-stream tasks. However, variability in training data can hinder a model's ability to generalize across domains. This paper studies the problem of \\textit{dataset alignment} for Natural Language to SQL (NL2SQL or text-to-SQL), examining how well SFT training data matches the structural characteristics of target queries and how this alignment impacts model performance.\nWe hypothesize that alignment can be accurately estimated by comparing the distributions of structural SQL features across the training set, target data, and the model’s predictions prior to SFT. \nThrough comprehensive experiments on three large cross-domain NL2SQL benchmarks and multiple model families, we show that structural alignment is a strong predictor of fine-tuning success. When alignment is high, SFT yields substantial gains in accuracy and SQL generation quality; when alignment is low, improvements are marginal or absent. These findings highlight the importance of alignment-aware data selection for effective fine-tuning and generalization in NL2SQL tasks.", "tldr": "This paper introduces KL-alignment and the Alignment Ratio to predict when supervised fine-tuning on a Text-to-SQL dataset will improve a model’s performance across different target workloads.", "keywords": ["Natural Language to SQL (NL2SQL)", "Dataset Alignment", "Structural Alignment", "Text-to-SQL", "Supervised Fine-Tuning (SFT)"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7d93f7fb9bc18dc75c3500a771ca082bcfe317b4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates how dataset alignment affects supervised fine-tuning for Text-to-SQL models. The authors propose a KL-based metric to quantify the structural similarity between SFT training data and target SQL queries, and show that this alignment strongly predicts post-SFT performance. Extensive experiments across multiple NL2SQL benchmarks and model families confirm that high structural alignment leads to substantial gains in accuracy and SQL generation quality, while low alignment yields limited improvements or even performance degradation."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides extensive experiments across diverse NL2SQL benchmarks and multiple LLM families, offering convincing evidence that the proposed KL-based alignment metric is strongly correlated with post-SFT improvements. \n\n2. The narrative is well structured and easy to follow, with a clear motivation, carefully articulated methodology, and thorough analysis."}, "weaknesses": {"value": "1. The central conclusion — that structurally aligned fine-tuning data yield better SFT performance — is fairly straightforward and offers limited deeper insight beyond confirming the intuitive notion that “more similar data helps”.\n\n2. The methodology of applying the Kullback‑Leibler divergence (KL-divergence) to measure dataset alignment or support data selection is not particularly novel. Prior literature has used KL divergence for distributional comparison and subset selection [1, 2], which somewhat diminishes the originality of the methodological contribution.\n\n3. The reliance on SQL skeletons (query templates) for computing structural statistics restricts the generality of the approach: by design the method is tightly coupled to the SQL domain and may not extend easily to tasks with less rigid templated structure or to downstream applications beyond NL2SQL.\n\n[1] Everaert D, Potts C. Gio: Gradient information optimization for training dataset selection[J]. arXiv preprint arXiv:2306.11670, 2023.\n\n[2] Kurian J F, Allali M. Detecting drifts in data streams using Kullback-Leibler (KL) divergence measure for data engineering applications[J]. Journal of Data, Information and Management, 2024, 6(3): 207-216."}, "questions": {"value": "None."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jPlXwcTThX", "forum": "umAHLaZqTN", "replyto": "umAHLaZqTN", "signatures": ["ICLR.cc/2026/Conference/Submission13895/Reviewer_H47W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13895/Reviewer_H47W"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659972019, "cdate": 1761659972019, "tmdate": 1762924403558, "mdate": 1762924403558, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the role of dataset alignment in supervised fine-tuning (SFT) for text-to-SQL tasks. The authors propose a KL-alignment metric based on structural SQL features to measure how well training data matches target query distributions. Through extensive experiments on multiple benchmarks and model families, the authors demonstrate that alignment strongly predicts SFT success and generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The observation of this paper has certain value for subsequent post-training.\n2. The evaluation model is comprehensive."}, "weaknesses": {"value": "1. Whether the proposed alignment prediction framework can directly improve the SFT performance, there is a lack of a clear method to directly improve the performance of SFT.\n2. A large amount of related work published in 2025 was not discussed.\n3. No automated data selection or valid tuning method is proposed—only a diagnostic metric. I believe alignment will be effective, but I cannot verify it at this stage."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NXyqaDZoqm", "forum": "umAHLaZqTN", "replyto": "umAHLaZqTN", "signatures": ["ICLR.cc/2026/Conference/Submission13895/Reviewer_Z5Wx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13895/Reviewer_Z5Wx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761665925212, "cdate": 1761665925212, "tmdate": 1762924403193, "mdate": 1762924403193, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the problem of dataset alignment in supervised fine-tuning (SFT) for Natural Language to SQL (NL2SQL) tasks. Essentially, the authors ask: how well do the characteristics of the training data align with those of the target queries? They hypothesize and empirically show that when SFT data is well-aligned with the structural patterns in the target data, the resulting fine-tuned models perform much better. The paper formalizes a KL-alignment metric and an alignment ratio (based on distributions of SQL n-grams/templates) and demonstrates that these predict the success of fine-tuning. Through comprehensive experiments on several cross-domain NL2SQL benchmarks (BIRD, Spider, Gretel) and a range of LLM families (Qwen, CodeLlama, Deepseek), they show high alignment correlates with strong gains in execution and exact match accuracy, while low alignment can yield little to no improvement (sometimes even degrading performance). The authors also propose a simple framework for predicting post-SFT performance before actually fine-tuning, which can help practitioners select training datasets more strategically."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Identifies and systematically formalizes the effect of dataset alignment in NL2SQL fine-tuning. Introduces alignment metrics (KL-alignment, ratio) that not only measure but also predict transfer learning success or failure before SFT. Comprehensive empirical study spanning a wide model and dataset range; clear, robust trends. Shows practical use: enables practitioners to avoid wasted effort/failures due to misaligned data. Readily reusable ideas and framework could be adapted to other semi-structured outputs, e.g., code generation."}, "weaknesses": {"value": "KL-alignment is focused on syntactic distribution. it may not capture semantic nuances or correctness of the generated SQL, so has limits as a universal proxy. Statistical trends could be more explicit e.g., when/how often does high alignment fail to predict actual gains?. Limited discussion on how much alignment is enough for different problem scales or domains, and what to do when no dataset aligns well. Technical explanations  like calculation of features, practical computation of large n-gram sets might be too heavy for non-experts. While the approach is generalizable, the actual experiments only show text-to-SQL. extension to other structured seq2seq tasks is not explored or discussed."}, "questions": {"value": "Do you have plans or suggestions for alignment metrics that could also measure semantic or functional compatibility e.g., for queries with equivalent meaning but different syntax? How would you recommend users act when no candidate training set aligns well, is few-shot prompting viable, or is new data collection unavoidable? Can the alignment prediction/generalization story be extended to very large LLMs with more “universal” prior coverage? Did you find any real-world settings outside the chosen benchmarks where KL-alignment failed to track actual SFT performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zQcpGaggoj", "forum": "umAHLaZqTN", "replyto": "umAHLaZqTN", "signatures": ["ICLR.cc/2026/Conference/Submission13895/Reviewer_hWDs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13895/Reviewer_hWDs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950023106, "cdate": 1761950023106, "tmdate": 1762924402821, "mdate": 1762924402821, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}