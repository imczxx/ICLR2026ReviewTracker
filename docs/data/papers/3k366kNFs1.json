{"id": "3k366kNFs1", "number": 9887, "cdate": 1758146426873, "mdate": 1763101037070, "content": {"title": "Weighted Iterative Society-of-Experts for Robust Multi-Agent Debate", "abstract": "Recent large language models (LLMs) are trained on diverse corpora and tasks, leading them to develop complementary strengths. Multi-agent debate (MAD) has emerged as a popular way to leverage these strengths for robust reasoning, though it has mostly been applied to language-only tasks, leaving its efficacy on multimodal problems underexplored. In this paper, we study MAD for multimodal reasoning. Our setup enables generalizing the debate protocol with heterogeneous experts that possess single- and multi-modal capabilities. We evaluate our method on several mathematical and visual reasoning datasets. Our results show that our model consistently improves accuracy by over state-of-the-art MAD setups and aggregation methods across diverse tasks and LLM configurations.", "tldr": "A novel way to conduct multi-agent debate using ranking", "keywords": ["multi-agent debate; mathematical reasoning;"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/a19fe1007cd938adf3cab70b2c5e281d31a28559.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces WISE (Weighted Iterative Society-of-Experts), a general framework for robust multi-agent debate (MAD) applied to multimodal, multi-agent reasoning tasks involving vision-and-language. The core innovation lies in partitioning a set of heterogeneous agents (LLMs and MLLMs) into Solvers (who propose solutions) and Reflectors (who critique and weight those solutions), orchestrated by another LLM and aggregated using an adapted Dawid-Skene mechanism. WISE is evaluated empirically on several benchmarks (SMART-840, VisualPuzzles, EvoChart-QA, SMART-840++), demonstrating consistent improvements over single-model, self-reflection, and existing MAD baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The WISE framework introduces a well-reasoned partitioning of roles—Solvers and Reflectors—enabling explicit handling of model heterogeneity, including unimodal, multimodal, and various pretrained capabilities. The architecture diagram (Figure 1) clearly defines these roles, the feedback flow, and the orchestration process, thereby improving both conceptual clarity and reproducibility.\n\n2.The paper extends the Dawid-Skene method for consensus aggregation in a thoughtful manner, accounting for error patterns from both Solvers and Reflectors. The mathematical formulation is suitable for modeling joint agent errors, and the proposed weighting mechanism effectively incorporates both temporal recency (round-wise) and feedback heterogeneity.\n\n3.By releasing SMART-840++, the authors contribute a controlled-difficulty multimodal reasoning dataset, which will support more rigorous future benchmarking efforts in this area."}, "weaknesses": {"value": "1.Although the paper reviews several relevant MAD/MoA approaches, it omits direct empirical comparisons with very recent multimodal MAD frameworks.This makes the case for WISE’s significance against the immediate state of the art less decisive than it could be.\n\n2.Although the paper briefly mentions communication overhead in Section 3.2, it lacks empirical analysis or concrete figures regarding computation, token usage, and scalability as the number of agents or rounds increases. This omission raises concerns about the practical feasibility of scaling WISE, particularly for large-scale or resource-constrained applications.\n\n3.The orchestrator is critical, yet the manuscript glosses over the risk that the orchestrator's own biases, limitations, or capabilities (especially if implemented using a model less capable than the debate agents) could bottleneck performance or introduce single points of failure. There is also little analysis on orchestrator variance (e.g., prompt sensitivity or robustness)."}, "questions": {"value": "Refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wn8Ri50erh", "forum": "3k366kNFs1", "replyto": "3k366kNFs1", "signatures": ["ICLR.cc/2026/Conference/Submission9887/Reviewer_811f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9887/Reviewer_811f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9887/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761719071566, "cdate": 1761719071566, "tmdate": 1762921352269, "mdate": 1762921352269, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mT8N5weibJ", "forum": "3k366kNFs1", "replyto": "3k366kNFs1", "signatures": ["ICLR.cc/2026/Conference/Submission9887/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9887/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763101036309, "cdate": 1763101036309, "tmdate": 1763101036309, "mdate": 1763101036309, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose WISE, a multi-agent debate framework leveraging several heterogenous multimodal LLMs. The framework consists of (1) some solver models that generate solutions, (2) some reflector models that are responsible for verification and generating feedback, and (3) an orchestrator model that aggregates and summarizes all feedback to either terminate the debate or continue with the next round. Upon termination, the final answer is obtained by the Dawid–Skene algorithm that employs EM to estimate consensus. The authors conduct experiments on four datasets to show that WISE outperforms some prior single-agent and multi-agent debate frameworks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* WISE is a multi-agent framework that makes use of the diverse skills of various agents by employing them in two primary roles (solvers and verifiers) to arrive at a superior consensus.\n\n* Experiments show that a certain configuration of agents can lead to better performance on multiple benchmarks."}, "weaknesses": {"value": "* While the authors report improved performance, it is unclear whether the improvement comes from a better debate framework or from leveraging more compute from a greater number of inference calls. For example, the WISE configuration \"(G41+Ge3+S35)^2|G4o\" is not a fair comparison with the Reconcile configuration \"G41 + Ge3 + S35\" when the latter in each round only uses these agents for solving and there's also no G4o orchestrator. Thus it is desirable to compare WISE to baselines in compute-matched settings e.g., by matching the number of tokens generated or inference calls, etc.\n\n* A common limitation of these kinds of debate frameworks is knowing which agents to involve in the process. Based on Table 4, a different configuration of agents leads to much lower performance (which is expected if some agents are weaker). Thus, in the absence of any principled mechanism of choosing models from a large pool, it is hard to conclude if the framework will generalize with any configuration of agents. \n\n* The novelty of this paper is also limited given that many such debate frameworks have been proposed in the past. The key contribution here seems to be applying a variant of such frameworks for multimodal tasks."}, "questions": {"value": "* Since one of the motivations of the work is to leverage diverse strengths of models, given an arbitrary task, how does one know which models indeed have diverse strengths and can be involved in this debate framework? Relatedly, what happens if some agents are significantly weaker than other agents? Can they derail the debate process?\n\n* Can you compare WISE to baselines in compute-matched settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "u6AeJlaGQy", "forum": "3k366kNFs1", "replyto": "3k366kNFs1", "signatures": ["ICLR.cc/2026/Conference/Submission9887/Reviewer_VWRU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9887/Reviewer_VWRU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9887/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762230157900, "cdate": 1762230157900, "tmdate": 1762921351820, "mdate": 1762921351820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes WISE (Weighted Iterative Society-of-Experts), a multi-agent debate (MAD) framework for multimodal reasoning. WISE partitions heterogeneous agents into Solvers (produce solutions) and Reflectors (verify, weight, and give feedback), coordinates them with an orchestrator, and aggregates solutions using a modified Dawid–Skene post-processing step. The authors evaluate on SMART-840, VisualPuzzles, EvoChart-QA, and introduce SMART-840++ with programmatically varied instances. They report consistent gains of roughly 2–7% over prior MAD/aggregation baselines across datasets and configurations, and argue that language-only reflectors can still help multimodal solvers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Splitting agents into Solvers vs. Reflectors is a clean abstraction that reduces quadratic message complexity and lets different capabilities be used where they fit best.\n\n+ Extending Dawid–Skene to jointly model solver/reflector error provides a more grounded alternative to majority/weighted voting, with empirical improvements over crowd-label baselines.\n\n+ Results on three VL benchmarks plus the SMART-840++ variant (harder, procedurally varied puzzles) give a wider view than standard single-set reports; tables/figures show consistent but modest gains."}, "weaknesses": {"value": "- The framework is largely modality-agnostic; the paper does not isolate what is specifically gained for vision-language vs. text-only settings beyond reporting accuracy splits. Stronger analyses (e.g., image-dependent failure modes, ablations where images are scrambled/removed) are needed to justify the multimodal focus.\n\n- Multi-round debate with multiple agents and long explanations can be expensive; the paper acknowledges message volume but lacks a concrete cost/performance trade-off (tokens, latency, $) and budgeted settings (e.g., fixed token caps per query)\n\n- Improvements may conflate better reranking/aggregation with actual reasoning gains. There’s no controlled analysis of confounders (e.g., chain length, difficulty, solver vs. reflector strength, or sensitivity to orchestrator choices). The DS extension is evaluated end-to-end, but ablations that fix the debate and swap only the aggregator—or vice versa—are minimal."}, "questions": {"value": "As in weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7rYHeXCFT2", "forum": "3k366kNFs1", "replyto": "3k366kNFs1", "signatures": ["ICLR.cc/2026/Conference/Submission9887/Reviewer_jgii"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9887/Reviewer_jgii"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9887/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762361467552, "cdate": 1762361467552, "tmdate": 1762921351390, "mdate": 1762921351390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies multi-agent debate (MAD) for vision-and-language mathematical reasoning with heterogeneous LLM / MLLM experts. It introduces \\textbf{WISE} (Weighted Iterative Society-of-Experts), a MAD framework that splits agents into two roles: Solvers and Reflectors, coordinated by an orchestrator. A probabilistic aggregation method \\textbf{WISE-DS} extends Dawid--Skene to jointly model solver answers and reflector reliability via EM. Experiments on SMART-840, VisualPuzzles, EvoChart-QA, and SMART-840++ show consistent 2--7\\% gains over strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Well-motivated problem. Clean role split improves MAD engineering clarity. DS-style aggregation is principled. Gains are consistent across datasets. SMART-840++ is a useful asset. This aligns with the trend toward mixture-of-agents and model orchestration."}, "weaknesses": {"value": "Limited analysis of DS assumption violations and no uncertainty estimates. Limited ablations on aggregators. Generalization beyond benchmarks is not demonstrated. Implementation / prompt details not centralized. No compute or cost breakdowns."}, "questions": {"value": "1.\\ sensitivity of WISE--DS to DS independence violations.\\\\\n2.\\ comparison to a simple learned aggregator.\\\\\n3.\\ exact mapping of negative / missing reflector weights in DS.\\\\\n4.\\ transfer to larger real-world multimodal tasks.\\\\\n5.\\ cost vs accuracy tradeoff.\\\\\n6.\\ SMART-840++ generation details and coverage balance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ifqeCKvH9U", "forum": "3k366kNFs1", "replyto": "3k366kNFs1", "signatures": ["ICLR.cc/2026/Conference/Submission9887/Reviewer_qmsE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9887/Reviewer_qmsE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9887/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762405476457, "cdate": 1762405476457, "tmdate": 1762921351119, "mdate": 1762921351119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}