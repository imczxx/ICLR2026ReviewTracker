{"id": "wM3Mdk2Pa5", "number": 18113, "cdate": 1758284003211, "mdate": 1759897132704, "content": {"title": "Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall", "abstract": "Discrete diffusion models offer a promising alternative to autoregressive generation through parallel decoding, but they suffer from a sampling wall: once categorical sampling occurs, rich distributional information collapses into one-hot vectors and cannot be propagated across steps. We introduce Loopholing, a mechanism that preserves this information via a deterministic latent pathway, leading to Loopholing Discrete Diffusion Models (LDDMs). Trained efficiently with a self-conditioning strategy, LDDMs achieve substantial gains—reducing generative perplexity by up to 61\\% over prior baselines, closing (and in some cases surpassing) the gap with autoregressive models, and producing more coherent text. Applied to reasoning tasks, LDDMs also improve performance on arithmetic benchmarks such as Countdown and Game of 24. These results also indicates that loopholing mitigates idle steps and oscillations, providing a scalable path toward high-quality non-autoregressive text generation.", "tldr": "", "keywords": ["Discrete Diffusion", "Generative Models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e42b1356b4f29e081cbd558b7bf1970b0c12de8f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper identifies a key limitation in discrete diffusion models, which the authors term the sampling wall. This refers to the information collapse that occurs when the rich, continuous categorical distributions predicted by the model are sampled, reducing them to one-hot vectors for the next denoising step. The authors hypothesize that this loss of distributional information is a root cause of known inefficiencies in discrete diffusion, such as \"idle steps\" and \"excessive oscillation\" .To address this, the paper introduces Loopholing, a mechanism that creates a deterministic latent pathway to complement the standard stochastic sampling path. The resulting models, Loopholing Discrete Diffusion Models (LDDMs), are evaluated on language modeling and arithmetic reasoning. Experiments show that LDDMs significantly improve upon baseline models, achieving up to a 61% reduction in PPL. It also improves performance on reasoning tasks like Countdown and Game of 24."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "a. The proposed Loopholing mechanism is a simple and logical solution to the stated problem. Propagating the continuous latent state $h_s$ is a direct way to preserve information, and the architectural modification is relatively minor but highly effective.\n\nb. The authors successfully apply Loopholing to two different families of diffusion models (Masked Diffusion and Uniform Diffusion) and two different domains (open-ended language modeling and structured arithmetic reasoning ). This suggests that Loopholing is a general and widely applicable technique.\n\nc. The analysis of Temporal KL (TKL) and Token-Prediction Entropy (TPE) in Figure 5 compellingly supports the hypothesis that Loopholing mitigates oscillations and idle steps.\n\nd. Loopholling mechanism surpass of its discrete diffusion backbone even under the same computing budget."}, "weaknesses": {"value": "a. While the results are excellent at this scale, it remains an open question whether these substantial relative gains will persist with much larger models.\n\nb. The paper notes that an attempt to apply Loopholing only during fine-tuning was unsuccessful. This limits the capability to improve existing diffusion models. Is it possible to continue pre-train with an existing diffusion model with the loopholing mechanism?\n\nc. Loopholing yields strong improvements for MDLM but marginal gains for UDLM (Table 2), except on PTB. The authors attribute this to domain shift sensitivity in UDLM perplexity, but this undermines the generality of the proposed mechanism. Are there any other metrics can be used to evaluate the performance?"}, "questions": {"value": "The paper modified the TopK decoding of MGDM to only apply to masked tokens. However, Table 4 in the appendix shows that the original MGDM decoding actually performs better for both the baseline and LDDM-G. Why does this approach that ‘conflicts with the training objective’ achieve higher performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pqL9T2S5e6", "forum": "wM3Mdk2Pa5", "replyto": "wM3Mdk2Pa5", "signatures": ["ICLR.cc/2026/Conference/Submission18113/Reviewer_Sjct"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18113/Reviewer_Sjct"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813591219, "cdate": 1761813591219, "tmdate": 1762927881057, "mdate": 1762927881057, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper shows strong improvements in generation and reasoning accuracy of discrete diffusion models by allowing each diffusion step to condition on the pre-logit hidden states of the previous step.  This avoids the problem of losing information in the discrete sampling step, despite the fact that these hidden states are not trained for this purpose.\n\nThis problem is fundamentally the same as the problem with backprop across a discrete sampling step, and the intuition for solving it is essentially the same as the intuition behind Gumbel softmax (i.e. mixing the complete predicted distribution with the sampled one).  But the authors identify the forward direction of this problem as a separate issue independent of the backward direction, and demonstrate its importance for diffusion models.  They also propose a practical architecture which implements this intuition in an efficient way, by conditioning on the pre-logit hidden states (mixing these pre-sampling embeddings with the embeddings from the sampled tokens) and not backproping error across this conditioning."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The model and its motivation are well explained.  The empirical results are strong, thorough and convincing, and include the obvious ablations.\n\nUsing diffusion for non-autoregressive generation of text is an important open problem, and this paper demonstrates a method for closing the gap in accuracy with auto-regressive models.  It also shows how iterative methods such as this can improve reasoning ability."}, "weaknesses": {"value": "Identifying the problem of passing information forward across discrete sampling steps is not as novel as they claim, since it just the forward perspective on the well-known problems with backprop across a discrete sampling step.  But the method for addressing this intuition is novel, and it is novel to show that it applies even when the model has no backprop across this step.  It would have been interesting to see how this compares to a model which does backprop across this step, but this is mentioned as future work.\n\nEquation (2) is confusing because it uses the same variables to sometimes refer to the entire sequence and sometimes refer to individual tokens within the sequence.  I think it would be clearer to add explicit token indexes where appropriate.\n\nI wasn't convinced by the discussion of Idle Steps, since the graphs are averages and thus do not show whether individual paths have idle steps.\n\nFor the claim in lines 360-361, please mention which graph backs up this claim."}, "questions": {"value": "Please explain if I have misunderstood the argument about Idle Steps and Excessive Oscillation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hLjb91m45u", "forum": "wM3Mdk2Pa5", "replyto": "wM3Mdk2Pa5", "signatures": ["ICLR.cc/2026/Conference/Submission18113/Reviewer_2QKi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18113/Reviewer_2QKi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012494879, "cdate": 1762012494879, "tmdate": 1762927880408, "mdate": 1762927880408, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Loopholing Discrete Diffusion Models (LDDMs), which modify discrete diffusion LMs by adding a deterministic latent pathway (h_t) that is passed between denoising steps, in addition to the standard sampled token outputs. The idea is to “bypass the sampling wall,” defined as loss of distributional information once you collapse logits into a one-hot token during sampling. The paper also proposes a two-pass self-conditioning scheme to train this recurrent latent path without having to unroll time.\nThe authors claim:\n\nlower perplexity than prior discrete diffusion baselines such as MDLM and UDLM on LM1B and OpenWebText,\n\nlower “generative perplexity” (measured by GPT-2) and higher GPT-4.1 “consistency”/“naturalness” scores for unconditional generations,\n\nand improved success rates on small arithmetic reasoning tasks like Countdown and Game of 24 when applied to MGDM."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* The paper articulates a clear failure mode of discrete diffusion LMs: once you sample a discrete token, you throw away the richer distributional state and force the next step to start from a one-hot. They call this the “sampling wall.” \n\n* The proposed “loopholing” mechanism - passing a continuous latent h_t forward alongside the sampled token sequence — is architecturally straightforward and appealing for implementation. \n\n* LDDM-M beats MDLM on perplexity on LM1B and OWT (e.g. ≤25.95 vs ≤27.60 on LM1B; ≤21.90 vs ≤23.05 on OWT). \n* On unconditional generation, “Gen PPL” improves a lot (e.g. 49.13 vs 108.94) and GPT-4.1 gives higher fluency/consistency scores. \n* On arithmetic reasoning puzzles, LDDM-G improves success rates vs MGDM (e.g. Countdown4: 86.5→94.4% at 85M params)."}, "weaknesses": {"value": "* Evaluation is narrow and relies only on perplexity metric.\nThe paper repeatedly claims “closing the autoregressive gap,” but this is based entirely on approximate perplexity (NELBO upper bounds) rather than true log-likelihood or downstream task performance.\nThere is no evaluation on actual generative tasks such as summarization, dialogue, open-ended story writing, or reasoning. Consequently, we cannot conclude that the method improves generation quality. It is important to evaluate the models on actual dowsntream performances, some of the current widely used benchmakrs for evaluation of the large scale language models are summarization tasks, MMLU, MMLU-Pro, Math-500, GSM8k, and reasoning benchmarks, and code benchmarks like Humaneval, MBPP, ... \n \n* Limited novelty beyond standard self-conditioning.\nThe proposed “loopholing” mechanism - passing a continuous latent state between denoising steps trained via a two-pass stop-gradient trick — is almost identical to self-conditioning already used in diffusion and consistency models (e.g. Jabri et al., 2022; Chen et al., 2022).\nThe only real difference is that LDDM explicitly names and propagates a latent vector rather than the previous clean prediction. This is a minor architectural variant, not a new principle.\n\n* The “sampling wall” is largely a renamed version of known problems.\nWhat the paper calls the “sampling wall” (loss of information when discretizing predictions) is conceptually the same as the “idle steps” and “oscillation” problems already identified in earlier discrete diffusion work (e.g., MDLM, SSD-LM).\nThe paper renames these issues and overstates their novelty, without providing direct causal evidence that loopholing specifically resolves them.\n\n* Causal explanation lacks experimental proof.\nThe claim that the propagated latent  “bypasses” the sampling wall is asserted, not demonstrated.\nThere is no ablation isolating: the effect of the latent path from the effect of self-conditioning, or the effect of feeding forward x_{theta, t} versus h_t\n\t​\n* The observed differences could easily stem from generic stabilization due to the two-pass stop-gradient process.\n\n* Weak baseline fairness and inherited limitations from MDLM.\nLDDM inherits MDLM’s fairness issues:\nPerplexity is computed as an upper bound, which is not directly comparable to autoregressive likelihoods.\n\n\n* Trivial or overly simple benchmarks.\nLanguage modeling experiments are limited to LM1B and OpenWebText at relatively small scale.\nThe “reasoning” benchmarks (Countdown, Game of 24) involve symbolic arithmetic and tiny vocabularies.\nThese tasks do not capture the complexities of realistic generation (e.g., global coherence, factual reasoning, long context).\nThe method is not tested on any challenging downstream generation benchmarks (summarization, QA, GSM8K, MATH, etc.).\n\n* Efficiency and compute cost not substantiated.\nThe paper claims fewer idle steps and higher efficiency, but provides no wall-clock, FLOP, or token-throughput comparisons to MDLM or UDLM.\nTraining is actually ~30% slower due to doubled embeddings and latent propagation overhead.\nThere is no evidence that LDDM improves quality per unit of compute."}, "questions": {"value": "* Novelty vs self-conditioning: How does loopholing differ from existing self-conditioning techniques beyond storing an explicit latent ?\n* Please include an ablation where standard self-conditioning is applied to MDLM without your recurrent latent path, to show what the new component adds.\n\n* Isolation of latent path effect:\nCan you run controlled ablations for:\n(a) no recurrent latent but with self-conditioning;\n(b) recurrent latent but single-pass training;\n(c) caching and reusing previous x_{\\theta, t} instead of h_t? \n\t​This would clarify which mechanism drives the improvements.\n\n* Task breadth: \nThe current benchmarks (LM1B, OWT, Countdown, Game of 24) are short and low-complexity.\nCan you evaluate on actual generation tasks such as summarization (CNN/DailyMail, XSum), long-form reasoning (GSM8K, MATH), or instruction-following datasets?\nWithout these, it’s unclear if LDDM meaningfully improves text generation quality.\n\n* Perplexity vs real performance:\nSince the evaluation focuses on approximate NELBO perplexity and GPT-based metrics, can you show concrete qualitative examples or human evaluations demonstrating that loopholing produces better text (fluency, coherence, factuality) than MDLM or AR baselines?\n\n* Efficiency claim:\nCan you provide real compute metrics (tokens/sec, FLOPs/sample, latency for 1k tokens) to support the “higher efficiency” claim?\nDoes LDDM actually require fewer diffusion steps at equivalent output quality?\n\n* Baseline fairness:\nAre the MDLM and AR baselines trained with equal data, compute, and precision settings?\nHow sensitive are the reported improvements to these factors?\n\n* Robustness of evaluation modifications:\nFor MGDM, your evaluation differs from Ye et al. (2024). Can you report results under the original evaluation scheme for transparency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rGOgD3dAJu", "forum": "wM3Mdk2Pa5", "replyto": "wM3Mdk2Pa5", "signatures": ["ICLR.cc/2026/Conference/Submission18113/Reviewer_dHL3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18113/Reviewer_dHL3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762088212952, "cdate": 1762088212952, "tmdate": 1762927879959, "mdate": 1762927879959, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel mechanism, \"Loopholing,\" to address the critical \"sampling wall\" limitation in Discrete Diffusion Models (DDMs). The core idea is to bypass the loss of information incurred by categorical sampling by introducing a deterministic latent pathway that preserves rich distributional information across diffusion steps."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* The paper articulates a clear failure mode of discrete diffusion LMs: once you sample a discrete token, you throw away the richer distributional state and force the next step to start from a one-hot. They call this the “sampling wall.” \n\n* The proposed “loopholing” mechanism - passing a continuous latent h_t forward alongside the sampled token sequence - is architecturally straightforward and simple for implementation. \n\n* The paper includes experimental results on LDDM-M beats MDLM on perplexity on LM1B and OWT and on arithmetic reasoning puzzles"}, "weaknesses": {"value": "- Looking into samples in appendix, I have a huge concerns on how strong or properly tuned the baselines and the proposed method are. The shared samples from baseline and approach are absolutely not coherent text.\n\n- Evaluation is narrow and relies only on perplexity metric. This is not necessarily showing a high quality generated text. For instance, repeated phrases can give artificially low perplexity. The generated text needs to be compared in various quality metric measuring the actual quality of generated text. Some import metrics are: \n   1) Evaluating diversity using metrics such as  distant unigrams (D-1) and diverse 4-grams (D-4) (Deshpande et al., 2018). \n   2) BERTScore (Zhang et al., 2020) \n   3) In terms of textual coherence, authors can also sample some text and use LLM as judge to measure coherency \n\nDiversity is specially very important to measure as there are possible risk of mode collapose, which is important to measure.\n\n- There is no evaluation on actual downstream generative tasks such as summarization, reasoning, paraphrase generations, text simplifications, .... Consequently, we cannot conclude that the method improves generation quality. Additionally, the used benchmarks are rather simple benchmarks.  Language modeling experiments are limited to LM1B and OpenWebText at relatively small scale. These tasks do not capture the complexities of realistic generation (e.g., global coherence, factual reasoning, long context). It is important to evaluate the models on actual dowsntream performances, some of the current widely used benchmakrs for evaluation of the large scale language models are summarization tasks, MMLU, MMLU-Pro, Math-500, GSM8k, and reasoning benchmarks, and code benchmarks like Humaneval, MBPP, ... \n \n \n- The authors need to compare with SOTA autoregressive models in all experimental results tables. \n\n- Limited novelty beyond standard self-conditioning.\nThe proposed “loopholing” mechanism is almost identical to self-conditioning already used in various prior diffusion models, which does not look to be novel. Additionally, there is no ablation on how much this approachs adds on top of self-conditioning. Could you add baseline + self-conditioning in all table of results as the relevant baseline. This helps to understand benefits from the proposed method.\n\n- The paper claims higher efficiency, but provides no wall-clock, FLOP measurements. It is important to provide the measurements."}, "questions": {"value": "-  Novelty vs self-conditioning: How does loopholing differ from existing self-conditioning techniques?\nPlease include additional baseline where standard self-conditioning is applied to baselines without your recurrent latent path, to show what the new component adds.\n\n\n- The current benchmarks (LM1B, OWT, Countdown, Game of 24) are short and low-complexity.\nCan you evaluate on actual generation tasks such as summarization (CNN/DailyMail, XSum), long-form reasoning, code generation, etc and measure the actual downstream performances? This can show if the generations are of good quality able to solve downstream tasks and perpelexity cannot measure this. Without these, it’s unclear if approach meaningfully improves text generation quality.\n\n- Could you provide comparisons with SOTA autoregressive models? \n\n- Can you provide real compute metrics (tokens/sec, FLOPs) to support the “higher efficiency” claim?\n\n- Could you provide metrics measuring diversity of the generated text such as D-1/D-4 and also BERTScore? \n\n- Why generated samples in the appendix are rather poor?  my suggestion is to use stronger base models ensuring generation of coherent text."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rGOgD3dAJu", "forum": "wM3Mdk2Pa5", "replyto": "wM3Mdk2Pa5", "signatures": ["ICLR.cc/2026/Conference/Submission18113/Reviewer_dHL3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18113/Reviewer_dHL3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762088212952, "cdate": 1762088212952, "tmdate": 1763639030412, "mdate": 1763639030412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}