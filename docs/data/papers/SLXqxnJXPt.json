{"id": "SLXqxnJXPt", "number": 21748, "cdate": 1758321212165, "mdate": 1759896905206, "content": {"title": "Some Robustness Properties of Label Cleaning", "abstract": "We demonstrate that learning procedures that rely on aggregated labels, e.g., label information distilled from noisy responses, enjoy robustness properties impossible without data cleaning. This robustness appears in several ways. In the context of risk consistency---when one takes the standard approach in machine learning of minimizing a surrogate (typically convex) loss in place of a desired task loss (such as the zero-one mis-classification error)---procedures using label aggregation obtain stronger consistency guarantees than those even possible using raw labels. And while classical statistical scenarios of fitting perfectly-specified models suggest that incorporating all possible information---modeling uncertainty in labels---is statistically efficient, consistency fails for ``standard'' approaches as soon as a loss to be minimized is even slightly mis-specified. Yet procedures leveraging aggregated information still converge to optimal classifiers, highlighting how incorporating a fuller view of the data analysis pipeline, from collection to model-fitting to prediction time, can yield a more robust methodology by refining noisy signals.", "tldr": "", "keywords": ["Label aggregation", "surrogate consistency", "robustness"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/84ca3d697c43969c435d6f4141442d1ce4e3d2df.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The work takes a deeper analysis on the robustness of surrogate losses using label aggregation like majority voting. The paper argues that aggregating multiple noisy labels before training yields robustness and consistency guarantees that we cannot achieve when learning directly from single raw labels. It shows several simple examples from ranking to multi-class classification to support the theoretical results presented. The paper, rich in analysis, does not present any empirical evidence connecting to the practicality of the observations. Some simple demonstrations could have been added to support the theoretical results."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "Strengths:\n\n1.\tThe paper takes a deep statistical learning theoretic approach to the label denoising task, substantiating many empirical successes of the label aggregation algorithms such as majority voting. \n\n2.\tThe analysis such as used in ranking could be beneficial to drive more in-depth look in how this may be useful in current popular frameworks such as RLHF."}, "weaknesses": {"value": "See Questions section."}, "questions": {"value": "1.\tThe organization of the paper needs quite a bit of improvement. The logical flow is missing in several places where discussion is jumping from one example to another, like starting with ranking to then switching classification etc without providing the reasoning of the shift.\n\n2.\tThe paper attempts to investigate “robustness” of label cleaning. Robustness can have many interpretations and definitions in learning. There is alack of clarity in what sort of robustness the authors are investigating. Is it task-specific or model-specific?\n\n3.\tThe introduction section talks about comparing label cleaning and aggregation, but in my opinion, the discussions are bit opaque in describing the setup whether the context is with using crowdsourced labels/multiple labels. \n\n4.\tAfter Corrollary 3, the discussion is around whether using paired observations (X,Y) or tuples with multiple labels for Fisher consistency. However, the analysis in section 3 does not reveal any such comparison. It is unclear why “using only paired observations (X, Y ) rather than tuples (X, Y1, . . . , Ym), we could bring the entire theory of empirical processes and related statistical tools”. For example, the works in [1] has presented some analysis using such noisy tuples establishing statistical consistency and error bounds. So, it is unclear what are specific analytical challenges here?\n\n[1] Ibrahim, Shahana, Tri Nguyen, and Xiao Fu. \"Deep learning from crowdsourced labels: Coupled cross-entropy minimization, identifiability, and regularization, ICLR 2023.\n\n5.\tIt is not clear what is “*” after Proposition 1 in Section 3.1. What is the implication of Proposition 1 and 2? Why Proposition 2 considers only a certain definition of the surrogate loss? Why this observation (fisher consistency failure without label aggregation) happens for ranking, but not in classification? Alos, this results shows convex surrogate losses, so how does this result impact/inform the practically used surrogate losses, which need not be convex?\n\n6.\tExample 3 looks trivial, as the Definition 3.1 is based on label aggregation. Does the example cover the multiple label case as well?\n\n7.\tThe asymptotic analysis with m going to infinity is a bit impractical assumption. Most asymptotic analysis in the existing studies looks at number of observations is going to be infinite. I see the discussion in the last part of the paper acknowledges this to some extent. But there is lack of clarity in the nature of asymptotic analysis used here. Does that mean repeatedly sampling infinitely for observations or unique labelers (as in crowdsourcing scenario)? \n\n8.\tIn Eq. (8), y^* is not defined.\n\n9.\tIn section 4.1, optimal linear predictors are analyzed. How does the label noise rate in fact affect this analysis? The definition of optimality is a bit unclear in this section? Does this change with level of label noise?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "TEwBDOWBDL", "forum": "SLXqxnJXPt", "replyto": "SLXqxnJXPt", "signatures": ["ICLR.cc/2026/Conference/Submission21748/Reviewer_xdn5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21748/Reviewer_xdn5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947886055, "cdate": 1761947886055, "tmdate": 1762941917196, "mdate": 1762941917196, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the theoretical “robustness” properties of label aggregation, arguing that combining multiple noisy labels via averaging or majority voting can enhance surrogate risk consistency and yield more robust classifiers. The authors formalize this through a series of asymptotic results involving Fisher consistency, identifying surrogates, and consistency.\n\nWhile the general theme of robust learning under noisy supervision is relevant, the paper contributes little new theoretical insight. The results largely restate well-known intuitions that aggregating noisy labels reduces variance and improves consistency without offering novel analysis, quantitative bounds, or practical implications. The exposition is heavy and unfocused, and the theory remains purely asymptotic and disconnected from realistic labeling scenarios. Overall, the work is technically shallow, poorly motivated, and lacks both novelty and practical significance. I recommend rejection."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses a broadly relevant theme: robustness under label noise.\n- Connects to known frameworks on surrogate risk consistency (e.g., Bartlett & Jordan, Steinwart).\n- Includes some formal statements and asymptotic guarantees."}, "weaknesses": {"value": "- The idea that aggregating noisy labels (where noise rate is not dominant) improves robustness is self-evident and already well known. Most theorems are restatements of standard asymptotic arguments; if you average away noise, you approach the Bayes optimal predictor. \n- Lack of practical or scientific significance. Most results assume the number of labels per example $m\\rightarrow \\infty$, which is unrealistic. No finite-m or sample-complexity analysis is provided. The setting is detached from any real-world labeling scenario.\n- Poor exposition and organization. The writing is unclear, repetitive, and full of unnecessary formalism. The narrative is disjointed, making it difficult to follow the motivation or intuition. It often reads as though auto-generated or assembled from prior papers rather than written coherently.\n- No empirical or illustrative evidence. Despite focusing on robustness, the paper provides no empirical demonstrations or even synthetic experiments to illustrate its claims. The absence of finite-sample evidence severely undermines the credibility and practical impact of the theoretical results."}, "questions": {"value": "- Can the authors provide any finite-m characterization of when aggregation actually helps?\n- Is there any empirical evidence that the derived asymptotic trends manifest in realistic datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "wJHPpmcZVf", "forum": "SLXqxnJXPt", "replyto": "SLXqxnJXPt", "signatures": ["ICLR.cc/2026/Conference/Submission21748/Reviewer_SAh9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21748/Reviewer_SAh9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962597319, "cdate": 1761962597319, "tmdate": 1762941916947, "mdate": 1762941916947, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the theoretical benefits of label aggregation (e.g., majority voting over multiple noisy labels) for supervised learning. The authors argue that data cleaning—far from being merely a preprocessing step—fundamentally enhances surrogate consistency and robustness in ways that are impossible with single noisy labels."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The work shows situations where no convex surrogate is Fisher-consistent without aggregation. These results are compelling and motivate aggregation theory.\n- The logistic-regression example is striking: m-majority vote converges to the true direction with mis-specified link, while raw labels fail—even under tiny label corruption.\n- The paper contextualizes within seminal work (Bartlett et al., Steinwart, Tsybakov), providing a credible extension."}, "weaknesses": {"value": "- Given the theoretical nature this is understandable, but even small-scale simulations (ranking / multiclass) would aid intuition.\n- Majority vote is treated as the canonical aggregator. Extending beyond simple voting would broaden impact."}, "questions": {"value": "The conditions (e.g., identifying surrogate, noise functions, κ(x)) are mathematically elegant but not intuitive for practitioners."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pKSHHChgpk", "forum": "SLXqxnJXPt", "replyto": "SLXqxnJXPt", "signatures": ["ICLR.cc/2026/Conference/Submission21748/Reviewer_x3t4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21748/Reviewer_x3t4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010053290, "cdate": 1762010053290, "tmdate": 1762941916713, "mdate": 1762941916713, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the robustness of learning with aggregated labels (e.g., majority vote) and establishes that label aggregation provides stronger surrogate risk consistency than using raw noisy labels. The authors show that standard Fisher consistency can fail in tasks like ranking or multiclass classification, but aggregation can “upgrade” inconsistent surrogates into consistent ones. They prove new theoretical results demonstrating consistency amplification and robustness, even for finite-dimensional or slightly mis-specified models. Overall, the work reframes label cleaning as a theoretically grounded robustness mechanism rather than a heuristic preprocessing step, supported by rigorous analysis and general theorems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper offers rigorous extensions of surrogate risk consistency theory, introducing new definitions (e.g., identifying surrogates) and proving nontrivial consistency amplification results.\n\nBy interpreting label cleaning as a theoretical mechanism for robustness, the paper bridges practical data processing (e.g., crowdsourcing denoising) and formal consistency theory.\n\nThe framing of label aggregation as robustness enhancement, rather than a heuristic data cleaning step, is compelling and original."}, "weaknesses": {"value": "The paper is entirely theoretical; it would benefit from even minimal empirical demonstrations or synthetic experiments showing how label aggregation improves performance in practice.\n\nThe mathematical exposition is dense and heavily notation-driven. The core intuition, why aggregation improves consistency, could be explained more visually or intuitively.\n\nThe theory focuses primarily on convex surrogates and majority-vote-like aggregations; it is unclear how well results generalize to modern deep-learning setups or non-convex training objectives.\n\nThe connection to real-world label noise processes (e.g., annotator bias, adversarial noise) could be more concretely illustrated."}, "questions": {"value": "Can the authors provide empirical verification (e.g., on crowdsourced or noisy benchmark datasets) to support their theoretical robustness claims?\n\nAre there settings where aggregation could harm performance—for example, when label noise is adversarial or when aggregation over-smooths minority-label signals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pEMzVd06R2", "forum": "SLXqxnJXPt", "replyto": "SLXqxnJXPt", "signatures": ["ICLR.cc/2026/Conference/Submission21748/Reviewer_nKCk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21748/Reviewer_nKCk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762125223395, "cdate": 1762125223395, "tmdate": 1762941916482, "mdate": 1762941916482, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}