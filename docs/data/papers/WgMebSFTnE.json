{"id": "WgMebSFTnE", "number": 20252, "cdate": 1758304178629, "mdate": 1759896988331, "content": {"title": "Automating Meta-learning by Learning to Map Task Distributions to Initial Weights", "abstract": "Meta-learning recovers the Bayes-optimal learner for a particular distribution over tasks. However, meta-learning is slow and requires retraining from scratch if we want to modify the environment. In our work, we directly learn a mapping from a task distribution to the Bayes-optimal parameters of the learner (for a neural network, these are the initial weights of the network). We provide theoretical results characterizing the optimal mapping in the case of linear-Gaussian models and then demonstrate that hypernetworks can be used to learn this mapping from empirical data for both linear and non-linear models.  This approach reduces the computational resources required to make adaptive Bayes-optimal learners: by leveraging the underlying structure of  task distributions, we can meta-learn once and then quickly adapt to new settings with a single forward pass through the learned mapping.", "tldr": "We propose a hypernetwork-based approach to meta-learning that learns to map from task distributions directly to initial weights.", "keywords": ["meta-learning", "hypernetworks"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3295fcd939fa5b3d57865cbeeaf0e1a74a160cca.pdf", "supplementary_material": "/attachment/932e44289ae05dfb3ce68f8528193f2ad00ed7bd.zip"}, "replies": [{"content": {"summary": {"value": "The submission proposes to automatize the process of MAML-style meta-learning by learning a mapping from task environment parameters to initial model weights. Formal derivations are presented in a hierarchical Bayesian form where meta-learning happens by marginal likelihood maximization. This is illustrated by the case of Bayesian linear regression, where analytic expressions emerge. In a second, somewhat disconnected part, a hypernetwork-based approach is proposed, namely to directly train a hypernetwork is trained to predict adapted model initializations from task environment parameters. Illustrative experiments are provided with Gaussian distributions in $\\mathbb{R}^2$."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ the problem setting of automatizing meta-learning is new\n+ the provided derivations seems correct (up to a lack of clarity, see below)"}, "weaknesses": {"value": "Unfortunately, there submission has a number of shortcomings.\n\n*Motivation*\n\nThe work aims automatizing the process of meta-learning: given many \nrelated meta-learning problems with parametric descriptions, it \nlearns a hypernetwork to perform the model adaptation instead of \nhaving to do it numerically. \nHowever, I see no real-world scenario where this problem would occur:\nwhile single task environments can occur, e.g. a distribution over \nusers of an online platform, I cannot imagine a case where many \nrelated such environments would be available for a training step, \nand where each environment would have a known parameter vector,\nexcept in simulations. \n\n*Clarity of presentation*\n\nThe manuscript has two largely independent parts, the Bayesian \nderivation of Section 3.1/3.2 and the Hypernetwork-based approach\nin Section 3.3\n\n1) Currently, the Bayesian formulation lacks clarity, presumably because \nsome key aspects are not explained well enough. \n\n+ the role of $x$: in (3), it appears that all tasks share the same marginal \n$p(x)$ and only differ in their conditional $p(y|x)$. That feels like an \nstrong but unrealistic condition that is not explained. In (4)/(5), \nX does not appear anymore. It has proably not been marginalized out,\nbecause $y$ depends on it, so should I read the expressions as implicitly \nconditioned on (or a function of) $x$? \n\n+ the dependence of $Y$ on $\\Phi$/$X$: (6) allows a nonlinear feature \nmap for the target function $f_w$. (7) assume the predictive distribution \nto be Gaussian centered at a $X\\theta$, so $Y$'s dependence on $X$ is \nonce nonlinear and once linear. Of course, there are different other \nquantities involved, but the description left me puzzled about the \nintuition of this construction.\n\nA minor issue: $\\mathbf{y}$ initially denotes a single output, but later it is used as a vector of outputs. \nFor $\\mathbf{x}$, a different convention ($x_i$, $X$ is used).\n \nUnfortunately, I did not find the three provided references helpful to \njustify or clarify the marginal likelihood setup, as they cover quite \ndifferent topics. \n\n\n2) the hypernetwork aspect is quite short and detached from the \nBayesian part. The objective (14) is simply minimizing the Eucidean\ndistance between model output and target, which does not need a \nBayesian derivation. The argument \"Reptile can be viewed as approximately \nmaximizing marginal likelihood\" is also not very powerful. \n\nIn fact, I would appreciate a more precise formulation the procedure, e.g. in form of pseudocode, given that plugging (13) into the expression for $\\hat\\theta$ (line 262) and inserting it into (14) trivialized the expression. \nTherefore, something else must go on, such as the arrow in (13) indicating that $\\theta_0$ should be treated as constant and not as a function of the hypernetwork. This should be clarified.\n\n\n*Scientific contribution*\n\nI find the scientific contribution quite limited. The merits of meta-learning \nwith a marginal likelihood objective is not clear to me, yet, please see my \nquestions below. The subsequent analysis of the Bayesian linear regression \nsetting contains little useful insight for me, it feels more like an exercise\nin Bayesian inference with Gaussians. \nThe hypernetwork part suggests a straight-forward way to train a hypernetwork \nsuch that it predicts one vector (the result of reptile) from another vector \n(the task parameters). This makes sense in this setup, but I do not consider \nit a major conceptual contribution. \n\n\n*Experimental evaluation*\n\nThe experimental evaluation did not convince me. The setup is highly artificial,\nusing two-dimensional Gaussian data. The first experiments just confirms that the \nanalytics expression are correct. The other experiments trains a very small \nnetwork, still in the linear 2D Gaussian setup. The results Table 3 reports \none numeric experiments (measured in two ways), without error bars or test of \nstatistical significance."}, "questions": {"value": "* please clarify the notation in the marginal likelihood setup\n\n* what are real-world scenario in which many meta-learning tasks need \n  to be solved, and parameter vectors are available as hypernetwork \n  inputs?\n  \nPlease keep your answers short and scientific, then I will be happy to \nengage in a discussion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "La8wtJI9Jr", "forum": "WgMebSFTnE", "replyto": "WgMebSFTnE", "signatures": ["ICLR.cc/2026/Conference/Submission20252/Reviewer_3kEY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20252/Reviewer_3kEY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20252/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760546682848, "cdate": 1760546682848, "tmdate": 1762933738664, "mdate": 1762933738664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for automating meta-learning by learning a direct mapping from task distribution parameters to Bayes-optimal learner parameters. The method uses hypernetworks to predict the initial weights for a model given the parameters of the task distribution, enabling fast adaptation to new environments without rerunning meta-learning every time."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and easy to follow\n- The proposed idea of mapping task distributions to model weights is interesting.\n- The theoretical analysis provides an intuitive understanding of the method's foundations."}, "weaknesses": {"value": "- A central claim of the paper is that the proposed approach enables rapid adaptation to new task distributions without retraining. However, this is not convincingly demonstrated in the experiments. An analysis of performance on out-of-distribution (OoD) task distributions is necessary to substantiate this claim.\n- The experimental evaluation is limited. Additional baselines—such as Bayesian meta-learning methods, hypernetwork-based meta-learning approaches, and meta-learning algorithms designed for cross-task distribution generalization—should be included for a fair comparison.\n- The experiments are restricted to small-scale synthetic tasks. It would strengthen the paper to show applicability to more complex architectures (e.g., CNNs or Transformers) and realistic datasets.\n- An analysis of the computational complexity (in terms of memory usage, training time, and computational cost) is missing.\n- Reporting standard deviations or confidence intervals for all performance metrics would make the results more robust and comparable."}, "questions": {"value": "- Can the proposed approach adapt to any OoD task, even when the task distribution is very different than the one used for training? In other words, how does the hypernetwork behave when faced with a task distribution far from the training set?\n- In Table 2, why does the proposed method outperform the oracle baseline?\n- How were the hyperparameters chosen, and were they tuned separately for each baseline?\n- Is the method applicable to larger architectures? How does the hypernetwork scale with the dimensionality of the model parameters?\n- Does the limited query set size in the experiments affect the reported performance or stability of the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7nLSa5SJYr", "forum": "WgMebSFTnE", "replyto": "WgMebSFTnE", "signatures": ["ICLR.cc/2026/Conference/Submission20252/Reviewer_QKgG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20252/Reviewer_QKgG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20252/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761130979132, "cdate": 1761130979132, "tmdate": 1762933737982, "mdate": 1762933737982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a framework that learns a direct mapping from the parameters of a task distribution to the initial weights of a model. This allows adaptation to new environments without re-running meta-learning. The paper derives a closed-form Bayes-optimal mapping between task distribution parameters and model hyperparameters for Bayesian linear regression."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Reinterprets meta-learning as a mapping problem from task distributions to model priors. This reframing is conceptually simple yet powerful, potentially transforming how adaptation is handled in meta-learning. \n- The proposed hypernetwork offers meta-level amortization: meta-learn once, then generalize to new task distributions with a single forward pass.\n- The hierarchical Bayesian perspective is well-articulated, providing strong theoretical continuity with existing literature."}, "weaknesses": {"value": "- The experiments are limited that only toy regression and small MLP tasks are considered. No experiments on high-dimensional or real-world domains (e.g., vision, NLP, RL), making it unclear how the method scales or generalizes. Additionally, the baselines are narrow, including only MAML and one of its variants.\n- The authors highlight efficiency as a benefit, yet they do not provide an ablation study on the impact of hypernetwork size on performance, nor do they include a detailed analysis of computational complexity or inference/training time."}, "questions": {"value": "The method relies on explicit access to task distribution parameters $\\eta$. When these parameters are unknown or difficult to estimate, how to handle such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AQKwqTJ27D", "forum": "WgMebSFTnE", "replyto": "WgMebSFTnE", "signatures": ["ICLR.cc/2026/Conference/Submission20252/Reviewer_u7vP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20252/Reviewer_u7vP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20252/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641745120, "cdate": 1761641745120, "tmdate": 1762933737632, "mdate": 1762933737632, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a meta-learning method that uses a hypernetwork to predict model initialization weights, then runs MAML on this initialization to create the final model for a task.  Here, the tasks fall under a hierarchical probability model $p(\\mu) -> \\mu(w) -> w$ where w is a task and \\mu is a distribution over tasks.  The hypernetwork is used to predict a model init $\\theta_0$ for MAML given a task distribution $\\mu$, which MAML can then use as its init point for adapting to tasks $w$ drawn from $\\mu$.\n\nThe setup is analyzed in the context of linar-gaussian models where all distributions mentioned above are gaussians with means determined by a linear model of the sample from the layer before.  Numerical experiments are performed on simple examples including the linear-gaussian case and a low-dimensional MLP (dims 2 -> 32 -> 1), finding improvements over constant init learned by vanilla MAML in these small test settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The use of a hypernetwork to output initializations that are further refined is an interesting construction and strategy.  The paper formulates this setup well and develops its soundness in theoretical simple case (linear-Gaussian).  It has good experiments in small, toy settings that illustrate and confirm its behavior."}, "weaknesses": {"value": "The largest weakness with this paper is it only studies the method in very small, toy settings.  While these confirm that it's basically working as intended, they don't go very far in illustrating its performance.  Likewise, the theoretical results only show the existence and form of a solution in a limited case; while that demonstrates a basic level of soundness, it doesn't seem to say much about the method's performance beyond its ability to converge in a simple case.\n\nIn addition, I couldn't find much in the way of concrete descriptions for how $\\mu$ might be set up in a more realistic setting.  Table 1 mentions a few applications, but there are no concrete constructions that actually demonstrate how this might work.  Without this, I'm a little bit confused about the motivation for the task distribution $\\mu$, and why it's used as the hypernetwork inputs as opposed to the task w directly.  See questions below for more details on these points."}, "questions": {"value": "* Why use $h(\\mu)$, as opposed to applying h directly to the task w, as $\\theta_0 = h(w)$ to get \\theta_0 and run MAML on that?  The w distribution $p(w|\\mu)p(\\mu|\\eta)$ can remain the same as it is now when training the hypernetwork; the only difference is h is applied to w instead of the \\mu params.  It would be good to compare to this as well, as it seems a somewhat simpler setup to me.\n\n* What is an example of \\mu and w  in a more concrete setting, like image classification?  from what I understand, in this case a task w is a set of classes, and \\mu is a distrib over sets of classes.  But for example in benchmarks like mini-/tiered-Imagenet, classes are split between meta-train and meta-test, so that no class in the meta-test (which benchmarks generalization into unknown class deployments) occurs in the meta-training set.  What can \\mu be in this case, and how can it be used at test-time?\n\n* formulation with x ~ p(x), y ~ p(y | x, w):  This supposes inputs x are shared between all tasks w.  Which is certainly a valid way to formulate.  But for image classification, for example, if w are the classes and x ~ p(x) from all images over some large image distribution, then it's possible many images don't contain any class in w.  How does this affect the model in practice, perhaps in terms of sampling methods?\n\n* Eq 4:  I don't entirely understand how X and w fit into this objective.  I checked the Snell 21 reference and they have X in their conditioning, but also formulate their objectives in an overall quite different context so it's not immediately clear how to make this correspond.  Since y ~ p(y|x,w), where does p(x) come into play in the eq 4 objective?\n\n* l.355 baselines \"Pooled MAML, is equivalent to our method but has no hypernetwork\" --- would this be equivalent to vanilla Reptile?  it would be if it's trained on a single distribution of tasks, but not sure if this is the case with sampled task distribs.  OTOH, if tasks are sampled from \\mu_w and \\mu_w is sampled from a task distrib prior, this implies a modeled distribution on the tasks w as p(\\mu) -> \\mu -> w, and so pooled maml seems it would be the same as reptile under this overall distrib for w?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MLq53kjjpd", "forum": "WgMebSFTnE", "replyto": "WgMebSFTnE", "signatures": ["ICLR.cc/2026/Conference/Submission20252/Reviewer_qfNk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20252/Reviewer_qfNk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20252/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761709531827, "cdate": 1761709531827, "tmdate": 1762933737223, "mdate": 1762933737223, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}