{"id": "Ux11GkiQD2", "number": 21317, "cdate": 1758316192496, "mdate": 1758814770190, "content": {"title": "Beyond Real Data: Synthetic Data through the Lens of Regularization", "abstract": "Synthetic data can improve generalization when real data is scarce, but excessive reliance may introduce distributional mismatches that degrade performance. In this paper, we present a learning-theoretic framework to quantify the trade-off between synthetic and real data. Our approach leverages algorithmic stability to derive generalization error bounds, characterizing the optimal synthetic-to-real data ratio that minimizes expected test error as a function of the Wasserstein distance between the real and synthetic distributions. We motivate our framework in the setting of kernel ridge regression with mixed data, offering a detailed analysis that may be of independent interest. Our theory predicts the existence of an optimal ratio, leading to a U-shaped behavior of test error with respect to the proportion of synthetic data. Empirically, we validate this prediction on CIFAR-10 and a clinical brain MRI dataset. Our theory extends to the important scenario of domain adaptation, showing that carefully blending synthetic target data with limited source data can mitigate domain shift and enhance generalization. We conclude with practical guidance for applying our results to both in-domain and out-of-domain scenarios.", "tldr": "We present a theoretical framework that characterizes the optimal synthetic-to-real data ratio as a form of regularization, supported by experiments on CIFAR-10 and Brain MRI.", "keywords": ["Generalization", "in-domain", "out-of-domain", "synthetic data", "regularization"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/407bd2d1e47ed6570ea63536edcf4783a365efe9.pdf", "supplementary_material": ""}, "replies": [], "withdrawn": true}