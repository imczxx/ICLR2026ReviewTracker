{"id": "L7S7nNEPmk", "number": 18400, "cdate": 1758287244441, "mdate": 1758852949708, "content": {"title": "Plug-in Sample Complexity For Constrained Reinforcement Learning", "abstract": "We present a novel plug-in approach for constrained reinforcement learning that achieves the  sample complexity of $\\tilde{O}\\left(\\frac{SAH^4}{\\epsilon^2\\zeta^2}\\right)$ using a generative model. Unlike previous specialized algorithms, our method is general: it requires only black-box access to an optimization oracle that solves the empirical CMDP. The core of our approach is a reward perturbation technique that guarantees the oracle's solution is valid for the original problem.", "tldr": "We demonstrate that strategically perturbing the reward function enhances the sample efficiency of linear programming in constrained reinforcement learning.", "keywords": ["Reinforcement learning", "plug-in algorithm", "generative model"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/98917e1c18e8d53b858839ce45c3ac66680c1509.pdf", "supplementary_material": ""}, "replies": [], "withdrawn": true}