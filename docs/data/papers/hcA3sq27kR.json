{"id": "hcA3sq27kR", "number": 22894, "cdate": 1758336806394, "mdate": 1759896841011, "content": {"title": "ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis", "abstract": "Artifacts in electroencephalography (EEG)---muscle, eye movement, electrode, chewing, and shiver---confound automated analysis yet are costly to label at scale. We study whether modern generative models can synthesize realistic, label-aware artifact segments suitable for augmentation and stress-testing. Using the TUH EEG Artifact (TUAR) corpus, we curate subject-wise splits and fixed-length multi-channel windows (e.g., 250 samples) with preprocessing tailored to each model (per-window min--max for adversarial training; per-recording/channel $z$-score for diffusion). We compare a conditional WGAN-GP with a projection discriminator to a 1D denoising diffusion model with classifier-free guidance, and evaluate along three axes: (i) fidelity via Welch band-power deltas ($\\Delta\\delta,\\ \\Delta\\theta,\\ \\Delta\\alpha,\\ \\Delta\\beta$), channel-covariance Frobenius distance, autocorrelation $L_2$, and distributional metrics (MMD/PRD); (ii) specificity via class-conditional recovery with lightweight $k$NN/classifiers; and (iii) utility via augmentation effects on artifact recognition. In our setting, WGAN-GP achieves closer spectral alignment and lower MMD to real data, while both models exhibit weak class-conditional recovery, limiting immediate augmentation gains and revealing opportunities for stronger conditioning and coverage. We release a reproducible pipeline---data manifests, training configurations, and evaluation scripts---to establish a baseline for EEG artifact synthesis and to surface actionable failure modes for future work.", "tldr": "On TUAR, we benchmark WGAN-GP vs diffusion for label-aware EEG artifact synthesis; WGAN leads on spectral/MMD, but both struggle with class recovery; reproducible eval pipeline.", "keywords": ["EEG", "Generative Models", "Diffusion Models", "GANs", "Time-Series", "Neurophysiology", "Data Augmentation", "Artifact Synthesis", "Healthcare AI", "Benchmarking"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0717c8361a73e5222bcbea0ada6b45780855b5af.pdf", "supplementary_material": "/attachment/c8011ed5ac144e8e8e784deb74e229356ef4a867.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a pipeline for label-aware synthesis of EEG artifact segments using TUAR with subject-wise splits. It compares a conditional WGAN-GP with projection discriminator to a 1D diffusion model with FiLM conditioning and classifier-free guidance. The paper standardises preprocessing per model and assesses realism and usefulness using EEG-appropriate metrics—Welch band-power deltas, covariance and autocorrelation distances, simple recovery tests and augmentation effects. Results show WGAN-GP achieves tighter spectral alignment and lower MMD than diffusion but both models display weak class-conditional recovery that limits immediate augmentation gains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The subject-wise data curation pipeline for TUAR, with fixed-length multi-channel windowing, normalisation per model is technically solid and reusable. It provides a good foundation for reproducible EEG artefact synthesis and evaluation, which is often missing in prior GAN-based EEG work. This is of interest to the research community working in this area.\n\n- The paper introduces an EEG-specific evaluation framework using Welch band-power deltas, covariance Frobenius distance, autocorrelation L2 and MMD.\n\n- The paper provides a comparison between conditional WGAN-GP and a diffusion model within the same EEG artifact generation context. \n\n- The discussion in the paper identifies the main bottlenecks of conditioning strength, interchannel covariance modelling, normalisation differences and sampling efficiency. It then ties them to technical solutions such as spectral consistency losses. This makes the paper constructive and informative beyond its results."}, "weaknesses": {"value": "- Several listed contributions (e.g., evaluation suite, comparison tables, embedding plots) are standard experimental components rather than methodological advances. Evaluation and comparison are expected elements of any paper in this field and should not be framed as primary contributions.\n\n- The WGAN-GP and diffusion setups differ in normalisation, window length and sampling steps, meaning the comparison is not strictly controlled. The diffusion baseline, in particular, is underexplored with only 50-80 sampling steps used. This makes it hard to draw fair conclusions about relative performance.\n\n- The paper compares only WGAN-GP and diffusion, and ignores other relevant generative approaches such as VAEs, TimeGAN or flow-based models, among others. And the reasons for the choice of these two models are not well justified. \n\n- While the abstract and motivation emphasise artifact synthesis for data augmentation, the paper does not show concrete downstream improvements or task-based gains. Without functional results (like the performances of a downstream classifier), the significance of the work is limited.\n\n- The paper is overloaded with frequent in-text enumerations (i, ii, iii), which makes it difficult for readers to identify the main message and key takeaways. Generally, the paper is hard to read and follow. Also numerous abbreviations are introduced that are either used only once or not at all later in the paper. This also makes the paper difficult to read."}, "questions": {"value": "- The WGAN-GP and diffusion models use different normalisation schemes (per-window min–max vs per-recording z-score) and window lengths . Could the authors clarify whether these differences were essential for stable training or were they chosen mainly for convenience? Have they tried aligning these preprocessing steps to enable a more controlled comparison?\n\n- The diffusion model used only 50-80 sampling steps with a modest 1D U-Net. Did the authors experiment with higher sampling counts or alternative samplers to check if the performance gap versus WGAN-GP persists?\n\n- The paper emphasises the potential of synthetic artifacts for augmentation, but no downstream task results are reported. Do the authors have preliminary evidence to demonstrate whether these synthetic samples improve classifier performance?\n\n- The comparison focuses solely on WGAN-GP and DDPM. Could the authors justify excluding other generative baselines, which might offer different fidelity-diversity trade-offs in 1D signals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dCBbS8VmSH", "forum": "hcA3sq27kR", "replyto": "hcA3sq27kR", "signatures": ["ICLR.cc/2026/Conference/Submission22894/Reviewer_zhtR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22894/Reviewer_zhtR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22894/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761496879771, "cdate": 1761496879771, "tmdate": 1762942428094, "mdate": 1762942428094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper compares WGAN-GP and diffusion models for generating synthetic EEG artifact signals. WGAN-GP achieves better spectral alignment (lower band-power errors, 48% better MMD), but both models struggle with class-conditional generation. The main contribution is a reproducible evaluation framework with domain-appropriate metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Domain-appropriate evaluation: Using EEG-specific metrics instead of just image metrics (FID) is a major contribution\nReproducibility: All hyperparameters documented, subject-wise splits prevent leakage, code release promised\nAuthors acknowledged limitations (preprocessing confound, weak class recovery, no confidence intervals)\nClinical relevance: Tackles real world problems with proper experimental setup."}, "weaknesses": {"value": "Different preprocessing is conducted for different models, WGAN (per-window min-max, 1s) vs Diffusion (per-recording z-score, 2s), can't tell if WGAN wins due to architecture or just better preprocessing.\n\nMissing experiments: one major motivation is to \"enable data augmentation\", but no augmentation experiments. \n\nIs MMD difference (0.40 vs 0.59) statistically significant? Should run 3-5 times with different seeds.\n\nI would encourage the author to run with larger models or more sampling steps, despite currently acknowledging \"modest capacity\"."}, "questions": {"value": "Ablation with same preprocessing (normalization + window length) to make comparison fair?\n\nCan you show actual augmentation results? (detector trained on real vs real+synthetic)\n\nCan you provide class-conditional metrics (confusion matrix, per-class accuracy)?\n\nCan you add uncertainty quantification (multiple runs, error bars)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "65kQyod6F8", "forum": "hcA3sq27kR", "replyto": "hcA3sq27kR", "signatures": ["ICLR.cc/2026/Conference/Submission22894/Reviewer_z78f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22894/Reviewer_z78f"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22894/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761859253572, "cdate": 1761859253572, "tmdate": 1762942427860, "mdate": 1762942427860, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ARTIFACTGEN, a generative model for EEG artifact synthesis using two approaches: a conditional Wasserstein GAN (WGAN-GP) and a denoising diffusion probabilistic model (DDPM). The aim is to generate realistic, label-aware EEG artifact segments for use in augmentation and stress testing of artifact detection models. The authors perform a detailed evaluation of the models' fidelity, specificity, and utility, including spectral alignment, class-conditional recovery, and artifact recognition performance. Their results show that the WGAN-GP model performs better in terms of spectral alignment but both models show weak class-conditional recovery, pointing to potential areas for future improvements."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. Reproducibility and Transparency: The authors plan to provide comprehensive reproducibility scripts, dataset manifests, and configurations, which is valuable for ensuring transparency in their work.\n\n2. Clear Evaluation Metrics: The paper employs a well-defined evaluation suite that goes beyond image-style metrics, focusing on domain-appropriate measures such as band-power deltas and MMD, which are more suited to EEG data."}, "weaknesses": {"value": "1. Writing and Structure Issues:\n\nThe writing is difficult to follow and does not meet the standards expected for academic papers. The introduction fails to clearly describe the background and problem, and it lacks a meaningful discussion of related work. The section repeats ideas already mentioned in the abstract, leading to unnecessary redundancy. The structure of the paper is flawed. The background section lacks focus, while the related work section is overly detailed without contributing much to the context of the problem. The methodology section is unclear and lacks necessary diagrams to illustrate the proposed models, making the overall readability very poor. The paper suffers from poor semantic flow, and many parts are difficult to understand due to unclear expressions. It doesn’t follow the typical academic writing style, which affects the clarity of the arguments presented.\n\n2. Lack of Novelty and Innovation:\n\nThe methods used in this work, such as WGAN-GP (from 2017) and traditional diffusion models, are quite old and fail to demonstrate a significant advancement in the field. While these methods have been influential, they have been largely superseded by newer techniques that offer better performance, scalability, and efficiency. The primary contribution of this paper seems to be the evaluation of existing models, rather than the introduction of novel approaches. The lack of innovation in the proposed method limits the overall value of the work."}, "questions": {"value": "1.It is suggested to rewrite the Introduction and Related Work sections, integrating the background into the Introduction.\n\n2.Considering that WGAN-GP and DDPMs are older models, can you justify why these particular methods were chosen over more modern alternatives? Additionally, could you discuss whether newer generative models, such as those based on recent advancements in transformers or flow-based models, might offer improved performance for EEG artifact generation?\n\n3.Considering that the background outlines several practical needs for EEG artifact synthesis, could you evaluate the effectiveness of the proposed methods in light of these practical requirements? Specifically, how well do the models meet the needs for data augmentation, robustness testing, and artifact detection in real-world applications?\n\n4.This work only compares the performance of the two proposed methods. Is there any comparison with other existing methods for EEG artifact synthesis, and how do the proposed methods perform relative to them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "24CEk9b4ca", "forum": "hcA3sq27kR", "replyto": "hcA3sq27kR", "signatures": ["ICLR.cc/2026/Conference/Submission22894/Reviewer_sjT1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22894/Reviewer_sjT1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22894/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980081079, "cdate": 1761980081079, "tmdate": 1762942427624, "mdate": 1762942427624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper is about EEG artifact generation: how to create realistic artificial EEG signals that include common noise patterns such as eye blinks, muscle activity, or electrode interference. It compares two types of generative AI models: (1) a conditional WGAN-GP with a projection discriminator, and (2) a 1D diffusion model with FiLM conditioning and classifier-free guidance.\n\nThe goal of the paper is to benchmark these generative approaches and provide a reproducible framework for generating and evaluating synthetic EEG artifacts. The authors build and share a standardized pipeline using the TUH EEG Artifact (TUAR) dataset, apply both models on the same data, and compare them using EEG-specific metrics that measure signal fidelity, similarity, and diversity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles a clear and practical problem: EEG classifiers and machine learning models need a large amount of training data, but recording and labeling EEG data are both costly and time-consuming. Generating realistic synthetic data could help overcome this limitation. The paper is easy to follow and well organized, with clear sections explaining the data, models, and results. Figures and tables make the results easy to understand.\n- The paper directly compares two different types of generative models, WGAN-GP and diffusion, in a detailed way. The authors also use EEG-specific evaluation methods (like frequency band power and MMD) instead of borrowing metrics from image generation, which makes the study feel appropriate for this domain.\n- The authors share their setup in a transparent way, including how data were processed and how experiments can be repeated. This makes the paper useful for anyone wanting to build on it later.\n- Overall, the paper is clearly written, addresses a real gap in EEG research, and gives a helpful benchmark for others to use."}, "weaknesses": {"value": "- The study evaluates only one dataset (TUAR) under a single experimental configuration. Although TUAR is a well-known choice for labeled EEG artifacts, depending solely on it means the results might not generalize to other EEG setups or recording conditions. Including or even discussing results on a second dataset, or showing how the framework could extend to others, would make the benchmark stronger.\n- The paper compares only two model families: a WGAN-GP and one diffusion model. While these are logical choices, the comparison would feel more complete with a few additional or simpler baselines, such as TimeGAN, WaveGAN or RCGAN. This would help position the results in a broader context and make the benchmark more informative.\n- Although the authors acknowledge this limitation, the comparison between WGAN-GP and diffusion is not fully balanced. The two models differ in window size (1 s vs 2 s), normalization, and diffusion sampling steps (only 50), which makes it hard to draw firm conclusions about which method is better. Using matched settings or stronger diffusion baselines (e.g., larger U-Net architectures or improved samplers such as DPM-Solver) could make the comparison more convincing.\n- The diffusion model setup also feels too small to show its full potential. With more steps or a stronger model, it might have done better.\n- Finally, both models had trouble creating clean differences between artifact types, but the paper doesn’t explore why this happens or how to fix it."}, "questions": {"value": "- 1. The paper uses different preprocessing and normalization schemes for the WGAN-GP and diffusion models. Since this can affect spectral and distribution metrics, did you test a unified preprocessing setup to confirm that results are not driven by these differences?\n- 2. The diffusion model uses only 50 sampling steps, which is relatively few for this type of model. Was this decision based on computational limits or diminishing returns in performance? \n- 3. The benchmark is built around the TUAR dataset. How adaptable the current framework is to other EEG datasets? \n- 4. Since both models show overlapping artifact distributions, it would be useful to know whether this is due to the dataset’s intrinsic label overlap, model conditioning limits, or metric sensitivity.\n- 5. There appears to be an unresolved reference on page 1 showing as a “?”. Could the authors verify that all citation keys are correctly compiled before the final submission?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QMjJ4Zpxpt", "forum": "hcA3sq27kR", "replyto": "hcA3sq27kR", "signatures": ["ICLR.cc/2026/Conference/Submission22894/Reviewer_Z9QM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22894/Reviewer_Z9QM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22894/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762149016282, "cdate": 1762149016282, "tmdate": 1762942427435, "mdate": 1762942427435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}