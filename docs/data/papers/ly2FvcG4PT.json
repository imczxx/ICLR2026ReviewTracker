{"id": "ly2FvcG4PT", "number": 12125, "cdate": 1758205800010, "mdate": 1759897530380, "content": {"title": "Heterogeneous Transfer Learning with Feature Transformation-Based Adaptation for Modeling Dynamical Systems", "abstract": "In this work, a novel heterogeneous transfer learning framework is proposed for modeling dynamical systems, where the source and target domains have different feature spaces. A feature transformation scheme is implemented via customized adaptation layers integrated into the pre-trained model. We conduct theoretical analysis of heterogeneous domain adaptation, demonstrating the generalization performance of the pre-trained model on the target domain after feature transformation. Based on this analysis, a two-phase training strategy is proposed to improve the performance of the heterogeneous transfer learning model. The experimental results in three case studies across different application domains demonstrate the effectiveness of the proposed method.", "tldr": "In this work, a novel heterogeneous transfer learning framework is proposed for modeling dynamical systems, where the source and target domains have different feature spaces.", "keywords": ["nonlinear dynamical system", "heterogeneous transfer learning", "domain adaptation", "generalization error analysis"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/37fe8955ab3cb5f821bff551e817a47583635e58.pdf", "supplementary_material": "/attachment/b5dc9ead9cff521df6232c6d2b63036fe5381a02.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates heterogeneous transfer learning for modeling dynamical systems, where the source and target domains have different feature spaces. The authors propose a novel framework that integrates customized adaptation layers into a pre-trained model to enable effective feature transformation across domains. A theoretical analysis is provided to evaluate the generalization performance of the transformed model in the target domain. Building on this foundation, a two-phase training strategy is introduced to further enhance adaptation. Experimental results demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a significant but underexplored problem: the generalization of neural network-based models for complex dynamical systems. Tackling this challenge is valuable and appreciated.\n2. The authors provide theoretical guarantees regarding model generalization, which adds rigor to the proposed framework.\n3. The designed feature transformation modules for enabling target domain adaptation is simple and efficient."}, "weaknesses": {"value": "1. The theoretical analysis lacks a strong connection to the characteristics of dynamical systems, especially nonlinear dynamics. \n\n2. The experimental validation looks too weak. The paper would benefit from more diverse datasets and comprehensive ablation studies to validate the contribution."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SgIrfwp7rg", "forum": "ly2FvcG4PT", "replyto": "ly2FvcG4PT", "signatures": ["ICLR.cc/2026/Conference/Submission12125/Reviewer_DzLo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12125/Reviewer_DzLo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761459812918, "cdate": 1761459812918, "tmdate": 1762923089907, "mdate": 1762923089907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework for heterogeneous transfer learning (HTL) tailored to modeling nonlinear dynamical systems when the source and target domains have mismatched feature spaces."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors provide a detailed derivation of generalization error bounds for HTL using statistical learning theory and derive a two-phase training strategy, in which the custom loss function incorporates multiple theoretical terms, balancing empirical performance with generalization. The framework is modular and easily integrable into existing neural architectures. Adaptation layers are lightweight and interpretable, making the method scalable and practical."}, "weaknesses": {"value": "1. Remark 1: when the input and output dimensions differ between the source and target domains, how the fact that different features repeated or different strategies to add the zero vectors affects the efficiency of the proposed algorithm?\n2. dx in (1) is the dimension of the state vector, and dxs in (2) is the dimension of the model input features of the source domain, how to ensure that Assumption 1 is meaningful?\n3. Any function h(\\cdot) in the set of hypothesis functions H (Line 163-164 in Page 4): the input of h(\\cdot) is any vector in the subspace spanned by x1 to xt, or one of x1 to xt?\n4. As shown in (2), Xs, Xt, Ys, and Yt are subspaces. In (4), the authors assume that the corresponding subspaces are equivalent. Are the matrices P and Q nonsingular?\n5. What about when replacing the linear transformation in (4) as some nonlinear transformation?"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "c7hJumZpv8", "forum": "ly2FvcG4PT", "replyto": "ly2FvcG4PT", "signatures": ["ICLR.cc/2026/Conference/Submission12125/Reviewer_8hdV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12125/Reviewer_8hdV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761554632035, "cdate": 1761554632035, "tmdate": 1762923089395, "mdate": 1762923089395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "A method for heterogeneous transfer learning on dynamical systems is proposed. It is based on linear transformations of the inputs and outputs. A bound of the generalization error in the target domain is provided. The proposed loss function is based on the insight obtained from the bound. The experimental results support the utility of the proposed method compared to several baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The method is simple.\n- The analysis of the generalization error bound may not be overly technically novel but does make sense, and the insight obtained from the bound is neatly utilized in the loss function."}, "weaknesses": {"value": "Although the technical contribution looks solid, the paper seems to need some updates to clear the bar to appear in ICLR.\n\n**(1)**\nMost notably, no ablation studies are presented, due to which we cannot analyze how each part of the proposed method was effective. The loss function has multiple terms, and the proposed algorithm comprises two different phases. The contributions of each of these components of the method should be examined in more detail.\n\n**(2)**\nThe writing in Section 6 could be polished much more. Currently it rephrases the same thing over and over, and it's hard to extract important information.\n\n**(3)**\nThe necessity of Assumption 1 is unclear. The matrices $P$ and $Q$ can simply be of sizes $d_{xs} \\times d_{xt}$ and $d_{xt} \\times d_{xs}$, respectively.\n\nBelow are minor things:\n- Around Eq. (7) (and on the other occasions too), quantities $B_{V,F}$, $B_{W,F}$, $B_{U,F}$ are used without definition.\n- Line 345: \"The second term measures the performance of $h^*$ on the empirical source and target domains.\" ... I don't think so, it instead measure the *difference* of the performances."}, "questions": {"value": "Do you have any results of ablation studies, investigating the effect of each component of the method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rHyduXyGFv", "forum": "ly2FvcG4PT", "replyto": "ly2FvcG4PT", "signatures": ["ICLR.cc/2026/Conference/Submission12125/Reviewer_D1Da"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12125/Reviewer_D1Da"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743152221, "cdate": 1761743152221, "tmdate": 1762923088910, "mdate": 1762923088910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Heterogeneous Transfer Learning framework that aligns source and target feature spaces through linear adaptation layers added before and after a pre-trained model. Experiments showed the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A novel heterogeneous transfer learning framework is proposed to address the feature mismatch between the source and target domains.\n2. Theoretical analysis is provided. \n3. Experiments showed the effectiveness of the proposed method."}, "weaknesses": {"value": "1. Insufficient analysis of data scale and noise sensitivity;\n2. Limit in the ablation study."}, "questions": {"value": "1. All current experiments have been conducted under conditions with sufficient data volume and controlled noise levels. It remains unclear how the proposed HTL framework performs in scenarios with small sample sizes or high noise levels.\n2. The paper proposes a two-stage training process (Phase 1 feature adaptation and Phase 2 global fine-tuning). Still, the current experimental section fails to fully validate the independent contributions and synergistic effects of the two stages.\n3. The adaptation matrices P and Q are theoretically responsible for implementing linear mappings between the feature spaces of the source domain and target domain. However,  is there a significant difference among all competing ones?\n4. All datasets are from continuous control systems. How is the performance of the proposed method in more cross-domain experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PESFkfT3pM", "forum": "ly2FvcG4PT", "replyto": "ly2FvcG4PT", "signatures": ["ICLR.cc/2026/Conference/Submission12125/Reviewer_FXTu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12125/Reviewer_FXTu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12125/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821945812, "cdate": 1761821945812, "tmdate": 1762923088382, "mdate": 1762923088382, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}