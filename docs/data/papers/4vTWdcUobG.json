{"id": "4vTWdcUobG", "number": 7092, "cdate": 1758007371602, "mdate": 1763608824285, "content": {"title": "Enhancing Adversarial Transferability via Component-Wise Transformation", "abstract": "Deep Neural Networks (DNNs) are highly vulnerable to adversarial examples, which pose significant challenges in security-sensitive applications. Among various adversarial attack strategies, input transformation-based attacks have demonstrated remarkable effectiveness in enhancing adversarial transferability. However, current methods struggle with cross-architecture transferability, even when performing well within the same architecture. This limitation arises because, while models of the same architecture may focus on different regions of the object, the variation is even more pronounced across different architectures. Unfortunately, current approaches fail to effectively guide models to attend to these diverse regions. To address this issue, this paper proposes a novel input transformation-based attack method, termed Component-Wise Transformation (CWT). CWT applies interpolation and selective rotation to individual image blocks, ensuring that each transformed image highlights different target regions. Extensive experiments on the standard ImageNet and COCO datasets demonstrate that CWT consistently outperforms state-of-the-art methods across both CNN- and Transformer-based models.", "tldr": "The paper proposes CWT, a method that enhances adversarial transferability by applying block-wise interpolation and selective rotation to diversify model attention, achieving state-of-the-art attack success rates across diverse architectures.", "keywords": ["Adversarial Transferability", "Untargeted Attack", "Input transformation-based attacks"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/87b3f0529bdcc692bf87fe48367f37182068c7e6.pdf", "supplementary_material": "/attachment/56ed8db77bb94caab5210d3aa8868935b26ee40a.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes Component‑Wise Transformation (CWT), a block-wise input transformation method to improve adversarial example transferability across architectures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1 Cross-architecture adversarial transfer is a relevant and challenging research topic. Grad-CAM visualizations convincingly illustrate architectural attention differences.\n\n2 CWT is easy to implement, computationally efficient, and integrates naturally with MI-FGSM."}, "weaknesses": {"value": "1 Incomplete comparison with SOTA: The paper omits some SOTA methods (e.g., Boosting the Transferability of Adversarial Attack on Vision Transformer with Adaptive Token Tuning, Improving Adversarial Transferability via\nIntermediate-level Perturbation Decay),\n\n2 There is no rigorous quantitative analysis showing that CWT systematically improve gradient alignment, or that improved alignment directly leads to higher transfer success. Without this connection, it is unclear whether the empirical gains are due to the claimed mechanism or just incidental effects of more diverse transformations."}, "questions": {"value": "1 Have you evaluated targeted transfer attacks or adaptive defenses? \n\n2 Can you provide more empirical evidence that CWT consistently increases gradient alignment across architectures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VcRGbcurAQ", "forum": "4vTWdcUobG", "replyto": "4vTWdcUobG", "signatures": ["ICLR.cc/2026/Conference/Submission7092/Reviewer_PLGw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7092/Reviewer_PLGw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731426060, "cdate": 1761731426060, "tmdate": 1762919270050, "mdate": 1762919270050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mh358oOOzW", "forum": "4vTWdcUobG", "replyto": "4vTWdcUobG", "signatures": ["ICLR.cc/2026/Conference/Submission7092/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7092/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763608823448, "cdate": 1763608823448, "tmdate": 1763608823448, "mdate": 1763608823448, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper works on improving the input transformations directions in image adversarial attacks, The paper first explores the theoretical roots of poor cross-architecture transferability, and then proposes component-wise transformation (CWT) aiming to boost the transferability. The authors conducted. extensive experiments on standard datasets like ImageNet and COCO."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is easy to follow.\n- The paper studies an important field in AI security."}, "weaknesses": {"value": "1. Evaluation.\n    - Model utility is not included in evaluations. The reviewer is concerned that block-wise rotation may include artifacts in image, such that the artifacts could be easily observed by a human, hence it may hinder the **imperceptibility**, a pivotal principle in adversarial attack field. The reviewer kindly asks the authors to provide more examples of adversarial examples generated by the proposed algorithm to showcase their imperceptibility**.**\n2. Soundness of the method\n- It is not clear that the top part of figure 2 is based on real data, or hand-made illustrations.\n- On Equation (6): the claims in lines 209-211 could be essentially wrong. The reason is that as shown in equation (6), two gradient operators are regarding different inputs, i.e., $x_s^{adv}$ and $x$ (another concern: $x$ is not defined here).\n- The IoU metric proposed in Equation (7) may be problematic. The equation builds upon the assumption that every images contains a foreground (and hence a background), however it is not clear that the assumption holds in the scenario in the paper.\n\n3. Presentation\n\n- For Figure 2, the meaning of “attack directions from” is not clear.\n- The term 'attention' in Figure 2 is misleading. The reviewer recommends replacing it with 'attribution map' or 'saliency map' (for CAM methods) to prevent confusion with the attention operations used in Transformer.\n- Figure 3. should appear in the evaluation section (i.e., section 4) instead of methodology section.\n- $s$ and $t$ should be italicized in lines 193-194."}, "questions": {"value": "Please respond the concerns above.\n\nThe reviewer will raise the rating if the concern gets solved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "r0gQsuCm0K", "forum": "4vTWdcUobG", "replyto": "4vTWdcUobG", "signatures": ["ICLR.cc/2026/Conference/Submission7092/Reviewer_cTxy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7092/Reviewer_cTxy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861286827, "cdate": 1761861286827, "tmdate": 1762919269579, "mdate": 1762919269579, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Component-Wise Transformation (CWT) to boost adversarial transferability. CWT applies interpolation and selective rotation to individual image blocks, ensuring that each transformed image highlights different target regions. Extensive experiments on the ImageNet and COCO datasets demonstrate that CWT consistently outperforms state-of-the-art methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The experiment scope on the COCO dataset is good.\n\nThe topic of adversarial transferability is important."}, "weaknesses": {"value": "The motivation is not convincing.\n\nThe details of the proposed method are unclear.\n\nThe experiment may be unfair.\n\n(Minor) Format issue in Table 2."}, "questions": {"value": "1 The authors point out that the previous approaches fail to alter the model’s attention, leading to an attention distribution remaining consistent with the original image or deviating from the areas of interest in Lines 101-104. However, why this attention can influence the adversarial transferability is not discussed.\n\n2 CWT encourages models to focus on diverse regions of the object in the original image, which can enhance the transferability in Lines 105 - 107. However, why focusing on a diverse part of the object can improve the transferability is not validated.\n\n3 In Lines 139-142, the authors aim to improve the attention diversity by the proposed CWT. However, in the motivating example Table 1, the authors measure the IoU as the metric to compare with BSR. The IoU only measures the coverage, not the diversity. Therefore, the motivating example is not convincing enough to demonstrate the effect of diversity on performance.\n\n4 In the method section, the content of the Component-wise Transformation approach is less than one page. The details of the approach are missing. The authors should show the workflow of their approach to visualize the intermediate transformed images of their approach. Otherwise, the semantic meaning of the transformed image cannot be guaranteed.\n\n5 In Algorithm 1, I cannot find any useful information. The core part of the CWT approach is covered by only one sentence, “Calculate the gradient by Eq. 11.” The remaining part is the general optimization framework, similar to other attacking algorithms.\n\n6 The details of other baselines should be discussed in the experimental setup to make sure you can compare with them in a fair way. E.g., you can state the scaled copies of other baselines for a fair comparison under a similar computation complexity. Otherwise, your Runtime experiment is also unfair."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tHhY1CH0Gn", "forum": "4vTWdcUobG", "replyto": "4vTWdcUobG", "signatures": ["ICLR.cc/2026/Conference/Submission7092/Reviewer_XAUX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7092/Reviewer_XAUX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762069289628, "cdate": 1762069289628, "tmdate": 1762919269238, "mdate": 1762919269238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on enhancing the transferability of adversarial examples under black-box models. The authors propose a method called CWT (Component-Wise Transformation), which applies interpolation and selective rotation to individual image blocks to guide the model's attention toward different target regions. The paper is well written and easy to read, and the experimental results have validated the effectiveness of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper reveals that the differences in the target regions focused on by various models may be a primary reason for the limited transferability of adversarial examples. \n\n2 . Fig.3 shows the relationship between different models from three perspectives: gradient cosine similarity, adversarial noise cosine similarity, and transferability of attacks.\n\n3. The experimental results of the CWT method demonstrate the effectiveness of the method proposed in this paper.\n\n4. Fig.A3 in the appendix demonstrates the effectiveness of the CWT method against attacks in real-world scenarios."}, "weaknesses": {"value": "1. In Figure 2, the authors claim that the BSR method focuses too much on the region outside the target object, i.e., the background area, which limits the transferability of adversarial examples. Does this description contradict the actual experimental results? Methods like DIM, SIM, and Admix, even though they focus on the region within the target object, exhibit worse transferability than BSR. Furthermore, since the model's input is a whole image rather than just the target object, attackers can enhance perturbations in background regions outside the target to enhance the attack capability of the entire photo. Therefore, I think this part of the description is overly absolute. \n\n2. The CWT method seems to be an integration of multiple input transformation techniques (Pre-Interpolation, Block-wise Scaling, Rotation). The authors should theoretically elaborate on the positive effects each input transformation method brings to guiding the model's focus on different regions of the target object.\n\n3. I think the comparison in Table 1 is not a fair comparison. Figure 2 already shows that the region of interest for BSR is not on the target object. The authors should calculate the IOU results with methods like DIM, SIM, and Admix to highlight your motivation, i.e., “Aims to generate transformed images that strategically encourage models to focus on diverse regions of an object.”. Additionally, from Figure 2, I don't clearly see any differences in the regions of interest between the CWT method and those used by DIM, SIM, and Admix.\n\n4. For the third contribution, since the authors only compared some input transformation-based methods, it is recommended to revise it to “compared to existing input transformation-based approaches.”\n\n5. Line 266 seems to have an incorrect word."}, "questions": {"value": "Please refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ocCfYxaCMw", "forum": "4vTWdcUobG", "replyto": "4vTWdcUobG", "signatures": ["ICLR.cc/2026/Conference/Submission7092/Reviewer_fMuc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7092/Reviewer_fMuc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762069690403, "cdate": 1762069690403, "tmdate": 1762919268835, "mdate": 1762919268835, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}