{"id": "yZirk1CoZQ", "number": 1581, "cdate": 1756894110982, "mdate": 1759898200111, "content": {"title": "TRACE: Transcoder-based Concept Editing", "abstract": "Image generation with diffusion and autoregressive models can inadvertently output undesirable content, such as copyrighted characters, harmful images, unwanted objects, or protected artistic styles. Therefore, trustworthy content moderation remains a major challenge: retraining for the removal of each of these concepts is infeasible, while existing post-hoc interventions are either easy to bypass or come at the cost of image quality. We introduce a white-box, model-agnostic framework that uses *Transcoders* as an integrated, surgical intervention layer that allows precise, in-place suppression of targeted concepts without retraining the generative model. Because our approach modifies the model’s backbone and not just external modules, it is robust against circumvention and preserves overall generation quality. Empirically, our method achieves new state-of-the-art results for both diffusion and autoregressive image generative models, remaining robust even against adversarial prompts and throughout sequential, diverse concept removal requests. Thereby, our approach sets the practical foundation for trustworthy image generation in real-world scenarios.", "tldr": "We leverage Transcoders to selectively remove any concepts from image generative models.", "keywords": ["transcoder", "concept editing", "text-to-image model", "interpretability", "Trustworthy GenAI", "Safe AI", "safe generation", "image generation", "image generative models", "diffusion models", "image autoregressive models", "IARs"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8e92ed13480068d5c415b2ff68c6eedd8c67cca2.pdf", "supplementary_material": "/attachment/96ca3950b10007d8d269a7e7c42a90f84d555127.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces TRACE (TRAnscoder-based Concept Editing), a novel framework for concept removal in text-to-image generative models. Instead of retraining or relying on detachable safety modules, TRACE integrates a *transcoder layer* directly into the model backbone, allowing targeted suppression of specific concepts (e.g., styles, objects, NSFW, IP content) in a persistent and architecture-agnostic manner. The transcoder learns sparse and interpretable representations, enabling surgical removal of concept-associated latents while preserving unrelated content. Experiments on state-of-the-art diffusion and autoregressive models (SD3.5, Flux, Infinity-2B/8B) show that TRACE achieves higher unlearning and retention accuracies than existing white-box editing methods (UCE, LOCOEDIT), scales robustly to multi-concept and sequential removals, and maintains strong image fidelity and robustness against adversarial prompting attacks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles sequential multi-concept removal, which is a highly practical and realistic setting for real-world deployment of generative models.\n2. The use of transcoders to intervene on the text encoder’s output is well-motivated, and replacing the original transformation layers directly is a sound design choice that ensures applicability and persistence in white-box settings."}, "weaknesses": {"value": "1. The writing quality needs improvement — the paper is sometimes difficult to follow, especially for readers not already familiar with the concept editing literature.\n2. The proposed Transcoder can largely be viewed as a variant of Sparse Autoencoders (SAEs), differing mainly in that it reconstructs new feature mappings rather than latent activations. However, the paper does not mention SAEs or related methods until page 5, where a comparison first appears. Given that several recent works have explored SAE-based concept editing, the authors should better position their contribution within this line of research and discuss these connections more thoroughly [1,2].\n3. In the second paragraph of the Introduction, the authors argue that existing methods suffer from *high computational cost*. However, training a well-defined transcoder itself also appears computationally demanding — it requires a large number of prompt-based forward passes to collect data and additional training for the transcoder module. The paper should provide quantitative evidence or comparisons to justify this claimed advantage.\n4. In Section 4.3, the authors state that once the transcoder is trained, new concept removals can be achieved simply by suppressing corresponding decoder columns. While this makes sense intuitively, it assumes a *well-trained transcoder* with sufficient data coverage. How does the method handle unseen or rare concepts (e.g., niche IP characters) that were not present in the training prompts? Does it generalize effectively, or is retraining required in such cases?\n5. The applicability of the method depends on model architecture: TRACE replaces the projection or MLP layers following the text encoder, which exist in models such as SD3.5 and Flux. However, some popular text-to-image architectures (e.g., SD1.4) feed text embeddings directly into cross-attention layers without such intermediate transformations. It remains unclear how TRACE would apply to these cases.\n6. The main results lack sufficient baselines. Since the motivation centers on *sequential concept erasure*, several relevant multi-concept removal methods should be included for comparison [3,4,5]. Although some of these approaches focus on simultaneous multi-concept erasure, methods like MACE (which trains per-concept LoRA adapters and fuses them) or other editing-based techniques can be adapted to the sequential setting, given their short per-edit computation time.\n7. All experiments are conducted on SD3.5, Flux, and autoregressive models, but results on SD1.4 are missing. Since most existing benchmarks and prior works are based on SD1.4, this omission makes it difficult to assess TRACE’s relative performance fairly.\n8. Table 2 only reports results under the Ring-A-Bell (RAB) adversarial prompting attack, which is a relatively weak black-box evaluation. Stronger or more diverse adversarial attack benchmarks [6,7] should be included to substantiate the robustness claims.\n9. The paper lacks prior preservation experiments beyond the in-domain IRA metric. Reporting results on a general benchmark such as MS-COCO would strengthen the evidence for prior retention.\n10. The paper does not include any NSFW concept removal results (e.g., nudity). Since NSFW moderation is a key motivation for concept editing, evaluating TRACE on such concepts would be important to demonstrate its generality and real-world applicability.\n\n\nThe most significant limitation lies in the experimental evaluation. The absence of SD1.4 results prevents fair comparison to prior works, the choice of baselines is too limited (only two are included), and crucial evaluations such as NSFW removal and stronger adversarial benchmarks are missing. Together, these gaps make it difficult to fully assess the empirical effectiveness of TRACE.\n\n\n\n[1] Concept Steerers: Leveraging K-Sparse Autoencoders for Controllable Generations\n\n[2] Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models\n\n[3] MACE: Mass Concept Erasure in Diffusion Models\n\n[4] One-Dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications\n\n[5] Set You Straight: Auto-Steering Denoising Trajectories to Sidestep Unwanted Concepts\n\n[6] To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now\n\n[7] MMA-Diffusion: MultiModal Attack on Diffusion Models"}, "questions": {"value": "See the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SQMqjjbSjm", "forum": "yZirk1CoZQ", "replyto": "yZirk1CoZQ", "signatures": ["ICLR.cc/2026/Conference/Submission1581/Reviewer_Xqs8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1581/Reviewer_Xqs8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1581/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761203640561, "cdate": 1761203640561, "tmdate": 1762915823667, "mdate": 1762915823667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a method for the removal of certain concepts from the generative model, with a method named TRACE, where they focus on transcoder layers that bridge the text encoder and the generative model. The method claims that this approach does not require retraining the generative model, and thus reducing the computational cost for the concept removal problem. To evaluate the effectiveness of the method, the authors benchmark TRACE over UnlearnCanvas benchmark, which focuses on style and object removal. The experiments has been conducted over a diverse set of generator architectures (e.g. autoregressive, rectified-flow). In the proposed lightweight training approach, the authors also propose a new training objective that addresses the dead gradients problem in the latents."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method serves as a solution for both rectified-flow models and image autoregressive models.\n- TRACE shows its effectiveness towards multiple tasks and aspects. For one, the method shows clear margins in multi-concept removal and robustness.\n- The proposed method serves as an efficient alternative compared to the competing approaches.\n- From both the qualitative and quantitative results, the proposed approach seems as an effective method for concept removal."}, "weaknesses": {"value": "- In Eq. 5, the notation $md$ is not clear, the authors should clarify that.\n- The proposed method is an approach that has certain similarities with SAEuron, as the authors also specify. While completely acknowledging their differences (inference cost, training cost), a comparison should be included where the current benchmark only compares with LOCOEDIT and UCE. In addition these methods are all for $\\textbf{closed-form editing}$. The final benchmark should also include metrics for the other end for the task, which is methods classified as $\\textbf{Training-based Editing}$.\n- In terms of image quality, using scores such as HPSv3, and aesthetics score can reveal more intuitive evaluations as metrics trained on large scale data and less effected than the test set size (compared to FID).\n- The method examines the projection layer used for the pooled embeddings before being fed to the model. In architectures such as FLUX and SD 3.5, this only covers one part of the text conditioning, where the other involves the attention mechanism with token-wise embeddings. From the current presentation, the method seems to be missing the concepts encoded in the attention layers where it appears that the method only concerns the pooled embeddings. The authors should clarify this. Otherwise, the method may be limited in terms of the concepts that can be removed with this method."}, "questions": {"value": "- What are the details of the FID measurements, in terms of the number of samples used? The metric is known to have a bias towards small number of samples. Given the scale of the FID score is high, this should also be acknowledged in the paper.\n- For the ablations, the replacement of ReLU with TopK seems like an improtant contribution of the paper. Does the effectiveness of this process be quantifiable with the performed evaluations, or with qualitative examples? The authors are encouraged to report such evaluations.\n- The method has an efficiency claim. Does this can be supported with quantifiable metrics such as convergence time, FLOPs and GPU memory required? \n- Are there any types of concepts that cannot be removed, and can be considered as a failure case?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N3HGFGAjP5", "forum": "yZirk1CoZQ", "replyto": "yZirk1CoZQ", "signatures": ["ICLR.cc/2026/Conference/Submission1581/Reviewer_4vVf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1581/Reviewer_4vVf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1581/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794981209, "cdate": 1761794981209, "tmdate": 1762915823403, "mdate": 1762915823403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TRACE (Transcoder-based Concept Editing), a framework for removing unwanted concepts from text-to-image generative models without retraining. The approach replaces transformation layers between text encoders and generative backbones with transcoders - neural networks that learn sparse, interpretable representations. By identifying and redirecting concept-specific features to null representations, TRACE enables persistent concept removal across both diffusion models (SD3.5, FLUX) and image autoregressive models (Infinity). The method demonstrates superior performance compared to existing baselines, particularly in sequential multi-concept removal scenarios and robustness against adversarial attacks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- It is interesting to see the application of transcoders (originally from LLM interpretability) to visual concept removal.\n- A unified approach to concept removal for both diffusion and autoregressive paradigms."}, "weaknesses": {"value": "- Missing evaluation on NSFW content removal despite being mentioned as a key motivation\n- No discussion of failure modes or limitations when concepts share overlapping features\n- The loss contains multiple components; however, there are no ablation studies to show the effectiveness of each component."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "KEYPDLZwbl", "forum": "yZirk1CoZQ", "replyto": "yZirk1CoZQ", "signatures": ["ICLR.cc/2026/Conference/Submission1581/Reviewer_dLr2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1581/Reviewer_dLr2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1581/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923863444, "cdate": 1761923863444, "tmdate": 1762915823230, "mdate": 1762915823230, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the challenge of trustworthy content moderation in generative image models. Existing approaches either require expensive retraining for each concept to be removed, or rely on post-hoc interventions that are easily bypassed or degrade image quality. To overcome these limitations, the authors propose a white-box, model-agnostic framework that inserts a transcoder module as an integrated, surgical intervention layer. This enables precise and in-place suppression of targeted visual concepts without retraining the underlying generative model. The intervention is embedded directly into the model’s architecture, making it persistent and resistant to circumvention, while maintaining overall image fidelity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I am not a domain expert in concept editing for generative models, but from my perspective, this paper addresses an important and timely problem regarding trustworthy content moderation. The use of transcoders as an integrated intervention mechanism appears novel and technically interesting. The overall writing is clear and logical, making the method and empirical findings easy to follow."}, "weaknesses": {"value": "The comparisons to existing baselines are somewhat limited. It would be helpful to include a broader set of concept removal or safety editing methods, especially more recent ones, to better contextualize the contribution. In addition, the paper does not clearly report the computational cost of training the transcoder (e.g., number of training steps, GPU hours, or hardware used). Providing quantitative training cost estimates would strengthen the claim that the approach is lightweight and scalable."}, "questions": {"value": "See the concerns noted under Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "70EZiljj5N", "forum": "yZirk1CoZQ", "replyto": "yZirk1CoZQ", "signatures": ["ICLR.cc/2026/Conference/Submission1581/Reviewer_6ETn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1581/Reviewer_6ETn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1581/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979726141, "cdate": 1761979726141, "tmdate": 1762915822905, "mdate": 1762915822905, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}