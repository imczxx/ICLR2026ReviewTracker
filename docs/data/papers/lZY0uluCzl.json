{"id": "lZY0uluCzl", "number": 7840, "cdate": 1758038368613, "mdate": 1763618138138, "content": {"title": "Interactive Learning of Single-Index Models via Stochastic Gradient Descent", "abstract": "Stochastic gradient descent (SGD) is a cornerstone algorithm for high-dimensional optimization, renowned for its empirical successes. Recent theoretical advances have provided a deep understanding of how SGD enables feature learning in high-dimensional nonlinear models, most notably the \\emph{single-index model} with i.i.d. data. In this work, we study the sequential learning problem for single-index models, also known as generalized linear bandits or ridge bandits, where SGD is a simple and natural solution, yet its learning dynamics remain largely unexplored. We show that, similar to the optimal interactive learner, SGD undergoes a distinct \"burn-in\" phase before entering the \"learning\" phase in this setting. Moreover, with an appropriately chosen learning rate schedule, a single SGD procedure simultaneously achieves near-optimal (or best-known) sample complexity and regret guarantees across both phases, for a broad class of link functions. Our results demonstrate that SGD remains highly competitive for learning single-index models under adaptive data.", "tldr": "We show that SGD, applied to single-index models (ridge bandits), naturally transitions from a burn-in to a learning phase. With the right step-size schedule, SGD achieves near-optimal regret across both phases for a wide range of link functions.", "keywords": ["single-index model", "stochastic gradient descent", "nonlinear bandit"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1d7e03d6259811c7cc02d3676e004827589bb649.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies a variation of Single Index Models where the features are 'interactive' meaning they depend on the current state of the parameter vector in a specific way and hence the data is not iid. The required sample complexity to learn the unknown parameter vector under SGD is studied. This paper proves sample complexity bounds on estimating the unknown parameter vector to arbitrary precision for a class of link functions which according to other recent works is tight up to poly-logarithmic factors. Additionally for the same set up the authors prove regret bounds. \n\nI think the results shown in this paper are interesting and begin to contribute to filling in the picture of SGD and Single Index Models with different features, however, I think the results are somewhat marginal as there seem to be other very closely related questions regarding sample complexity of these models which are not quite flushed out here. Please see the sections on weaknesses and my questions below. If my concerns can be addressed and I can be convinced that the story is more complete than I currently suspect it to be I would be happy to increase my scores. Currently I think this is a good start to a paper but needs a bit more flushing out to be complete."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper proves novel results for understanding the training dynamics and sample complexity of SGD for Single Index Models with interactive features. The results are novel and demonstrate the value of SGD in this setting. The paper does a good job at explaining their results and the outlines of the proofs which are often otherwise hidden in the appendix."}, "weaknesses": {"value": "The assumptions feel rather restrictive, particularly monotonicity of the link function. There is discussion of the 'necessity' of the monotonicity assumption, however there is not nearly enough detail to convince me that the assumption is necessary. If the assumption is truly necessary for the results it would be nice to have a rigorous negative result such as a counter example demonstrating that a lack of monotonicity will indeed break the conclusion of the proof.\n\nThe relationship of the information exponent in the Gaussian iid feature case is discussed and how the concept does not directly apply to the non-interactive setting. However the information exponent in general relates to the taylor expansion of the population loss and specifically for single index models with iid gaussian data this concept reduces to checking the Hermite coefficients of the link function. It is unsurprising that when the data is not gaussian the Hermite coefficients are no longer important. What would be nice is to consider the original notion of information exponent applied specifically to this problem. For example it is not clear to me that the assumptions (monotonicity and either bounded derivative from below or convexity) do not somehow still just imply information exponent 1 but under a more appropriate definition."}, "questions": {"value": "Do you suspect that there is a similar notion of information exponent for single index models with 'interactive features'? With Gaussian data the sample complexity is of course strongly dependant on the information exponent and can vary widely. Here, only one case is presented: i.e. you can solve the problem with quadratic complexity for the given class of functions. Do you suspect that it is possible to solve the problem for a more general class of link functions given larger sample complexity? Or that outside of the given class you cannot solve the problem? Simulations may be informative as well to answer these questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ttd4YPsVtL", "forum": "lZY0uluCzl", "replyto": "lZY0uluCzl", "signatures": ["ICLR.cc/2026/Conference/Submission7840/Reviewer_6gnD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7840/Reviewer_6gnD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760480715371, "cdate": 1760480715371, "tmdate": 1762919883363, "mdate": 1762919883363, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies a variation of Single Index Models where the features are 'interactive' meaning they depend on the current state of the parameter vector in a specific way and hence the data is not iid. The required sample complexity to learn the unknown parameter vector under SGD is studied. This paper proves sample complexity bounds on estimating the unknown parameter vector to arbitrary precision for a class of link functions which according to other recent works is tight up to poly-logarithmic factors. Additionally for the same set up the authors prove regret bounds. \n\nI think the results shown in this paper are interesting and begin to contribute to filling in the picture of SGD and Single Index Models with different features, however, I think the results are somewhat marginal as there seem to be other very closely related questions regarding sample complexity of these models which are not quite flushed out here. Please see the sections on weaknesses and my questions below. If my concerns can be addressed and I can be convinced that the story is more complete than I currently suspect it to be I would be happy to increase my scores. Currently I think this is a good start to a paper but needs a bit more flushing out to be complete."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper proves novel results for understanding the training dynamics and sample complexity of SGD for Single Index Models with interactive features. The results are novel and demonstrate the value of SGD in this setting. The paper does a good job at explaining their results and the outlines of the proofs which are often otherwise hidden in the appendix."}, "weaknesses": {"value": "The assumptions feel rather restrictive, particularly monotonicity of the link function. There is discussion of the 'necessity' of the monotonicity assumption, however there is not nearly enough detail to convince me that the assumption is necessary. If the assumption is truly necessary for the results it would be nice to have a rigorous negative result such as a counter example demonstrating that a lack of monotonicity will indeed break the conclusion of the proof.\n\nThe relationship of the information exponent in the Gaussian iid feature case is discussed and how the concept does not directly apply to the non-interactive setting. However the information exponent in general relates to the taylor expansion of the population loss and specifically for single index models with iid gaussian data this concept reduces to checking the Hermite coefficients of the link function. It is unsurprising that when the data is not gaussian the Hermite coefficients are no longer important. What would be nice is to consider the original notion of information exponent applied specifically to this problem. For example it is not clear to me that the assumptions (monotonicity and either bounded derivative from below or convexity) do not somehow still just imply information exponent 1 but under a more appropriate definition."}, "questions": {"value": "Do you suspect that there is a similar notion of information exponent for single index models with 'interactive features'? With Gaussian data the sample complexity is of course strongly dependant on the information exponent and can vary widely. Here, only one case is presented: i.e. you can solve the problem with quadratic complexity for the given class of functions. Do you suspect that it is possible to solve the problem for a more general class of link functions given larger sample complexity? Or that outside of the given class you cannot solve the problem? Simulations may be informative as well to answer these questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ttd4YPsVtL", "forum": "lZY0uluCzl", "replyto": "lZY0uluCzl", "signatures": ["ICLR.cc/2026/Conference/Submission7840/Reviewer_6gnD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7840/Reviewer_6gnD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760480715371, "cdate": 1760480715371, "tmdate": 1763577676050, "mdate": 1763577676050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the author study the time/sample complexity of learning single-index models when the learner is allowed \nto query a specific, instead of random, point. They show that a simple SGD-type algorithm can achieve the best-known \nbounds on this problem, under the assumption that (1) the target function is monotone and has a nonzero derivative \nat $0$, or (2) the target function is convex. \nAt each step, the algorithm queries the reward/target value at a perturbed version of the current weight and update the \nweight using the (spherical) SGD. The size of the perturbation controls the exploration-exploitation trade-off: \nIn the burn-in stage ($1/\\sqrt{d}$ to constant correlation) and the exploration stage (constant correlation to $1 - o(1)$\ncorrelation), larger perturbations are used, and in the final exploitation stage (minimizing the regret in the $1 - o(1)$\ncorrelation regime), a small perturbation is used."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* Overall, this is a well-written paper and is easy-to-follow. In addition, it is short (19 pages), which is a nice and \n  rare thing for a theory paper to have.\n* It is somewhat surprising that how being able to choose the position of the query greatly simplifies the analysis and \n  improves the bounds (when the label noise is large). They choose the next query position $a_t$ to be a weighted average \n  of the current weight $\\theta_t$ and a noise that is *orthogonal* to the current weight. This makes the \n  $f( \\theta_t \\cdot a_t )$ part deterministic. Together with the monotonicity/convexity assumption, the analysis \n  becomes much cleaner than the usual analysis."}, "weaknesses": {"value": "This is a neat paper that does everything the authors claim to achieve, so I do not think there is any major weakness,\nthough one could complain that the setting is too easy. Nevertheless, the following are a few complaints I have. \n\n* As someone who is more familiar with IE/Gaussian single-index models, I found the $\\tilde{O}(d^2)$ bounds really \n  confusing until I realized that the scaling is different, as the non-interactive bounds are $\\tilde{O}(d)$. It \n  might be better to point this out early on, instead of putting the discussion in the Related Work section and \n  Section 5.\n* The comparison with the information exponent results is not entirely fair, as the discrepancy comes mainly from the \n  label noises $\\epsilon_t$. Without the label noise (i.e., we have access to $f(\\theta^*, a)$), the IE bounds are \n  invariant under rescaling. It seems that being able to choosing the query point does not lead to improvements in \n  the no-label-noise setting. Moreover, if the link function is $f(x)=x^{2q}$ for some positive integer $q$ (the convex \n  setting), the IE is $2$, so the IE bound is $\\tilde{O}(d)$, while Theorem 2(2) depends on $1/f'(1/\\sqrt{d})$, which \n  can be large when $q$ is large."}, "questions": {"value": "* See the 2nd point of the weakness section. In particular, how do your bounds depend on the size of the label noise?\n  Can they recover/improve over the usual IE bounds when there are no label noises or the label noise is small?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BMhtJ6ciAO", "forum": "lZY0uluCzl", "replyto": "lZY0uluCzl", "signatures": ["ICLR.cc/2026/Conference/Submission7840/Reviewer_Veb4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7840/Reviewer_Veb4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761287093615, "cdate": 1761287093615, "tmdate": 1762919882913, "mdate": 1762919882913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers interactive SGD for single-index bandit problems where the reward is a potentially non-linear function of the dot-product between the current and optimal actions. The paper analyses both a burn-in phase to get a constant dot-product, and a learning phase which starts from a warm-start initialization and achieves a $\\tilde{O}(d^2/\\varepsilon)$ sample-complexity and $\\tilde{O}(d\\sqrt{T})$ regret."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "While there is now a rich literature for learning single-index models in the supervised setting, I believe the literature on online/bandit settings is more sparse. Therefore, the problem that this paper wants to tackle is novel and of importance to the community. Also, the paper is explicit about its assumptions and it is generally easy to read and follow."}, "weaknesses": {"value": "My main concerns are the following:\n* In the pure exploration case $\\sigma_t = 1$, this algorithm is the same as one-pass SGD studied by Ben Arous et al., 2021. However, the sample complexity seems to be worse. Due to the monotonicity of $f$ (hence information exponent 1), the sample complexity of (pure exploration) SGD would scale linearly with $d$ (at least in the noiseless setting, but I believe it should be able to tolerate $O(1)$ i.i.d. noise as well). However, the bound of Theorem 1 (SGD with warm-start initialization) scales with $O(d^2)$ and that of Corollary 1 can be as large as $O(d^p)$ for $f(x) = x^p$. It might be plausible that to get sub-linear regret, one should ultimately settle for a worse sample complexity, but if that's the case it should be better highlighted.\n\n* The argument of Section 5 only shows that $f$ needs to be monotone around $m \\approx 1$, and one can drive $m$ towards $1$ by pure exploration. This accommodates higher order Hermite polynomials, e.g. $H\\_2,H\\_6,...$. It would be interesting to know the effect of high information exponent in such cases."}, "questions": {"value": "* I think it would be very useful if the schedule of $\\sigma_t$ could be presented more explicitly for regret minimization in Corollary 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xxOsSxRW6b", "forum": "lZY0uluCzl", "replyto": "lZY0uluCzl", "signatures": ["ICLR.cc/2026/Conference/Submission7840/Reviewer_zDB6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7840/Reviewer_zDB6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135916803, "cdate": 1762135916803, "tmdate": 1762919882602, "mdate": 1762919882602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall response"}, "comment": {"value": "We thank all reviewers for the valuable comments. We acknowledge that some distinctions may not have been communicated clearly in the current draft, and we have uploaded a revision (with changes in blue) for better clarifications. \n\nBefore providing a point-to-point response to each of your comments, we’d like to clarify some of the confusions and misunderstandings you may have about our work. \n\n1. The interactive learning of single-index models is **fundamentally different** from the non-interactive case: in the interactive case, even the statistical (i.e. information-theoretic) complexity becomes challenging. As was witnessed in [Rajaraman et al. 2024], interactive learning in single-index models (or non-linear bandits) exhibits two distinct phases, i.e. the burn-in phase and the learning phase. The main results of [Rajaraman et al. 2024] include: \n\n- Interaction reduces the statistical complexity of the burn-in phase in an adaptive manner, where the optimal learning trajectory is sandwiched between two differential equations (cf. Theorem 1.1 and 1.2 of [Rajaraman et al. 2024]). In contrast, any non-interactive algorithm follows a “linear” trajectory and can be strictly suboptimal (Theorem 4.1 in [Rajaraman et al. 2024]).\n\n- While many classical algorithms (UCB, regression-based methods, etc) achieve optimal performance in the learning phase, they are strictly suboptimal for the burn-in phase. Consequently, new algorithmic ideas are necessary for the burn-in phase.\n\nFor a more detailed overview of these findings, we refer the reader to the introduction of [Rajaraman et al. 2024]. In view of these existing results, our new results on SGD for the same task are surprising for several reasons:\n\n+ Statistical: For a subclass of link functions (e.g., convex), SGD matches the best-known sample complexity bounds of [Rajaraman et al. 2024] in the interactive setting. In particular, the SGD trajectory in the burn-in phase is adaptive (taking an integral form). Unlike UCB which is provably suboptimal during the burn-in phase, SGD achieves optimal performance in this phase for many link functions.\n\n+ Algorithmic: Despite its simplicity, our SGD method differs fundamentally from existing interactive burn-in algorithms. As discussed in Section 5, our formulation yields an unbiased estimator of the population gradient, unlike the noisy gradient estimators in the zeroth-order approach of [Huang et al. 2021]. Moreover, the burn-in algorithm in [Rajaraman et al. 2024] relies on a complex hypothesis-testing routine. Finally, SGD achieves optimal performance in both the burn-in and learning phases simultaneously, whereas [Rajaraman et al. 2024] employs distinct algorithms for each phase. This makes SGD an appealing and unified solution for interactive single-index learning. \n\nReferences: \n\n[Huang et al. 2021] Huang, B., Huang, K., Kakade, S., Lee, J. D., Lei, Q., Wang, R., & Yang, J. (2021). Optimal gradient-based algorithms for non-concave bandit optimization. Advances in Neural Information Processing Systems, 34, 29101-29115.\n\n[Rajaraman et al. 2024]: Rajaraman, N., Han, Y., Jiao, J., & Ramchandran, K. (2024). Statistical complexity and optimal algorithms for nonlinear ridge bandits. The Annals of Statistics, 52(6), 2557-2582."}}, "id": "C8RVJHRQoq", "forum": "lZY0uluCzl", "replyto": "lZY0uluCzl", "signatures": ["ICLR.cc/2026/Conference/Submission7840/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7840/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7840/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763566775730, "cdate": 1763566775730, "tmdate": 1763567271143, "mdate": 1763567271143, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers interactive SGD for single-index bandit problems where the reward is a potentially non-linear function of the dot-product between the current and optimal actions. The paper analyses both a burn-in phase to get a constant dot-product, and a learning phase which starts from a warm-start initialization and achieves a $\\tilde{O}(d^2/\\varepsilon)$ sample-complexity and $\\tilde{O}(d\\sqrt{T})$ regret."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "While there is now a rich literature for learning single-index models in the supervised setting, I believe the literature on online/bandit settings is more sparse. Therefore, the problem that this paper wants to tackle is novel and of importance to the community. Also, the paper is explicit about its assumptions and it is generally easy to read and follow."}, "weaknesses": {"value": "My main concerns are the following:\n* In the pure exploration case $\\sigma_t = 1$, this algorithm is the same as one-pass SGD studied by Ben Arous et al., 2021. However, the sample complexity seems to be worse. Due to the monotonicity of $f$ (hence information exponent 1), the sample complexity of (pure exploration) SGD would scale linearly with $d$ (at least in the noiseless setting, but I believe it should be able to tolerate $O(1)$ i.i.d. noise as well). However, the bound of Theorem 1 (SGD with warm-start initialization) scales with $O(d^2)$ and that of Corollary 1 can be as large as $O(d^p)$ for $f(x) = x^p$. It might be plausible that to get sub-linear regret, one should ultimately settle for a worse sample complexity, but if that's the case it should be better highlighted.\n\n* The argument of Section 5 only shows that $f$ needs to be monotone around $m \\approx 1$, and one can drive $m$ towards $1$ by pure exploration. This accommodates higher order Hermite polynomials, e.g. $H\\_2,H\\_6,...$. It would be interesting to know the effect of high information exponent in such cases."}, "questions": {"value": "* I think it would be very useful if the schedule of $\\sigma_t$ could be presented more explicitly for regret minimization in Corollary 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xxOsSxRW6b", "forum": "lZY0uluCzl", "replyto": "lZY0uluCzl", "signatures": ["ICLR.cc/2026/Conference/Submission7840/Reviewer_zDB6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7840/Reviewer_zDB6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135916803, "cdate": 1762135916803, "tmdate": 1763596311383, "mdate": 1763596311383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}