{"id": "Lt7VDm7zTL", "number": 22725, "cdate": 1758334807837, "mdate": 1759896850396, "content": {"title": "Balancing Plasticity and Stability with Fast and Slow Successor Features", "abstract": "A hallmark of intelligence is the ability to adapt in non-stationary environments, yet deep Reinforcement Learning (RL) agents often struggle in such settings. Most prior studies introduce non-stationarity through abrupt shifts in features or dynamics, whereas real-world changes might be more gradual and continuous. Moreover, existing methods have largely attributed these struggles to either plasticity or stability loss at the level of Q-values, yet it remains unclear how these factors affect representations such as Successor Features (SFs). To address these concerns, we modify existing 3D Miniworld and MuJoCo environments to incorporate continuous non-stationary changes and use them to identify whether poor performance arises from a loss of plasticity or stability. We find that methods preserving stability, such as synaptic consolidation, achieve better performance than those focused on plasticity. Motivated by this finding, and prior evidence that SFs reduce interference in non-stationary settings, we investigate whether SFs provide a better target than Q-values for consolidation. Across both environments, we find that applying a neuro-inspired synaptic consolidation mechanism to SFs yields superior performance. To better understand the benefits of consolidating SFs, we conduct a cross-attention analysis to probe the relative contributions of the consolidation variables. We find that consolidation is most effective when SFs are stabilized across multiple timescales, as different timescales capture complementary aspects of learning. Together, these results show that multi-timescale consolidation of predictive representations is critical for robust RL in continuous non-stationary environments.", "tldr": "", "keywords": ["successor features", "deep reinforcement learning", "synaptic consolidation", "plasticity", "stability"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cf6af4141ab621b54b0c383198b3212e80f61a51.pdf", "supplementary_material": "/attachment/2b68a81812807b445cf4fdda92c739dc44079a3a.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes the use of successor features (SF) along with synaptic consolidation(SC) for the stability-plasticity tradeoff. It shows that consolidation is more effective when done on parameters of SF rather than Q-values, in DQN and DDPG.\nIt also compares their method (SF+SC) with baselines that either generally help with stability (e.g., elastic weight consolidation or synaptic consolidation) or plasticity (continual backprop or plasticity injection) and shows that their method outperforms in most cases.\nIt also motivates the use of environments where change happens gradually over time, not abruptly, and uses those settings throughout the experiments."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation to use environments that reflect the natural, gradual change, as they occur in real-world settings, is valuable.\n\n2. The paper is well-written,  covers the related literature, and the idea to apply consolidation to SF instead of Q-values is relatively simple and potentially helpful."}, "weaknesses": {"value": "1. The paper emphasizes the importance of stability in the experiments; however, stability and plasticity are not decoupled and evaluated quantitatively in the paper. As mentioned in the paper, some methods help more with plasticity, and some more with stability. However, it is valid but incomplete to determine which one performs better in an experiment and conclude that the underlying reason for failure is what the method is designed to address. It would help to define some metrics for plasticity (e.g., how fast the agent adapts after a change in the environment) and stability (e.g., forgetting, or performance drop in a familiar previous setting after being trained on new data), to support the idea that stability is playing a more crucial role.\n\n2. Environments without task boundaries are motivated in the paper, but in the four rooms experiments, two tasks are defined on top of the gradual non-stationarity, and the agent goes through a multi-task environment. Also, most of the agents reach a good performance in each task at the end of the task duration, which suggests that the non-stationarity generated by the slippery actions does not create a dynamic complex enough to break the agents' performance. How can you modify this environment such that it’s still a challenging and suitable testbed for gradual non-stationary, and without the notion of tasks?\n\n3. The paper would benefit from statistical tests, e.g., for the bar plots, especially since the number of seeds is limited.\n\nMinor comments:\n1. Continuous may not be a good word for referring to the types of environments aimed at in this paper. continual, natural non-stationary, or gradual might be better, as continuous environments might be mistaken with environments with continuous action spaces as opposed to discrete.\n\n2. It would be helpful to add a comparison of the computational complexity of the methods.\n\n3. Please cite some of the previous work that proposes or uses environments with gradual change, and without task boundaries, for continual/lifelong reinforcement learning."}, "questions": {"value": "1. What metrics could be used to quantitatively measure plasticity and stability, beyond learning curves or AUC of episodic returns? \n\n2. Why is CBP missing from the baselines in the Four Rooms experiment?\n\n3. Some mitigation methods perform worse than the vanilla DQN or DDPG baselines (e.g., DDPG + P-last in the mujoco environments). Could you clarify why this might happen, and whether it is a tuning problem or is inherent to the algorithm?\n\n4. In Figure 5, the legend lists six agents, but subfigure (a) appears to include seven curves. What does the pink line show?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ccgF9AtN3j", "forum": "Lt7VDm7zTL", "replyto": "Lt7VDm7zTL", "signatures": ["ICLR.cc/2026/Conference/Submission22725/Reviewer_P8uF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22725/Reviewer_P8uF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761696752320, "cdate": 1761696752320, "tmdate": 1762942359526, "mdate": 1762942359526, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses continual reinforcement learning in environments with continuous non-stationarity, rather than the typical discrete task boundaries. The authors modify 3D Four Rooms and MuJoCo environments to incorporate smoothly changing dynamics using noisy sine functions. They investigate whether poor performance stems from loss of plasticity or stability, finding that stability-preserving methods outperform plasticity-focused ones. The main contribution is combining Successor Features (SFs) with a neuro-inspired synaptic consolidation mechanism across multiple timescales, which outperforms consolidating Q-values directly."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an important problem - real-world environments change gradually, not abruptly. The experimental design fairly compares stability vs plasticity mechanisms without requiring task boundary information, which is more realistic. The finding that stability matters more than plasticity in continuous settings contradicts recent emphasis on plasticity loss, providing valuable empirical insights.\n\n2. The use of multi-timescale consolidation (not just dual fast/slow) is more biologically plausible and the cross-attention analysis provides useful interpretability about which timescales contribute to learning. The authors are honest about limitations - reporting when complex embodiments don't benefit from their approach adds credibility. The biological inspiration from synaptic consolidation provides a principled framework for thinking about memory consolidation in RL."}, "weaknesses": {"value": "1. The environments remain relatively simple - continuous mass changes or slip probabilities don't fundamentally alter task structure. Performance changes are often modest and inconsistent across environments. \n\n2. The paper lacks theoretical justification for why SF consolidation should outperform Q-value consolidation. The technical novelty is limited - essentially swapping Q-values with SFs in an existing consolidation mechanism. The choice of noisy sine functions seems arbitrary, and testing only one type of non-stationarity per environment (mass in MuJoCo, action replacement in Four Rooms) limits generalizability claims."}, "questions": {"value": "1. How sensitive are the results to the specific form of continuous non-stationarity? Have you tested with other continuous functions beyond noisy sines?\n\n2. What's the computational overhead of maintaining multiple consolidation variables compared to baseline methods?\n\n3. Can you provide theoretical insight into when SF consolidation should outperform Q-value consolidation?\n\n4. Could you clarify the reparameterization trick used for training with analytically computed consolidation variables?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EEk4jZ2Tw0", "forum": "Lt7VDm7zTL", "replyto": "Lt7VDm7zTL", "signatures": ["ICLR.cc/2026/Conference/Submission22725/Reviewer_an5Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22725/Reviewer_an5Z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725734834, "cdate": 1761725734834, "tmdate": 1762942359302, "mdate": 1762942359302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies continual RL under continuous (rather than abrupt) non-stationarity and argues that stability is the principal bottleneck, and not plasticity. The authors employ the Successive Features (SF) framework for RL and propose to adapt the neuro-inspired consolidation mechanisms of Benna et al. (2016) to stabilise the feature themselves (as opposed to consolidate the synapses). They show via several experiments that consolidation of SF yields superior performances/learning efficiency than either plasticity-injection models or stabilisation of Q-function/policies in environments that experience continuous changes. Ablation studies highlight the importance of multi-scale stabilisation for performance, while a cross-attention analysis on the use of the SF suggests complementary roles of fast- and slow-consolidation variables."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This work represents a welcomed and timely contribution to the field of continuous learning in variable environments. The focus on continuous non-stationarity is a realistic and improves on other techniques that relied on clearly defined task-boundaries. Of particular importance is the result that targeting predictive representations (SFs) for multi-timescale synaptic consolidation under continuous non-stationarity is more effective than stabilizing Q-functions/policies.\n\nIn general, the authors provided comparisons with multiple baselines (P-last, CBP, EWC, SC) and metrics (AUC, sample steps), strengthening their case that SF+SC offers excellent performance across the different tasks and environments tested. Furthermore, the paper is well written and executed, with clear figures and explicit questions that clarify the goal of the presented experiments."}, "weaknesses": {"value": "While I believe this work represents a valuable contribution and is already above acceptance level at the current stage, I have listed some weakness/limitations I noticed and I would be happy to raise my score if the author could address them.\n\n1. Author used DDPG as the primary continuous-control baseline. However, DDPG can be less robust to than other actor-critic techniques (TD3, SAC), which may understate the competitiveness of Q- or policy-centric stabilization.\n2. The paper argues that SGD is necessary to preserve timescales (Appendix B), but it is unclear whether all compared methods (EWC, CBP, plasticity injections) were trained under exactly the same optimizer/step-size schedules. Fair comparisons require an explicit fixed choice across methods (or provide evidence of robustness against optimizer change).\n3. The authors argues that replay-based approaches are problematic because “new vs. old” becomes ill-defined without task boundaries. However, there exists several variants (Kim et al., 2020, Chen & Lin, 2021) that relax such constraints and enable replay-based continual learning without knowledge of explicit task-boundaries. It would have thus be helpful to see how the author's approach stack against such baselines.\n\n----------\n### Typos:\n- L189: $w$ should be bold"}, "questions": {"value": "1. The noisy sinusoidal drift is periodic and potentially predictable. Could this fact be a factor in explaining why preserving SFs is more efficient? Would the situation change if we start to include non-periodic/stochastic drifts?\n2. In the experiments consolidation capacity $C_k$ is always fixed to a single choice of scaling, as well as the flow rates $g_{1,2}$. How important are this parameters for the success of the algorithm?\n3. Does SF + SC act only on the last layer (SF head), or do you consolidate earlier representation layers as well? If only on the head, is the drift in deeper representations negligible or mitigated indirectly?\n4. Since SC is inspired by synaptic consolidation models, have you analyzed whether the timescales learned by SF + SC correspond to biologically plausible values (e.g., logarithmically spaced memory decay constants)?\n5. The environments use a noisy sinusoidal drift for dynamics. How sensitive are your conclusions (e.g., superiority of SC over EWC) to the amplitude and frequency of the drift? Is there a regime in which plasticity injection becomes competitive again?\n6. Do you have an intuition for *why* SF are better suited for consolidation (maybe lower variance?)?\n7. What is the computational cost of SC compared to standard EWC? Are there measurable differences in GPU memory or update latency as K increases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SYzYWf2iQk", "forum": "Lt7VDm7zTL", "replyto": "Lt7VDm7zTL", "signatures": ["ICLR.cc/2026/Conference/Submission22725/Reviewer_PeYf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22725/Reviewer_PeYf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914117266, "cdate": 1761914117266, "tmdate": 1762942359069, "mdate": 1762942359069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the stability-plasticity tradeoff in deep RL under continuous non-stationary environments. The authors modify existing benchmarks (3D Miniworld Four Rooms, MuJoCo) to incorporate gradual dynamics changes via noisy sine functions. They find that stability (via synaptic consolidation) is more critical than plasticity (via parameter resets), and propose consolidating Successor Features (SFs) across multiple timescales. The approach outperforms consolidating Q-values and plasticity-focused methods. A cross-attention analysis reveals that faster timescales contribute more to learning, though this mechanism only improves simpler embodiments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Continuous non-stationarity is a more realistic and understudied problem formulation compared to discrete task boundaries commonly used in continual learning; the gradual dynamics changes via noisy sine functions better reflect real-world scenarios\n- Comprehensive experimental validation across two environments and multiple embodiments consistently demonstrates SF+SC superiority over both Q-value consolidation and plasticity injection methods"}, "weaknesses": {"value": "- Limited technical novelty as the work primarily combines two existing techniques (Successor Features and synaptic consolidation); the contribution is largely empirical without new algorithmic insights\n- Experiments confined to relatively simple domains with state-based observations; scalability to high-dimensional spaces (pixel-based observations, complex robotics) remains unclear and untested"}, "questions": {"value": "- Can you test on at least one high-dimensional domain (e.g., pixel-based Atari with continuous dynamics changes) to demonstrate the approach scales beyond state-based control?\n- Why does the cross-attention mechanism fail for complex embodiments (Humanoid, Quadruped)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uBMflT5Owk", "forum": "Lt7VDm7zTL", "replyto": "Lt7VDm7zTL", "signatures": ["ICLR.cc/2026/Conference/Submission22725/Reviewer_DS9m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22725/Reviewer_DS9m"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762259930407, "cdate": 1762259930407, "tmdate": 1762942358750, "mdate": 1762942358750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}