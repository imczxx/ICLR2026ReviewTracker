{"id": "62uxwRcvGr", "number": 20458, "cdate": 1758306382234, "mdate": 1759896976607, "content": {"title": "ECHOSAT: Estimating Canopy Height Over Space And Time", "abstract": "Forest monitoring is critical for climate change mitigation. However, existing global tree height maps provide only static snapshots and do not capture temporal forest dynamics, which are essential for accurate carbon accounting. We introduce ECHOSAT, a global and temporally consistent tree height map at 10m resolution spanning multiple years. To this end, we resort to multi-sensor satellite data to train a specialized vision transformer model, which performs pixel-level temporal regression. A self-supervised growth loss regularizes the predictions to follow growth curves that are in line with natural tree development, including gradual height increases over time, but also abrupt declines due to forest loss events such as fires. Our experimental evaluation shows that our model improves state-of-the-art accuracies in the context of single-year predictions. We also provide the first global-scale height map that accurately quantifies tree growth and disturbances over time. We expect ECHOSAT to advance global efforts in carbon monitoring and disturbance assessment. The produced height maps will be made accessible upon acceptance.", "tldr": "We present the first global temporal tree height map. Our map uses a novel loss function targeted at learning tree growth inherently from sparse labels.", "keywords": ["remote sensing", "application", "transformer", "tree height", "climate change", "satellite", "pixel-wise regression"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d6a95947e503ba932dfe79524758124c08a7f92b.pdf", "supplementary_material": "/attachment/45163dd4078893c50e0e09b8803af15131445a77.zip"}, "replies": [{"content": {"summary": {"value": "The authors present ECHOSAT, the first spatio-temporal global-scale canopy height map at 10m resolution spanning seven years. They exploit multi-source satellite imagery to train a vision transformer that performs pixel-wise temporal regression with an adapted loss function designed for sparse temporal supervision. Analyses demonstrate that the model outperforms competing methods in single-date evaluations and that it learns realistic forest height dynamics over time."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The downstream application of canopy height estimation for large-scale biomass estimation is relevant and important for climate change understanding and mitigation.\n\n2. Introducing optical and SAR time series for canopy height estimation at global scale and 10m resolution to include forest dynamics is a novelty and relevant for the task.\n\n3. The design of the proposed Growth loss is a novelty and inspired by domain knowledge from the field of application. It accounts for potential forest disturbances, addresses missing LiDAR ground truth by filling gaps with regressions, employs constrained piecewise linear regressions to generate pseudo-labels, and combines real and pseudo-labels. \n\n4. An analysis of canopy growth and decline is provided (Section 4.2, Figure 2) thanks to the integration of time series. This contribution is well appreciated and could open discussions for future work."}, "weaknesses": {"value": "1. There is a clear lack of related work on: 1/ spatio-temporal methods for remote sensing that have shown to learn spatio-temporal dynamics on various tasks [1, 2, 3], and 2/ remote sensing foundation models pretrained on large-scale optical and SAR datasets [4, 5, 6], sometimes used for downstream forest monitoring applications [6, 7]. One may note that these methods could be leveraged either as a starting point for architecture design or for canopy height estimation fine-tuning. \n\n2. Similarities and differences with other time series-based methods for forest monitoring remote sensing applications [8, 9, 10] have not been discussed. \n\n3. There is a clear lack of ablation studies to understand whether the performance gain comes from the architecture selection or the loss function design. 1/ One would appreciate a comparison of the Growth loss in its final form with a simpler formulation using a single linear regression, and with losses from competing works such as standard MSE. 2/ There is no comparison with simple competing methods (e.g., U-Net) combined with the Growth loss. 3/ It would have been appreciated to compare other architectures to the Temporal-Swin-Unet to better understand its relative performance gain, such as a 3D U-Net [11] or remote sensing-based architectures as mentioned above. \n\n4. The authors did not provide standard deviations of their quantitative results in Table 1, questioning the actual gain compared to competing methods. One may question the actual gain of the proposed method compared to Pauls et al. [12]: the proposed method achieves better performance on average, while absolute values of both methods are comparable, and Table 6 shows average errors per tree height that are similar within similar box plot interquartile ranges.\n\n5. One would question the hypothesis of excluding labels below 5m according to Hansen et al. methodology [13] since: 1/ this guideline has not been followed by other competing methods, 2/ specific metrics for tree heights < 5m and > 5m could be easily defined to better distinguish use cases, and 3/ estimating tree heights < 5m is an actual use case for monitoring recent forest restoration projects through time. While all competing methods provide predictions < 5m (Table 4, right), it is not clear why the authors exclude this particular use case, whereas it represents a significant use case where the margin for improvement seems reasonable and would be useful. \n\n6. There is a lack of explanation about the train, validation, and test split definitions that must be clarified to avoid significant issues. As an example, the methodology followed by Pauls et al. [12] is questionable since the splits have been defined by random patches that could introduce data leakage between the train and test sets through spatial autocorrelation. \n\n7. The authors neither mention limitations of their work nor provide pathways to future work.\n\n**References**:\n\n[1] V. Sainte Fare Garnot & L. Landrieu, Panoptic Segmentation of Satellite Image Time Series with Convolutional Temporal Attention Networks. In ICCV 2021.\n\n[2] M. Tarasiou et al., ViTs for SITS: Vision Transformers for Satellite Image Time Series. In CVPR 2023.\n\n[3] G. Tseng et al., Lightweight, Pre-trained Transformers for Remote Sensing Timeseries. In ArXiv 2024.\n\n[4] A. Fuller et al., CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders. In NeurIPS 2023\n\n[5] G. Tseng et al., Galileo: Learning Global & Local Features of Many Remote Sensing Modalities. In ICML 2025.\n\n[6] G. Astruc et al., AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities. In CVPR 2025.\n\n[7] N. Bountos et al., FoMo: Multi-Modal, Multi-Scale and Multi-Task Remote Sensing Foundation Models for Forest Monitoring. In AAAI 2025.\n\n[8] T. Nguyen et al., Multi-temporal forest monitoring in the Swiss Alps with knowledge-guided deep learning. In Remote sensing of environment 2024.\n\n[9] K. Wu et al., A semantic-enhanced multi-modal remote sensing foundation model for Earth observation. In Nature machine intelligence 2025.\n\n[10] Z. Yu et al., QRS-Trs: Style Transfer-Based Image-to-Image Translation for Carbon Stock Estimation in Quantitative Remote Sensing. In EEEI Access 2025.\n\n[11] O. Cicek et al., 3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation. In MICCAI 2016.\n\n[12] Pauls et al., Estimating Canopy Height at Scale. In ICML 2024.\n\n[13] Hansen et al., High-resolution global maps of 21st-century forest cover change. In Science 2013."}, "questions": {"value": "**Questions:**\n\n1. What is the quantitative gain of the piecewise linear regressions versus using a single linear regression in the Growth loss function? \n\n2. Is the model trained from scratch or from pretrained weights? If it is trained from scratch or pretrained on natural image-based datasets, why did the authors not consider exploiting various remote sensing backbones pretrained on large-scale optical and SAR datasets? Note that some of them are actually designed to exploit time series [1, 2, 3, 4]. \n\n3. Height estimation is a proxy for biomass estimation, which is the most important downstream application. In this work and related work, errors are mostly quantified via height estimation. However, what would be the equivalent of the height error in biomass estimation? Since the global allometric equation is not linear, this link is not straightforward and has been barely studied in previous canopy height map estimation works. Where are the biomass errors most important (small, medium, large trees) in average and absolute values? \n\n4. Considering the increasing number of UAV LiDAR datasets [5, 6, 7], why did the authors not attempt to better evaluate methods on more precise datasets than GEDI-based annotations?\n\n\n**Comments:**\n\n• Please add numbers to relevant equations on page 5.\n\n• One would appreciate integrating Figure 6 into the main paper, as the presented results are valuable and insightful.\n\n• L. 353: \"For 2019-2022, MAE values range from 5.36 m to 6.27 m, indicating consistent prediction accuracy.\" One may consider softening this claim since a 5-6m error on trees between 10-30m is quite significant for estimating their biomass.\n\n• Section 4.1: One would appreciate an additional analysis of errors through time per tree height range, similar to Table 6.\n\n• Figure 5: Please integrate a few GEDI LiDAR point clouds within the same color scale on the Google Map images to better understand the order of magnitude of the ground truth. With the current form of the figure, we can visually observe the difference in resolutions but cannot assess the quality of height predictions.\n\n\n**References:**\n\n[1] M. Tarasiou et al., ViTs for SITS: Vision Transformers for Satellite Image Time Series. In CVPR 2023.\n\n[2] G. Tseng et al., Lightweight, Pre-trained Transformers for Remote Sensing Timeseries. In ArXiv 2024.\n\n[3] G. Tseng et al., Galileo: Learning Global & Local Features of Many Remote Sensing Modalities. In ICML 2025.\n\n[4] K. Wu et al., A semantic-enhanced multi-modal remote sensing foundation model for Earth observation. In Nature machine intelligence 2025.\n\n[5] S. Puliti et al., FOR-instance: a UAV laser scanning benchmark dataset for semantic and instance segmentation of individual trees. In ArXiv 2023.\n\n[6] B. Xiang et al., ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest  LiDAR 3D Point Clouds. In ICCV 2025.\n\n[7] M. Wielgosz et al., SegmentAnyTree: A sensor and platform  agnostic deep learning model for tree  segmentation using laser scanning data. In Remote Sensing of Environment 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "A2YjQsK2O0", "forum": "62uxwRcvGr", "replyto": "62uxwRcvGr", "signatures": ["ICLR.cc/2026/Conference/Submission20458/Reviewer_c1mT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20458/Reviewer_c1mT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761334691683, "cdate": 1761334691683, "tmdate": 1762933899907, "mdate": 1762933899907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SUMMARY: The paper focuses on the task of temporal tree canopy height estimation from remotely sensed data. As the authors outline, this task is relevant for global forest monitoring and directly impacts downstream applications like carbon stock or sequestration estimates. The authors aim to provide a global map - and the first map over time, allowing users to assess changes. Methodologically, the authors propose a new neural net architecture to model tree height, the Temporal-Swin-Unet. This is a combination of two existing methods, the Video Swin Transformer and the Swin Unet. The authors then evaluate their approach by comparing it to existing global tree height maps, showing consistently improved accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "STRENGTHS:\nI particularly enjoyed the following aspects of the paper:\n- The paper is well motivated and tackles an incredibly important real-world task that is clearly suited for ML/vision models.\n- The paper is very well written; it is easy to understand and has a good / intuitive flow.\n- Part of that is the papers simplicity; the paper (mostly, exceptions below) has a great balance of depth and simplicity; the proposed methodological advancement is simple but quite elegant and well motivated by the problem setting."}, "weaknesses": {"value": "SHORTCOMINGS:\n\nI have two major concerns with the current draft of the manuscript:\n\n- Part of the \"growth loss\" is the disturbance indicator. The paragraph introducing it is too short and it is unclear how the disturbance indicator motivated? choice of thresholds here seem arbitrary? The authors say that \"A disturbance is considered to occur in zref ∈ RY when a) tree height decreased by more than 50% and more than 4 m and b) tree height decreased to less than 10 m within two years.\" (line 224), but the choice for these numbers are not explained at all and seem arbitrary. I assume there is some sort of expert knowledge behind them but this NEEDS to be explained!\n\n- Crucial experiments on the performance over space and time are missing. It would be very important to know if the method performs equally well everywhere on the planet, or whether there are areas of higher and lower performance. This should follow e.g. the analysis in [1] (see Extended Data Fig. 1 in [1]). This sort of knowledge is very important for on-the-ground practitioners. Secondly, an analysis of the performance over time would be equally interesting / important. I see that the authors say that \"Due to the sparse temporal and spatial distribution of GEDI labels, a temporal validation with GEDI is not possible. \" (line 366) - What is meant by this exactly? Are GEDI labels not spatio-temporally aligned (e.g. a given location only occurs on one time step)? You should still be able to assess temporal performance by averaging errors for a given time step. Am I missing something?\n\n- A more minor point is that I would like to see some discussion of the applicability of the method to local height mapping problems. Specifically [2] argues that these sort of global tree height maps fall short of being actually useful in many local applications. I would be curious how the authors contextualize their work within this critique."}, "questions": {"value": "Overall this a paper tackling a relevant real-world problem and introducing an intuitive new method. I'd ask the authors to consider my questions and concerns in the \"weaknesses\" section. \n\nReferences:\n\n[1] Lang, Nico, et al. \"A high-resolution canopy height model of the Earth.\" Nature Ecology & Evolution 7.11 (2023): 1778-1789.\n\n[2] Rolf, Esther, et al. \"Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas.\" arXiv preprint arXiv:2411.14354 (2024)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KbybEJMh2Q", "forum": "62uxwRcvGr", "replyto": "62uxwRcvGr", "signatures": ["ICLR.cc/2026/Conference/Submission20458/Reviewer_G5Vh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20458/Reviewer_G5Vh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761596673175, "cdate": 1761596673175, "tmdate": 1762933899295, "mdate": 1762933899295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces *ECHOSAT*, a global 10m tree canopy height time series spanning 2018–2023. A Vision Transformer performs pixel-level temporal regression on multi-year satellite imagery (Sentinel-2, Landsat) and sparse GEDI height labels. A novel growth loss is introduced to regularize predictions to follow realistic tree dynamics (gradual growth, sudden loss from fires/logging) without need for post-processing. The model improves over prior single-year SOTA methods on held-out GEDI data (RMSE=10.87m) and demonstrates disturbance detection (F1=0.82). Public release of height maps is planned."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- **Originality**: The growth loss enforces monotonic height increase and abrupt drops; this is the first global 10m multi-year canopy height map with inherent temporal modeling \n%%previous work looks at single years only.\n\n- **Quality**: The model uses multi-sensor data and sparse GEDI labels for GT. Ablations isolate growth loss impact on held-out GEDI (Table 1, p. 8).\n\n- **Clarity**: The paper is very well-written; it's clearly structured, with well-explained methods; outlines explicit contributions, provides clear mathematical formulations, and effective visuals.\n- **Significance**: The resulting height map time series supports global-scale monitoring of forest growth and disturbance, with applications in carbon accounting and climate mitigation. The planned public release of height maps is a valuable contribution."}, "weaknesses": {"value": "- **Clarity**: Equations are unnumbered, making referencing difficult.\n- **Significance**: Height-to-carbon flux not evaluated -- above-ground biomass (AGB) to CO₂ conversion or flux tower validation would enhance climate impact, i.e. in carbon accounting.\n\n- **Originality**: The main novelty lies in the growth loss (Sec 3.3), but a comparison to learned temporal dynamics in *TimeSformer* (Bertasius et al., ICCV 2021) or *EarthFormer* (Gao et al., NeurIPS 2022) would help quantify value the loss adds beyond attention-based modeling.  \n- **Quality**: Results are strong against modern single-year baselines, but temporal SOTA comparisons could further strengthen the authors' claims."}, "questions": {"value": "1. Consider comparing to *TimeSformer* or *EarthFormer* -- Replacing your ViT encoder with one of these approaches that learn temporal dynamics via space-time attention would help clarify the advantage your growth loss provides.\n\n2. Validate carbon flux using height -- Height is a solid proxy, but for carbon accounting claims, it's valuable to estimate flux by converting your maps to AGB then CO₂  uptake/release using allometry like Jucker et al. (2022), validated against a flux tower site (e.g., Harvard Forest with public data).This additional step would ground the significance in real carbon metrics and strengthen the climate impact from my perspective.\n\n3. To improve mathematical clarity, consider numbering equations -- this would make it easier to reference formulations like the growth loss and follow derivations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fd0bNKwC2y", "forum": "62uxwRcvGr", "replyto": "62uxwRcvGr", "signatures": ["ICLR.cc/2026/Conference/Submission20458/Reviewer_P5pZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20458/Reviewer_P5pZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998496522, "cdate": 1761998496522, "tmdate": 1762933898288, "mdate": 1762933898288, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ECHOSAT provides a 50TB multi-modal (radar, multi-spectral, LiDAR), multi-temporal (monthly composites from 2018 to 2024) dataset from Earth observation with 3 million globally sampled geolocations of shape 18x84x96x96 (= channel x time x widht x height) at 10m pixel resolution. The authors explore the performance (Tab. 1, Figs. 3 & 4) of a Video-Swin-UNet-like architecture (Fig. 1) to predict tree height as determined by the GEDI sensor (mounted onto the ISS) when the network is trained by an additional loss that restricts tree growth to physical bounds (Sect. 3.3). Results indicate an advantage over existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly structured, written in plain English, with the main text accommodated by illustrative figures, equations, tables, and appendices with additional details. The dataset is carefully curated (App. A.2.1) and the methodology well documented (App A.2.2). Experimental results are cleanly evaluated against existing methods (Sect. 4.3)."}, "weaknesses": {"value": "The work falls short in major novelties for the ICLR community regarding learning representation methods. While ECHOSAT resembles a valuable dataset for the Earth observation community, the Temporal-Swin-Unet (Sect. 3.2) blends minor adjustments (1x1 patch size, additional layers and skip connections) from existing architecture. The additional *Growth Loss* (Sect. 3.3) is specific to the application of tree height mapping, and resembles a neat, but limited innovation.\n\nUnfortuantely, the authors evaluate the model performance on (hold-out) GEDI data the model was trained on. An independent modality to verify the temporal evolution of tree heights predicted, and a qualitative comparison to corresponding field surveys is missing. However, I appreciate the author's discussion of qualitative investigations such as in Fig. 7.\n\nGiven the Earth observation modalities fused ship in various spatial resolutions, I would appreciate a more detailed discussion around upsampling strategies to 10m per pixel, and their consequences. In particular, the label source GEDI for tree height estimation probes geospatial scenes at about 25 meter footprints. Discontinuities in tree height are common at forest boundaries and in areas disturbed by wild fires and logging.\n\nI rate the paper a valuable scientific piece of work carefully conducted in general, but I believe it would better fit the scope of an Earth observation conference, a computer vision conference with geospatial tracks, or a high-profile domain journal. However, if other reviewers read the paper and consider my input to come to the conclusion this work fits the scope of ICLR, I am fine with acceptance.\n\n- typos:\n  * l105: typo _captures_ to _capture_\n  * l633: $20\\circ$ to $20^\\circ$"}, "questions": {"value": "- Which license will the ECHOSAT dataset and the Temporal-Swin-Unet be published under?\n- Please provide a table with dataset and its source utilized. In particular which datasets have been pulled from Google Earth Engine, and how was geospatial alignment implemented?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FfSb4yScxJ", "forum": "62uxwRcvGr", "replyto": "62uxwRcvGr", "signatures": ["ICLR.cc/2026/Conference/Submission20458/Reviewer_kAKD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20458/Reviewer_kAKD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20458/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762209025368, "cdate": 1762209025368, "tmdate": 1762933897192, "mdate": 1762933897192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}