{"id": "YDl4vqQqGP", "number": 11231, "cdate": 1758193895922, "mdate": 1759897599716, "content": {"title": "MambaSL: Exploring Single-Layer Mamba for Time Series Classification", "abstract": "Despite recent advances in state space models (SSMs) such as Mamba across various sequence domains, research on their standalone capacity for time series classification (TSC) has remained limited. \nWe propose MambaSL, a framework that minimally redesigns the selective SSM and projection layers of a single-layer Mamba, guided by four TSC-specific hypotheses. \nTo address benchmarking limitations—restricted configurations, partial University of East Anglia (UEA) dataset coverage, and insufficiently reproducible setups—we re-evaluate 20 strong baselines across all 30 UEA datasets under a unified protocol. \nOur results show that MambaSL achieves state-of-the-art performance on the UEA benchmark among 21 models, with statistically significant average improvements over baselines while ensuring reproducibility via public checkpoints.", "tldr": "We introduce MambaSL, a minimally redesigned single-layer Mamba that achieves state-of-the-art accuracy on the UEA30 benchmark, with reproducible evaluation covering all baselines.", "keywords": ["modular selective SSM", "multi-head adaptive pooling", "skip connection", "single-layer Mamba", "time series classification"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/041442ea4b96902959f58c174914fe606691b475.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces MambaSL, a single-layer Mamba architecture for time series classification. The authors walk through the Mamba architecture in detail, explaining the individual components and the intuition behind how these components related to time series classification. They then propose their method which makes use of these observations in four succinct hypotheses that they use to build MambaSL. They then demonstrate state-of-the-art results across the UEA dataset, a common time series classification dataset, and examine their hypotheses through detailed ablations."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The authors walk through the Mamba architecture in incredible detail, explaining the components that are necessary to understand their newly proposed architecture. This is greatly appreciated especially for readers with limited knowledge of SSMs. \n- The architecture choices are well-motivated and explained. It’s greatly appreciated that authors are succinct and organized in their description of augmentations to the Mamba architecture, and the ablation results support their decisions. \n- The work puts incredible emphasis on reproducibility and goes to great lengths to discuss the differences in reported vs. optimized accuracy for baseline methods. I found this incredibly rigorous and greatly appreciated, boosting my confidence in the MambaSL performance given their careful considerations of baselines. In addition, the number of baselines included is quite substantial and covers a wide range of methods.\n- This work is overall very principled and novel, with authors clearly laying out the augmentations made on top of the Mamba architecture that are suitable for time series. I think this paves the way for more exploration in this space, and it lays forth a foundation for rigorous and proper benchmarking and principled development of time series models."}, "weaknesses": {"value": "- The experiments could use errors bars for presentation of results across datasets. Many of the performances are very close to each other on Figure 4, and it’s unclear whether the difference between MambaSL is statistically significant from other methods. In addition, error bars are needed in ablations to understand significance of differences in the dataset.\n- The model seems to not transfer well to variable-length settings, an assumption made implicitly in Hypothesis 1 where the k value is chosen based on the length of the dataset. Can authors comment on the ability of the model in variable-length settings?\n- The UEA dataset, while extensive, contains many small and curated datasets that are not representative of many real-world time series datasets. Did the authors test the method on other datasets for other challenging tasks? The work could use some demonstration on a frontier dataset, such as one released recently that represents a challenging real-world task."}, "questions": {"value": "- Did authors test MambaSL on datasets with very long samples? One benefit of the Mamba architecture and other SSMs are the ability to capture long contexts; this could be a beneficial demonstration but is also not required.\n- The UMAP showing comparisons of results across datasets is very cool! I’d love to see this UMAP reduction done along the dataset dimension as well to understand which datasets on which MambaSL performs well compared to non-DL vs. DL methods. This is not required at all but could also be an interesting analysis.\n- The authors focus on time series classification in this case, but could this be extended to forecasting?\n- Further, does the work easily extend to irregular time series, where time points are collected in irregular intervals. Can the architecture make use of the irregularity in observations when making predictions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MQfjL97h6a", "forum": "YDl4vqQqGP", "replyto": "YDl4vqQqGP", "signatures": ["ICLR.cc/2026/Conference/Submission11231/Reviewer_GbtJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11231/Reviewer_GbtJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921624544, "cdate": 1761921624544, "tmdate": 1762922393076, "mdate": 1762922393076, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MambaSL, a single‑layer Mamba architecture tailored to time‑series classification (TSC). Four hypotheses drive minimal but targeted changes: H1 scales the input Conv1D kernel with sequence length; H2 modularizes time (in)variance of the SSM parameters; H3 disables the skip (D) connection; H4 introduces a multi‑head adaptive pooling readout. The overall block is in Figure 2 (p.5); ablation evidence is in Table 1 (p.8) and Table 2 (p.8–9). On the full 30‑dataset UEA archive, the method attains the top average accuracy and rank among 21 models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "+ Thorough ablations, including eight TI/TV combinations (Table 2) and multiple pooling alternatives (Table 1). \n+ Excellent commitment to reproducibility across all 30 UEA datasets, with promises of public code, checkpoints, and full logs.\n+ The re-evaluation of TSF-origin models, showing they were previously underestimated, is an important finding. The analysis of H2 (time variance) is the most interesting part, showing that for TSC, simpler LTI systems can be better than LTV."}, "weaknesses": {"value": "+ The novelty of H1–H4 is moderate; each component is a small change rather than a new architectural principle.\n+ The paper's own ablation study (Table 1) shows that H1 (scaling kernel size) is not clearly supported by the average accuracy metric.\n+ The paper's title and focus on a \"single-layer\" model  is not well-justified. Why is one layer sufficient? The paper is missing a ablation study on the effect of model depth (i.e., stacking MambaSL layers)."}, "questions": {"value": "+ Could you provide a statistical test (e.g., a Wilcoxon signed-rank test) comparing the performance of MambaSL (with H1) directly against the \"w/o H1\" variant, or should H1 be re-framed in light of this evidence?\n+ Did you try multi‑layer (2–3 layers) MambaSL to confirm single‑layer sufficiency? How does MambaSL perform on variable‑length sequences at test time (beyond the pooling stage)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GFONO6u85u", "forum": "YDl4vqQqGP", "replyto": "YDl4vqQqGP", "signatures": ["ICLR.cc/2026/Conference/Submission11231/Reviewer_XLs9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11231/Reviewer_XLs9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993714471, "cdate": 1761993714471, "tmdate": 1762922392537, "mdate": 1762922392537, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MambaSL, a framework that minimally modifies the selective state space models and projection layers of a single-layer Mamba architecture for time series classification. Experimental evaluations conducted on 30 datasets from the UEA benchmark demonstrate that MambaSL consistently outperforms 20 competitive baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper applies the Mamba architecture to time series classification tasks and achieves superior performance compared to Transformer, MLP, and CNN models on multivariate time series classification benchmarks. This demonstrates the strong potential of Mamba for time series classification modeling.  \n2. The authors provide open-source code for the proposed model, along with implementations of the baseline methods, ensuring the reproducibility and transparency of the experimental results."}, "weaknesses": {"value": "1. The paper’s title, introduction, and model design focus primarily on time series classification without providing an in-depth discussion of how variable relationships are modeled in multivariate time series. In this case, the experiments are limited to the 30 datasets from the UEA multivariate time series classification archive, while excluding the 128 univariate datasets. This omission weakens the paper’s motivation and makes it difficult to assess whether the proposed method achieves state-of-the-art performance under univariate settings.  \n\n2. Although the application of Mamba to time series classification is commendable, the paper does not clearly explain how the proposed MambaSL framework captures intrinsic temporal properties—such as temporal dependencies, inter-variable relationships, and short- or long-term sequence characteristics. The introduction and contribution sections also fail to clarify how MambaSL learns discriminative feature patterns beneficial for classification.  \n\n3. The model section contains extensive background on basic Mamba concepts, making it difficult for readers unfamiliar with Mamba to follow. At the same time, readers experienced in time series classification may still find it unclear how the model effectively learns task-relevant features for classification.  \n\n4. Despite the considerable experimental effort and the inclusion of reproducible scripts, all deep learning results in the paper suffer from a **test data leakage issue**. As shown in the provided code (`MambaSL/exp/exp_classification.py`, lines 22–25), the test set is incorrectly used as the validation set:\n\n   ```python\n   self.train_data, self.train_loader = self._get_data(flag='TRAIN')\n   if self.args.is_training:\n       self.vali_data, self.vali_loader = self._get_data(flag='TEST')\n   self.test_data, self.test_loader = self._get_data(flag='TEST')\n\nThis indicates that the test set is used for model validation and hyperparameter selection, resulting in a significant evaluation bias.\n\n5. In Appendix A, the authors mention that the experimental framework is based on the **Time-Series Library (TSLib)** (Wu et al., 2023). While TSLib is widely recognized for fair benchmarking in forecasting tasks, prior research ([1], Section 4.4 “Leaky Baselines”) has shown that TSLib introduces **test data leakage** in classification experiments. Furthermore, several non-deep learning baselines (e.g., Rocket, HC2, Hydra) do not rely on validation sets during training and for model selection. Consequently, using the maximum test performance as the final evaluation metric for MambaSL constitutes an **unfair comparison** with these baselines.\n\n**Reference**\n\n[1] *TOTEM: Tokenized Time Series Embeddings for General Time Series Analysis*, TMLR, 2024."}, "questions": {"value": "1. In univariate time series classification, the original **InceptionTime** paper evaluates models based on the checkpoint with the lowest training loss, and the same evaluation strategy is adopted in **[2]**. Under a comparable setting, how does **MambaSL** perform relative to **HC2** and **MultiRocket+Hydra** on the 30 UEA multivariate time series datasets?  \n\n2. On the 128 UCR univariate time series datasets, following the **InceptionTime evaluation protocol**—where the model with the lowest training loss is used for testing—how does **MambaSL** compare in classification performance with **HC2** and **MultiRocket+Hydra**?  \n\n3. Beyond the evaluation setups in **InceptionTime** and **[2]**, some studies (e.g., **TSLANet**) adopt a different experimental protocol that uses **20% of the training set as a validation subset** for model selection on both UCR and UEA datasets. Under this widely used setting, how does **MambaSL** perform compared with **HC2**, **MultiRocket+Hydra**, and other competitive baselines?  \n\n4. Compared to 20 baseline methods, what are the advantages and disadvantages of the proposed **MambaSL** method in terms of runtime?\n\n**Reference**\n\n[2] *Inherently Interpretable Time Series Classification via Multiple Instance Learning*, ICLR, 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pog7d1pEPA", "forum": "YDl4vqQqGP", "replyto": "YDl4vqQqGP", "signatures": ["ICLR.cc/2026/Conference/Submission11231/Reviewer_wsQb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11231/Reviewer_wsQb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762697069241, "cdate": 1762697069241, "tmdate": 1762922392124, "mdate": 1762922392124, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}