{"id": "TXdKKABtWB", "number": 7859, "cdate": 1758039369754, "mdate": 1759897826940, "content": {"title": "RelA-Diffusion: Relativistic Adversarial Diffusion for Multi-Tracer PET Synthesis from Multi-Sequence MRI", "abstract": "Multi-tracer positron emission tomography (PET) provides critical insights into diverse neuropathological processes such as tau accumulation, neuroinflammation, and β-amyloid deposition in the brain, making it indispensable for comprehensive neurological assessment. However, routine acquisition of multi-tracer PET is limited by high costs, radiation exposure, and restricted tracer availability. Recent efforts have explored deep learning approaches for synthesizing PET images from structural MRI. While some methods rely solely on T1-weighted MRI, others incorporate additional sequences such as T2-FLAIR to improve pathological sensitivity. However, existing methods often struggle to capture fine-grained anatomical and pathological details, resulting in artifacts and unrealistic outputs. To address these limitations, we propose RelA-Diffusion, a Relativistic Adversarial Diffusion framework for multi-tracer PET synthesis from multi-sequence MRI. By leveraging both T1-weighted and T2-FLAIR scans as complementary inputs, RelA-Diffusion captures richer structural information to guide image generation. To improve synthesis fidelity, we introduce a gradient-penalized relativistic adversarial loss to the intermediate clean predictions of the diffusion model. This loss compares real and generated images in a relative manner, encouraging the synthesis of more realistic local structures. Both the relativistic formulation and the gradient penalty contribute to stabilizing the training, while adversarial feedback at each diffusion timestep enables consistent refinement throughout the generation process. Extensive experiments on two datasets demonstrate that RelA-Diffusion outperforms existing methods in both visual fidelity and quantitative metrics, highlighting its potential for accurate synthesis of multi-tracer PET.", "tldr": "", "keywords": ["Image Synthesis", "Image Translation", "MRI", "PET", "‪Medical Image Analysis‬"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b89daefb0b657b66806cdfa9db4e0631a0480fb1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper, the authors propose RelA-Diffusion: a 3D PET synthesis algorithm for multi-sequence MRI within the DDPM framework. The core approach is to simultaneously apply an L1 image constraint and a relative adversarial loss to the intermediate clean predictions $\\hat{x_0}$ at each randomly sampled time step during training, with a zero-centered gradient penalty added to stabilize training. During inference, only the diffusion generator is used (the discriminator is not involved). On two datasets, the algorithm is compared with seven representative methods and achieves superior PSNR, SSIM, and MAE performance in most cases. Ablation results for de-modulation and de-modalization are also provided."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. great motivation: PET is expensive and has radiation protection issues, so the generation of MRI-synthesized PET is a practical alternative.\n\n2. clear method coupling: Relative discrimination and gradient penalty are applied to $\\hat{x_0}$, forming a hybrid loss function L with the diffuse noise prediction and image L1."}, "weaknesses": {"value": "1. The novelty is incremental, the main contribution seems like applying Diffusion-GAN to the generation from MRI to PET. It is suggested to focus on more concrete problem in the generation of PET.\n\n2. It is suggested to add more downstream tasks to verify the performance of generation, like segmentation, classification. \n\n3. In Table 1, CycleGAN outperforms DiffGAN, FICD, MTGD in most metrics across three tasks. Besides, the CycleGAN do not use the diffusion model. I wonder why the CycleGAN achieve so superior results? It is suggested to add more discussion about it, more importantly, the proposed method is also leveraging the diffusion model. \n\n4. In formula 11, does the combination of losses need weights?\n\n5. Many typos. In Line 40, there are double \"with\". In line 605, the paper format is confusing with \"[!htp]\"."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "a8RC9uaSYj", "forum": "TXdKKABtWB", "replyto": "TXdKKABtWB", "signatures": ["ICLR.cc/2026/Conference/Submission7859/Reviewer_T9B3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7859/Reviewer_T9B3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761244875997, "cdate": 1761244875997, "tmdate": 1762919897812, "mdate": 1762919897812, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes RelA-Diffusion, a diffusion-based framework for synthesizing multi-tracer PET images (e.g., TAU, PIB, PBR) from multi-sequence MRI (T1w and T2-FLAIR). The key novelty lies in: 1) A gradient-penalized relativistic adversarial loss applied to intermediate clean predictions within the diffusion process. 2) Leveraging multi-sequence MRI for richer anatomical context. 3) Using relativistic comparison instead of binary real/fake judgments to stabilize training. Experiments on NFL-LONG and ADNI datasets demonstrate quantitative superiority over GAN, diffusion, and hybrid baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The integration of relativistic adversarial loss into the diffusion framework is a novel way to stabilize adversarial training while improving structural fidelity.\n\nThe method section provides a clear mathematical formulation for forward/reverse diffusion, adversarial losses, and the hybrid objective. It is easy to follow. \n\nAblation experiments (w/o RA, w/o T1w, w/o T2F) convincingly support each component’s contribution. The method achieves consistent improvements in PSNR, SSIM, and MAE across three tracers and generalizes well to ADNI without fine-tuning. Visualizations (difference maps) clearly show sharper anatomical details and fewer artifacts."}, "weaknesses": {"value": "The training involves 1000 diffusion steps and adversarial updates. No runtime, training time, or sampling speed comparison is provided against standard diffusion or GAN models.\n\nOnly 10 subjects for testing in NFL-LONG and 30 ADNI subjects for external validation are relatively small sample sizes, which might limit claims of robustness and clinical readiness."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XR2r2R8tmW", "forum": "TXdKKABtWB", "replyto": "TXdKKABtWB", "signatures": ["ICLR.cc/2026/Conference/Submission7859/Reviewer_22Ei"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7859/Reviewer_22Ei"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761685283800, "cdate": 1761685283800, "tmdate": 1762919897068, "mdate": 1762919897068, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for synthesizing PET images from structural MRI (T1w and T2-FLAIR). They propose technical innovations including a relativistic adversarial loss and gradient penalty to have sharper output images and capture fine-grained anatomical and pathological details. The authors evaluate on two datasets, training on and one and testing generalization on the other. They compare against several baselines and outperform in both qualitative and quantitative metrics."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written, well-motivated, and extensively evaluated. They tackle an important problem, synthesizing PET images, which are both costly to obtain and patients often do not want to expose themselves to the radiation involved. As PET images are used for monitoring neurodegenerative disroders, synthetic images may improve the accuracy of predictions of disorder.\n\nThe authors propose a model that combines the strengths of both diffusion and GAN models to synthesize realistic images. They propose an extension to the standard diffusion framework by training with a relativistic adversarial loss and a gradient penalty. Ablations demonstrate that these extensions improve image synthesis quality. \n\nThey offer extensive experimental evaluations against 7 recent methods for this task. Qualitative evaluations also visually demonstrate the performance of their model."}, "weaknesses": {"value": "### Clinical Utility\nWhile I believe this paper is clearly written and technically sound, I have a hard time justifying the need for such a method. The authors claim that synthesizing PET images can be useful for clinical analysis of neurological disorder. However, I have a hard time believing that clinicians would actually use these types of images to make clinical decisions. While the authors evaluated well that the synthesized images were high quality, I am unconvinced that such a model would actually be used. A more interesting and useful experiment would be to demonstrate several tasks where training with the synthetic data improves performance on clinical classification, regression, or segmentation tasks over using just the T1w and T2F images. \n\nFurther, I have several small concerns that can be addressed.\n\n### Evaluation and Generalization\nThe authors claim a key result is the ability of their model to generalize, by showing performance on 30 subjects from the ADNI dataset. There are a few issues here. First, 30 subjects is quite small, and I wonder why the authors did not just use the full 502 images in the dataset. Second, the authors are testing the AV1451 tracer, which was the same tracer used in the training set from the NFL-LONG dataset. So, this is not really a generalization task. Especially because the subject demographics are somewhat similar, this is less of a generalization result.\n\nSimilarly, the authors use a very small held out set of 10 subjects from NFL-LONG for testing. In my opinion, this is too small to make any meaningful conclusion against the baselines.\n\nFurther, on Figs. 2 and 3, the difference maps actually show that the synthesized images are fairly different from the true ones. Can the author comment on these differences?\n\nI would also like the authors to run statistical tests to assess whether the differences in results are significant.\n\n### Ablations\n- Can the authors comment on why the MAE did not improve from some ablation studies? \n- Were these ablations done on the 10 subjects in the NFL-LONG test set? If so, this is again too small of a sample size to make any conclusions\n- Can the authors do one ablation with the standard GAN penalty and the gradient penalty?"}, "questions": {"value": "Many of my questions are embedded in the weaknesses section\n\nWhat are some applications that you see this method being useful for?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RCLdt1Czpl", "forum": "TXdKKABtWB", "replyto": "TXdKKABtWB", "signatures": ["ICLR.cc/2026/Conference/Submission7859/Reviewer_B64g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7859/Reviewer_B64g"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762030626303, "cdate": 1762030626303, "tmdate": 1762919896347, "mdate": 1762919896347, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}