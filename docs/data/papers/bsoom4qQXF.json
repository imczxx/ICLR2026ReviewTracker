{"id": "bsoom4qQXF", "number": 6768, "cdate": 1757994897927, "mdate": 1759897895044, "content": {"title": "Bootstrapped Exploration with Causal Reasoning: A Training Paradigm for Adaptive Forecasting Agent", "abstract": "Time series forecasting is critical in domains such as finance, energy, and healthcare, yet real-world datasets often exhibit non-stationarity, noise, missing values, and distribution shifts, posing severe challenges for generalization. In practice, industry solutions typically rely on customized forecasting frameworks that combine imputation, decomposition, and specialized models. However, such frameworks incur high labor costs. Moreover, we observe that many frameworks suffer from the impacts of distribution shifts, which degrade their respective performance. Thus, it is critical to establish a new paradigm that retains high transferability across diverse datasets while accumulating reusable strategy knowledge. This is fundamental for large-scale and dynamic environments. While large language model-based agents have recently demonstrated strong reasoning and tool-use capabilities, no forecasting agent can automatically adapt to diverse time-series datasets. This gap arises from two core obstacles: the scarcity of labeled supervision and the inherent complexity of mapping dataset-specific meta-features to effective forecasting strategies. To address these challenges, we propose BECRA, a novel agent training paradigm that learns forecasting intelligence through contrast-aware exploration and causal lesson extraction, without any human-annotated supervision. BECRA distills symbolic strategy lessons that enable in-context planning on unseen datasets, achieving zero training adaptation.", "tldr": "", "keywords": ["Time Series Forecasting", "Agent", "LLM", "Agent Training Paradigm"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2b9e237e72c6b1732b2d7c59672b2fe9d244c36e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a training paradigm (BECRA) that autonomously learns how different forecasting toolchains perform under varying dataset meta-features. It explores combinations of preprocessing and modeling tools, evaluates their performance, and uses a large language model to extract interpretable causal “lessons” describing when and why each toolchain succeeds or fails. These lessons are stored in textual form, allowing the agent to reuse and compose them for zero-shot forecasting on unseen datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The method description is mostly clear, and Figure 1 effectively illustrates the core workflow of the BECRA framework.\n\n2. The mathematical notation is standard and consistent, making the formulation easy to follow.\n\n3. The paper integrates exploration, causal reasoning, and symbolic knowledge extraction in a unified pipeline, which is novel for time-series forecasting."}, "weaknesses": {"value": "1. Unclear formulation (Page 3, Line 159):\nThe description of the UCB-based exploration step is ambiguous. It states that empirical performance is updated for each toolchain, but the equation provided defines $a^*$, which instead selects the next toolchain. \n\n2. Reliance on LLM reasoning without validation:\nThe method assumes that the LLM can accurately extract causal “lessons,” but there is no quantitative or qualitative analysis demonstrating how reliable these extracted lessons are. The paper should include either human evaluation or consistency checks to assess hallucination or reasoning errors.\n\n3. Limited expressiveness of meta-features:\nThe agent operates on hand-crafted, scalar meta-features that summarize dataset characteristics. These descriptors may fail to capture the full complexity of high-dimensional or non-stationary time series, limiting the generality of the causal lessons.\n\n4. Toolchain selection criteria unclear:\nThe paper does not describe how individual tools (imputation, decomposition, forecasting models, etc.) were chosen. It remains unclear whether the library is comprehensive, balanced, or biased toward specific architectures.\n\n5. Experimental setup lacks transparency:\nThe description of datasets, forecasting tasks, and evaluation protocol is too brief. The paper should specify dataset sizes, forecast horizons, and input/output configurations. The baselines are listed but not fully explained or cited in the main text.\n\n6. Missing statistical rigor:\nReported results lack error bars or significance tests. Variability across runs should be reported to support claims of robustness and superiority.\n\n7. Figure quality issues:\nFigure 2 suffers from small font size and low resolution, making it difficult to read. The shaded red region below the curve is unexplained and should be clarified.\n\n8. Overly strong or subjective language (minor):\nThe writing repeatedly uses subjective qualifiers such as \"clearly\", \"strong results\".  Such language should be replaced by factual statements and quantitative evidence, allowing readers to draw their own conclusions."}, "questions": {"value": "Please address my each point in the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fXA0JcxEmI", "forum": "bsoom4qQXF", "replyto": "bsoom4qQXF", "signatures": ["ICLR.cc/2026/Conference/Submission6768/Reviewer_mHFv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6768/Reviewer_mHFv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761414824568, "cdate": 1761414824568, "tmdate": 1762919047662, "mdate": 1762919047662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the challenges of time series forecasting, highlighting the limitations of current industry frameworks, which often require manual trial-and-error, fail to adapt efficiently, and do not accumulate reusable forecasting knowledge. The authors propose BECRA, an agent-based training paradigm designed to develop \"forecasting intelligence\" through contrast-aware exploration and causal lesson extraction, all without human-annotated supervision. BECRA aims to replace traditional frameworks with a LLM agent.\n\nAuthors summarize as main contributions: 1) identify limitations of existing models and frameworks, 2) BECRA - LLM agent training for forecasting intelligence with contract-aware exploration and causal lesson extraction without human supervision, 3) library. The BECRA framework operates in a four-stage cycle: sampling strategies, causal lesson learning, lesson verification, and lesson-guided forecasting, aiming to replace manual framework design with automated."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear Problem Identification: The paper provides an analysis of the limitations in current time series forecasting frameworks;\n- Introduces an LLM agent for time series forecast, moving beyond traditional manual and trial-and-error methods.\n- The framework enables automated, structured exploration and in-context planning, allowing the agent to adapt to new datasets without human supervision.\n- Not dataset (or domain) dependent, being able to be adopted in a range of different time-series applications."}, "weaknesses": {"value": "(There are questions related to most of these weaknessses)\n- The 'causal reasoning' component: I'm convinced what we see is actually 'causal' lessons, and not just correlations. It would be nice to have more information about it.\n- Meta-features seems very important to the whole process, but there limited information about how their quality might impact on overall performance; \n- The experiments lack confidence intervals, which makes it hard to make comparisons between different methods."}, "questions": {"value": "- Impact of Meta-Features: How does the quality of meta-features affect the BECRA framework? What happens if meta-features quality is poor? How much can one over-engineer meta-features? \n- RL Agents vs. LLM Agents: Could reinforcement learning (RL) agents be used instead of LLM agents, given that RL also balances exploration and exploitation? Did you make tests with RL agents?\n- Causal Lesson Validity: How are counterfactuals for causal lessons obtained, and what guarantees exist that these lessons reflect true causality rather than spurious correlations?\n- Computational Cost: While fine-tuning is computationally expensive, LLMs also incur significant costs (albeit monetary rather than time). How does this trade-off compare?\n- Reporting of Results: In Table 1, what are the confidence intervals for the reported metrics? Without error bars, it is difficult to interpret the results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oQRS1Cykus", "forum": "bsoom4qQXF", "replyto": "bsoom4qQXF", "signatures": ["ICLR.cc/2026/Conference/Submission6768/Reviewer_iPnK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6768/Reviewer_iPnK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761694872747, "cdate": 1761694872747, "tmdate": 1762919047073, "mdate": 1762919047073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BECRA, a novel paradigm for training adaptive forecasting agents by distilling reusable, symbolic knowledge without human supervision. The approach demonstrates strong empirical performance in rigorous zero-shot settings, outperforming specialized models and foundation models across various benchmarks utilizing a leave-one-out protocol."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a novel approach to address the scarcity of labeled supervision for time-series strategy selection, shifting the focus from repetitive dataset optimization (like AutoML) to reusable, symbolic knowledge. \n\n2. The use of contrast-aware UCB sampling explicitly preserves both high and low performing examples, which is important for causal reasoning. The performance drop of the greedy variant in the ablation study validates this choice.\n\n3. The paradigm is model-agnostic, the distilled symbolic lessons are transferrable and can be successfully utilized by various other LLMs with only graceful performance degradation.\n\n4. The manuscript is clearly structured and easy to follow."}, "weaknesses": {"value": "**1. Ambiguous Formulation:**\nThe UCB objective formulation in Sec. 3.1 is defined as $a^{*}=arg~max_{a\\in\\mathcal{A}}\\mu(a)+\\lambda\\cdot\\sigma(a)$, where $\\mu(a)$ is the average historical performance (MSE). The formulation should imply minimization (e.g., Lower Confidence Bound) or maximization of the inverted MSE.\n\n**2. Negative Lessons:**\nThe paper says they “verify negative causal lessons” and “check if performance improves when the lesson is contradicted or removed.”, but the Algorithm 3 seems only removes $\\phi_k$ but never contradicts it (checking if performance improves when the lesson is contradicted is not clearly integrated).\n\n**3. Verification Procedure:**\nThe verification procedure in Algorithm 3 involves the agent planning strategies guided by the lesson library with and without the specific lesson $\\phi_{k}$. This means the measured effect $\\Delta_{\\phi_{k}}$ can be potentially confounded by the LLM agent's subsequent planning choices, rather than isolating the direct impact of the lesson itself.\n\n**4. (Minor) Threshold not Defined:**\nThe definition of the causal effect $\\Delta_{\\phi_{k}}$ relies on $P(y=1|...)$, where $y=1$ signifies a successful outcome based on a threshold $\\tau$. However, the criteria for determining this threshold are not defined."}, "questions": {"value": "1. Planning retrieves all lessons whose conditions match the new dataset, then passes them together to the LLM to pick a strategy. Is there a explicit rule for resolving contradictions among those retrieved lessons?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ForUyiIcr6", "forum": "bsoom4qQXF", "replyto": "bsoom4qQXF", "signatures": ["ICLR.cc/2026/Conference/Submission6768/Reviewer_bq9j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6768/Reviewer_bq9j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949076129, "cdate": 1761949076129, "tmdate": 1762919046615, "mdate": 1762919046615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors present BECRA, an agent training framework for time-series forecasting. It first explores a diverse set of toolchains including time-series analysis and processing tools. Then it generates causal lessons (strategies of choosing toolchains) based on the data metadata and toolchains that achieve high-reward and low-reward samples, via upper confidence bound. It verify the derived causal lessons by measuring the causal effect of these lessons' successful outcome under corresponding patterns. The verified lessons are stored in knowledge base and then retrieved and employed for language agent to do in-context forecasting. Experiments on long-term,  short-term forecasting, and noisy data (missing values, contaminated values) show the efficiency of the proposed approach, that help the language agent choose appropriate toolchains considering different dataset characteristic. Ablation studies confirm the effectiveness of proposed modules such as contrast UCB sampling, causal lesson learning and verification."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* This paper targets at an impactful and practical question about domain gaps in time-series forecasting. It presents its motivation and methodology very clear.\n\n* The knowledge base of causal lessons are valuable for the community and applications to efficiently leverage language agents to choose proper analysis techniques and forecasting models, reducing the requirement of human prior. \n\n* Experiments show that BECRA works as an accurate orchestration layer that smartly choose pipelines referring data properties, The  robustness experiments like missing and contaminated data are valuable. The ablations probe the roles of exploration strategy, causal lessons  and verification, and demonstrate the flexibility of in-context learning compared to SFT models."}, "weaknesses": {"value": "* This work is highly relevant to the recent line of combining language agents and time-series models, e.g. [1][2][3][4]. The author should expand Related Work to review this line of work and compare BECRA’s lesson induction/verification to other time-series agent studies. \n\n* Time-series foundation models are general forecaster which are expected to handle diverse domains' data, which is another way of handling domain gaps. The author should consider benchmarking the proposed method (agent aspect) with time-series foundation models (model aspect) that don't have data leakage, e.g., using benchmark GIFT-eval [5].\n\n* The author should run more runs and add the uncertainty/confidence metrics to the experiments. Means without error bars/tests obscure whether improvements are statistically reliable.\n\n[1] Yeh, Chin-Chia Michael, et al. \"Empowering Time Series Forecasting with LLM-Agents.\" arXiv preprint arXiv:2508.04231 (2025).\n\n[2] Garza, Azul, and Reneé Rosillo. \"TimeCopilot.\" arXiv preprint arXiv:2509.00616 (2025).\n\n[3] Zhao, Haokun, et al. \"Timeseriesscientist: A general-purpose ai agent for time series analysis.\" arXiv preprint arXiv:2510.01538 (2025).\n\n[4] Wang, Xinlei, et al. \"From news to forecast: Integrating event analysis in llm-based time series forecasting with reflection.\" Advances in Neural Information Processing Systems 37 (2024): 58118-58153.\n\n[5] Aksu, Taha, et al. \"Gift-eval: A benchmark for general time series forecasting model evaluation.\" arXiv preprint arXiv:2410.10393 (2024)."}, "questions": {"value": "I have listed most of my concerns and suggestions in the weakness section. Here are my additional questions:\n\n* How is the set of candidate toolchains sampled? Are they just combinations of all possible available tool sequences? Wouldn't this be intractable for following computation? \n\n* What is the training data for collecting causal lessons? Does it have overlapping with the test data?\n\n* How does the generalizability of the compiled knowledge base? Could it be used to completely unseen datasets? How does it behave and could authors provide some failure/suboptimal cases and analysis? Demonstrations of the agent behavior and reasoning would also be interesting and more interpretable to have."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2bIswob5RO", "forum": "bsoom4qQXF", "replyto": "bsoom4qQXF", "signatures": ["ICLR.cc/2026/Conference/Submission6768/Reviewer_HGPo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6768/Reviewer_HGPo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981877036, "cdate": 1761981877036, "tmdate": 1762919046222, "mdate": 1762919046222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}