{"id": "7SkGH9yW3s", "number": 22421, "cdate": 1758330832124, "mdate": 1759896867398, "content": {"title": "Hierarchical Object-Oriented POMDP Planning for Object Rearrangement", "abstract": "We present an online planning approach and a new benchmark dataset for solving multi-object rearrangement problems in partially observable, multi-room environments. Current object rearrangement solutions, primarily based on Reinforcement Learning or hand-coded planning methods, often lack adaptability to diverse challenges. To address this limitation, we propose a Hierarchical Object-Oriented Partially Observed Markov Decision Process (HOO-POMDP) planner that leverages object-factored belief representations for efficient multi-object rearrangement. This approach comprises of (a) an object-oriented POMDP planner generating sub-goals, (b) a set of low-level policies for sub-goal achievement, and (c) an abstraction system converting the continuous low-level world into a representation suitable for abstract planning. To enable rigorous evaluation of rearrangement challenges, we introduce MultiRoomR, a comprehensive benchmark featuring diverse multi-room environments with varying degrees of partial observability (10-30\\% initial visibility), blocked paths, obstructed goals, and multiple objects (10-20) distributed across 2-4 rooms. Experiments demonstrate that our system effectively handles these complex scenarios while maintaining robust performance even with imperfect perception, achieving promising results across both existing benchmarks and our new MultiRoomR dataset.", "tldr": "We propose a Hierarchical Object-Oriented POMDP planning approach for multi-object rearrangement in partially observable environments. We show it's effectiveness in the AI2Thor simulator experiments", "keywords": ["rearrangement", "POMDP", "planning", "reinforcement learning", "object search"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/93dc5ecd129d711e44ed44288dded2cefafa4ce4.pdf", "supplementary_material": "/attachment/4f206331c5ea7e7ec10f59635e2f3d40342e3f2d.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a novel method for multi-room, multi-object rearrangement in a partially observable setting. The rearrangement process operates in two phases. In the walkthrough phase, the agent explores the environment to build a map, record receptacle locations, and gather scene information; objects are then placed randomly in the environment. In the rearrangement phase, the agent uses the constructed map, the known set of object classes, and the specified goal locations to perform the rearrangement. The approach employs a hierarchical planning framework, with a high-level planner based on PO-UCT to generate abstract actions such as move, pick, and place, and a low-level controller that uses reinforcement learning for pick-and-place behaviors and A* for navigation. The method explicitly addresses challenges posed by blocked paths and blocked goal locations, which earlier approaches do not handle effectively. Experimental results demonstrate that the system successfully operates under partial observability and scales to scenarios with up to 20 objects. Additionally, the paper introduces MultiRoomR, a benchmark featuring more rooms, more objects, and a greater variety of rearrangement configurations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and clearly structured, making the motivation and methodology easy to follow.\n2. The proposed method is novel, particularly in how it discovers partially observable objects. It also effectively handles blocked-path scenarios, which prior work does not address.\n3. The approach benefits from using PO-UCT as an iterative planner, which reduces dependence on learned policies, thereby lowering the risk of catastrophic failures often seen in purely neural methods.\n4. The experimental evaluation is extensive and thorough, including strong comparisons to prior approaches and informative ablation studies that highlight the importance of each system component.\n5. The newly introduced MultiRoomR benchmark is a valuable contribution that provides a more challenging and realistic testbed for future research on multi-room, multi-object rearrangement.\n6. The authors have released the code and provided detailed algorithmic descriptions to support reproducibility, and they include the MultiRoomR dataset along with the supplementary material to facilitate future research."}, "weaknesses": {"value": "1. Limited novelty in methodology: While the system is thoughtfully designed, the novelty is incremental. The method primarily combines existing components (PO-UCT, PPO-based low-level skills, and A* navigation) into a pipeline, and the core contribution lies in their integration. The main new challenge addressed is the blocked-path scenarios, which, although important, limits the conceptual innovation relative to prior hierarchical rearrangement frameworks.\n2. Scalability concerns due to PO-UCT: The reliance on PO-UCT for high-level planning means computation scales with the number of simulations and search depth, which is strongly influenced by the number of objects and environment complexity. As a result, planning time may grow significantly as task complexity increases, limiting scalability to larger or more cluttered scenes.\n3. Limited generalizability to real-world deployment: Because the high-level decisions are generated through Monte-Carlo tree search rather than a learned policy, the system must perform online planning at each step. This limits generalization and makes real-world application challenging, as the approach does not amortize planning into a neural policy that could execute quickly without repeated simulation.\n4. Problem formulation relies on extra prior knowledge: The problem setup assumes access to the set of object classes that need to be rearranged, which is not typically available in prior works and may not be realistic in practical settings. Furthermore, the method assumes that the user provides precise 3D goal locations for objects. In real-world applications, such explicit spatial goal specifications are uncommon; instead, agents are generally expected to use commonsense semantic priors to infer plausible goal locations (e.g., as in TIDEE (Sarch et al.) or Housekeep (Kant et al.)). Integrating semantic goal inference would make the approach more practical and aligned with real-world deployment expectations.\n5. Simplifying independence assumption in belief modeling: The belief update assumes objects are independent, which does not hold in real household environments where objects commonly co-occur, occlude each other, or exhibit relational structure (e.g., items inside containers or grouped functionally). This assumption restricts the model’s ability to reason about relational or compositional uncertainty and may limit performance in more complex, cluttered scenes."}, "questions": {"value": "1. To better understand the scalability of the proposed approach, could you clarify the minimum number of simulations and the required search depth needed to achieve the best performance for different numbers of rooms and objects? Additionally, how does compute time grow as these parameters increase? A quantitative analysis of simulation budget vs. performance vs. time would help assess how the method scales to larger and more complex environments.\n2. In the appendix Table 3, the “Time (m)” column is not clearly defined. Does this value represent the average total clock time to complete an entire rearrangement episode (planning + execution), or only the planning time? Additionally, is this reported per episode or normalized per object?\n3. Have you considered incorporating semantic goal inference or preference-based goal discovery, similar to TIDEE or Housekeep?\n4. Can the framework be extended to reason about correlations (e.g., object occlusions, functional groupings)? Do you observe failure cases where this assumption becomes limiting?\n5. Can you provide insights into the most common failure modes? For example, is performance more sensitive to detection errors, navigation failure, or belief update ambiguity?\n6. Could you comment on the feasibility of deploying this framework on a real robot?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Ltg3Ontl4I", "forum": "7SkGH9yW3s", "replyto": "7SkGH9yW3s", "signatures": ["ICLR.cc/2026/Conference/Submission22421/Reviewer_v1Hc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22421/Reviewer_v1Hc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885326013, "cdate": 1761885326013, "tmdate": 1762942211914, "mdate": 1762942211914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a hierarchical planning algorithm for the object-rearrangement problem, in the presence of partial observability. The three primary components of the algorithm are: 1) high-level POMDP planning in an abstract state space, 2) macro-actions which are implemented using Markov methods, and 3) an object-factored belief state. The result is a practical and high-performing algorithm for this important robot subtask. The algorithm is thoroughly evaluated on a novel benchmark task, where its performance exceeds previous methods'."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- This is an important problem that displays many of the characteristics of real-robot tasks.\n- The approach is practical and simple, and builds on a lot of recent work focused on exploiting structure in POMDPs to generate efficient solutions.\n- The method is sufficiently structured that I expect it would work on a real robot, with some engineering effort required obviously.\n - Using Markov low-level controllers to support a more abstract level that can then plan taking partial-observability into account has appeared in a few places, and has worked very well. This is a highly appropriate use of that strategy.\n- The evaluation is thorough and the new benchmark proposed is valuable.\n - The paper is well written (though not well-structured, see below) and easy to read."}, "weaknesses": {"value": "- The paper is oddly structured. There's a Related Work section that occurs before the Background section, which makes no sense. How am I to understand the RW section when I haven't been precisely told what problem you are solving yet? Then the Background section is called Problem Formulation, though instead of a formulation (which is a precise mathematical description of the task), we are given some implementation details about AI2Thor. The paper and ideas have to stand on their own outside of AI2Thor. There's some problem formulation going on in section 4 (!!), where the authors define an OO-POMDP. Anyway I had to re-read the paper several times, out of order, to actually follow, which is bad.\n- The authors talk about embodied AI, but there are no bodies in this paper. Also, the first sentence is a little melodramatic. I'm not sure that multi-object rearrangement in a simulator is such a fundamental challenge. It's a good problem to work on though. Anyway I would tone some of that down.\n - It's not clear what the authors mean by \"hand-coded\" planning approach. Do they mean someone hand-codes a plan? Or a planner? Hand-coding a planner is what the planning research community does all day! Or do they mean, hand-design for a specific case? In that case, that's what this paper does! But they seem to be criticizing prior work here, so I think some clarify about what exactly they are criticizing would be good.\n - The paper is related to structured models of POMDPs. It cites an extends OO-POMDPs, which is appropriate, but I think MOMDPs are Merlin's work on local observability is probably also relevant. \n - Occasionally the paper uses a parenthetical citation as a noun, which should be fixed."}, "questions": {"value": "In the table, why does PK not have a 100% success rate? Or maybe that's not a percentage?\n\nCan you please confirm my understanding that the low-level policies for the macro-actions are essentially Markov? Are there any implications for that>"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SoVQT9Cmwq", "forum": "7SkGH9yW3s", "replyto": "7SkGH9yW3s", "signatures": ["ICLR.cc/2026/Conference/Submission22421/Reviewer_mkKK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22421/Reviewer_mkKK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926266757, "cdate": 1761926266757, "tmdate": 1762942211691, "mdate": 1762942211691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a hierarchical solution for an Object-Oriented Partially Observable Markov Decision Process (OOPOMDP). The system decomposes the problem by using a high-level abstract POMDP planner (based on PO-UCT) to reason over object-factored belief states and generate high-level actions (e.g., MoveToLocation, PickPlaceObject). A low-level policy executor, composed of classical planners and trained RL policies, is then responsible for executing these sub-goals. They also built a multi-room evaluation on top of ProcThor, creating a new multi-room dataset for evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The authors demonstrate an improvement over their selected baselines of FHC, VRR, and MSS. I found the inclusion of different ablations, such as having an oracle belief or a perfect object detector, helps validate their design choices. Their multi-room benchmark also highlights the limitations of the methods they chose to compare against."}, "weaknesses": {"value": "My main concerns are as follows:\n* The object independence assumption seems to directly conflict with trying to improve performance on scenarios involving blocked goals or blocked paths. \n* Requiring a pre-task walkthrough to build a map of the static environment is a significant practical limitation. This makes the solution inapplicable to new environments and the methodologies' robustness to any change in the map, or if there were blocking objects during this phase of planning. \n* The error analysis clearly identifies that the low-level pick/place policies are a major bottleneck, which makes it hard to isolate the planning performance.\n* The manual initialization of possible abstract actions (described in Abstract OOPOMDP Planner) limits the system's generality. The planner does not discover actions but instead searches over a pre-defined set based on object locations. This would limit the tasks to which this can be applied.\n* The paper's presentation is often unclear, making it difficult to fully grasp the methodology and its positioning within related works. Key details of the planning and abstraction systems are distributed between the main text and the appendix, hindering readability.\n* The anonymous code link provided in the paper is expired."}, "questions": {"value": "* How does FHC perform with an Oracle object detector?\n* Do other methods require an initial walk-through of the environment?\n* How sensitive is the planner to an imperfect static map from the \"walkthrough phase\"? What happens if a static object, like a chair, is moved between the walkthrough and the rearrangement phase?\n* Given that low-level policy failures are a key bottleneck, do you have any data on the planner's success rate? For example, during failed episodes, does the planner still produce a semantically correct sequence of abstract sub-goals?\n* Could you clarify the algorithmic novelty of your algorithm's planner? The paper positions it as an extension of OO-POMDPs from search to rearrangement. Is the primary difference simply the inclusion of PickPlace actions and their corresponding belief updates?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "eVF4SGs7SC", "forum": "7SkGH9yW3s", "replyto": "7SkGH9yW3s", "signatures": ["ICLR.cc/2026/Conference/Submission22421/Reviewer_bVLn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22421/Reviewer_bVLn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762558315817, "cdate": 1762558315817, "tmdate": 1762942211083, "mdate": 1762942211083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a Hierarchical Object-Oriented Partially Observable Markov Decision Process (HOO-POMDP) planner for multi-object (scene) rearrangement problems. This includes a Object-Oriented POMDP planner for generating sub-goals, with low-level policies for achieving these sub-goals and a method for converting the low-level world into a representation for abstract planning. In addition, the paper presents a benchmark simulation environment (called MultiRoomR) of multi-room environments with different levels of partial observability, obstructions, and multiple objects. The authors present results of experimentally evaluating the HOO-POMDP against baselines in the context of various benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(i) The paper focuses on the problem of multi-object rearrangement, and formulates it as a probabilistic sequential decision-making problem under partial observability.\n\n(ii) The paper provides a new benchmark for multi-object rearrangement in the form of multi-room environments."}, "weaknesses": {"value": "(i) One key problem with the paper is that it makes claims that are not fully substantiated. For example, the authors mention that object rearrangement solutions are based on RL and hand-coded planning methods; it is not clear what the authors mean by \"hand-coded planning methods\", but there are many other ways of solving this problem. Also, existing probabilistic planners can handle large domains and uncertainty resulting from partial observability. \n\n(ii) The discussion of related work unfortunately seems to be limited to the more recent RL-based or deep networks-based methods; there is no acknowledgement or discussion of the rich literature in hierarchical planning, including those based on RL and POMDPs, e.g., [1-3]. The existing papers have already explored  factorization of state space (and belief updates) in complex domains. The authors need to clarify how their proposed approach is different and makes a new contribution.\n\n(iii) Following up on previous points: it is unclear if/how the proposed approach is an hierarchical planner. The proposed pipeline processes sensory inputs to obtain concepts that are then used to compute a plan for the rearrangement task. This is the standard pipeline in many AI systems that process sensor inputs and plan actions. The \"abstraction system\" is just a manually encoded method that is executed to map the sensor inputs to the representation for POMDP planning. This can be contrasted with prior work on hierarchical planning with POMDPs [1, 2] where there is an actual hierarchy of POMDPs and tasks to be performed. In addition, these systems support complex state spaces, uncertainty in perception and actuation, different objective functions (e.g., optimize for travel distance and time), and have been used for planning on physical robot platforms.\n\n(iv) From the description of problem formulation and the algorithms, it is not clear if there is any actual uncertainty in actuation; even the uncertainty in perception is captured by a very simple model, and the \"partial observability\" seems to be a reference to the fact that the agent's view of the domain is limited at any point in time. It is also not clear why RL policies are needed for the low-level execution of simple movements in a simulation environment.\n\n(v) In the experimental evaluation, the baselines seem to be systems that pose the rearrangement task as a learning problem (e.g., with deep networks), or seek to complete the task after removing the limited uncertainty introduced in perception. It is also not clear what it means to \"remove the hierarchical planning\" in the HOOP-HP baseline, and how it impacts the corresponding state (also action, observation) space. Given the limited noise in the system, it is unclear why there is no comparison with a state of the art classical planning or probabilistic planning system. Finally, the statistical significance of the results shown in Table 1 is unclear.\n\n[1] Joelle Pineau and Sebastian Thrun. High-level Robot Behavior Control using POMDPs. National Conference on Artificial Intelligence (AAAI), 2002.\n\n[2] Mohan Sridharan, Jeremy Wyatt and Richard Dearden. Planning to See: A Hierarchical Approach to Planning Visual Actions on a Robot using POMDPs. Artificial Intelligence, 174 (11):704-725, 2010.\n\n[3] Harsha Kokel, Sriraam Natarajan, Balaraman Ravindran, and Prasad Tadepalli. RePReL: A Unified Framework for Integrating Relational Planning and Reinforcement Learning for Effective Abstraction in Discrete and Continuous Domains. Neural Computing and Applications, 35: 16877-16892, 2023."}, "questions": {"value": "Please address comments in the \"weaknesses\" section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "s84u6MeZfK", "forum": "7SkGH9yW3s", "replyto": "7SkGH9yW3s", "signatures": ["ICLR.cc/2026/Conference/Submission22421/Reviewer_ZgC5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22421/Reviewer_ZgC5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762743792650, "cdate": 1762743792650, "tmdate": 1762942210784, "mdate": 1762942210784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}