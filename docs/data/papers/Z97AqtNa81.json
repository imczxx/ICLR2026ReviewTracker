{"id": "Z97AqtNa81", "number": 3987, "cdate": 1757580366795, "mdate": 1759898059613, "content": {"title": "CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting", "abstract": "Multivariate time series forecasting (MTSF) is crucial across various domains but remains challenging due to three main difficulties: capturing the temporal patterns of each variable, modeling complex cross-variable dependencies, and eliminating spurious correlations. Most existing MTSF methods adopt an all-to-all paradigm that feeds all variable histories into a unified model to predict their future values without distinguishing their individual roles. However, this undifferentiated paradigm makes it difficult to identify variable-specific causal influences and often entangles causally relevant information with spurious correlations. To address this limitation, we propose an all-to-one forecasting paradigm that predicts each target variable separately. Specifically, we first construct a Structural Causal Model (SCM) from observational data and then, for each target variable, we partition the historical sequence into four sub-segments according to the inferred causal structure: endogenous, direct causal, collider causal, and spurious correlation. The prediction relies solely on the first three causally relevant sub-segments, while the spurious correlation sub-segment is excluded. Furthermore, we propose Causal Informed Transformer (CAIFormer), a novel forecasting model comprising three components: Endogenous Sub-segment Prediction Block (ESPB), Direct Causal Sub-segment Prediction Block (DCSPB), and Collider Causal Sub-segment Prediction Block (CCSPB), which model the endogenous, direct causal, and collider causal sub-segments, respectively. Their outputs are then combined to produce the final prediction. Extensive experiments and ablation studies on multiple benchmark datasets demonstrate the effectiveness of the CAIFormer.", "tldr": "", "keywords": ["Time Series Forecasting; Causal Analysis"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e5d0d8edf0be693a9c6bb0b13932eba4c9c99c1f.pdf", "supplementary_material": "/attachment/553db4175f9056eb0aaa3bf33c6782dbb5b2a0cc.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces CAIFormer, a novel approach to multivariate time series forecasting that departs from the conventional all-to-all paradigm where all variables' histories are fed into a unified model. The authors propose an all-to-one forecasting strategy that predicts each target variable separately based on a causal decomposition of the input history. The method first constructs a Structural Causal Model using the PC algorithm on observational data, then partitions each target variable's historical influences into four sub-segments: endogenous (the target's own history), direct causal (variables with direct causal relationships), collider causal (variables forming collider structures), and spurious correlation (which is discarded)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The extensive experimental validation across eight diverse datasets with multiple baseline comparisons shows thoroughness, and the ablation studies effectively demonstrate the contribution of each component. The paper maintains good clarity through well-structured presentation that logically builds from motivation through theory to implementation."}, "weaknesses": {"value": "The most critical limitation is the reliance on the PC algorithm for causal discovery, which assumes causal sufficiency (no hidden confounders) - an assumption rarely satisfied in real-world time series data. While the authors acknowledge this limitation and mention alternatives like FCI or tsFCI, they do not empirically evaluate these alternatives or discuss how violations of causal sufficiency might impact performance. The computational overhead of running causal discovery as a preprocessing step is mentioned but not thoroughly analyzed, particularly for high-dimensional datasets where causal discovery becomes computationally prohibitive."}, "questions": {"value": "How sensitive is the method to errors in the causal discovery phase, and have the authors considered using ensemble methods or bootstrapping to obtain more robust causal structures?\n\nThe paper uses linear PC throughout but mentions nonlinear variants - could the authors provide more insight into when nonlinear causal discovery would be preferred and how it might impact the overall framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RHM7B9Eftq", "forum": "Z97AqtNa81", "replyto": "Z97AqtNa81", "signatures": ["ICLR.cc/2026/Conference/Submission3987/Reviewer_Si3J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3987/Reviewer_Si3J"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761009493755, "cdate": 1761009493755, "tmdate": 1762917127280, "mdate": 1762917127280, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a Causally Informed Transformer (CAIFormer) for multivariate time series forecasting, which reformulates the traditional all-to-all paradigm into an all-to-one forecasting framework. \n\nSpecifically, for each target variable, the model first constructs a Structural Causal Model (SCM) from observational data, and then partitions the historical sequence into four sub-segments: endogenous, direct causal, collider causal, and spurious correlation.Only the first three causally relevant sub-segments are retained for prediction.\n\nEach sub-segment is processed through a dedicated self-attention block to capture variable-specific dependencies, and their outputs are finally concatenated and fused to generate the final forecast."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly describes the target task and provides a corresponding rationale for the proposed approach. The overall problem setup is easy to follow, the motivation for moving from the all-to-all to the all-to-one forecasting paradigm is intuitive.\n\n2. The proposed method is supported by a theoretical foundation. The authors present formal definitions and operator-based formulations to justify their causal decomposition framework, which enhances the soundness of the approach."}, "weaknesses": {"value": "1. The paper’s presentation lacks clarity in several aspects.\n\na) The discussion of causal path types (a–f) is overly detailed and fragmented — intuitively, the relationships between variables could be summarized more compactly, making the current exposition unnecessarily complex.\n\nb) The description of the Transformer architecture is vague: although matrix dimensions are provided, it remains unclear how the time-series data in each sub-segment are organized into the sequential format required by the Transformer. This ambiguity makes it difficult for readers to fully grasp the algorithmic flow.\n\n2. The paper’s causal discovery procedure is conceptually questionable.\n\nThe authors state that “To avoid trivial autoregressive effects, conditional independence tests are only applied across variables at the same time index.” However, in time-series settings, considering only instantaneous dependencies is insufficient and incomplete, as temporal lags often encode the essential causal dynamics. Ignoring cross-time effects undermines the validity of the discovered causal structure and its utility for forecasting.\n\n3. The authors propose leveraging causal relationships to improve forecasting performance. However, the paper does not clearly articulate the connection between causal reasoning and predictive performance. From the perspective of a Structural Causal Model (SCM), the causal generative mechanism of a variable can be fully determined by its parent nodes alone. it is unclear why identifying and removing so-called “spurious correlations”is necessary.If the goal is purely predictive performance, the conclusion from https://arxiv.org/abs/2402.09891 (NIPS2024) [1] suggests that incorporating all variables can effectively improve forecasting accuracy, which contradicts the fundamental premise of this paper.\n\n4. The PC algorithm adopted in the first stage is order-dependent, meaning that early errors in conditional independence testing can accumulate and propagate through the causal discovery process, potentially leading to numerous incorrect or spurious causal relationships. However, the authors do not provide empirical evidence showing whether the learned causal graphs approximate the ground truth, nor do they discuss the robustness of the algorithm with respect to noise, sample size, or ordering effects.\n\n[1] Nastl, Vivian, and Moritz Hardt. \"Do causal predictors generalize better to new domains?.\" Advances in Neural Information Processing Systems 37 (2024): 31202-31315."}, "questions": {"value": "1. Why do the authors only consider variables at the same time index? If this is the case, are the lagged variables in the time series ignored ? If these lagged variables are not properly masked, does that mean the resulting causal graph is inconsistent with the true temporal causal structure?\n\n2. The paper introduces causal reasoning into forecasting but still includes collider variables in the model. From a causal standpoint, the generation of the target T should depend only on its parents; including colliders and then removing their influence via projection seems unnecessary and conceptually inconsistent. If the goal is prediction rather than causal discovery, this also contradicts recent findings (e.g., NeurIPS 2024) https://arxiv.org/abs/2402.09891[1] showing that using all features—regardless of causality—often yields the best performance. Why, then, restrict the predictor to only selected causal sub-segments?\n\n3. Could the authors provide empirical evidence or further clarification on whether the causal graphs learned by the PC algorithm approximate the ground-truth structures, and how the overall forecasting performance is affected when the discovered graphs contain errors or spurious relations?\n\n4. The ablation results show that the ESPB-only variant performs almost as well as the full model. Does this imply that other variables contribute little effective information to the prediction? If relying mainly on the autoregressive features of a single variable already yields near-optimal performance, might the claimed benefits of the proposed causal decomposition be overstated?\n\n[1] Nastl, Vivian, and Moritz Hardt. \"Do causal predictors generalize better to new domains?.\" Advances in Neural Information Processing Systems 37 (2024): 31202-31315."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sWIjQYcfx7", "forum": "Z97AqtNa81", "replyto": "Z97AqtNa81", "signatures": ["ICLR.cc/2026/Conference/Submission3987/Reviewer_qzzU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3987/Reviewer_qzzU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922193370, "cdate": 1761922193370, "tmdate": 1762917127060, "mdate": 1762917127060, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel “one-versus-all” prediction model called CAIFormer, which predicts each target variable individually. Specifically, CAIFormer first constructs a structural causal model based on observational data. For each target variable, it then divides the historical sequence into four sub-segments according to the inferred causal structure: endogeneity, direct causality, collision causality, and spurious correlation. Predictions rely solely on the first three causally relevant sub-segments, while the spurious correlation segment is excluded. CAIFormer achieves state-of-the-art performance across eight datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. State-of-the-art performance. As shown in Table 1, CAIFormer achieves state-of-the-art performance across eight datasets.\n\n2. Solid theoretical foundation. The author provides extensive theoretical proofs in the methodology and appendices, enhancing the reliability of the approach.\n\n3. Clear Motivation. The paper argues that the non-partitioned model makes it difficult to identify the causal effects of specific variables and often confuses causally relevant information with spurious correlations. To address this limitation, the paper proposes a “one-versus-all” prediction model, which separately predicts each target variable. The motivation is clear."}, "weaknesses": {"value": "1. Lack of relevant prior work. The authors claim in the abstract and introduction that previous work has overlooked the differing causal effects various variables may exert relative to the target. However, a similar approach (i.e., multiple lags) has already been proposed in TimePro[1]. The authors should include a discussion of TimePro and explicitly state the differences between their method and TimePro. Furthermore, Table 1 needs to demonstrate that CAIFormer outperforms TimePro.\n\n[1] TimePro: Efficient Multivariate Long-term Time Series Forecasting with Variable- and Time-Aware Hyper-state\n\n2. Unsatisfactory readability. For lines 195-213, the author should add appropriate paragraph breaks. The Avg column in Table 1 should be removed. What does “condition e” mean in Figure 2? The author should add a note.\n\n3. Many formulas are unnecessary. For example, Line 327-344. The introduction of numerous letters or formulas makes the Methods section overly redundant. As a result, the author provides less content on the Related works and lacks clarity in describing the background of the methods."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "SU8GzfYUOu", "forum": "Z97AqtNa81", "replyto": "Z97AqtNa81", "signatures": ["ICLR.cc/2026/Conference/Submission3987/Reviewer_QtHD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3987/Reviewer_QtHD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978963222, "cdate": 1761978963222, "tmdate": 1762917126680, "mdate": 1762917126680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CAIFormer, a causal-informed transformer framework for multivariate time-series forecasting (MTSF). Based on a causal discovery step using the Peter-Clark (PC) algorithm, the method decomposes the information flow into Direct Causal Segments (DCS) and Collider Causal Segments (CCS). The authors further provide a theoretical analysis showing that an orthogonal projection operator $\\Psi$ can remove spurious dependencies arising from collider structures, thereby improving generalization. Empirically, CAIFormer is evaluated on several standard MTSF benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's main strength lies in its novel reframing of the MTSF problem from a causal perspective. Moving from a monolithic \"all-to-all\" approach to a causally informed \"all-to-one\" paradigm is a significant and well-motivated conceptual contribution that could inspire future research in this area.\n\n2. The CAIFormer architecture is not arbitrary; its design is directly motivated by the proposed causal decomposition. The use of separate modules for different causal roles (ES, DCS, CCS) is elegant and provides a clear path to improved model interpretability."}, "weaknesses": {"value": "1. The theoretical derivation in Section 3.5 suffers from an inconsistency and relies on an overly strong independence assumption. Specifically, it critically assumes that the target variable $V_i$ and its spouse variable $V_s$ are strictly independent, a condition that rarely holds in practice.\n\n2. The experimental scope is limited. The comparison includes only baselines published up to 2023. Given the rapid progress in MTSF, evidenced by numerous recent works from 2024 and 2025, it remains unclear whether CAIFormer can still achieve competitive performance against the latest state-of-the-art methods. Without such comparisons, the empirical evidence supporting the claimed advantages remains incomplete.\n\n3. The paper provides insufficient analysis of the reliability and interpretability of the causal discovery step. The entire framework depends on the DAG learned by the PC algorithm, which is sensitive to noise and relies on the faithfulness assumption. However, the authors present no quantitative evaluation of the learned graph’s stability or correctness, nor do they discuss how errors in causal discovery affect the downstream segmentation (DCS and CCS) and forecasting performance."}, "questions": {"value": "1. The Granger-causality heatmaps in Fig. 1 clearly show that almost all variable pairs exhibit non-zero causal influence, implying that the variables are highly interdependent. However, the theoretical derivation in Section 3.5 (Eqs. (3)–(7)) explicitly assumes that the target variable $V_i$ and its spouse $V_s$ are independent. This raises a fundamental concern: if such independence never holds empirically—as suggested by Fig. 1—does this assumption invalidate or substantially weaken the correctness and rigor of all subsequent theoretical results (e.g., the definition of $\\mathcal{F}_\\Psi$, the projection property, and Theorem 3.1)? Could the authors clarify whether the claimed generalization guarantee still holds when variables are only weakly dependent, and how the proposed framework behaves under the dense causal graphs observed in Fig. 1?\n\n2. Figures 1 and 4 appear to convey different causal densities: the Granger causality heatmaps show dense interactions, whereas the DAGs discovered by the PC algorithm are sparse and partly disconnected.\n\n3. Why are the latest state-of-the-art (SOTA) models not included in the benchmark comparison? Do the authors expect CAIFormer to maintain its advantage against these stronger baselines?\n\n4. Which representation (Granger vs. PC) should readers regard as the underlying causal structure assumed by CAIFormer?\n\n5. How robust is CAIFormer to errors in the discovered causal graph? For instance, what happens to performance if a certain percentage of edges are randomly perturbed—for example, by missing true causal links or introducing spurious ones? This would directly test the fragility of the entire framework.\n\n6. Could the authors provide a discussion comparing the “hard” discarding of the SCS block to a “soft” alternative? For example, one could still feed the SCS variables into a separate block but apply strong regularization (e.g., a large L1 penalty on its output weights) or use an attention mechanism that strongly suppresses attention to this block. This would clarify whether complete removal is truly necessary or whether a less drastic approach would suffice."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xu7LZottza", "forum": "Z97AqtNa81", "replyto": "Z97AqtNa81", "signatures": ["ICLR.cc/2026/Conference/Submission3987/Reviewer_PUAg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3987/Reviewer_PUAg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990325947, "cdate": 1761990325947, "tmdate": 1762917126459, "mdate": 1762917126459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}