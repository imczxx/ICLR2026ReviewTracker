{"id": "JOroN3ORXp", "number": 5517, "cdate": 1757917485203, "mdate": 1759897969924, "content": {"title": "AutoMixer: A Lightweight and Scalable Industrial 5.0 Safety Assurance Model with Multi-Scale Adaptive Dual-Attention", "abstract": "With the rapid growth of intelligent transportation and industrial automation, traffic safety management and industrial system safety generate vast amounts of spatio-temporal data. These data offer rich temporal and spatial patterns for analysis but pose significant challenges, including dynamic traffic patterns, high-dimensional sensor data, and complex anomalies in industrial systems. Traditional methods struggle to capture nonlinear accident patterns, handle noisy sensor data, or model intricate multi-variable interactions, especially in real-time scenarios. Although deep learning and large-scale models have improved the accuracy of accident prediction and anomaly detection, their reliance on complex spatial operations and large parameter sizes creates computational bottlenecks, limiting scalability in large-scale and real-time safety applications. Therefore, we propose AutoMixer, a lightweight and scalable model that avoids explicit spatial modeling. It uses a dual cross-attention module to identify coupled trend and periodic features in multi-resolution spatio-temporal data. Extensive experiments demonstrate that AutoMixer consistently outperforms state-of-the-art baselines, achieving 7% higher detection accuracy while effectively handling large-scale node distributions and high-frequency data. AutoMixer provides a practical and deployable solution for real-time accident detection and industrial system safety analysis, enhancing computational efficiency and applicability in resource-constrained environments, thus optimizing performance for large-scale traffic and industrial safety tasks.", "tldr": "", "keywords": ["Spatio-temporal prediction", "Efficiency optimization", "Sequence frequency decomposition", "Dual cross-attention"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ec9a2979b10bbdcfd9bd48b5b0bec0445f312d73.pdf", "supplementary_material": "/attachment/a6d4268f49a4276e68e8fb2543a7b0a12986963b.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents **AutoMixer**, a lightweight time-series forecasting model designed for Industrial 5.0 safety and traffic anomaly detection. The model applies frequency-domain decomposition (DFT-based) to capture multi-scale temporal features and uses a dual cross-attention mechanism to integrate trend and periodic components without explicit spatial modeling. The authors claim state-of-the-art performance on multiple datasets such as ETT, Electricity, and PEMS-BAY."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.   Lightweight design with efficient inference suitable for real-time industrial applications.\\\n2.   Ablation studies are reasonably complete.\n3.   Stable performance on short-term forecasting tasks.\n4.   Implementation simplicity facilitates reproducibility."}, "weaknesses": {"value": "1.   Limited novelty: The proposed combination of frequency decomposition and attention mechanisms is not conceptually new.\n\n2.   Weak long-horizon performance: The model’s accuracy degrades significantly for long forecasting horizons (e.g., output=720), contradicting the claimed “long-term scalability.”\n3.   Marginal overall improvement: Across most datasets, AutoMixer’s improvements over baselines such as FEDformer and TimeMixer are small and often within the margin of experimental variance. In some long-term cases, it even performs worse. This weakens the empirical significance of the claimed contribution.\n4.   Presentation flaw: Main comparative results are absent from the main text, violating transparency norms.\n5.   Lack of empirical validation for spatial modeling removal: No evidence that omitting spatial graphs maintains robustness in truly spatially correlated datasets.\n6.   Lack of evidence for removing spatial modeling: The paper does not test whether omitting explicit spatial graphs maintains robustness in spatially correlated datasets such as traffic networks."}, "questions": {"value": "1.   What is the fundamental difference between AutoMixer and TimeMixer/FEDformer in terms of mechanism?\n2.   Since AutoMixer eliminates spatial graphs, have the authors evaluated its performance on datasets with strong spatial topology (e.g., traffic networks)?\n3.   The results show a noticeable drop in performance for output=720.Have the authors analyzed why AutoMixer fails to maintain long-horizon stability?\n4.   The paper frequently emphasizes scalability and lightweight design. Could the authors provide FLOPs, parameter count, and inference latency comparisons with TimeMixer or FEDformer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "amU6UNBT6N", "forum": "JOroN3ORXp", "replyto": "JOroN3ORXp", "signatures": ["ICLR.cc/2026/Conference/Submission5517/Reviewer_mk9c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5517/Reviewer_mk9c"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761057355233, "cdate": 1761057355233, "tmdate": 1762918106120, "mdate": 1762918106120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents AutoMixer, a lightweight and scalable model for spatial-temporal modelling.   \nIt consists of four components: adaptive frequency-domain decomposition, dynamic coupled feature weighting, a dual-attention mechanism for spatiotemporal analysis, and a multi-resolution dynamic coupling module. \n\nExperiments are conducted on time-series and spatial-temporal modelling tasks such as energy, weather, traffic, etc.   \nSeveral baseline methods such as TimeMixer, PatchTST, AutoFormer, and FedFormer are adopted for comparison.   \nAblation studies of module and parameter analysis are conducted. Model size, training time, inference time, and GPU memory are also compared and reported."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "## Strengths\n- This paper proposes AutoMixer, with four core modules: Adaptive Frequency-Domain Decomposition, dynamic coupled feature weighting, dual-attention mechanism, and multi-resolution dynamic coupling. \n- Experiments are conducted on several datasets: Ett, Electricity, Weather, Metr-LA, PEMS-BAY, Traffic, and PEMS03/08. \n> Baseline methods include TimeMixer 2024, Informer 2021, AutoFormer 2021, FedFormer 2022, PyraFormer 2022, DLinear 2022, and PatchTST 2023.   \n> Ablation study, parameter analysis, complexity and runtime analysis are reported."}, "weaknesses": {"value": "## Weaknesses\n- **Lack of Novelty** The method is a simple combination of mature modules/techniques in the area of time-series analysis and spatiotemporal modelling. \n> E.g., Frequency-Domain Decomposition has been proposed in FedFormer.   \n> Dynamic coupled feature weighting is a basic and simple re-weighting using NN.   \n> Dual-attention mechanism modifies self-attention, which has been extensively studied in existing literature such as AutoFormer, Informer.   \n> Multi-resolution processing is also a common technique in spatial-temporal modelling, e.g., PatchTST. \n- **Out-of-Date Comparison** The baseline models are out-of-date: TimeMixer 2024, Informer 2021, AutoFormer 2021, FedFormer 2022, PyraFormer 2022, DLinear 2022, and PatchTST 2023. Among them, only TimeMixer is a 2024 paper, others are not new and recent SOTA methods. \n> Most recent methods such as LLMs are not discussed and compared, e.g., Time-LLM, Uni-ST [R2]. \n\n\n[R1] Jin, Ming, et al. \"Time-llm: Time series forecasting by reprogramming large language models.\" arXiv preprint arXiv:2310.01728 (2023).\n\n[R2] Yuan, Yuan, et al. \"Unist: A prompt-empowered universal model for urban spatio-temporal prediction.\" Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024."}, "questions": {"value": "In table 3, why the results of Informer, ... , DLinear are quite large (e.g., 64608), while TimeMixer is only 41.1397?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9NYAL1WHqA", "forum": "JOroN3ORXp", "replyto": "JOroN3ORXp", "signatures": ["ICLR.cc/2026/Conference/Submission5517/Reviewer_Wxky"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5517/Reviewer_Wxky"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556366382, "cdate": 1761556366382, "tmdate": 1762918104738, "mdate": 1762918104738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an ML model designed to predict accidents and detect problems in traffic systems and industrial facilities (like factories and power plants). Its problem statement is as follows: Modern transportation systems and factories generate massive amounts of sensor data. Traditional analysis methods struggle because the data is complex and noisy, real-time analysis is needed but computationally expensive and existing AI models are too slow or inaccurate for practical use. Innovations in Automixer are stated as: (a) smarter pattern recognition - It breaks down data into different frequency components to identify both regular patterns and trends (b) Multi-scale analysis at different time scales simultaneously, (c) its dual-attention mechanism and (d) No need for explicit spatial modeling of the data. Results claimed as outperforming existing methods by roughly 4% in detection accuracy when tested on traffic accident prediction (using data from road sensors) and industrial equipment monitoring for failures in power systems and factories, even in the presence of \nshort-term historical data (100 data points),  incomplete sensor readings, and at scale."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This is a well-written paper that looks at the standard problem of predicting accident potential on roads and defect potential in manufacturing operations. The techniques employed seemed sound. Results were good (a 4% improvement). Ablation studies were done (good)."}, "weaknesses": {"value": "Lines of the graphs in Figures 2 and 3 need to have more contrast in visibility. Also the use of colors will be a barrier for readers with vision issues.\n\nComputational resource usage of the various techniques were presented. So that the claim of real time response is supported sugges adding graphs on computational times."}, "questions": {"value": "How did the presented techniques compare with the baselines with respect to computational time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ySTBufbqqx", "forum": "JOroN3ORXp", "replyto": "JOroN3ORXp", "signatures": ["ICLR.cc/2026/Conference/Submission5517/Reviewer_EGtJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5517/Reviewer_EGtJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761666006710, "cdate": 1761666006710, "tmdate": 1762918104495, "mdate": 1762918104495, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores accident prediction and anomaly detection with an attention-based framework. It leverages a dual cross-attention head to model both spatial and temporal dependency. The authors aim to address the high computational cost of large-scale models. Experiments have been conducted on real datasets by comparing with transformer-based models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper pointed out the weaknesses of the transformer-based model for traffic prediction.\n2. Both accuracy and efficiency have been reported.\n3. Figure 1 is a good example to explain the complicated framework."}, "weaknesses": {"value": "1. The paper states that \"their reliance on complex spatial\noperations and large parameter sizes creates computational bottlenecks\" but have not provided any supportive empirical data about the bottlenecks. In fact, according to Table 4 and Figure 3, the proposed method is even worse and at the same level as the baseline. It is confusing how the proposed method addresses \"Lightweight and Scalable\".\n\n2. The framework is not novel. It basically modifies the transformer framework. Such a change is incremental.\n\n3. According to Table 3, the MSE of Informeron London 64608, where the MSE of the proposed method is 40. For some columns, the result is NA. It is unclear why NA is there, and it looks like the baselines have not been used correctly. \n\n4. The paper only compares with transformer-based models. It is well-known transformer is heavy. Since the motivation is the \"cost\", the author should compare with light models, such as graph-based models.\n\n5. The experiment quality is low. The maximum number of nodes is only 300. It is not large enough to prove the scalability. Varying the number of nodes has not been conducted. The error variance has not been reported. There is no visualization on a real map for the prediction."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "iaB5D0FdZ0", "forum": "JOroN3ORXp", "replyto": "JOroN3ORXp", "signatures": ["ICLR.cc/2026/Conference/Submission5517/Reviewer_THT7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5517/Reviewer_THT7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841417102, "cdate": 1761841417102, "tmdate": 1762918104223, "mdate": 1762918104223, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}