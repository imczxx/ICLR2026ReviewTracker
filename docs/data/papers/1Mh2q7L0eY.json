{"id": "1Mh2q7L0eY", "number": 356, "cdate": 1756736480124, "mdate": 1759898265701, "content": {"title": "Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking", "abstract": "In information retrieval, training reranking models mainly focuses on two types of objectives: metric learning (e.g. contrastive loss to increase the predicted scores on relevant query-document pairs) and classification (binary label prediction of relevance vs. irrelevance).\nFor BERT-style encoders, various studies have shown that contrastive learning (CL) can be more effective than discriminative (classification) learning. However, for large language models (LLMs), classification via supervised fine-tuning (SFT), which predicts ''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears more promising as it aligns well with the generative nature of LLMs.\nThis divergence raises a central question: which objective is intrinsically better suited to LLM-based reranking, and what mechanism underlies the difference? In this work, we conduct a comprehensive comparison and analysis between CL and SFT for reranking, taking the universal multimodal retrieval (UMR) as the experimental playground. We first decompose the objectives into two components: weight, which controls the magnitude of those updates, and direction, which guides the model updates, then present a unified framework for understanding their interactions. Through probing experiments, we find that SFT provides a substantially stronger weighting scheme than CL, whereas the preferred scoring direction shows no clear winner. Taken together, these results point to a consistent advantage of SFT over CL for LLM reranking. To further validate our findings, we conduct large-scale training with SFT and present new state-of-the-art rerankers on the MRB benchmark. We also provide ablations on SFT settings and expect our findings to benefit future research and applications in this area.", "tldr": "", "keywords": ["Multimodal Retrieval", "LLM Reranking"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/460a4c77bb2f8d79b8101c292e7524200dfe880f.pdf", "supplementary_material": "/attachment/786dab6ac371e7770e01dd47fd64c6fdf9170008.zip"}, "replies": [{"content": {"summary": {"value": "This paper compares two popular approaches for training reranking models—Supervised Fine-Tuning (SFT) and Contrastive Learning (CL)—in the context of large language model (LLM)-based reranking. The paper introduces a unified framework that decomposes the loss functions into two key components: weight and direction. The authors conduct a comprehensive theoretical analysis and empirical comparison between SFT and CL using the Universal Multimodal Retrieval (UMR) task. Their findings suggest that SFT offers better performance than CL due to its stronger optimization signals, specifically in the weight component. The authors also introduce a new multimodal reranking benchmark (MRB), which consists of 40 datasets across various modalities. Through this analysis, they develop new state-of-the-art rerankers, GMR-3B and GMR-7B, achieving superior results in the MRB benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a novel framework to analyze two popular reranking training methods, SFT and CL, by decomposing their loss functions. This decomposition into weight and direction provides new insights into their effectiveness. Additionally, the creation of the MRB benchmark is a significant contribution to the multimodal reranking field, offering a diverse and comprehensive dataset for evaluating models.\n\n2. The authors provide a thorough theoretical analysis combined with extensive experiments. They rigorously evaluate both SFT and CL, demonstrating that SFT outperforms CL in terms of model performance. The experiments are well-designed, and the results are statistically significant.\n\n3. The paper is clearly written, with well-defined objectives, methodology, and results. The use of equations and illustrations, such as Figure 1, helps clarify the distinctions between the two training paradigms. The explanations of the framework, loss function decomposition, and the MRB benchmark are easy to follow.\n\n4. The findings that SFT offers superior performance to CL for LLM-based reranking are crucial for future research and practical applications in multimodal information retrieval. The introduction of the MRB benchmark and the state-of-the-art models developed (GMR-3B and GMR-7B) have the potential to impact a wide range of tasks in multimodal retrieval systems."}, "weaknesses": {"value": "1. While the MRB benchmark is comprehensive, it might be seen as overly focused on tasks where image-text retrieval is central. Future work could explore additional modalities or larger-scale datasets to evaluate the generalizability of the reranking models to other forms of multimodal data, such as video or audio.\n\n2. Given the reliance on MRB for validation, there is a risk of overfitting to this specific benchmark, as many models may perform well only on the datasets included in MRB but struggle on entirely new or more complex multimodal benchmarks. The paper could benefit from additional cross-benchmark evaluations to test the robustness of the proposed models."}, "questions": {"value": "1. Since the MRB benchmark is restricted to single-image inputs, would the performance of the models differ when dealing with queries or documents containing multiple images or mixed modalities (e.g., a combination of images and text)?\n\n2. The paper mentions the use of random and hard negative sampling strategies. How do the negative sampling strategies influence the performance in specific modalities (e.g., images vs. text)? Is there a particular strategy that consistently outperforms the others across all tasks?\n\n3. While the paper primarily focuses on SFT and CL, would it be worth exploring hybrid architectures that combine the strengths of both methods? How could a mixed approach impact the performance of multimodal rerankers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jYx9PNdB0r", "forum": "1Mh2q7L0eY", "replyto": "1Mh2q7L0eY", "signatures": ["ICLR.cc/2026/Conference/Submission356/Reviewer_xxqB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission356/Reviewer_xxqB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893460088, "cdate": 1761893460088, "tmdate": 1762915501887, "mdate": 1762915501887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper asks whether Supervised Fine-Tuning (SFT) or Contrastive Learning (CL) is inherently better for LLM-based (multimodal) reranking. Authors build a unified reranking loss (URL) that decomposes training signals into two orthogonal parts—weight (magnitude) and direction (update vector)—such that SFT and CL can be compared under the same lens. Empirically, SFT beats CL (on a newly assembled, broad Multimodal Reranking Benchmark). Ablating URL shows the weighting scheme explains most of the gap while update direction matters less. Finally, the authors train GMR-3B/7B rerankers with SFT and report SOTA on MRB."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Multi-modal retrievers are very popular these days, and less work is dedicated to multi-modal rerankers. It is an interesting topic per se—given how rerankers usually boost performance in any given setting—we can see how GMR (but also the tested baselines) improve over the tested retriever (GME-2B). \n* Overall the paper is clear, straight forward and well written (a few things could be improved though, see later). Related works contain most of the relevant references I am aware of. I would maybe add [1] somewhere (the first paper doing a cross-encoder with BERT).\n* The weight/direction derivation gives a mechanistic account of why SFT wins: SFT’s weights are per-document (no across-negative normalization), while CL’s weights couple all negatives, which weakens positive signal magnitude-especially when many easy negatives are present. The derivation looks correct to me. The loss decomposition shows that supervised fine-tuning (SFT) and contrastive learning (CL) differ mainly in how they weigh each training example, not in the basic direction of the update.\n* This feels like an interesting (**although not ground breaking**) contribution imo. But the main takeaway is SFT > CL for training pointwise rerankers, which is a valuable finding by itself.\n* After ablations (SFT vs CL), authors train two multi-modal rerankers (GMR 2B and GMR 7B) on 1.5M instances. They also assemble a new benchmark MRB (40 **existing** datasets; multiple modalities and tasks), making results quite robust; Table 4 shows GMR outperforming strong baselines across categories. Note that the baselines are 2B (or 4B for Qwen). \n\n[1] Passage Re-ranking with BERT"}, "weaknesses": {"value": "* Novelty/contribution feels a bit limited, but I still could see this paper fit into ICLR (especially if authors release the code and models as stated in the paper). Especially, it focuses (by design) on pointwise approaches, and obfuscate listwise rerankers which might become more predominant in the future (due to the nature of LLMs).\n* “MRB excludes datasets where the retriever already scores very high”; in these cases rerankers have no effect? Scores could be very high for retrievers but still be improved by rerankers in practice no? Anyway, authors could also have included “weaker” retrievers; this would even show more the effect of reranking. Maybe varying topk could have been beneficial too, to test whether SFT’s advantage holds when the negative mix changes.\n* Although the paper is clear overall, some parts could be improved/clarified (not critical). There are many typos/weird formulations across the paper; for instance, in the Supervised Fine-Tuning paragraph (Section 3.2), “The objective is predicting correct next token” or “Then predict the likelihood of “yes” [...]”. And there are many more...\n* It seems that what makes ICL different from SFT is the fact that ICL couples all negatives through a softmax denominator (vs independently for SFT); it feels that the impact of negatives could have been studied further. Do findings still apply with 1 neg? 100 negs? What about temperature which is barely discussed (although is it common practice)?"}, "questions": {"value": "See other questions in weaknesses; see also\n\n* In Appendix E.3, unfreezing the LM head benefits CL but not SFT. Could you explore whether adding a small projection layer (instead of the LM head) narrows the gap? That would indicate whether SFT’s advantage comes from leveraging pretrained lexical priors?\n* Do you think your analysis could extend to pairwise or listwise rerankers where the loss itself defines relative weighting across candidates rather than independent pairs? Clarifying this could help generalize the decomposition beyond pointwise reranking.\n* Authors directly tackle multi-modal reranking; could you show the same findings in standard text scenarios (mono- and/or multi-lingual)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "km3kZVa4D9", "forum": "1Mh2q7L0eY", "replyto": "1Mh2q7L0eY", "signatures": ["ICLR.cc/2026/Conference/Submission356/Reviewer_W9sD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission356/Reviewer_W9sD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921101903, "cdate": 1761921101903, "tmdate": 1762915501666, "mdate": 1762915501666, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper systematically investigates two primary training paradigms for large language model (LLM)-based reranking—Supervised Fine-Tuning (SFT) and Contrastive Learning (CL)—within a universal multimodal retrieval setting. The authors introduce a unified theoretical framework that decomposes both objectives into weight and direction components, enabling a fair analytical comparison. Through extensive probing experiments, they show that the weighting mechanism in SFT provides stronger optimization signals than CL, accounting for most of the performance gap. The study culminates in the development of GMR (General Multimodal Reranker) models (3B and 7B parameters), trained via SFT, that achieve state-of-the-art results on a newly constructed MRB benchmark comprising 40 multimodal retrieval datasets. The work provides both theoretical insight and practical advances for multimodal reranking."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1, Extensive experiments, including ablations, controlled comparisons, and probing analyses, convincingly support the claims.\n\n2, MRB provides a comprehensive, standardized testbed likely to benefit the broader research community.\n\n3, GMR models consistently outperform existing multimodal rerankers across 40 datasets.\n\n4, The paper addresses a timely and underexplored question—the objective design for LLM-based reranking—bridging theoretical understanding with real-world performance."}, "weaknesses": {"value": "1, The conclusion of this theoretical analysis – \"CL computes the weight using all positive and negative documents within a sample, while SFT assigns weights independently per document, making this the likely key factor in performance variation\" – is extremely obvious. It can be verified simply by checking which terms are involved in the calculation when computing the loss. What we are more curious about is:  Why would training with both positive and negative examples lead to better or worse performance? We need a theoretical explanation from perspectives such as generalization, embedding space, and the difficulty of training convergence. These are exactly the areas where mathematical analysis should play its role.\n\n2, In the ai search era, we mainly care about llm reranker for text. Experiments on mllm rerankers are somehow limited.\n\n3, While weight and direction are well formalized, their intuitive interpretation in semantic space could be further elaborated. e.g. what's the difference between \"generating\" the score and the traditional \"encoding then scoring with mlp\" pipeline?"}, "questions": {"value": "1, What about list-wise reranking (where llm generates a sequence of doc ids)? e.g (https://aclanthology.org/2024.emnlp-main.491.pdf) In this case, what's the difference between sft and cl?\n\n2,  How sensitive is the performance gap between SFT and CL to negative sampling strategies or batch size?\n\n3, Does SFT’s superior performance persist when the LLM backbone is not generative? e.g. A randomly initialized LLM"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EgGdkgXoSv", "forum": "1Mh2q7L0eY", "replyto": "1Mh2q7L0eY", "signatures": ["ICLR.cc/2026/Conference/Submission356/Reviewer_XjCJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission356/Reviewer_XjCJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927689338, "cdate": 1761927689338, "tmdate": 1762915501456, "mdate": 1762915501456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the tradeoffs between direct supervision (binary cross entropy) and contrastive loss (InfoNCE) for training reranking models. They decompose each loss into two parts: weight (gradient magnitude) and direction. Given that both losses rely on the same data, one can mix and match components to have a new loss that uses the weight of direct supervision and direction of contrastive (and vice versa). The authors find that direct supervision is more effective than contrastive in their experiments, and analysis reveals that it is in large part because of the \"weight\" component of direct supervision --- extrapolating from the analysis, my sense is the weight is potentially more robust against easy negatives, given that contrastive leads to relatively small gradients. They train a reranker with direct supervision and see strong results across multiple benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The paper nicely walks through the differences of direct supervision and contrastive loss, fundamental concepts for embedding and reranker training.\n\nS2. There was extensive analysis of the two losses, including of their hybrid forms. This analysis reveals some insights for reranker training, although it was unclear how this influenced their main result experiments. Those experiments simply could have use direct supervision and contrastive as a hyperparameter to explore.\n\nS3. The authors train multiple versions of Qwen2.5-VL-Instruction for reranking with strong performance across multiple benchmarks. Details for training and data selection are provided. The authors also say they will release code, data and models."}, "weaknesses": {"value": "W1. The paper is not self contained in the main text. Many of the main results are in the appendix. For this statement \"Rival and surpass leading textual reranker\", there is no easy way for the reader to verify. The relevant results are in the appendix, and not averaged across datasets.\n\nW2. There are only experiments when reranking the top-100 retrieved documents, but many real world settings will require reranking more or less than this amount. Given that the reranker here is pointwise, it would be relatively straightforward to report results across a large range of top-N rather than only N=100. See https://arxiv.org/abs/2411.11767v2 which incorporates a related evaluation protocol and shows how reranker quality can degrade as more documents are reranked.\n\nW3. The masking approach in sec 4.1 seems very similar to margin-based methods, yet no margin-based methods are explored. It would be interesting to see if contrastive loss with additive margin yields a similar effect. https://arxiv.org/abs/2203.02167\n\nW4. There are more losses that can be explored. The RD-Suite paper https://arxiv.org/abs/2306.04455 is focused on distillation, but it is a good starting point for exploring other losses. RankGPT and Pairwise Rank Prompting (PRP) are not well suited for multimodal reranking unless multiple documents can be represented in the same context.\n\nW5. Importantly, not many approaches for negative selection are explored. Given that one of the main weaknesses of CL is small gradients, likely caused by easy negatives, it seems important to explore the proposed framework under different negative selection strategies. Previous work shows more than a 10% difference in nDCG is possible when using different negative selection strategies for embedding models, and it's plausible this would apply to rerankers, see https://arxiv.org/abs/2407.15831\n\nW6. Finally, the authors should make it clear whether they plan to release the model or data. These would greatly strengthen the contribution of the paper."}, "questions": {"value": "Did you investigate whether SFT or CL is more robust against hard negatives? Jacob et al investigate reranker failures and find that reranker can get progressively worse as they need to rerank more documents at test time, suggesting they are undertrained against noisy negatives. See: https://arxiv.org/abs/2411.11767"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ADME92qcd7", "forum": "1Mh2q7L0eY", "replyto": "1Mh2q7L0eY", "signatures": ["ICLR.cc/2026/Conference/Submission356/Reviewer_51SZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission356/Reviewer_51SZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission356/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129026488, "cdate": 1762129026488, "tmdate": 1762915501156, "mdate": 1762915501156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}