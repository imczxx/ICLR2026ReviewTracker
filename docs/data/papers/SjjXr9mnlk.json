{"id": "SjjXr9mnlk", "number": 1568, "cdate": 1756892700398, "mdate": 1762919788181, "content": {"title": "From Motion to Behavior: Hierarchical Modeling of Humanoid Generative Behavior Control", "abstract": "Human motion generative modeling aims to synthesize complex motions from daily activities. However, current research is fragmented, focusing on either low-level, short-horizon motions or high-level, disembodied action planning, thereby neglecting the hierarchical and goal-oriented nature of human activities. This work shifts the research focus from motion generation to the more holistic task of humanoid behavior modeling. To formally address this, we first introduce Generative Behavior Control (GBC), a new task focused on generating long-term, physically plausible, and semantically coherent behaviors from high-level intentions. To tackle this task, we present a novel framework that aligns motion synthesis with hierarchical plans generated by large language models (LLMs), leveraging principles from task and motion planning. Concurrently, to overcome the limitations of existing benchmarks, we introduce the GBC-100K dataset, a large-scale corpus annotated with hierarchical semantic and motion plans. Experimental results demonstrate our framework, trained on GBC-100K, generates more diverse and purposeful human behaviors with up to 10$\\times$ longer horizons than existing methods. This work lays a foundation for future research in behavior-centric modeling, with all code and data to be made publicly available.", "tldr": "We introduce Generative Behavior Control (GBC) and the GBC-100K dataset to generate long-horizon, goal-directed, and coherent humanoid behaviors via LLM planning and physics-informed control.", "keywords": ["Human motion generation", "Long-horizon synthesis", "Task planning", "Motion planning", "Behavior control"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/7c1888332dfe48654f7506c3c66c081e25486693.pdf", "supplementary_material": "/attachment/e7d49c4fb719cea22b3a4182d317118447f766a0.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Generative Behavior Control (GBC), a new task aimed at synthesizing long-horizon, goal-directed, and physically plausible humanoid behaviors. The authors present two main contributions:\n\n* PHYLOMAN framework, which integrates LLM-based planning, a novel Multi-segment Parallel Motion Diffusion Model (MP-MDM), and physics-based control for behavior generation.\n\n* GBC-100K dataset, a large-scale dataset combining SMPL motion estimations and hierarchical textual annotations, designed to support and evaluate GBC.\n\nExperiments across HumanML3D and GBC-100K are reported, with claims that the method generates more diverse, semantically coherent, and longer motion sequences than prior baselines"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Ambitious scope: The work reframes the field from motion generation to behavior generation, highlighting the importance of goal-directedness.\n\n2. Scalability: Dataset construction is large-scale, leveraging ∼500k videos and semi-automated annotation pipelines, which could benefit the community if released.\n\n3. Long-horizon motion generation: The MP-MDM parallel generation strategy is technically interesting and addresses efficiency for multi-second or minute-long behaviors."}, "weaknesses": {"value": "1. Dataset reliability:\n\n* The dataset relies on monocular SMPL estimation (TRAM) as its “gold standard,” which is problematic because SMPL often drifts in translation even when subjects are static (e.g., the provided example clip (`H--TB3aFpxY_000115_000125`) shows the person standing still while SMPL translation varies). This undermines claims of physical plausibility.\n\n* Using noisy pseudo-ground-truth motion as the foundation of a benchmark (evaluation target) introduces significant bias; thus, it is questionable whether GBC-100K can be considered a reliable benchmark.\n\n2. Evaluation design flaws:\n\n* In Table 2, comparisons confound dataset quality with model design since training and test data are simultaneously altered. To properly assess the dataset’s contribution, training sets should vary while the test set remains fixed.\n\n* In Tables 3 and 4, if the evaluation test set is indeed GBC-100K, then performance comparisons may simply reflect train-test overlap. Distribution similarity between train and test splits risks inflating results and obscures real generalization ability.\n\n* Physical grounding gap: Despite emphasizing “physics-informed” behavior generation, much of the evaluation remains in SMPL parameter space without showing how the motions transfer to physically simulated humanoids. GBC-100K is based on monocular SMPL estimations, which often have severe physics artifacts."}, "questions": {"value": "Please see Weaknssses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ksB1iUHQE0", "forum": "SjjXr9mnlk", "replyto": "SjjXr9mnlk", "signatures": ["ICLR.cc/2026/Conference/Submission1568/Reviewer_4Xj3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1568/Reviewer_4Xj3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760487198815, "cdate": 1760487198815, "tmdate": 1762915818617, "mdate": 1762915818617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "bh5Figzt8P", "forum": "SjjXr9mnlk", "replyto": "SjjXr9mnlk", "signatures": ["ICLR.cc/2026/Conference/Submission1568/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1568/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762919786861, "cdate": 1762919786861, "tmdate": 1762919786861, "mdate": 1762919786861, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Generative Behavior Control (GBC), a new task for generating long-term, goal-oriented, and physically plausible humanoid behaviors. The authors propose PHYLOMAN, a hierarchical framework combining LLM-based high-level planning and physics-informed motion control, supported by the new GBC-100K dataset. Experiments show improvements in behavior diversity, semantic alignment, and motion length compared to baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- GBC formalizes long-term behavior generation, addressing key gaps in motion generation research.\n- PHYLOMAN integrates hierarchical planning and physics-based control, bridging high-level semantics and low-level execution.\n- GBC-100K provides a valuable, hierarchically annotated benchmark for behavior generation."}, "weaknesses": {"value": "- Claims of goal-orientation and semantic coherence lack rigorous task-driven evaluation.\n- Comparisons are primarily with motion generation methods, not task-and-motion planning approaches.\n- Automated annotations may introduce noise; dataset limitations are not fully analyzed.\n- Lack of detailed ablations to isolate contributions of hierarchical planning and MP-MDM."}, "questions": {"value": "Please see Weaknesses for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "GYf6OtIiDG", "forum": "SjjXr9mnlk", "replyto": "SjjXr9mnlk", "signatures": ["ICLR.cc/2026/Conference/Submission1568/Reviewer_NKyX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1568/Reviewer_NKyX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820093148, "cdate": 1761820093148, "tmdate": 1762915818350, "mdate": 1762915818350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a hierarchical framework, PHYLOMAN, for Generative Behavior Control (GBC), combining language-driven planning, diffusion-based motion generation, and physics-based control, and constructs a large-scale hierarchical text-to-motion dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.This paper introduces a hierarchical framework, PHYLOMAN, for Generative Behavior Control (GBC), combining language-driven planning, diffusion-based motion generation, and physics-based control.\n2.The paper constructs a large-scale hierarchical text-to-motion dataset with three levels of structured annotations: BehaviorScript, PoseScript, and MotionScript."}, "weaknesses": {"value": "1.While the proposed PHYLOMAN framework is structurally coherent, its components—an LLM-based planner, a motion diffusion model, and a physics controller—are largely based on existing paradigms.\n2.Although the paper cites MotionAgent (Wu et al., 2024) as a representative language-to-motion framework, there is no direct experimental comparison and analysis.\n3.In the main experimental section, PHYLOMAN is not included in the key comparison Table 2, which presents quantitative results across baselines. The authors should include PHYLOMAN in Table 2 using the same configuration and evaluation metrics as other methods. \n4.The GBC-100K dataset, described as containing 123.7K motion sequences and 250 hours of video, introduces hierarchical annotations: BehaviorScript, PoseScript, and MotionScript. While this is valuable, several issues arise:\nThe reported W-MPJPE ≈ 222 mm (Table 7) remains quite large for a high-quality motion dataset. The evaluation only includes PA-MPJPE, W-MPJPE, and RTE,and while the authors acknowledge the presence of typical error types in their data, it is necessary to address additional aspects of physical consistency, such as foot sliding, body penetration, failure ratio, and temporal jitter.\nThere is no analysis of long-horizon temporal consistency, which is crucial for “ultra-long” behaviors.\n5. The paper repeatedly refers to the motion diffusion backbone as “parallel-in-time”, implying computational efficiency. However, there is no quantitative evidence (e.g., speedup, training cost, or memory footprint) to support this claim."}, "questions": {"value": "Please refer the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jokJsHq69W", "forum": "SjjXr9mnlk", "replyto": "SjjXr9mnlk", "signatures": ["ICLR.cc/2026/Conference/Submission1568/Reviewer_1oWQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1568/Reviewer_1oWQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991515779, "cdate": 1761991515779, "tmdate": 1762915817947, "mdate": 1762915817947, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a hierarchical planning and diffusion-based framework (PHYLOMAN), and builds a new dataset GBC-100K for long-term behavior generation. The motivation—bridging semantic intention and physical motion—is relevant and aligned with the community’s long-term goals."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper highlights a meaningful research gap, moving from short-term motion generation to long-horizon, goal-directed behavior control, which is conceptually valuable for embodied AI.\n\n-The paper proposes a full pipeline combining language planning, motion generation, and physics-based execution.\n\n-The proposed dataset GBC-100K is relatively large compared to many prior datasets and includes hierarchical semantic annotations, which could support richer planning and evaluation of long-duration behaviors."}, "weaknesses": {"value": "- The proposed framework mainly combines existing components: LLM-based behavior planning, Diffusion motion models,  and Physics-based controllers. The integration appears incremental without introducing new theoretical insights or algorithmic advances. Claiming a “first unified solution” is overstated, given recent works combining language, motion priors, and controllers.\n\n-The dataset is largely auto-annotated using pose estimation with LLM captioning, raising concerns about noise and annotation quality. \n\n-The structure of PoseScript with MotionScript is a data-level decomposition; the LLM planner is not grounded in physically valid constraints during generation, contradicting the claimed TAMP formulation.\n\n-The extremely long-horizon results rely heavily on truncation and indirect evaluation metrics. Physical plausibility and task completion demonstrations are limited and lack real-world testing or robotics integration."}, "questions": {"value": "-Since the majority of annotations come from automated VLM captioning and pose estimation, how to evaluate the annotation quality? And how sensitive is the model performance to annotation errors?\n\n-The LLM planner is said to enforce physical feasibility (CT). How is this concretely implemented? Is there any explicit consideration in the model to ensure transitions are executable before feeding to the diffusion model?\n\n-How is “success” defined for behaviors with abstract semantics, e.g., dancing happily?\n\n-Are baselines given text annotations consistent with their original training domains?\n\n-Does the system degrade gracefully with longer horizons, e.g., multi-minute outputs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HnCihj3wdl", "forum": "SjjXr9mnlk", "replyto": "SjjXr9mnlk", "signatures": ["ICLR.cc/2026/Conference/Submission1568/Reviewer_iC6n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1568/Reviewer_iC6n"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762144838938, "cdate": 1762144838938, "tmdate": 1762915817786, "mdate": 1762915817786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}