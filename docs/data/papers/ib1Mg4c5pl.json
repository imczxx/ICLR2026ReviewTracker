{"id": "ib1Mg4c5pl", "number": 20988, "cdate": 1758312435908, "mdate": 1759896948249, "content": {"title": "Binary Diff Summarization using Large Language Models", "abstract": "Security of software supply chains is necessary to ensure that software updates do not contain maliciously injected code or introduce vulnerabilities that may compromise the integrity of critical infrastructure.\nVerifying the integrity of software updates involves binary differential analysis (binary diffing) to highlight the changes between two binary versions by incorporating binary analysis and reverse engineering. \nLarge language models (LLMs) have been applied to binary analysis to augment traditional tools by producing natural language summaries that cybersecurity experts can grasp for further analysis. \nCombining LLM-based binary code summarization with binary diffing can improve the LLM's focus on critical changes and enable complex tasks such as automated malware detection.\nTo address this, we propose a novel framework for binary diff summarization using LLMs. We introduce a novel *functional sensitivity score* (FSS) that helps with automated triage of sensitive binary functions for downstream detection tasks. We create a *software supply chain security* benchmark by injecting 3 different malware into 6 open-source projects which generates 104 binary versions, 392 binary diffs, and 46,023 functions. On this, our framework achieves a precision of 0.98 and recall of 0.64 for malware detection, displaying high accuracy with low false positives. Across malicious and benign functions, we achieve FSS separation of 3.0 points, confirming that FSS categorization can classify sensitive functions. We conduct a case study on the real-world XZ utils supply chain attack; our framework correctly detects the injected backdoor functions with high FSS.", "tldr": "A novel framework for binary diff summarization using LLMs and a novel functional sensitivity score help automate malware detection for software supply chain security.", "keywords": ["binary analysis", "supply chain security", "binary diffing", "large language models"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0e15e614d66ee778d9ac1c0869ad51205ad04c73.pdf", "supplementary_material": "/attachment/6d3798ede809647ddef31f2c00f5376c0ca3cfac.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of detecting malicious or vulnerable changes in software supply chain updates by proposing a binary diff summarization framework using LLMs. The framework combines traditional binary diffing with natural language summarization and introduces the Functional Sensitivity Score (FSS), a metric inspired by CVSS, to triage binary functions according to sensitivity. The paper creates a benchmark of six open-source projects injected with three types of malware, totaling 104 versions, 392 binary diffs, and over 46K functions. Experiment results show high precision and reasonable recall in malware detection, with clear separation between benign and malicious functions."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduces an integration of binary diffing, LLM summarization, and FSS scoring, enabling triage of sensitive code changes.\n2. Builds a realistic dataset by injecting ransomware, RAT, and botnet malware into six widely used open-source projects."}, "weaknesses": {"value": "1. The paper offers limited technical novelty.\n2. The experiments are not comprehensive."}, "questions": {"value": "This paper introduces an interesting pipeline, but in its current form it is not strong enough for acceptance.\n\n1. The overall approach (diff → LLM summary → score) is primarily a pragmatic composition rather than a new technical contribution. Since FSS is directly adapted from CVSS with hand-tuned weights and the final malicious/benign decision is delegated to another LLM, the novelty is insufficient. \n\n2. There are many relevant baselines (e.g., those in Appendix A.1 such as DeepBinDiff). How does the proposed method compare against these in terms of accuracy and efficiency? In addition, how do different prompting strategies (e.g., zero-shot vs. chain-of-thought vs. few-shot) or reasoning-optimized/domain-specific models affect performance?\n\n3. There are several existing datasets, such as those from DeepBinDiff or BinSimDB[1], etc. They could provide stronger external validation. Why were these not used, and how does the proposed dataset in this paper differ from or improve upon them? And how's the performance of the proposed framework on those datasets?\n\n4. The framework does not clearly define a threshold for distinguishing malicious from benign using the FSS. For a deployable tool, a principled thresholding or calibration strategy seems necessary. \n\n5. The results show significant variance in recall across models and programs. Could the paper provide a detailed breakdown of failure cases to illustrate where and why the framework fails?\n\nReference:\n\n[1] Zuo, Fei, Cody Tompkins, Qiang Zeng, Lannan Luo, Yung Ryn Choe, and Junghwan Rhee. \"BinSimDB: Benchmark Dataset Construction for Fine-Grained Binary Code Similarity Analysis.\" In International Conference on Security and Privacy in Communication Systems, pp. 203-225. Cham: Springer Nature Switzerland, 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "c6L8nGPcPa", "forum": "ib1Mg4c5pl", "replyto": "ib1Mg4c5pl", "signatures": ["ICLR.cc/2026/Conference/Submission20988/Reviewer_kc2V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20988/Reviewer_kc2V"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20988/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761686760443, "cdate": 1761686760443, "tmdate": 1762939805516, "mdate": 1762939805516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The author(s) propose a novel framework that combines LLM-based binary code summarization with binary diffing to enhance the model's ability to focus on critical code changes and support complex tasks such as automated malware detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "They create a software supply chain security benchmark by injecting 3 different malware into 6 open-source projects which generate 104 binary versions, 392 binary diffs, and 46,023 functions."}, "weaknesses": {"value": "1. The methodological justification requires more clarity. It would be beneficial if the authors could explain why the proposed combination of LLM summarization and binary diffing offers advantages over existing binary analysis or summarization approaches.\n2. The experimental section needs more comparisons with related baselines.\n3. The paper would benefit from a more detailed discussion of the hyperparameter settings and ablation study used during the framework and evaluation."}, "questions": {"value": "see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "I4CbE2KGBm", "forum": "ib1Mg4c5pl", "replyto": "ib1Mg4c5pl", "signatures": ["ICLR.cc/2026/Conference/Submission20988/Reviewer_qTpZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20988/Reviewer_qTpZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20988/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716117239, "cdate": 1761716117239, "tmdate": 1762939729171, "mdate": 1762939729171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for binary diff summarization using LLMs. Given two binary versions, the system uses Ghidriff to extract only the added, deleted, and modified functions, constructs a diff callgraph, and then processes functions in reverse BFS order so that each function's LLM prompt can include summaries of its callees. On top of the summaries, the paper introduces a Functional Sensitivity Score, inspired by CVSS, with five categories\n$B,R,C,I,A \\in \\{\\text{none},\\text{low},\\text{medium},\\text{high}\\},$\naggregated as\n$S = 1 - (1 - B)(1 - R), \\quad M = 1 - (1 - C)(1 - I)(1 - A),$\n$\\text{FSS} =\n\\begin{cases}\n\\text{roundup}(5.3S + 6.1M), & M > 0,\\\\\n0, & \\text{otherwise.}\n\\end{cases}$\nThen the top-$k$ highest-FSS functions are fed to the LLM again to classify the whole diff as MALICIOUS or BENIGN. The authors also build a supply-chain benchmark (6 OSS projects, 104 versions, 392 diffs, 46023 functions, 3 malware families). With GPT-5 mini and $k=5$ + changelog, they report precision 0.98 and recall 0.64."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Originality: Instead of plain binary summarization, the method couples diffing, callgraph-aware prompting, and LLM-based triage (FSS), which is a novel combination for supply-chain inspection.\n\nQuality: FSS is fully specified with explicit weights and formulas, and the two-prompt LLM pattern (summary $\\to$ FSS) is clearly shown (Fig. 2).\n\nClarity: The pipeline (Fig.~1) is easy to follow and reverse-BFS ordering is well motivated.\n\nSignificance: The dataset is sizable and realistic for OSS supply-chain updates and the XZ case study connects the framework to a real incident."}, "weaknesses": {"value": "Mid recall. The best setting gets precision 0.98 but recall only 0.64, meaning ~36% of malicious updates are missed. This is high precision, not high accuracy. A threshold/$k$ sweep is needed.\n\nLLM brittleness. Some models do not output the requested labels, and the paper fixes this by using GPT-5 mini as the final predictor for all models (Table 3). This shows the method depends on a particular LLM.\n\nFSS validation is indirect. FSS is evaluated against the very malware the authors injected (malicious vs. benign functions), not against human-labeled sensitivity or a trivial rule baseline.\n\nBenchmark scope. All malwares are source-level, compiled with the same toolchain, and there is no obfuscation/packing, so the claim should be narrowed to \"LLM-assisted analysis of cleanly injected updates.''\n\nNo FSS ablation. There is no experiment showing that FSS is actually better than, e.g., selecting functions by the presence of network/crypto/file ops."}, "questions": {"value": "1- Can you report precision/recall for more $k$ values and/or FSS thresholds so we can see whether recall can be raised above $0.8$ at acceptable precision?\n\n2- On what data were the FSS weights/tuning done, and were the same weights used on the XZ case? Please clarify to rule out test-set tuning.\n\n3- In the XZ case, GPT-5 mini misclassifies its own summaries but GPT-5 succeeds. Does this mean the final predictor must be a high-capability LLM?\n\n4- What happens when Ghidriff mismatches or fails to match a modified function? Is the downstream LLM step robust to an incomplete diff callgraph?\n\n5- Will you release sanitized ghidriff outputs + prompts + LLM responses so others can test the FSS part without distributing malware binaries?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X651dgq4iT", "forum": "ib1Mg4c5pl", "replyto": "ib1Mg4c5pl", "signatures": ["ICLR.cc/2026/Conference/Submission20988/Reviewer_KHs7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20988/Reviewer_KHs7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20988/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803314499, "cdate": 1761803314499, "tmdate": 1762939656486, "mdate": 1762939656486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an LLM-based binary diff summarization that can be used to detect maliciously injected code or vulnerabilities from software updates. This approach utilizes LLM to analyze binary code and diff. The paper introduces a software supply chain security benchmark with 3 malware injections into 6 open-source projects. The proposed LLM-based binary diff summarization technique is used to create summaries that a downstream detector (utilizing functional sensitivity scores) uses to detect the injected malware. The proposed techniques achieve a 98% precision and 64% recall on the introduced dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ Detecting malware is an important topic. Having a reliable automatic technique that can flag potential malicious changes would make an IT admin’s job much easier.\n+ The precision is quite good without many false negatives."}, "weaknesses": {"value": "- The paper did not discuss any potential baseline, nor did it compare to any baseline. It would be possible to use prior work in binary analysis to create a baseline.\n- The recall is quite low at just under 60%. Having some quality analysis on modes of failure for those false negatives would give future researchers some insights into how to improve malicious diffs.\n- The lack of an ablation study makes it hard to know how each component contributes to the overall effectiveness of the technique."}, "questions": {"value": "1. What is the reason for not having a baseline? Can any of the prior binary analysis tools be used as a baseline?\n2. Since FSS behaves similarly to CVSS3.1, can CVSS3.1 be used instead and still produce similar results?\n3. Since using GPT5mini as a predictor while using a smaller model for summary produces very close results to the full GPT5mini stack. What are the differences in cost? Would a cost vs effectiveness analysis be done to show the cost vs gain?\n4. What are the typical modes of failure for false negatives?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FHM1REH1Ov", "forum": "ib1Mg4c5pl", "replyto": "ib1Mg4c5pl", "signatures": ["ICLR.cc/2026/Conference/Submission20988/Reviewer_2Hkg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20988/Reviewer_2Hkg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20988/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059811132, "cdate": 1762059811132, "tmdate": 1762939644855, "mdate": 1762939644855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}