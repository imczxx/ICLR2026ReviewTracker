{"id": "YPPD3Gf8mc", "number": 2156, "cdate": 1757001744447, "mdate": 1759898166066, "content": {"title": "3D Shape Generation via Tri-Vectors: a Parsimonious Representation", "abstract": "The pursuit of optimal 3D representations remains both a long-standing challenge and an exciting frontier within the vision and graphics communities. We argue that compressing 3D data into low-dimensional components improves parameter efficiency and captures essential features, providing a parsimonious representation that enhances shape generation. To this end, we propose Tri-Vectors, a parsimonious 3D representation tailored for shape generation. Tri-Vectors instantiates the classical CANDECOMP/PARAFAC (CP) decomposition of a shape’s continuous signed distance field (SDF) into orthogonal tri-vector sets, yielding a compact, resolution-independent, and highly adaptable structure. Specifically, Tri-Vectors has three major advantages: (i) direct shape reconstruction through linear combinations of components, (ii) adjustable dimension and number of components to suit varying shape complexities, and (iii) robustness across arbitrary resolutions. Extensive experiments across multiple datasets show that Tri-Vectors outperforms state-of-the-art methods in terms of parameter efficiency and geometric fidelity. Moreover, we extend its application to textured and deformable shapes, demonstrating the scalability and versatility of the representation.", "tldr": "", "keywords": ["3D shape representation", "generative model", "flow matching"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f1ce577e730424b78ddbe5c0af9256c3e71ee49d.pdf", "supplementary_material": "/attachment/00e30a0ca0facb3963d83171076256a53a1049a3.zip"}, "replies": [{"content": {"summary": {"value": "Following the classical CANDECOMP/PARAFAC (CP) decomposition, this work explores tri-vectors of a shape’s signed distance field (SDF) as an alternative continuous shape representation, demonstrating their efficiency in both shape reconstruction and generation. \nHowever, establishing such representations for all shapes in a large dataset, such as ShapeNet, would require substantial time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The tri-vectors represent surfaces in a continuous manner while achieving higher parameter efficiency compared to SDFs. \n2. Unlike latent generative models that rely on a separate decoder to map latent representations to signed distance fields, tri-vectors directly compute SDF values of query points. This eliminates the dependency on decoders after generation. \n3. The representation based on tri-vectors is extendable to textured shape reconstruction and deformable shape reconstruction."}, "weaknesses": {"value": "1. Tri-vectors have been previously explored in TensoRF (Chen et al., 2022) and Strivec (Gao et al., 2023).\n2. Since the tri-vector representation is more parameter-efficient than SDF-based approaches, the paper would benefit from comparisons with HyperDiffusion (Erkoc et al., ICCV 2023), which represents shapes using neural SDF parameters.\n3. The current experiments focus only on single category shape generation. Demonstrating unconditional generation across multiple shape categories would make the method more compelling, as shown in S2VS (Zhang et al., 2023)."}, "questions": {"value": "1. would be better if the authors could report the performance of per-shape SDF representations and S2VS (Zhang et al., 2023) in Table 2.\n2. how many shapes are used from the Thingi10K and ShapeNet datasets in Table 2 evaluations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zlgPwXjU4k", "forum": "YPPD3Gf8mc", "replyto": "YPPD3Gf8mc", "signatures": ["ICLR.cc/2026/Conference/Submission2156/Reviewer_MHCt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2156/Reviewer_MHCt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761554915956, "cdate": 1761554915956, "tmdate": 1762916057867, "mdate": 1762916057867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper formalizes a CP decomposition as Tri-Vectors for representing and generating continuous SDFs. The method emphasizes parameter efficiency, resolution scalability, and potential extension to textured and deformable settings. Experiments demonstrate competitive reconstruction and generation results with extremely few parameters, and the visual examples are appealing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presents a clear and intuitive application of classical CP tensor decomposition for continuous SDF representation and compression.\n\n2. The method is resolution-independent and scalable. By adjusting vector resolution and the number of components, the model smoothly transitions from coarse to fine representations\n\n3. The experiments cover diverse scenarios, including reconstruction and generative tasks, and extend to textured and deformable objects.\n\n4. Tri-Vectors achieve comparable or even superior results to baselines with significantly fewer parameters, supporting the claim of a parsimonious representation."}, "weaknesses": {"value": "Baseline comparisons are not rigorously controlled. Some listed methods differ in design purpose (scene-specific vs. generative), yet the comparisons are not made under equivalent parameter, training, or resolution settings. Several important baselines (e.g., modern VAE-latent models with strong decoders) are missing, making it unclear whether improvements arise from the representation itself or other implementation differences.\n\n1. Limited reproducibility and missing experimental details. Essential hyperparameters—such as learning rate schedules, optimization steps, implementation specifics of SiT, random seeds for masking, and the rationale for the extremely small regularization weights ($\\lambda$L2, $\\lambda$var)—are omitted. The use of six million sampling points is computationally expensive, but the paper does not analyze its sensitivity or discuss possible lower-cost alternatives.\n\n2. Insufficient evaluation of generative quality and diversity. The generation results mainly rely on COV/MMD/1-NN metrics without assessing sample diversity, mode collapse, or generation stability. Qualitative comparisons are subjective and lack detailed error analysis (e.g., distortion types or failure statistics).\n\n3. Lack of limitation analysis and failure cases. The paper does not examine the performance degradation on complex topologies, fine-grained geometries, or noisy inputs. The robustness under violation of the “approximately separable structure” assumption remains unclear, and the random masking experiments are not deeply analyzed."}, "questions": {"value": "1. The proposed method relies on multi-view alignment and generative priors, but it is unclear how robust the approach is when the input views exhibit significant occlusion or illumination inconsistency. Could the authors clarify the method’s behavior under such challenging conditions?\n\n2. The paper emphasizes reconstruction fidelity, but there is limited discussion on the computational cost. What is the inference time and memory consumption for a typical sample compared to baseline methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "qLrolAd4iQ", "forum": "YPPD3Gf8mc", "replyto": "YPPD3Gf8mc", "signatures": ["ICLR.cc/2026/Conference/Submission2156/Reviewer_nFFR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2156/Reviewer_nFFR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761574384423, "cdate": 1761574384423, "tmdate": 1762916057688, "mdate": 1762916057688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Tri-Vectors, a 3D shape representation based on CP decomposition, for improving the efficiency of 3D generative models. The authors show their model as a solution to the trade-offs faced by existing methods, such as neural implicit functions and tensor representations."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "While the topic is interesting, and the authors tried to integrate classic mathematics into generative settings (which is an interesting attempt), but the paper suffers from weak presentation and argumentation."}, "weaknesses": {"value": "The paper in its current form is dense and difficult to follow. The problem definition is unclear, and the motivation for using CP decomposition is weak. The paper lists common trade-offs of existing methods (like, heavy compute or scene-specific), but didnt provide details for why these are the most bottlenecks. \n\nThere is no description of CP decomposition in the introduction, and the motivation for using it as the solution for a generative model is not well-defined. In my opinion, simply saying that a technique \"has not been explored\" in a generative setting, is not a sufficient technical motivation. There is no argument for why CP decomposition is suited to overcoming the limitations of other generative representations. Indeed, throughout the paper (specially in the introduction), the \"why\" is missing. \n\nThe related work section is weak. It doesn't define the key contributions and limitations of prior works. For example, in section 2.2, the authors list some transformer and diffusion models. Then, the last sentence is about their Tri-Vectors. There is no connection between them. It doesn't explain why is Tri-Vectors better than a transformer-based model? or how it solve the high dimensionality problem of diffusion models in a new way?\n\nBeyond the lack of clarity, i have a question about figure 2.  In part (a), what is optimization block? If this block shows the Tri-Vectors, so this is the most important part of the representation idea and must be clearly defined, or maybe with a formulation. \n\nIn part (b), the Tri-Vectors are fed into an encoding block before going into the SIT network. This is confusing, because the Tri-Vectors are already the shape encoding, so why are using encoding an encoding? maybe this needs some justification. \n\nAnother confusing point is l_2 loss. The figure shows the loss is calculated between the model output and a target as, x_0 - x_t.  Am I right? maybe the authors need to justify it and explain what advantage it provides over diffusion model losses? It is not clear what each block or step contributes to the model."}, "questions": {"value": "My questions are placed in the weaknesses block."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HAJXzbFlll", "forum": "YPPD3Gf8mc", "replyto": "YPPD3Gf8mc", "signatures": ["ICLR.cc/2026/Conference/Submission2156/Reviewer_hDan"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2156/Reviewer_hDan"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761775111031, "cdate": 1761775111031, "tmdate": 1762916057242, "mdate": 1762916057242, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper represent 3D shapes with 3 orthogonal vectors. And run diffusion model to generate such 3D representation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-"}, "weaknesses": {"value": "This paper is outdated. Similar to tri-planes, Tri-Vectors appear to be more compact and data-efficient. However, generating such data representations has proven difficult, as they collapse data along certain dimensions, leading to irreversible data ambiguities.\nThe research community has shifted from using tri-planes to Vecset and Trellis. This paper misses comparisons with these methods and only compares with methods from before 2024. It is recommended to make a major revision before resubmitting, including:\n1) Comparison with more recent approaches like Vecset and Trellis.\n2) Scaling up the method to verify its robustness across complex shape, and general categories."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xjTUEIPHBs", "forum": "YPPD3Gf8mc", "replyto": "YPPD3Gf8mc", "signatures": ["ICLR.cc/2026/Conference/Submission2156/Reviewer_g5fd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2156/Reviewer_g5fd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762175013218, "cdate": 1762175013218, "tmdate": 1762916055754, "mdate": 1762916055754, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}