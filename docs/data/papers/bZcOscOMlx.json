{"id": "bZcOscOMlx", "number": 7151, "cdate": 1758009754946, "mdate": 1759897869992, "content": {"title": "Ca$^2$P: Cache-Augmented Code-as-Policies for Open-Domain Embodied Tasks", "abstract": "Embodied agents deployed in open-domain environments must continuously handle unpredictable tasks beyond predefined action policies. Such tasks are often given as natural language instructions, and recent progress in code-writing large language models (CodeLLMs) has inspired the Code-as-Policies (CaP) paradigm, where instructions are translated into executable control code when issued. However, generating full code from scratch for each instruction incurs high latency and inconsistency, limiting CaP's practicality in real-world, time-sensitive scenarios. To address these limitations, we present Ca$^2$P, a Cache-Augmented Code-as-Policies framework that improves CodeLLM-based robotic programming by introducing function-level key-value (KV) caching, a repurposed and extended form of the native KV caching mechanism tailored for function reuse, together with cache-augmented code policy synthesis. Ca$^2$P decomposes previously generated and validated code policies and stores them as function-level KV caches, supporting efficient compositional programming, where new policies are synthesized by invoking cached functions directly through their KV states. Furthermore, by revisiting and editing cached functions within their KV states, Ca$^2$P provides cache-refactoring, thereby enabling efficient synthesis of task-specific code policies without the need for full regeneration. Evaluated on ALFRED, TEACh, and RLBench benchmarks together with real-world robot manipulation, Ca$^2$P achieves the best trade-off between robustness and latency, with $19.80\\%$ higher task success rate and $2.91\\times$ faster policy synthesis than the CaP baseline.", "tldr": "Ca$^2$P: Cache-Augmented Code-as-Policies for Open-Domain Embodied Tasks", "keywords": ["LLM", "KV Cache", "Embodied AI"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a60e7cd434166d97d2fca246462ba3b3d87a1d4c.pdf", "supplementary_material": "/attachment/d49c22fad20a6b95babc6b63532dafa1bffafef3.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a caching mechanism for the code as policies base. At a high-level, a coding LLM is used to write composable functions for executing manipulation tasks given a set of perception and control APIs (the idea previously in code as policies). In this work, the authors propose to augment it with an explicit cache across domains, which store separately the function description and the function implementation. At deployment time, functions are accumulated from successful runs and reused later in other tasks by referencing the stored function description."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is written with clarity in general and easy to follow.\n- The empirical results are extensive across several evaluation domains."}, "weaknesses": {"value": "- The contribution of this work appears to solely focus on the cache management for code generation (though for applications in embodied tasks), which has been very well understood and explored in both research and commercial systems such as coding agents. As a result, it is questionable whether the contribution is meaningful enough for ICLR community. Importantly, the major benefit in the context of embodied tasks appears to be mainly efficiency gain for LLM calls (which typically happens before any robot execution). Although it may be argued that this is important for certain tasks (such as that in figure 1), the scope remains limited and there are many ways to improve efficiency that has been widely deployed in existing tool boxes (such as token caching, model quantization).\n- The open-sourced implementation of code as policies already contains a caching mechanism, albeit within the per-episode execution. It would enhance the paper if it can made further clearer the differences in the proposed caching mechanism to the existing one. Notably, what advantages does it offer?"}, "questions": {"value": "See weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YvrcJafMEl", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_cxo5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_cxo5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950317577, "cdate": 1761950317577, "tmdate": 1762919316976, "mdate": 1762919316976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a practical issue with Code-as-Policies (CaP) for robot control—every new instruction forces the model to rewrite all the code, making it slow and sometimes inconsistent. The proposed approach, CA2P, reuses previously verified functions by caching key–value (KV) states and updating code in place instead of regenerating everything from scratch. It builds a function-level caching system that supports both code reuse and quick local edits. Tests on ALFRED, TEACh, and RLBench show higher success rates and up to 2.9× faster responses than standard CaP methods. Real-robot trials confirm the improvements in both speed and stability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear and well-structured technical design (two-tier cache: Function-Interface and Function-Code) with coherent equations and pseudocode.\n\n- Writing is clear and figures are informative\n\n- Extensive experimental setup across multiple environments, baselines, and metrics."}, "weaknesses": {"value": "- In Algorithm 1, the try–except block appears tailored for simulation, where errors can be easily caught. It remains unclear how such failures would be handled in real-world deployments."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Ebu6bOkFrk", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_r7c6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_r7c6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950540077, "cdate": 1761950540077, "tmdate": 1762919316024, "mdate": 1762919316024, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the high latency and inconsistency of the Code-as-Policies (CaP) paradigm, where large language models (LLMs) generate full control code from scratch for every embodied task. This paper presents $CA^{2}P$, a Cache-Augmented Code-as-Policies framework for embodied AI agents in open-domain environments. The core innovation is function-level key-value (KV) caching that repurposes native transformer attention caching to enable code reuse. The system maintains a two-tier cache (Function-Interface and Function-Code) indexed by function identifiers, supporting compositional programming (assembling new policies from cached functions) and cache-refactoring (editing cached functions via fill-in-the-middle). A cache management scheme based on recency, frequency, co-occurrence, and semantic diversity scores determines retention. Experiments on ALFRED, TEACh, and RLBench 8benchmarks, as well as real-world robot manipulation, show that $CA^{2}P$ achieves a superior trade-off between task success rate (SR) and policy synthesis latency (PSL), outperforming CaP baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The two-tier cache design (Function-Interface I and Function-Code C) is well-motivated for separating lightweight references from full implementations, enabling efficient compositional programming without redundant attention computation\n\n- Evaluation spans three simulation benchmarks (ALFRED, TEACh, RLBench) with different task characteristics plus real-world manipulation. Thorough baseline comparisons and ablation studies are conducted"}, "weaknesses": {"value": "- The locality score $l(f_k)$ in Equation (3) is central to the method, but its components are defined only at a high level. $l_{freq}$ (\"usage frequency\") and $l_{asso}$ (\"conditional association\") are not given precise mathematical definitions, making it difficult to reimplement the scoring function exactly. The weights $\\alpha, \\beta, \\gamma$ in Equation (3) are set to 0.4, 0.3, and 0.3, but this choice is presented without justification. No ablation or sensitivity analysis is provided.\n\n- The \"code cache warm-up\" analysis (Fig 4) explicitly states it starts from an \"empty cache\". However, Appendix D.1 states: \"All cache-based baselines and $CA^{2}P$ begin with the same initial KV cache states derived from basic success code policies\" for the main benchmark results. This implies the main results in Table 1 use a pre-populated cache, not one warmed-up from empty. This is a crucial distinction that is not clarified in the main paper.\n\n- The \"open-domain\" framing is somewhat overstated—all benchmarks provide predefined API sets (Tables 6-9) with fixed primitives; true open-domain deployment would require handling novel APIs or learning from demonstrations, which is not addressed."}, "questions": {"value": "- For the real-world experiments (Table 2), the paper states the cache is built by \"first solves simpler tasks in RLBench\". Is the performance therefore dependent on this pre-population step?\n\n- In Algorithm 1, when is generate() versus edit() called? How are exceptions E detected and categorized? What triggers cache updates beyond task success?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sjuGSMJuFn", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_qB9j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_qB9j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994382710, "cdate": 1761994382710, "tmdate": 1762919315111, "mdate": 1762919315111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Authors propose to utilize caching in order to improve the latency of code as policies framework for LLM based robotic control. Authors perform experiments with real world robot."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Good empirical performance.\n- Clear contribution as identified knowledge gap in code as policies framework. \n- Well engineered solution."}, "weaknesses": {"value": "- Related work does not have any citations. Please rewrite, the purpose of related work is to cite previous works. \n- In respect to these hyperparameters, such as  $\\alpha$,  $\\beta$, $\\gamma$ and others, I did not see experiments where those values were varied. This is strange considering the amount of results in presented in the paper. Maybe authors can explain this?"}, "questions": {"value": "- In line 203, why $\\alpha$,  $\\beta$, $\\gamma$ needs to sum to one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UzspxIEhiL", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_NSpR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_NSpR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998251322, "cdate": 1761998251322, "tmdate": 1762919314488, "mdate": 1762919314488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}