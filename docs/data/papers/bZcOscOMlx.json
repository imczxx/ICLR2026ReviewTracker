{"id": "bZcOscOMlx", "number": 7151, "cdate": 1758009754946, "mdate": 1763730077913, "content": {"title": "Ca$^2$P: Cache-Augmented Code-as-Policies for Open-Domain Embodied Tasks", "abstract": "Embodied agents deployed in open-domain environments must continuously handle unpredictable tasks beyond predefined action policies. Such tasks are often given as natural language instructions, and recent progress in code-writing large language models (CodeLLMs) has inspired the Code-as-Policies (CaP) paradigm, where instructions are translated into executable control code when issued. However, generating full code from scratch for each instruction incurs high latency and inconsistency, limiting CaP's practicality in real-world, time-sensitive scenarios. To address these limitations, we present Ca$^2$P, a Cache-Augmented Code-as-Policies framework that improves CodeLLM-based robotic programming by introducing function-level key-value (KV) caching, a repurposed and extended form of the native KV caching mechanism tailored for function reuse, together with cache-augmented code policy synthesis. Ca$^2$P decomposes previously generated and validated code policies and stores them as function-level KV caches, supporting efficient compositional programming, where new policies are synthesized by invoking cached functions directly through their KV states. Furthermore, by revisiting and editing cached functions within their KV states, Ca$^2$P provides cache-refactoring, thereby enabling efficient synthesis of task-specific code policies without the need for full regeneration. Evaluated on ALFRED, TEACh, and RLBench benchmarks together with real-world robot manipulation, Ca$^2$P achieves the best trade-off between robustness and latency, with $19.80\\%$ higher task success rate and $2.91\\times$ faster policy synthesis than the CaP baseline.", "tldr": "Ca$^2$P: Cache-Augmented Code-as-Policies for Open-Domain Embodied Tasks", "keywords": ["LLM", "KV Cache", "Embodied AI"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c94ccf2619255df79df95b2ee3e5141520a0d5ce.pdf", "supplementary_material": "/attachment/d49c22fad20a6b95babc6b63532dafa1bffafef3.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a caching mechanism for the code as policies base. At a high-level, a coding LLM is used to write composable functions for executing manipulation tasks given a set of perception and control APIs (the idea previously in code as policies). In this work, the authors propose to augment it with an explicit cache across domains, which store separately the function description and the function implementation. At deployment time, functions are accumulated from successful runs and reused later in other tasks by referencing the stored function description."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is written with clarity in general and easy to follow.\n- The empirical results are extensive across several evaluation domains."}, "weaknesses": {"value": "- The contribution of this work appears to solely focus on the cache management for code generation (though for applications in embodied tasks), which has been very well understood and explored in both research and commercial systems such as coding agents. As a result, it is questionable whether the contribution is meaningful enough for ICLR community. Importantly, the major benefit in the context of embodied tasks appears to be mainly efficiency gain for LLM calls (which typically happens before any robot execution). Although it may be argued that this is important for certain tasks (such as that in figure 1), the scope remains limited and there are many ways to improve efficiency that has been widely deployed in existing tool boxes (such as token caching, model quantization).\n- The open-sourced implementation of code as policies already contains a caching mechanism, albeit within the per-episode execution. It would enhance the paper if it can made further clearer the differences in the proposed caching mechanism to the existing one. Notably, what advantages does it offer?"}, "questions": {"value": "See weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YvrcJafMEl", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_cxo5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_cxo5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950317577, "cdate": 1761950317577, "tmdate": 1762919316976, "mdate": 1762919316976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a practical issue with Code-as-Policies (CaP) for robot control—every new instruction forces the model to rewrite all the code, making it slow and sometimes inconsistent. The proposed approach, CA2P, reuses previously verified functions by caching key–value (KV) states and updating code in place instead of regenerating everything from scratch. It builds a function-level caching system that supports both code reuse and quick local edits. Tests on ALFRED, TEACh, and RLBench show higher success rates and up to 2.9× faster responses than standard CaP methods. Real-robot trials confirm the improvements in both speed and stability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear and well-structured technical design (two-tier cache: Function-Interface and Function-Code) with coherent equations and pseudocode.\n\n- Writing is clear and figures are informative\n\n- Extensive experimental setup across multiple environments, baselines, and metrics."}, "weaknesses": {"value": "- In Algorithm 1, the try–except block appears tailored for simulation, where errors can be easily caught. It remains unclear how such failures would be handled in real-world deployments."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Ebu6bOkFrk", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_r7c6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_r7c6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950540077, "cdate": 1761950540077, "tmdate": 1762919316024, "mdate": 1762919316024, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the high latency and inconsistency of the Code-as-Policies (CaP) paradigm, where large language models (LLMs) generate full control code from scratch for every embodied task. This paper presents $CA^{2}P$, a Cache-Augmented Code-as-Policies framework for embodied AI agents in open-domain environments. The core innovation is function-level key-value (KV) caching that repurposes native transformer attention caching to enable code reuse. The system maintains a two-tier cache (Function-Interface and Function-Code) indexed by function identifiers, supporting compositional programming (assembling new policies from cached functions) and cache-refactoring (editing cached functions via fill-in-the-middle). A cache management scheme based on recency, frequency, co-occurrence, and semantic diversity scores determines retention. Experiments on ALFRED, TEACh, and RLBench 8benchmarks, as well as real-world robot manipulation, show that $CA^{2}P$ achieves a superior trade-off between task success rate (SR) and policy synthesis latency (PSL), outperforming CaP baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The two-tier cache design (Function-Interface I and Function-Code C) is well-motivated for separating lightweight references from full implementations, enabling efficient compositional programming without redundant attention computation\n\n- Evaluation spans three simulation benchmarks (ALFRED, TEACh, RLBench) with different task characteristics plus real-world manipulation. Thorough baseline comparisons and ablation studies are conducted"}, "weaknesses": {"value": "- The locality score $l(f_k)$ in Equation (3) is central to the method, but its components are defined only at a high level. $l_{freq}$ (\"usage frequency\") and $l_{asso}$ (\"conditional association\") are not given precise mathematical definitions, making it difficult to reimplement the scoring function exactly. The weights $\\alpha, \\beta, \\gamma$ in Equation (3) are set to 0.4, 0.3, and 0.3, but this choice is presented without justification. No ablation or sensitivity analysis is provided.\n\n- The \"code cache warm-up\" analysis (Fig 4) explicitly states it starts from an \"empty cache\". However, Appendix D.1 states: \"All cache-based baselines and $CA^{2}P$ begin with the same initial KV cache states derived from basic success code policies\" for the main benchmark results. This implies the main results in Table 1 use a pre-populated cache, not one warmed-up from empty. This is a crucial distinction that is not clarified in the main paper.\n\n- The \"open-domain\" framing is somewhat overstated—all benchmarks provide predefined API sets (Tables 6-9) with fixed primitives; true open-domain deployment would require handling novel APIs or learning from demonstrations, which is not addressed."}, "questions": {"value": "- For the real-world experiments (Table 2), the paper states the cache is built by \"first solves simpler tasks in RLBench\". Is the performance therefore dependent on this pre-population step?\n\n- In Algorithm 1, when is generate() versus edit() called? How are exceptions E detected and categorized? What triggers cache updates beyond task success?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sjuGSMJuFn", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_qB9j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_qB9j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994382710, "cdate": 1761994382710, "tmdate": 1762919315111, "mdate": 1762919315111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Authors propose to utilize caching in order to improve the latency of code as policies framework for LLM based robotic control. Authors perform experiments with real world robot."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Good empirical performance.\n- Clear contribution as identified knowledge gap in code as policies framework. \n- Well engineered solution."}, "weaknesses": {"value": "- Related work does not have any citations. Please rewrite, the purpose of related work is to cite previous works. \n- In respect to these hyperparameters, such as  $\\alpha$,  $\\beta$, $\\gamma$ and others, I did not see experiments where those values were varied. This is strange considering the amount of results in presented in the paper. Maybe authors can explain this?"}, "questions": {"value": "- In line 203, why $\\alpha$,  $\\beta$, $\\gamma$ needs to sum to one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UzspxIEhiL", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Reviewer_NSpR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Reviewer_NSpR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998251322, "cdate": 1761998251322, "tmdate": 1762919314488, "mdate": 1762919314488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Comment: Summary of Revisions in Response to Reviewer Feedback"}, "comment": {"value": "# Dear Area Chair, Reviewers and ICLR community,\n\nWe sincerely thank you for your thoughtful and highly constructive feedback. Your careful assessments have been invaluable in strengthening the clarity, positioning, and technical rigor of our paper. Below, we summarize the major revisions made in response to the reviewers' comments.\n\n---\n## Summary of Revisions\n---\n### 1. Revisions addressing Reviewer NSpR\n\nReviewer NSpR noted the need for clearer positioning within the related work and more explicit justification of our locality design and hyperparameter choices.\n\nTo address this:\n- Explained in our replies is how each method is utilized or extended, and the missing citations are provided in Section 2.\n- Expanded the description of the locality components, clarifying how each score is computed and how normalization is applied. The full details are included in Appendix C.2.\n- Provided a detailed explanation of the hyperparameter selection process and the rationale for using a normalized weighted combination. The corresponding material is included in Appendix D.8.\n---\n\n### 2. Revisions addressing Reviewer qB9j\n\nReviewer qB9j requested clearer elaboration of the locality formulation and expressed concern about ambiguous terminology across experiments.\n\nTo address this:\n- Expanded the locality formulation by clarifying the role of each component and explaining the necessity of the normalized weighted combination for consistent retrieval and cache-eviction behavior across task settings; the full details are provided in Appendix C.2 and Appendix D.8.\n- Refined the descriptions of the code cache warm-up experiments and clarified that their behavior is independent of the main-phase evaluations. The corresponding updates have been added to Sections 4.1 and 4.3.\n- Clarified that the failure-handling mechanism in Algorithm 1 is not simulation-specific by explaining how real-world failures (e.g., grasp failures, pose mismatches, safety interruptions) map into the same structured exception interface used during simulation. This material has been added to Appendix C.2.\n\n---\n\n### 3. Revisions addressing Reviewer r7c6\n\nReviewer r7c6 questioned whether the try–except structure in Algorithm 1 was overly tailored to simulation and how failures would be detected and handled in real-world robot execution.\n\nTo address this:\n- Added a unified explanation showing how both simulation-driven and perception-driven failures map into the same structured exception interface.\n- Clarified how real-world failures are detected via perception signals (e.g., grasp verification, pose mismatch, safety interruptions), ensuring the same exception-handling path applies consistently across simulated and physical environments.\n- The unified design, along with the newly added detection-level table, is documented in Appendix C.2.\n\n---\n\n### 4. Revisions addressing Reviewer cxo5\n\nReviewer cxo5 requested an additional experiment evaluating efficiency trade-offs introduced by quantization.\n\nTo address this:\n- Conducted the requested quantization experiment and evaluated its influence on latency, memory usage, and end-to-end task performance.\n- Reported how quantization interacts with the cache retrieval mechanism to ensure that reduced numerical precision does not adversely affect policy synthesis.\n- The full results and analysis are included in Appendix D.10.\n\n---\n\nWe have carefully revised the manuscript to incorporate all reviewer suggestions while preserving the integrity and intent of the original contribution.  \nIf any part of our revisions remains unclear or would benefit from further elaboration, please let us know - we would be happy to clarify or revise further.\n\n**Sincerely,  \nThe Authors**"}}, "id": "ZUbP2MCbzW", "forum": "bZcOscOMlx", "replyto": "bZcOscOMlx", "signatures": ["ICLR.cc/2026/Conference/Submission7151/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7151/Authors"], "number": 21, "invitations": ["ICLR.cc/2026/Conference/Submission7151/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763725077090, "cdate": 1763725077090, "tmdate": 1763725077090, "mdate": 1763725077090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}