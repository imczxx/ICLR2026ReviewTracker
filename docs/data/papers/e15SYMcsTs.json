{"id": "e15SYMcsTs", "number": 19923, "cdate": 1758300649735, "mdate": 1759897011991, "content": {"title": "Learning Dynamics of Logits Debiasing for Long-Tailed Semi-Supervised Learning", "abstract": "Long-tailed distributions are prevalent in real-world semi-supervised learning (SSL), where pseudo-labels tend to favor majority classes, leading to degraded generalization. Although numerous long-tailed SSL (LTSSL) methods have been proposed, the underlying mechanisms of class bias remain underexplored. In this work, we investigate LTSSL through the lens of learning dynamics and introduce the notion of baseline images to characterize accumulated bias during training. We provide a step-wise decomposition showing that baseline predictions are determined solely by shallow bias terms, making them reliable indicators of class priors. Building on this insight, we propose a novel framework, DyTrim, which leverages baseline images to guide data pruning. Specifically, we perform class-aware pruning on labeled data to balance class distribution and label-agnostic soft pruning with confidence filtering on unlabeled data to mitigate error accumulation. Theoretically, we show that our method implicitly realizes risk reweighting, effectively suppressing class bias. Extensive experiments on public benchmarks show that DyTrim consistently enhances the performance of existing LTSSL methods by improving representation quality and prediction accuracy.", "tldr": "", "keywords": ["learning dynamics; semi-supervised learning; long-tailed; logits debiasing"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d57508565716cbaf17bd48fc369c05fbfb1be9f8.pdf", "supplementary_material": "/attachment/1d6680bb242e41f234cd8d2ddc189a678cbd48e1.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes the DyTrim method, which eliminates bias by employing benchmark image-guided dynamic data pruning. The authors demonstrate that this approach implicitly implements risk reweighting, elucidate the mechanism by which benchmark images mitigate classifier bias in class-imbalanced scenarios, and reveal how class-imbalanced datasets influence a model's predictions on baseline images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper demonstrates through a solid theoretical foundation that the DyTrim method can effectively suppress class bias. The DyTrim method provides an elegant solution to the class imbalance problem in semi-supervised learning without requiring complex network branches or de-biasing mechanisms. Extensive experiments on public benchmarks validate the effectiveness of the proposed method. This approach contributes to the advancement of the field."}, "weaknesses": {"value": "[1] Conventional pruning strategies are typically employed to eliminate samples that contribute minimally to training, thereby accelerating the training process. However, this paper utilizes such strategies to obtain a relatively balanced training subset. Would this approach suffer from the undersampling problem, specifically for tail classes?\n\n[2] Figure 1 fails to provide sufficient evidence for the conclusions put forward in the paper. Especially in the bottom part, the predicted distributions derived from pseudo-labels—whether correct or incorrect—show no significant difference; in some cases, they are even completely identical.\n\n[3] In Equation 18, what is the distinction between H_t^l  and the subsequent H_(c,t)^l? Additionally, how are the scoring functions H_t^l and H_t^u specifically obtained?\n\n[4] In Eq (20), for unlabeled data, high pseudo-label confidence links to a random pruning probability r , where a larger r results in a larger gradient scaling factor. Could this intensify the model’s bias toward high-confidence samples (usually head classes)? Furthermore, the gradient scaling follows Qin et al.’s setting. Ablation studies demonstrate that it contributes more to model performance than other components proposed in this work, and removing it causes a notable decline in performance.\n\n[5] According to Equations (19) and (20), the scores corresponding to pruned samples will no longer be modified. Does this mean that these samples will not be used in subsequent training processes? If so, it would result in severe information waste.\n\n[6] The experimental section lacks comparisons with the latest literature. Additionally, it would be beneficial if the authors could provide information on the pruning amount of training samples in each iteration.\n\n[7] It seems that the predicted class probabilities obtained from Figure 3(a) and (b) both appear to be unsatisfactory. Additionally, some errors appear to exist in the titles and their corresponding descriptions for Figure 3, Figure 4, and Figures 6 to 10.\n\n[8] There are still some expression errors and unclear descriptions in the manuscript. For instance, the definition of the imbalance of the unlabeled dataset and the description of Figure 2 require clarification."}, "questions": {"value": "As described in “Weaknesses”."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PixZJmmy7r", "forum": "e15SYMcsTs", "replyto": "e15SYMcsTs", "signatures": ["ICLR.cc/2026/Conference/Submission19923/Reviewer_jDsT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19923/Reviewer_jDsT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761486477410, "cdate": 1761486477410, "tmdate": 1762932092117, "mdate": 1762932092117, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In their manuscript, the authors address the problem of long-tailed semi-supervised learning. More specifically, the problem of estimating the accumulated biased is approached using techniques of learning dynamics and benchmark images. The proposed framework, DyTrim, uses these findings to guide data pruning. The approach is evaluated on three standard benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The manuscript makes use of very recent work such as Learning Dynamics (Ren&Sutherland, ICLR2025) and solid-color input for optimal bias estimation (Xing et al., AAAI2025)\n- The writing is generally good, although the text-flow is sometimes confusing\n- Figure 1 is a good illustration, although it needs better connection with the main storyline.\n- The method has been compared in a comprehensive set of experiments with good results."}, "weaknesses": {"value": "- Both soundness and contribution seem to be problematic, possibly cause by unclear presentation\n    - contribution: it remains unclear in which sense the current method goes beyond combining the works by Ren&Sutherland, ICLR2025 (btw: the reference should be updated from the pre-print) and Xing et al., AAAI2025 for guiding sub-sampling\n    - soundness: it remains unclear how the authors reflect about their use of definitions and propositions. The presentations of the theory leaves the reader with serious doubts that the construction based on definition 1, subsequent propositions, and theorem 1 is sound. The proofs in the appendix are not mentioned in the main text and seem to be not fully completed (e.g. missing references)\n    - writing: although generally good, it is sometimes unnecessary hard to interpret the writing, also caused by some language issues (e.g. line 040: \"the approach employ baseline image \") \n- Some relevant references are missing, e.g. mixing-based approaches (built on [1]) \n- The presentation of results is a bit confusing: which results are taken from the literature and which have been reproduced; why deviate reproduced values from the literature, etc.\n\n[1] Zhang et al. Mixup: Beyond empirical risk minimization. ICLR 2018."}, "questions": {"value": "1. how does the proposed method goes beyond combining Ren&Sutherland, ICLR2025 and Xing et al., AAAI2025 for guiding sub-sampling?\n1. what is defined in Definition 1? In its current from, it says \"decompose\" which implies a proposition\n1. in which ways go propositions 1 and 3 beyond definition 1 (which might be a proposition)?\n1. how can the use of a bias-free first layer (line 173) be justified?\n1. what is the intuitive, non-trivial connection between proposition 2 and theorem 1?\n1. which results in the experiments were reproduced and which were taken from the literature?\n1. in case of deviations: why do the results differ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xam4aPgPlv", "forum": "e15SYMcsTs", "replyto": "e15SYMcsTs", "signatures": ["ICLR.cc/2026/Conference/Submission19923/Reviewer_yN6a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19923/Reviewer_yN6a"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921999528, "cdate": 1761921999528, "tmdate": 1762932091590, "mdate": 1762932091590, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of semi-supervised learning with heavy class imbalance. It proposes to dynamically prune the dataset according to the model confidence as well as the approximate marginal class distribution based on the logits derived from a baseline black image. The proposed approach performs well on small-scale image benchmarks (32x32)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed approach seems to intuitively make sense in solving the problem (for the most part)\n- The proposed approach seems to do well on the various benchmarks explored.\n- The presentation of the paper is clear and professional. Figure 2 is very helpful in understanding the proposed approach."}, "weaknesses": {"value": "The paper load for ICLR this year has been large, and so I have not been able to spend as much time as I would like on reviewing. I encourage the authors to correct any errors/misunderstandings I may have with regards to the paper.  Moreover, I do not work in either semi-supervised or long-tailed learning, so my review confidence will be low, and I will defer to other more knowledgeable reviewers.\n\n1. **Motivation is hard to understand**\n    1. The learning dynamics theory doesn't feel particularly relevant or well-connected to the downstream approach. \n    1. Figure 1 is not very easy for the reader to interpret.\n1. **Baseline image design choice**\n    1. I am confused by the choice to use a black image as a baseline to extract marginal class probabilities. Why not just directly extract the bias vector from the final fully connected layer? This is usually accessible for most deep learning models in my experience. \n    2. Suppose we have a class-balanced dataset of images where a CNN learns to classify different solid colours (e.g. white, black, red). Wouldn't you expect the black baseline image to return a probability vector close to [0,1,0]?\n1. **Experiments only on small-scale data**\n    1. Although experimental results seem good, they are only on small-scale data (up to 64x64). I would be much more confident in the approach if the authors demonstrated strong performance on imagenet-scale (224x224) scale data such as https://github.com/zhmiao/OpenLongTailRecognition-OLTR. \n\n1. **Complexity of approach**\n    1. It seems like the proposed approach is quite complicated with many knobs for the practitioner to adjust. I am a little sceptical whether such an approach could be conveniently adopted."}, "questions": {"value": "I am unsure why pruning of data is performed rather than simply reweighting the sampling frequency. Can the authors clarify this point?\n\nI am open to raising my score if my above issues are addressed; however, I will still keep low confidence even if I do so, as I am not familiar with this field of research."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "yICJbpsuuG", "forum": "e15SYMcsTs", "replyto": "e15SYMcsTs", "signatures": ["ICLR.cc/2026/Conference/Submission19923/Reviewer_CLxv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19923/Reviewer_CLxv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926129982, "cdate": 1761926129982, "tmdate": 1762932091025, "mdate": 1762932091025, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes long-tailed SSL bias through learning dynamics. Key insight: predictions on baseline images (solid-color inputs) \\pi_\\theta(\\mathcal{I}) encode class bias via BatchNorm terms (Theorem 1). DyTrim uses these as pruning ratios for class-aware labeled data pruning and label-agnostic unlabeled pruning. Shows 1-3% improvements over CDMAD on CIFAR-LT/STL-LT/ImageNet-127."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Principled framework: decomposing learning dynamics with a formal link between baseline representations and class priors.\n\nConsistency: Works with FixMatch/FlexMatch/FreeMatch and WRN/ViT/ResNet.\n\nThorough validation: 15+ baselines, diverse settings (matched/mismatched \\gamma)."}, "weaknesses": {"value": "Incremental Gains: Performance improves by only 1–2 % over CDMAD, which is modest given their conceptual overlap—both methods rely on baseline-image statistics."}, "questions": {"value": "When does the method fail? What are its limitations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4Fk74jaUH6", "forum": "e15SYMcsTs", "replyto": "e15SYMcsTs", "signatures": ["ICLR.cc/2026/Conference/Submission19923/Reviewer_hNP6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19923/Reviewer_hNP6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762184653724, "cdate": 1762184653724, "tmdate": 1762932090539, "mdate": 1762932090539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}