{"id": "fNr4xz74kG", "number": 20149, "cdate": 1758303043676, "mdate": 1759896998999, "content": {"title": "CenterlineNet: Patch-Aligned Supervision For Thin Road Centerline Extraction", "abstract": "Road networks evolve over time, requiring frequent map updates. AI tools can\nassist with this task; however, methods based on raster segmentation followed by\nthinning, skeletonization, or automatic tracing may fail to capture the local struc-\nture of road networks, increasing the burden on human annotators. Our goal is to\ndirectly predict thin centerline representations that reflect structural patterns used\nby annotators, particularly at intersections. A secondary goal is to scale train-\ning by learning from variable-quality vector data, such as OpenStreetMap, rather\nthan relying on precisely aligned segmentation masks that are difficult to produce\nat scale. A key challenge is spatial misalignment in training data: while minor\nfor thick segmentation masks, even small shifts become a major obstacle when\nlearning thin centerlines, as pixel-wise losses are disproportionately affected. We\npropose CenterlineNet, a weakly supervised model that addresses this challenge\nwith a patch alignment loss that compares local neighborhoods instead of individ-\nual pixels. This loss matches each predicted neighborhood to its nearest annotated\ncenterline, enabling flexible alignment within a distance tolerance. We present\ntwo variants, basic and reciprocal, with the latter handling many-to-one mappings\nvia softmax-in-group weighting, and introduce an intersection-aware component\nthat specifically targets road junctions to improve connectivity.", "tldr": "CenterlineNet addresses spatial misalignment in road extraction by integrating patch alignment, reciprocal weighting, and intersection-aware loss to preserve connectivity.", "keywords": ["Road centerline extraction", "Remote sensing imagery", "Spatial misalignment", "Patch alignment loss", "Softmax-in-group weighting", "Intersection-aware loss", "Topology preservation", "Weakly supervised segmentation", "Vector field correspondence", "CenterlineNet"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9bfdeb0a896e052bd7b94f0981260138486a8bc1.pdf", "supplementary_material": "/attachment/f54ef7e9ca796e24fc6faec6c19df6a86546c362.pdf"}, "replies": [{"content": {"summary": {"value": "The paper addresses road centerline extraction from remote sensing imagery under spatial misalignment between predictions and noisy vector labels (e.g., OpenStreetMap). It proposes CenterlineNet, a weakly supervised model featuring a patch alignment loss that compares local neighborhoods via offset fields, a reciprocal softmax-in-group weighting to resolve many-to-one mappings, and an intersection-aware loss to preserve junction connectivity. Experiments on Centerline1M, SpaceNet, and RoadTracer show improved structural fidelity and robustness to misalignment."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Introduces a novel patch alignment loss that explicitly tolerates spatial misalignment by comparing local neighborhoods via learned or derived offset fields, directly addressing a key limitation of pixel-wise losses.  \n- Proposes a reciprocal softmax-in-group weighting mechanism to handle many-to-one correspondences along thin centerlines, encouraging sparse and confident predictions.  \n- Incorporates synthetic occlusion augmentation to improve robustness, with qualitative results showing maintained connectivity across obscured regions."}, "weaknesses": {"value": "- The ablation study (Table 1) does not clarify whether architectural changes (DeepLabUNetPrecise vs. standard U-Net/DeepLabV3+) or the loss functions drive performance gains; the contribution of the backbone is conflated with the proposed losses (Sec. 3.1; Table 1).  \n- Baseline models (e.g., CoANet) on SpaceNet and RoadTracer are compared without specifying whether they were retrained on the same misaligned labels or used with original settings, raising fairness concerns (Sec. 4.3; Table 2).  \n- Hyperparameters (e.g., dmax, τ, α/β/γ weights) are reported but their sensitivity is not analyzed; robustness to these choices is unverified (Sec. 3.2; Eq. 1).  \n- The singleton loss (Eq. 5) assigns hard targets based on logit ranking, which may introduce bias or instability, yet no analysis of its behavior or failure cases is provided.  \n- Failure modes are mentioned (“occluded roads, very thin rural roads, complex interchanges”) but not illustrated or quantified (Sec. 4.5; No direct evidence found in the manuscript beyond a textual note).  \n- Training details such as batch size, optimizer, learning rate schedule, and random seeds are omitted, limiting reproducibility (Sec. 4.3; No direct evidence found in the manuscript)."}, "questions": {"value": "- How much of the performance gain in Table 1 is attributable to the DeepLabUNetPrecise architecture versus the proposed loss functions? Could the same losses be applied to a standard U-Net to isolate their effect?  \n- Were the baseline models (e.g., CoANet) retrained on your misaligned Centerline1M labels, or are the results based on models trained on clean data and evaluated under misalignment? This affects the validity of the comparison in Table 2.  \n- The singleton loss assigns non-differentiable hard targets (tx). Did you observe training instability or convergence issues due to this? Have you considered soft targets or alternative formulations?  \n- The intersection-aware loss uses a fixed radius r for matching. How was r chosen, and how sensitive is performance to this parameter?  \n- Could the patch alignment framework be extended to other thin-structure extraction tasks (e.g., rivers, power lines)? The conclusion mentions this, but no preliminary evidence is shown."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CxwaktOt0Y", "forum": "fNr4xz74kG", "replyto": "fNr4xz74kG", "signatures": ["ICLR.cc/2026/Conference/Submission20149/Reviewer_fV7L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20149/Reviewer_fV7L"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760943364897, "cdate": 1760943364897, "tmdate": 1762999987049, "mdate": 1762999987049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a semantic segmentation-based road extraction model. The model is built on the DeepLabv3 and UNet-like decoder, that the road centerline extraction is achieved with a combined loss function. The main difference to previous work is the loss items, which focus on improving several issues in large-scale road extraction training with low-quality GT. Overall, I don't think this work is innovative and good enough to publish in ICLR 2026. Currently, more popular methods for road extraction is global graph extraction-based approach, instead of semantic segmentation (or called pixelwise classification). The segmentation based approaches are usually worse than graph-based approach in maintaining good connectivity. Besides, it is hard to distinguish intersection and two roads on different heights (e.g., highway bridges). Therefore, I think a comparison with the current SOTA graph-based approach is important. I rate this paper as \"2: reject, not good enough\"."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper presents a new dataset called Centerline1M.\n\n2. This paper provides ablation study to show the effectiveness of their combined loss."}, "weaknesses": {"value": "1. Overall, this paper doesn't mention graph-based approaches (iterative graph growing RoadTracer  or global graph extraction TD-Road, SAMRoad) in the entire draft, including related work and experiments.\n\n2. Writing issues. Fig 2 is very confusing, especially the left part. Line 290 Tab ?\n\n3. Experiment is not solid. Lack of experiments and comparison on more popular datasets/evaluation metrics and recent SOTA like SpaceNet, SAMRoad. This paper can evaluate the model with more widely used metrics like APLS.\n\n4. In Fig 4, I cannot believe the road prediction on artificial occluded region is a good behavior. The occluded region can be roads, buildings, or some other objects. It is not reasonable to predict it as a road because of nearby roads and their orientations."}, "questions": {"value": "I don't have questions. I don't think this paper is good enough to publish in ICLR 2026."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "69reh3fBcs", "forum": "fNr4xz74kG", "replyto": "fNr4xz74kG", "signatures": ["ICLR.cc/2026/Conference/Submission20149/Reviewer_g7oR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20149/Reviewer_g7oR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761548814371, "cdate": 1761548814371, "tmdate": 1762933179289, "mdate": 1762933179289, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a practical problem in extracting thin road centerlines from satellite imagery: the data is often slightly misaligned. Standard methods that demand perfect pixel-to-pixel matches struggle with this, especially for one-pixel-wide lines. The authors introduce CenterlineNet, a new approach centered on a \"patch alignment loss.\" Instead of punishing single-pixel errors, it compares small local patches, allowing for minor shifts. This core idea is supported by two other clever components: a \"reciprocal weighting\" scheme to prevent blurry or multiple predictions on a single line, and a specialized \"intersection loss\" that actively improves connectivity at complex road junctions.\nThe results show that CenterlineNet is more robust to real-world data noise than standard models, delivering cleaner, better-connected road networks. Its main contribution is a training strategy that works effectively with the imperfect, crowd-sourced data we actually have, rather than requiring perfectly aligned labels."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of using a patch-based loss guided by an offset field for thin structure extraction under misalignment is novel. \n2. The authors design DeepLabUNetPrecise and provided detailed experimental results and explanations."}, "weaknesses": {"value": "3.2.2 & 3.2.3 - The loss function introduces numerous hyperparameters, particularly d_{max} controlling the tolerance band width and τ controlling the softmax temperature. These parameters require careful tuning.\n\n  4.4 - The use of rectangular occlusions and global mean value filling may be overly idealized and fail to simulate real-world occlusions (e.g., tree shadows, clouds), potentially leading to an overestimation of the model's generalization capability in genuine occlusion scenarios."}, "questions": {"value": "1.   In Section 3.1, the authors propose a hybrid \"DeepLabUNetPrecise\" architecture.  Were any controlled ablation studies conducted where your proposed loss functions were applied to other modern backbone networks (e.g., Transformer-based models)?\n2.   In Section 3.2.1, the temperature parameter τ is introduced to control the sharpness of the softmax distribution for weighting. How was the value of τ determined? Is it sensitive to different datasets or road widths? Are there any ablation studies demonstrating its impact on model performance?\n3.   In Table 1 of the ablation study, the configuration \"CenterlineNet + CE + Patch Alignment + Reciprocal Loss\" shows a lower F1 score compared to the version using only \"CenterlineNet + CE + Patch Alignment Loss\". Does this indicate that the Reciprocal Loss might be detrimental in certain scenarios? Could you explain this performance drop?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "a6ngZYeU6e", "forum": "fNr4xz74kG", "replyto": "fNr4xz74kG", "signatures": ["ICLR.cc/2026/Conference/Submission20149/Reviewer_rGKG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20149/Reviewer_rGKG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924780344, "cdate": 1761924780344, "tmdate": 1762933176882, "mdate": 1762933176882, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents CenterlineNet, a weakly supervised framework for extracting thin road centerlines from remote sensing imagery with misaligned annotations. The core idea is a patch-aligned supervision loss that compares local neighborhoods instead of pixel-wise labels, providing spatial tolerance to registration errors and enabling robust learning from noisy or imprecise vector data. The method further incorporates a reciprocal softmax-in-group weighting, a singleton constraint, and an intersection-aware loss to enhance sparsity and connectivity of thin-line predictions. The proposed approach is evaluated on the newly constructed Centerline1M dataset and further tested on SpaceNet and RoadTracer to assess generalization. Experimental results demonstrate that CenterlineNet consistently outperforms standard segmentation baselines in terms of F1 score and structural consistency, improving the accuracy and topological completeness of road extraction under misaligned supervision."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a practical problem in remote sensing, extracting thin road centerlines from imagery with spatially misaligned or noisy annotations.\n2. The proposed patch-aligned supervision loss is conceptually clear and technically novel, providing a principled way to tolerate registration errors during training without explicit label realignment"}, "weaknesses": {"value": "1. Formatting and layout issues:\nThe paper contains evident formatting errors, including unresolved cross-references (e.g., “Table ??”) and inconsistently formatted tables with misaligned columns. Such presentation problems are unacceptable for a submission to a conference like ICLR and significantly affect the readability and professionalism of the paper.\n\n2. Outdated and insufficient related work:\nThe review of related work is overly limited and lacks coverage of recent advances. Road extraction has been a long-standing and active research topic in remote sensing image interpretation, yet most of the cited literature predates 2022. The paper fails to engage with recent studies in weakly supervised segmentation, topology-preserving segmentation, and structure-aligned representation learning (e.g., NeurIPS 2023, CVPR 2024), which weakens the positioning and novelty of the proposed contribution.\n\n3. Unconvincing ablation study design:\nThe ablation experiments presented in Table 1 raise several concerns.\nFirst, all comparison models are outdated architectures from around seven years ago (e.g., U-Net, DeepLabV3), without including more competitive modern baselines. Second, the baselines employ only standard CE or Dice losses, leaving it unclear whether the proposed loss function can generalize across different backbones. Finally, the ablation design incrementally adds multiple loss components but does not analyze their interactions or redundancy. Notably, the model’s performance decreases after introducing the Reciprocal Loss, yet the paper provides no explanation for this behavior.\n\n4. Unreliable evaluation on public datasets:\nThe experiments reported in Table 2 are also unconvincing. The authors compare only with CoANet, which is not representative of current state-of-the-art models. Moreover, CoANet’s unusually low accuracy on the RoadTracer dataset raises doubts about whether it was properly trained. To enhance credibility, the authors should include more recent baselines, clearly describe their experimental settings in the supplementary material, and report performance across different pixel-tolerance thresholds."}, "questions": {"value": "1. The paper contains unresolved cross-references (e.g., “Table ??”) and inconsistently formatted tables. Please fix all formatting and layout errors and provide a properly typeset version in the rebuttal.\n2. The related work section lacks recent literature (2023–2025) on weakly supervised segmentation, topology-preserving losses, and structure-aligned representation learning. Please expand this section and discuss how your method differs from these more recent works.\n3. The baselines used in Tables 1 and 2 are outdated (e.g., U-Net, DeepLabV3, CoANet). Please include more recent and competitive baselines to provide a fair comparison.\n4. The proposed loss is only tested on DeepLabUNetPrecise. Could you verify whether the patch-aligned loss generalizes to other backbones such as ResNet-FPN or Transformer-based architectures?\n5. The ablation study only performs incremental additions of each loss term without analyzing their interactions. Please include a more detailed ablation matrix and explain why performance decreases after adding the Reciprocal Loss.\n6. Please provide full training and evaluation details in the supplementary material, including data preprocessing, hyperparameters, patch size, search radius, optimizer settings, hardware, and runtime.\n7. The evaluation metric relies on pixel-tolerance matching, but results under different tolerance thresholds (e.g., 1px, 3px, 5px) are not reported. Please include performance curves or tables across different tolerances.\n8. The CoANet baseline shows abnormally low accuracy on the RoadTracer dataset. Could you confirm whether it was properly trained or tuned, and provide the corresponding hyperparameter settings?\n9. The proposed patch-aligned loss may introduce extra computational overhead. Please report training time, GPU memory usage, and the relative cost compared to a standard CE loss.\n10. Figures 3, 4, and 5 are blurry and low resolution. Please provide high-quality visualizations or enlarged versions in the appendix for clearer comparison.\n11. Will the Centerline1M dataset and code implementation be released? If not, please clarify what data or scripts will be made available to ensure reproducibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5KKkI69KUE", "forum": "fNr4xz74kG", "replyto": "fNr4xz74kG", "signatures": ["ICLR.cc/2026/Conference/Submission20149/Reviewer_vcHC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20149/Reviewer_vcHC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20149/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982894953, "cdate": 1761982894953, "tmdate": 1762933176057, "mdate": 1762933176057, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}