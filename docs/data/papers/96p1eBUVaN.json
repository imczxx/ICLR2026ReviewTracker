{"id": "96p1eBUVaN", "number": 3260, "cdate": 1757389129257, "mdate": 1763713909015, "content": {"title": "Enabling True Global Perception in State Space Models for Visual Tasks", "abstract": "Despite the importance of global contextual modeling in visual tasks, a rigorous mathematical definition remains absent, and the concept is still largely described in heuristic or empirical terms. Existing methods either rely on computationally expensive attention mechanisms or are constrained by the recursive modeling nature of State Space Models (SSMs), making it challenging to achieve both efficiency and true global perception. To address this, we first propose a mathematical definition of global modeling for visual images, providing a theoretical foundation for designing globally-aware and interpretable models. Based on in-depth analysis of SSMs and frequency-domain modeling principles, we construct a complete theoretical framework that overcomes the limitations imposed by SSMs' recursive modeling mechanism from a frequency perspective, thereby adapting SSMs for global perception in image modeling. Guided by this framework, we design the Global-aware SSM (GSSM) module and formally prove that it satisfies definitional requirements of global image modeling. GSSM leverages a Discrete Fourier Transform (DFT)-based modulation mechanism, providing precise front-end control over the SSM's modeling behavior, and enabling efficient global image modeling with linear-logarithmic complexity. Building upon GSSM, we develop GMamba, a plug-and-play module that can be seamlessly integrated at any stage of Convolutional Neural Networks (CNNs). Extensive experiments across multiple tasks, including object detection, semantic segmentation, and instance segmentation, across diverse model architectures, demonstrate that GMamba consistently outperforms existing global modeling modules, validating both the effectiveness of our theoretical framework and the rigor of proposed definition.", "tldr": "", "keywords": ["State Space Model", "Frequency Domain Modulation", "Global Image Modeling", "Mathematical Definition"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1316f2e13c19e84ae021d47071c2cca4bac60903.pdf", "supplementary_material": "/attachment/8db45544c11b45c2d7a82e99f05b6a7eb8bc9d57.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a novel module, Global-aware SSM (GSSM), which is the core of a plug-and-play block called GMamba. The key idea is to use a Discrete Fourier Transform (DFT)-based modulation mechanism to \"inject\" global information into the features before they are processed by the SSM. This frequency-domain pre-modulation guides the SSM's state updates with a true global perspective, enabling efficient global modeling with linear-logarithmic complexity"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed GMamba block shows consistent and significant performance improvements when added to various backbones (e.g., ResNet, Swin, ConvNeXt) . It outperforms existing global modeling methods, including Transformer and other Mamba variants, on several dense-prediction tasks (semantic segmentation, object detection, and instance segmentation) across multiple datasets."}, "weaknesses": {"value": "1. The paper's theoretical claims rest heavily on its new definition of global perception—\"global gradient dependency\". This definition requires that the Frobenius norm of the gradient of the output with respect to any input pixel is bounded by a non-zero constant $\\tau$. This is a very low bar. A gradient that is infinitesimally small but non-zero would satisfy this definition, but this may not align with an intuitive or practical understanding of \"global influence.\" The claim of \"true\" global perception is therefore only as strong as the acceptance of this new, and debatable, definition.\n\n\n2. Although the authors claim that the proposed GSSM enables efficient global image modeling, there is no related experimental data on practical inference latency or GPU memory cost. Relying only on FLOPs may not accurately reflect the module's true efficiency, as operations like 2D-DFT can have different hardware utilization profiles than standard convolutions.\n\n3. The experimental validation is extensive on dense prediction tasks (segmentation and detection). However, a standard benchmark for vision backbones is ImageNet classification. The absence of this benchmark makes it slightly more difficult to assess the module's generalizability as a fundamental building block for all vision tasks.\n\n4. Some illustrations of previous work in this paper appear to be incorrect and may mislead readers. The authors show the ViM scanning routes in Figure 1(c), but this depiction seems to be wrong (as noted in other work, e.g., [1]). This potential misrepresentation of a key baseline method is a concern.\n\n[1]. Visual mamba: A survey and new outlooks, 2024."}, "questions": {"value": "Please check the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YVRWZ2OPxr", "forum": "96p1eBUVaN", "replyto": "96p1eBUVaN", "signatures": ["ICLR.cc/2026/Conference/Submission3260/Reviewer_YRTs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3260/Reviewer_YRTs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761457821046, "cdate": 1761457821046, "tmdate": 1762916633614, "mdate": 1762916633614, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limited global perception of State Space Models (SSMs) in vision tasks by proposing a frequency-domain modulation approach. The proposed GSSM block applies DFT-based frequency decomposition to extract global semantic information and uses adaptive modulation coefficients to guide SSM's state updates before sequential processing, achieving linear-logarithmic complexity O(nlogn). The authors show that the proposed GMamba block is plug-and-play across different CNN architectures. Experiments on semantic segmentation (Vaihingen, Potsdam, LoveDA, UAVid), object detection, and instance segmentation (MS-COCO) demonstrate consistent improvements of 2-3% mIoU across ResNet, Swin Transformer, and ConvNeXt backbones. While the theoretical framework looks good, the practical gains are modest given the added complexity, and the core idea of frequency-domain processing for vision is well-established in prior work."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides an interesting mathematical definition of global image modeling and establishes a complete theoretical framework showing how DFT-based modulation can enrich the SSMs with global perception capabilities. \n\n- The motivation is simple yet effective: SSMs rely on sequential state updates, which limit them to local rather than global modeling, and existing methods using different scanning strategies have not enhanced SSM's global modeling capability.\n\n- The authors did extensive experiments on multiple tasks (semantic segmentation, object detection, instance segmentation) across many datasets with different backbone architectures, demonstrating the generalization capability of GMamba models."}, "weaknesses": {"value": "- While the theoretical framework is novel, the core idea of using frequency-domain information for computer vision is well-established. (i.e, ICCV'23 works like SPANet [1]) and recent methods FAD [2]. The paper doesn't sufficiently differentiate its approach from these existing frequency-based methods.\n\n- Existing work, such as Vim and VMamb, has demonstrated that SSMs can achieve global receptive fields through bidirectional processing and multi-directional scanning. The paper's claim that current SSMs lack global perception seems overstated.\n\n- The related work and the comparison are missing recent state-space models (i.e, GroupMamba[3] (CVPR'25), MambaVision[4] (CVPR'25). Also, the provided implementation of GMamba_Block.py in the supplementary material appears to be largely derived from the MambaVisionMixer module introduced in MambaVision [4]. The authors have added their frequency components on top of that code. However, they neither cite nor compare their results with MambaVision paper [4].\n\n- The reported improvements are relatively modest (around 2–3% mIoU) while introducing a significant parameter increase of 20–35%. It remains unclear whether these gains come from the added parameters or from the model’s inherent effectiveness. For example, in Table 2, the baseline UNet-ConvNeXt(S) has 58.42M parameters, whereas incorporating GMamba raises this to 71.06M, yielding 2.89% improvement in mIoU. A fair comparison would require scaling the baseline (e.g., by increasing the number of channels or blocks) to match 71.06M parameters, to determine if the gains are truly architectural rather than parameter-driven.\n\n[1] https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.pdf\n\n[2] https://arxiv.org/pdf/2505.08349\n \n[3] https://openaccess.thecvf.com/content/CVPR2025/papers/Shaker_GroupMamba_Efficient_Group-Based_Visual_State_Space_Model_CVPR_2025_paper.pdf\n\n[4] https://openaccess.thecvf.com/content/CVPR2025/papers/Hatamizadeh_MambaVision_A_Hybrid_Mamba-Transformer_Vision_Backbone_CVPR_2025_paper.pdf"}, "questions": {"value": "- It is unclear whether the GMamba models used for object detection and instance segmentation are initialized with backbones pre-trained on ImageNet or not. If yes, what is the top-1 accuracy of GMamba on ImageNet?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dirW60HAYH", "forum": "96p1eBUVaN", "replyto": "96p1eBUVaN", "signatures": ["ICLR.cc/2026/Conference/Submission3260/Reviewer_PSzr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3260/Reviewer_PSzr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761694511039, "cdate": 1761694511039, "tmdate": 1762916633374, "mdate": 1762916633374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the efficiency-global perception trade-off in visual tasks by proposing a rigorous mathematical definition of global image modeling and a frequency-domain modulated framework. Leveraging 2D-DFT’s global properties, the authors design the GSSM module and plug-and-play GMamba block, which seamlessly integrate into CNNs/Transformers. Extensive experiments across semantic segmentation, object detection, and instance segmentation show GMamba outperforms existing modules with linear-logarithmic complexity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- First rigorous mathematical definition of global image modeling with formal proofs.\n- DFT-based modulation overcomes SSMs’ local limitation without complex scanning.\n- Strong performance across tasks, backbones, and datasets with efficiency advantages.\n- Thorough ablations for validating key design choices (GSSM components, frequency contributions)."}, "weaknesses": {"value": "- Insufficient analysis of scaling to ultra-high-resolution images (e.g., 4K+) and inference speed (FPS).\n- Lack of explicit comparison with recent frequency-domain SSM variants (e.g., FreqMamba [1]).\n- No analysis of failure cases.\n- Lack experiments on the Imagenet benchmark.\n\n[1] Freqmamba: Viewing mamba from a frequency perspective for image deraining"}, "questions": {"value": "please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HjVduHII7p", "forum": "96p1eBUVaN", "replyto": "96p1eBUVaN", "signatures": ["ICLR.cc/2026/Conference/Submission3260/Reviewer_rPrr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3260/Reviewer_rPrr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761798565669, "cdate": 1761798565669, "tmdate": 1762916633131, "mdate": 1762916633131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Global-aware SSM (GSSM) module, which integrates frequency-domain modulation using Discrete Fourier Transform (DFT) to enable true global perception in State Space Models (SSMs). ​ The authors propose a mathematical definition for global image modeling and prove that GSSM satisfies this definition. ​ They design GMamba, a plug-and-play module that enhances global contextual understanding in Convolutional Neural Networks (CNNs) with linear-logarithmic complexity. Extensive experiments on semantic segmentation, object detection, and instance segmentation demonstrate GMamba’s superior performance and efficiency compared to existing methods. ​ The study highlights the importance of frequency-domain information and adaptive modulation for balancing global semantics and local precision."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. True Global Perception: GMamba, powered by the GSSM module, achieves true global perception by leveraging the Discrete Fourier Transform (DFT) for frequency-domain modulation. This enables the model to capture global semantic information efficiently. \n\n2. Efficiency: GMamba exhibits linear-logarithmic computational complexity, making it significantly more efficient than traditional self-attention mechanisms with quadratic complexity.\n\n3. Plug-and-Play Design: GMamba can be seamlessly integrated into various stages of CNNs and other backbone architectures, enhancing their global modeling capabilities without requiring major architectural changes. \n\n4. Scalability: GMamba demonstrates scalable performance gains when integrated with more powerful backbone architectures, such as ConvNeXt-Small and Swin Transformer-Tiny.\n\n5. Effective Frequency Decomposition: The use of both high-frequency and low-frequency components enhances global semantic modeling and local detail preservation, with adaptive modulation further optimizing their integration."}, "weaknesses": {"value": "1. Limitation: The reliance on DFT-based frequency-domain modulation may introduce challenges in scenarios where frequency-domain information is less effective, such as highly noisy or irregular data.\n\n2. Impact: While the frequency-domain approach enhances global perception, it may struggle in cases where spatial features dominate or where frequency information is less relevant.\n\n3. Although GMamba is more efficient than self-attention mechanisms, it still introduces additional computational overhead compared to simpler SSM-based methods like Vim or TinyViM. \n\n4. While GMamba is described as \"plug-and-play,\" its integration requires careful tuning of parameters such as modulation coefficients and frequency-domain weights. This could increase the complexity of implementation and training.\n\n5. The robustness of GMamba in such challenging scenarios remains unclear, which could affect its reliability in real-world applications."}, "questions": {"value": "1. The paper claims to provide the first rigorous mathematical definition of global image modeling, which is a significant contribution. However, it does not compare this definition with existing heuristic approaches in detail, leaving room for further exploration of how it improves interpretability and theoretical support.\n\n2. How does the frequency-domain transfer function derived for SSMs compare to other global modeling techniques, such as attention mechanisms?\n\n3. How does GMamba's linear-logarithmic complexity compare to the linear complexity of other SSM-based methods like Vim, VMamba or spatial mamba?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WnHUhHr0cC", "forum": "96p1eBUVaN", "replyto": "96p1eBUVaN", "signatures": ["ICLR.cc/2026/Conference/Submission3260/Reviewer_nc9h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3260/Reviewer_nc9h"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762036220514, "cdate": 1762036220514, "tmdate": 1762916632681, "mdate": 1762916632681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}