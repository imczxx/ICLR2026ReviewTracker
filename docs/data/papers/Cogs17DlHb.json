{"id": "Cogs17DlHb", "number": 6132, "cdate": 1757953827457, "mdate": 1759897933864, "content": {"title": "3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding", "abstract": "Large vision-language models (VLMs) have made significant strides in 2D visual understanding tasks, sparking interest in extending these capabilities to 3D scene understanding. However, current 3D VLMs often struggle with robust reasoning and generalization due to limitations in high-quality spatial data and the static nature of viewpoint assumptions. To address these challenges, we propose 3D-R1, a general framework that enhances the reasoning capabilities of 3D VLMs. Specifically, we first construct a high-quality synthetic dataset with CoT, named Scene-30K, leveraging existing 3D-VL datasets and a data engine based on DeepSeek-R1. It serves as cold-start initialization data for 3D-R1. Moreover, we leveraging RLHF policy such as GRPO in the reinforcement learning training process to enhance reasoning capabilities and introduce two reward functions: a perception reward and a semantic similarity reward to maintain detection accuracy and answer semantic precision. Furthermore, we introduce a dynamic view selection strategy that adaptively chooses the most informative perspectives for 3D scene understanding. Extensive experiments demonstrate that 3D-R1 delivers an average improvement of 10% across various 3D scene benchmarks, highlighting its effectiveness in enhancing reasoning and generalization in 3D scene understanding.", "tldr": "", "keywords": ["3D Scene Understanding", "3D Computer Vision", "Reinforcement Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6fae3c138160a8351c1a94480c8d2e3891f3d392.pdf", "supplementary_material": "/attachment/9dc275c16b1cd5c742e8f149d28ad9eecee209e5.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents 3D-R1, a 3D vision-language foundation model aimed at enhancing reasoning and generalization in unified 3D scene understanding. The model combines cold-start supervised fine-tuning on a newly built Scene-30K CoT dataset with reinforcement learning using Group Relative Policy Optimization (GRPO). Extensive experiments on multiple benchmarks (ScanRefer, Nr3D, Cap3D, ScanQA, 3D-LLM, and SQA3D) show consistent performance gains, with 3D-R1 outperforming prior 3D VLMs by roughly 10% on average across tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The integration of reinforcement learning (GRPO) into 3D vision-language training is essential. The use of multi-reward signals to align reasoning, perception, and semantic accuracy is a clear conceptual advancement.\n2. The Scene-30K dataset, generated with Gemini 2.5 Pro and structured CoT reasoning, is a valuable resource for promoting step-by-step spatial reasoning in 3D.\n3. The experiments are comprehensive and detailed across diverse tasks."}, "weaknesses": {"value": "1. The discussion of related work is insufficient. Several recent and more advanced 3D multimodal LLMs—such as **Inst3D-LMM (CVPR 2025)** and **Video-3D LLM (CVPR 2025)**—are not discussed or compared. A more comprehensive review and comparison would strengthen the paper.\n2. The writing quality, as well as the presentation and layout of figures and tables, still have considerable room for improvement.\n3. The paper lacks ablation studies to validate the generalization ability and effectiveness of the proposed 3D-R1."}, "questions": {"value": "I will update my assessment after considering feedback and technical insights from other reviewers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OR2QjFzGzp", "forum": "Cogs17DlHb", "replyto": "Cogs17DlHb", "signatures": ["ICLR.cc/2026/Conference/Submission6132/Reviewer_NWsq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6132/Reviewer_NWsq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6132/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761488834236, "cdate": 1761488834236, "tmdate": 1762918492051, "mdate": 1762918492051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents 3D-R1, a foundational vision-language model that improves 3D scene understanding by leveraging a high-quality synthetic dataset (Scene-30K) with chain-of-thought annotations and advanced data generation. The model is further enhanced using reinforcement learning with specialized reward functions and a dynamic view selection strategy. Experiments show that 3D-R1 achieves an average 10% improvement on multiple 3D scene benchmarks, demonstrating better reasoning and generalization than previous models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper writen is clear and easy-to-follow.\n2. The paper achieves performance improvements over current models.\n3. The experiments show that the proposal modules can effectively imrpove model performance, e.g., RL rewards and view selection."}, "weaknesses": {"value": "1. Recent papers, such as VG-LLM [1] and 3DRS [2], have not been cited or compared.\n\n2. In terms of technical novelty, the proposed GRPO algorithm is a straightforward extension of the original, but lacks clear innovation compared to recent variants like Visual-RFT [3].\n\n3. While the paper introduces multiple encoders for visual feature extraction, it does not provide FLOPs or inference speed comparisons. Additionally, most prior methods employ only a single encoder.\n\n[1] Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors. NeurIPS 2025.\n\n[2]  MLLMs Need 3D-Aware Representation Supervision for Scene Understanding. NeurIPS 2025.\n\n[3] Visual-RFT: Visual Reinforcement Fine-Tuning. ICCV 2025."}, "questions": {"value": "1. Please cite and discuss recent relevant papers.\n\n2. Please evaluate the impact of using multiple encoders"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4FHQoxCFiy", "forum": "Cogs17DlHb", "replyto": "Cogs17DlHb", "signatures": ["ICLR.cc/2026/Conference/Submission6132/Reviewer_62Jv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6132/Reviewer_62Jv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6132/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761553021229, "cdate": 1761553021229, "tmdate": 1762918491640, "mdate": 1762918491640, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents three main contributions:\n\n1.\tScene-30K Dataset – A large-scale dataset annotated with Chain-of-Thought (CoT) labels derived from existing 3D-VL datasets using an unspecified 3D-VLM model and Gemini 2.5 Pro.\n2.\tGRPO-based Reinforcement Learning Framework – An RL training strategy designed to enhance the reasoning capabilities of 3D-VLMs.\n3.\tDynamic View Selection Strategy – An adaptive mechanism that automatically selects the most informative viewpoints from 3D scenes for multi-view visual understanding.\n\nThe proposed approach achieves state-of-the-art performance across multiple 3D scene understanding benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* The proposed method is conceptually simple and clearly motivated.  \n* The paper is well-written and easy to follow.  \n* Extensive experiments demonstrate strong performance, achieving state-of-the-art results on several standard 3D scene benchmarks."}, "weaknesses": {"value": "* Lack of Related Work Discussion:  \n  The paper lacks a comprehensive related works section that situates this research within the broader context of 3D-VLM and reasoning-based approaches. A deeper comparison with existing 3D reasoning or view selection methods would strengthen the positioning of this work.  \n\n* Insufficient Methodological Details:  \n  * In Section 2.2 (CoT Data Engine), the authors mention using “a pre-trained 3D VLM that produces a concise textual summary of the scene.” However, it is unclear which specific 3D-VLM model is used. Is this the same as the final model trained with GRPO, or a different one?  \n  * If the pre-trained 3D-VLM can already generate high-quality textual scene summaries, could combining it with a strong LLM yield comparable performance to the proposed method? This point deserves clarification.\n\n* Limited technical contribution: The CoT data engine design is rather straightforward, and the overall training framework largely mirrors DeepSeek-R1’s GRPO pipeline, offering limited technical contribution.\n\n* Missing Ablation Studies:  \n  * The paper does not report the model’s performance before and after GRPO fine-tuning. How are the weighting coefficients in Equation (7) selected? Ablation experiments are necessary to justify these design choices.  \n  * Similarly, the impact of the proposed dynamic view selection strategy is not isolated. Quantitative comparison with and without this component would provide a clearer understanding of its contribution."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nXAIFcdcdv", "forum": "Cogs17DlHb", "replyto": "Cogs17DlHb", "signatures": ["ICLR.cc/2026/Conference/Submission6132/Reviewer_nUgE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6132/Reviewer_nUgE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6132/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805631912, "cdate": 1761805631912, "tmdate": 1762918490074, "mdate": 1762918490074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces 3D-R1, a foundation model designed to enhance the reasoning capabilities of 3D VLMs. The model achieves this through a two-stage approach: incorporating cold-start initialization using Scene-30K, a novel, high-quality synthetic dataset with CoT, and subsequent refinement via GRPO. Extensive experiments show that 3D-R1 achieves notable performance gains across a wide range of 3D reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. 3D-R1 demonstrates clear performance improvements over prior SOTA methods across various demanding 3D reasoning benchmarks.\n2. The paper provides detailed descriptions of the model architecture and experimental setup. The supplementary material, including the provided code, further enhances the potential for reproducibility."}, "weaknesses": {"value": "1. The overall approach (CoT data collection followed by GRPO) appears somewhat conventional for enhancing VLM reasoning. And the data collection method is straightforward.\n2. The \"Experiments\" section primarily focuses on setup and metrics, lacking in-depth summarization and analysis of the quantitative results. The rich ablation studies and qualitative results in the Appendix also suffer from a similar lack of interpretation.\n3. The paper's layout is inefficient, as several important components, such as the Related Work and Ablation Studies, are placed in the Appendix, which diminishes their visibility and immediate impact on the reader."}, "questions": {"value": "1. The rule-based filtering seems primarily focused on verifying the format of the CoT data. Could the authors clarify the specific mechanism used to verify the logical consistency between the multi-step CoT reasoning process and the final answer to ensure the quality of the reasoning chain itself?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w9NASctqe6", "forum": "Cogs17DlHb", "replyto": "Cogs17DlHb", "signatures": ["ICLR.cc/2026/Conference/Submission6132/Reviewer_1wga"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6132/Reviewer_1wga"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6132/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921863012, "cdate": 1761921863012, "tmdate": 1762918489490, "mdate": 1762918489490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}