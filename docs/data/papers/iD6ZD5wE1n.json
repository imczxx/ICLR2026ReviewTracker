{"id": "iD6ZD5wE1n", "number": 21663, "cdate": 1758320258217, "mdate": 1759896909940, "content": {"title": "A dimensional R2 regression metric", "abstract": "Evaluation metrics are the primary guide in modeling. For regression tasks, the R2 score is the gold standard, offering a magnitude-agnostic measure of accuracy that captures variance. However, R2 has three key limitations: it is limited to at most two dimensional inputs, it reduces the score to a single scalar that hides rich patterns of prediction accuracy, and it is sensitive to low-variance noise channels which can yield large, uninterpretable negative values. We introduce the Dimensional R2 score (Dim-R2), a simple extension of R2 that accepts data of arbitrary dimensionality, provides a multidimensional view of accuracy, and reduces sensitivity to noise. We demonstrate its advantages on both synthetic sinusoidal data and data-constrained recurrent neural networks trained to simulate mouse neural activity during a skilled motor task. Dim-R2 offers an interpretable and flexible metric that illuminates patterns in regression accuracy, guiding regression modeling.", "tldr": "A new dimensional R2 regression metric that accepts multidimenional data, shows dimensional view, and is resilient to noise compared to conventional R2 score.", "keywords": ["Regression", "Evaluation metric", "Multidimensional data", "Multidimensional score", "Noise resilience", "Recurrent neural network", "Motor cortex recording"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3086557a57b7f6b247451dea5db6494f65032f21.pdf", "supplementary_material": "/attachment/d2c8af150b4854f6ff5c8312583ae9a7dea2d541.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes Dimensional R² (Dim‑R²), a generalization of the coefficient of determination that: (1) works with arbitrarily high‑dimensional regression targets by collapsing user‑selected axes, (2) produces multidimensional maps of predictive accuracy instead of a single scalar, and (3) is less sensitive to low‑variance noise channels than mean per‑channel R². The method is specified via three arguments — Axis, Axis_ref, and Axis_bias — and computes RSS and TSS with broadcasting to preserve the remaining dimensions (Equations 3–6; schematic in Figure 3, p. 3). The paper demonstrates properties on (a) synthetic sinusoidal data with controlled noise and bias and (b) a data‑constrained RNN trained to reproduce mouse spiking activity during a reach‑to‑grab task. It highlights how Dim‑R² surfaces structure across time, trial, and neuron axes that is obscured by the mean of per‑channel R², and it reports that Dim‑R² is more robust when some channels are near‑constant noise."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- For practitioners, the dimensional view in Figures 6–7 (pp. 6–7) shows informative accuracy structure (e.g., time‑localized predictability and region‑specific effects) that scalar R² cannot reveal. The paper explains how changing Axis_ref changes what “variance explained” means operationally.\n- Simple to implement and deploy. The formulation reduces to computing RSS/TSS over collapsed axes and broadcasting the shapes; a NumPy reference implementation following scikit‑learn syntax is mentioned. This lowers integration friction in typical pipelines."}, "weaknesses": {"value": "- Novelty is narrower than claimed. The paper states conventional R² is “limited to at most two-dimensional inputs” and must be averaged per channel, but widely used libraries already support multi‑output R² with options (raw_values, uniform_average, variance_weighted) and variance‑weighted aggregation across outputs. At minimum, this weakens the motivation that basic R² “cannot” operate beyond 2D. The submission’s real contribution is a systematic axis‑aware mapping and reference‑variance design, not multi‑output support per se. Additionally, the nonparametric extension of R² can deal with functional data.\n- Comparative baselines are too thin. The paper compares Dim‑R² mostly to mean per‑channel R². It does not compare against explained variance (which explicitly addresses constant‑variance pathologies) nor against off‑the‑shelf variance‑weighted R² and raw per‑output R² summaries. These are natural, strong baselines for the stated robustness claims.\n- External validity is narrow. The main real‑world case study is neural spiking data with an RNN, a specialized domain. It’s unclear how Dim‑R² behaves on standard multi‑target ML benchmarks (multi‑variate time‑series forecasting, multi‑task regression, multichannel sensor prediction) or how it interacts with common evaluation practices there."}, "questions": {"value": "- The authors are encouraged to strengthen their empirical results, by adding stronger baselines and a failure‑mode table. Include variance‑weighted R², raw per‑output R², explained variance (finite vs non‑finite behavior), and correlation maps, and summarize when each metric is recommended. One can also compare with nonparametric R².\n- For functional data, like time series, R² does not provide a meaningful explanation, because of dependence among data points. Would the extension of R² also suffer the same issue?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t5bIvf6H1c", "forum": "iD6ZD5wE1n", "replyto": "iD6ZD5wE1n", "signatures": ["ICLR.cc/2026/Conference/Submission21663/Reviewer_oZZX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21663/Reviewer_oZZX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760768638740, "cdate": 1760768638740, "tmdate": 1762941878788, "mdate": 1762941878788, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed the \"Dimensional R2 (Dim-R2)\" score, an extension of the conventional R2 (coefficient of Determination) Metric. The author claims that the conventional R2, as the gold standard, has three key limitations:\n- is limited to at most two-dimensional data (is defined for 1D input and is averaged across channels for 2D input)\n- reduces model performance to a single scalar, hiding the insight into how accuracy varies across data dimensions\n- is highly sensitive to low-variance noise channels in multi-channel regression tasks, yielding large and uninterpretable negative values\n\nThe Dim-R2 metric aims to solve those limitations by \"flattening\" selected dimensions of multidimensional data into independent observations and computing the single and standard R2 score, while retaining the shape of the remaining dimensions. So that the author claim the Dim-R2 will provide three key benefits:\n- accepts regression input of \"arbitrary dimensionality\"\n- provides a \"multidimensional view of prediction accuracy\", helping modelers identify patterns in both data and models\n- will be more \"resilient to noise\" than the conventional Mean R2 score, yielding a more robust score with high-variance (information) channels outweigh low-variance (noise) channels."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper has reasonable motivation: the common practice of Mean R2 scores for multidimension data could be sensitive to noise and can hide performance patterns. Providing a \"dimensional view\" of accuracy can be useful for specific applications such as neuroscience."}, "weaknesses": {"value": "1. The synthetic sinusoidal dataset is a simple sine wave with added noise. A mouse neural recording dataset is quite specialized. Without additional datasets, from popular modalities like images, audio, and text, existing experiments are insufficient to demonstrate the generalizability and broad applicability of the proposed metric.\n\n2. The paper frames the problem as \"Mean R2 is limited, so here is Dim-R2.\" But It is highly unlikely that no other similar solutions for conventional (Mean) R2 have been proposed. This lack of a thorough literature review and citations on existing metrics makes the paper's contributions isolated. This can also be seen from the fact that, most of the cited references are not from the ML field; I am not sure if ICLR is the right venue for this paper.\n\n3. It will be better if there is theoretically analysis why or how to introduce the Axis, Axis_ref, and Axis_bias, as well as the relationship between them, and theoretically analysis why or how the high-variance (informative) channels outweigh low-variance (noisy) ones."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mi1nHcE11E", "forum": "iD6ZD5wE1n", "replyto": "iD6ZD5wE1n", "signatures": ["ICLR.cc/2026/Conference/Submission21663/Reviewer_rB8j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21663/Reviewer_rB8j"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761792480014, "cdate": 1761792480014, "tmdate": 1762941878269, "mdate": 1762941878269, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Dim-R$^2$, a new regression evaluation metric that extends the conventional R$^2$ score to handle data of any dimensionality. The standard R$^2$ is limited due to three reasons: restriction to 1–2D data, reduction of model performance to a single scalar, and sensitivity to low-variance noise channels. Dim-R$^2$ addresses these issues by flattening selected data dimensions and computing specified variance reference scores (via adjusting Axis_ref, Axis_bias), enabling a multidimensional view of model accuracy and reducing noise sensitivity. The authors validated Dim-R$^2$ using both synthetic sinusoidal data and an RNN trained on mouse neural recordings, showing that it effectively reveals structured prediction patterns across time, neurons, and trials. Moreover, results demonstrate that Dim-R$^2$ better highlights high-accuracy channels in noisy datasets than mean R$^2$, providing an interpretable metric for regression analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper identifies weaknesses in the conventional R² metric and motivates the need for an improved measure for regression accuracy.\n- Dim-R² is straightforward and intuitive, and generalizes to multidimensional data without deviating much from the familiar interpretation of R²."}, "weaknesses": {"value": "**The presentation could be largely improved:**\n\n- When reading some paragraphs in this paper, I often had to scroll up and down to look for figures paired with the text. For example (but not limited to these examples), equations (3-6) should be located closer to Figure 3. Figures 4 and 5 should appear on the same or adjacent page as Section 2.2.1.\n- Although the authors clarified that “Throughout this paper, the terms dimensions and axes, data and trials, and channels and neurons are used interchangeably”, frequent changes of these terms in the paper have negatively influenced the coherence of the paper reading.\n- There is no content in Section 2.2.2. I assume that this is some typo, and subsequent subsections should belong to the title of Section 2.2.2?\n\n**Some experimental details are unclear to me and need more clarification:**\n\n- For the synthetic sinusoidal dataset: If I understand correctly, $y_{true}$ and $y_{pred}$ with no added bias, differ only in the Gaussian noise added to them. What was the process of sampling the waveforms across trials? What are the parameters of the Gaussian noise distribution? How does the noise increase/decrease over time? Do the independent noises for $y_{true}$ and $y_{pred}$ follow the same Gaussian distribution? In terms of the Varying Bias case, is the bias also randomly assigned to $y_{true}$ across trials and neurons?\n- For the real-world dataset: What are the actual shapes (Random seeds, Validation folds, Test batch, Time, Channels) of the dataset used for computing Dim-R$^2$?\n- What is the Axis_bias used in the experiments in Figure 6? Since Axis_bias $\\subset$ Axis_ref, I assume that Axis_bias=Trial in Figure 6(a,b,e,f) and Axis_bias=Time in Figure 6(c,d,g,h)?\n- These experimental details should have appeared in the Appendix for reproduction purposes.\n\n**Concerning the impact/significance of this paper for the broader machine learning community,** the authors demonstrate Dim-R$^2$ on only one real dataset in the area of neural science. Although the authors argue in the Conclusion section that Dim-R$^2$ can serve as a better metric of regression accuracy in general AI areas, the citations there are mostly related to neural science. Could the authors provide more examples of how Dim-R$^2$ might exhibit an advantage over the original R$^2$ for tasks in other areas? Examples may include, but are not limited to the following: robotic imitation learning, autoencoder reconstruction loss, and the DDPM objective of diffusion models. Moreover, I do not see a related work section in the paper. Could the authors also discuss other metrics evaluating regression accuracy, in addition to R$^2$?\n\n**Minor Issues**:\n\n- Conventionally, the coefficient of determination is denoted $R^2$ (R-squared). And in Figures 1, 2, 3, 8, the authors wrote $R^2$ but $R2$ everywhere else."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wa4Tu1TDio", "forum": "iD6ZD5wE1n", "replyto": "iD6ZD5wE1n", "signatures": ["ICLR.cc/2026/Conference/Submission21663/Reviewer_yn9R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21663/Reviewer_yn9R"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816209043, "cdate": 1761816209043, "tmdate": 1762941877838, "mdate": 1762941877838, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the dimensional R2 regression metric (Dim-R2), which extends the conventional mean R2 score. In particular, it aims to address three key limitations of R2: (1) its limited scope for 2D data, (2) compression of accuracy notions into a single scalar, and (3) sensitivity to low-variance noise channels. Subsequently, the proposed Dim-R2 incorporates a multi-dimensional view of accuracy and is more robust than mean per-channel R² under low-variance noise channels. This proposal is supported by empirical evidence on synthetic sinusoidal studies and data-constrained RNNs predicting mouse Neuropixels activity."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The paper presents a relevant objective to extend the gold standard (R2 score) to have a multi-dimensional view. It identifies three limitations of conventional R2 and aims to address them with the extension. \n* The formulation is simple and straightforward, with formulas given in Equations 3-6 and accompanying visualizations."}, "weaknesses": {"value": "* **Underdeveloped Theory:** The proposed Dim-R2 metric is an intuitive extension of the R2 score from classical statistical theory, but only the formulas are presented. More theoretical analysis (bounds/equality, invariances, reduction to classical R2, etc.) would build confidence that Dim-R2 behaves predictably beyond the shown cases. I found the further theory to be both doable and necessary because the work serves to extend a fundamental statistic; however, there’s no properties section establishing basic guarantees. \n\n* **Presentation issues:** Some of the notations in Section 2 do not look mathematically professional, and the subscripts are difficult to read and confusing. I recommend dropping the “true” part and use y, \\hat{y}, \\bar{y} for ground-truth, predicted, and mean labels. Additionally, text phrases Axis, Axis_ref, and Axis_ref-Axis are used as sets, which is not professional. Please consider using rigorous set notations and clean the notations with care. \n\n* **Limited Empirical Evaluation:** The baseline comparisons are very narrow, namely the authors only compare it with the traditional R2. This significantly impacts the claimed novelty and robustness of the metric. Stronger baselines (weighted R2, correlation, mutual-information-type measures etc.) that can capture learned data variation should be considered to support the claims. Additionally, from my understanding, the Axis sets should be manually selected; this somewhat limits the practical value of this metric. If we have insights on how to define the set, we probably already know about some data structure and are aware of the noise channels. \n\n* **Revising Structure:** With the above recommended additions, I would suggest moving some visualizations that help explain Dim-R2 and experiment settings to the Appendix. Currently, these occupy too much space of the main text and do not significantly help with audiences' understanding given the text explanations. \n\nWhile I appreciate the idea of extending R2, I recommend “reject” for the lack of both theoretical guarantees and empirical depth in this paper."}, "questions": {"value": "Most questions are raised in the Weakness section. Additionally, \n\n1. Can you provide more concrete ablation studies on the Axis selection? This could help with selection heuristics. \n\n2. Are there any tangible counterexamples where Dim-R² could overstate performance (failure modes)? It is saying that this method necessarily has flaws, but it is good to know both sides of the story."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uirr8LYSGl", "forum": "iD6ZD5wE1n", "replyto": "iD6ZD5wE1n", "signatures": ["ICLR.cc/2026/Conference/Submission21663/Reviewer_dcXe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21663/Reviewer_dcXe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21663/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762757640714, "cdate": 1762757640714, "tmdate": 1762941877192, "mdate": 1762941877192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}