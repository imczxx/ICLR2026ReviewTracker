{"id": "YWlYITAhMC", "number": 16079, "cdate": 1758259555876, "mdate": 1759897263059, "content": {"title": "Towards Interpretable Visual Decoding with Attention to Brain Representations", "abstract": "Recent work has demonstrated that complex visual stimuli can be decoded from human brain activity using deep generative models, helping brain science researchers interpret how the brain represents real-world scenes. However, most current approaches leverage mapping brain signals into intermediate image or text feature spaces before guiding the generative process, masking the effect of contributions from different brain areas on the final reconstruction output. In this work, we propose \\textit{NeuroAdapter}, a visual decoding framework that directly conditions a latent diffusion model on brain representations, bypassing the need for intermediate feature spaces. Our method demonstrates competitive visual reconstruction quality on public fMRI datasets compared to prior work, while providing greater transparency into how brain signals shape the generation process. To this end, we contribute an Image–Brain BI-directional interpretability framework (\\textit{IBBI}) which investigates cross-attention mechanisms across diffusion denoising steps to reveal how different cortical areas influence the unfolding generative trajectory. Our results highlight the potential of end-to-end brain-to-image decoding and establish a path toward interpreting diffusion models through the lens of visual neuroscience.", "tldr": "The paper presents NeuroAdapter, which reconstructs images directly from brain activity and uses IBBI interpretability framework to show how brain regions influence generative trajectory.", "keywords": ["Brain Decoding", "Visual Reconstruction", "fMRI", "Stable Diffusion", "Interpretability"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1c3d00dc8b14a088ff74c682b2c8756d554985e9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper “Towards Interpretable Visual Decoding with Attention to Brain Representations” introduces NeuroAdapter, an end-to-end fMRI-to-image decoding framework that directly conditions a latent diffusion model on brain-derived tokens, bypassing intermediate image or text embedding spaces like CLIP. The approach integrates fMRI parcel-wise embeddings into Stable Diffusion via IP-Adapter–style cross-attention, allowing the model to learn mappings from cortical representations to visual stimuli. To interpret the generative process, the authors introduce the IBBI ramework, which analyzes cross-attention dynamics during denoising to reveal how specific cortical regions influence image formation. NeuroAdapter achieves nice results on NSD, NSD-Imagery, and DeepRecon datasets, and provides meaningful visualizations linking cortical regions to specific visual features. I think the work is a solid piece but lacks some comparison with recent work that could shadow his novelty."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "Quite elegant approach! The model removes the intermediate embedding bottleneck and directly links fMRI data to the diffusion process, addressing a key interpretability limitation in current brain-to-image pipelines.\n\nThe IBBI framework offers a structured and quantitative way to visualize brain–image interactions via cross-attention.\n\nNeuroAdapter matches or exceeds existing diffusion-based decoders on several high-level metrics, even without CLIP conditioning. However it's not the best-in class (author don't claim that). I don't think this is really important given the technical contribution, interpretability gains and the fact the metrics are kind of satured.\n\nThe method performs reasonably well on imagery and DeepRecon datasets, suggesting decent cross-distribution generalization.\n\nOverall, the paper is well-organized, includes ablations, clear diagrams, and code availability."}, "weaknesses": {"value": "While the paper is solid and promising, several important references and comparisons are missing or insufficiently discussed:\n1) Early encoder-based visual decoding: Nishimoto et al. (2011) pioneered similar end-to-end fMRI-to-video approaches, and this line of work should be acknowledged to contextualize the contribution, since Encoder here is used in a new fashion as a rescorer.\n\n2)Language decoding parallels: Huth and Antonello’s works on encoder-based and interpretable language decoding provide useful methodological analogies that could enrich the interpretability discussion.\n\n3)Interpretability precedents: Antonello et al. introduced early interpretability frameworks for language-to-brain decoding that align conceptually with IBBI’s aims.\n\n4) Cross-subject generalization: Ferrante et al.’s work on NSD cross-subject decoding is relevant for comparison and could be informative for assessing NeuroAdapter’s generalization strategy.\n\n5) Recent concurrent diffusion-based methods: The paper does not compare against or even mention Dynadiff (Meta, 2025), which jointly fine-tunes diffusion models with a brain module (akin to the IP-adapter here), achieving similar or superior results.\n\n6) Interpretability-focused diffusion pipelines: BrainDIVE and BrainScuba combine diffusion models and neural encoders for interpretability analysis, conceptually overlapping with interpretability findings here.\n\n7) Transformers as interpretability proxies: Kriegeskorte’s recent work on transformer-based brain encoders as interpretable models is directly relevant to the proposed analysis.\n\nI've been working in the field for years now and I perfectly understand that given the recent explosion of apporaches it's difficult to keep everything under track. Probably many other work could be cited here, but the ones I mentioned are particularly close to this work. Some of them are recent enough to be considered parallel concurrent work (for example a recently accepted paper at NeurIPS on interpretability on visual decoding with similar findings) but  I think integrating these citations and comparisons would better situate NeuroAdapter in the broader literature and clarify its novelty relative to ongoing work."}, "questions": {"value": "- The metrics used are not particularly informative given current saturation; however, the authors appropriately acknowledge this. The emphasis on qualitative and interpretability results is appreciated and well justified.\n\n- The examples are compelling, especially the attention visualizations and the demonstration of out-of-distribution (imagery) performance.\n\n- The use of the encoder as a ranker is an elegant and practical idea; expanding on its generalization capabilities or possible integration as a training-time guidance signal could strengthen the paper.\n\nThat said, I do have some questions for the authors.\n\n1) Could you elaborate on how the brain encoder–based ranking could be used during training (e.g., contrastive or self-distillation setups) rather than only at inference?\n\n2) Have you considered test-time augmentation (e.g., sampling multiple seeds or perturbations of brain tokens) to better generalize to imagery data? The input distribution shift could be a key factor here. The model is working to some extent but lacks the precision of the visual task.\n\n3) How does the interpretability of IBBI compare quantitatively to attribution methods such as SHAP or feature occlusion, maybe on yours or simpler models like Brain-Diffuser?\n\n4) Why parcel based approach instead of voxel-wise one? I'm curios I've seen both approaches working fine and would like to better understand what is in your opinion the advantage of this strategy.\n\n5) How do you expect NeuroAdapter to perform in a multi-subject joint training setting—does the architecture allow easy cross-subject fusion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Q3kP8g7gmj", "forum": "YWlYITAhMC", "replyto": "YWlYITAhMC", "signatures": ["ICLR.cc/2026/Conference/Submission16079/Reviewer_5Pr2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16079/Reviewer_5Pr2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760527328710, "cdate": 1760527328710, "tmdate": 1762926265550, "mdate": 1762926265550, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces \"NeuroAdapter,\" a framework for reconstructing visual images directly from fMRI brain activity. It bypasses the common two-stage approach of mapping brain signals to an intermediate feature space, instead conditioning a latent diffusion model directly on fMRI representations. The goal is to achieve competitive image reconstruction quality while also improving interpretability. The authors also propose an \"Image-Brain BI-directional interpretability framework\" (IBBI) that analyzes cross-attention mechanisms to visualize how different brain regions contribute to the image generation process."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes a framework that directly conditions a generative model on fMRI data, bypassing the intermediate feature mapping common in two-stage methods. A primary contribution is the IBBI interpretability framework, which is designed to analyze cross-attention weights to visualize how specific brain regions influence the image generation. The method also demonstrates competitive decoding performance, especially on semantic metrics, and shows generalization capabilities to mental imagery tasks and novel image categories."}, "weaknesses": {"value": "- The model uses a \"Parcel-wise Linear Mapping\" to transform fMRI data from each brain parcel into an embedding. This is a strong simplification. It assumes that the complex, high-dimensional neural information within an entire parcel can be sufficiently captured by a single linear projection. This could limit the amount of neural detail the model can use.\n\n- The methodology section notes that for evaluation, multiple images are generated, and a separate \"Brain Encoder\" model is used to select the best one. This complicates the claim of an \"end-to-end\" framework, as the final, high-quality output relies on a post-processing selection step that is external to the generative model itself.\n\n- The paper itself notes \"modest\" performance on low-level metrics (like pixel correlation and SSIM). It justifies this by stating it intentionally omitted a separate pathway for low-level features (which other models use) to favor interpretability. While this is a reasonable design choice, the model sacrifices high-fidelity, pixel-accurate visual reconstruction for semantic coherence and interpretability, which is a key weakness."}, "questions": {"value": "- The methodology relies on a separate \"Brain Encoder\" to select the best reconstruction from a batch of generated candidates. How dependent are the reported \"competitive\" performance metrics on this selection process? What is the average quality of a randomly selected (or \"raw\") generated image from the model, and how does this compare to the \"best\" selected image?\n\n- The model maps the complex, high-dimensional fMRI activity from an entire brain parcel to a single embedding using a simple linear projection. Is this linear mapping truly sufficient to capture the rich information in that parcel, or does it serve as a significant information bottleneck? Were more complex, non-linear mappings (e.g., small MLPs per parcel) explored, and if so, how did they affect performance and training stability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kj4pidGtzr", "forum": "YWlYITAhMC", "replyto": "YWlYITAhMC", "signatures": ["ICLR.cc/2026/Conference/Submission16079/Reviewer_hBgN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16079/Reviewer_hBgN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761720148465, "cdate": 1761720148465, "tmdate": 1762926265009, "mdate": 1762926265009, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes NeuroAdapter, an end‑to‑end brain‑to‑image decoding framework that directly conditions a latent diffusion model on parcel‑wise fMRI tokens, bypassing intermediate latent feature spaces. It introduces IBBI (Image–Brain BI‑directional Interpretability) to analyze cross‑attention across diffusion timesteps, offering a brain‑directed view (parcel contributions) and an image‑directed view (ROI attention maps). Experiments on NSD, NSD‑Imagery, and Deeprecon show competitive performance on high‑level semantic metrics relative to embedding‑aligned baselines, along with extensive ablations. Code and training details are provided for reproducibility."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- NeuroAdapter replaces U‑Net cross‑attention with an IP‑Adapter–style module and feeds only fMRI tokens. SD weights are frozen, and only the parcel‑wise linear mapper and new cross‑attention layers are trained. This separation makes the conditioning path easy to analyze and replicates the setup across datasets.\n\n- Results are reported on NSD, NSD‑Imagery, and Deeprecon, helping assess generalization beyond the main dataset. Qualitative grids and quantitative tables are provided in the main text and appendices.\n\n- The paper also analyzes cross‑attention dynamics. It reveals the contribution of attention at the pixel level throughout the generative process. It also uses parcel‑wise attention to quantify contributions at the image level. (That said, it is unclear whether these analyses yield any genuinely new insights beyond what was previously known. Please see weaknesses and questions.)\n\n- Ablations cover fMRI token dropout, condition dimension, # of high‑SNR parcels, etc.\n\n- The paper provides code, hardware/training schedules, and describes dataset preprocessing and metrics."}, "weaknesses": {"value": "- While high‑level metrics are competitive, PixCorr/SSIM are below strong baselines (e.g., Brain Diffuser, MindEye1).\n\n- The ROI attention maps (Face/Body/Scene/Word) and parcel contribution maps mostly illustrate expected effects (e.g., category ROIs attend to corresponding image regions). The paper does not yet demonstrate novel neuroscientific insights uniquely enabled by IBBI.\n\n- If the emphasis is understanding brain–feature correspondences, a conventional encoding framework (predicting brain activity from controlled features) is arguably the more direct tool. The manuscript does not fully justify why decoding is the right or necessary vehicle for the questions posed. For example, consider how “face‑selective” cortex was originally identified: via encoding analyses that directly linked face features to measured brain responses. In the present paper, the ROIs used for interpretability (Face/Body/Scene/Word) are not discovered by their decoding models; they are imported via a label‑mapping heuristic, and the ROI‑attention visualizations and ROI‑masking largely reaffirm known selectivities rather than revealing new ones. This leaves unclear what scientific insight requires the decoding step (as opposed to a targeted encoding analysis)."}, "questions": {"value": "- Beyond confirming known category selectivity, what new neuroscientific findings does IBBI enable? Can you formalize and test such hypotheses with statistics?\n\n- Given your use of a brain encoder and the standard role of encoding in neuroscience, please justify why decoding is preferable for the interpretability aims here—what questions can IBBI answer that a well‑designed encoding analysis could not?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Iv3YOV2l9I", "forum": "YWlYITAhMC", "replyto": "YWlYITAhMC", "signatures": ["ICLR.cc/2026/Conference/Submission16079/Reviewer_SDwm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16079/Reviewer_SDwm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825204049, "cdate": 1761825204049, "tmdate": 1762926264540, "mdate": 1762926264540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NeuroAdapter, an end-to-end framework for brain-to-image decoding that directly conditions a latent diffusion model on fMRI-derived parcel embeddings, bypassing intermediate image/text feature spaces. The key technical idea is to inject parcel-wise brain tokens into Stable Diffusion via an IP-Adapter–style cross-attention module while keeping the text encoder empty. To probe how brain signals guide generation, the authors propose IBBI framework, which analyzes cross-attention weights over diffusion steps from two complementary views: (i) a brain-directed view that quantifies parcel/ROI contributions over time, and (ii) an image-directed view that produces ROI attention maps highlighting where cortical regions attend in the generated image. Experiments on three datasets show that NeuroAdapter attains competitive reconstruction performance (especially on high-level semantic metrics) and provides intuitive interpretability visualizations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Contribution to interpretability is clear. Interpretability is important for both AI and neuroscience. The IBBI framework gives a principled way to link parcel-level signals to image-space attention at each diffusion step, which improves transparency of the decoding pipeline.\n\n- Interesting use of a brain encoder as a ranking tool. Using a separately trained brain encoder to score multiple decoded candidates by their predicted brain responses is a simple, effective mechanism to pick the final reconstruction.\n\n- Thorough experiments on three datasets. The paper evaluates on NSD (with multiple subjects), NSD-Imagery, and Deeprecon. The metric suite includes both low-level (e.g., PixCorr, SSIM) and high-level (e.g., AlexNet/CLIP/Inception-based) measures, with ablations on token dropout, parcel count, and condition dimension.\n\n- Comprehensive appendix. The supplementary materials provide substantial details (data processing, model choices, ablations, additional visualizations), which improve clarity and reproducibility."}, "weaknesses": {"value": "- Interpretability claims rely primarily on qualitative evidence. Although Figures highlighting ROI contributions and attention maps are compelling, the paper does not rigorously quantify interpretability (e.g., ROI-level correspondence metrics, sensitivity/perturbation scores summarized across subjects/ROIs, or agreement with independent neuroscience priors/experts). To make the interpretability claim more convincing, the authors are suggested to report a quantitative metric for benchmarking interpretability specifically.\n- With proper metrics defined for interpretability, the authors are suggested to compare NeuroAdapter’s outputs directly to those from related attention-map–producing baselines to confirm the effectivess of the proposed approach on interpretability.\n\n- Compute/efficiency and model size are unclear. Because NeuroAdapter adds an IP-Adapter–style conditioning path and uses 50 denoising steps with candidate sampling before brain-encoder ranking, it is important to clarify whether inference time and parameter count remain comparable to competing methods. Given that the main tables/figures show NeuroAdapter is competitive on high-level metrics but not leading on low-level metrics, the method could be at a disadvantage if it is substantially larger or slower. \n\n- Moreover, it is unclear when reporting results in Figure 5 or Table 1, the brain encoder ranking tool was used or not. The method is interesting but pretty stand-alone to the NeuroAdapter itself. Other methods may benefit from the design too."}, "questions": {"value": "Please see the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xvZWafvbqd", "forum": "YWlYITAhMC", "replyto": "YWlYITAhMC", "signatures": ["ICLR.cc/2026/Conference/Submission16079/Reviewer_rWiu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16079/Reviewer_rWiu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762217589031, "cdate": 1762217589031, "tmdate": 1762926264027, "mdate": 1762926264027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}