{"id": "AjgyGqMw1P", "number": 16476, "cdate": 1758264954278, "mdate": 1759897238325, "content": {"title": "FedSAGD: federated learning with stable and accelerated client gradient descent", "abstract": "Federated Learning (FL) has become a promising paradigm for distributed machine learning. However, FL often suffers from degraded generalization performance due to the inconsistency between local and global optimization objectives and client-side overfitting. In this paper, we introduce global-update stability as an analytical tool to study generalization error and derive the stability bounds of mainstream FL optimization algorithms under non-convex settings. Our analyses reveal how the number of global update steps, data heterogeneity, and update rules influence their stability. We observe that momentum-based FL acceleration methods do not improve stability.\nTo address this issue, we propose FedSAGD, a new FL algorithm that leverages the global momentum acceleration mechanism and a hybrid proximal term to enhance stability. This design ensures updates follow a globally consistent descent direction while retaining the benefits of acceleration.\nTheoretical analysis shows that FedSAGD achieves an advanced stability upper bound of $\\mathcal{O}(1-(1-\\Gamma)^T) (0 < \\Gamma < 1)$  and attains a convergence rate of $\\mathcal{O}(\\frac{1}{\\sqrt{sKT}})$ on non-i.i.d. datasets in the non-convex settings. Extensive experiments on real-world datasets demonstrate that FedSAGD significantly outperforms multiple baseline methods under standard FL settings, achieving faster convergence and state-of-the-art performance.", "tldr": "", "keywords": ["federated learning;momentum-based acceleration;stability;Nesterov accelerated gradient descent;generalization performance"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/65de5e062035569dd9ed8d7668ca2231fd586db5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper aims to address the deteriorating generalization performance of FL caused by heterogeneous local data distributions and client-side overfitting. It proposes a global-update stability framework to better analyze generalization errors in FL. Additionally, the paper develops a novel FL algorithm named FedSAGD and demonstrates that this method can achieve superior stability and generalization. Finally, extensive empirical studies are conducted to verify that FedSAGD outperforms baseline methods in terms of faster convergence and better generalization."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces and formalizes the concept of Global-Update Stability in FL, which is highly relevant for the practical setting of partial client participation."}, "weaknesses": {"value": "1. The novelty is somewhat incremental. It appears to be a straightforward extension of traditional sample-level stability analysis to the client-level setting. \n2. The form of the generalization error bound is uncommon — the effect of sample size is not clearly provided in the bound.\n3. The notation and writing in the problem setup are unconventional and need improvement — for example,  key quantities (loss function, empirical and population risks) are needed to define more clearly."}, "questions": {"value": "1. Please explain the meaning of the symbols $\\gamma$, $s$, $K$, and $T$ in the abstract, so that readers unfamiliar with FL can immediately understand them.\n2. In the *Related Work* section, I suggest splitting the discussion of \"Generalization and stability\" into two sub-sections:\n   - “Generalization in centralized learning” — introduce the traditional uniform-convergence framework, algorithm-dependent generalization (e.g., algorithmic stability, PAC-Bayes), deep-learning generalization theory, out-of-distribution/domain generalization theory, etc.\n   - “Generalization in federated learning” — discuss algorithmic stability and PAC-Bayes / information‐theoretic generalization for FL, federated domain generalization, unseen‐client participation scenarios, etc.\n\n   This clearer separation will help readers situate your contributions more precisely.\n3. The *Problem Formulation* part is somewhat non-standard. I recommend the following structure: first define the loss function (on a single sample), then define the local empirical risk (on the local dataset) based on that loss, then define the local population risk (on the local data distribution) which is used for the generalization analysis. I believe that explicitly define the local loss for a sample and the risks will improve the clarity of this paper.\n4. Regarding Assumption 3.1: In FL contexts it is common to assume that the variance of the local stochastic gradient (when sampling mini-batches from the local training set) is bounded. More precisely, the bounded local variance refers to the variance between the mini-batch‐SGD gradient and the full local empirical risk gradient (not between the SGD gradient and the true expected risk gradient w.r.t. local data distribution). \n5. Definition 3.4: What exactly does $A(\\mathcal{S}^{i},\\xi_j)$ denote? The notation is unclear—please provide a precise definition.\n6. The generalization analysis in this paper appears unconventional. I suggest decomposing Equation (2) further to introduce the empirical risk explicitly, which will help expose how the sample size influences the generalization bound.\n7. On the theoretical novelty/challenge: The concept of *Global-update stability* seems to mirror sample-level stability analysis by replacing “samples” with “clients”. Please clarify how this extension is non-trivial and what new technical difficulties you overcome.\n8. Could the authors provide an intuitive explanation for *why* the proposed hybrid proximal term improves stability more than the standard FedProx regularization? A more intuitive commentary would strengthen the presentation.\n9. I recommend presenting the generalization bound of your algorithm as a clearly stated theorem (rather than embedding it in the text). This helps readers locate and understand the key theoretical result.\n10. For the experiments:\n    - It would be beneficial to evaluate the robustness of the proposed method under feature skew (not only label skew), since real-world FL often suffers from heterogeneity in feature distributions.\n    - Please report results averaged over multiple runs (e.g., mean ± standard error or provide error bars) to show statistical reliability of improvements."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xz0W8POcko", "forum": "AjgyGqMw1P", "replyto": "AjgyGqMw1P", "signatures": ["ICLR.cc/2026/Conference/Submission16476/Reviewer_46Nf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16476/Reviewer_46Nf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760839271943, "cdate": 1760839271943, "tmdate": 1762926580984, "mdate": 1762926580984, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper stuided federated learning and proposed a new federated optimization algroithm. The authors cliamed that FL suffers from degraded generalization performance due to the inconsistency between local and global optimization objectives and client-side overfitting. They introduced global-update stability as an analytical tool to study generalization error and derive the stability bounds of mainstream FL optimization algorithms under non-convex settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The authors performed extensive analyses, covering both their method and existing baselines. The experimental section includes a wide range of simulation results demonstrating the effectiveness of the methods."}, "weaknesses": {"value": "1. This paper addresses a well-studied problem, but I did not observe a clear breakthrough over existing works. In fact, some of the results appear weaker than those of prior studies. For instance, the theoretical analysis in this paper relies on a **bounded heterogeneity assumption**, whereas existing methods such as **FedDyn** and **SCAFFOLD** do not require this restriction. Moreover, recent advances in **momentum-based optimization** [R1, R2] have established convergence guarantees **without assuming bounded data heterogeneity**. This raises concerns about the originality and strength of the theoretical contribution.\n\n\n2. The authors claim that their work addresses the stability issue under partial client participation. However, the presented analysis is not convincing. Specifically, the convergence proof is established under **uniform random client participation** and measures convergence using the **gradient norm**, while the stability analysis switches to the **parameter distance** metric without justification. For non-convex problems, existing algorithms have already demonstrated convergence under uniform random participation, so it is unclear why this particular metric is introduced or necessary.\n\nAdditionally, the result presented in **Line 1468** appears counterintuitive. It is unclear how one can meaningfully characterize the parameter property in the context of **non-convex optimization**. Furthermore, note that $\\Phi$ could be unbounded (infinite) under the definition in **Line 1002**, making the derivations there mathematically questionable and potentially invalid.\n\n[R1] Cheng, Ziheng, et al. \"Momentum benefits non-iid federated learning simply and provably.\" arXiv preprint arXiv:2306.16504 (2023).\n\n[R2] Cheng, Ziheng, and Margalit Glasgow. \"Convergence of Distributed Adaptive Optimization with Local Updates.\" arXiv preprint arXiv:2409.13155 (2024)."}, "questions": {"value": "See the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3EwbCCvZ1X", "forum": "AjgyGqMw1P", "replyto": "AjgyGqMw1P", "signatures": ["ICLR.cc/2026/Conference/Submission16476/Reviewer_BxwB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16476/Reviewer_BxwB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761625819788, "cdate": 1761625819788, "tmdate": 1762926580579, "mdate": 1762926580579, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FedSAGD, a FL algorithm that integrates global momentum and a hybrid proximal term to enhance both convergence and stability. By formalizing a new concept of global-update stability, the authors connect generalization guarantees to the sensitivity of global updates under partial participation. They provide rigorous theoretical proofs showing improved stability convergence, and validate the method through experiments on common FL benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces the novel concept of global-update stability and leverages it to design the FedSAGD algorithm, providing deep theoretical insights and improved generalization guarantees in federated learning, especially under client heterogeneity.\n\n2. This provides a principled theoretical foundation linking generalization ability to stability, distinguishing it from previous works that focused primarily on convergence or variance reduction."}, "weaknesses": {"value": "1. Sensitivity and Ablation Analysis Could Be Deeper: Although the paper examines parameter sensitivity for β, λ, and μ, it lacks detailed ablations isolating the effects of each component (momentum vs. proximal term). It’s unclear how much each part independently contributes to stability or convergence gains."}, "questions": {"value": "1. Methods like SCAFFOLD also improves global stability with the control variates, and they do not require tuning on proximal terms. Would you think such design can also be incorporated to FedSAGD for improved results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concern."}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wqmhprJ2nz", "forum": "AjgyGqMw1P", "replyto": "AjgyGqMw1P", "signatures": ["ICLR.cc/2026/Conference/Submission16476/Reviewer_yxXG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16476/Reviewer_yxXG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761853158001, "cdate": 1761853158001, "tmdate": 1762926579434, "mdate": 1762926579434, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper starts from the observation that existing momentum-based acceleration methods in FL don’t necessarily improve stability. Building on this, it proposes FedSAGD, a new optimization framework designed to make FL training more stable under partial participation and heterogeneous data. The paper proposes a novel notion called global update stability,  which measures how sensitive the global model is to variations in the participating client set. Theoretical results show the link between this stability and generalization error, and suggest that FedSAGD achieves optimal convergence rates for non-convex objectives. Empirical evaluations on several standard FL benchmarks (CIFAR-10/100, EMNIST-L, Shakespeare) show consistent improvements over popular baselines such as FedAvg, FedProx, and SCAFFOLD."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The introduction of global update stability as a metric to quantify the effect of client sampling randomness is original and potentially impactful. It provides a new way to reason about generalization in FL beyond the traditional sample-level stability.\n2. The paper is well-written, with clear definitions, lemmas. Most proofs are easy to follow."}, "weaknesses": {"value": "1. Theoretical assumptions are overly idealized.\n2. Communication and computation costs are not reported.\n\n3. Security and privacy concerns are ignored.\n4. Experimental evaluation lacks ablation and statistical rigor."}, "questions": {"value": "1. The convergence and stability analyses rely on a set of strong assumptions—smoothness, bounded gradients, limited client heterogeneity, synchronous updates, and i.i.d. client sampling. These are rarely satisfied in real-world FL systems, especially in cross-device settings. As a result, the theoretical results cover only a small fraction of realistic scenarios, and it’s not obvious how much they translate to practical improvements.\n\n2. The paper does not report communication or computation costs, even though FedSAGD adds extra components like the hybrid proximal term and global momentum updates. Without such analysis, it’s hard to judge the real efficiency gains. Is there any comparison of communication and computation overhead with baselines such as FedProx or SCAFFOLD? It would be useful to know how much extra cost the hybrid proximal term adds per round.\n\n3. There’s no empirical evidence showing that smaller global stability actually leads to better generalization. It would be helpful to see a quantitative analysis or correlation study to support this claim.\n\n4. The method requires the server to keep an exponential moving average of historical gradients.\n\n   Without secure aggregation, this can expose gradient information and potentially lead to data reconstruction risks, an issue that runs counter to FL’s privacy goals.\n\n5. How sensitive is FedSAGD to the choice of the global momentum coefficient $\\beta$ and proximal weights $(\\mu, \\lambda)$ under strongly non-IID settings?\n\n   Would performance drop significantly if the heterogeneity parameter \\alpha (in Dirichlet partitioning) were smaller?\n\n6. How does the proposed global update stability correlate with the empirical generalization gap in experiments? Was this relationship measured or analyzed quantitatively?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zepNfpf4hQ", "forum": "AjgyGqMw1P", "replyto": "AjgyGqMw1P", "signatures": ["ICLR.cc/2026/Conference/Submission16476/Reviewer_EQAa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16476/Reviewer_EQAa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921578602, "cdate": 1761921578602, "tmdate": 1762926578837, "mdate": 1762926578837, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}