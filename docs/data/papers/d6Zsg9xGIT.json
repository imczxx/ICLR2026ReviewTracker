{"id": "d6Zsg9xGIT", "number": 24297, "cdate": 1758355090075, "mdate": 1759896772201, "content": {"title": "ARM: Discovering Agentic Reasoning Modules for Generalizable Multi-Agent Systems", "abstract": "Large Language Model (LLM)-powered Multi-agent systems (MAS) have achieved state-of-the-art results on various complex reasoning tasks. Recent works have proposed techniques to automate the design of MASes, eliminating the need for manual engineering. However, these techniques perform poorly, often achieving similar or inferior performance to simple baselines. Furthermore, they require computationally expensive re-discovery of architectures for each new task domain and expensive data annotation on domains without existing labeled validation sets. A critical insight is that simple Chain of Thought (CoT) reasoning often performs competitively with these complex systems, suggesting that the fundamental reasoning unit of MASes, CoT, warrants further investigation. To this end, we present a new paradigm for automatic MAS design that pivots the focus to optimizing CoT reasoning. We introduce the Agentic Reasoning Module (ARM), an agentic generalization of CoT where each granular reasoning step is executed by a specialized reasoning module. This module is discovered through a tree search over the code space, starting from a simple CoT module and evolved using mutations informed by reflection on execution traces. The resulting ARM acts as a versatile reasoning building block which can be utilized as a direct recursive loop or as a subroutine in a learned meta-orchestrator. Our approach significantly outperforms both manually designed MASes and state-of-the-art automatic MAS design methods. Crucially, MASes built with ARM exhibit superb generalization, maintaining high performance across different foundation models and task domains without further optimization.", "tldr": "Agentic enhancement of reasoning steps within traditional yet strong reasoning methods like CoT. Our Agentic Reasoning Module initiated from CoT reasoning blocks outperforms several complex MAS systems.", "keywords": ["LLMs", "LLM Agents", "Agentic Systems", "Reasoning", "Multi-agent Systems"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/06db0b7d492af9f8af37ae2d0e99875db19061f2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper identifies a critical issue in current research: complex, automatically-designed Multi-Agent Systems often fail to outperform simple CoT baselines. The authors argue that the primary bottleneck is not the high-level agent orchestration but the quality of the fundamental, step-by-step reasoning unit. They propose the ARM, a self-contained, code-based agentic system that serves as a powerful, \"drop-in\" replacement for a single CoT step. This ARM module is not manually engineered but is automatically discovered through a reflection-guided evolutionary search that starts with a basic CoT implementation and iteratively mutates it based on performance feedback. To manage computational complexity, the framework is cleverly decoupled: an optimal step-generator module and an optimal high-level meta-policy are discovered independently. The meta-policy search uses the computationally cheap baseline CoT module as a surrogate, with the resulting policy effectively transferring to the more powerful ARM."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper's core premise—that improving the foundational reasoning step is more fruitful than designing ever-more-complex agent superstructures—is a crucial and timely contribution to the field.\n2. The empirical and theoretical justifications for this transfer add significant rigor.\n3. Comprehensive results support the work."}, "weaknesses": {"value": "1. While the method discovers a superior ARM, the paper does not provide sufficient insight into what makes the final module better. What specific agentic patterns (e.g., self-reflection loops, parallel hypothesis generation, weighted aggregation) are consistently evolved?\n2. The paper does not quantify the computational cost of the discovery process (e.g., total tokens, GPU hours, or monetary cost).\n3. The success of the reflection-guided search is contingent upon the high-level reasoning and coding capabilities of the \"Reviewer Agent\". The paper does not explore the sensitivity of the discovery process to the choice of this designer LLM."}, "questions": {"value": "1. Could you provide the final, discovered Python code for the top-performing ARM module and its corresponding Meta-Policy? Seeing the concrete implementation would offer profound insight into the \"agentic block\" that replaces the CoT step.\n2. The scaffolded objective uses a fixed window size of l=3 steps for evaluating candidate modules. How was this value chosen? Have you analyzed the sensitivity of the final discovered module's performance to this hyperparameter?\n3. The meta-policy is discovered using mCoT as a surrogate, which may bias the search toward strategies that are optimal for a simple, recursive step generator. Does this approach risk missing out on more complex strategies (e.g., those involving dynamic branching or resource allocation) that might be uniquely effective when orchestrating the more powerful m∗ module?\n4. Given ARM's success in revitalizing a fundamental reasoning primitive, have you considered its application beyond question-answering tasks? For instance, could it be adapted to enhance steps within other sequential processes like code generation, mathematical theorem proving, or long-term planning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2EpWFvuv2D", "forum": "d6Zsg9xGIT", "replyto": "d6Zsg9xGIT", "signatures": ["ICLR.cc/2026/Conference/Submission24297/Reviewer_T74Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24297/Reviewer_T74Q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760548891950, "cdate": 1760548891950, "tmdate": 1762943033696, "mdate": 1762943033696, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an agentic reasoning system comprising the low-level Agentic Reasoning Module (ARM) and the top-level Meta Policy. The ARM is discovered via evolutionary search, aiming to optimize the quality of single-step CoT reasoning. The Meta Policy learns how to orchestrate the execution flow of the ARM to solve complex, multi-step global reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The adoption of a reflection-guided evolutionary search for automatically discovering both ARM and the Meta Policy is a methodological contribution, eliminating the need for manual engineering of complex, heterogeneous MAS. Experimental results demonstrate that both ARM and the combined ARM+Meta Policy achieve better performance across diverse task domains."}, "weaknesses": {"value": "1. The proposed method might lead to complex workflows, which inherently suggests high computational overhead. While the paper fails to provide quantified data in the main text on the actual inference cost (i.e., total token consumption, API call count, or average latency) compared to efficient baselines like CoT or CoT-SC. The performance gains must be explicitly benchmarked against the running cost to justify their practicality in real-world applications.\n\n2. The paper lacks a thorough investigation into the stability of the optimization process: a) seed sensitivity: How sensitive are the final discovered modules to the initial CoT implementation and the specific sampling of the training trajectories? b) convergence analysis: A search trajectory to demonstrate the robustness and efficiency of the search algorithm is needed. Without this, the reliability of the discovered architecture remains questionable.\n\n3. Both the ARM and the Meta Policy are discovered as complex code-based workflows. Compared to manually designed MAS (like LLM-Debate or CoT-SC), which have clear, human-understandable agent roles, the interpretability of the discovered architecture is a major concern. If the complex workflow logic is opaque, it severely limits the system's applicability in domains requiring verifiable and trustworthy reasoning."}, "questions": {"value": "1. What was the total computational budget consumed for discovering both ARM and Meta Policy? \n\n2. Could the author provide some concrete examples of the Meta Policy's dynamic control flow? Under what conditions does the Meta Policy choose to initiate a branching parallel search versus conditional loops for verification?\n\n3. How does meta policy determine the termination condition? Does the discovered meta policy incorporate an explicit backtracking mechanism, and if so, how is the trigger and execution of the backtrack handled?\n\n4. The authors are encouraged to discuss more about the bad case of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7xG6r9KeJf", "forum": "d6Zsg9xGIT", "replyto": "d6Zsg9xGIT", "signatures": ["ICLR.cc/2026/Conference/Submission24297/Reviewer_5da4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24297/Reviewer_5da4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814113726, "cdate": 1761814113726, "tmdate": 1762943033497, "mdate": 1762943033497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Agentic Reasoning Module (ARM), a novel approach for designing Multi-Agent Systems (MAS). The authors observe that complex, automatically designed MAS often underperform simple baselines like Chain-of-Thought (CoT). Their core idea is to improve the fundamental reasoning unit itself, rather than designing elaborate agent orchestration. ARM replaces each step in a CoT sequence with a specialized, agentic module discovered through an evolutionary, reflection-guided tree search over code space. This process separately optimizes a step-generator module ($m^*$) and a meta-policy ($\\pi^*$). The resulting ARM-based systems are shown to be highly generalizable, achieving state-of-the-art performance across multiple reasoning benchmarks and foundation models without task-specific re-optimization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation of this paper is novel and provides new insights.\n\n2. The paper is well-organized and uses language that is easy to understand.\n\n3. The method has strong model generalization."}, "weaknesses": {"value": "1. The experimental results are questionable: The paper's results (Table 1) show that CoT and CoT-SC often outperform ADAS and AFlow. However, ADAS is supposedly designed to optimize based on common reasoning modules like CoT and CoT-SC. Even if the optimization fails to find a better solution, its performance should theoretically be at least equal to that of CoT or CoT-SC, not worse. This makes me skeptical about the experimental setup and the validity of the results.\n\n2. Lack of cost analysis: The experiments only analyze the performance of the final optimized agent.  There is no analysis of the computational cost incurred during the optimization process, nor is there an analysis of the execution cost (e.g., token usage) of the optimized agent itself.\n\n3. Lack of comparison with stronger baselines: The paper did not compare against other relevant or potentially stronger baselines, such as MaAS[1].\n\nReference\n\n[1]Zhang G, Niu L, Fang J, et al. Multi-agent Architecture Search via Agentic Supernet[C]//Forty-second International Conference on Machine Learning."}, "questions": {"value": "1. Can the authors provide the code repository, prompts, or other additional experimental details to improve reproducibility?\n\n2. Can the authors include a comparison against baselines such as MaAS[1]?\n\n3. The paper mentions $l=3$ and only states that 'it works well', but it lacks a sensitivity analysis for this hyperparameter.\n\nReference\n\n[1]Zhang G, Niu L, Fang J, et al. Multi-agent Architecture Search via Agentic Supernet[C]//Forty-second International Conference on Machine Learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "TpeHYxhPrY", "forum": "d6Zsg9xGIT", "replyto": "d6Zsg9xGIT", "signatures": ["ICLR.cc/2026/Conference/Submission24297/Reviewer_dWxr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24297/Reviewer_dWxr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887033361, "cdate": 1761887033361, "tmdate": 1762943033290, "mdate": 1762943033290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}