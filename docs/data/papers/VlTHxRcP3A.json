{"id": "VlTHxRcP3A", "number": 12011, "cdate": 1758205178049, "mdate": 1759897539498, "content": {"title": "Representational and Temporal Dynamics in Neural Decoding: Linear and Nonlinear Models for Position and Velocity Prediction", "abstract": "Understanding how neural activity encodes behavior remains a central challenge in systems neuroscience. Neural spike trains offer high temporal resolution and may contain information about specific motor features, but the extent of this information remains unclear. In this study, we evaluate how well motor features can be predicted from spike trains using two type of decoders: linear regressison and a deep neural network. Using data from mice performing a reach-to-grab task, we compare predictions of hand position and two velocity representations. To assess whether models capture meaningful patterns rather than superficial correlations, we introduce artificial temporal lags between neural and behavioral data. This disrupts genuine associations and reveals whether decoding reflects true information content. Decoding score across lags show how behavioral information is distributed in spike trains across time and how linear and nonlinear models decode such information. This approach provides a principled framework for evaluating the behavioral relevance of neural activity.", "tldr": "", "keywords": ["Behavior Decoding", "Deep Learning", "Computational Neuroscience"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e1db7566e12e52166dbb2a9ded9a56e5d2f18e4b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper compares linear and nonlinear neural decoders (LSTM, FingerFlex) for predicting \nhand position and velocity from spike trains during a reach-to-grab task in mice. The main \ncontribution is analyzing how artificial temporal lags between neural and behavioral data \naffect decoding performance across different model architectures and behavioral variables. \nThe authors find that position is more decodable than velocity, and that linear models \nperform comparably to nonlinear ones. While the temporal lag framework provides some utility, \nthe work suffers from critical limitations: severely restricted data scope (single mouse, \n3 sessions), lack of novelty over prior findings, incomplete literature coverage, inadequate \nbaseline comparisons, and insufficient experimental depth. These limitations substantially \nconstrain the paper's contribution."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. **Honest reporting of findings**: The observation that nonlinear models provide no clear \nadvantage over linear models is valuable and appropriately highlighted rather than being \nminimized.\n\n2. **Representation analysis via UMAP**: Figure 3 provides useful visualization of how \nlearned weights differ between position and velocity decoding, showing structure vs. \nfragmentation patterns.\n\n3. **Appropriate statistical practices**: Use of nested cross-validation and multiple random \nseeds demonstrates care in evaluation methodology."}, "weaknesses": {"value": "#### 1. Severely Limited Data and Generalizability\n\nThe dataset consists of **3 recording sessions from 1 mouse**, which is insufficient to \nsupport the paper's claims or constitute a significant contribution:\n\n- Single-animal studies cannot establish generalizable principles about neural encoding\n- No assessment of across-animal variability\n- No statistical significance testing across animals or brain regions  \n\n#### 2. Lack of Novelty\n\nThe core findings are not novel:\n\n- **Linear vs. nonlinear decoding**: Already extensively studied. Sauerbrei et al. (2020), \n  which the paper cites, demonstrates similar conclusions about linearity of motor cortex \n  encoding.\n- **Temporal lag analysis**: While useful, this is an experimental manipulation rather than \n  a methodological advance.\n\nThe paper essentially replicates prior findings on new data without advancing theoretical \nunderstanding or proposing novel methods.\n\n#### 3. Incomplete Literature Review\n\nCritical gaps in related work coverage:\n\n- **No engagement with modern benchmarks** in neural decoding (post-2020 work on attention \n  mechanisms, transformers, or advanced RNN variants)\n- **Superficial treatment of prior studies**: Cites Gallego et al. (2017), Russo et al. \n  (2018) on motor manifolds but doesn't deeply engage with their implications\n- **Missing recent work**: No coverage of disentangled representations, information-theoretic \n  approaches, or newer spiking neural network methods for decoding\n- **Limited baseline discussion**: Does not adequately position work relative to established \n  standards (Kalman filters, state-space models, particle filters)\n\n#### 4. Inadequate Experimental Comparisons\n\nComparisons are extremely limited:\n\n- Only 3 models tested (linear, LSTM, FingerFlex)\n- **No classical baselines**: Kalman filters, particle filters, or other standard motor \n  decoding methods\n- **Multi-region data underutilized**: Records from M1, thalamus, striatum, cerebellum but \n  provides no separate analysis per region\n- **No ablation studies**: Which neurons matter? How many are needed?\n- **No neuron/population analysis**: Feature importance, selectivity, or representational \n  role not examined\n\n\n### Minor Weaknesses\n\n**Hyperparameter selection underspecified**: \n   - How were LSTM/FingerFlex hyperparameters chosen?\n   - Early stopping criteria?\n   - What constitutes convergence?"}, "questions": {"value": "### Questions for Authors\n\n1. **Data scope**: Why only 3 sessions from 1 mouse? Can you provide analysis on 5+ animals? \n   How do results vary across animals?\n\n2. **Brain regions**: Why are M1, thalamus, striatum, and cerebellum pooled? How do decoding \n   accuracies differ per region? Which regions drive position vs. velocity decoding?\n\n3. **Baseline comparisons**: How do results compare to Kalman filters or state-space models, \n   standard baselines in motor decoding?\n\n4. **Representation metrics**: Can you quantify representation structure beyond UMAP \n   visualization (e.g., spectral properties, stability across seeds)?\n\n5. **Velocity filtering**: How sensitive are results to the 8th-order differentiation choice? \n   What if you use Savitzky-Golay or other filters?\n\n6. **Temporal receptive fields**: How do models integrate information over time? Are they \n   using history or just current activity?\n\n7. **Statistical significance**: Were there formal tests comparing models or conditions? What \n   are p-values for key claims?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZYuxcx9uUW", "forum": "VlTHxRcP3A", "replyto": "VlTHxRcP3A", "signatures": ["ICLR.cc/2026/Conference/Submission12011/Reviewer_Rz23"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12011/Reviewer_Rz23"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760990198361, "cdate": 1760990198361, "tmdate": 1762923000347, "mdate": 1762923000347, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper compares linear (regression) and non-linear (LSTM) decoding techniques for relating neural spike trains and behavioral variables."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is  cleanly written, the methods and experiments make sense and are well described and analyzed. The authors point out limitations (which I will still revisit below)."}, "weaknesses": {"value": "Overall, the depth, significance and scope of the experimental results does not meet the bar for ICLR. While the paper is overall well written and clear, it does not contribute much to the existing literature. The authors make very general statements from running established methods on very limited data. In this space, there is plenty of work and data/other methods available now that could have been considered.\n\nThe authors state some of the mentioned limitations themselves; I suggest to consider these and extend the work in this regard to improve the scientific depth of the paper. I am happy to engage in further discussions, but want to set expectations that it will be hard to convince me to increase my score with the present scope of the paper, and I find it close to impossible to bring this paper in a form that could be considered for acceptance. Instead, I would suggest that the authors thoroughly extend their study in terms of datasets and methods, and re-submit the work to a future venue. Please see my detailed comments below\n\n### Introduction\n\n- **W1.** L32-33, “it remains unclear how well these signals encode behaviorally relevant variables” — this seems like a stretch given a number of studies which are also cited later in the paper; it is unclear what the exact gap in the literature the authors want to point out. Behavior decoding is a standard method in many neuroscientific studies.\n- **W2.** L35-52 has no references more recent than 2022. In the 2023–2025 a substantial amount of new methods for decoding were introduced, including more theoretically grounded ones; these should be discussed here in the light of the literature gap the authors want to close.\n- **W3.** L53 it is unclear what “truly capturing behaviorally relevant and causally linked signals” means. How does the method presented here address this?\n\n### Method\n\n- **W4.** This is clearly written, but lacks depth. The authors run a linear regression, LSTM and FingerFlex, there is little methodological advance or connection to prior work, it is a purely empirical setup. \n\n### Conclusions\n\n- **W5** L 347–348: “Our results suggestion that rather than interpreting the underlying dynamics of spike trains, both linear and nonlinear models tend to function as projection mechanism that map neural activity onto behavioral output spaces” — this almost seems like a trivial statement — what does it entail to “interpret the underlying dynamics of spike trains”?\n\n### Minor comments\n\n- Typos in l. 152\n- Equations should be numbered\n- Typo in l. 158, missing space\n- l. 264 typo, extra dot"}, "questions": {"value": "- **Q1.** l. 142 does the cross validation consider blocks of time, or is it randomly shuffled?\n- **Q2.** Is L113 actually how the regression analysis was done, or was there regularization?\n- **Q3.** What motivates the choice of these particular models, vs. other established models for decoding? This might be related to the issue outlined above, no methods past 2022 are discussed in the literature review."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yAxOmFdIF6", "forum": "VlTHxRcP3A", "replyto": "VlTHxRcP3A", "signatures": ["ICLR.cc/2026/Conference/Submission12011/Reviewer_eMbv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12011/Reviewer_eMbv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932723640, "cdate": 1761932723640, "tmdate": 1762922999980, "mdate": 1762922999980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper uses both linear and nonlinear models training on neural activity data for position and velocity prediction. To assess whether models capture meaningful patterns rather than superficial correlations, they introduce artificial temporal lags between neural and behavioral data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The paper evaluated how temporal offsets (i.e., artificial time lags) between neural spike trains and behavioral data affect decoding performance, and compare linear and nonlinear modelsin their ability to capture behaviorally relevant patterns.\n\nThe paper investigate the representational differences between predicting hand velocity and position, demonstrating that position decoding is generally more accurate and structurally stable across model architectures and temporal conditions.\n\nThe paper visualize and analyze the internal representations learned by linear models, revealing that position-predictive models form smooth, temporally consistent manifolds, while velocity- predictive models form fragmented clusters—highlighting the representational simplicity and robustness of position decoding."}, "weaknesses": {"value": "The paper uses simple linear regression and simple models including LSTM and FingerFlex for the comparison, which is too simple and trivial. There's not too much sense for that. \n\nThe paper investigated the time lags with neural spike trains only by showing their $R^2$ score in heatmap."}, "questions": {"value": "On page 4, Figure 1 (a), can you explain why you use box plot for the $R^2$ values?\n\nOn page 4, Figure 1 (b), can you explain what the light lines and dark line in each pair mean? How can you tell the corresponding ground truth and prediction in each train? How did you do the prediction? What is given for the generation of a train?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "2RB4uzzuIX", "forum": "VlTHxRcP3A", "replyto": "VlTHxRcP3A", "signatures": ["ICLR.cc/2026/Conference/Submission12011/Reviewer_TdLe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12011/Reviewer_TdLe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974009569, "cdate": 1761974009569, "tmdate": 1762922999598, "mdate": 1762922999598, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper compares how neural spike recordings encode different movement variables (position, velocity) with different models (linear regression, LSTM, FingerFlex).  The authors introduce artificial temporal lags between behavior and neural recording to probe the causal relationship between the lag and decoding performance. They perform UMAP to compare the internal representation of position, velocity trained linear models."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The authors collected new neural and behavioral data from mice. They compared different behavioral decoding variables and model types."}, "weaknesses": {"value": "1. The paper lacks genuine insights drawn from different experimental results. The results are presented in fragmented manners and the authors did not connect those observations to make a coherent conclusion. Furthermore, many results seem to have already been shown in different papers, as the authors already cited. \n\n2. Many figures are lacking proper panel titles and axis labels. \n\n3. There is no detail about hyperparameter choice - since the dataset is small neural data, controlling for overfitting is important, but I don’t see any justification with the validation loss or hyperparameters search."}, "questions": {"value": "I do not think the paper is ready for publication. I recommend that the author work on what questions they are exactly asking, what experiments are needed and more rigorous experiments to draw a meaningful conclusion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nIrMbP0Qv4", "forum": "VlTHxRcP3A", "replyto": "VlTHxRcP3A", "signatures": ["ICLR.cc/2026/Conference/Submission12011/Reviewer_X7MY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12011/Reviewer_X7MY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999373407, "cdate": 1761999373407, "tmdate": 1762922999211, "mdate": 1762922999211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}