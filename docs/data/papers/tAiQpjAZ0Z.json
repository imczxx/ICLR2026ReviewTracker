{"id": "tAiQpjAZ0Z", "number": 15718, "cdate": 1758254273989, "mdate": 1759897286709, "content": {"title": "Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers", "abstract": "Large models based on the Transformer architecture are susceptible to extreme-token phenomena, such as attention sinks and value-state drains. These issues, which degrade model performance, quantization fidelity, and interpretability, arise from a problematic mutual reinforcement mechanism where the model learns an inefficient 'no-op' behavior by focusing attention on tokens with near-zero value states. In this paper, we propose Value-State Gated Attention (VGA), a simple dedicated and stable architectural mechanism for efficient performing of 'no-op' attention by directly breaking this cycle. VGA introduces a learnable, data-dependent gate, computed directly from the value vectors (V), to modulate the output. Through a theoretical analysis of the underlying gradients, we show that gating the value-state with a function of itself is more effective at decoupling value and attention score updates than prior methods that gate on input embeddings. This creates a direct regulatory pathway that allows the model to suppress a token's contribution based on its emergent value representation. Our experiments demonstrate that VGA significantly mitigates the formation of attention sinks and stabilizes value-state norms, leading to improved performance, robust quantization fidelity, and enhanced model interpretability.", "tldr": "", "keywords": ["Extreme-token Phenomena", "Transformers"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/649744d3642308f853cfa434c7d644fdf570edd9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a learnable gating mechanism driven by each token’s value vector to modulate its attention output, directly breaking the feedback loop behind extreme-token pathologies like attention sinks and value-state drains. This architectural fix markedly improves Transformer stability, model performance, and quantization fidelity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.VGA introduces a value-based gate that reactively regulates attention outputs, effectively breaking the feedback loop behind attention sinks—an improvement over prior input-gated methods.\n\n2.The gradient analysis clearly shows how VGA decouples attention magnitude from value norm suppression, providing a principled fix to the mutual reinforcement cycle.\n\n3.Tests on BERT, GPT-2, and OPT show VGA reduces activation outliers and improves stability without hurting perplexity, outperforming register tokens, learnable sinks, and IGA.\n\n4.VGA yields exceptional INT8 post-training quantization robustness, with negligible performance loss compared to severe degradation in baselines."}, "weaknesses": {"value": "1.Evaluations are limited to ~125M-parameter models; behavior on billion-scale LLMs remains unknown.\n\n2.VGA requires architecture modification and retraining or fine-tuning, limiting plug-and-play adoption.\n\n3.Experiments focus on language modeling only; generality across modalities or downstream tasks is unverified.\n\n4.Slightly lower raw perplexity than some baselines (e.g., register tokens), suggesting it optimizes for stability over peak task accuracy."}, "questions": {"value": "1.How does VGA scale to large-scale LLMs and long-context attention?\n\n2.Can VGA be retrofitted into pretrained models via fine-tuning, or must it be trained from scratch?\n\n3.Will value-based gating also help in non-language domains such as ViTs or multi-modal Transformers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VwgWvwFnBs", "forum": "tAiQpjAZ0Z", "replyto": "tAiQpjAZ0Z", "signatures": ["ICLR.cc/2026/Conference/Submission15718/Reviewer_A7mK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15718/Reviewer_A7mK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761631095276, "cdate": 1761631095276, "tmdate": 1762925962498, "mdate": 1762925962498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Value-State Gated Attention (VGA), an modification for Transformer models that aims to mitigate extreme-token phenomena (attention sinks, value-state drains). The authors provide an analysis of the gradient dynamics to motivate the mechanism of VGA, arguing VGA decouples high attention allocation from the destructive suppression of value norms. Experimental validation is conducted on a synthetic task and language modeling task, and quantization, show improve performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The motivation is clear and is supported by an empirical validation on a controlled synthetic task.\n- VGA shows some improvements on language modeling benchmarks, including better perplexity as well as quantization results."}, "weaknesses": {"value": "- Reported results lack standard deviations or error bars, making it difficult to assess the reliability and statistical significance of the improvements.\n- The paper claims VGA is a general enhancement applicable to any Transformer-based model, but it lacks evaluations beyond language tasks, such as in vision Transformers (e.g., ViT), which would strengthen the generalizability argument.\n- An experiment illustrating the disadvantages of IGA over VGA would be valuable. For example, could you extend the results in Figures 4 and 5 to include IGA, showing how it fails to fully mitigate attention sinks or value drains in the same settings?\n- Please provide more details on the creation of Figure 5. Explain the annotations (e.g., dots, dashed lines) and why specific training steps like 0.2k and 1k are marked?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z2kvzElKMW", "forum": "tAiQpjAZ0Z", "replyto": "tAiQpjAZ0Z", "signatures": ["ICLR.cc/2026/Conference/Submission15718/Reviewer_oSS8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15718/Reviewer_oSS8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820392904, "cdate": 1761820392904, "tmdate": 1762925962007, "mdate": 1762925962007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address extreme-token pathologies of transformers, including attention sinks and vanishing value-state vectors. By first attributing these phenomena to the mutual reinforcement loop in a typical softmax attention layer, the authors draw upon control theory to break this loop by proposing the Value-State Gate Attention (VGA) mechanism. In a nutshell, VGA adds a simple gating mechanism that is computed based on the value vectors V to regulate the gradient flow to them. The authors identify that such a mechanism enables a self-regulatory term that dynamically and adaptively adjusts the gradient path, effectively avoiding value drain. Experiments on a synthetic Bigram-Backcopy task and on BERT, OPT-125M, and GPT-2 (124M) show the effectiveness of the proposed mechanism."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is well-motivated and addresses the mutual reinforcement loop in a novel, mechanistic way. \n2. The method is very simple, and can be incorporated into existing practices with minimal overhead.\n3. The paper is also well-written and clear in presentation.\n4. Experiments show consistent gains by this simple fix. A nice bonus is the promising results on low-precision settings."}, "weaknesses": {"value": "1. This is a nitpick. While the experiments show promising results, it is a bit limiting in terms of scales as the experiments only considered sizes of ~100M. This is vastly smaller than modern models of billion-scale parameters. It is therefore a question of whether the same gains can be achieved on larger-scale models. \n2. The experiments mainly focus on language modeling. I think assessing the effectiveness of the proposed method on more diverse task domains such as vision will greatly improve the work.\n3. Forgetting gate mechanisms are widely used now and there have been many design choices: per-channel gates, temperature in sigmoid, normalized value states. The current design is simplistic, but could benefit greatly from ablating these different design choices to further enhance the performance of the method."}, "questions": {"value": "Please see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dG7tqjBJ6D", "forum": "tAiQpjAZ0Z", "replyto": "tAiQpjAZ0Z", "signatures": ["ICLR.cc/2026/Conference/Submission15718/Reviewer_PFsj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15718/Reviewer_PFsj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969362474, "cdate": 1761969362474, "tmdate": 1762925961611, "mdate": 1762925961611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Value-State Gated Attention (VGA), a lightweight and simple architectural add-on for Transformers that combats “extreme-token” pathologies - attention sinks and value-state drains. The key idea is a reactive, negative-feedback gate computed from the value vector $V_j$ itself, which multiplicatively modulates a token’s contribution at the attention head output. A gradient analysis argues this decouples pressure on value norms from attention-score updates, breaking the mutual-reinforcement loop that drives sinks/drains. Empirically, VGA reduces sink formation on a synthetic task and improves activation stability, perplexity, and post-training quantization (PTQ) robustness on BERT/OPT/GPT-2, with negligible overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The method is simple and clear. Turning the gate into a function of the value state (not the input) is a crisp design that directly targets the failure mode; the negative-feedback interpretation is compelling.\n\n- The gradient pathway analysis makes the stabilization story plausible and distinguishes VGA from input-gated variants.\n\n- Minimal code/param/compute overhead; orthogonal to attention-score computation; drop-in for many Transformer flavors.\n\n- Presented experiments contain synthetic validation, standard LM backbones, and a relevant application, where extreme activations are especially harmful. Results consistently show fewer sinks, stabler value norms, and quantization gains."}, "weaknesses": {"value": "- My main concern is that empirics are limited to a small set of baselines. Stronger comparisons against other sink-mitigation families (register tokens, softmax alternatives/clipping, predictive gates, state interventions) would better position VGA.\n\n- No evidence at very large scales or on long-context regimes where sinks/drains become acute. It’s unclear how VGA interacts with KV caching, RoPE/positional schemes, and very deep stacks.\n\n- There should be a formal metrics for the determination of “extreme tokens.” While qualitative/aggregate indicators are shown (norm stabilization, performance), clearer, standardized sink/drain metrics (incidence rates, attention concentration statistics, gradient norms) would strengthen claims."}, "questions": {"value": "- Is $g_j$ is a scalar (as Eq. 6 suggests)? Any results with vector (per-dimension) gates or applying the gate before vs. after the output projection $W_O$?\n\n- Are gates shared across heads or learned independently? Any empirical difference?\n\n- Any preliminary results on vision or multi-modal Transformers where sink-like effects also appear?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pnW45dzGos", "forum": "tAiQpjAZ0Z", "replyto": "tAiQpjAZ0Z", "signatures": ["ICLR.cc/2026/Conference/Submission15718/Reviewer_XV3o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15718/Reviewer_XV3o"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762036034596, "cdate": 1762036034596, "tmdate": 1762925961280, "mdate": 1762925961280, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}