{"id": "t1RNseMrGj", "number": 10689, "cdate": 1758179611974, "mdate": 1763532878852, "content": {"title": "Grouped Dirichlet Diffusion for Structured Generative Modeling", "abstract": "We present Grouped Dirichlet Diffusion (GDD), a novel generative model that employs the Grouped Dirichlet distribution to facilitate hierarchical and structured diffusion processes for high-dimensional bounded probability vectors, such as multichannel images. Unlike conventional diffusion methods that rely on Gaussian noise, GDD partitions data into meaningful feature groups (e.g., color channels in images) to preserve intra-group dependencies while allowing adaptive inter-group interactions over diffusion timesteps. Our theoretical framework ensures that both the forward marginals and reverse conditionals remain within the Grouped Dirichlet family, enabling closed-form transitions through multiplicative noise scheduling. This approach not only simplifies training dynamics but also guarantees numerical stability during sampling. Additionally, we replace the traditional evidence lower bound (ELBO) with a loss function based on the Kullback-Leibler divergence. Experimental evaluations validate the feasibility of GDD, with quantitative metrics demonstrating superior image generation performance compared to traditional diffusion models and several contemporary image generation methods.", "tldr": "", "keywords": ["Grouped Dirichlet Diffusion; Probability Simplex; Hierarchical Structured Generative Modeling"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1e719b844ef0c5c18a1a4e448f7830ad7412a775.pdf", "supplementary_material": "/attachment/0a891533ef2241d0db7b5afa53d50af12ace3985.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Grouped Dirichlet Diffusion (GDD), a generative model that employs the Grouped Dirichlet distribution as the foundation for its diffusion process. Unlike conventional diffusion methods that rely on Gaussian noise, GDD partitions data into feature groups (such as color channels in images) to capture inherent group dependencies and hierarchical structures in high-dimensional bounded data. This structured formulation improves modeling flexibility and numerical stability. This is achieved by ensuring the diffusion process operates strictly within the simplex constraints of the Dirichlet distribution. The main contributions include the introduction of GDD for diffusion modeling, improved flexibility in capturing multi-channel group patterns, and the development of a novel loss function based on KL divergence upper bounds (KLUBs)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Achieves a very good FID score on CIFAR-10.\n- Runs faster than traditional DDPMs, offering clear efficiency improvements."}, "weaknesses": {"value": "- Overall, the paper is hard to follow and lacks clarity (see questions below).\n- **Citations:** Extremely sloppy.\n    - Missing parentheses for indirect citations.\n    - Missing years for several citations (e.g., lines 49, 123).\n    - Redundant author mentions (e.g., lines 119, 124).\n    - **Table 1:** Some models are cited, others are not. Even if cited earlier, include all model references in the table for consistency. Also, consider left-aligning the “Model” column.\n- **Writing quality:** Inconsistent formatting and missing spaces between figure references and citations (e.g., lines 63, 74, 240, 275, 458, ...).\n- **Structure and readability:**\n    - The model figure introduces components (e.g., the mapping stage) that are never discussed in the main text, only in the appendix.\n    - Some variables and hyperparameters appear without prior definition.\n        - New indices are introduced without explanation (e.g., ($x_{g0}$, $x_{g0i}$) — what does the “0” represent?).\n        - ($S_{\\text{scale}}$) and ($S_{\\text{shift}}$) appear in Eq. 6 but are never described — are these hyperparameters?\n    - Suggestion: Introduce the concentration parameter later, when it first appears in Eq. 7.\n- **Results:** Insufficient experimental evidence to fully support the authors’ claims.\n    - Experiments only use color channels as groups; additional experiments with other grouping structures would strengthen the generality claim.\n    - Missing quantitative results on datasets other than CIFAR-10, despite apparent training on others (see Fig. 8).\n    - Line 349–350: Consider moving external links to a footnote.\n- **Table 1 issues:**\n    - **LSGM:** Best FID (2.10) not listed.\n    - **Consistency Models:** Only FID for consistency training (CT) shown, not the better consistency distillation CD, which is 2.93.\n    - **DDIM and GET:** Unclear where the reported results come from — not found in the original papers."}, "questions": {"value": "## \n\n- **General:**\n    \n    What specifically makes the process **hierarchical** (beyond Markov/sequential as in normal diffusion)? Across the paper you frequently mention “hierarchical,” e.g., line 142: *“hierarchical structure of grouped probability vectors.”* Are “grouped probability vectors” just images? If so, what is hierarchical about dividing it into color channels?\n    \n- **Lines 55–57 (claim on prior methods):**\n    \n    *“traditional diffusion methods based on Gaussian Ho et al., 2020; Guo et al., 2023 or Beta Zhou et al., 2023 struggle to capture group dependencies and hierarchical structures …”*\n    \n    Can you provide evidence for this claim (e.g., an experiment or citation)?\n    \n- **Lines 104–105 (masking):**\n    \n    *“… simultaneously adds noise to **and masks the data** …”*\n    \n    Where does masking occur? I couldn’t find a description or equation for it.\n    \n- **Notation (x_g):**\n    \n    You define $g$ as the group, so $x_g$ should be the **group vector**, not the group itself. (e.g., lines 152, 184).\n    \n- **Lines 172–174 (constraints & dependencies):**\n    \n    *“Standard Gaussian Ho et al. (2020)* *or scalar-Beta diffusion Zhou et al. (2023)* *models* *violate simplex non-negativity, unit-sum constraints, and overlook group dependencies.”*\n    \n    Briefly explain why these violations occur and why the first two constraints matter here.\n    \n- **Line 191 (conditioning direction):**\n    \n    You write the conditional $q(z_s∣z_t,x_0)$ with $s < t$. How does this fit the **forward** process (since $s$ is closer to $0$ than $t$)? Are you using future data $z_t$ to noise $z_s$?\n\n- **Lines 211–213:**\n    \n    This statement would benefit from a supporting citation or other evidence.\n    \n- **Line 225 (bidirectional transitions):**\n    \n    When introducing bidirectional transitions, clarify their purpose and how they are used.\n    \n- **Line 255 (replacement step):**\n    \n    *“… then replaces $x_{g0}$ with its approximation $\\hat{\\alpha}_g$.”*\n    \n    Since we aim to estimate $x$ anyway, is this an intermediate approximation with *$\\hat{\\alpha}_g$*? Why is this intermediate approximation beneficial to the final estimation of $x$?\n    \n- **Figure 4 (DDIM vs. DDPM):**\n    \n    DDIM results appear sharper than DDPM, yet DDIM typically trades sample quality for speed. How do you explain this (e.g., different model capacity or settings)?\n    \n- **Equation 2 (indices):**\n    \n    Indices look odd (e.g., $x_{g0i}$). Please define and justify the 0 index.\n    \n- **Difference from Dirichlet diffusion:**\n    \n    Can you elaborate on the difference betwee the Grouped Dirichlet diffusion and Dirichlet diffusion [1], especially in terms on novelty? \n    \n\n[1] Avdeyev, Pavel, et al. \"Dirichlet diffusion score model for biological sequence generation.\" *International Conference on Machine Learning*. PMLR, 2023."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UxNmYgGJRU", "forum": "t1RNseMrGj", "replyto": "t1RNseMrGj", "signatures": ["ICLR.cc/2026/Conference/Submission10689/Reviewer_2RpY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10689/Reviewer_2RpY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10689/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761324779639, "cdate": 1761324779639, "tmdate": 1762921933415, "mdate": 1762921933415, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Grouped Dirichlet Diffusion (GDD), a novel diffusion-based generative model that replaces Gaussian noise with multiplicative Dirichlet noise applied to feature groups (e.g., RGB channels). Each group remains on a probability simplex, ensuring non-negativity and unit-sum constraints throughout the diffusion process. The model preserves intra-group dependencies while allowing adaptive inter-group interactions, offering both theoretical closure (forward and reverse distributions remain Dirichlet) and practical stability via KL Upper Bound (KLUB) loss instead of the ELBO."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. GDD introduces a strong structural prior by explicitly modeling data as grouped probability vectors on a simplex. This design allows the model to naturally capture correlations within each feature group while maintaining valid probabilistic constraints throughout the diffusion process.\n\n2. The method ensures theoretical consistency through closed-form forward and reverse Dirichlet transitions. Its KL Upper Bound (KLUB) loss provides smooth optimization and avoids unstable boundary behavior, resulting in stable and efficient training.\n\n3. In experiments, GDD achieves superior FID/KID scores on benchmark image datasets and faster sampling speeds than comparable diffusion frameworks, demonstrating that the grouped Dirichlet design improves both generation quality and computational efficiency."}, "weaknesses": {"value": "1. “Meaningful groups” are claimed but only RGB channel grouping is demonstrated. The paper frames GDD as partitioning data into meaningful feature groups—explicitly citing image color channels as the running example—so as to preserve intra‑group dependencies while allowing adaptive inter‑group interactions. In practice, however, all implementations and evaluations instantiate grouping via fixed RGB channels in image space; the method section even notes that image channels are grouped as a prior modeling assumption to greatly simplify the mathematics and ensure closed‑form marginals. No experiments demonstrate learned group discovery or alternative semantics beyond color channels across domains. Consequently, the central claim about “meaningful groups” remains under‑validated empirically.\n\n2. No strategy for latent‑space grouping; evidence is limited to image‑space generation. GDD is formalized on grouped probability vectors derived from the observed data (after scaling/shifting), with the entire diffusion defined on the data/pixel space rather than a learned latent manifold. While the architecture includes an encoder–decoder U‑Net, the paper does not propose an algorithm to design or learn group partitions in latent space, nor does it report latent‑space generation results. As a result, portability to latent‑diffusion setups and non‑image domains is currently an open question rather than a demonstrated capability, narrowing the immediate applicability and generalization of the approach"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "92mXWnG9I8", "forum": "t1RNseMrGj", "replyto": "t1RNseMrGj", "signatures": ["ICLR.cc/2026/Conference/Submission10689/Reviewer_JJfZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10689/Reviewer_JJfZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10689/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974477489, "cdate": 1761974477489, "tmdate": 1762921933089, "mdate": 1762921933089, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Grouped Dirichlet Diffusion (GDD), a generative model for high-dimensional bounded probability vectors, such as images. The framework extends Beta Diffusion by using the Grouped Dirichlet distribution, which allows the model to partition data into feature groups (e.g., RGB channels) and preserve intra-group dependencies. Unlike traditional Gaussian-based diffusion, GDD features multiplicative noise. The method ensures closed-form transitions in theory, and replaces the standard ELBO with a KL divergence-based loss (KLUB) for optimization. Experiments on image datasets show that GDD achieves SOTA performance on FID and KID metrics compared to several baselines, including DDPM and Beta Diffusion."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The core idea is principled and elegant. Using the Grouped Dirichlet distribution to model dependencies between feature groups (like RGB channels) is a natural extension of Beta Diffusion and is more suitable for this data structure than independent Gaussian noise.\n2. The experimental results are strong. Table 1 shows that GDD achieves state-of-the-art FID (2.76) and KID (1.22) on CIFAR-10, outperforming the most relevant baseline, Beta Diffusion (FID 3.06).\n3. The framework appears computationally efficient. Table 3 shows GDD has a faster average processing time per batch and generates more images per second than both DDPM and Beta Diffusion, which is a significant practical advantage."}, "weaknesses": {"value": "1. The loss function (Eq. 19) is a heuristic KL Upper Bound (KLUB). It relies on an arbitrary-looking weighting factor ($\\omega=0.97$) to combine two different bounds. The paper provides no theoretical justification for this specific value, making the final training objective feel ad-hoc and not really that principled.\n2. The paper's central claim is about modeling \"hierarchical and structured\" data using \"meaningful feature groups.\" However, all experiments are on image datasets only, where the \"group\" is simply the three RGB channels. This is the simplest, most obvious grouping possible and does not sufficiently validate the model's ability to handle more complex group structures (*e.g.,* hierarchical features in tabular data or other modalities).\n3. The ablation study in Table 2 is weak. It only shows that a 4-layer MLP mapping network is better than a 1- or 2-layer one, and that removing it entirely breaks the model. This is not insightful and does not provide any analysis on the grouping strategy itself, which is the paper's main contribution."}, "questions": {"value": "1. The KLUB loss in Eq. 19 uses a weight $\\omega=0.97$. How sensitive is the model's performance to this hyperparameter? Is there a more principled way for choosing this value, or was it found empirically?\n2. The core contribution is \"grouping.\" How does the model perform if the group structure is mis-specified (*e.g.,* grouping pixels spatially instead of by channel)? The paper needs to demonstrate that the model is truly leveraging the group structure, rather than just performing well on CIFAR-10.\n3. Table 3 shows GDD is faster than Beta Diffusion, even though it is handling higher-dimensional (grouped) Dirichlet distributions instead of 1D Beta distributions. What is the source of this efficiency gain?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UYn5nYQjx6", "forum": "t1RNseMrGj", "replyto": "t1RNseMrGj", "signatures": ["ICLR.cc/2026/Conference/Submission10689/Reviewer_fN7s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10689/Reviewer_fN7s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10689/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987804213, "cdate": 1761987804213, "tmdate": 1762921932779, "mdate": 1762921932779, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Grouped Dirichlet Diffusion (GDD), a Dirichlet analogue of Beta Diffusion applied group-wise on the simplex, trained with a KL upper bound (KLUB). While the construction is mathematically clean, the empirical claims are not supported under matched settings, and key baselines are missing."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper presents an interesting generative modeling idea where leveraging constraints in certain data types should theoretically be advantageous. The paper could benefit from a more compelling use case (for example, applying it to data that is truly compositional and showing an advantage compared to other methods in that type of data)!"}, "weaknesses": {"value": "Major concerns\n\n1) “Faster convergence / better performance” not supported under matched settings.\nTo claim faster/better, the paper must train competing methods under identical recipes (same U-Net capacity, augmentation, schedule, optimizer, data budget, NFE grid) and report compute-normalized metrics. As written, no such matched study is presented.\n\n\n2) Missing strong baselines and modern solvers.\nDDPM++ 2.78\nDDPM++ cont. (VP) 2.55\nDDPM++ cont. (sub-VP) 2.61\nDDPM++ cont. (deep, VP) 2.41\nDDPM++ cont. (deep, sub-VP) 2.41\nNCSN++ 2.45\nNCSN++ cont. (VE) 2.38\nNCSN++ cont. (deep, VE) 2.20\n\nalready meet or beat GDD’s reported numbers in most configurations. More recent Karras-style v-parameterization with fast ODE solvers reports ≈1.8–2.0 FID at ≈35 NFEs, whereas GDD uses much higher NFE and attains worse FIDs. Thus the “faster/better” claim is not supported.\n\n3) DDIM / Consistency numbers unclear.\nThe DDIM FID around ~15 appears inconsistent with commonly reported values (e.g., ~13.6 at ~10 NFEs). Please provide exact citations, configs (conditional vs. unconditional), sample counts, and NFE for every table entry. For Consistency Models, ECT reaches ≈2.15 FID on CIFAR-10 with 2 function evaluations—two orders of magnitude fewer than GDD—so comparisons should be cost-normalized.\n\n4) Fairness and capacity parity.\nThe original DDPM U-Net (~35M params; limited attention) is dated. Modern backbones are ~50–60M and materially improve FID. Given your models are ~55M params, comparisons to older, smaller baselines without re-training are inconclusive.\n\n5) Evaluation diagnostics aren’t actionable.\nPeak memory utilization / similar stats are presented without a clear framing (what was expected, why differences arise, and how they tie to the method’s design). As is, it’s hard to draw conclusions.\n\n6) Visuals / preprocessing (minor thing).\nAFHQ samples appear muted/gray relative to modern baselines; this likely reflects range/logit/renormalization or plotting. Please clarify preprocessing and the exact visualization pipeline.\n\n7) Serious concern: baseline omission undermines claims. The paper acknowledges Karras et al. in Related Work but excludes it from experiments. This selective reporting makes the efficiency/quality conclusions non-actionable and, as presented, misleading. At minimum, include Karras-style v-param + modern solvers at matched NFE and parameter count. Similarly, for Consistency Models, please justify omissions of modern pipelines (e.g., ECT) or include them.\n\n\nMethodological positioning (incremental over Beta Diffusion)\n\nGDD is a near-mechanical lift of Beta Diffusion from Beta to Dirichlet noise, with in-family marginals and time-separable conditionals per group. A compact Gamma→Dirichlet derivation makes this immediate.\n\nBeta Case:\n\n$$ A \\sim \\Gamma(a, 1) $$\n$$ B \\sim \\Gamma(b, 1) $$\n$$ C \\sim \\Gamma(c, 1) $$\n$$ T \\equiv A + B + C $$\n\nNow, let \n\n$$z_{t} = \\frac{A}{T} \\sim \\beta(a, b + c) $$ \n$$ z_s = \\frac{A+B}{T} \\sim \\beta(a + b, c) $$\n\nand define \n\n$$ \\pi = \\frac{A}{ A + B } \\sim \\beta(a, b) $$\n$$ p = \\frac{B}{B + C} \\sim \\beta(b, c) $$ \nThen, it is clear that \n\n$$ z_{t} = z_{s} \\pi $$\n\n$$ z_{s} = z_{t} + (1-z_{t}) p$$  \n\nThese equations are precisely those that we see in the Beta Diffusion paper. \n\nGeneralization to the dirichlet distribution is almost immediate from this point of view \n\n$$ A_{i} \\sim \\Gamma(a_{i}, 1) $$ \n$$ B_{i} \\sim \\Gamma(b_{i}, 1) $$\n\n$$ z_{g, t} := \\text{Dir}( \\frac{A}{\\sum_{j} A_{j} } )$$\n\n$$ z_{g, s} := \\text{Dir}( \\frac{A+ B}{\\sum_{j} A_{j} + B_{j} } )$$\n\nBecause Dirichlet = normalized Gammas, the marginals are Dirichlet, which, with the appropriate choice of $A$ and $B$ recovers the equations from the paper exactly\n\n$$ a \\equiv \\eta \\alpha_{t} x_{g,0} $$ \n$$ b \\equiv \\eta (\\alpha_{s} - \\alpha_{t}) x_{g,0} $$\n\nNow, if we set \n\n$$ R_{i} : = \\frac{A_{i} }{B_{i} + A_{i} }$$ \n$$ U_{i} := A_{i} + B_{i} $$ \n\nand recall that $R_{i} \\perp U_{i}$ then we see that \n\n$$ z_{g,s} = \\frac{U}{\\sum_{i} U_{i} }$$\n\n$$ z_{g,t} = \\frac{U \\odot R}{\\langle U , R \\rangle } $$ \n\nNow, it is clear that the forward update (which falls naturally) is \n\n$$ R_{i} \\sim \\beta(a_{i}, b_{i}) $$ \n$$ z_{g,t} = \\text{Normalize}(z_{g,s} \\odot R) $$ \n\nThis yields the forward multiply-then-renormalize update; the reverse follows by adding Gamma increments then renormalizing, which also justifies the post–Euler–Maruyama renormalization step. The construction is clean but incremental relative to Beta Diffusion.\n\nIn its current form, I recommend rejection. The construction is sound but incremental; empirical claims require matched baselines and cost-normalized evidence."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Lpvvbg8380", "forum": "t1RNseMrGj", "replyto": "t1RNseMrGj", "signatures": ["ICLR.cc/2026/Conference/Submission10689/Reviewer_5TU9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10689/Reviewer_5TU9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10689/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762223727095, "cdate": 1762223727095, "tmdate": 1762921932455, "mdate": 1762921932455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}