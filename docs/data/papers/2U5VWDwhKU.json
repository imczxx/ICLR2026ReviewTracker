{"id": "2U5VWDwhKU", "number": 7853, "cdate": 1758039086168, "mdate": 1759897827192, "content": {"title": "Discovering Deep Chain-of-Thought Paths Across Broader QA: A General CoT-Decoding Framework for LLMs", "abstract": "Chain-of-Thought (CoT) prompting can enhance large language models’ (LLMs) reasoning capabilities, but it is influenced by the designer’s biases and requires designing different prompts for different tasks. Recently proposed CoT-decoding can guide the model to generate chain-of-thought-style decoding paths without prompts, but it is applicable only to questions whose answer sets or output formats are fixed. Therefore, in this paper we propose GCoT-decoding, a general decoding strategy applicable to broader QA tasks. GCoT-decoding first extends the original model output to generate a final answer—replacing the original specific answer span—and then aggregates paths of the same category based on the semantic similarity of those final answers to improve stability. We further propose an optimized two-stage branching method for generating candidate decoding paths, correcting potential error paths while ensuring result diversity. We conduct extensive experiments across diverse question‑answering tasks, obtaining competitive results that demonstrate the generality of our method. We also analyze how to choose the number of paths to balance performance and efficiency, providing effective guidance for practical applications.", "tldr": "A two-stage branching decoding strategy for Large Language Models to deliver robust performance across broader QA tasks.", "keywords": ["Chain-of-Thought", "Decoding Strategy", "Large Language Models", "Two-Stage Branching"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d6ac9572e6cda20849cc7fb3af6092a6046153a5.pdf", "supplementary_material": "/attachment/66d1f463e99a5444cee151969731db199bbceb9c.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces GCoT decoding - a general strategy for decoding by making use of many sampled paths. The method introduces three steps on top of typical decoding, including branching many path (with a fibonacci sampling strategy for diversity), backtracking from local minima (reversing whenever tokens show lower confidence), computing confidence in a length-aware manner, and finally greedy semantic clustering for path aggregation. Compared to standard sampling (greedy, nucleus, beam search) and basic prompting (CoT, self-consistency), it shows some QA improvements for models around the 8B scale."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper studies the import foundatioanl problem of how to best elicit answers to questions from LLMs]\n- The paper is generally well written and easy to follow\n- The analysis of how CoT decoding can miss correct answers (Sec 2.2, Table 2) is interesting\n- The experiments show some improvements over diverse models and settings, in addition to an ablation table"}, "weaknesses": {"value": "- One overall weakness of the paper is that it proposes several different pieces, but doesn't go into depth on each of them making it unclear which of them are important\n  - The fibonacci sampling (3.1) seems useful but somewhat arbitrary compared to more standard solutions such as sampling uniformly within a top-p\n  - Similarly, backtracking from local minima (3.1) is interesting and potentially very useful if it works reliably\n  - Greedy semantic clustering for path aggregation (3.3) similarly seems interesting, but it would be nice to see it compared against simple alternatives, e.g. having an LLM aggregate the paths through prompting\n  - Though the authors show a shallow ablation of some pieces of the method in Table 5, it would be nice to see comparisons to baseline methods for each of these steps, e.g. baselines for path aggregation or alternatives to backtracking. The main comparisons too seem to be missing comparisons to baseline methods for prompt ensembling when computing answers, as many variations have been proposed as early as tree of thought and modern variations of self consistency.\n- A second major weakness is in the evaluation setup for the models\n  - Once concern is about the prompting setup used for these models. Performance for benchmarks like SQuAD is oddly low for these models (e.g. see Figure 3; LLaMA-3.1 8B gets <20% Match score with CoT). This seems like there may be an issue with the baseline method the authors use to query the models.\n  - Similarly, in querying the model to output an answer (e.g. in Sec 2.1), the authors append \"So the answer is: \" at the end of the prompt, although a more standard prompt might begin by asking the model to output answer in a particular format (e.g. in JSON or using <think> / <answer> tags.\n  - It would be nice also to see results for some reasoning models, where querying for an answer is more straightforward"}, "questions": {"value": "I am confused exactly what +SpanAlign refers to in the tables / figures.\n\nMinor: typo in Figure 1: \"Cot-deocding\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "coMvlQbmzV", "forum": "2U5VWDwhKU", "replyto": "2U5VWDwhKU", "signatures": ["ICLR.cc/2026/Conference/Submission7853/Reviewer_6WEQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7853/Reviewer_6WEQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7853/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761219677110, "cdate": 1761219677110, "tmdate": 1762919894115, "mdate": 1762919894115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GCoT-decoding, a general Chain-of-Thought decoding strategy for LLMs that works on both fixed and open-ended QA tasks. Experiments on six datasets show improved performance and broader applicability over standard CoT-decoding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Overall, the paper is reasonably well-written and includes a sufficient number of ablation studies supporting the proposed approach.\n\n- The investigated scenario is interesting and practically relevant.\n\n- Proposes a general decoding framework that enhances reasoning diversity."}, "weaknesses": {"value": "- More details on the computational cost of the proposed approach would be appreciated. \n\n- [Minor] There is a typo in Figure 1: the label “deocding” appears incorrectly for both the orange and green labels.\n\n- The multi-path exploration process increases decoding time and may limit scalability on large datasets. The paper should better justify or quantify the trade-off between improved reasoning performance and the associated computational cost."}, "questions": {"value": "- It is unclear how using the template “so the answer is” directly guides the model toward the desired outcome. Have the authors considered alternative prompting strategies to better investigate this effect?\n\n- Please address the ponts in the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed.", "Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "10a7Px4amg", "forum": "2U5VWDwhKU", "replyto": "2U5VWDwhKU", "signatures": ["ICLR.cc/2026/Conference/Submission7853/Reviewer_98Jy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7853/Reviewer_98Jy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7853/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761560195197, "cdate": 1761560195197, "tmdate": 1762919893399, "mdate": 1762919893399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GCoT-Decoding, it is a general chain-of-thought decoding framework designed to uncover deeper correct reasoning paths without relying on predefined output formats. GCoT uses a two-stage branching strategy: (i) Fibonacci sampling to pick diverse early tokens as path seeds, and (ii) backtracking at the first local confidence minimum to spawn corrective branches. Each path is then scored by a top-2 token prob logit gap, length-aware. The final answer is aggregated via \"greedy semantic clustering\", which accumulates evidence within paraphrase-equivalent answer clusters and selects the representative. Experiments on fixed-answer (GSM8K, MultiArith, BBH-Sports) and free-form (SQuAD, BARQA, Auto-Categorization) QA show GCoT is competitive with standard multi-path decoders on fixed tasks and  improves BLEU/MATCH on free-form tasks; it also composes well with few-shot CoT prompting. Ablations confirm that all three components—branching & backtracking, length×top-2 scoring, and semantic aggregation—are jointly necessary."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) Exploring decoding strategies beyond greedy decoding to cover greater hypothesis diversity makes sense, since the correct reasoning path is often not prominent early in decoding.\n\n(2) The evaluation is carefully executed, with a systematic comparison of multiple decoding strategies."}, "weaknesses": {"value": "(1) In the introductory sections, it may be easier to follow if more concrete examples can be added to make the concepts crisper and easier to follow.\n\n(2) Section 3.3 (“Greedy Semantic Clustering for Path Aggregation”) appears potentially fragile, as its behavior can depend heavily on the choice of embedding model."}, "questions": {"value": "(1) In Section 2.1’s rule-based extraction, why emphasize taking the last numeric token to compute confidence? Does this mean the analysis of extraction methods’ impact on CoT-decoding was evaluated primarily on math-style fixed-answer QA?\n\n(2) Backtracking is triggered only at the first local minimum below δ, and each path backtracks at most once. Could this single-shot method miss later errors that arise further in the sequence?\n\n(3) For LCS(gen1, gen2) you score only the terminal aligned segment. If the answer phrase appears multiple times, or if tokenization/punctuation differs slightly, could this introduce instability in the confidence calculation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WJszsFh7DP", "forum": "2U5VWDwhKU", "replyto": "2U5VWDwhKU", "signatures": ["ICLR.cc/2026/Conference/Submission7853/Reviewer_dEkg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7853/Reviewer_dEkg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7853/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886019845, "cdate": 1761886019845, "tmdate": 1762919892994, "mdate": 1762919892994, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}